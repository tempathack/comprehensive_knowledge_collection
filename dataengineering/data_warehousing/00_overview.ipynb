{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7636ab0",
   "metadata": {},
   "source": [
    "# Data Warehousing — Overview\n",
    "\n",
    "## Purpose\n",
    "This notebook provides a comprehensive introduction to **data warehousing** concepts, architectures, and modern platforms. Data warehouses are central to business intelligence, enabling organizations to consolidate, analyze, and derive insights from vast amounts of data.\n",
    "\n",
    "## Key Questions\n",
    "1. What is a data warehouse, and how does it differ from operational databases?\n",
    "2. What are OLAP and OLTP, and when should each be used?\n",
    "3. How do star and snowflake schemas structure data for analytics?\n",
    "4. What is dimensional modeling, and why are facts and dimensions important?\n",
    "5. What are the leading modern data warehouse platforms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728b2c3f",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. What is a Data Warehouse?\n",
    "\n",
    "A **data warehouse** is a centralized repository designed to store, integrate, and manage large volumes of structured data from multiple sources. It is optimized for **analytical queries** and **reporting**, rather than transactional processing.\n",
    "\n",
    "### Characteristics of a Data Warehouse\n",
    "| Characteristic | Description |\n",
    "|----------------|-------------|\n",
    "| **Subject-Oriented** | Organized around key business subjects (e.g., sales, customers, products) |\n",
    "| **Integrated** | Consolidates data from disparate sources into a consistent format |\n",
    "| **Time-Variant** | Maintains historical data for trend analysis |\n",
    "| **Non-Volatile** | Data is stable; once loaded, it is not frequently changed |\n",
    "\n",
    "### Data Warehouse vs. Data Lake\n",
    "| Aspect | Data Warehouse | Data Lake |\n",
    "|--------|----------------|----------|\n",
    "| **Data Type** | Structured, curated | Raw, unstructured, semi-structured |\n",
    "| **Schema** | Schema-on-write | Schema-on-read |\n",
    "| **Use Case** | BI, reporting, dashboards | ML, data science, exploration |\n",
    "| **Processing** | ETL (Extract, Transform, Load) | ELT (Extract, Load, Transform) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef843ce1",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. OLAP vs. OLTP\n",
    "\n",
    "Understanding the difference between **OLAP** and **OLTP** is fundamental to data warehousing.\n",
    "\n",
    "### OLTP (Online Transaction Processing)\n",
    "- Designed for **transactional workloads** (inserts, updates, deletes)\n",
    "- Optimized for **fast, short queries** affecting few rows\n",
    "- Examples: banking systems, e-commerce order processing, CRM\n",
    "- Normalized schema to minimize redundancy\n",
    "\n",
    "### OLAP (Online Analytical Processing)\n",
    "- Designed for **complex analytical queries** across large datasets\n",
    "- Optimized for **aggregations, joins, and historical analysis**\n",
    "- Examples: sales trend analysis, financial reporting, dashboards\n",
    "- Denormalized schema for faster reads\n",
    "\n",
    "### Comparison Table\n",
    "| Feature | OLTP | OLAP |\n",
    "|---------|------|------|\n",
    "| **Purpose** | Day-to-day operations | Analytical reporting |\n",
    "| **Query Type** | Simple, short | Complex, long-running |\n",
    "| **Data Volume per Query** | Small (rows) | Large (millions of rows) |\n",
    "| **Schema Design** | Normalized (3NF) | Denormalized (Star/Snowflake) |\n",
    "| **Concurrency** | High (many users) | Lower (analysts, reports) |\n",
    "| **Data Freshness** | Real-time | Periodic (batch loads) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5f30c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual Example: OLTP vs OLAP Query Patterns\n",
    "\n",
    "# OLTP Query Example (transactional - affects single row)\n",
    "oltp_query = \"\"\"\n",
    "SELECT order_id, customer_name, total_amount\n",
    "FROM orders\n",
    "WHERE order_id = 12345;\n",
    "\"\"\"\n",
    "\n",
    "# OLAP Query Example (analytical - aggregates millions of rows)\n",
    "olap_query = \"\"\"\n",
    "SELECT \n",
    "    d.year,\n",
    "    d.quarter,\n",
    "    p.category,\n",
    "    SUM(f.sales_amount) AS total_sales,\n",
    "    AVG(f.sales_amount) AS avg_sale\n",
    "FROM fact_sales f\n",
    "JOIN dim_date d ON f.date_key = d.date_key\n",
    "JOIN dim_product p ON f.product_key = p.product_key\n",
    "GROUP BY d.year, d.quarter, p.category\n",
    "ORDER BY d.year, d.quarter;\n",
    "\"\"\"\n",
    "\n",
    "print(\"OLTP Query (Single Record Lookup):\")\n",
    "print(oltp_query)\n",
    "print(\"\\nOLAP Query (Aggregation & Analysis):\")\n",
    "print(olap_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd611da",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Star Schema and Snowflake Schema\n",
    "\n",
    "Data warehouses typically use **dimensional models** organized as star or snowflake schemas.\n",
    "\n",
    "### Star Schema\n",
    "The **star schema** is the simplest and most widely used dimensional model.\n",
    "\n",
    "```\n",
    "                    ┌─────────────┐\n",
    "                    │  dim_date   │\n",
    "                    └──────┬──────┘\n",
    "                           │\n",
    "┌─────────────┐     ┌──────┴──────┐     ┌─────────────┐\n",
    "│ dim_product │─────│  fact_sales │─────│ dim_customer│\n",
    "└─────────────┘     └──────┬──────┘     └─────────────┘\n",
    "                           │\n",
    "                    ┌──────┴──────┐\n",
    "                    │  dim_store  │\n",
    "                    └─────────────┘\n",
    "```\n",
    "\n",
    "**Characteristics:**\n",
    "- Central **fact table** surrounded by **dimension tables**\n",
    "- Dimension tables are **denormalized** (flat)\n",
    "- Simple joins, excellent query performance\n",
    "- Some data redundancy in dimensions\n",
    "\n",
    "### Snowflake Schema\n",
    "The **snowflake schema** normalizes dimension tables into sub-dimensions.\n",
    "\n",
    "```\n",
    "┌───────────┐     ┌─────────────┐\n",
    "│  country  │─────│  dim_store  │\n",
    "└───────────┘     └──────┬──────┘\n",
    "                         │\n",
    "                  ┌──────┴──────┐\n",
    "                  │  fact_sales │\n",
    "                  └──────┬──────┘\n",
    "                         │\n",
    "┌───────────┐     ┌──────┴──────┐\n",
    "│ category  │─────│ dim_product │\n",
    "└───────────┘     └─────────────┘\n",
    "```\n",
    "\n",
    "**Characteristics:**\n",
    "- Dimension tables are **normalized** (split into related tables)\n",
    "- Reduces data redundancy\n",
    "- More complex joins, slightly slower queries\n",
    "- Easier to maintain data integrity\n",
    "\n",
    "### Comparison\n",
    "| Aspect | Star Schema | Snowflake Schema |\n",
    "|--------|-------------|------------------|\n",
    "| **Normalization** | Denormalized | Normalized |\n",
    "| **Query Complexity** | Simple | More complex |\n",
    "| **Query Performance** | Faster | Slower |\n",
    "| **Storage** | More redundancy | Less redundancy |\n",
    "| **Maintenance** | Easier updates to facts | Easier dimension integrity |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832679b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Star Schema Example: SQL DDL\n",
    "\n",
    "star_schema_ddl = \"\"\"\n",
    "-- DIMENSION TABLES (Denormalized)\n",
    "\n",
    "CREATE TABLE dim_date (\n",
    "    date_key        INT PRIMARY KEY,\n",
    "    full_date       DATE,\n",
    "    day_of_week     VARCHAR(10),\n",
    "    month           INT,\n",
    "    quarter         INT,\n",
    "    year            INT,\n",
    "    is_holiday      BOOLEAN\n",
    ");\n",
    "\n",
    "CREATE TABLE dim_product (\n",
    "    product_key     INT PRIMARY KEY,\n",
    "    product_id      VARCHAR(50),\n",
    "    product_name    VARCHAR(200),\n",
    "    category        VARCHAR(100),      -- Denormalized\n",
    "    subcategory     VARCHAR(100),      -- Denormalized\n",
    "    brand           VARCHAR(100),\n",
    "    unit_price      DECIMAL(10,2)\n",
    ");\n",
    "\n",
    "CREATE TABLE dim_customer (\n",
    "    customer_key    INT PRIMARY KEY,\n",
    "    customer_id     VARCHAR(50),\n",
    "    customer_name   VARCHAR(200),\n",
    "    city            VARCHAR(100),      -- Denormalized\n",
    "    state           VARCHAR(100),      -- Denormalized\n",
    "    country         VARCHAR(100),      -- Denormalized\n",
    "    segment         VARCHAR(50)\n",
    ");\n",
    "\n",
    "-- FACT TABLE (Measures + Foreign Keys)\n",
    "\n",
    "CREATE TABLE fact_sales (\n",
    "    sales_key       INT PRIMARY KEY,\n",
    "    date_key        INT REFERENCES dim_date(date_key),\n",
    "    product_key     INT REFERENCES dim_product(product_key),\n",
    "    customer_key    INT REFERENCES dim_customer(customer_key),\n",
    "    quantity        INT,\n",
    "    sales_amount    DECIMAL(12,2),\n",
    "    discount        DECIMAL(5,2),\n",
    "    profit          DECIMAL(12,2)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"Star Schema DDL Example:\")\n",
    "print(star_schema_ddl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f39edf",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Dimensional Modeling: Facts and Dimensions\n",
    "\n",
    "**Dimensional modeling** is a design technique optimized for data retrieval and analysis.\n",
    "\n",
    "### Fact Tables\n",
    "Fact tables contain **quantitative, measurable data** (metrics) about business events.\n",
    "\n",
    "| Property | Description |\n",
    "|----------|-------------|\n",
    "| **Measures** | Numeric values that can be aggregated (SUM, AVG, COUNT) |\n",
    "| **Foreign Keys** | References to dimension tables |\n",
    "| **Grain** | The level of detail (e.g., one row per transaction) |\n",
    "| **Types** | Transaction facts, periodic snapshots, accumulating snapshots |\n",
    "\n",
    "**Types of Fact Tables:**\n",
    "1. **Transaction Fact Table**: One row per event (e.g., each sale)\n",
    "2. **Periodic Snapshot**: One row per time period (e.g., daily inventory levels)\n",
    "3. **Accumulating Snapshot**: One row per lifecycle (e.g., order fulfillment stages)\n",
    "\n",
    "### Dimension Tables\n",
    "Dimension tables contain **descriptive attributes** that provide context to facts.\n",
    "\n",
    "| Property | Description |\n",
    "|----------|-------------|\n",
    "| **Attributes** | Descriptive fields (name, category, location) |\n",
    "| **Surrogate Key** | System-generated primary key |\n",
    "| **Natural Key** | Business identifier (e.g., product_id) |\n",
    "| **Hierarchies** | Drill-down paths (Year → Quarter → Month → Day) |\n",
    "\n",
    "### Slowly Changing Dimensions (SCD)\n",
    "Dimensions change over time. **SCD types** define how to handle changes:\n",
    "\n",
    "| Type | Strategy | Use Case |\n",
    "|------|----------|----------|\n",
    "| **SCD Type 1** | Overwrite old value | No history needed |\n",
    "| **SCD Type 2** | Add new row with version | Full history required |\n",
    "| **SCD Type 3** | Add column for previous value | Limited history |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1def120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCD Type 2 Example: Tracking Customer Address Changes\n",
    "\n",
    "scd_type2_example = \"\"\"\n",
    "-- SCD Type 2: Customer dimension with versioning\n",
    "\n",
    "CREATE TABLE dim_customer_scd2 (\n",
    "    customer_key        INT PRIMARY KEY,       -- Surrogate key\n",
    "    customer_id         VARCHAR(50),           -- Natural key (business key)\n",
    "    customer_name       VARCHAR(200),\n",
    "    city                VARCHAR(100),\n",
    "    state               VARCHAR(100),\n",
    "    country             VARCHAR(100),\n",
    "    effective_date      DATE,                  -- When this version became active\n",
    "    expiration_date     DATE,                  -- When this version expired (NULL = current)\n",
    "    is_current          BOOLEAN                -- Flag for current record\n",
    ");\n",
    "\n",
    "-- Example: Customer moved from New York to Los Angeles\n",
    "\n",
    "-- Original record (now expired)\n",
    "-- customer_key=1, customer_id='C001', city='New York', \n",
    "-- effective_date='2020-01-01', expiration_date='2024-06-15', is_current=FALSE\n",
    "\n",
    "-- New record (current)\n",
    "-- customer_key=2, customer_id='C001', city='Los Angeles',\n",
    "-- effective_date='2024-06-15', expiration_date=NULL, is_current=TRUE\n",
    "\n",
    "-- Query to get current customer data\n",
    "SELECT * FROM dim_customer_scd2 WHERE is_current = TRUE;\n",
    "\n",
    "-- Query to get customer data as of a specific date\n",
    "SELECT * FROM dim_customer_scd2 \n",
    "WHERE '2023-01-01' BETWEEN effective_date AND COALESCE(expiration_date, '9999-12-31');\n",
    "\"\"\"\n",
    "\n",
    "print(\"SCD Type 2 Implementation Example:\")\n",
    "print(scd_type2_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb86810",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Modern Data Warehouse Platforms\n",
    "\n",
    "Modern cloud data warehouses offer scalability, performance, and ease of use.\n",
    "\n",
    "### Platform Comparison\n",
    "\n",
    "| Platform | Provider | Key Features |\n",
    "|----------|----------|-------------|\n",
    "| **Snowflake** | Snowflake Inc. | Separation of storage/compute, near-zero maintenance, data sharing |\n",
    "| **BigQuery** | Google Cloud | Serverless, built-in ML, real-time analytics |\n",
    "| **Redshift** | AWS | Tight AWS integration, Spectrum for S3 queries, ML integration |\n",
    "| **Azure Synapse** | Microsoft | Unified analytics, Power BI integration, serverless options |\n",
    "| **Databricks SQL** | Databricks | Lakehouse architecture, Delta Lake, unified with ML |\n",
    "\n",
    "### Snowflake\n",
    "- **Architecture**: Multi-cluster shared data architecture\n",
    "- **Scaling**: Independent scaling of compute and storage\n",
    "- **Features**: Time travel, zero-copy cloning, secure data sharing\n",
    "- **Pricing**: Pay per second of compute used\n",
    "\n",
    "### Google BigQuery\n",
    "- **Architecture**: Serverless, columnar storage (Capacitor format)\n",
    "- **Scaling**: Automatic, no infrastructure management\n",
    "- **Features**: Built-in ML (BQML), streaming inserts, geospatial analysis\n",
    "- **Pricing**: Pay per query (bytes scanned) or flat-rate\n",
    "\n",
    "### Amazon Redshift\n",
    "- **Architecture**: Massively parallel processing (MPP), columnar storage\n",
    "- **Scaling**: RA3 nodes separate compute/storage, Serverless option\n",
    "- **Features**: Redshift Spectrum, ML integration, federated queries\n",
    "- **Pricing**: On-demand or reserved instances\n",
    "\n",
    "### Architecture Pattern: Modern Data Stack\n",
    "```\n",
    "┌─────────────┐     ┌─────────────┐     ┌─────────────┐\n",
    "│   Sources   │────▶│  Ingestion  │────▶│  Warehouse  │\n",
    "│ (DBs, APIs) │     │  (Fivetran) │     │ (Snowflake) │\n",
    "└─────────────┘     └─────────────┘     └──────┬──────┘\n",
    "                                               │\n",
    "                    ┌─────────────┐     ┌──────▼──────┐\n",
    "                    │     BI      │◀────│  Transform  │\n",
    "                    │  (Looker)   │     │    (dbt)    │\n",
    "                    └─────────────┘     └─────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb28b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Platform-Specific Query Syntax\n",
    "\n",
    "queries = {\n",
    "    \"Snowflake\": \"\"\"\n",
    "-- Snowflake: Time Travel (query data from 1 hour ago)\n",
    "SELECT * FROM sales AT (OFFSET => -3600);\n",
    "\n",
    "-- Snowflake: Zero-copy clone\n",
    "CREATE TABLE sales_backup CLONE sales;\n",
    "\n",
    "-- Snowflake: Clustering for performance\n",
    "ALTER TABLE fact_sales CLUSTER BY (date_key, product_key);\n",
    "\"\"\",\n",
    "    \n",
    "    \"BigQuery\": \"\"\"\n",
    "-- BigQuery: Partitioned table for cost optimization\n",
    "CREATE TABLE `project.dataset.sales`\n",
    "PARTITION BY DATE(sale_date)\n",
    "CLUSTER BY customer_id AS\n",
    "SELECT * FROM raw_sales;\n",
    "\n",
    "-- BigQuery: Built-in ML (create a forecasting model)\n",
    "CREATE MODEL `project.dataset.sales_forecast`\n",
    "OPTIONS(model_type='ARIMA_PLUS') AS\n",
    "SELECT sale_date, SUM(amount) as total_sales\n",
    "FROM sales GROUP BY sale_date;\n",
    "\"\"\",\n",
    "    \n",
    "    \"Redshift\": \"\"\"\n",
    "-- Redshift: Query data in S3 with Spectrum\n",
    "CREATE EXTERNAL SCHEMA spectrum_schema\n",
    "FROM DATA CATALOG DATABASE 'my_db'\n",
    "IAM_ROLE 'arn:aws:iam::123456789:role/RedshiftRole';\n",
    "\n",
    "-- Redshift: Distribution style for join optimization\n",
    "CREATE TABLE fact_sales (\n",
    "    sale_id INT,\n",
    "    customer_id INT,\n",
    "    amount DECIMAL(10,2)\n",
    ") DISTKEY(customer_id) SORTKEY(sale_date);\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "for platform, query in queries.items():\n",
    "    print(f\"=== {platform} ===\")\n",
    "    print(query)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c466db",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Best Practices for Data Warehousing\n",
    "\n",
    "### Design Principles\n",
    "1. **Define clear grain**: Establish the level of detail for each fact table\n",
    "2. **Use surrogate keys**: Synthetic keys protect against source system changes\n",
    "3. **Conform dimensions**: Shared dimensions across fact tables enable cross-analysis\n",
    "4. **Partition large tables**: Improve query performance and reduce costs\n",
    "5. **Document lineage**: Track data from source to warehouse\n",
    "\n",
    "### Performance Optimization\n",
    "| Technique | Description |\n",
    "|-----------|-------------|\n",
    "| **Partitioning** | Divide tables by date or key for faster scans |\n",
    "| **Clustering** | Co-locate related rows for efficient access |\n",
    "| **Materialized Views** | Pre-compute expensive aggregations |\n",
    "| **Column Pruning** | Select only needed columns to reduce I/O |\n",
    "| **Predicate Pushdown** | Filter early in query execution |\n",
    "\n",
    "### Data Quality\n",
    "- Implement data validation checks during ETL\n",
    "- Use tools like **dbt tests** or **Great Expectations**\n",
    "- Monitor for schema drift and data anomalies\n",
    "- Establish SLAs for data freshness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a71780",
   "metadata": {},
   "source": [
    "---\n",
    "## Takeaways\n",
    "\n",
    "| Concept | Key Points |\n",
    "|---------|------------|\n",
    "| **Data Warehouse** | Centralized, subject-oriented repository optimized for analytics |\n",
    "| **OLAP vs OLTP** | OLAP for complex analytics; OLTP for transactional operations |\n",
    "| **Star Schema** | Denormalized design with central fact table and dimension tables |\n",
    "| **Snowflake Schema** | Normalized dimensions for reduced redundancy |\n",
    "| **Dimensional Modeling** | Facts hold measures; Dimensions provide context |\n",
    "| **SCD Types** | Strategies for handling dimension changes over time |\n",
    "| **Modern Platforms** | Snowflake, BigQuery, Redshift offer cloud-scale analytics |\n",
    "\n",
    "### Next Steps\n",
    "- Explore **ETL/ELT pipelines** for loading data into warehouses\n",
    "- Learn **dbt (data build tool)** for transformation and testing\n",
    "- Practice designing dimensional models for real business scenarios\n",
    "- Understand cost optimization strategies for cloud warehouses"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
