{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67d29d31",
   "metadata": {},
   "source": [
    "# Cloud Data Engineering — Overview\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook provides an overview of cloud-based data engineering services across the three major cloud providers: AWS, Azure, and GCP. Understanding these services is essential for designing scalable, cost-effective, and resilient data pipelines in modern enterprise environments.\n",
    "\n",
    "## Key Questions\n",
    "\n",
    "1. What are the core data engineering services offered by each major cloud provider?\n",
    "2. How do equivalent services compare across AWS, Azure, and GCP?\n",
    "3. What factors should guide cloud service selection for data workloads?\n",
    "4. How do you design for multi-cloud or hybrid-cloud data architectures?\n",
    "5. What are the cost, performance, and operational trade-offs between providers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ddff77",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## AWS Data Services\n",
    "\n",
    "Amazon Web Services offers a comprehensive suite of data engineering services:\n",
    "\n",
    "### AWS Glue\n",
    "\n",
    "**Serverless ETL service** for data preparation and transformation.\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Glue Data Catalog** | Centralized metadata repository (Hive-compatible) |\n",
    "| **Glue Crawlers** | Automatic schema discovery and cataloging |\n",
    "| **Glue ETL Jobs** | PySpark/Scala-based serverless transformations |\n",
    "| **Glue Studio** | Visual ETL job authoring interface |\n",
    "| **Glue DataBrew** | No-code data preparation for analysts |\n",
    "\n",
    "```python\n",
    "# Example: Simple Glue ETL job structure\n",
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from awsglue.context import GlueContext\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "\n",
    "# Read from Glue Data Catalog\n",
    "datasource = glueContext.create_dynamic_frame.from_catalog(\n",
    "    database=\"my_database\",\n",
    "    table_name=\"raw_data\"\n",
    ")\n",
    "\n",
    "# Transform and write\n",
    "transformed = ApplyMapping.apply(frame=datasource, mappings=[...])\n",
    "glueContext.write_dynamic_frame.from_options(transformed, ...)\n",
    "```\n",
    "\n",
    "### Amazon EMR (Elastic MapReduce)\n",
    "\n",
    "**Managed big data platform** for running Apache Spark, Hive, Presto, and other frameworks.\n",
    "\n",
    "| Deployment Option | Use Case |\n",
    "|-------------------|----------|\n",
    "| **EMR on EC2** | Full control, persistent clusters |\n",
    "| **EMR on EKS** | Kubernetes-native Spark workloads |\n",
    "| **EMR Serverless** | Auto-scaling, pay-per-use compute |\n",
    "\n",
    "### Amazon Kinesis\n",
    "\n",
    "**Real-time streaming data platform** with multiple components:\n",
    "\n",
    "- **Kinesis Data Streams**: Low-latency data ingestion (sharded)\n",
    "- **Kinesis Data Firehose**: Zero-admin delivery to S3, Redshift, OpenSearch\n",
    "- **Kinesis Data Analytics**: SQL/Flink-based stream processing\n",
    "\n",
    "### Amazon S3 (Simple Storage Service)\n",
    "\n",
    "**Object storage** — the foundation of AWS data lakes.\n",
    "\n",
    "| Storage Class | Use Case | Retrieval |\n",
    "|---------------|----------|----------|\n",
    "| S3 Standard | Frequently accessed data | Immediate |\n",
    "| S3 Intelligent-Tiering | Unknown access patterns | Immediate |\n",
    "| S3 Glacier Instant | Archive with instant access | Immediate |\n",
    "| S3 Glacier Deep Archive | Long-term archive | 12-48 hours |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b589a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Azure Data Services\n",
    "\n",
    "Microsoft Azure provides tightly integrated data engineering services:\n",
    "\n",
    "### Azure Data Factory (ADF)\n",
    "\n",
    "**Cloud-scale ETL/ELT orchestration service** with 90+ native connectors.\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| **Pipelines** | Orchestration workflows with activities |\n",
    "| **Data Flows** | Spark-based visual transformations |\n",
    "| **Integration Runtime** | Compute for data movement (Azure, self-hosted, SSIS) |\n",
    "| **Triggers** | Schedule, tumbling window, or event-based execution |\n",
    "\n",
    "```json\n",
    "// Example: ADF pipeline definition structure\n",
    "{\n",
    "  \"name\": \"IngestPipeline\",\n",
    "  \"properties\": {\n",
    "    \"activities\": [\n",
    "      {\n",
    "        \"name\": \"CopyFromBlobToLake\",\n",
    "        \"type\": \"Copy\",\n",
    "        \"inputs\": [{\"referenceName\": \"BlobSource\"}],\n",
    "        \"outputs\": [{\"referenceName\": \"LakeSink\"}]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Azure Databricks\n",
    "\n",
    "**Unified analytics platform** built on Apache Spark with collaborative notebooks.\n",
    "\n",
    "- **Delta Lake**: ACID transactions on data lakes\n",
    "- **Unity Catalog**: Unified governance across workspaces\n",
    "- **Photon Engine**: Vectorized query execution (3-8x faster)\n",
    "- **MLflow Integration**: End-to-end ML lifecycle management\n",
    "\n",
    "### Azure Synapse Analytics\n",
    "\n",
    "**Unified analytics service** combining data warehousing and big data.\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| **Dedicated SQL Pool** | MPP data warehouse (formerly SQL DW) |\n",
    "| **Serverless SQL Pool** | Query data lake files directly |\n",
    "| **Spark Pools** | Managed Apache Spark clusters |\n",
    "| **Synapse Pipelines** | ADF-compatible orchestration |\n",
    "| **Synapse Link** | Real-time analytics on operational data |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973bf503",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## GCP Data Services\n",
    "\n",
    "Google Cloud Platform leverages Google's expertise in large-scale data processing:\n",
    "\n",
    "### Cloud Dataflow\n",
    "\n",
    "**Serverless stream and batch processing** based on Apache Beam.\n",
    "\n",
    "```python\n",
    "# Example: Simple Dataflow pipeline\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "\n",
    "options = PipelineOptions([\n",
    "    '--runner=DataflowRunner',\n",
    "    '--project=my-project',\n",
    "    '--region=us-central1',\n",
    "    '--temp_location=gs://my-bucket/temp'\n",
    "])\n",
    "\n",
    "with beam.Pipeline(options=options) as p:\n",
    "    (p \n",
    "     | 'Read' >> beam.io.ReadFromPubSub(topic='projects/my-project/topics/events')\n",
    "     | 'Transform' >> beam.Map(process_event)\n",
    "     | 'Write' >> beam.io.WriteToBigQuery('dataset.table'))\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "- Unified batch and streaming model\n",
    "- Auto-scaling and dynamic work rebalancing\n",
    "- Exactly-once processing semantics\n",
    "\n",
    "### Cloud Dataproc\n",
    "\n",
    "**Managed Spark/Hadoop service** with fast cluster provisioning (~90 seconds).\n",
    "\n",
    "| Feature | Benefit |\n",
    "|---------|--------|\n",
    "| **Preemptible VMs** | Up to 80% cost savings |\n",
    "| **Component Gateway** | Easy access to Spark UI, Jupyter |\n",
    "| **Autoscaling** | Scale workers based on YARN metrics |\n",
    "| **Dataproc Serverless** | No cluster management required |\n",
    "\n",
    "### Cloud Pub/Sub\n",
    "\n",
    "**Serverless messaging service** for event-driven architectures.\n",
    "\n",
    "- **At-least-once delivery** with exactly-once processing (with Dataflow)\n",
    "- **Push and pull subscriptions**\n",
    "- **Message retention**: Up to 31 days\n",
    "- **Dead-letter topics** for failed message handling\n",
    "\n",
    "### Google Cloud Storage (GCS)\n",
    "\n",
    "**Object storage** with strong consistency and global edge caching.\n",
    "\n",
    "| Storage Class | Min Duration | Use Case |\n",
    "|---------------|--------------|----------|\n",
    "| Standard | None | Frequently accessed |\n",
    "| Nearline | 30 days | Monthly access |\n",
    "| Coldline | 90 days | Quarterly access |\n",
    "| Archive | 365 days | Yearly access |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc11d04",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Service Comparison Matrix\n",
    "\n",
    "| Capability | AWS | Azure | GCP |\n",
    "|------------|-----|-------|-----|\n",
    "| **ETL/Orchestration** | Glue, Step Functions | Data Factory, Synapse Pipelines | Dataflow, Cloud Composer |\n",
    "| **Managed Spark** | EMR, Glue | Databricks, Synapse Spark | Dataproc, Dataproc Serverless |\n",
    "| **Streaming** | Kinesis | Event Hubs, Stream Analytics | Pub/Sub, Dataflow |\n",
    "| **Object Storage** | S3 | Blob Storage, ADLS Gen2 | Cloud Storage |\n",
    "| **Data Warehouse** | Redshift | Synapse Dedicated Pool | BigQuery |\n",
    "| **Data Catalog** | Glue Data Catalog | Purview | Data Catalog |\n",
    "| **Serverless Query** | Athena | Synapse Serverless | BigQuery |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45833934",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cost Optimization & FinOps\n",
    "\n",
    "**Common cost drivers:**\n",
    "- Storage growth (hot vs cold tiers)\n",
    "- Data egress between regions/providers\n",
    "- Over-provisioned clusters or long-running jobs\n",
    "\n",
    "**Practices:**\n",
    "- Use **serverless** where possible for spiky workloads.\n",
    "- Apply **auto-scaling** and **spot/preemptible** instances.\n",
    "- Optimize file formats (Parquet/ORC), partitioning, and compaction.\n",
    "- Set **budgets/alerts** and chargeback tags.\n",
    "\n",
    "**Decision hint:** Start with cost visibility (tags, budgets), then optimize the biggest line items first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8850ef3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Security, Governance, and Observability\n",
    "\n",
    "**Security & IAM**\n",
    "- Enforce **least privilege** with scoped roles and service accounts.\n",
    "- Use **customer-managed keys** (KMS) for encryption at rest.\n",
    "- Centralize secrets (AWS Secrets Manager, Azure Key Vault, GCP Secret Manager).\n",
    "\n",
    "**Governance**\n",
    "- Data catalogs + lineage (Glue Data Catalog, Purview, Data Catalog).\n",
    "- Policy enforcement (row/column-level security, masking).\n",
    "- Data classification and retention policies.\n",
    "\n",
    "**Observability**\n",
    "- Unified logging/metrics/tracing (CloudWatch, Azure Monitor, Cloud Logging).\n",
    "- Data pipeline SLIs: freshness, completeness, failure rate, cost per TB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa7f05",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Multi-Cloud Considerations\n",
    "\n",
    "### Why Multi-Cloud?\n",
    "\n",
    "| Driver | Example |\n",
    "|--------|--------|\n",
    "| **Best-of-breed** | BigQuery for analytics + AWS for ML |\n",
    "| **Vendor lock-in avoidance** | Portability requirements |\n",
    "| **Regulatory/compliance** | Data residency constraints |\n",
    "| **M&A integration** | Inherited cloud environments |\n",
    "| **Resilience** | Cross-cloud disaster recovery |\n",
    "\n",
    "### Multi-Cloud Data Patterns\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                    Multi-Cloud Data Mesh                    │\n",
    "├─────────────────┬─────────────────┬─────────────────────────┤\n",
    "│      AWS        │     Azure       │         GCP             │\n",
    "│  ┌───────────┐  │  ┌───────────┐  │  ┌───────────────────┐  │\n",
    "│  │ S3 Lake   │  │  │ ADLS Gen2 │  │  │ BigQuery + GCS    │  │\n",
    "│  └─────┬─────┘  │  └─────┬─────┘  │  └─────────┬─────────┘  │\n",
    "│        │        │        │        │            │            │\n",
    "│        └────────┴────────┴────────┴────────────┘            │\n",
    "│                         │                                   │\n",
    "│              ┌──────────▼──────────┐                        │\n",
    "│              │  Data Virtualization │                       │\n",
    "│              │  (Starburst/Dremio)  │                       │\n",
    "│              └─────────────────────┘                        │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Key Challenges\n",
    "\n",
    "1. **Data Movement Costs**: Egress fees between clouds ($0.08-0.12/GB)\n",
    "2. **Latency**: Cross-cloud network latency (50-150ms typical)\n",
    "3. **Consistency**: Eventual consistency across distributed systems\n",
    "4. **Security**: Unified IAM and encryption key management\n",
    "5. **Observability**: Centralized monitoring across providers\n",
    "\n",
    "### Multi-Cloud Tools & Strategies\n",
    "\n",
    "| Approach | Tools |\n",
    "|----------|-------|\n",
    "| **Data Virtualization** | Starburst, Dremio, Denodo |\n",
    "| **Portable Compute** | Apache Spark, Apache Beam, Kubernetes |\n",
    "| **Open Formats** | Parquet, Avro, Delta Lake, Apache Iceberg |\n",
    "| **Infrastructure as Code** | Terraform, Pulumi |\n",
    "| **Unified Orchestration** | Apache Airflow, Dagster, Prefect |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41e589f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Takeaway\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "1. **Each cloud has strengths**: AWS excels in breadth, Azure in enterprise integration, GCP in analytics and ML\n",
    "\n",
    "2. **Serverless is the trend**: Glue, Dataflow, Synapse Serverless reduce operational overhead\n",
    "\n",
    "3. **Open formats enable portability**: Parquet, Delta Lake, and Iceberg reduce vendor lock-in\n",
    "\n",
    "4. **Multi-cloud requires investment**: Added complexity in networking, security, and operations\n",
    "\n",
    "5. **Cost optimization is critical**: Reserved capacity, spot instances, and right-sizing impact TCO significantly\n",
    "\n",
    "### Decision Framework\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────┐\n",
    "│              Cloud Selection Criteria                   │\n",
    "├─────────────────────────────────────────────────────────┤\n",
    "│  1. Existing ecosystem (enterprise agreements, skills)  │\n",
    "│  2. Specific service capabilities required              │\n",
    "│  3. Data residency and compliance requirements          │\n",
    "│  4. Integration with source/target systems              │\n",
    "│  5. Total cost of ownership (compute + egress + ops)    │\n",
    "│  6. Future portability requirements                     │\n",
    "└─────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "- AWS Well-Architected Framework — Data Analytics Lens\n",
    "- Azure Cloud Adoption Framework — Data Management\n",
    "- Google Cloud Architecture Framework — Data Analytics\n",
    "- Data Mesh: Delivering Data-Driven Value at Scale (Zhamak Dehghani)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
