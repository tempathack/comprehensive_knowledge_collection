{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db3d7ecb",
   "metadata": {},
   "source": [
    "# Data Engineering — Overview\n",
    "\n",
    "## Purpose\n",
    "To understand the fundamentals of data engineering, including its role in the data ecosystem, core concepts like ETL/ELT and data pipelines, and the modern data stack architecture.\n",
    "\n",
    "## Key Questions\n",
    "- What is data engineering and why is it critical for data-driven organizations?\n",
    "- What are the differences between ETL and ELT approaches?\n",
    "- How do batch and streaming processing differ?\n",
    "- What components make up the modern data stack?\n",
    "- How do data engineers ensure data quality and reliability?\n",
    "\n",
    "## Topics\n",
    "1. What is Data Engineering?\n",
    "2. Core Concepts: Pipelines, ETL/ELT, Batch vs Streaming\n",
    "3. The Modern Data Stack\n",
    "4. Data Engineering Landscape Visualization\n",
    "5. Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6919fa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. What is Data Engineering?\n",
    "\n",
    "**Data Engineering** is the discipline of designing, building, and maintaining the infrastructure and systems that enable the collection, storage, transformation, and delivery of data at scale.\n",
    "\n",
    "### Role in the Data Ecosystem\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                           DATA ECOSYSTEM                                     │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                              │\n",
    "│   Data Sources          Data Engineering           Data Consumers           │\n",
    "│   ────────────          ────────────────           ──────────────           │\n",
    "│                                                                              │\n",
    "│   • Databases     ──►   • Ingestion         ──►   • Data Scientists         │\n",
    "│   • APIs                • Transformation          • Analysts                │\n",
    "│   • IoT Devices         • Storage                 • ML Engineers            │\n",
    "│   • Log Files           • Orchestration           • Business Users          │\n",
    "│   • SaaS Apps           • Quality                 • Applications            │\n",
    "│                                                                              │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Key Responsibilities\n",
    "\n",
    "| Responsibility | Description |\n",
    "|----------------|-------------|\n",
    "| **Data Ingestion** | Collecting data from various sources (APIs, databases, files, streams) |\n",
    "| **Data Transformation** | Cleaning, validating, and transforming raw data into usable formats |\n",
    "| **Data Storage** | Designing and managing data warehouses, lakes, and lakehouses |\n",
    "| **Data Orchestration** | Scheduling and managing data pipeline workflows |\n",
    "| **Data Quality** | Ensuring accuracy, completeness, and reliability of data |\n",
    "| **Infrastructure** | Building and maintaining scalable data infrastructure |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d72445f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Core Concepts\n",
    "\n",
    "### Data Pipelines\n",
    "\n",
    "A **data pipeline** is a series of data processing steps that move data from source to destination, applying transformations along the way.\n",
    "\n",
    "```\n",
    "┌──────────┐    ┌──────────┐    ┌───────────┐    ┌──────────┐    ┌─────────────┐\n",
    "│  SOURCE  │───►│ EXTRACT  │───►│ TRANSFORM │───►│   LOAD   │───►│ DESTINATION │\n",
    "└──────────┘    └──────────┘    └───────────┘    └──────────┘    └─────────────┘\n",
    "                     │               │               │\n",
    "                     ▼               ▼               ▼\n",
    "                Validation      Business        Quality\n",
    "                & Schema        Logic           Checks\n",
    "```\n",
    "\n",
    "### ETL vs ELT\n",
    "\n",
    "| Aspect | ETL (Extract-Transform-Load) | ELT (Extract-Load-Transform) |\n",
    "|--------|------------------------------|------------------------------|\n",
    "| **Order** | Transform before loading | Load first, transform in destination |\n",
    "| **Where** | Transformation on separate server | Transformation in data warehouse |\n",
    "| **Best For** | On-premise, structured data | Cloud, large-scale analytics |\n",
    "| **Speed** | Slower for large datasets | Faster loading, scalable transforms |\n",
    "| **Cost** | Compute costs upfront | Warehouse compute costs |\n",
    "| **Tools** | Informatica, Talend, SSIS | dbt, Snowflake, BigQuery |\n",
    "\n",
    "### Batch vs Streaming Processing\n",
    "\n",
    "| Characteristic | Batch Processing | Stream Processing |\n",
    "|----------------|------------------|-------------------|\n",
    "| **Latency** | Minutes to hours | Milliseconds to seconds |\n",
    "| **Data Volume** | Large historical datasets | Continuous real-time data |\n",
    "| **Use Cases** | Reports, analytics, ML training | Real-time dashboards, alerts, fraud detection |\n",
    "| **Complexity** | Lower | Higher |\n",
    "| **Tools** | Spark, Hive, Airflow | Kafka, Flink, Spark Streaming |\n",
    "| **Processing** | All data at once | Record by record or micro-batches |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ed819d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. The Modern Data Stack\n",
    "\n",
    "The **Modern Data Stack (MDS)** is a collection of cloud-native tools that work together to collect, store, transform, and analyze data.\n",
    "\n",
    "### Architecture Layers\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                        MODERN DATA STACK                                     │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                              │\n",
    "│  ┌─────────────────────────────────────────────────────────────────────┐    │\n",
    "│  │ CONSUMPTION: Tableau, Looker, Power BI, Metabase, Custom Apps       │    │\n",
    "│  └─────────────────────────────────────────────────────────────────────┘    │\n",
    "│                                    ▲                                         │\n",
    "│  ┌─────────────────────────────────────────────────────────────────────┐    │\n",
    "│  │ TRANSFORMATION: dbt, Dataform, Spark                                │    │\n",
    "│  └─────────────────────────────────────────────────────────────────────┘    │\n",
    "│                                    ▲                                         │\n",
    "│  ┌─────────────────────────────────────────────────────────────────────┐    │\n",
    "│  │ STORAGE: Snowflake, BigQuery, Databricks, Redshift                  │    │\n",
    "│  └─────────────────────────────────────────────────────────────────────┘    │\n",
    "│                                    ▲                                         │\n",
    "│  ┌─────────────────────────────────────────────────────────────────────┐    │\n",
    "│  │ INGESTION: Fivetran, Airbyte, Stitch, Debezium                      │    │\n",
    "│  └─────────────────────────────────────────────────────────────────────┘    │\n",
    "│                                    ▲                                         │\n",
    "│  ┌─────────────────────────────────────────────────────────────────────┐    │\n",
    "│  │ ORCHESTRATION: Airflow, Dagster, Prefect, Mage                      │    │\n",
    "│  └─────────────────────────────────────────────────────────────────────┘    │\n",
    "│                                                                              │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Key Components\n",
    "\n",
    "| Layer | Purpose | Popular Tools |\n",
    "|-------|---------|---------------|\n",
    "| **Ingestion** | Extract data from sources | Fivetran, Airbyte, Stitch, Debezium |\n",
    "| **Storage** | Centralized data repository | Snowflake, BigQuery, Databricks, Redshift |\n",
    "| **Transformation** | Model and transform data | dbt, Dataform, Spark SQL |\n",
    "| **Orchestration** | Workflow scheduling | Airflow, Dagster, Prefect |\n",
    "| **Quality** | Data validation & testing | Great Expectations, dbt tests, Monte Carlo |\n",
    "| **Catalog** | Metadata management | Atlan, DataHub, Alation |\n",
    "| **Consumption** | Visualization & analysis | Tableau, Looker, Power BI, Metabase |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1cb9f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Data Engineering Landscape Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5122d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Data Engineering Landscape - Sunburst Chart\n",
    "labels = [\n",
    "    \"Data Engineering\",\n",
    "    # Level 1: Main Categories\n",
    "    \"Ingestion\", \"Storage\", \"Processing\", \"Orchestration\", \"Quality\", \"Consumption\",\n",
    "    # Level 2: Ingestion\n",
    "    \"Batch Ingestion\", \"Stream Ingestion\", \"CDC\",\n",
    "    # Level 2: Storage\n",
    "    \"Data Warehouse\", \"Data Lake\", \"Lakehouse\",\n",
    "    # Level 2: Processing\n",
    "    \"Batch\", \"Stream\", \"Transformation\",\n",
    "    # Level 2: Orchestration\n",
    "    \"Workflow\", \"Scheduling\", \"Monitoring\",\n",
    "    # Level 2: Quality\n",
    "    \"Validation\", \"Testing\", \"Observability\",\n",
    "    # Level 2: Consumption\n",
    "    \"BI Tools\", \"ML/AI\", \"APIs\"\n",
    "]\n",
    "\n",
    "parents = [\n",
    "    \"\",\n",
    "    # Level 1 parents\n",
    "    \"Data Engineering\", \"Data Engineering\", \"Data Engineering\", \n",
    "    \"Data Engineering\", \"Data Engineering\", \"Data Engineering\",\n",
    "    # Level 2: Ingestion parents\n",
    "    \"Ingestion\", \"Ingestion\", \"Ingestion\",\n",
    "    # Level 2: Storage parents\n",
    "    \"Storage\", \"Storage\", \"Storage\",\n",
    "    # Level 2: Processing parents\n",
    "    \"Processing\", \"Processing\", \"Processing\",\n",
    "    # Level 2: Orchestration parents\n",
    "    \"Orchestration\", \"Orchestration\", \"Orchestration\",\n",
    "    # Level 2: Quality parents\n",
    "    \"Quality\", \"Quality\", \"Quality\",\n",
    "    # Level 2: Consumption parents\n",
    "    \"Consumption\", \"Consumption\", \"Consumption\"\n",
    "]\n",
    "\n",
    "values = [\n",
    "    100,\n",
    "    # Level 1 values\n",
    "    18, 20, 22, 15, 12, 13,\n",
    "    # Level 2 values\n",
    "    6, 7, 5,\n",
    "    8, 6, 6,\n",
    "    8, 7, 7,\n",
    "    6, 5, 4,\n",
    "    4, 4, 4,\n",
    "    5, 5, 3\n",
    "]\n",
    "\n",
    "colors = [\n",
    "    \"#2E4057\",  # Center\n",
    "    # Level 1 colors\n",
    "    \"#048A81\", \"#54C6EB\", \"#8EE3EF\", \"#F7A072\", \"#D64550\", \"#7D5BA6\",\n",
    "    # Level 2 colors (lighter shades)\n",
    "    \"#06B6A8\", \"#07D4C4\", \"#05A89A\",\n",
    "    \"#6DD4F5\", \"#85DCFA\", \"#9EE4FC\",\n",
    "    \"#A8EBF3\", \"#C2F1F7\", \"#DCF7FB\",\n",
    "    \"#F9B894\", \"#FACAAD\", \"#FCDCC6\",\n",
    "    \"#E06B75\", \"#EA919A\", \"#F4B7BE\",\n",
    "    \"#9A7FC0\", \"#B7A3D4\", \"#D4C7E8\"\n",
    "]\n",
    "\n",
    "fig = go.Figure(go.Sunburst(\n",
    "    labels=labels,\n",
    "    parents=parents,\n",
    "    values=values,\n",
    "    marker=dict(colors=colors),\n",
    "    branchvalues=\"total\",\n",
    "    hovertemplate='<b>%{label}</b><br>Relative Weight: %{value}<extra></extra>',\n",
    "    textfont=dict(size=12)\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Data Engineering Landscape\",\n",
    "        font=dict(size=20, color=\"#2E4057\"),\n",
    "        x=0.5\n",
    "    ),\n",
    "    width=700,\n",
    "    height=600,\n",
    "    margin=dict(t=60, l=20, r=20, b=20)\n",
    ")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ed97b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Batch vs Streaming Comparison\n",
    "categories = ['Latency', 'Throughput', 'Complexity', 'Cost Efficiency', 'Real-time Capability', 'Fault Tolerance']\n",
    "\n",
    "batch_scores = [2, 5, 2, 4, 1, 4]  # 1-5 scale\n",
    "streaming_scores = [5, 3, 4, 3, 5, 3]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "    r=batch_scores + [batch_scores[0]],\n",
    "    theta=categories + [categories[0]],\n",
    "    fill='toself',\n",
    "    name='Batch Processing',\n",
    "    line=dict(color='#048A81', width=2),\n",
    "    fillcolor='rgba(4, 138, 129, 0.3)'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "    r=streaming_scores + [streaming_scores[0]],\n",
    "    theta=categories + [categories[0]],\n",
    "    fill='toself',\n",
    "    name='Stream Processing',\n",
    "    line=dict(color='#D64550', width=2),\n",
    "    fillcolor='rgba(214, 69, 80, 0.3)'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, 5],\n",
    "            tickvals=[1, 2, 3, 4, 5],\n",
    "            ticktext=['Low', '', 'Medium', '', 'High']\n",
    "        )\n",
    "    ),\n",
    "    title=dict(\n",
    "        text=\"Batch vs Stream Processing Comparison\",\n",
    "        font=dict(size=18, color=\"#2E4057\"),\n",
    "        x=0.5\n",
    "    ),\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=-0.15,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5\n",
    "    ),\n",
    "    width=650,\n",
    "    height=500,\n",
    "    margin=dict(t=80, b=80)\n",
    ")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16010e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Modern Data Stack Tools by Category\n",
    "categories = ['Ingestion', 'Storage', 'Transformation', 'Orchestration', 'Quality', 'BI/Analytics']\n",
    "tools_count = [12, 8, 6, 10, 7, 15]\n",
    "adoption_rate = [78, 92, 85, 72, 58, 88]  # Percentage\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=(\"Tools Available by Category\", \"Enterprise Adoption Rate (%)\"),\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
    ")\n",
    "\n",
    "colors = ['#048A81', '#54C6EB', '#8EE3EF', '#F7A072', '#D64550', '#7D5BA6']\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=categories,\n",
    "        y=tools_count,\n",
    "        marker_color=colors,\n",
    "        text=tools_count,\n",
    "        textposition='outside',\n",
    "        name='Tools Count',\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=categories,\n",
    "        y=adoption_rate,\n",
    "        marker_color=colors,\n",
    "        text=[f\"{r}%\" for r in adoption_rate],\n",
    "        textposition='outside',\n",
    "        name='Adoption Rate',\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Modern Data Stack Overview\",\n",
    "        font=dict(size=20, color=\"#2E4057\"),\n",
    "        x=0.5\n",
    "    ),\n",
    "    width=900,\n",
    "    height=450,\n",
    "    margin=dict(t=80, b=60)\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title_text=\"Number of Tools\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Adoption Rate (%)\", range=[0, 100], row=1, col=2)\n",
    "fig.update_xaxes(tickangle=45)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a9d271",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Key Takeaways\n",
    "\n",
    "### Summary\n",
    "\n",
    "| Concept | Key Points |\n",
    "|---------|------------|\n",
    "| **Data Engineering** | Bridges data sources and consumers; enables data-driven decisions |\n",
    "| **ETL vs ELT** | ETL transforms before loading; ELT leverages warehouse compute power |\n",
    "| **Batch vs Stream** | Batch for throughput & analytics; Stream for real-time requirements |\n",
    "| **Modern Data Stack** | Cloud-native, modular tools working together |\n",
    "| **Data Quality** | Critical for trust; implement testing and observability |\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Design for Scale** — Build pipelines that can handle 10x growth\n",
    "2. **Embrace Modularity** — Use composable tools that do one thing well\n",
    "3. **Prioritize Data Quality** — Test data like you test code\n",
    "4. **Document Everything** — Maintain data catalogs and lineage\n",
    "5. **Monitor Proactively** — Set up alerts before issues impact downstream users\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "- [Fundamentals of Data Engineering](https://www.oreilly.com/library/view/fundamentals-of-data/9781098108298/) by Joe Reis & Matt Housley\n",
    "- [The Data Warehouse Toolkit](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/books/) by Ralph Kimball\n",
    "- [Designing Data-Intensive Applications](https://dataintensive.net/) by Martin Kleppmann"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}