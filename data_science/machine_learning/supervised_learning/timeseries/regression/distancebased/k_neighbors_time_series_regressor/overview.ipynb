{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c4a3a8",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Time Series Regressor (KNN-TS) — analog forecasting from scratch\n",
    "\n",
    "A **KNN time-series regressor** predicts by finding **similar past windows** (“analogs”) and averaging what happened **next**.\n",
    "\n",
    "Why it’s useful:\n",
    "- **non-parametric** baseline (no parametric trend/seasonality assumptions)\n",
    "- can model **nonlinear** patterns if they repeat in history\n",
    "- naturally provides a **distribution of plausible next values** via neighbor targets (confidence intuition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f855e",
   "metadata": {},
   "source": [
    "## Goals\n",
    "- Implement `KNeighborsTimeSeriesRegressor([...])` in **NumPy** (brute-force neighbors)\n",
    "- Show the key design choices: windowing, distance metric, normalization, weighting\n",
    "- Plot with **Plotly**:\n",
    "  - the raw series\n",
    "  - 1-step ahead forecasts with an **empirical prediction band** from neighbors\n",
    "  - a \"fan\" view to build confidence intuition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1179b4",
   "metadata": {},
   "source": [
    "## 1) Time series forecasting as supervised regression\n",
    "\n",
    "Given a univariate series $y_0, y_1, \\dots, y_{T-1}$, choose:\n",
    "- window length $L$ (how many past points to compare)\n",
    "- forecast horizon $h$ (predict how far ahead)\n",
    "\n",
    "Define the feature window and target:\n",
    "$$\n",
    "\\mathbf{x}_t = [y_{t-L},\\; y_{t-L+1},\\; \\dots,\\; y_{t-1}]^\\top \\in \\mathbb{R}^L,\n",
    "\\qquad\n",
    "y^{(\\mathrm{target})}_t = y_{t+h-1}.\n",
    "$$\n",
    "\n",
    "for $t = L, L+1, \\dots, T-h$.\n",
    "\n",
    "This builds a supervised dataset $(\\mathbf{x}_t, y^{(\\mathrm{target})}_t)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b81c66f",
   "metadata": {},
   "source": [
    "## 2) KNN regression on windows\n",
    "\n",
    "Given a query window $\\mathbf{x}$, compute distances to all training windows $\\{\\mathbf{x}_i\\}_{i=1}^n$:\n",
    "$$\n",
    "d_i = d(\\mathbf{x}, \\mathbf{x}_i).\n",
    "$$\n",
    "\n",
    "Let $\\mathcal{N}_k(\\mathbf{x})$ be the indices of the $k$ smallest distances.\n",
    "\n",
    "### Uniform-weight KNN regressor\n",
    "$$\n",
    "\\hat{y}(\\mathbf{x}) = \\frac{1}{k} \\sum_{i\\in\\mathcal{N}_k(\\mathbf{x})} y_i.\n",
    "$$\n",
    "\n",
    "### Distance-weighted KNN regressor\n",
    "A common choice is inverse-distance weights:\n",
    "$$\n",
    "w_i = \\frac{1}{d_i + \\varepsilon},\n",
    "\\qquad\n",
    "\\hat{y}(\\mathbf{x}) = \\frac{\\sum_{i\\in\\mathcal{N}_k(\\mathbf{x})} w_i y_i}{\\sum_{i\\in\\mathcal{N}_k(\\mathbf{x})} w_i}.\n",
    "$$\n",
    "\n",
    "### Distance choice matters\n",
    "- **Euclidean** on raw windows matches level + shape.\n",
    "- **Z-normalized** Euclidean (normalize each window to mean 0, std 1) matches *shape* more than level.\n",
    "- **DTW** (dynamic time warping) matches shapes that may be slightly time-warped.\n",
    "\n",
    "This notebook implements Euclidean (fast, vectorized) and DTW (slower, but instructive).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84cbf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "rng = np.random.default_rng(7)\n",
    "\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"plotly:\", plotly.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8d4984",
   "metadata": {},
   "source": [
    "## 3) Synthetic series with repeating structure\n",
    "\n",
    "KNN works well when patterns **repeat**. We’ll simulate a series with trend + multiple seasonalities + noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c07b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 520\n",
    "t = np.arange(n)\n",
    "dates = pd.date_range(\"2020-01-01\", periods=n, freq=\"D\")\n",
    "\n",
    "trend = 0.03 * t\n",
    "season_30 = 2.2 * np.sin(2 * np.pi * t / 30)\n",
    "season_7 = 0.9 * np.sin(2 * np.pi * t / 7)\n",
    "noise = rng.normal(0.0, 0.9, size=n)\n",
    "\n",
    "# A few shock events\n",
    "shocks = np.zeros(n)\n",
    "shock_idx = rng.choice(np.arange(40, n - 40), size=10, replace=False)\n",
    "shocks[shock_idx] = rng.normal(0.0, 4.0, size=len(shock_idx))\n",
    "\n",
    "y = 50 + trend + season_30 + season_7 + noise + shocks\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=dates, y=y, mode=\"lines\", name=\"y\"))\n",
    "fig.update_layout(height=350, title=\"Synthetic series (trend + seasonality + noise)\", xaxis_title=\"Time\", yaxis_title=\"Value\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128d7f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_supervised_windows(\n",
    "    y: np.ndarray,\n",
    "    *,\n",
    "    window_length: int,\n",
    "    horizon: int = 1,\n",
    "    stride: int = 1,\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Turn a 1D series into (X, y_target, t_target).\n",
    "\n",
    "    X[i] is a length-L window, and y_target[i] is the value horizon steps after the window end.\n",
    "    t_target[i] is the time index of y_target[i] in the original series.\n",
    "    \"\"\"\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    L = int(window_length)\n",
    "    h = int(horizon)\n",
    "    s = int(stride)\n",
    "    if L < 2:\n",
    "        raise ValueError(\"window_length must be >= 2\")\n",
    "    if h < 1:\n",
    "        raise ValueError(\"horizon must be >= 1\")\n",
    "    if s < 1:\n",
    "        raise ValueError(\"stride must be >= 1\")\n",
    "\n",
    "    last_start = y.size - L - h\n",
    "    if last_start < 0:\n",
    "        raise ValueError(\"y is too short for the chosen window_length/horizon\")\n",
    "\n",
    "    starts = np.arange(0, last_start + 1, s)\n",
    "    n_samples = len(starts)\n",
    "\n",
    "    X = np.empty((n_samples, L), dtype=float)\n",
    "    y_target = np.empty(n_samples, dtype=float)\n",
    "    t_target = np.empty(n_samples, dtype=int)\n",
    "\n",
    "    for i, start in enumerate(starts):\n",
    "        end = start + L\n",
    "        target_idx = end + h - 1\n",
    "        X[i] = y[start:end]\n",
    "        y_target[i] = y[target_idx]\n",
    "        t_target[i] = target_idx\n",
    "\n",
    "    return X, y_target, t_target\n",
    "\n",
    "\n",
    "L = 60\n",
    "horizon = 1\n",
    "\n",
    "X, y_next, t_next = make_supervised_windows(y, window_length=L, horizon=horizon, stride=1)\n",
    "\n",
    "h_test = 120\n",
    "X_train, y_train = X[:-h_test], y_next[:-h_test]\n",
    "X_test, y_test = X[-h_test:], y_next[-h_test:]\n",
    "t_test = t_next[-h_test:]\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"| X_test:\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape, \"| y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_per_series(X: np.ndarray, *, eps: float = 1e-8) -> np.ndarray:\n",
    "    \"\"\"Z-normalize each sample (and each dim) across time.\"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    if X.ndim == 2:\n",
    "        mu = X.mean(axis=1, keepdims=True)\n",
    "        sd = X.std(axis=1, keepdims=True)\n",
    "        return (X - mu) / (sd + eps)\n",
    "    if X.ndim == 3:\n",
    "        mu = X.mean(axis=2, keepdims=True)\n",
    "        sd = X.std(axis=2, keepdims=True)\n",
    "        return (X - mu) / (sd + eps)\n",
    "    raise ValueError(\"X must be 2D or 3D\")\n",
    "\n",
    "\n",
    "def pairwise_euclidean_distances(X_query: np.ndarray, X_train: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Fast pairwise Euclidean distances for 2D arrays (n_query, p) vs (n_train, p).\"\"\"\n",
    "    X_query = np.asarray(X_query, dtype=float)\n",
    "    X_train = np.asarray(X_train, dtype=float)\n",
    "    if X_query.ndim != 2 or X_train.ndim != 2:\n",
    "        raise ValueError(\"X_query and X_train must be 2D arrays\")\n",
    "    if X_query.shape[1] != X_train.shape[1]:\n",
    "        raise ValueError(\"X_query and X_train must have the same number of features\")\n",
    "\n",
    "    q_sq = np.sum(X_query**2, axis=1, keepdims=True)\n",
    "    t_sq = np.sum(X_train**2, axis=1)\n",
    "    d2 = q_sq + t_sq[None, :] - 2.0 * (X_query @ X_train.T)\n",
    "    d2 = np.maximum(d2, 0.0)\n",
    "    return np.sqrt(d2)\n",
    "\n",
    "\n",
    "def dtw_distance_1d(a: np.ndarray, b: np.ndarray, *, window: int | None = None) -> float:\n",
    "    \"\"\"DTW distance between two 1D sequences using squared-cost DP (optionally banded).\"\"\"\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    b = np.asarray(b, dtype=float)\n",
    "    n = a.size\n",
    "    m = b.size\n",
    "\n",
    "    if window is None:\n",
    "        window = max(n, m)\n",
    "    window = int(window)\n",
    "    window = max(window, abs(n - m))\n",
    "\n",
    "    D = np.full((n + 1, m + 1), np.inf)\n",
    "    D[0, 0] = 0.0\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        j_start = max(1, i - window)\n",
    "        j_end = min(m, i + window)\n",
    "        for j in range(j_start, j_end + 1):\n",
    "            cost = (a[i - 1] - b[j - 1]) ** 2\n",
    "            D[i, j] = cost + min(D[i - 1, j], D[i, j - 1], D[i - 1, j - 1])\n",
    "\n",
    "    return float(np.sqrt(D[n, m]))\n",
    "\n",
    "\n",
    "def pairwise_dtw_distances(X_query: np.ndarray, X_train: np.ndarray, *, window: int | None = None) -> np.ndarray:\n",
    "    X_query = np.asarray(X_query, dtype=float)\n",
    "    X_train = np.asarray(X_train, dtype=float)\n",
    "    if X_query.ndim != 2 or X_train.ndim != 2:\n",
    "        raise ValueError(\"X_query and X_train must be 2D arrays\")\n",
    "    if X_query.shape[1] != X_train.shape[1]:\n",
    "        raise ValueError(\"DTW here assumes equal-length windows\")\n",
    "\n",
    "    out = np.empty((X_query.shape[0], X_train.shape[0]), dtype=float)\n",
    "    for i in range(X_query.shape[0]):\n",
    "        for j in range(X_train.shape[0]):\n",
    "            out[i, j] = dtw_distance_1d(X_query[i], X_train[j], window=window)\n",
    "    return out\n",
    "\n",
    "\n",
    "def weighted_quantile_1d(values: np.ndarray, quantiles: np.ndarray, *, weights: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Weighted quantiles for 1D values. quantiles in [0,1].\"\"\"\n",
    "    values = np.asarray(values, dtype=float)\n",
    "    weights = np.asarray(weights, dtype=float)\n",
    "    quantiles = np.asarray(quantiles, dtype=float)\n",
    "    if values.ndim != 1 or weights.ndim != 1:\n",
    "        raise ValueError(\"values and weights must be 1D\")\n",
    "    if values.size != weights.size:\n",
    "        raise ValueError(\"values and weights must have the same length\")\n",
    "    if np.any(quantiles < 0) or np.any(quantiles > 1):\n",
    "        raise ValueError(\"quantiles must be in [0,1]\")\n",
    "\n",
    "    sorter = np.argsort(values)\n",
    "    v = values[sorter]\n",
    "    w = weights[sorter]\n",
    "    w_sum = np.sum(w)\n",
    "    if w_sum <= 0:\n",
    "        raise ValueError(\"sum of weights must be > 0\")\n",
    "\n",
    "    cdf = np.cumsum(w) / w_sum\n",
    "    return np.interp(quantiles, cdf, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d0f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _as_3d_panel(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Accept (n,m) or (n,d,m) and return (n,d,m).\"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    if X.ndim == 2:\n",
    "        return X[:, None, :]\n",
    "    if X.ndim == 3:\n",
    "        return X\n",
    "    raise ValueError(\"X must have shape (n,m) or (n,d,m)\")\n",
    "\n",
    "\n",
    "class KNeighborsTimeSeriesRegressor:\n",
    "    \"\"\"Brute-force KNN regressor for fixed-length time-series windows.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_neighbors : int\n",
    "        Number of neighbors (k).\n",
    "    weights : {\"uniform\",\"distance\"}\n",
    "        Uniform average or inverse-distance weighting.\n",
    "    metric : {\"euclidean\",\"dtw\"}\n",
    "        Distance metric between windows.\n",
    "    normalize : {None,\"zscore\",\"global\"}\n",
    "        - None: use raw windows\n",
    "        - \"zscore\": normalize each window to mean 0 and std 1 (shape matching)\n",
    "        - \"global\": normalize using training mean/std (level + scale normalization)\n",
    "    dtw_window : int | None\n",
    "        Sakoe-Chiba band size for DTW (None -> unconstrained).\n",
    "    eps : float\n",
    "        Small constant for inverse-distance weights.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        n_neighbors: int = 10,\n",
    "        weights: str = \"uniform\",\n",
    "        metric: str = \"euclidean\",\n",
    "        normalize: str | None = \"zscore\",\n",
    "        dtw_window: int | None = None,\n",
    "        eps: float = 1e-8,\n",
    "    ):\n",
    "        self.n_neighbors = int(n_neighbors)\n",
    "        self.weights = str(weights)\n",
    "        self.metric = str(metric)\n",
    "        self.normalize = normalize\n",
    "        self.dtw_window = dtw_window\n",
    "        self.eps = float(eps)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X3 = _as_3d_panel(X)\n",
    "        y = np.asarray(y, dtype=float).reshape(-1)\n",
    "        if X3.shape[0] != y.size:\n",
    "            raise ValueError(\"X and y must have the same number of samples\")\n",
    "        if self.n_neighbors < 1:\n",
    "            raise ValueError(\"n_neighbors must be >= 1\")\n",
    "        if self.weights not in {\"uniform\", \"distance\"}:\n",
    "            raise ValueError(\"weights must be 'uniform' or 'distance'\")\n",
    "        if self.metric not in {\"euclidean\", \"dtw\"}:\n",
    "            raise ValueError(\"metric must be 'euclidean' or 'dtw'\")\n",
    "        if self.normalize not in {None, \"zscore\", \"global\"}:\n",
    "            raise ValueError(\"normalize must be None, 'zscore', or 'global'\")\n",
    "\n",
    "        self.n_train_ = int(X3.shape[0])\n",
    "        self.n_dims_ = int(X3.shape[1])\n",
    "        self.n_timepoints_ = int(X3.shape[2])\n",
    "\n",
    "        self.X_train_raw_ = X3.copy()\n",
    "        self.y_train_ = y.copy()\n",
    "\n",
    "        if self.normalize == \"global\":\n",
    "            mu = X3.mean(axis=(0, 2), keepdims=True)\n",
    "            sd = X3.std(axis=(0, 2), keepdims=True)\n",
    "            self._mu_ = mu\n",
    "            self._sd_ = sd\n",
    "            self.X_train_ = (X3 - mu) / (sd + self.eps)\n",
    "        elif self.normalize == \"zscore\":\n",
    "            self.X_train_ = zscore_per_series(X3, eps=self.eps)\n",
    "        else:\n",
    "            self.X_train_ = X3\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _transform(self, X) -> np.ndarray:\n",
    "        X3 = _as_3d_panel(X)\n",
    "        if X3.shape[1] != self.n_dims_ or X3.shape[2] != self.n_timepoints_:\n",
    "            raise ValueError(\n",
    "                f\"X must have shape (n,{self.n_dims_},{self.n_timepoints_}) (or (n,{self.n_timepoints_}) for univariate)\"\n",
    "            )\n",
    "\n",
    "        if self.normalize == \"global\":\n",
    "            return (X3 - self._mu_) / (self._sd_ + self.eps)\n",
    "        if self.normalize == \"zscore\":\n",
    "            return zscore_per_series(X3, eps=self.eps)\n",
    "        return X3\n",
    "\n",
    "    def _pairwise_distances(self, X_query) -> np.ndarray:\n",
    "        Q3 = self._transform(X_query)\n",
    "        T3 = self.X_train_\n",
    "\n",
    "        if self.metric == \"euclidean\":\n",
    "            Q2 = Q3.reshape(Q3.shape[0], -1)\n",
    "            T2 = T3.reshape(T3.shape[0], -1)\n",
    "            return pairwise_euclidean_distances(Q2, T2)\n",
    "\n",
    "        # DTW implementation here is univariate for simplicity.\n",
    "        if self.n_dims_ != 1:\n",
    "            raise ValueError(\"DTW metric currently supports only univariate windows\")\n",
    "        Q2 = Q3[:, 0, :]\n",
    "        T2 = T3[:, 0, :]\n",
    "        return pairwise_dtw_distances(Q2, T2, window=self.dtw_window)\n",
    "\n",
    "    def kneighbors(self, X_query) -> tuple[np.ndarray, np.ndarray]:\n",
    "        dists = self._pairwise_distances(X_query)\n",
    "        k = min(self.n_neighbors, self.n_train_)\n",
    "\n",
    "        # argpartition gives k smallest in arbitrary order\n",
    "        idx = np.argpartition(dists, kth=k - 1, axis=1)[:, :k]\n",
    "        row = np.arange(dists.shape[0])[:, None]\n",
    "        dist_k = dists[row, idx]\n",
    "\n",
    "        # sort neighbors by distance\n",
    "        order = np.argsort(dist_k, axis=1)\n",
    "        idx_sorted = idx[row, order]\n",
    "        dist_sorted = dist_k[row, order]\n",
    "        return dist_sorted, idx_sorted\n",
    "\n",
    "    def predict(self, X_query) -> np.ndarray:\n",
    "        dist, idx = self.kneighbors(X_query)\n",
    "        yk = self.y_train_[idx]\n",
    "\n",
    "        if self.weights == \"uniform\":\n",
    "            return yk.mean(axis=1)\n",
    "\n",
    "        w = 1.0 / (dist + self.eps)\n",
    "        w = w / np.sum(w, axis=1, keepdims=True)\n",
    "        return np.sum(w * yk, axis=1)\n",
    "\n",
    "    def neighbor_targets(self, X_query) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Return (distances, indices, neighbor y-values) for each query window.\"\"\"\n",
    "        dist, idx = self.kneighbors(X_query)\n",
    "        return dist, idx, self.y_train_[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55c701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsTimeSeriesRegressor(\n",
    "    n_neighbors=25,\n",
    "    weights=\"distance\",\n",
    "    metric=\"euclidean\",\n",
    "    normalize=\"zscore\",\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Empirical \"prediction band\" from the neighbor targets.\n",
    "dist, idx, y_nei = model.neighbor_targets(X_test)\n",
    "\n",
    "if model.weights == \"distance\":\n",
    "    w = 1.0 / (dist + model.eps)\n",
    "    q = weighted_quantile_1d\n",
    "    qs = np.array([0.05, 0.50, 0.95])\n",
    "    q_mat = np.vstack([q(y_nei[i], qs, weights=w[i]) for i in range(y_nei.shape[0])])\n",
    "    q05, q50, q95 = q_mat[:, 0], q_mat[:, 1], q_mat[:, 2]\n",
    "else:\n",
    "    q05, q50, q95 = np.quantile(y_nei, [0.05, 0.50, 0.95], axis=1)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(f\"MAE:  {mae:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832c77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates = dates[t_test]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=dates, y=y, mode=\"lines\", name=\"y\", line=dict(color=\"#444\")))\n",
    "\n",
    "# 90% band from neighbor targets\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=test_dates, y=q95, mode=\"lines\", line=dict(width=0), showlegend=False)\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=test_dates,\n",
    "        y=q05,\n",
    "        mode=\"lines\",\n",
    "        line=dict(width=0),\n",
    "        fill=\"tonexty\",\n",
    "        fillcolor=\"rgba(31,119,180,0.20)\",\n",
    "        name=\"90% neighbor band\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(x=test_dates, y=y_test, mode=\"lines\", name=\"Actual (test)\", line=dict(color=\"#000\")))\n",
    "fig.add_trace(go.Scatter(x=test_dates, y=y_pred, mode=\"lines\", name=\"KNN forecast\", line=dict(color=\"#1f77b4\")))\n",
    "\n",
    "fig.update_layout(\n",
    "    height=450,\n",
    "    title=\"1-step ahead forecast via KNN windows (with neighbor-based band)\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Value\",\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c7b5cb",
   "metadata": {},
   "source": [
    "## 4) Confidence intuition: the neighbor target distribution\n",
    "\n",
    "KNN doesn’t give a parametric confidence interval, but it naturally gives a **set of neighbor targets**.\n",
    "\n",
    "If the nearest neighbors all lead to similar next-step values, the forecast is “confident”. If neighbor targets vary widely, you should expect more uncertainty.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4be44ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 35  # pick a test point\n",
    "xq = X_test[i : i + 1]\n",
    "y_true = float(y_test[i])\n",
    "y_hat = float(y_pred[i])\n",
    "\n",
    "dist1, idx1, yk = model.neighbor_targets(xq)\n",
    "dist1 = dist1[0]\n",
    "idx1 = idx1[0]\n",
    "yk = yk[0]\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, column_widths=[0.55, 0.45], subplot_titles=(\"Query vs nearest windows\", \"Neighbor targets\"))\n",
    "\n",
    "# Left: overlay neighbor windows (aligned by relative time within the window)\n",
    "rel_t = np.arange(L)\n",
    "for j in range(min(12, len(idx1))):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=rel_t,\n",
    "            y=X_train[idx1[j]],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"rgba(31,119,180,0.18)\", width=1),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=rel_t, y=xq[0], mode=\"lines\", name=\"Query window\", line=dict(color=\"#000\", width=3)),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# Right: histogram of neighbor targets\n",
    "fig.add_trace(go.Histogram(x=yk, nbinsx=18, name=\"Neighbor y\", marker=dict(color=\"rgba(31,119,180,0.65)\")), row=1, col=2)\n",
    "\n",
    "for xval, name, color in [\n",
    "    (y_true, \"Actual\", \"#000\"),\n",
    "    (y_hat, \"Pred\", \"#1f77b4\"),\n",
    "    (float(np.median(yk)), \"Median(nei)\", \"#ff7f0e\"),\n",
    "]:\n",
    "    fig.add_vline(x=xval, line_width=2, line_dash=\"dash\", line_color=color, row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"Window time index\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Value\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Next value\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Count\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(height=420, title=\"KNN confidence intuition via neighbor dispersion\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997d7e40",
   "metadata": {},
   "source": [
    "## 5) Forecasting beyond the observed data (recursive)\n",
    "\n",
    "To forecast multiple steps ahead, one simple approach is **recursive** forecasting:\n",
    "1) predict the next point from the last window,\n",
    "2) append it to the history,\n",
    "3) repeat.\n",
    "\n",
    "We’ll also propagate a simple **fan** by taking quantiles of the neighbor targets at each step (heuristic, but visually useful).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff1f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_full = KNeighborsTimeSeriesRegressor(\n",
    "    n_neighbors=25,\n",
    "    weights=\"distance\",\n",
    "    metric=\"euclidean\",\n",
    "    normalize=\"zscore\",\n",
    ")\n",
    "\n",
    "# Fit on all available windows.\n",
    "X_all, y_all, t_all = make_supervised_windows(y, window_length=L, horizon=1, stride=1)\n",
    "model_full.fit(X_all, y_all)\n",
    "\n",
    "\n",
    "def recursive_forecast_with_band(\n",
    "    model: KNeighborsTimeSeriesRegressor,\n",
    "    y_hist: np.ndarray,\n",
    "    *,\n",
    "    window_length: int,\n",
    "    steps: int,\n",
    "    qs=(0.05, 0.50, 0.95),\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    y_hist = np.asarray(y_hist, dtype=float)\n",
    "    L = int(window_length)\n",
    "    out = np.zeros((steps, 3), dtype=float)\n",
    "\n",
    "    buf = y_hist.tolist()\n",
    "    for s in range(steps):\n",
    "        xq = np.asarray(buf[-L:], dtype=float)[None, :]\n",
    "        dist, _, yk = model.neighbor_targets(xq)\n",
    "        dist = dist[0]\n",
    "        yk = yk[0]\n",
    "\n",
    "        if model.weights == \"distance\":\n",
    "            w = 1.0 / (dist + model.eps)\n",
    "            out[s] = weighted_quantile_1d(yk, np.asarray(qs), weights=w)\n",
    "        else:\n",
    "            out[s] = np.quantile(yk, qs)\n",
    "\n",
    "        # Use the median as the point to recurse on (robust to outliers)\n",
    "        buf.append(float(out[s, 1]))\n",
    "\n",
    "    q05, q50, q95 = out[:, 0], out[:, 1], out[:, 2]\n",
    "    return q50, q05, q95\n",
    "\n",
    "\n",
    "n_future = 60\n",
    "fc_med, fc_lo, fc_hi = recursive_forecast_with_band(model_full, y, window_length=L, steps=n_future)\n",
    "future_dates = pd.date_range(dates[-1] + pd.Timedelta(days=1), periods=n_future, freq=\"D\")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=dates, y=y, mode=\"lines\", name=\"History\", line=dict(color=\"#444\")))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=future_dates, y=fc_hi, mode=\"lines\", line=dict(width=0), showlegend=False))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=future_dates,\n",
    "        y=fc_lo,\n",
    "        mode=\"lines\",\n",
    "        line=dict(width=0),\n",
    "        fill=\"tonexty\",\n",
    "        fillcolor=\"rgba(31,119,180,0.20)\",\n",
    "        name=\"90% band (heuristic)\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=future_dates, y=fc_med, mode=\"lines\", name=\"Forecast (median)\", line=dict(color=\"#1f77b4\", width=3)))\n",
    "\n",
    "fig.update_layout(height=450, title=\"Recursive KNN forecast with fan-style band\", xaxis_title=\"Time\", yaxis_title=\"Value\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d2f7f",
   "metadata": {},
   "source": [
    "## Practical notes + typical use cases\n",
    "\n",
    "### When KNN-TS is a good fit\n",
    "- **Analog forecasting**: the future behaves like the past when similar patterns occur\n",
    "- **Small data**: you want a strong baseline without heavy training\n",
    "- **Nonlinear but repetitive** dynamics\n",
    "- You want an easy-to-explain model: “these past windows looked most like today”\n",
    "\n",
    "### Pitfalls\n",
    "- **Scaling/normalization** is crucial: distances are the model.\n",
    "- Large windows increase dimensionality → neighbors become less meaningful (curse of dimensionality).\n",
    "- Brute-force KNN is $O(n\\,L)$ per query for Euclidean (and slower for DTW). For large $n$, you need approximations / indexing.\n",
    "- Non-stationarity (level shifts, changing seasonality) can break \"similarity\" unless you normalize or add features.\n",
    "\n",
    "### Extensions\n",
    "- Use DTW for more flexible shape matching (slower).\n",
    "- Add calendar / exogenous features by concatenating them to the window vector.\n",
    "- Predict multi-step horizons directly by changing the target to $y_{t+h}$.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}