{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locally Linear Embedding (LLE) — Manifold Learning (From Scratch)\n",
    "\n",
    "Locally Linear Embedding (LLE) is a **nonlinear** dimensionality reduction method that tries to “unfold” a manifold by preserving how each point can be reconstructed from its nearest neighbors.\n",
    "\n",
    "## Learning goals\n",
    "- Build intuition for *why* LLE works (local geometry → global coordinates)\n",
    "- Derive the **local reconstruction weights** and the **global embedding objective**\n",
    "- See how LLE becomes an **eigenvalue problem**\n",
    "- Implement standard LLE from scratch in NumPy\n",
    "- Visualize neighborhood reconstruction + weight preservation with Plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Linear algebra basics (matrix solve, eigenvectors)\n",
    "- K-nearest neighbors (KNN)\n",
    "- A mental model of a *manifold*: high-dimensional data that is “locally simple”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Intuition\n",
    "\n",
    "> “Rebuilding each point from its neighbors”\n",
    "\n",
    "LLE starts with a very local question:\n",
    "\n",
    "- If I look only at the **K nearest neighbors** of a point, can I express that point as a **linear combination** of those neighbors?\n",
    "\n",
    "Think of each neighborhood as a tiny patch of the manifold. Even if the manifold is curved globally, **small patches are often close to flat**.\n",
    "\n",
    "> “Local recipes that must still work globally”\n",
    "\n",
    "Once we learn a “recipe” (the neighbor weights) for each point in the original space, LLE searches for low-dimensional coordinates where **the same recipes still reconstruct the points**. The embedding is the set of coordinates that makes all of those local recipes consistent at once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A small 2D intuition picture: one point + its neighbors\n",
    "n_curve = 240\n",
    "theta = np.linspace(0, 2 * np.pi, n_curve, endpoint=False)\n",
    "X_curve = np.c_[np.cos(theta), np.sin(theta)] + 0.03 * rng.normal(size=(n_curve, 2))\n",
    "\n",
    "i0 = 40\n",
    "k0 = 10\n",
    "dist2 = np.sum((X_curve - X_curve[i0]) ** 2, axis=1)\n",
    "nn0 = np.argsort(dist2)[1 : k0 + 1]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=X_curve[:, 0],\n",
    "        y=X_curve[:, 1],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=6, color=\"rgba(120,120,120,0.35)\"),\n",
    "        name=\"data\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=X_curve[nn0, 0],\n",
    "        y=X_curve[nn0, 1],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=10, color=\"#1f77b4\"),\n",
    "        name=f\"{k0} nearest neighbors\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[X_curve[i0, 0]],\n",
    "        y=[X_curve[i0, 1]],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=14, color=\"black\", symbol=\"star\"),\n",
    "        name=\"target point\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Light “spokes” to show the neighborhood\n",
    "for j in nn0:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[X_curve[i0, 0], X_curve[j, 0]],\n",
    "            y=[X_curve[i0, 1], X_curve[j, 1]],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"rgba(31,119,180,0.25)\", width=2),\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Intuition: neighborhoods are small patches of the manifold\",\n",
    "    xaxis_title=\"x₁\",\n",
    "    yaxis_title=\"x₂\",\n",
    "    width=750,\n",
    "    height=520,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Mathematical Explanation\n",
    "\n",
    "### 2.1 Local linear reconstruction weights\n",
    "\n",
    "Let the dataset be points $x_1, \\dots, x_n$ with $x_i \\in ℝ^D$.\n",
    "\n",
    "For each point $x_i$, pick its neighbor index set $N(i)$ (usually KNN). LLE chooses weights $w_{ij}$ (only for $j \\in N(i)$) that minimize the local reconstruction error:\n",
    "\n",
    "$$\n",
    "min_{w_i} \\; \\left\\|x_i - \\sum_{j \\in N(i)} w_{ij} x_j\\right\\|_2^2\n",
    "\\quad \\text{s.t.} \\quad \\sum_{j \\in N(i)} w_{ij} = 1\n",
    "$$\n",
    "\n",
    "The **sum-to-one constraint** makes the weights invariant to translations (shifting all points by the same vector).\n",
    "\n",
    "A common way to compute $w_i$:\n",
    "- Build the neighbor difference matrix $Z_i \\in ℝ^{K \\times D}$ with rows $x_j - x_i$ for $j \\in N(i)$.\n",
    "- Form the local covariance (Gram) matrix $C_i = Z_i Z_i^T \\in ℝ^{K \\times K}$.\n",
    "- Solve $C_i w_i = 1$ and normalize $w_i$ so its entries sum to 1.\n",
    "- Add a small regularization term to $C_i$ for numerical stability (especially when neighbors are nearly collinear).\n",
    "\n",
    "### 2.2 Global cost function (preserve the weights)\n",
    "\n",
    "After we have weights, we search for low-dimensional coordinates $y_i \\in ℝ^d$ that preserve those same reconstructions:\n",
    "\n",
    "$$\n",
    "min_Y \\; \\sum_{i=1}^n \\left\\|y_i - \\sum_{j=1}^n W_{ij} y_j\\right\\|_2^2\n",
    "$$\n",
    "\n",
    "Here $W$ is an $n \\times n$ matrix where $W_{ij}$ is nonzero only if $j \\in N(i)$.\n",
    "\n",
    "Write the objective in matrix form (with $Y \\in ℝ^{n \\times d}$):\n",
    "\n",
    "$$\n",
    "\\Phi(Y) = \\|(I - W)Y\\|_F^2 = Tr\\left(Y^T M Y\\right), \\quad M = (I - W)^T (I - W)\n",
    "$$\n",
    "\n",
    "To avoid the trivial solution, we constrain $Y$ (e.g., center it and fix its scale). Minimizing the trace under those constraints yields an **eigenvalue problem**:\n",
    "\n",
    "$$\n",
    "Mv = \\lambda v\n",
    "$$\n",
    "\n",
    "The embedding $Y$ is formed from the eigenvectors with the **smallest non-zero** eigenvalues (skipping the smallest one, whose eigenvector is the constant vector).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Step-by-Step Algorithm\n",
    "\n",
    "1. **Neighbor selection**\n",
    "   - For each point $x_i$, find the indices of its $K$ nearest neighbors $N(i)$.\n",
    "\n",
    "2. **Weight computation** (local step)\n",
    "   - For each point $x_i$, solve for weights $w_i$ that reconstruct $x_i$ from $X[N(i)]$.\n",
    "   - Enforce $\\sum_j w_{ij} = 1$.\n",
    "\n",
    "3. **Global embedding**\n",
    "   - Build the sparse weight matrix $W$.\n",
    "   - Form $M = (I - W)^T(I - W)$.\n",
    "   - Compute the bottom eigenvectors of $M$ and take the smallest non-trivial ones as the embedding coordinates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_squared_distances(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute dense pairwise squared Euclidean distances.\n",
    "\n",
    "    Returns an (n, n) matrix with `np.inf` on the diagonal.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    if X.ndim != 2:\n",
    "        raise ValueError(\"X must be a 2D array of shape (n_samples, n_features)\")\n",
    "\n",
    "    n = X.shape[0]\n",
    "    if n < 2:\n",
    "        raise ValueError(\"X must contain at least 2 samples\")\n",
    "\n",
    "    X_norm = np.sum(X**2, axis=1, keepdims=True)\n",
    "    dist2 = X_norm + X_norm.T - 2.0 * (X @ X.T)\n",
    "    dist2 = np.maximum(dist2, 0.0)\n",
    "    np.fill_diagonal(dist2, np.inf)\n",
    "    return dist2\n",
    "\n",
    "\n",
    "def knn_indices_from_dist2(dist2: np.ndarray, k: int) -> np.ndarray:\n",
    "    \"\"\"Return (n, k) neighbor indices given a pairwise distance matrix.\"\"\"\n",
    "    dist2 = np.asarray(dist2, dtype=float)\n",
    "    if dist2.ndim != 2 or dist2.shape[0] != dist2.shape[1]:\n",
    "        raise ValueError(\"dist2 must be a square (n,n) distance matrix\")\n",
    "\n",
    "    n = dist2.shape[0]\n",
    "    if not (1 <= k < n):\n",
    "        raise ValueError(f\"k must satisfy 1 <= k < n (got k={k}, n={n})\")\n",
    "\n",
    "    idx = np.argpartition(dist2, kth=k - 1, axis=1)[:, :k]\n",
    "    rows = np.arange(n)[:, None]\n",
    "    order = np.argsort(dist2[rows, idx], axis=1)\n",
    "    idx = idx[rows, order]\n",
    "    return idx\n",
    "\n",
    "\n",
    "def lle_local_weights(X: np.ndarray, neighbors: np.ndarray, reg: float = 1e-3) -> np.ndarray:\n",
    "    \"\"\"Compute LLE reconstruction weights for each point.\n",
    "\n",
    "    Returns weights with shape (n, k), aligned with `neighbors`.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    neighbors = np.asarray(neighbors)\n",
    "\n",
    "    if X.ndim != 2:\n",
    "        raise ValueError(\"X must be a 2D array of shape (n_samples, n_features)\")\n",
    "    if neighbors.ndim != 2:\n",
    "        raise ValueError(\"neighbors must be a 2D integer array of shape (n, k)\")\n",
    "\n",
    "    n, d = X.shape\n",
    "    if neighbors.shape[0] != n:\n",
    "        raise ValueError(\"neighbors must have the same number of rows as X\")\n",
    "\n",
    "    k = neighbors.shape[1]\n",
    "    if not (1 <= k < n):\n",
    "        raise ValueError(f\"neighbors k must satisfy 1 <= k < n (got k={k}, n={n})\")\n",
    "    if np.any(neighbors < 0) or np.any(neighbors >= n):\n",
    "        raise ValueError(\"neighbors contains out-of-range indices\")\n",
    "\n",
    "    weights = np.zeros((n, k), dtype=float)\n",
    "    ones = np.ones(k, dtype=float)\n",
    "\n",
    "    for i in range(n):\n",
    "        Ni = neighbors[i]\n",
    "        Z = X[Ni] - X[i]  # (k, d)\n",
    "        C = Z @ Z.T        # (k, k)\n",
    "\n",
    "        tr = np.trace(C)\n",
    "        C += (reg * tr if tr > 0 else reg) * np.eye(k)\n",
    "\n",
    "        try:\n",
    "            w = np.linalg.solve(C, ones)\n",
    "        except np.linalg.LinAlgError:\n",
    "            w = np.linalg.lstsq(C, ones, rcond=None)[0]\n",
    "\n",
    "        w_sum = np.sum(w)\n",
    "        if np.isclose(w_sum, 0.0):\n",
    "            w = ones / k\n",
    "        else:\n",
    "            w /= w_sum\n",
    "        weights[i] = w\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "class ScratchLLE:\n",
    "    def __init__(self, n_neighbors: int = 12, n_components: int = 2, reg: float = 1e-3):\n",
    "        self.n_neighbors = int(n_neighbors)\n",
    "        self.n_components = int(n_components)\n",
    "        self.reg = float(reg)\n",
    "\n",
    "    def fit(self, X: np.ndarray):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        if X.ndim != 2:\n",
    "            raise ValueError(\"X must be a 2D array of shape (n_samples, n_features)\")\n",
    "\n",
    "        n = X.shape[0]\n",
    "        if n < 2:\n",
    "            raise ValueError(\"X must contain at least 2 samples\")\n",
    "        if not (1 <= self.n_components < n):\n",
    "            raise ValueError(\n",
    "                f\"n_components must satisfy 1 <= n_components < n (got {self.n_components}, n={n})\"\n",
    "            )\n",
    "        if not (1 <= self.n_neighbors < n):\n",
    "            raise ValueError(\n",
    "                f\"n_neighbors must satisfy 1 <= n_neighbors < n (got {self.n_neighbors}, n={n})\"\n",
    "            )\n",
    "\n",
    "        dist2 = pairwise_squared_distances(X)\n",
    "        neighbors = knn_indices_from_dist2(dist2, self.n_neighbors)\n",
    "        weights = lle_local_weights(X, neighbors, reg=self.reg)\n",
    "\n",
    "        W = np.zeros((n, n), dtype=float)\n",
    "        rows = np.arange(n)[:, None]\n",
    "        W[rows, neighbors] = weights\n",
    "\n",
    "        M = np.eye(n) - W\n",
    "        M = M.T @ M\n",
    "\n",
    "        evals, evecs = np.linalg.eigh(M)\n",
    "        Y = evecs[:, 1 : self.n_components + 1]\n",
    "\n",
    "        self.embedding_ = Y\n",
    "        self.neighbors_ = neighbors\n",
    "        self.weights_ = weights\n",
    "        self.eigenvalues_ = evals\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        return self.fit(X).embedding_\n",
    "\n",
    "\n",
    "def lle_from_scratch(\n",
    "    X: np.ndarray,\n",
    "    n_neighbors: int = 12,\n",
    "    n_components: int = 2,\n",
    "    reg: float = 1e-3,\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Convenience wrapper around `ScratchLLE` (standard LLE).\"\"\"\n",
    "    model = ScratchLLE(n_neighbors=n_neighbors, n_components=n_components, reg=reg).fit(X)\n",
    "    return model.embedding_, model.neighbors_, model.weights_, model.eigenvalues_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Plotly Visualizations\n",
    "\n",
    "We’ll use a classic benchmark: the **Swiss roll**. It’s a 2D surface embedded in 3D.\n",
    "\n",
    "### 4.1 Swiss roll → 2D embedding\n",
    "### 4.2 Local neighborhood reconstruction\n",
    "### 4.3 Weight preservation illustration\n",
    "### 4.4 Compare with `sklearn` (sanity check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 900\n",
    "X_swiss, t = make_swiss_roll(n_samples=n_samples, noise=0.06, random_state=42)\n",
    "X_swiss = StandardScaler().fit_transform(X_swiss)\n",
    "\n",
    "n_neighbors = 12\n",
    "n_components = 2\n",
    "\n",
    "scratch_lle = ScratchLLE(n_neighbors=n_neighbors, n_components=n_components, reg=1e-3).fit(X_swiss)\n",
    "Y_scratch = scratch_lle.embedding_\n",
    "neighbors_swiss = scratch_lle.neighbors_\n",
    "weights_swiss = scratch_lle.weights_\n",
    "evals = scratch_lle.eigenvalues_\n",
    "\n",
    "X_hat = np.sum(weights_swiss[..., None] * X_swiss[neighbors_swiss], axis=1)\n",
    "recon_err = np.linalg.norm(X_swiss - X_hat, axis=1)\n",
    "print(\n",
    "    f\"Local reconstruction error: mean={recon_err.mean():.4f}, \"\n",
    "    f\"95th%={np.percentile(recon_err, 95):.4f}\"\n",
    ")\n",
    "\n",
    "fig = px.histogram(recon_err, nbins=40, title=\"Local reconstruction errors (||x - x̂||)\")\n",
    "fig.update_layout(xaxis_title=\"||x - x̂||\", yaxis_title=\"count\", width=850, height=420)\n",
    "fig.show()\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    x=X_swiss[:, 0],\n",
    "    y=X_swiss[:, 1],\n",
    "    z=X_swiss[:, 2],\n",
    "    color=t,\n",
    "    title=\"Swiss roll in 3D (color = intrinsic parameter)\",\n",
    "    labels={\"x\": \"x₁\", \"y\": \"x₂\", \"z\": \"x₃\"},\n",
    ")\n",
    "fig.update_traces(marker=dict(size=3, opacity=0.8))\n",
    "fig.show()\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=Y_scratch[:, 0],\n",
    "    y=Y_scratch[:, 1],\n",
    "    color=t,\n",
    "    title=f\"LLE embedding from scratch (K={n_neighbors}, d={n_components})\",\n",
    "    labels={\"x\": \"y₁\", \"y\": \"y₂\"},\n",
    ")\n",
    "fig.update_traces(marker=dict(size=5, opacity=0.9))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Local neighborhood reconstruction\n",
    "\n",
    "For one point $x_i$, we can visualize:\n",
    "- its neighbor set $N(i)$\n",
    "- the reconstructed point $\\hat{x}_i = \\sum_{j \\in N(i)} w_{ij} x_j$\n",
    "\n",
    "The reconstruction should be close in the original space if the neighborhood is locally “flat enough”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_local_reconstruction_3d(\n",
    "    X: np.ndarray,\n",
    "    t: np.ndarray,\n",
    "    neighbors: np.ndarray,\n",
    "    weights: np.ndarray,\n",
    "    i: int,\n",
    ") -> go.Figure:\n",
    "    Ni = neighbors[i]\n",
    "    wi = weights[i]\n",
    "    x_i = X[i]\n",
    "    x_hat = wi @ X[Ni]\n",
    "    err = float(np.linalg.norm(x_i - x_hat))\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=X[:, 0],\n",
    "            y=X[:, 1],\n",
    "            z=X[:, 2],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=2, color=\"rgba(140,140,140,0.25)\"),\n",
    "            name=\"all points\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=X[Ni, 0],\n",
    "            y=X[Ni, 1],\n",
    "            z=X[Ni, 2],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=7,\n",
    "                color=wi,\n",
    "                colorscale=\"RdBu\",\n",
    "                reversescale=True,\n",
    "                colorbar=dict(title=\"weight\"),\n",
    "            ),\n",
    "            name=\"neighbors (colored by weight)\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[x_i[0]],\n",
    "            y=[x_i[1]],\n",
    "            z=[x_i[2]],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=9, color=\"black\", symbol=\"diamond\"),\n",
    "            name=f\"x[{i}]\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[x_hat[0]],\n",
    "            y=[x_hat[1]],\n",
    "            z=[x_hat[2]],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=9, color=\"#d62728\", symbol=\"x\"),\n",
    "            name=\"reconstruction (x̂)\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[x_i[0], x_hat[0]],\n",
    "            y=[x_i[1], x_hat[1]],\n",
    "            z=[x_i[2], x_hat[2]],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"#d62728\", width=6),\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Local reconstruction in 3D (i={i}, ||x - x̂||={err:.3e})\",\n",
    "        scene=dict(xaxis_title=\"x₁\", yaxis_title=\"x₂\", zaxis_title=\"x₃\"),\n",
    "        width=900,\n",
    "        height=620,\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "i_demo = 250\n",
    "plot_local_reconstruction_3d(X_swiss, t, neighbors_swiss, weights_swiss, i_demo).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Weight preservation illustration\n",
    "\n",
    "In the embedding, LLE tries to make each point satisfy the same reconstruction:\n",
    "\n",
    "$$\n",
    "y_i \\approx \\sum_{j \\in N(i)} w_{ij} y_j\n",
    "$$\n",
    "\n",
    "Below, we apply the *same weights* to neighbors in both the original space and the embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weight_preservation(\n",
    "    X: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    neighbors: np.ndarray,\n",
    "    weights: np.ndarray,\n",
    "    i: int,\n",
    ") -> go.Figure:\n",
    "    Ni = neighbors[i]\n",
    "    wi = weights[i]\n",
    "\n",
    "    x_i = X[i]\n",
    "    x_hat = wi @ X[Ni]\n",
    "    err_x = float(np.linalg.norm(x_i - x_hat))\n",
    "\n",
    "    y_i = Y[i]\n",
    "    y_hat = wi @ Y[Ni]\n",
    "    err_y = float(np.linalg.norm(y_i - y_hat))\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=2,\n",
    "        specs=[[{\"type\": \"scene\"}, {\"type\": \"xy\"}]],\n",
    "        subplot_titles=(\n",
    "            f\"Original space (||x - x̂||={err_x:.3e})\",\n",
    "            f\"Embedding space (||y - ŷ||={err_y:.3e})\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Original space (3D)\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=X[:, 0],\n",
    "            y=X[:, 1],\n",
    "            z=X[:, 2],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=2, color=\"rgba(140,140,140,0.22)\"),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=X[Ni, 0],\n",
    "            y=X[Ni, 1],\n",
    "            z=X[Ni, 2],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=7, color=wi, colorscale=\"RdBu\", reversescale=True),\n",
    "            name=\"neighbors\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[x_i[0]],\n",
    "            y=[x_i[1]],\n",
    "            z=[x_i[2]],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=9, color=\"black\", symbol=\"diamond\"),\n",
    "            name=\"x\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[x_hat[0]],\n",
    "            y=[x_hat[1]],\n",
    "            z=[x_hat[2]],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=9, color=\"#d62728\", symbol=\"x\"),\n",
    "            name=\"x̂\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "    # Embedding space (2D)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=Y[:, 0],\n",
    "            y=Y[:, 1],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=6, color=\"rgba(140,140,140,0.25)\"),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=Y[Ni, 0],\n",
    "            y=Y[Ni, 1],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=11, color=wi, colorscale=\"RdBu\", reversescale=True, showscale=True),\n",
    "            name=\"neighbors (weights)\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[y_i[0]],\n",
    "            y=[y_i[1]],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=14, color=\"black\", symbol=\"diamond\"),\n",
    "            name=\"y\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[y_hat[0]],\n",
    "            y=[y_hat[1]],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=14, color=\"#d62728\", symbol=\"x\"),\n",
    "            name=\"ŷ\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Weight preservation (same neighborhood weights, i={i})\",\n",
    "        width=1100,\n",
    "        height=520,\n",
    "    )\n",
    "    fig.update_scenes(xaxis_title=\"x₁\", yaxis_title=\"x₂\", zaxis_title=\"x₃\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"y₁\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"y₂\", row=1, col=2)\n",
    "    return fig\n",
    "\n",
    "\n",
    "plot_weight_preservation(X_swiss, Y_scratch, neighbors_swiss, weights_swiss, i_demo).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Compare with `sklearn` (sanity check)\n",
    "\n",
    "Different implementations can produce embeddings that are rotated/flipped/scaled differently, but the *geometry* should match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lle = LocallyLinearEmbedding(\n",
    "    n_neighbors=n_neighbors,\n",
    "    n_components=n_components,\n",
    "    method=\"standard\",\n",
    "    random_state=42,\n",
    ")\n",
    "Y_sklearn = lle.fit_transform(X_swiss)\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=Y_sklearn[:, 0],\n",
    "    y=Y_sklearn[:, 1],\n",
    "    color=t,\n",
    "    title=\"`sklearn` LocallyLinearEmbedding (standard)\",\n",
    "    labels={\"x\": \"y₁\", \"y\": \"y₂\"},\n",
    ")\n",
    "fig.update_traces(marker=dict(size=5, opacity=0.9))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Strengths & Weaknesses\n",
    "\n",
    "### Strengths\n",
    "- Captures **nonlinear** structure while preserving local geometry.\n",
    "- Works well when data lies on a **smooth manifold** and neighborhoods are well-sampled.\n",
    "- No gradient descent needed for the standard method (solve local linear systems + an eigenproblem).\n",
    "\n",
    "### Weaknesses\n",
    "- **Manifold assumptions**: if the data is not locally linear (or not a manifold), LLE can distort structure.\n",
    "- **Noise sensitivity**: noisy neighbors → unstable weights → poor embeddings.\n",
    "- Choice of **K** is critical: too small → disconnected graph; too large → “short-circuits” across the manifold.\n",
    "- Global step needs an eigen-decomposition (can be expensive for large $n$ without sparse solvers).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "1. Try different values of `n_neighbors` (e.g., 6, 12, 24). When does the embedding break?\n",
    "2. Add more noise to the Swiss roll. How do the local reconstruction errors change?\n",
    "3. Replace the brute-force neighbor search with `sklearn.neighbors.NearestNeighbors` and compare runtime.\n",
    "\n",
    "## References\n",
    "- Roweis & Saul (2000), *Nonlinear Dimensionality Reduction by Locally Linear Embedding*.\n",
    "- `sklearn.manifold.LocallyLinearEmbedding` documentation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
