{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "173f897d",
   "metadata": {},
   "source": [
    "# Multidimensional Scaling (MDS) — “Recreating a map using only pairwise distances”\n",
    "\n",
    "Multidimensional Scaling (MDS) is a family of techniques for turning a matrix of **pairwise distances / dissimilarities** into coordinates in a low-dimensional space.\n",
    "\n",
    "If you’ve ever seen a road-distance table and wondered *“can I draw a map from this?”*, you already understand the core idea.\n",
    "\n",
    "## What you’ll learn\n",
    "- the intuition: map-making from distances (and why the solution is only defined up to rotation/translation/reflection)\n",
    "- the math: distance matrices, the **stress** objective, and what changes in classical vs metric vs non-metric MDS\n",
    "- how classical MDS becomes an **eigendecomposition** problem (closed form)\n",
    "- how metric MDS can be solved by iterative **stress minimization** (SMACOF)\n",
    "- how MDS compares to **PCA** and **Isomap**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b55115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from sklearn.manifold import Isomap, MDS\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61058505",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Euclidean distance and what a distance matrix represents\n",
    "- Basic linear algebra: eigenvalues/eigenvectors, matrix multiplication\n",
    "- Helpful (not required): intuition for PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3fd84d",
   "metadata": {},
   "source": [
    "## 1) Intuition: recreating a map from pairwise distances\n",
    "\n",
    "Imagine you have **no coordinates** for a set of cities.\n",
    "\n",
    "All you have is a table like:\n",
    "\n",
    "- distance from City A to City B\n",
    "- distance from City A to City C\n",
    "- …and so on for every pair\n",
    "\n",
    "MDS tries to place points on a 2D plane so that the **distances on the plane** match the distances in the table.\n",
    "\n",
    "Important subtlety: even with perfect distances, the “map” is **not unique**.\n",
    "\n",
    "- You can translate (shift) the whole map.\n",
    "- You can rotate it.\n",
    "- You can mirror it.\n",
    "\n",
    "All of those transformations preserve pairwise distances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1a25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers (NumPy-first)\n",
    "\n",
    "\n",
    "def pairwise_euclidean_distances(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute the full pairwise Euclidean distance matrix for X.\n",
    "\n",
    "    Args:\n",
    "        X: (n, d) array\n",
    "\n",
    "    Returns:\n",
    "        D: (n, n) distance matrix where D[i, j] = ||x_i - x_j||_2\n",
    "    \"\"\"\n",
    "\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    if X.ndim != 2:\n",
    "        raise ValueError(\"X must be a 2D array of shape (n, d)\")\n",
    "\n",
    "    sq_norms = np.sum(X**2, axis=1)\n",
    "    D2 = sq_norms[:, None] + sq_norms[None, :] - 2.0 * (X @ X.T)\n",
    "    D2 = np.maximum(D2, 0.0)\n",
    "    return np.sqrt(D2)\n",
    "\n",
    "\n",
    "def validate_distance_matrix(D: np.ndarray, *, tol: float = 1e-10) -> np.ndarray:\n",
    "    \"\"\"Validate a distance/dissimilarity matrix.\n",
    "\n",
    "    Checks shape, finiteness, symmetry, and (approximately) zero diagonal.\n",
    "    \"\"\"\n",
    "\n",
    "    D = np.asarray(D, dtype=float)\n",
    "    if D.ndim != 2 or D.shape[0] != D.shape[1]:\n",
    "        raise ValueError(\"D must be a square matrix\")\n",
    "\n",
    "    if not np.all(np.isfinite(D)):\n",
    "        raise ValueError(\"D must contain only finite values\")\n",
    "\n",
    "    if np.min(D) < -tol:\n",
    "        raise ValueError(\"D must be non-negative (up to numerical tolerance)\")\n",
    "\n",
    "    if not np.allclose(np.diag(D), 0.0, atol=tol, rtol=0.0):\n",
    "        raise ValueError(\"D must have a (near) zero diagonal\")\n",
    "\n",
    "    if not np.allclose(D, D.T, atol=tol, rtol=0.0):\n",
    "        raise ValueError(\"D must be symmetric\")\n",
    "\n",
    "    return D\n",
    "\n",
    "\n",
    "def procrustes_align(reference: np.ndarray, target: np.ndarray, *, allow_scaling: bool = True) -> np.ndarray:\n",
    "    \"\"\"Align `target` to `reference` using an optimal orthogonal transform.\n",
    "\n",
    "    This is only for plotting/visual comparison. Pairwise distances are invariant to\n",
    "    translation/rotation/reflection, so different MDS solutions can look \"different\"\n",
    "    while still being correct.\n",
    "    \"\"\"\n",
    "\n",
    "    ref = np.asarray(reference, dtype=float)\n",
    "    tgt = np.asarray(target, dtype=float)\n",
    "\n",
    "    if ref.ndim != 2 or tgt.ndim != 2:\n",
    "        raise ValueError(\"reference and target must be 2D arrays\")\n",
    "    if ref.shape != tgt.shape:\n",
    "        raise ValueError(\"reference and target must have the same shape\")\n",
    "\n",
    "    ref0 = ref - ref.mean(axis=0, keepdims=True)\n",
    "    tgt0 = tgt - tgt.mean(axis=0, keepdims=True)\n",
    "\n",
    "    # Solve: min_R || (tgt0 @ R) - ref0 ||_F, s.t. R is orthogonal\n",
    "    U, s, Vt = np.linalg.svd(tgt0.T @ ref0, full_matrices=False)\n",
    "    R = U @ Vt\n",
    "\n",
    "    scale = (s.sum() / (np.sum(tgt0**2) + 1e-12)) if allow_scaling else 1.0\n",
    "    return scale * tgt0 @ R\n",
    "\n",
    "\n",
    "# Synthetic \"cities\" on a plane\n",
    "n_cities = 18\n",
    "cities_true = rng.uniform(0, 10, size=(n_cities, 2))\n",
    "city_labels = [f\"C{i+1}\" for i in range(n_cities)]\n",
    "\n",
    "# The only input MDS needs: pairwise distances\n",
    "D = validate_distance_matrix(pairwise_euclidean_distances(cities_true))\n",
    "\n",
    "# Reconstruct coordinates from the distance matrix\n",
    "mds_sklearn = MDS(\n",
    "    n_components=2,\n",
    "    metric=True,\n",
    "    dissimilarity=\"precomputed\",\n",
    "    random_state=42,\n",
    "    n_init=8,\n",
    "    max_iter=500,\n",
    ")\n",
    "\n",
    "cities_mds = mds_sklearn.fit_transform(D)\n",
    "cities_mds_aligned = procrustes_align(cities_true, cities_mds, allow_scaling=True)\n",
    "\n",
    "mds_sklearn.stress_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b8abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\n",
    "        \"True map (unknown to MDS)\",\n",
    "        \"Reconstructed using only distances (metric MDS)\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=cities_true[:, 0],\n",
    "        y=cities_true[:, 1],\n",
    "        mode=\"markers+text\",\n",
    "        text=city_labels,\n",
    "        textposition=\"top center\",\n",
    "        name=\"true\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=cities_mds_aligned[:, 0],\n",
    "        y=cities_mds_aligned[:, 1],\n",
    "        mode=\"markers+text\",\n",
    "        text=city_labels,\n",
    "        textposition=\"top center\",\n",
    "        name=\"mds\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "for c in [1, 2]:\n",
    "    fig.update_xaxes(scaleanchor=f\"y{'' if c == 1 else c}\", scaleratio=1, row=1, col=c)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"MDS as map-making: reconstructing coordinates from distances\",\n",
    "    height=450,\n",
    "    showlegend=False,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1efdb9",
   "metadata": {},
   "source": [
    "## 2) Mathematical explanation\n",
    "\n",
    "### Distance (dissimilarity) matrix\n",
    "\n",
    "We start with an $n \\times n$ matrix $\\Delta$ where each entry is a dissimilarity:\n",
    "\n",
    "$$\n",
    "\\Delta_{ij} \\ge 0,\\quad \\Delta_{ii} = 0,\\quad \\Delta_{ij} = \\Delta_{ji}.\n",
    "$$\n",
    "\n",
    "If the dissimilarities come from Euclidean distances between unknown points $x_i$, then:\n",
    "\n",
    "$$\n",
    "\\Delta_{ij} = \\|x_i - x_j\\|_2.\n",
    "$$\n",
    "\n",
    "### Embedding distances\n",
    "\n",
    "We want points $y_i \\in \\mathbb{R}^p$ (often $p=2$) so the induced distances\n",
    "\n",
    "$$\n",
    "d_{ij}(Y) = \\|y_i - y_j\\|_2\n",
    "$$\n",
    "\n",
    "match the input as well as possible.\n",
    "\n",
    "### Stress function\n",
    "\n",
    "A standard objective is **raw stress** (with optional weights $w_{ij} \\ge 0$):\n",
    "\n",
    "$$\n",
    "\\sigma(Y) = \\sum_{i<j} w_{ij}\\,(d_{ij}(Y) - \\Delta_{ij})^2.\n",
    "$$\n",
    "\n",
    "Minimizing stress is exactly the “move the points until the distances match” story.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d0d83f",
   "metadata": {},
   "source": [
    "### Classical vs metric vs non-metric MDS\n",
    "\n",
    "| Variant | What you try to preserve | Typical solver | Notes |\n",
    "|---|---|---|---|\n",
    "| **Classical MDS** (Torgerson–Gower) | Distances *assuming* they are Euclidean | **Eigen decomposition** (closed form) | Very fast; closely related to PCA |\n",
    "| **Metric MDS** | Distances (in the metric sense) | Iterative **stress minimization** (e.g., SMACOF) | Handles general dissimilarities; may have local minima |\n",
    "| **Non-metric MDS** | **Rank order** of dissimilarities | Stress minimization + **monotone regression** | Great when “only order matters” (ratings, human judgments) |\n",
    "\n",
    "A useful mental model:\n",
    "\n",
    "- **Metric MDS** cares about *how far*.\n",
    "- **Non-metric MDS** cares about *which is farther*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ece8b7a",
   "metadata": {},
   "source": [
    "## 3) Optimization process\n",
    "\n",
    "### 3.1 Classical MDS: eigen decomposition (closed form)\n",
    "\n",
    "If $\\Delta$ is a matrix of **Euclidean distances**, we can recover an (approximate) inner-product matrix.\n",
    "\n",
    "Let $J = I - \\frac{1}{n}\\mathbf{1}\\mathbf{1}^\\top$ be the centering matrix and let $\\Delta^{\\circ 2}$ be elementwise-squared distances.\n",
    "\n",
    "Define the double-centered matrix:\n",
    "\n",
    "$$\n",
    "B = -\\tfrac{1}{2} J\\,\\Delta^{\\circ 2}\\,J.\n",
    "$$\n",
    "\n",
    "When the distances are truly Euclidean, $B$ is a Gram matrix $B = YY^\\top$.\n",
    "\n",
    "So we eigendecompose:\n",
    "\n",
    "$$\n",
    "B = V\\Lambda V^\\top,\n",
    "\\quad\n",
    "Y = V_p\\,\\Lambda_p^{1/2}\n",
    "$$\n",
    "\n",
    "using the top $p$ **positive** eigenvalues.\n",
    "\n",
    "Connection to PCA:\n",
    "\n",
    "- If $\\Delta$ comes from Euclidean distances of data points, classical MDS and PCA produce the same coordinates (up to rotation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1478056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classical_mds(D: np.ndarray, n_components: int = 2) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Classical MDS (Torgerson-Gower) from a distance matrix.\n",
    "\n",
    "    Classical MDS assumes distances are (approximately) Euclidean.\n",
    "\n",
    "    Returns:\n",
    "        Y: (n, n_components) embedding\n",
    "        eigvals: eigenvalues of the centered Gram matrix (sorted descending)\n",
    "    \"\"\"\n",
    "\n",
    "    D = validate_distance_matrix(D)\n",
    "\n",
    "    n = D.shape[0]\n",
    "    if not (1 <= n_components <= n):\n",
    "        raise ValueError(\"n_components must be between 1 and n\")\n",
    "\n",
    "    J = np.eye(n) - np.ones((n, n)) / n\n",
    "    B = -0.5 * J @ (D**2) @ J\n",
    "\n",
    "    eigvals, eigvecs = np.linalg.eigh(B)\n",
    "    order = np.argsort(eigvals)[::-1]\n",
    "    eigvals = eigvals[order]\n",
    "    eigvecs = eigvecs[:, order]\n",
    "\n",
    "    # Keep only the leading components; clamp tiny negatives due to numerical noise\n",
    "    L = np.diag(np.sqrt(np.maximum(eigvals[:n_components], 0.0)))\n",
    "    Y = eigvecs[:, :n_components] @ L\n",
    "    return Y, eigvals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979b024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_classical, eigvals_cities = classical_mds(D, n_components=2)\n",
    "cities_classical_aligned = procrustes_align(cities_true, cities_classical, allow_scaling=True)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\n",
    "        \"True map\",\n",
    "        \"Classical MDS (aligned)\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=cities_true[:, 0],\n",
    "        y=cities_true[:, 1],\n",
    "        mode=\"markers+text\",\n",
    "        text=city_labels,\n",
    "        textposition=\"top center\",\n",
    "        name=\"true\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=cities_classical_aligned[:, 0],\n",
    "        y=cities_classical_aligned[:, 1],\n",
    "        mode=\"markers+text\",\n",
    "        text=city_labels,\n",
    "        textposition=\"top center\",\n",
    "        name=\"classical\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "for c in [1, 2]:\n",
    "    fig.update_xaxes(scaleanchor=f\"y{'' if c == 1 else c}\", scaleratio=1, row=1, col=c)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Classical MDS: eigendecomposition reconstruction\",\n",
    "    height=450,\n",
    "    showlegend=False,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d9594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvalues of B tell you how many meaningful dimensions the distances support.\n",
    "# Negative eigenvalues often indicate the distances are not perfectly Euclidean (or there is noise).\n",
    "\n",
    "fig = px.line(\n",
    "    x=np.arange(1, len(eigvals_cities) + 1),\n",
    "    y=eigvals_cities,\n",
    "    markers=True,\n",
    "    title=\"Classical MDS: eigenvalues of the centered Gram matrix\",\n",
    "    labels={\"x\": \"eigenvalue index\", \"y\": \"eigenvalue\"},\n",
    ")\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"black\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09888ec6",
   "metadata": {},
   "source": [
    "### 3.2 Metric MDS: stress minimization (SMACOF)\n",
    "\n",
    "Metric MDS directly minimizes stress. A common workhorse algorithm is **SMACOF** (Scaling by MAjorizing a COmplicated Function).\n",
    "\n",
    "At a high level:\n",
    "\n",
    "1. Start with a guess $Y^{(0)}$.\n",
    "2. Repeat:\n",
    "   - compute the current distances $d_{ij}(Y^{(t)})$\n",
    "   - build a matrix $B(Y^{(t)})$ that depends on $\\Delta_{ij} / d_{ij}(Y^{(t)})$\n",
    "   - update $Y^{(t+1)} = \\frac{1}{n} B(Y^{(t)}) Y^{(t)}$\n",
    "\n",
    "For the raw-stress metric case (all weights 1), SMACOF is popular because it **monotonically decreases stress**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0149f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_stress(D: np.ndarray, Y: np.ndarray) -> float:\n",
    "    \"\"\"Raw stress: sum_{i<j} (||y_i - y_j|| - D_ij)^2.\"\"\"\n",
    "\n",
    "    D = validate_distance_matrix(D)\n",
    "    Y = np.asarray(Y, dtype=float)\n",
    "\n",
    "    if Y.ndim != 2 or Y.shape[0] != D.shape[0]:\n",
    "        raise ValueError(\"Y must have shape (n, p) matching D\")\n",
    "\n",
    "    dist = pairwise_euclidean_distances(Y)\n",
    "    tri = np.triu_indices(D.shape[0], 1)\n",
    "    return float(np.sum((dist[tri] - D[tri]) ** 2))\n",
    "\n",
    "\n",
    "def smacof_metric(\n",
    "    D: np.ndarray,\n",
    "    n_components: int = 2,\n",
    "    max_iter: int = 300,\n",
    "    tol: float = 1e-7,\n",
    "    random_state: int = 42,\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"A small, from-scratch SMACOF implementation for metric MDS (raw stress).\n",
    "\n",
    "    The update has the form:\n",
    "        Y <- (1/n) B(Y) Y\n",
    "\n",
    "    For raw stress with uniform weights:\n",
    "        B_ij = -D_ij / d_ij(Y) for i != j\n",
    "        B_ii = -sum_{j != i} B_ij\n",
    "\n",
    "    Returns:\n",
    "        Y: embedding (n, n_components)\n",
    "        stress_history: array of raw-stress values per iteration\n",
    "    \"\"\"\n",
    "\n",
    "    D = validate_distance_matrix(D)\n",
    "\n",
    "    n = D.shape[0]\n",
    "    if not (1 <= n_components <= n):\n",
    "        raise ValueError(\"n_components must be between 1 and n\")\n",
    "    if max_iter <= 0:\n",
    "        raise ValueError(\"max_iter must be > 0\")\n",
    "    if tol <= 0:\n",
    "        raise ValueError(\"tol must be > 0\")\n",
    "\n",
    "    tri = np.triu_indices(n, 1)\n",
    "\n",
    "    rng_local = np.random.default_rng(random_state)\n",
    "    Y = rng_local.normal(scale=1.0, size=(n, n_components))\n",
    "    Y -= Y.mean(axis=0, keepdims=True)\n",
    "\n",
    "    stress_history: list[float] = []\n",
    "    eps = 1e-12\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        dist = pairwise_euclidean_distances(Y)\n",
    "        dist = np.maximum(dist, eps)\n",
    "\n",
    "        ratio = D / dist\n",
    "        B = -ratio\n",
    "        np.fill_diagonal(B, 0.0)\n",
    "        np.fill_diagonal(B, -B.sum(axis=1))\n",
    "\n",
    "        Y_new = (1.0 / n) * (B @ Y)\n",
    "        Y_new -= Y_new.mean(axis=0, keepdims=True)\n",
    "\n",
    "        stress = float(np.sum((pairwise_euclidean_distances(Y_new)[tri] - D[tri]) ** 2))\n",
    "        stress_history.append(stress)\n",
    "\n",
    "        if len(stress_history) >= 2:\n",
    "            prev = stress_history[-2]\n",
    "            if (prev - stress) / (prev + eps) < tol:\n",
    "                Y = Y_new\n",
    "                break\n",
    "\n",
    "        Y = Y_new\n",
    "\n",
    "    return Y, np.asarray(stress_history)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ScratchMetricMDS:\n",
    "    \"\"\"Metric MDS solved with SMACOF (learning-oriented).\"\"\"\n",
    "\n",
    "    n_components: int = 2\n",
    "    max_iter: int = 300\n",
    "    tol: float = 1e-7\n",
    "    random_state: int = 42\n",
    "\n",
    "    embedding_: np.ndarray | None = None\n",
    "    stress_history_: np.ndarray | None = None\n",
    "\n",
    "    def fit_transform(self, D: np.ndarray) -> np.ndarray:\n",
    "        self.embedding_, self.stress_history_ = smacof_metric(\n",
    "            D,\n",
    "            n_components=self.n_components,\n",
    "            max_iter=self.max_iter,\n",
    "            tol=self.tol,\n",
    "            random_state=self.random_state,\n",
    "        )\n",
    "        return self.embedding_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ecc43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_mds = ScratchMetricMDS(n_components=2, max_iter=300, tol=1e-8, random_state=42)\n",
    "cities_smacof = scratch_mds.fit_transform(D)\n",
    "stress_hist = scratch_mds.stress_history_\n",
    "cities_smacof_aligned = procrustes_align(cities_true, cities_smacof, allow_scaling=True)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\n",
    "        \"Metric MDS (SMACOF) embedding (aligned)\",\n",
    "        \"Stress vs iterations\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=cities_smacof_aligned[:, 0],\n",
    "        y=cities_smacof_aligned[:, 1],\n",
    "        mode=\"markers+text\",\n",
    "        text=city_labels,\n",
    "        textposition=\"top center\",\n",
    "        name=\"smacof\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(1, len(stress_hist) + 1),\n",
    "        y=stress_hist,\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"stress\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(scaleanchor=\"y\", scaleratio=1, row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"iteration\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"raw stress\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Metric MDS via SMACOF: embedding + optimization trace\",\n",
    "    height=450,\n",
    "    showlegend=False,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f6f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity check (like in the supervised notebooks): scratch vs sklearn\n",
    "comparison = (\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            {\"method\": \"Classical MDS (eig)\", \"raw stress\": raw_stress(D, cities_classical)},\n",
    "            {\"method\": \"Metric MDS (SMACOF scratch)\", \"raw stress\": raw_stress(D, cities_smacof)},\n",
    "            {\"method\": \"Metric MDS (sklearn)\", \"raw stress\": raw_stress(D, cities_mds)},\n",
    "        ]\n",
    "    )\n",
    "    .sort_values(\"raw stress\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1508ef",
   "metadata": {},
   "source": [
    "## 4) Plotly diagnostics: distance preservation errors\n",
    "\n",
    "Perfect Euclidean distances are a *best case*.\n",
    "\n",
    "In practice, your dissimilarities might come from:\n",
    "\n",
    "- measurement noise\n",
    "- road distances (not straight-line Euclidean)\n",
    "- human similarity ratings\n",
    "\n",
    "So the distances may not be exactly representable in 2D.\n",
    "\n",
    "Below we add a small amount of symmetric noise to the distance matrix and compare:\n",
    "\n",
    "- **Classical MDS** (eigendecomposition)\n",
    "- **Metric MDS** (our SMACOF optimizer)\n",
    "- **Metric MDS** (scikit-learn, as a reference implementation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c060e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add symmetric noise to the distance matrix (simulate imperfect measurements)\n",
    "noise_level = 0.08\n",
    "noise = rng.normal(loc=0.0, scale=noise_level, size=D.shape)\n",
    "\n",
    "D_noisy = D * (1.0 + noise)\n",
    "D_noisy = np.maximum(D_noisy, 0.0)\n",
    "D_noisy = 0.5 * (D_noisy + D_noisy.T)\n",
    "np.fill_diagonal(D_noisy, 0.0)\n",
    "\n",
    "cities_classical_noisy, eigvals_noisy = classical_mds(D_noisy, n_components=2)\n",
    "cities_smacof_noisy, stress_hist_noisy = smacof_metric(\n",
    "    D_noisy,\n",
    "    n_components=2,\n",
    "    max_iter=500,\n",
    "    tol=1e-8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "mds_sklearn_noisy = MDS(\n",
    "    n_components=2,\n",
    "    metric=True,\n",
    "    dissimilarity=\"precomputed\",\n",
    "    random_state=42,\n",
    "    n_init=8,\n",
    "    max_iter=500,\n",
    ")\n",
    "\n",
    "cities_mds_noisy = mds_sklearn_noisy.fit_transform(D_noisy)\n",
    "\n",
    "methods_noisy = {\n",
    "    \"Classical MDS\": cities_classical_noisy,\n",
    "    \"Metric MDS (SMACOF)\": cities_smacof_noisy,\n",
    "    \"Metric MDS (sklearn)\": cities_mds_noisy,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance_errors(D_target: np.ndarray, Y: np.ndarray) -> dict[str, np.ndarray | float]:\n",
    "    D_target = validate_distance_matrix(D_target)\n",
    "    Y = np.asarray(Y, dtype=float)\n",
    "\n",
    "    D_emb = pairwise_euclidean_distances(Y)\n",
    "\n",
    "    n = D_target.shape[0]\n",
    "    tri = np.triu_indices(n, 1)\n",
    "\n",
    "    d0 = D_target[tri]\n",
    "    d1 = D_emb[tri]\n",
    "\n",
    "    rel = (d1 - d0) / (d0 + 1e-12)\n",
    "    abs_rel = np.abs(rel)\n",
    "\n",
    "    return {\n",
    "        \"abs_rel_error\": abs_rel,\n",
    "        \"spearman_r\": float(spearmanr(d0, d1).statistic),\n",
    "    }\n",
    "\n",
    "\n",
    "rows = []\n",
    "summary = []\n",
    "for name, Y in methods_noisy.items():\n",
    "    stats = pairwise_distance_errors(D_noisy, Y)\n",
    "\n",
    "    rows.append(pd.DataFrame({\"method\": name, \"abs_rel_error\": stats[\"abs_rel_error\"]}))\n",
    "\n",
    "    summary.append(\n",
    "        {\n",
    "            \"method\": name,\n",
    "            \"mean(|Δd|/d)\": float(np.mean(stats[\"abs_rel_error\"])),\n",
    "            \"median(|Δd|/d)\": float(np.median(stats[\"abs_rel_error\"])),\n",
    "            \"spearman_r\": float(stats[\"spearman_r\"]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_err = pd.concat(rows, ignore_index=True)\n",
    "df_summary = pd.DataFrame(summary).sort_values(\"mean(|Δd|/d)\")\n",
    "\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c726e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    df_err,\n",
    "    x=\"abs_rel_error\",\n",
    "    color=\"method\",\n",
    "    nbins=35,\n",
    "    barmode=\"overlay\",\n",
    "    opacity=0.6,\n",
    "    marginal=\"box\",\n",
    "    title=\"Distance preservation errors on a noisy distance matrix\",\n",
    "    labels={\"abs_rel_error\": \"|d_emb - d_target| / d_target\"},\n",
    ")\n",
    "fig.update_layout(height=450)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac39c09",
   "metadata": {},
   "source": [
    "## 5) Comparison: MDS vs PCA vs Isomap\n",
    "\n",
    "All three produce low-dimensional embeddings, but they optimize different things.\n",
    "\n",
    "| Method | Input you start from | What it tries to preserve | When it shines |\n",
    "|---|---|---|---|\n",
    "| **PCA** | feature matrix $X$ | variance in a **linear** subspace | fast baseline, denoising, roughly-linear structure |\n",
    "| **(Classical/Metric) MDS** | distance matrix $\\Delta$ | **pairwise distances** (or ranks of distances) | when “distances come first” (similarity tables, human judgments, graph distances) |\n",
    "| **Isomap** | feature matrix $X$ | **geodesic distances** on a manifold | nonlinear “unrolling” when a manifold model is reasonable |\n",
    "\n",
    "Rules of thumb:\n",
    "\n",
    "- Use **PCA** when a linear subspace is a good approximation.\n",
    "- Use **MDS** when you trust your dissimilarities (or only trust their **order**, for non-metric MDS).\n",
    "- Use **Isomap** when local neighborhoods are meaningful and you want to preserve them globally.\n",
    "\n",
    "Fun fact: **Isomap** is essentially **classical MDS** applied to a *geodesic* distance matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa433346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A classic nonlinear dataset: the swiss roll\n",
    "X3, t = make_swiss_roll(n_samples=450, noise=0.05, random_state=42)\n",
    "X3 = StandardScaler().fit_transform(X3)\n",
    "\n",
    "# PCA (linear)\n",
    "Y_pca = PCA(n_components=2, random_state=42).fit_transform(X3)\n",
    "\n",
    "# Classical MDS on Euclidean distances in 3D\n",
    "D_euclid = validate_distance_matrix(pairwise_euclidean_distances(X3))\n",
    "Y_mds, _ = classical_mds(D_euclid, n_components=2)\n",
    "\n",
    "# Isomap (geodesic distances)\n",
    "iso = Isomap(n_neighbors=10, n_components=2)\n",
    "Y_iso = iso.fit_transform(X3)\n",
    "D_geo = iso.dist_matrix_\n",
    "\n",
    "df_embed = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame({\"dim1\": Y_pca[:, 0], \"dim2\": Y_pca[:, 1], \"method\": \"PCA\", \"t\": t}),\n",
    "        pd.DataFrame({\"dim1\": Y_mds[:, 0], \"dim2\": Y_mds[:, 1], \"method\": \"Classical MDS\", \"t\": t}),\n",
    "        pd.DataFrame({\"dim1\": Y_iso[:, 0], \"dim2\": Y_iso[:, 1], \"method\": \"Isomap\", \"t\": t}),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_embed,\n",
    "    x=\"dim1\",\n",
    "    y=\"dim2\",\n",
    "    color=\"t\",\n",
    "    facet_col=\"method\",\n",
    "    facet_col_spacing=0.06,\n",
    "    title=\"Swiss roll: PCA vs MDS vs Isomap\",\n",
    "    labels={\"t\": \"roll parameter\"},\n",
    "    height=450,\n",
    ")\n",
    "\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
    "fig.update_xaxes(matches=None)\n",
    "fig.update_yaxes(matches=None)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_rmse(D_target: np.ndarray, Y: np.ndarray) -> float:\n",
    "    D_target = validate_distance_matrix(D_target)\n",
    "    Y = np.asarray(Y, dtype=float)\n",
    "\n",
    "    D_emb = pairwise_euclidean_distances(Y)\n",
    "\n",
    "    n = D_target.shape[0]\n",
    "    tri = np.triu_indices(n, 1)\n",
    "\n",
    "    d0 = D_target[tri]\n",
    "    d1 = D_emb[tri]\n",
    "\n",
    "    rel = (d1 - d0) / (d0 + 1e-12)\n",
    "    return float(np.sqrt(np.mean(rel**2)))\n",
    "\n",
    "\n",
    "metrics = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"method\": \"PCA (vs Euclidean)\",\n",
    "            \"relative RMSE\": relative_rmse(D_euclid, Y_pca),\n",
    "        },\n",
    "        {\n",
    "            \"method\": \"Classical MDS (vs Euclidean)\",\n",
    "            \"relative RMSE\": relative_rmse(D_euclid, Y_mds),\n",
    "        },\n",
    "        {\n",
    "            \"method\": \"Isomap (vs geodesic)\",\n",
    "            \"relative RMSE\": relative_rmse(D_geo, Y_iso),\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16230ed",
   "metadata": {},
   "source": [
    "## Pitfalls & diagnostics\n",
    "\n",
    "- **Local minima (metric/non-metric MDS):** different initializations can land in different solutions; try multiple `n_init`.\n",
    "- **Non-Euclidean dissimilarities:** classical MDS may show negative eigenvalues; metric/non-metric MDS is often safer.\n",
    "- **Scaling matters:** if dissimilarities are on wildly different scales, stress values are hard to interpret; consider normalization.\n",
    "- **Missing distances:** real problems may have unknown entries; you’ll need weights/masks (not covered here).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c295bf6",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Add noise to the distance matrix $\\Delta$ and observe what happens to (a) eigenvalues in classical MDS and (b) the stress curve in metric MDS.\n",
    "2. Implement a weighted stress function where some pairs have $w_{ij}=0$ (missing distances).\n",
    "3. Try non-metric MDS on data where distances are monotone-transformed (e.g., square all distances) and compare Spearman correlation.\n",
    "4. On swiss roll, change `n_neighbors` in Isomap and see when it fails (too small = disconnected graph, too large = geodesics become Euclidean).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d009942",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- scikit-learn docs: `sklearn.manifold.MDS`, `sklearn.manifold.Isomap`\n",
    "- Borg & Groenen — *Modern Multidimensional Scaling*\n",
    "- Torgerson (1952), Gower (1966) — classical MDS foundations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
