{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contingency Matrix (`sklearn.metrics.cluster.contingency_matrix`)\n",
    "\n",
    "The **contingency matrix** is a count table that summarizes how two labelings overlap.\n",
    "In clustering evaluation it is commonly built from:\n",
    "\n",
    "- `labels_true`: ground-truth classes (if available)\n",
    "- `labels_pred`: predicted cluster IDs (**arbitrary up to permutation**)\n",
    "\n",
    "It is the fundamental object behind many external clustering scores (purity, mutual information, Rand index, ...).\n",
    "\n",
    "---\n",
    "\n",
    "## Quick import\n",
    "\n",
    "```python\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "```\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "- Define the contingency matrix with clear math notation\n",
    "- Implement it from scratch in NumPy\n",
    "- Visualize and interpret it (raw counts + normalized views)\n",
    "- Use it to align cluster IDs to classes and compute simple derived scores (purity, \"best-mapped\" accuracy)\n",
    "- Use it for a simple hyperparameter search (choose `k` for k-means) when ground truth exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from scipy import sparse as sp\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Definition\n",
    "\n",
    "Let there be $n$ items. For each item $i$ we have two labels:\n",
    "\n",
    "- a reference label (often ground truth) $y_i$\n",
    "- a predicted label (often a cluster ID) $z_i$\n",
    "\n",
    "Assume the unique values in $y$ are $\\mathcal{C} = \\{c_1,\\dots,c_C\\}$ and in $z$ are $\\mathcal{K} = \\{k_1,\\dots,k_K\\}$.\n",
    "\n",
    "The **contingency matrix** $N \\in \\mathbb{R}^{C \\times K}$ is defined by:\n",
    "\n",
    "$$\n",
    "N_{a,b} = \\sum_{i=1}^n \\mathbf{1}\\{y_i=c_a \\ \\wedge \\ z_i=k_b\\}\n",
    "$$\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "- Row $a$ describes how true class $c_a$ is split across clusters.\n",
    "- Column $b$ describes which true classes appear inside cluster $k_b$.\n",
    "\n",
    "Useful marginals:\n",
    "\n",
    "$$\n",
    "n_a = \\sum_{b=1}^K N_{a,b} \\quad (\\text{size of class } c_a), \\qquad\n",
    "m_b = \\sum_{a=1}^C N_{a,b} \\quad (\\text{size of cluster } k_b)\n",
    "$$\n",
    "\n",
    "and $\\sum_{a,b} N_{a,b} = n$.\n",
    "\n",
    "### Probabilistic view\n",
    "\n",
    "Dividing by $n$ gives the empirical joint distribution:\n",
    "\n",
    "$$\n",
    "P_{a,b} = \\frac{N_{a,b}}{n}\n",
    "$$\n",
    "\n",
    "Many information-theoretic clustering metrics (e.g. mutual information) are computed from $P$ (plus its row/column marginals).\n",
    "\n",
    "### `eps` in scikit-learn\n",
    "\n",
    "`sklearn.metrics.cluster.contingency_matrix` has an optional `eps` argument that adds a constant to every entry:\n",
    "\n",
    "$$\n",
    "N \\leftarrow N + \\varepsilon\n",
    "$$\n",
    "\n",
    "This is mainly a numerical trick to avoid `log(0)` / NaN propagation in downstream computations.\n",
    "It changes the counts, so use it intentionally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) NumPy implementation (dense, plus an optional sparse variant)\n",
    "\n",
    "Below is a small from-scratch implementation.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- scikit-learn returns only the matrix; here we also return the unique label values so we can label axes in plots.\n",
    "- `sparse=True` returns a CSR matrix (useful when $C\\times K$ is huge but only few entries are non-zero).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contingency_matrix_np(labels_true, labels_pred, *, eps=None, sparse=False, dtype=np.int64):\n",
    "    \"\"\"Build a contingency matrix N where N[a,b] = #{i : y_i=c_a and z_i=k_b}.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cm : ndarray or scipy.sparse.csr_matrix of shape (n_true, n_pred)\n",
    "    true_labels : ndarray of shape (n_true,)\n",
    "        Sorted unique values from labels_true (np.unique ordering).\n",
    "    pred_labels : ndarray of shape (n_pred,)\n",
    "        Sorted unique values from labels_pred (np.unique ordering).\n",
    "    \"\"\"\n",
    "    y = np.asarray(labels_true)\n",
    "    z = np.asarray(labels_pred)\n",
    "\n",
    "    if y.shape != z.shape:\n",
    "        raise ValueError(f\"labels_true and labels_pred must have the same shape; got {y.shape} vs {z.shape}\")\n",
    "\n",
    "    y = y.ravel()\n",
    "    z = z.ravel()\n",
    "\n",
    "    true_labels, y_inv = np.unique(y, return_inverse=True)\n",
    "    pred_labels, z_inv = np.unique(z, return_inverse=True)\n",
    "\n",
    "    n_true = true_labels.size\n",
    "    n_pred = pred_labels.size\n",
    "\n",
    "    if sparse:\n",
    "        if eps is not None:\n",
    "            raise ValueError(\"eps must be None when sparse=True (matches scikit-learn behavior)\")\n",
    "        data = np.ones_like(y_inv, dtype=dtype)\n",
    "        cm = sp.coo_matrix((data, (y_inv, z_inv)), shape=(n_true, n_pred), dtype=dtype).tocsr()\n",
    "        return cm, true_labels, pred_labels\n",
    "\n",
    "    cm = np.zeros((n_true, n_pred), dtype=dtype)\n",
    "    np.add.at(cm, (y_inv, z_inv), 1)\n",
    "\n",
    "    if eps is not None:\n",
    "        cm = cm.astype(np.float64, copy=False) + float(eps)\n",
    "\n",
    "    return cm, true_labels, pred_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_true = np.array([\"cat\", \"cat\", \"dog\", \"dog\", \"dog\", \"fish\", \"fish\"])\n",
    "labels_pred = np.array([1, 1, 0, 0, 2, 2, 2])\n",
    "\n",
    "cm_np, y_vals, z_vals = contingency_matrix_np(labels_true, labels_pred)\n",
    "cm_sk = contingency_matrix(labels_true, labels_pred)\n",
    "\n",
    "print(\"true label values:\", y_vals)\n",
    "print(\"pred label values:\", z_vals)\n",
    "print(\"\\ncontingency (NumPy):\\n\", cm_np)\n",
    "print(\"\\ncontingency (sklearn):\\n\", cm_sk)\n",
    "print(\"\\nallclose:\", np.allclose(cm_np, cm_sk))\n",
    "\n",
    "cm_sparse, _, _ = contingency_matrix_np(labels_true, labels_pred, sparse=True)\n",
    "print(\"\\nsparse (csr) -> dense:\\n\", cm_sparse.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(\n",
    "    cm_np,\n",
    "    text_auto=True,\n",
    "    aspect=\"auto\",\n",
    "    x=[str(v) for v in z_vals],\n",
    "    y=[str(v) for v in y_vals],\n",
    "    labels={\"x\": \"predicted label / cluster\", \"y\": \"true label\", \"color\": \"count\"},\n",
    "    title=\"Contingency matrix (raw counts)\",\n",
    ")\n",
    "fig.update_layout(height=350)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Normalized views (row-wise vs column-wise)\n",
    "\n",
    "Raw counts are great for interpretability, but they scale with dataset size.\n",
    "Two common normalizations turn the table into conditional probabilities:\n",
    "\n",
    "- **Row-normalized**: $N_{a,b} / n_a \\approx P(z=k_b \\mid y=c_a)$\n",
    "- **Column-normalized**: $N_{a,b} / m_b \\approx P(y=c_a \\mid z=k_b)$\n",
    "\n",
    "Row-normalization answers: *\"Given a true class, how does it get distributed over clusters?\"*\n",
    "Column-normalization answers: *\"Given a predicted cluster, what's its composition?\"*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = cm_np.sum(axis=1, keepdims=True)\n",
    "col_sums = cm_np.sum(axis=0, keepdims=True)\n",
    "\n",
    "row_norm = np.divide(cm_np, row_sums, where=row_sums > 0)\n",
    "col_norm = np.divide(cm_np, col_sums, where=col_sums > 0)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Row-normalized: P(cluster | class)\", \"Column-normalized: P(class | cluster)\"),\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=row_norm,\n",
    "        x=[str(v) for v in z_vals],\n",
    "        y=[str(v) for v in y_vals],\n",
    "        zmin=0,\n",
    "        zmax=1,\n",
    "        colorbar=dict(title=\"prob\"),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=col_norm,\n",
    "        x=[str(v) for v in z_vals],\n",
    "        y=[str(v) for v in y_vals],\n",
    "        zmin=0,\n",
    "        zmax=1,\n",
    "        showscale=False,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_layout(height=360, title=\"Same contingency table, different questions\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Label permutation (why clusters are different from classes)\n",
    "\n",
    "Cluster IDs have **no semantic meaning**: cluster `0` vs `1` is arbitrary.\n",
    "If we relabel clusters, the contingency matrix columns simply **permute**.\n",
    "\n",
    "This is why many clustering scores are **label-permutation invariant**.\n",
    "If you compare contingency matrices directly, make sure you're comparing them in a consistent column order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permute the predicted labels (swap the meaning of cluster IDs)\n",
    "\n",
    "# Here z_vals are [0, 1, 2], so we can permute by an index mapping.\n",
    "perm = np.array([2, 0, 1])  # 0->2, 1->0, 2->1\n",
    "labels_pred_perm = perm[labels_pred]\n",
    "\n",
    "cm_perm, _, z_vals_perm = contingency_matrix_np(labels_true, labels_pred_perm)\n",
    "inv_perm = np.argsort(perm)  # new->old\n",
    "\n",
    "print(\"perm (old->new):\", perm)\n",
    "print(\"inv_perm (new->old):\", inv_perm)\n",
    "print(\"original pred label values:\", z_vals)\n",
    "print(\"permuted pred label values:\", z_vals_perm)\n",
    "print(\"cm_perm == cm_np[:, inv_perm] ?\", np.allclose(cm_perm, cm_np[:, inv_perm]))\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Original\", \"After permuting cluster IDs\"))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Heatmap(z=cm_np, x=[str(v) for v in z_vals], y=[str(v) for v in y_vals], text=cm_np, texttemplate=\"%{text}\"),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=cm_perm,\n",
    "        x=[str(v) for v in z_vals_perm],\n",
    "        y=[str(v) for v in y_vals],\n",
    "        text=cm_perm,\n",
    "        texttemplate=\"%{text}\",\n",
    "        showscale=False,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_layout(height=350, title=\"Permuting cluster IDs permutes contingency columns\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) A 2D clustering example (synthetic data)\n",
    "\n",
    "We'll create 3 Gaussian blobs with known labels (only for evaluation), run a simple NumPy k-means,\n",
    "and then visualize the resulting contingency matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic 2D dataset with 3 ground-truth classes\n",
    "\n",
    "centers = np.array([\n",
    "    [-2.0, -2.0],\n",
    "    [0.0, 2.5],\n",
    "    [2.5, -0.5],\n",
    "])\n",
    "std = 0.7\n",
    "n_per_class = 180\n",
    "\n",
    "X = np.vstack([rng.normal(loc=c, scale=std, size=(n_per_class, 2)) for c in centers])\n",
    "y_true = np.repeat(np.arange(len(centers)), n_per_class)\n",
    "\n",
    "# Shuffle so class blocks are mixed\n",
    "perm_idx = rng.permutation(X.shape[0])\n",
    "X = X[perm_idx]\n",
    "y_true = y_true[perm_idx]\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=X[:, 0],\n",
    "    y=X[:, 1],\n",
    "    color=y_true.astype(str),\n",
    "    title=\"Ground truth classes (for evaluation only)\",\n",
    "    labels={\"x\": \"x1\", \"y\": \"x2\", \"color\": \"true class\"},\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_single_run(X, k, *, n_iters=50, rng=None):\n",
    "    \"\"\"Basic k-means (Lloyd's algorithm) for Euclidean distance.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "    centers : ndarray of shape (k, n_features)\n",
    "    inertia : float\n",
    "        Sum of squared distances to assigned centers.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    # Init centers by sampling points\n",
    "    init_idx = rng.choice(n_samples, size=k, replace=False)\n",
    "    centers = X[init_idx].copy()\n",
    "\n",
    "    labels = np.zeros(n_samples, dtype=int)\n",
    "\n",
    "    for _ in range(n_iters):\n",
    "        # Assignment step\n",
    "        d2 = np.sum((X[:, None, :] - centers[None, :, :]) ** 2, axis=2)  # (n_samples, k)\n",
    "        new_labels = np.argmin(d2, axis=1)\n",
    "\n",
    "        # Update step\n",
    "        new_centers = centers.copy()\n",
    "        for j in range(k):\n",
    "            mask = new_labels == j\n",
    "            if not np.any(mask):\n",
    "                # Empty cluster -> re-init to a random point\n",
    "                new_centers[j] = X[rng.integers(0, n_samples)]\n",
    "            else:\n",
    "                new_centers[j] = X[mask].mean(axis=0)\n",
    "\n",
    "        if np.array_equal(new_labels, labels):\n",
    "            centers = new_centers\n",
    "            labels = new_labels\n",
    "            break\n",
    "\n",
    "        centers = new_centers\n",
    "        labels = new_labels\n",
    "\n",
    "    inertia = float(np.sum((X - centers[labels]) ** 2))\n",
    "    return labels, centers, inertia\n",
    "\n",
    "\n",
    "def kmeans_np(X, k, *, n_iters=50, n_init=10, rng=None):\n",
    "    \"\"\"Run k-means with multiple random initializations and keep the best inertia.\"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    best_labels = None\n",
    "    best_centers = None\n",
    "    best_inertia = np.inf\n",
    "\n",
    "    for _ in range(n_init):\n",
    "        labels, centers, inertia = kmeans_single_run(X, k, n_iters=n_iters, rng=rng)\n",
    "        if inertia < best_inertia:\n",
    "            best_inertia = inertia\n",
    "            best_labels = labels\n",
    "            best_centers = centers\n",
    "\n",
    "    return best_labels, best_centers, float(best_inertia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "labels_km, centers_km, inertia_km = kmeans_np(X, k, n_iters=60, n_init=8, rng=rng)\n",
    "\n",
    "print(\"k-means inertia (SSE):\", inertia_km)\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=X[:, 0],\n",
    "    y=X[:, 1],\n",
    "    color=labels_km.astype(str),\n",
    "    title=\"Predicted k-means clusters (k=3)\",\n",
    "    labels={\"x\": \"x1\", \"y\": \"x2\", \"color\": \"cluster\"},\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=centers_km[:, 0],\n",
    "        y=centers_km[:, 1],\n",
    "        mode=\"markers\",\n",
    "        name=\"centers\",\n",
    "        marker=dict(symbol=\"x\", size=14, color=\"black\"),\n",
    "    )\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm, y_vals, z_vals = contingency_matrix_np(y_true, labels_km)\n",
    "\n",
    "fig = px.imshow(\n",
    "    cm,\n",
    "    text_auto=True,\n",
    "    aspect=\"auto\",\n",
    "    x=[str(v) for v in z_vals],\n",
    "    y=[str(v) for v in y_vals],\n",
    "    labels={\"x\": \"cluster\", \"y\": \"true class\", \"color\": \"count\"},\n",
    "    title=\"Contingency matrix for k-means vs ground truth\",\n",
    ")\n",
    "fig.update_layout(height=360)\n",
    "fig.show()\n",
    "\n",
    "# Also show column-normalized view: P(class | cluster)\n",
    "col_sums = cm.sum(axis=0, keepdims=True)\n",
    "cm_col_norm = np.divide(cm, col_sums, where=col_sums > 0)\n",
    "\n",
    "fig = px.imshow(\n",
    "    cm_col_norm,\n",
    "    text_auto=\".2f\",\n",
    "    aspect=\"auto\",\n",
    "    x=[str(v) for v in z_vals],\n",
    "    y=[str(v) for v in y_vals],\n",
    "    labels={\"x\": \"cluster\", \"y\": \"true class\", \"color\": \"P(class | cluster)\"},\n",
    "    title=\"Column-normalized: how pure is each cluster?\",\n",
    "    zmin=0,\n",
    "    zmax=1,\n",
    ")\n",
    "fig.update_layout(height=360)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Derived scores + label alignment\n",
    "\n",
    "The contingency matrix itself is not a single \"score\", but you can derive many useful quantities.\n",
    "\n",
    "### Purity\n",
    "\n",
    "A simple external clustering score is **purity**:\n",
    "\n",
    "$$\n",
    "\\mathrm{Purity}(y,z) = \\frac{1}{n} \\sum_{b=1}^K \\max_{a \\in \\{1,\\dots,C\\}} N_{a,b}\n",
    "$$\n",
    "\n",
    "It measures how dominated each cluster is by its majority class. Purity increases as you increase $K$ (more clusters) and can reach 1.0 when every point is its own cluster.\n",
    "\n",
    "### \"Best-mapped\" accuracy\n",
    "\n",
    "Because cluster IDs are arbitrary, people sometimes map each cluster to a class and then compute an accuracy-like number.\n",
    "\n",
    "- **Majority-vote mapping**: map each cluster to its majority class.\n",
    "- **One-to-one mapping** (when $K=C$): choose a permutation that maximizes the total matches.\n",
    "\n",
    "These are useful for *interpretation* and *benchmarking*, but they are not a loss you can optimize with gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity_from_contingency(cm):\n",
    "    cm = np.asarray(cm)\n",
    "    return float(np.sum(np.max(cm, axis=0)) / np.sum(cm))\n",
    "\n",
    "\n",
    "def majority_vote_mapping(cm, true_labels, pred_labels):\n",
    "    \"\"\"Map each predicted label to the true label that is most frequent in that cluster.\"\"\"\n",
    "    cm = np.asarray(cm)\n",
    "    best_true_idx_per_cluster = np.argmax(cm, axis=0)\n",
    "    mapping = {pred_labels[j]: true_labels[i] for j, i in enumerate(best_true_idx_per_cluster)}\n",
    "    return mapping\n",
    "\n",
    "\n",
    "purity = purity_from_contingency(cm)\n",
    "mv_map = majority_vote_mapping(cm, y_vals, z_vals)\n",
    "y_pred_mv = np.array([mv_map[z] for z in labels_km])\n",
    "acc_mv = float(np.mean(y_pred_mv == y_true))\n",
    "\n",
    "print(\"purity:\", purity)\n",
    "print(\"majority-vote mapping:\", mv_map)\n",
    "print(\"majority-vote mapped accuracy:\", acc_mv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-to-one label alignment via the assignment problem (Hungarian algorithm)\n",
    "# Works best when K == C; otherwise it matches only min(C, K) pairs.\n",
    "\n",
    "row_ind, col_ind = linear_sum_assignment(-cm)  # maximize sum of counts\n",
    "hungarian_map = {z_vals[j]: y_vals[i] for i, j in zip(row_ind, col_ind)}\n",
    "y_pred_h = np.array([hungarian_map[z] for z in labels_km])\n",
    "acc_h = float(np.mean(y_pred_h == y_true))\n",
    "\n",
    "print(\"Hungarian mapping:\", hungarian_map)\n",
    "print(\"Hungarian mapped accuracy:\", acc_h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Using it for a simple optimization: choosing `k` for k-means (external criterion)\n",
    "\n",
    "The contingency matrix requires ground truth labels, so it is mainly used for:\n",
    "\n",
    "- benchmarking clustering algorithms on labeled datasets\n",
    "- semi-supervised settings (you *do* have labels)\n",
    "- debugging / sanity checks on synthetic data\n",
    "\n",
    "A simple way to \"optimize\" with it is to pick hyperparameters that maximize a derived external score (here: purity).\n",
    "\n",
    "We'll compare:\n",
    "\n",
    "- **Purity** (external, uses `y_true`)\n",
    "- **Inertia / SSE** (internal k-means objective, does *not* use labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity_score_np(y_true, z_pred):\n",
    "    cm, _, _ = contingency_matrix_np(y_true, z_pred)\n",
    "    return purity_from_contingency(cm)\n",
    "\n",
    "\n",
    "ks = list(range(2, 9))\n",
    "purities = []\n",
    "inertias = []\n",
    "\n",
    "for k in ks:\n",
    "    labels_k, centers_k, inertia_k = kmeans_np(X, k, n_iters=70, n_init=10, rng=rng)\n",
    "    purities.append(purity_score_np(y_true, labels_k))\n",
    "    inertias.append(inertia_k)\n",
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_trace(go.Scatter(x=ks, y=purities, mode=\"lines+markers\", name=\"Purity\"), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=ks, y=inertias, mode=\"lines+markers\", name=\"Inertia (SSE)\"), secondary_y=True)\n",
    "\n",
    "fig.update_xaxes(title_text=\"k (#clusters)\")\n",
    "fig.update_yaxes(title_text=\"Purity (higher better)\", range=[0, 1.05], secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"Inertia / SSE (lower better)\", secondary_y=True)\n",
    "fig.update_layout(title=\"Hyperparameter selection with contingency-derived purity\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple restarts: internal objective (inertia) vs external purity\n",
    "\n",
    "k = 3\n",
    "seeds = rng.integers(0, 1_000_000, size=40)\n",
    "\n",
    "purity_list = []\n",
    "inertia_list = []\n",
    "\n",
    "for s in seeds:\n",
    "    labels_s, centers_s, inertia_s = kmeans_single_run(X, k, n_iters=70, rng=np.random.default_rng(int(s)))\n",
    "    inertia_list.append(inertia_s)\n",
    "    purity_list.append(purity_score_np(y_true, labels_s))\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=inertia_list,\n",
    "    y=purity_list,\n",
    "    title=\"Random restarts (k=3): inertia vs purity\",\n",
    "    labels={\"x\": \"inertia / SSE\", \"y\": \"purity\"},\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Pros, cons, and when to use it\n",
    "\n",
    "### Pros\n",
    "\n",
    "- **Interpretable**: a direct count table of overlaps.\n",
    "- **Fast**: $\\mathcal{O}(n)$ time to build once labels are mapped to indices.\n",
    "- **Foundational**: many clustering metrics are functions of the contingency matrix.\n",
    "- **Flexible**: works with any hashable labels (ints, strings, ...).\n",
    "- **Sparse-friendly**: can be represented efficiently when $C\\times K$ is huge but most pairs never occur.\n",
    "\n",
    "### Cons\n",
    "\n",
    "- **Not a scalar score**: you usually need an additional reduction (purity, MI, ARI, ...).\n",
    "- **Requires reference labels** (`labels_true`): not available in pure unsupervised clustering.\n",
    "- **Easy to game** with $K$ (more clusters) if you turn it into purity/accuracy-like scores.\n",
    "- **Comparisons need care**: raw counts depend on dataset size and class imbalance.\n",
    "\n",
    "### Good uses\n",
    "\n",
    "- Debugging clustering pipelines on labeled or synthetic datasets.\n",
    "- Understanding failure modes (which classes get mixed/split).\n",
    "- As an intermediate object to compute robust, permutation-invariant clustering scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Pitfalls + diagnostics\n",
    "\n",
    "- **Axis confusion**: rows correspond to `labels_true`, columns to `labels_pred`.\n",
    "- **Permutation invariance**: cluster IDs are arbitrary; a \"different looking\" matrix may just be a column permutation.\n",
    "- **Imbalance**: a large class can dominate counts; inspect normalized views ($P(\\text{cluster}|\\text{class})$ and $P(\\text{class}|\\text{cluster})$).\n",
    "- **Different numbers of classes/clusters**: one-to-one alignment is not well-defined when $K\\neq C$.\n",
    "- **Using labels for tuning**: choosing hyperparameters by maximizing a contingency-derived score leaks supervision.\n",
    "- **`eps` changes the table**: only use it for numerical reasons in downstream log-based metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Exercises\n",
    "\n",
    "1. Implement a dense contingency matrix builder using only `np.bincount` (hint: flatten 2D indices).\n",
    "2. For the synthetic dataset, compare purity to a permutation-invariant score like ARI or NMI.\n",
    "3. Show how purity behaves as you let $k$ grow all the way to the number of points.\n",
    "4. Implement a one-to-one alignment using brute-force permutations for $K\\leq 7$ and compare to the Hungarian solution.\n",
    "\n",
    "## References\n",
    "\n",
    "- scikit-learn docs: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cluster.contingency_matrix.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}