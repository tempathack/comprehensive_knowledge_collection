{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silhouette Score — Clustering Validation (From Scratch)\n",
    "\n",
    "The **silhouette score** is an *internal* clustering metric: it evaluates cluster quality using only the data and the assigned cluster labels (no ground-truth classes needed).\n",
    "\n",
    "It compares, for each sample, how close it is to points in its own cluster (**cohesion**) versus how close it is to points in the nearest other cluster (**separation**).\n",
    "\n",
    "## What you’ll learn\n",
    "- The exact definition of $a(i)$, $b(i)$, and the silhouette coefficient $s(i)$\n",
    "- A NumPy implementation of `silhouette_samples` / `silhouette_score`\n",
    "- How to read a **silhouette plot** (per-sample diagnostics)\n",
    "- How to use the silhouette score to **select $k$** for a simple K-means implementation\n",
    "- Pros/cons and common pitfalls (distance metrics, scaling, cluster shape)\n",
    "\n",
    "## Quick import (scikit-learn)\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score as skl_silhouette_score\n",
    "from sklearn.metrics import silhouette_samples as skl_silhouette_samples\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Intuition: “am I closer to my own cluster?”\n",
    "\n",
    "For a point $x_i$:\n",
    "\n",
    "- if it’s **much closer** to points in its own cluster than to points in other clusters → silhouette near **1**\n",
    "- if it lies on the **border** between clusters → silhouette near **0**\n",
    "- if it’s actually **closer to another cluster** than to its assigned one → silhouette becomes **negative**\n",
    "\n",
    "This makes the silhouette score useful not only as a single number, but also as a **diagnostic**: you can find which points are likely misclustered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Definition (math + notation)\n",
    "\n",
    "Let:\n",
    "\n",
    "- $X = \\{x_i\\}_{i=1}^n$ with $x_i \\in \\mathbb{R}^d$\n",
    "- cluster labels $y_i \\in \\{0, 1, \\dots, k-1\\}$\n",
    "- a distance function $d(x_i, x_j)$ (often Euclidean)\n",
    "\n",
    "Define the index set of cluster $c$:\n",
    "\n",
    "$$\n",
    "C_c = \\{ i \\in \\{1,\\dots,n\\} : y_i = c \\}\n",
    "$$\n",
    "\n",
    "For a given sample $i$ with assigned cluster $c = y_i$:\n",
    "\n",
    "### 2.1 Intra-cluster distance $a(i)$ (cohesion)\n",
    "\n",
    "$$\n",
    "a(i) = \\frac{1}{|C_c| - 1} \\sum_{j \\in C_c,\\; j \\neq i} d(x_i, x_j)\n",
    "$$\n",
    "\n",
    "If $|C_c| = 1$ (a singleton cluster), $a(i)$ is undefined; in practice we set the sample’s silhouette to 0.\n",
    "\n",
    "### 2.2 Nearest-cluster distance $b(i)$ (separation)\n",
    "\n",
    "Mean distance from $i$ to another cluster $c' \\neq c$:\n",
    "\n",
    "$$\n",
    "d(i, C_{c'}) = \\frac{1}{|C_{c'}|} \\sum_{j \\in C_{c'}} d(x_i, x_j)\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "b(i) = \\min_{c' \\neq c} d(i, C_{c'})\n",
    "$$\n",
    "\n",
    "### 2.3 Silhouette coefficient\n",
    "\n",
    "$$\n",
    "s(i) = \\frac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}}\n",
    "$$\n",
    "\n",
    "- $s(i) \\in [-1, 1]$\n",
    "- larger is better\n",
    "\n",
    "### 2.4 Mean silhouette score\n",
    "\n",
    "$$\n",
    "S = \\frac{1}{n} \\sum_{i=1}^n s(i)\n",
    "$$\n",
    "\n",
    "The score is only defined when $2 \\le k \\le n-1$ (you need at least 2 clusters, and not every point in its own cluster).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) From-scratch NumPy implementation\n",
    "\n",
    "A straightforward implementation computes the full pairwise distance matrix $D \\in \\mathbb{R}^{n\\times n}$ where $D_{ij} = d(x_i, x_j)$.\n",
    "\n",
    "- **Time**: $\\mathcal{O}(n^2 d)$ to build distances + additional work per cluster\n",
    "- **Memory**: $\\mathcal{O}(n^2)$ for the distance matrix\n",
    "\n",
    "For very large $n$, you typically need approximations (subsampling, nearest-neighbor graphs, or chunked computations).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X, eps=1e-12):\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    mean = X.mean(axis=0, keepdims=True)\n",
    "    std = X.std(axis=0, ddof=0, keepdims=True)\n",
    "    return (X - mean) / (std + eps), mean, std\n",
    "\n",
    "\n",
    "def pairwise_euclidean_distances(X):\n",
    "    \"\"\"Compute D[i, j] = ||x_i - x_j||_2 for all pairs.\n",
    "\n",
    "    Uses: ||a-b||^2 = ||a||^2 + ||b||^2 - 2 a·b\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    sq_norms = np.sum(X * X, axis=1, keepdims=True)  # (n, 1)\n",
    "    D2 = sq_norms + sq_norms.T - 2.0 * (X @ X.T)\n",
    "    D2 = np.maximum(D2, 0.0)  # numerical guard\n",
    "    return np.sqrt(D2)\n",
    "\n",
    "\n",
    "def silhouette_samples_from_distance_matrix(D, labels):\n",
    "    \"\"\"Silhouette coefficient per sample from a full distance matrix.\n",
    "\n",
    "    Args:\n",
    "        D: (n, n) symmetric distance matrix with zeros on diagonal\n",
    "        labels: (n,) cluster labels\n",
    "\n",
    "    Returns:\n",
    "        s: (n,) silhouette per sample\n",
    "    \"\"\"\n",
    "    labels = np.asarray(labels)\n",
    "    n = labels.shape[0]\n",
    "\n",
    "    D = np.asarray(D, dtype=float)\n",
    "    if D.shape != (n, n):\n",
    "        raise ValueError(f\"D must have shape (n,n) = {(n, n)}, got {D.shape}\")\n",
    "\n",
    "    unique_labels, inv = np.unique(labels, return_inverse=True)\n",
    "    k = unique_labels.size\n",
    "    if k < 2 or k >= n:\n",
    "        raise ValueError(\n",
    "            f\"silhouette is defined only for 2 <= n_clusters <= n_samples-1; got n_clusters={k}, n_samples={n}\"\n",
    "        )\n",
    "\n",
    "    cluster_indices = [np.where(inv == j)[0] for j in range(k)]\n",
    "\n",
    "    # a(i): mean intra-cluster distance (exclude self)\n",
    "    a = np.zeros(n, dtype=float)\n",
    "    singleton_mask = np.zeros(n, dtype=bool)\n",
    "    for j, idx in enumerate(cluster_indices):\n",
    "        m = idx.size\n",
    "        if m <= 1:\n",
    "            singleton_mask[idx] = True\n",
    "            continue\n",
    "        a[idx] = D[np.ix_(idx, idx)].sum(axis=1) / (m - 1)\n",
    "\n",
    "    # mean_dist[i, j] = mean_{p in cluster j} D[i, p]\n",
    "    mean_dist = np.empty((n, k), dtype=float)\n",
    "    for j, idx in enumerate(cluster_indices):\n",
    "        mean_dist[:, j] = D[:, idx].mean(axis=1)\n",
    "\n",
    "    # b(i): distance to nearest other cluster\n",
    "    mean_dist[np.arange(n), inv] = np.inf\n",
    "    b = mean_dist.min(axis=1)\n",
    "\n",
    "    denom = np.maximum(a, b)\n",
    "    s = np.zeros(n, dtype=float)\n",
    "    nonzero = denom > 0\n",
    "    s[nonzero] = (b[nonzero] - a[nonzero]) / denom[nonzero]\n",
    "\n",
    "    # sklearn convention: silhouette = 0 for singleton clusters\n",
    "    s[singleton_mask] = 0.0\n",
    "    return s\n",
    "\n",
    "\n",
    "def silhouette_score_from_distance_matrix(D, labels):\n",
    "    return float(silhouette_samples_from_distance_matrix(D, labels).mean())\n",
    "\n",
    "\n",
    "def silhouette_score_numpy(X, labels):\n",
    "    D = pairwise_euclidean_distances(X)\n",
    "    return silhouette_score_from_distance_matrix(D, labels)\n",
    "\n",
    "\n",
    "def silhouette_point_details(D, labels, i):\n",
    "    \"\"\"Return a(i), b(i), and mean distances to each cluster for sample i.\"\"\"\n",
    "    labels = np.asarray(labels)\n",
    "    unique_labels, inv = np.unique(labels, return_inverse=True)\n",
    "    cluster_indices = [np.where(inv == j)[0] for j in range(unique_labels.size)]\n",
    "\n",
    "    i_cluster = inv[i]\n",
    "    idx_self = cluster_indices[i_cluster]\n",
    "\n",
    "    mean_to_clusters = np.array([D[i, idx].mean() for idx in cluster_indices], dtype=float)\n",
    "\n",
    "    if idx_self.size <= 1:\n",
    "        a = 0.0\n",
    "    else:\n",
    "        # includes self-distance 0 in the sum; dividing by (m-1) excludes it effectively\n",
    "        a = float(D[i, idx_self].sum() / (idx_self.size - 1))\n",
    "\n",
    "    tmp = mean_to_clusters.copy()\n",
    "    tmp[i_cluster] = np.inf\n",
    "    b_cluster = int(np.argmin(tmp))\n",
    "    b = float(tmp[b_cluster])\n",
    "\n",
    "    return {\n",
    "        \"a\": a,\n",
    "        \"b\": b,\n",
    "        \"mean_to_clusters\": mean_to_clusters,\n",
    "        \"cluster_labels\": unique_labels,\n",
    "        \"i_cluster_label\": unique_labels[i_cluster],\n",
    "        \"b_cluster_label\": unique_labels[b_cluster],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) A tiny example (including a negative silhouette)\n",
    "\n",
    "We’ll create two compact clusters in 2D, then intentionally **mislabel one point**. That point should end up with a **negative** silhouette.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two tight clusters + one misassigned point\n",
    "X_toy = np.array(\n",
    "    [\n",
    "        [0.0, 0.0],\n",
    "        [0.0, 1.0],\n",
    "        [1.0, 0.0],\n",
    "        [1.0, 1.0],\n",
    "        [5.0, 0.0],\n",
    "        [5.0, 1.0],\n",
    "        [6.0, 0.0],\n",
    "        [6.0, 1.0],\n",
    "        [5.0, 0.5],  # near cluster 1...\n",
    "    ],\n",
    "    dtype=float,\n",
    ")\n",
    "\n",
    "labels_toy = np.array([0, 0, 0, 0, 1, 1, 1, 1, 0], dtype=int)  # ...but labeled as cluster 0\n",
    "\n",
    "D_toy = pairwise_euclidean_distances(X_toy)\n",
    "s_toy = silhouette_samples_from_distance_matrix(D_toy, labels_toy)\n",
    "score_toy = float(s_toy.mean())\n",
    "\n",
    "# sanity check vs scikit-learn\n",
    "skl_s_toy = skl_silhouette_samples(X_toy, labels_toy)\n",
    "skl_score_toy = float(skl_silhouette_score(X_toy, labels_toy))\n",
    "\n",
    "print(\"from scratch mean silhouette:\", score_toy)\n",
    "print(\"sklearn mean silhouette     :\", skl_score_toy)\n",
    "print(\"max |per-sample diff|       :\", float(np.max(np.abs(s_toy - skl_s_toy))))\n",
    "\n",
    "i = len(X_toy) - 1\n",
    "details = silhouette_point_details(D_toy, labels_toy, i)\n",
    "print(\"\\nselected point index:\", i)\n",
    "print(\"assigned cluster:\", int(labels_toy[i]))\n",
    "print(f\"a(i) (own cluster mean dist): {details['a']:.3f}\")\n",
    "print(f\"b(i) (nearest other cluster): {details['b']:.3f}\")\n",
    "print(f\"s(i)                         : {s_toy[i]:.3f}\")\n",
    "\n",
    "# scatter plot\n",
    "fig = px.scatter(\n",
    "    x=X_toy[:, 0],\n",
    "    y=X_toy[:, 1],\n",
    "    color=labels_toy.astype(str),\n",
    "    title=\"Toy clustering (one point is misassigned)\",\n",
    "    labels={\"color\": \"cluster\"},\n",
    "    width=750,\n",
    "    height=450,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[X_toy[i, 0]],\n",
    "        y=[X_toy[i, 1]],\n",
    "        mode=\"markers\",\n",
    "        name=\"selected point\",\n",
    "        marker=dict(symbol=\"star\", size=18, color=\"black\", line=dict(width=1, color=\"white\")),\n",
    "    )\n",
    ")\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig.show()\n",
    "\n",
    "# mean distance from selected point to each cluster\n",
    "cluster_labels = details[\"cluster_labels\"]\n",
    "mean_to = details[\"mean_to_clusters\"]\n",
    "x_names = [f\"cluster {c}\" for c in cluster_labels]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=x_names, y=mean_to, name=\"mean distance\"))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_names,\n",
    "        y=[details[\"a\"]] * len(x_names),\n",
    "        mode=\"lines\",\n",
    "        name=\"a(i)\",\n",
    "        line=dict(color=\"royalblue\", dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_names,\n",
    "        y=[details[\"b\"]] * len(x_names),\n",
    "        mode=\"lines\",\n",
    "        name=\"b(i)\",\n",
    "        line=dict(color=\"firebrick\", dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Mean distance from the selected point to each cluster\",\n",
    "    yaxis_title=\"mean distance\",\n",
    "    width=750,\n",
    "    height=420,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) The silhouette plot (per-sample diagnostics)\n",
    "\n",
    "A silhouette plot shows all $s(i)$ values, grouped by cluster and sorted within each cluster. This helps you see:\n",
    "\n",
    "- whether some clusters contain many borderline points ($s(i) \\approx 0$)\n",
    "- whether a cluster has many negatives (likely misclustered)\n",
    "- whether cluster sizes are extremely imbalanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_silhouette(s, labels, title=\"Silhouette plot\"):\n",
    "    s = np.asarray(s, dtype=float)\n",
    "    labels = np.asarray(labels)\n",
    "    unique = np.unique(labels)\n",
    "\n",
    "    colors = px.colors.qualitative.Set2\n",
    "    fig = go.Figure()\n",
    "\n",
    "    y_offset = 0\n",
    "    for j, lab in enumerate(unique):\n",
    "        vals = np.sort(s[labels == lab])\n",
    "        y = np.arange(y_offset, y_offset + vals.size)\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=vals,\n",
    "                y=y,\n",
    "                orientation=\"h\",\n",
    "                marker_color=colors[j % len(colors)],\n",
    "                name=f\"cluster {lab}\",\n",
    "                hovertemplate=\"s=%{x:.3f}<extra></extra>\",\n",
    "            )\n",
    "        )\n",
    "        y_offset += vals.size + 6\n",
    "\n",
    "    mean_s = float(np.mean(s))\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[mean_s, mean_s],\n",
    "            y=[-5, y_offset],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"black\", dash=\"dash\"),\n",
    "            showlegend=False,\n",
    "            hoverinfo=\"skip\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_annotation(x=mean_s, y=y_offset, text=f\"mean={mean_s:.3f}\", showarrow=False, yshift=10)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"silhouette value\",\n",
    "        yaxis_title=\"samples (grouped by cluster)\",\n",
    "        xaxis=dict(range=[-1, 1]),\n",
    "        width=900,\n",
    "        height=450,\n",
    "    )\n",
    "    fig.update_yaxes(showticklabels=False)\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = plot_silhouette(s_toy, labels_toy, title=\"Toy silhouette plot\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Using silhouette to select $k$ in K-means (from scratch)\n",
    "\n",
    "The silhouette score is **not** a smooth, differentiable loss in terms of cluster centroids (assignments change discretely). So you typically don’t optimize it with gradient descent.\n",
    "\n",
    "Instead, it’s commonly used for **model selection**:\n",
    "\n",
    "- choose a hyperparameter like the number of clusters $k$\n",
    "- compare different clustering algorithms / distance metrics\n",
    "- pick the best run among multiple random initializations\n",
    "\n",
    "Below is a minimal Lloyd-style K-means implementation + a small grid search over $k$ where we pick the best $k$ by maximizing the mean silhouette score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_lloyd(X, k, rng, max_iter=100, tol=1e-6):\n",
    "    \"\"\"Very small K-means (Lloyd's algorithm) implementation.\"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    n, d = X.shape\n",
    "    if not (1 <= k <= n):\n",
    "        raise ValueError(\"k must be in [1, n_samples]\")\n",
    "\n",
    "    centroids = X[rng.choice(n, size=k, replace=False)]\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        # assignment step\n",
    "        D2 = np.sum((X[:, None, :] - centroids[None, :, :]) ** 2, axis=2)  # (n, k)\n",
    "        labels = np.argmin(D2, axis=1)\n",
    "\n",
    "        # update step\n",
    "        new_centroids = centroids.copy()\n",
    "        for j in range(k):\n",
    "            mask = labels == j\n",
    "            if not np.any(mask):\n",
    "                # handle empty cluster by reinitializing to a random point\n",
    "                new_centroids[j] = X[rng.integers(n)]\n",
    "            else:\n",
    "                new_centroids[j] = X[mask].mean(axis=0)\n",
    "\n",
    "        shift = np.linalg.norm(new_centroids - centroids)\n",
    "        centroids = new_centroids\n",
    "\n",
    "        if shift <= tol:\n",
    "            break\n",
    "\n",
    "    # final assignment with the final centroids\n",
    "    D2 = np.sum((X[:, None, :] - centroids[None, :, :]) ** 2, axis=2)\n",
    "    labels = np.argmin(D2, axis=1)\n",
    "    return labels, centroids\n",
    "\n",
    "\n",
    "def best_kmeans_by_silhouette(X, D, k, n_init=10, seed=0, max_iter=100):\n",
    "    rng_local = np.random.default_rng(seed)\n",
    "    best_score = -np.inf\n",
    "    best_labels = None\n",
    "    best_centroids = None\n",
    "\n",
    "    for _ in range(n_init):\n",
    "        labels, centroids = kmeans_lloyd(X, k, rng_local, max_iter=max_iter)\n",
    "        try:\n",
    "            score = silhouette_score_from_distance_matrix(D, labels)\n",
    "        except ValueError:\n",
    "            # can happen if a run collapses into 1 effective cluster\n",
    "            continue\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_labels = labels\n",
    "            best_centroids = centroids\n",
    "\n",
    "    if best_labels is None:\n",
    "        raise RuntimeError(\"All initializations produced an invalid clustering\")\n",
    "\n",
    "    return float(best_score), best_labels, best_centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic 2D dataset (3 Gaussian blobs with different spreads + a few outliers)\n",
    "n_per = 150\n",
    "centers = np.array([[-2.5, -0.5], [0.0, 2.8], [2.7, -0.2]])\n",
    "scales = np.array([0.35, 0.55, 0.75])\n",
    "\n",
    "X_raw = np.vstack(\n",
    "    [rng.normal(loc=centers[j], scale=scales[j], size=(n_per, 2)) for j in range(centers.shape[0])]\n",
    ")\n",
    "\n",
    "outliers = rng.uniform(low=[-4.0, -3.0], high=[4.0, 4.0], size=(25, 2))\n",
    "X_raw = np.vstack([X_raw, outliers])\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=X_raw[:, 0],\n",
    "    y=X_raw[:, 1],\n",
    "    title=\"Synthetic dataset (unlabeled)\",\n",
    "    width=750,\n",
    "    height=450,\n",
    ")\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig.show()\n",
    "\n",
    "# IMPORTANT: silhouette uses distances, so feature scaling matters.\n",
    "X, _, _ = standardize(X_raw)\n",
    "D = pairwise_euclidean_distances(X)\n",
    "\n",
    "ks = list(range(2, 9))\n",
    "scores = []\n",
    "models = {}\n",
    "\n",
    "for k in ks:\n",
    "    score, labels, centroids = best_kmeans_by_silhouette(X, D, k, n_init=8, seed=100 + k, max_iter=80)\n",
    "    scores.append(score)\n",
    "    models[k] = (labels, centroids)\n",
    "\n",
    "k_best = int(ks[int(np.argmax(scores))])\n",
    "labels_best, centroids_best = models[k_best]\n",
    "\n",
    "print(\"best k:\", k_best)\n",
    "print(\"best mean silhouette:\", float(np.max(scores)))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ks, y=scores, mode=\"lines+markers\", name=\"mean silhouette\"))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[k_best],\n",
    "        y=[float(np.max(scores))],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=12, color=\"black\"),\n",
    "        name=\"chosen k\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Silhouette score vs number of clusters (K-means from scratch)\",\n",
    "    xaxis_title=\"k\",\n",
    "    yaxis_title=\"mean silhouette\",\n",
    "    width=800,\n",
    "    height=420,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=X[:, 0],\n",
    "    y=X[:, 1],\n",
    "    color=labels_best.astype(str),\n",
    "    title=f\"K-means from scratch (k={k_best})\",\n",
    "    labels={\"color\": \"cluster\"},\n",
    "    width=750,\n",
    "    height=450,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=centroids_best[:, 0],\n",
    "        y=centroids_best[:, 1],\n",
    "        mode=\"markers\",\n",
    "        name=\"centroids\",\n",
    "        marker=dict(symbol=\"x\", size=12, color=\"black\"),\n",
    "    )\n",
    ")\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_best = silhouette_samples_from_distance_matrix(D, labels_best)\n",
    "fig = plot_silhouette(s_best, labels_best, title=f\"Silhouette plot (k={k_best})\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Practical usage with scikit-learn\n",
    "\n",
    "In practice you’ll often compute silhouette for a fitted clustering model:\n",
    "\n",
    "```python\n",
    "labels = model.fit_predict(X)\n",
    "score = silhouette_score(X, labels)\n",
    "```\n",
    "\n",
    "Below we compute silhouette for scikit-learn’s `KMeans` and verify that our NumPy implementation matches `sklearn.metrics.silhouette_score` for the same labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=k_best, n_init=10, random_state=7)\n",
    "labels_skl = kmeans.fit_predict(X)\n",
    "\n",
    "score_skl = float(skl_silhouette_score(X, labels_skl))\n",
    "score_np = silhouette_score_numpy(X, labels_skl)\n",
    "\n",
    "print(\"sklearn KMeans silhouette:\", score_skl)\n",
    "print(\"our silhouette (same labels):\", score_np)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros / Cons / Pitfalls\n",
    "\n",
    "### Pros\n",
    "- **No ground truth needed** (internal validation)\n",
    "- **Interpretable scale** in $[-1, 1]$ and available **per-sample** (easy to diagnose bad assignments)\n",
    "- Works with **any distance metric** (Euclidean, cosine, etc.) if it matches your notion of similarity\n",
    "\n",
    "### Cons / limitations\n",
    "- **Expensive** for large datasets: exact computation needs all pairwise distances ($\\mathcal{O}(n^2)$)\n",
    "- Assumes distances are meaningful; in high dimensions distances can **concentrate**\n",
    "- Often favors **compact / convex** clusters; can be misleading for non-globular structure (e.g., \"two moons\")\n",
    "- Sensitive to **feature scaling**, outliers, and clusters with very different sizes/densities\n",
    "- Not a training loss: it’s generally **non-differentiable**, so it’s used for **model selection**, not gradient descent\n",
    "\n",
    "### Practical diagnostics\n",
    "- Don’t rely on the mean alone: inspect the **silhouette plot**.\n",
    "- Many negative values → points are likely assigned to the wrong cluster or $k$ is wrong.\n",
    "- Singleton clusters get silhouette 0 by convention; if they appear, treat it as a warning sign.\n",
    "\n",
    "## Exercises\n",
    "- Implement silhouette using **Manhattan distance** and compare results.\n",
    "- Create a dataset with non-convex clusters (two moons) and see how silhouette behaves with K-means.\n",
    "\n",
    "## References\n",
    "- P. J. Rousseeuw (1987), *Silhouettes: a graphical aid to the interpretation and validation of cluster analysis*.\n",
    "- scikit-learn docs: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
