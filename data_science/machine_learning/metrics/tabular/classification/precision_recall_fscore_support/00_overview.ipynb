{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# precision_recall_fscore_support\n",
    "\n",
    "Compute precision, recall, F-score, and support.\n",
    "\n",
    "## Quick import\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- **Intuition**: returns precision, recall, F1-score, and support per class.\n",
    "- **Aggregation**: use `average=` to compute micro/macro/weighted summaries.\n",
    "- **Pitfalls**: undefined metrics for classes with no predicted samples; manage via `zero_division`.\n",
    "\n",
    "## Example\n",
    "\n",
    "Small, self-contained example:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Toy multiclass example\n",
    "y_true = np.array([0, 1, 2, 2, 1, 0])\n",
    "y_pred = np.array([0, 2, 2, 2, 1, 0])\n",
    "\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    y_true, y_pred, average=None\n",
    ")\n",
    "precision, recall, f1, support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- scikit-learn docs: https://scikit-learn.org/stable/api/sklearn.metrics.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}