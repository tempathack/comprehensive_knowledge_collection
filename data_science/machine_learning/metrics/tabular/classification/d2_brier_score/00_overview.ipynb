{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D² Brier Score (`d2_brier_score`)\n",
    "\n",
    "The **Brier score** measures how close your predicted probabilities are to the true 0/1 outcomes.\n",
    "The **D² Brier score** turns that into an **explained fraction** (similar to $R^2$):\n",
    "\n",
    "- $D^2 = 1$ is perfect probability predictions\n",
    "- $D^2 = 0$ is a constant **\"predict the base rate\"** baseline\n",
    "- $D^2 < 0$ means worse than the baseline\n",
    "\n",
    "This notebook covers:\n",
    "\n",
    "- intuition + plots (Plotly)\n",
    "- the math (LaTeX)\n",
    "- a from-scratch NumPy implementation\n",
    "- using the metric as an optimization objective (logistic regression trained by minimizing Brier loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import brier_score_loss, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Problem setting\n",
    "\n",
    "We focus on **binary classification**.\n",
    "\n",
    "- True labels: $y_i \\in \\{0, 1\\}$\n",
    "- Predicted probability for the positive class: $p_i \\in [0, 1]$ where\n",
    "\n",
    "$$\n",
    "p_i \\approx \\mathbb{P}(y_i = 1 \\mid x_i).\n",
    "$$\n",
    "\n",
    "The key is that we evaluate **probabilities**, not hard class labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Brier score (the underlying loss)\n",
    "\n",
    "For binary outcomes, the Brier score is just mean squared error in probability space:\n",
    "\n",
    "$$\n",
    "\\mathrm{BS}(y, p)\n",
    "= \\frac{1}{n}\\sum_{i=1}^n (p_i - y_i)^2.\n",
    "$$\n",
    "\n",
    "With non-negative sample weights $w_i$:\n",
    "\n",
    "$$\n",
    "\\mathrm{BS}_w(y, p)\n",
    "= \\frac{\\sum_{i=1}^n w_i (p_i - y_i)^2}{\\sum_{i=1}^n w_i}.\n",
    "$$\n",
    "\n",
    "**Interpretation:** each example contributes a squared error term.\n",
    "\n",
    "- Predict $p_i \\approx 1$ when $y_i = 1$ and $p_i \\approx 0$ when $y_i = 0$ → small loss\n",
    "- Be very confident and wrong (e.g. $p_i \\approx 1$ but $y_i = 0$) → loss close to 1\n",
    "\n",
    "The Brier score is a **proper scoring rule**: in expectation, it is minimized by predicting the true probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "p = np.linspace(0, 1, 401)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=p, y=(p - 0.0) ** 2, mode=\"lines\", name=\"y=0\"))\n",
    "fig.add_trace(go.Scatter(x=p, y=(p - 1.0) ** 2, mode=\"lines\", name=\"y=1\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Brier loss for a single example: (p - y)^2\",\n",
    "    xaxis_title=\"Predicted probability p\",\n",
    "    yaxis_title=\"Squared error\",\n",
    ")\n",
    "fig.update_xaxes(range=[0, 1])\n",
    "fig.update_yaxes(range=[0, 1])\n",
    "fig"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) D² Brier score (fraction of Brier explained)\n",
    "\n",
    "The D² Brier score compares your model to a simple reference predictor:\n",
    "\n",
    "- Reference probability: the empirical base rate\n",
    "\n",
    "$$\n",
    "\\bar{y} = \\frac{1}{n}\\sum_{i=1}^n y_i.\n",
    "$$\n",
    "\n",
    "- Reference predictions: $p_i^{\\text{ref}} = \\bar{y}$ for all $i$\n",
    "\n",
    "The **reference Brier score** is the Brier score of this constant predictor:\n",
    "\n",
    "$$\n",
    "\\mathrm{BS}_{\\text{ref}} = \\frac{1}{n}\\sum_{i=1}^n (\\bar{y} - y_i)^2.\n",
    "$$\n",
    "\n",
    "For binary $y \\in \\{0,1\\}$, this simplifies to:\n",
    "\n",
    "$$\n",
    "\\mathrm{BS}_{\\text{ref}} = \\bar{y}(1-\\bar{y}).\n",
    "$$\n",
    "\n",
    "The **D² Brier score** is then:\n",
    "\n",
    "$$\n",
    "D^2_{\\text{Brier}} = 1 - \\frac{\\mathrm{BS}(y, p)}{\\mathrm{BS}_{\\text{ref}}}.\n",
    "$$\n",
    "\n",
    "**How to read it**\n",
    "\n",
    "- $D^2=1$: perfect probabilities (Brier score is 0)\n",
    "- $D^2=0$: no improvement over predicting the base rate\n",
    "- $D^2<0$: worse than the base-rate predictor\n",
    "\n",
    "**Edge case:** if all labels are the same, then $\\mathrm{BS}_{\\text{ref}} = 0$ and $D^2$ is undefined.\n",
    "A common convention (used by `sklearn.metrics.r2_score` with `force_finite=True`) is:\n",
    "\n",
    "- return 1.0 if your predictions are perfect\n",
    "- otherwise return 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Connection to $R^2$\n",
    "\n",
    "For binary targets, the D² Brier score is **exactly** the coefficient of determination computed on\n",
    "$(y, p)$:\n",
    "\n",
    "$$\n",
    "D^2_{\\text{Brier}}\n",
    "= 1 - \\frac{\\sum_i (y_i - p_i)^2}{\\sum_i (y_i - \\bar{y})^2}.\n",
    "$$\n",
    "\n",
    "That is the same algebraic form as $R^2$.\n",
    "\n",
    "This is useful as a sanity check:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import r2_score\n",
    "d2_brier = r2_score(y_true, y_prob)\n",
    "```\n",
    "\n",
    "scikit-learn exposes `brier_score_loss` but doesn't currently ship a `d2_brier_score` convenience function.\n",
    "You can compute it directly from Brier scores with the base-rate reference:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "p_ref = y_true.mean()\n",
    "d2_brier = 1 - brier_score_loss(y_true, y_prob) / brier_score_loss(\n",
    "    y_true,\n",
    "    np.full_like(y_true, p_ref, dtype=float),\n",
    ")\n",
    "```\n",
    "\n",
    "But conceptually, D² Brier is about **probabilistic classification** and is usually discussed\n",
    "together with calibration diagnostics (reliability diagrams).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def brier_score_loss_np(y_true, y_prob, sample_weight=None):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_prob = np.asarray(y_prob, dtype=float)\n",
    "\n",
    "    err2 = (y_prob - y_true) ** 2\n",
    "\n",
    "    if sample_weight is None:\n",
    "        return float(np.mean(err2))\n",
    "\n",
    "    w = np.asarray(sample_weight, dtype=float)\n",
    "    return float(np.average(err2, weights=w))\n",
    "\n",
    "\n",
    "def d2_brier_score_np(y_true, y_prob, sample_weight=None):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_prob = np.asarray(y_prob, dtype=float)\n",
    "\n",
    "    if sample_weight is None:\n",
    "        p_ref = float(np.mean(y_true))\n",
    "    else:\n",
    "        p_ref = float(np.average(y_true, weights=sample_weight))\n",
    "\n",
    "    y_ref = np.full_like(y_true, p_ref, dtype=float)\n",
    "\n",
    "    bs = brier_score_loss_np(y_true, y_prob, sample_weight=sample_weight)\n",
    "    bs_ref = brier_score_loss_np(y_true, y_ref, sample_weight=sample_weight)\n",
    "\n",
    "    if np.isclose(bs_ref, 0.0):\n",
    "        return 1.0 if np.isclose(bs, 0.0) else 0.0\n",
    "\n",
    "    return 1.0 - bs / bs_ref\n",
    "\n",
    "\n",
    "def plot_reliability_diagram(y_true, probas_by_name, n_bins=12, title=\"Reliability diagram\"):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0, 1],\n",
    "            y=[0, 1],\n",
    "            mode=\"lines\",\n",
    "            name=\"Perfect calibration\",\n",
    "            line=dict(dash=\"dash\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for name, p in probas_by_name.items():\n",
    "        prob_true, prob_pred = calibration_curve(\n",
    "            y_true, p, n_bins=n_bins, strategy=\"uniform\"\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=prob_pred,\n",
    "                y=prob_true,\n",
    "                mode=\"lines+markers\",\n",
    "                name=name,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Mean predicted probability\",\n",
    "        yaxis_title=\"Fraction of positives\",\n",
    "        legend_title=\"Model\",\n",
    "    )\n",
    "    fig.update_xaxes(range=[0, 1])\n",
    "    fig.update_yaxes(range=[0, 1], scaleanchor=\"x\", scaleratio=1)\n",
    "    return fig\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Quick sanity checks\n",
    "y = rng.integers(0, 2, size=2000)\n",
    "p = rng.random(size=y.shape[0])\n",
    "\n",
    "bs_np = brier_score_loss_np(y, p)\n",
    "bs_sklearn = brier_score_loss(y, p)\n",
    "\n",
    "d2_np = d2_brier_score_np(y, p)\n",
    "d2_r2 = r2_score(y, p)\n",
    "\n",
    "print(f\"Brier  (NumPy)  : {bs_np:.6f}\")\n",
    "print(f\"Brier  (sklearn): {bs_sklearn:.6f}\")\n",
    "print(f\"D² Brier (NumPy): {d2_np:.6f}\")\n",
    "print(f\"r2_score        : {d2_r2:.6f}\")\n",
    "\n",
    "assert np.allclose(bs_np, bs_sklearn)\n",
    "assert np.allclose(d2_np, d2_r2)\n",
    "\n",
    "# Baseline should give D² = 0\n",
    "p_base = np.full_like(y, y.mean(), dtype=float)\n",
    "assert np.allclose(d2_brier_score_np(y, p_base), 0.0)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Intuition: calibrated vs. miscalibrated probabilities\n",
    "\n",
    "We'll generate data from a known probability model so we can create different types of predictors:\n",
    "\n",
    "- **Oracle**: predicts the true probability (best possible Brier score)\n",
    "- **Underconfident**: probabilities are pushed toward 0.5\n",
    "- **Overconfident**: probabilities are pushed toward 0 or 1\n",
    "- **Baseline**: always predicts the base rate $\\bar{y}$\n",
    "\n",
    "Then we compare Brier and D² Brier and visualize calibration.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def sigmoid(z):\n",
    "    z = np.asarray(z)\n",
    "    out = np.empty_like(z, dtype=float)\n",
    "    pos = z >= 0\n",
    "    out[pos] = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    exp_z = np.exp(z[~pos])\n",
    "    out[~pos] = exp_z / (1.0 + exp_z)\n",
    "    return out\n",
    "\n",
    "\n",
    "n = 6000\n",
    "x = rng.normal(size=n)\n",
    "\n",
    "p_true = sigmoid(1.8 * x - 0.2)\n",
    "y = rng.binomial(1, p_true)\n",
    "\n",
    "logit_true = np.log(p_true / (1 - p_true))\n",
    "\n",
    "p_oracle = p_true\n",
    "p_under = sigmoid(0.5 * logit_true)\n",
    "p_over = sigmoid(2.0 * logit_true)\n",
    "p_base = np.full_like(y, y.mean(), dtype=float)\n",
    "\n",
    "models = {\n",
    "    \"baseline (̅y)\": p_base,\n",
    "    \"underconfident\": p_under,\n",
    "    \"oracle\": p_oracle,\n",
    "    \"overconfident\": p_over,\n",
    "}\n",
    "\n",
    "names = list(models.keys())\n",
    "briers = np.array([brier_score_loss_np(y, models[name]) for name in names])\n",
    "d2s = np.array([d2_brier_score_np(y, models[name]) for name in names])\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Brier score (lower is better)\", \"D² Brier score (higher is better)\"),\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Bar(x=names, y=briers), row=1, col=1)\n",
    "fig.add_trace(go.Bar(x=names, y=d2s), row=1, col=2)\n",
    "\n",
    "fig.update_layout(title=\"Same data, different probability quality\", showlegend=False)\n",
    "fig.update_yaxes(title_text=\"Brier\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"D²\", row=1, col=2)\n",
    "fig"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig = plot_reliability_diagram(\n",
    "    y_true=y,\n",
    "    probas_by_name=models,\n",
    "    title=\"Reliability diagram: calibration differences show up in Brier/D²\",\n",
    ")\n",
    "fig"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Per-example contributions (what drives the score?)\n",
    "\n",
    "The Brier score is an average of $(p_i - y_i)^2$.\n",
    "Looking at the worst individual contributions helps you see *why* a model is doing poorly.\n",
    "\n",
    "Below we visualize the biggest squared errors for the **overconfident** predictor.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "contrib = (p_over - y) ** 2\n",
    "idx = np.argsort(contrib)[::-1][:60]\n",
    "\n",
    "colors = np.where(y[idx] == 1, \"#d62728\", \"#1f77b4\")\n",
    "hover = [f\"p={p_over[i]:.3f}<br>y={int(y[i])}<br>(p-y)^2={contrib[i]:.3f}\" for i in idx]\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Bar(\n",
    "            x=np.arange(len(idx)),\n",
    "            y=contrib[idx],\n",
    "            marker_color=colors,\n",
    "            hovertext=hover,\n",
    "            hoverinfo=\"text\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Largest Brier contributions (overconfident predictor)\",\n",
    "    xaxis_title=\"Worst examples (rank)\",\n",
    "    yaxis_title=\"(p - y)^2\",\n",
    ")\n",
    "fig"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Using D² Brier for optimization (logistic regression)\n",
    "\n",
    "On a fixed dataset, the reference Brier score $\\mathrm{BS}_{\\text{ref}}$ depends only on $y$.\n",
    "So maximizing D² Brier is equivalent to minimizing the Brier score:\n",
    "\n",
    "$$\n",
    "D^2_{\\text{Brier}} = 1 - \\frac{\\mathrm{BS}(y,p)}{\\mathrm{BS}_{\\text{ref}}}\n",
    "\\quad \\Rightarrow \\quad\n",
    "\\arg\\max D^2_{\\text{Brier}} = \\arg\\min \\mathrm{BS}(y,p).\n",
    "$$\n",
    "\n",
    "We'll fit a simple logistic regression model:\n",
    "\n",
    "$$\n",
    "p(x) = \\sigma(w^T x),\n",
    "\\quad \\sigma(t) = \\frac{1}{1 + e^{-t}}.\n",
    "$$\n",
    "\n",
    "Using the Brier score as the objective:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(w) = \\frac{1}{n} \\sum_{i=1}^n (\\sigma(w^T x_i) - y_i)^2.\n",
    "$$\n",
    "\n",
    "The gradient is (vectorized):\n",
    "\n",
    "$$\n",
    "\\nabla_w \\mathcal{L}\n",
    "= \\frac{2}{n} X^T\\Big((p-y) \\odot p \\odot (1-p)\\Big)\n",
    "$$\n",
    "\n",
    "where $p = \\sigma(Xw)$ and $\\odot$ is elementwise multiplication.\n",
    "\n",
    "We'll also train the same model with **log loss** for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=3500,\n",
    "    n_features=2,\n",
    "    n_redundant=0,\n",
    "    n_informative=2,\n",
    "    n_clusters_per_class=1,\n",
    "    class_sep=1.2,\n",
    "    flip_y=0.03,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize for nicer optimization\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0) + 1e-12\n",
    "\n",
    "X_train = (X_train - mean) / std\n",
    "X_val = (X_val - mean) / std\n",
    "\n",
    "\n",
    "def add_intercept(X):\n",
    "    return np.c_[np.ones((X.shape[0], 1)), X]\n",
    "\n",
    "\n",
    "X_train_i = add_intercept(X_train)\n",
    "X_val_i = add_intercept(X_val)\n",
    "\n",
    "X_train_i.shape, X_val_i.shape\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def fit_logistic_gd(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    *,\n",
    "    loss=\"brier\",\n",
    "    lr=0.5,\n",
    "    n_epochs=800,\n",
    "    l2=0.0,\n",
    "    seed=0,\n",
    "):\n",
    "    rng_local = np.random.default_rng(seed)\n",
    "    w = rng_local.normal(scale=0.1, size=X_train.shape[1])\n",
    "\n",
    "    history = {\n",
    "        \"brier_train\": np.empty(n_epochs),\n",
    "        \"d2_train\": np.empty(n_epochs),\n",
    "        \"brier_val\": np.empty(n_epochs),\n",
    "        \"d2_val\": np.empty(n_epochs),\n",
    "    }\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # Forward\n",
    "        p_train = sigmoid(X_train @ w)\n",
    "        p_val = sigmoid(X_val @ w)\n",
    "\n",
    "        # Metrics\n",
    "        history[\"brier_train\"][epoch] = brier_score_loss_np(y_train, p_train)\n",
    "        history[\"d2_train\"][epoch] = d2_brier_score_np(y_train, p_train)\n",
    "        history[\"brier_val\"][epoch] = brier_score_loss_np(y_val, p_val)\n",
    "        history[\"d2_val\"][epoch] = d2_brier_score_np(y_val, p_val)\n",
    "\n",
    "        # Gradient\n",
    "        if loss == \"brier\":\n",
    "            grad = (2.0 / X_train.shape[0]) * X_train.T @ (\n",
    "                (p_train - y_train) * p_train * (1.0 - p_train)\n",
    "            )\n",
    "        elif loss == \"log\":\n",
    "            # Negative log-likelihood / cross-entropy\n",
    "            grad = (1.0 / X_train.shape[0]) * X_train.T @ (p_train - y_train)\n",
    "        else:\n",
    "            raise ValueError(\"loss must be 'brier' or 'log'\")\n",
    "\n",
    "        # L2 regularization (skip intercept)\n",
    "        if l2:\n",
    "            reg = np.r_[0.0, w[1:]]\n",
    "            grad = grad + l2 * reg\n",
    "\n",
    "        # Update\n",
    "        w = w - lr * grad\n",
    "\n",
    "    return w, history\n",
    "\n",
    "\n",
    "w_brier, hist_brier = fit_logistic_gd(\n",
    "    X_train_i,\n",
    "    y_train,\n",
    "    X_val_i,\n",
    "    y_val,\n",
    "    loss=\"brier\",\n",
    "    lr=0.8,\n",
    "    n_epochs=800,\n",
    "    l2=1e-3,\n",
    "    seed=1,\n",
    ")\n",
    "\n",
    "w_log, hist_log = fit_logistic_gd(\n",
    "    X_train_i,\n",
    "    y_train,\n",
    "    X_val_i,\n",
    "    y_val,\n",
    "    loss=\"log\",\n",
    "    lr=0.3,\n",
    "    n_epochs=800,\n",
    "    l2=1e-3,\n",
    "    seed=1,\n",
    ")\n",
    "\n",
    "w_brier, w_log\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "epochs = np.arange(len(hist_brier[\"brier_train\"]))\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Validation Brier score\", \"Validation D² Brier\"),\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=epochs, y=hist_brier[\"brier_val\"], mode=\"lines\", name=\"GD (Brier objective)\"),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=epochs, y=hist_log[\"brier_val\"], mode=\"lines\", name=\"GD (Log-loss objective)\"),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=epochs, y=hist_brier[\"d2_val\"], mode=\"lines\", name=\"GD (Brier objective)\"),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=epochs, y=hist_log[\"d2_val\"], mode=\"lines\", name=\"GD (Log-loss objective)\"),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_layout(title=\"Training dynamics (validation)\")\n",
    "fig.update_yaxes(title_text=\"Brier\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"D²\", row=1, col=2)\n",
    "fig"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "p_val_brier = sigmoid(X_val_i @ w_brier)\n",
    "p_val_log = sigmoid(X_val_i @ w_log)\n",
    "p_val_base = np.full_like(y_val, y_train.mean(), dtype=float)\n",
    "\n",
    "print(\"Validation metrics\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, p_val in {\n",
    "    \"baseline (train ̅y)\": p_val_base,\n",
    "    \"logistic GD (Brier objective)\": p_val_brier,\n",
    "    \"logistic GD (Log-loss objective)\": p_val_log,\n",
    "}.items():\n",
    "    bs = brier_score_loss_np(y_val, p_val)\n",
    "    d2 = d2_brier_score_np(y_val, p_val)\n",
    "    print(f\"{name:30s}  Brier={bs:.4f}  D²={d2:.4f}\")\n",
    "\n",
    "fig = plot_reliability_diagram(\n",
    "    y_true=y_val,\n",
    "    probas_by_name={\n",
    "        \"baseline\": p_val_base,\n",
    "        \"GD (Brier objective)\": p_val_brier,\n",
    "        \"GD (Log loss objective)\": p_val_log,\n",
    "    },\n",
    "    title=\"Calibration on validation set\",\n",
    ")\n",
    "fig"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Pros, cons, and where to use it\n",
    "\n",
    "**Pros**\n",
    "\n",
    "- Evaluates *probabilities* directly (not just class labels)\n",
    "- Sensitive to calibration (reliability) and accuracy\n",
    "- Proper scoring rule: incentivizes honest probabilities\n",
    "- D² gives a normalized scale: \"fraction of Brier explained\" relative to the base-rate predictor\n",
    "\n",
    "**Cons / pitfalls**\n",
    "\n",
    "- Needs well-defined probabilities; feeding hard labels (0/1) throws away information\n",
    "- If the dataset is extremely imbalanced, $\\bar{y}(1-\\bar{y})$ can be very small → D² can become unstable\n",
    "- If all labels are identical, the score is undefined (denominator 0)\n",
    "- As a training objective with a sigmoid model, Brier loss has an extra $p(1-p)$ factor in the gradient\n",
    "  (can lead to smaller gradients when $p$ saturates near 0/1 compared to log loss)\n",
    "\n",
    "**Good use cases**\n",
    "\n",
    "- Risk prediction / decision support where probability calibration matters (medicine, finance, fraud)\n",
    "- Comparing probabilistic models against a simple baseline\n",
    "- Monitoring probabilistic models over time (drift can show up as calibration degradation)\n",
    "\n",
    "**Diagnostics to pair with it**\n",
    "\n",
    "- Reliability diagram (calibration curve)\n",
    "- Histogram of predicted probabilities (do you predict only around 0.5?)\n",
    "- If you also care about ranking/discrimination, add AUC/PR-AUC alongside Brier/D²\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Exercises\n",
    "\n",
    "1. Create a model that ranks perfectly but is badly calibrated (e.g. apply an aggressive temperature to logits).\n",
    "   What happens to AUC vs. Brier/D²?\n",
    "2. Implement sample weights and verify that your weighted D² matches `sklearn.metrics.r2_score(..., sample_weight=...)`.\n",
    "3. Try Platt scaling or isotonic regression to calibrate a model; measure the change in Brier and D².\n",
    "\n",
    "## References\n",
    "\n",
    "- Brier score (Wikipedia): https://en.wikipedia.org/wiki/Brier_score\n",
    "- scikit-learn `brier_score_loss`: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html\n",
    "- scikit-learn `r2_score`: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}