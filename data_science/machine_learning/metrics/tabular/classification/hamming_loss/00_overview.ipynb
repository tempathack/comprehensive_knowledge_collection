{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hamming_loss (bitwise error rate for multilabel classification)\n",
    "\n",
    "`hamming_loss` measures the fraction of labels that are **wrong**.\n",
    "\n",
    "- For standard (single-label) classification it reduces to the **misclassification rate**.\n",
    "- For multilabel classification it averages mistakes across the `(sample, label)` grid — *how many bits did we flip?*\n",
    "\n",
    "## Learning goals\n",
    "- write the multiclass and multilabel formulas (with clear notation)\n",
    "- build intuition with plots (what counts as an error)\n",
    "- implement Hamming loss from scratch in NumPy (including `sample_weight`)\n",
    "- see how Hamming loss interacts with probability thresholds in multilabel logistic regression\n",
    "- know pros/cons and when to prefer other metrics\n",
    "\n",
    "## Quick import\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import hamming_loss\n",
    "```\n",
    "\n",
    "## Table of contents\n",
    "1. Definitions and notation\n",
    "2. Intuition (plots)\n",
    "3. NumPy implementation + sanity checks\n",
    "4. Using Hamming loss for threshold tuning (multilabel logistic regression)\n",
    "5. Pros, cons, pitfalls\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.metrics import hamming_loss as sk_hamming_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pio.templates.default = 'plotly_white'\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(precision=3, suppress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Definitions and notation\n",
    "\n",
    "Assume we have $n$ samples.\n",
    "\n",
    "### Single-label classification (binary or multiclass)\n",
    "\n",
    "- True label: $y_i \\in \\{0,1,\\dots,K-1\\}$\n",
    "- Predicted label: $\\hat{y}_i \\in \\{0,1,\\dots,K-1\\}$\n",
    "\n",
    "The Hamming loss is the average number of **wrong labels** per sample:\n",
    "\n",
    "$$\n",
    "\\operatorname{HL}(y,\\hat{y}) = \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}[y_i \\neq \\hat{y}_i]\n",
    "$$\n",
    "\n",
    "For single-label classification this is exactly the **misclassification rate** (a.k.a. `zero_one_loss`).\n",
    "\n",
    "### Multilabel classification (label indicator matrix)\n",
    "\n",
    "- True labels: $Y \\in \\{0,1\\}^{n\\times L}$ (each row can have multiple 1s)\n",
    "- Predictions: $\\hat{Y} \\in \\{0,1\\}^{n\\times L}$\n",
    "\n",
    "Hamming loss counts mismatches over all `(sample, label)` decisions:\n",
    "\n",
    "$$\n",
    "\\operatorname{HL}(Y,\\hat{Y})\n",
    "= \\frac{1}{nL}\\sum_{i=1}^n\\sum_{\\ell=1}^L \\mathbf{1}[Y_{i\\ell} \\neq \\hat{Y}_{i\\ell}]\n",
    "$$\n",
    "\n",
    "Equivalently, it is the average **Hamming distance per sample**, normalized by $L$.\n",
    "\n",
    "### Relationship to micro-accuracy\n",
    "\n",
    "If you treat each `(sample, label)` as a binary decision, then:\n",
    "\n",
    "$$\n",
    "\\text{micro-accuracy} = \\frac{TP + TN}{nL}\n",
    "\\quad\\Rightarrow\\quad\n",
    "\\operatorname{HL} = 1 - \\text{micro-accuracy}\n",
    "$$\n",
    "\n",
    "### Contrast with subset accuracy (exact match)\n",
    "\n",
    "Subset accuracy (a.k.a. *exact match ratio*) for multilabel requires getting **all labels** correct for a sample:\n",
    "\n",
    "$$\n",
    "\\text{subset-accuracy}(Y,\\hat{Y}) = \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}[Y_{i,:} = \\hat{Y}_{i,:}]\n",
    "$$\n",
    "\n",
    "Hamming loss is more forgiving: getting 1 label wrong out of 20 is a small penalty, while subset accuracy would count the whole sample as wrong.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Intuition (plots)\n",
    "\n",
    "Think of each label decision as a **bit**.\n",
    "\n",
    "- `0` means perfect predictions.\n",
    "- `0.25` means 25% of all bits are wrong.\n",
    "\n",
    "Below we visualize `Y_true`, `Y_pred`, and the mismatch matrix `(Y_true != Y_pred)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_true = np.array(\n",
    "    [\n",
    "        [1, 0, 0, 1, 0, 1],\n",
    "        [0, 1, 0, 0, 0, 0],\n",
    "        [1, 1, 0, 0, 1, 0],\n",
    "        [0, 0, 0, 1, 0, 0],\n",
    "        [1, 0, 1, 1, 0, 0],\n",
    "        [0, 1, 0, 0, 1, 1],\n",
    "        [0, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 0, 0, 0],\n",
    "    ],\n",
    "    dtype=int,\n",
    ")\n",
    "\n",
    "Y_pred = np.array(\n",
    "    [\n",
    "        [1, 0, 1, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0],\n",
    "        [1, 0, 0, 0, 1, 0],\n",
    "        [0, 0, 0, 1, 1, 0],\n",
    "        [1, 0, 0, 1, 0, 0],\n",
    "        [0, 1, 0, 1, 0, 1],\n",
    "        [0, 0, 0, 0, 0, 0],\n",
    "        [1, 0, 1, 0, 0, 0],\n",
    "    ],\n",
    "    dtype=int,\n",
    ")\n",
    "\n",
    "mismatch = (Y_true != Y_pred).astype(int)\n",
    "\n",
    "hl_manual = float(mismatch.mean())\n",
    "hl_sklearn = float(sk_hamming_loss(Y_true, Y_pred))\n",
    "\n",
    "subset_acc = float(np.mean(np.all(Y_true == Y_pred, axis=1)))\n",
    "\n",
    "print(f'Hamming loss (manual) : {hl_manual:.3f}')\n",
    "print(f'Hamming loss (sklearn): {hl_sklearn:.3f}')\n",
    "print(f'Subset accuracy       : {subset_acc:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_samples, n_labels = Y_true.shape\n",
    "x_labels = [f'label_{j}' for j in range(n_labels)]\n",
    "y_labels = [f'sample_{i}' for i in range(n_samples)]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=3,\n",
    "    subplot_titles=['Y_true', 'Y_pred', 'Mismatch (1 = wrong)'],\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=Y_true,\n",
    "        x=x_labels,\n",
    "        y=y_labels,\n",
    "        colorscale='Blues',\n",
    "        zmin=0,\n",
    "        zmax=1,\n",
    "        showscale=False,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=Y_pred,\n",
    "        x=x_labels,\n",
    "        y=y_labels,\n",
    "        colorscale='Greens',\n",
    "        zmin=0,\n",
    "        zmax=1,\n",
    "        showscale=False,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=mismatch,\n",
    "        x=x_labels,\n",
    "        y=y_labels,\n",
    "        colorscale=[[0, '#ffffff'], [1, '#d62728']],\n",
    "        zmin=0,\n",
    "        zmax=1,\n",
    "        showscale=False,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=3,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Hamming loss = {hl_manual:.3f} (fraction of wrong bits)',\n",
    "    height=420,\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "per_sample = mismatch.mean(axis=1)\n",
    "per_label = mismatch.mean(axis=0)\n",
    "\n",
    "fig1 = px.bar(\n",
    "    x=[f'sample_{i}' for i in range(n_samples)],\n",
    "    y=per_sample,\n",
    "    title='Per-sample contribution: fraction of wrong labels',\n",
    "    labels={'x': 'sample', 'y': 'wrong-label fraction'},\n",
    ")\n",
    "fig1.add_hline(y=hl_manual, line_dash='dash', annotation_text='global HL')\n",
    "fig1.update_yaxes(range=[0, 1])\n",
    "fig1.show()\n",
    "\n",
    "fig2 = px.bar(\n",
    "    x=x_labels,\n",
    "    y=per_label,\n",
    "    title='Per-label error rate',\n",
    "    labels={'x': 'label', 'y': 'error rate'},\n",
    ")\n",
    "fig2.add_hline(y=hl_manual, line_dash='dash', annotation_text='global HL')\n",
    "fig2.update_yaxes(range=[0, 1])\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A common pitfall: multiclass as one-hot vs integer labels\n",
    "\n",
    "For multiclass problems you often have **one true class** per sample.\n",
    "\n",
    "- If you pass integer labels (`shape = (n,)`), Hamming loss is the misclassification rate.\n",
    "- If you convert to one-hot (`shape = (n, K)`), a single wrong prediction creates **two bit errors** (one FN + one FP), so the value changes.\n",
    "\n",
    "Below we compare the two representations.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_true_mc = np.array([0, 1, 2, 2, 1, 0])\n",
    "y_pred_mc = np.array([0, 2, 2, 1, 1, 0])\n",
    "\n",
    "hl_int = float(sk_hamming_loss(y_true_mc, y_pred_mc))\n",
    "\n",
    "K = 3\n",
    "Y_true_oh = np.eye(K, dtype=int)[y_true_mc]\n",
    "Y_pred_oh = np.eye(K, dtype=int)[y_pred_mc]\n",
    "\n",
    "hl_onehot = float(sk_hamming_loss(Y_true_oh, Y_pred_oh))\n",
    "\n",
    "print(f'Hamming loss with integer labels: {hl_int:.3f}')\n",
    "print(f'Hamming loss with one-hot labels: {hl_onehot:.3f}  (note the scaling)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) NumPy implementation + sanity checks\n",
    "\n",
    "A from-scratch implementation is straightforward once you remember the definition: **count mismatches and average**.\n",
    "\n",
    "`sample_weight` in `sklearn.metrics.hamming_loss` applies at the **sample** level:\n",
    "\n",
    "- compute per-sample Hamming loss (mean mismatches across labels)\n",
    "- take a weighted average across samples\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def hamming_loss_np(y_true, y_pred, *, sample_weight=None) -> float:\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f'shape mismatch: y_true {y_true.shape} vs y_pred {y_pred.shape}')\n",
    "\n",
    "    if y_true.ndim == 1:\n",
    "        mismatches = (y_true != y_pred).astype(float)\n",
    "        if sample_weight is None:\n",
    "            return float(mismatches.mean())\n",
    "\n",
    "        w = np.asarray(sample_weight, dtype=float)\n",
    "        if w.shape != (y_true.shape[0],):\n",
    "            raise ValueError(f'sample_weight must have shape {(y_true.shape[0],)}, got {w.shape}')\n",
    "        return float(np.average(mismatches, weights=w))\n",
    "\n",
    "    if y_true.ndim == 2:\n",
    "        mismatches = (y_true != y_pred).astype(float)\n",
    "        per_sample = mismatches.mean(axis=1)\n",
    "\n",
    "        if sample_weight is None:\n",
    "            return float(per_sample.mean())\n",
    "\n",
    "        w = np.asarray(sample_weight, dtype=float)\n",
    "        if w.shape != (y_true.shape[0],):\n",
    "            raise ValueError(f'sample_weight must have shape {(y_true.shape[0],)}, got {w.shape}')\n",
    "        return float(np.average(per_sample, weights=w))\n",
    "\n",
    "    raise ValueError('y_true and y_pred must be 1D (single-label) or 2D (multilabel)')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sanity checks vs scikit-learn\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "# 1) single-label (multiclass)\n",
    "y_true_1d = rng.integers(0, 4, size=200)\n",
    "y_pred_1d = rng.integers(0, 4, size=200)\n",
    "\n",
    "print(\n",
    "    '1D close?',\n",
    "    np.allclose(\n",
    "        hamming_loss_np(y_true_1d, y_pred_1d),\n",
    "        sk_hamming_loss(y_true_1d, y_pred_1d),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 2) multilabel indicator\n",
    "Y_true_2d = rng.integers(0, 2, size=(120, 7))\n",
    "Y_pred_2d = rng.integers(0, 2, size=(120, 7))\n",
    "\n",
    "print(\n",
    "    '2D close?',\n",
    "    np.allclose(\n",
    "        hamming_loss_np(Y_true_2d, Y_pred_2d),\n",
    "        sk_hamming_loss(Y_true_2d, Y_pred_2d),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 3) sample weights\n",
    "w = rng.random(size=Y_true_2d.shape[0])\n",
    "\n",
    "hl_np_w = hamming_loss_np(Y_true_2d, Y_pred_2d, sample_weight=w)\n",
    "hl_sk_w = float(sk_hamming_loss(Y_true_2d, Y_pred_2d, sample_weight=w))\n",
    "\n",
    "print('weighted close?', np.allclose(hl_np_w, hl_sk_w))\n",
    "print('weighted value:', hl_np_w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Using Hamming loss for threshold tuning (multilabel logistic regression)\n",
    "\n",
    "Hamming loss is defined on **hard predictions** (`0/1`), so it is **not differentiable**.\n",
    "\n",
    "A common pattern is:\n",
    "\n",
    "1. Train a probabilistic model (e.g. multilabel logistic regression) by minimizing a differentiable surrogate (binary cross-entropy / `log_loss`).\n",
    "2. Convert probabilities to hard labels with a threshold $t$.\n",
    "3. Choose $t$ (or per-label thresholds) to minimize Hamming loss on a validation set.\n",
    "\n",
    "### Model\n",
    "\n",
    "For $L$ labels, we use independent sigmoids:\n",
    "\n",
    "$$\n",
    "Z = XW + b,\\quad P = \\sigma(Z)\n",
    "$$\n",
    "\n",
    "Prediction with a threshold $t$:\n",
    "\n",
    "$$\n",
    "\\hat{Y}_{i\\ell} = \\mathbf{1}[P_{i\\ell} \\ge t]\n",
    "$$\n",
    "\n",
    "We will train with average binary cross-entropy (from logits):\n",
    "\n",
    "$$\n",
    "J(W,b) = \\frac{1}{nL}\\sum_{i=1}^n\\sum_{\\ell=1}^L \\Big(\\operatorname{softplus}(Z_{i\\ell}) - Y_{i\\ell} Z_{i\\ell}\\Big)\n",
    "$$\n",
    "\n",
    "Then we will *tune* $t$ to minimize Hamming loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=float)\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "\n",
    "def softplus(z):\n",
    "    # Stable softplus: log(1 + exp(z))\n",
    "    z = np.asarray(z, dtype=float)\n",
    "    return np.log1p(np.exp(-np.abs(z))) + np.maximum(z, 0.0)\n",
    "\n",
    "\n",
    "def bce_from_logits(Y, Z) -> float:\n",
    "    Y = np.asarray(Y, dtype=float)\n",
    "    Z = np.asarray(Z, dtype=float)\n",
    "    return float(np.mean(softplus(Z) - Y * Z))\n",
    "\n",
    "\n",
    "def standardize_fit_transform(X):\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    mean = X.mean(axis=0)\n",
    "    std = X.std(axis=0)\n",
    "    std = np.where(std == 0, 1.0, std)\n",
    "    return (X - mean) / std, mean, std\n",
    "\n",
    "\n",
    "def standardize_transform(X, mean, std):\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    std = np.where(std == 0, 1.0, std)\n",
    "    return (X - mean) / std\n",
    "\n",
    "\n",
    "def fit_multilabel_logreg_gd(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    X_val=None,\n",
    "    Y_val=None,\n",
    "    *,\n",
    "    lr=0.8,\n",
    "    n_steps=400,\n",
    "    l2=0.0,\n",
    "    threshold=0.5,\n",
    "):\n",
    "    X_train = np.asarray(X_train, dtype=float)\n",
    "    Y_train = np.asarray(Y_train, dtype=float)\n",
    "    n_samples, n_features = X_train.shape\n",
    "    n_labels = Y_train.shape[1]\n",
    "\n",
    "    W = np.zeros((n_features, n_labels))\n",
    "    b = np.zeros(n_labels)\n",
    "\n",
    "    history = {\n",
    "        'step': [],\n",
    "        'train_bce': [],\n",
    "        'train_hl': [],\n",
    "        'val_bce': [],\n",
    "        'val_hl': [],\n",
    "    }\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        Z = X_train @ W + b\n",
    "        P = sigmoid(Z)\n",
    "\n",
    "        train_bce = bce_from_logits(Y_train, Z)\n",
    "\n",
    "        # dJ/dZ = (P - Y) / (n_samples * n_labels) when J is the mean over all entries\n",
    "        G = (P - Y_train) / (n_samples * n_labels)\n",
    "        grad_W = X_train.T @ G + l2 * W\n",
    "        grad_b = G.sum(axis=0)\n",
    "\n",
    "        W -= lr * grad_W\n",
    "        b -= lr * grad_b\n",
    "\n",
    "        Y_hat = (P >= threshold).astype(int)\n",
    "        train_hl = hamming_loss_np(Y_train.astype(int), Y_hat)\n",
    "\n",
    "        history['step'].append(step)\n",
    "        history['train_bce'].append(train_bce)\n",
    "        history['train_hl'].append(train_hl)\n",
    "\n",
    "        if X_val is not None and Y_val is not None:\n",
    "            Z_val = X_val @ W + b\n",
    "            P_val = sigmoid(Z_val)\n",
    "            val_bce = bce_from_logits(Y_val, Z_val)\n",
    "            val_hl = hamming_loss_np(Y_val.astype(int), (P_val >= threshold).astype(int))\n",
    "\n",
    "            history['val_bce'].append(val_bce)\n",
    "            history['val_hl'].append(val_hl)\n",
    "        else:\n",
    "            history['val_bce'].append(None)\n",
    "            history['val_hl'].append(None)\n",
    "\n",
    "    return W, b, history\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Synthetic multilabel dataset\n",
    "rng = np.random.default_rng(1)\n",
    "\n",
    "n_samples = 1600\n",
    "n_features = 8\n",
    "n_labels = 6\n",
    "\n",
    "X = rng.normal(size=(n_samples, n_features))\n",
    "\n",
    "W_true = rng.normal(scale=1.2, size=(n_features, n_labels))\n",
    "# Make some labels rarer than others by shifting biases\n",
    "b_true = np.linspace(-2.0, 0.5, n_labels)\n",
    "\n",
    "Z_true = X @ W_true + b_true\n",
    "P_true = sigmoid(Z_true)\n",
    "Y = (rng.random(size=P_true.shape) < P_true).astype(int)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=0.3,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "X_train_s, mean, std = standardize_fit_transform(X_train)\n",
    "X_val_s = standardize_transform(X_val, mean, std)\n",
    "\n",
    "W, b, hist = fit_multilabel_logreg_gd(\n",
    "    X_train_s,\n",
    "    Y_train,\n",
    "    X_val=X_val_s,\n",
    "    Y_val=Y_val,\n",
    "    lr=0.9,\n",
    "    n_steps=300,\n",
    "    l2=0.0,\n",
    "    threshold=0.5,\n",
    ")\n",
    "\n",
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "fig.add_trace(go.Scatter(x=hist['step'], y=hist['train_bce'], name='train BCE'), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=hist['step'], y=hist['val_bce'], name='val BCE'), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=hist['step'], y=hist['train_hl'], name='train Hamming loss'), secondary_y=True)\n",
    "fig.add_trace(go.Scatter(x=hist['step'], y=hist['val_hl'], name='val Hamming loss'), secondary_y=True)\n",
    "\n",
    "fig.update_xaxes(title_text='gradient descent step')\n",
    "fig.update_yaxes(title_text='binary cross-entropy (lower is better)', secondary_y=False)\n",
    "fig.update_yaxes(title_text='Hamming loss (lower is better)', secondary_y=True, range=[0, 1])\n",
    "fig.update_layout(title='Train with BCE, monitor Hamming loss at threshold=0.5', height=480)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Tune the probability threshold to minimize validation Hamming loss\n",
    "Z_val = X_val_s @ W + b\n",
    "P_val = sigmoid(Z_val)\n",
    "\n",
    "thresholds = np.linspace(0.05, 0.95, 91)\n",
    "hl_vals = []\n",
    "for t in thresholds:\n",
    "    Y_hat_val = (P_val >= t).astype(int)\n",
    "    hl_vals.append(hamming_loss_np(Y_val, Y_hat_val))\n",
    "\n",
    "hl_vals = np.array(hl_vals)\n",
    "best_idx = int(np.argmin(hl_vals))\n",
    "best_t = float(thresholds[best_idx])\n",
    "\n",
    "t05_idx = int(np.where(np.isclose(thresholds, 0.5))[0][0])\n",
    "hl_at_05 = float(hl_vals[t05_idx])\n",
    "hl_best = float(hl_vals[best_idx])\n",
    "\n",
    "print(f'Validation HL at t=0.50: {hl_at_05:.4f}')\n",
    "print(f'Best threshold t*:      {best_t:.2f}')\n",
    "print(f'Validation HL at t*:    {hl_best:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    x=thresholds,\n",
    "    y=hl_vals,\n",
    "    title='Validation Hamming loss vs threshold',\n",
    "    labels={'x': 'threshold t', 'y': 'Hamming loss'},\n",
    ")\n",
    "fig.add_vline(x=0.5, line_dash='dash', line_color='gray', annotation_text='t=0.5')\n",
    "fig.add_vline(x=best_t, line_dash='dash', line_color='green', annotation_text='best t*')\n",
    "fig.update_yaxes(range=[0, 1])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optional: per-label threshold tuning (can reduce HL when base rates differ)\n",
    "per_label_thresholds = np.zeros(n_labels)\n",
    "\n",
    "for j in range(n_labels):\n",
    "    errs = []\n",
    "    for t in thresholds:\n",
    "        pred_j = (P_val[:, j] >= t).astype(int)\n",
    "        errs.append(float(np.mean(pred_j != Y_val[:, j])))\n",
    "    per_label_thresholds[j] = thresholds[int(np.argmin(errs))]\n",
    "\n",
    "Y_hat_per_label = (P_val >= per_label_thresholds).astype(int)\n",
    "hl_per_label = hamming_loss_np(Y_val, Y_hat_per_label)\n",
    "\n",
    "print('Per-label thresholds:', np.round(per_label_thresholds, 2))\n",
    "print('Validation HL (single t*) :', hl_best)\n",
    "print('Validation HL (per-label) :', hl_per_label)\n",
    "\n",
    "fig = px.bar(\n",
    "    x=[f'label_{j}' for j in range(n_labels)],\n",
    "    y=per_label_thresholds,\n",
    "    title='Per-label thresholds that minimize per-label error',\n",
    "    labels={'x': 'label', 'y': 'best threshold'},\n",
    ")\n",
    "fig.update_yaxes(range=[0, 1])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Pros, cons, pitfalls\n",
    "\n",
    "### Pros\n",
    "- **Simple and interpretable**: “fraction of wrong labels.”\n",
    "- **Works naturally for multilabel**: does not require perfect set matches.\n",
    "- **Label-wise averaging**: each label decision contributes equally (micro view over all bits).\n",
    "- **Comparable across models** when the label space is fixed (same $L$).\n",
    "\n",
    "### Cons / caveats\n",
    "- **Can look deceptively good on sparse multilabel problems**: if most labels are 0, predicting all zeros yields many true negatives and a low Hamming loss.\n",
    "- **Does not capture set quality**: predicting a wrong combination can still have a small Hamming loss if only a few bits differ.\n",
    "- **Not differentiable**: not suitable as a direct gradient-based training objective; use a surrogate loss and treat Hamming loss as an evaluation metric.\n",
    "- **Representation matters for multiclass**: integer labels vs one-hot produce different scales.\n",
    "\n",
    "### Common pitfalls\n",
    "- Passing **probabilities** instead of hard labels (threshold them first).\n",
    "- Using one-hot for multiclass and interpreting the value as misclassification rate.\n",
    "- Relying on Hamming loss alone with heavy class imbalance; complement with per-label precision/recall/F1, Jaccard score, or subset accuracy.\n",
    "\n",
    "### Where it’s a good fit\n",
    "- Multilabel tagging where each label decision matters roughly equally (e.g. topic tags, attribute prediction).\n",
    "- Problems where you want a single number that reflects “average per-label error rate,” not strict exact matches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "- Show algebraically that for multilabel indicators, `Hamming loss = 1 - micro-accuracy`.\n",
    "- Construct a sparse multilabel dataset where predicting all zeros achieves a low Hamming loss but terrible recall.\n",
    "- Implement a per-label F1 score and compare its behavior to Hamming loss under imbalance.\n",
    "\n",
    "## References\n",
    "- scikit-learn docs: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hamming_loss.html\n",
    "- Hamming distance (background): https://en.wikipedia.org/wiki/Hamming_distance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}