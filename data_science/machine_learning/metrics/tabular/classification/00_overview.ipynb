{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification Metrics (Tabular)\n",
        "\n",
        "A structured place to collect `sklearn.metrics` notebooks for tabular ML tasks.\n",
        "\n",
        "## Metrics\n",
        "\n",
        "- `accuracy_score`: Accuracy classification score.\n",
        "- `auc`: Compute Area Under the Curve (AUC) using the trapezoidal rule.\n",
        "- `average_precision_score`: Compute average precision (AP) from prediction scores.\n",
        "- `balanced_accuracy_score`: Compute the balanced accuracy.\n",
        "- `brier_score_loss`: Compute the Brier score loss.\n",
        "- `class_likelihood_ratios`: Compute binary classification positive and negative likelihood ratios.\n",
        "- `classification_report`: Build a text report showing the main classification metrics.\n",
        "- `cohen_kappa_score`: Compute Cohen's kappa: a statistic that measures inter-annotator agreement.\n",
        "- `confusion_matrix`: Compute confusion matrix to evaluate the accuracy of a classification.\n",
        "- `confusion_matrix_at_thresholds`: Calculate binary confusion matrix terms per classification threshold.\n",
        "- `d2_brier_score`: Score function: fraction of Brier score explained.\n",
        "- `d2_log_loss_score`: Score function: fraction of log loss explained.\n",
        "- `dcg_score`: Compute Discounted Cumulative Gain.\n",
        "- `det_curve`: Compute Detection Error Tradeoff (DET) for different probability thresholds.\n",
        "- `f1_score`: Compute the F1 score, also known as balanced F-score or F-measure.\n",
        "- `fbeta_score`: Compute the F-beta score.\n",
        "- `hamming_loss`: Compute the average Hamming loss.\n",
        "- `hinge_loss`: Average hinge loss (non-regularized).\n",
        "- `jaccard_score`: Jaccard similarity coefficient score.\n",
        "- `log_loss`: Log loss, aka logistic loss or cross-entropy loss.\n",
        "- `matthews_corrcoef`: Compute the Matthews correlation coefficient (MCC).\n",
        "- `multilabel_confusion_matrix`: Compute a confusion matrix for each class or sample.\n",
        "- `ndcg_score`: Compute Normalized Discounted Cumulative Gain.\n",
        "- `precision_recall_curve`: Compute precision-recall pairs for different probability thresholds.\n",
        "- `precision_recall_fscore_support`: Compute precision, recall, F-measure and support for each class.\n",
        "- `precision_score`: Compute the precision.\n",
        "- `recall_score`: Compute the recall.\n",
        "- `roc_auc_score`: Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.\n",
        "- `roc_curve`: Compute Receiver operating characteristic (ROC).\n",
        "- `top_k_accuracy_score`: Top-k Accuracy classification score.\n",
        "- `zero_one_loss`: Zero-one classification loss.\n",
        "\n",
        "## Multilabel ranking metrics\n",
        "\n",
        "- `coverage_error`: Coverage error measure.\n",
        "- `label_ranking_average_precision_score`: Compute ranking-based average precision.\n",
        "- `label_ranking_loss`: Compute Ranking loss measure.\n",
        "\n",
        "## References\n",
        "\n",
        "- User guide: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "- API: https://scikit-learn.org/stable/api/sklearn.metrics.html\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
