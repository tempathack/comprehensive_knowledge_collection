{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# median_absolute_error (MedAE)\n",
    "\n",
    "Median Absolute Error (MedAE) is a **regression** metric that summarizes the *typical* absolute prediction error by taking the **median** of absolute residuals.\n",
    "\n",
    "Compared to MAE (mean absolute error), MedAE is much more **robust to outliers**: as long as fewer than 50% of samples are extreme, the median barely moves.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "- Define MedAE precisely (math + units)\n",
    "- Build intuition with Plotly visuals (median vs mean, outliers)\n",
    "- Implement MedAE from scratch in NumPy (including multi-output)\n",
    "- Use MedAE as an optimization objective for a simple model (derivative-free search)\n",
    "- Know pros/cons and when to use it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, median_absolute_error\n",
    "\n",
    "pio.templates.default = 'plotly_white'\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Definition\n",
    "\n",
    "Let $y \\in \\mathbb{R}^n$ be targets and $\\hat{y} \\in \\mathbb{R}^n$ predictions.\n",
    "\n",
    "Define absolute errors:\n",
    "\n",
    "$$\n",
    "a_i = |y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "Then the median absolute error is:\n",
    "\n",
    "$$\n",
    "\\mathrm{MedAE}(y, \\hat{y}) = \\operatorname{median}(a_1, \\dots, a_n)\n",
    "= \\operatorname{median}_{i=1,\\dots,n}\\; |y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "If we sort the absolute errors $a_{(1)} \\le \\dots \\le a_{(n)}$:\n",
    "\n",
    "- if $n$ is odd, $\\operatorname{median}(a)=a_{((n+1)/2)}$\n",
    "- if $n$ is even, $\\operatorname{median}(a)=\\frac{a_{(n/2)} + a_{(n/2+1)}}{2}$  (NumPy / scikit-learn convention)\n",
    "\n",
    "In quantile notation:\n",
    "\n",
    "$$\n",
    "\\mathrm{MedAE} = Q_{0.5}(|y-\\hat{y}|)\n",
    "$$\n",
    "\n",
    "### Multi-output targets\n",
    "\n",
    "If $y \\in \\mathbb{R}^{n \\times m}$ (m outputs), compute MedAE per output:\n",
    "\n",
    "$$\n",
    "\\mathrm{MedAE}_j = \\operatorname{median}_{i=1,\\dots,n} |y_{ij}-\\hat{y}_{ij}|\n",
    "$$\n",
    "\n",
    "and then aggregate across outputs (uniform average or custom weights).\n",
    "\n",
    "### Units\n",
    "\n",
    "MedAE has the **same units** as the target $y$ (e.g. dollars, °C).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tiny example with an extreme outlier\n",
    "y_true = np.array([2.0, 0.0, 4.0, 1.0, 100.0])\n",
    "y_pred = np.array([1.5, 0.2, 3.0, 2.0, 0.0])\n",
    "\n",
    "abs_errors = np.abs(y_true - y_pred)\n",
    "\n",
    "medae_np = float(np.median(abs_errors))\n",
    "medae_sklearn = median_absolute_error(y_true, y_pred)\n",
    "\n",
    "print('y_true     =', y_true)\n",
    "print('y_pred     =', y_pred)\n",
    "print('|error|    =', abs_errors)\n",
    "print('MedAE (NumPy)   =', medae_np)\n",
    "print('MedAE (sklearn) =', medae_sklearn)\n",
    "print('MAE  (compare)  =', mean_absolute_error(y_true, y_pred))\n",
    "print('RMSE (compare)  =', np.sqrt(mean_squared_error(y_true, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(y_true))\n",
    "mean_abs = float(np.mean(abs_errors))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=idx, y=abs_errors, name='|y - ŷ|'))\n",
    "fig.add_hline(\n",
    "    y=medae_np,\n",
    "    line_dash='dash',\n",
    "    line_color='black',\n",
    "    annotation_text=f'median={medae_np:.2f}',\n",
    ")\n",
    "fig.add_hline(\n",
    "    y=mean_abs,\n",
    "    line_dash='dot',\n",
    "    line_color='crimson',\n",
    "    annotation_text=f'mean={mean_abs:.2f}',\n",
    ")\n",
    "fig.update_layout(\n",
    "    title='Absolute errors: median vs mean',\n",
    "    xaxis_title='sample index',\n",
    "    yaxis_title='|error|',\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Intuition: “typical” error (the 50th percentile)\n",
    "\n",
    "MedAE does **not** average errors. It asks:\n",
    "\n",
    "> “What is the error magnitude that **half** of my predictions beat?”\n",
    "\n",
    "Equivalently, MedAE is the **50th percentile** (median) of the absolute-error distribution.\n",
    "\n",
    "- If a few predictions are catastrophically wrong, they usually land in the *upper tail* of $|\\mathrm{error}|$.\n",
    "- The median ignores that tail unless it becomes more than half the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 400\n",
    "y_true = rng.normal(0, 1, size=n)\n",
    "y_pred = y_true + rng.normal(0, 0.4, size=n)\n",
    "\n",
    "# Inject a few extreme misses\n",
    "out_idx = rng.choice(n, size=8, replace=False)\n",
    "y_pred[out_idx] += rng.normal(0, 10.0, size=out_idx.size)\n",
    "\n",
    "abs_errors = np.abs(y_true - y_pred)\n",
    "med = float(np.median(abs_errors))\n",
    "mean_ = float(np.mean(abs_errors))\n",
    "\n",
    "fig = px.histogram(abs_errors, nbins=40, title='Distribution of |error|')\n",
    "fig.add_vline(x=med, line_dash='dash', line_color='black', annotation_text=f'median={med:.2f}')\n",
    "fig.add_vline(x=mean_, line_dash='dot', line_color='crimson', annotation_text=f'mean={mean_:.2f}')\n",
    "fig.update_layout(xaxis_title='|error|', yaxis_title='count')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Outliers: why MedAE is robust\n",
    "\n",
    "Because the median has a **50% breakdown point**, MedAE can tolerate large outliers as long as they affect **< 50%** of samples:\n",
    "\n",
    "- With 10% bad points, making those points 10× worse barely changes MedAE.\n",
    "- MAE and RMSE *do* change because they average (and RMSE squares) the tail.\n",
    "\n",
    "Let's simulate that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 300\n",
    "y_true = rng.normal(0, 1, size=n)\n",
    "y_pred_base = y_true + rng.normal(0, 0.3, size=n)\n",
    "\n",
    "outlier_frac = 0.10\n",
    "k = int(outlier_frac * n)\n",
    "out_idx = rng.choice(n, size=k, replace=False)\n",
    "signs = rng.choice([-1.0, 1.0], size=k)\n",
    "\n",
    "magnitudes = np.linspace(0, 25, 60)\n",
    "\n",
    "medae_vals = []\n",
    "mae_vals = []\n",
    "rmse_vals = []\n",
    "\n",
    "for m in magnitudes:\n",
    "    y_pred = y_pred_base.copy()\n",
    "    y_pred[out_idx] += signs * m\n",
    "\n",
    "    medae_vals.append(float(np.median(np.abs(y_true - y_pred))))\n",
    "    mae_vals.append(mean_absolute_error(y_true, y_pred))\n",
    "    rmse_vals.append(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=magnitudes, y=medae_vals, mode='lines', name='MedAE (median)'))\n",
    "fig.add_trace(go.Scatter(x=magnitudes, y=mae_vals, mode='lines', name='MAE (mean)'))\n",
    "fig.add_trace(go.Scatter(x=magnitudes, y=rmse_vals, mode='lines', name='RMSE (sqrt MSE)'))\n",
    "fig.update_layout(\n",
    "    title=f'Effect of {outlier_frac:.0%} extreme outliers on common metrics',\n",
    "    xaxis_title='outlier magnitude added to predictions',\n",
    "    yaxis_title='metric value (same units as y)',\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medae_with_fraction_outliers(frac, *, seed_offset=0):\n",
    "    local_rng = np.random.default_rng(123 + seed_offset)\n",
    "    k = int(frac * n)\n",
    "    idx = local_rng.choice(n, size=k, replace=False)\n",
    "    signs = local_rng.choice([-1.0, 1.0], size=k)\n",
    "\n",
    "    vals = []\n",
    "    for m in magnitudes:\n",
    "        y_pred = y_pred_base.copy()\n",
    "        y_pred[idx] += signs * m\n",
    "        vals.append(float(np.median(np.abs(y_true - y_pred))))\n",
    "    return vals\n",
    "\n",
    "\n",
    "medae_10 = medae_with_fraction_outliers(0.10, seed_offset=0)\n",
    "medae_60 = medae_with_fraction_outliers(0.60, seed_offset=1)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=magnitudes, y=medae_10, mode='lines', name='MedAE (10% outliers)'))\n",
    "fig.add_trace(go.Scatter(x=magnitudes, y=medae_60, mode='lines', name='MedAE (60% outliers)'))\n",
    "fig.update_layout(\n",
    "    title='Median breakdown: once >50% are outliers, MedAE moves too',\n",
    "    xaxis_title='outlier magnitude added to predictions',\n",
    "    yaxis_title='MedAE',\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) NumPy implementation (from scratch)\n",
    "\n",
    "scikit-learn's `median_absolute_error` supports:\n",
    "\n",
    "- 1D targets: `y.shape == (n_samples,)`\n",
    "- multi-output targets: `y.shape == (n_samples, n_outputs)`\n",
    "- aggregation via `multioutput`:\n",
    "  - `'raw_values'` → one MedAE per output\n",
    "  - `'uniform_average'` → average over outputs (default)\n",
    "  - array-like weights → weighted average over outputs\n",
    "\n",
    "Unlike MAE/MSE, MedAE does **not** accept `sample_weight` in scikit-learn (there is no universally-agreed \"weighted median\" convention).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _as_2d(y):\n",
    "    y = np.asarray(y)\n",
    "    if y.ndim == 1:\n",
    "        return y.reshape(-1, 1)\n",
    "    if y.ndim == 2:\n",
    "        return y\n",
    "    raise ValueError(f'y must be 1D or 2D, got shape={y.shape}')\n",
    "\n",
    "\n",
    "def median_absolute_error_np(y_true, y_pred, *, multioutput='uniform_average'):\n",
    "    \"\"\"NumPy implementation compatible with sklearn.metrics.median_absolute_error.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true, y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
    "    multioutput : {'raw_values', 'uniform_average'} or array-like of shape (n_outputs,)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float or np.ndarray\n",
    "    \"\"\"\n",
    "    y_true_2d = _as_2d(y_true)\n",
    "    y_pred_2d = _as_2d(y_pred)\n",
    "\n",
    "    if y_true_2d.shape != y_pred_2d.shape:\n",
    "        raise ValueError(\n",
    "            f'y_true and y_pred must have the same shape, got {y_true_2d.shape} vs {y_pred_2d.shape}'\n",
    "        )\n",
    "\n",
    "    abs_errors = np.abs(y_true_2d - y_pred_2d)\n",
    "    med_per_output = np.median(abs_errors, axis=0)\n",
    "\n",
    "    if isinstance(multioutput, str):\n",
    "        if multioutput == 'raw_values':\n",
    "            return med_per_output\n",
    "        if multioutput == 'uniform_average':\n",
    "            return float(np.mean(med_per_output))\n",
    "        raise ValueError(\n",
    "            \"multioutput must be 'raw_values', 'uniform_average', or an array of output weights\"\n",
    "        )\n",
    "\n",
    "    weights = np.asarray(multioutput, dtype=float)\n",
    "    if weights.shape != med_per_output.shape:\n",
    "        raise ValueError(\n",
    "            f'multioutput weights must have shape {med_per_output.shape}, got {weights.shape}'\n",
    "        )\n",
    "    return float(np.average(med_per_output, weights=weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D check\n",
    "y_true = rng.normal(size=50)\n",
    "y_pred = y_true + rng.normal(scale=0.3, size=50)\n",
    "\n",
    "print('MedAE (np)     =', median_absolute_error_np(y_true, y_pred))\n",
    "print('MedAE (sklearn)=', median_absolute_error(y_true, y_pred))\n",
    "\n",
    "# Multi-output check\n",
    "y_true = rng.normal(size=(80, 3))\n",
    "y_pred = y_true + rng.normal(scale=0.5, size=(80, 3))\n",
    "\n",
    "print('\\nraw_values (np)     =', median_absolute_error_np(y_true, y_pred, multioutput='raw_values'))\n",
    "print('raw_values (sklearn)=', median_absolute_error(y_true, y_pred, multioutput='raw_values'))\n",
    "\n",
    "weights = np.array([0.2, 0.3, 0.5])\n",
    "print('\\nweighted (np)     =', median_absolute_error_np(y_true, y_pred, multioutput=weights))\n",
    "print('weighted (sklearn)=', median_absolute_error(y_true, y_pred, multioutput=weights))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Using MedAE to optimize a model\n",
    "\n",
    "MedAE is great as an **evaluation** metric, but it's awkward as a **training loss**:\n",
    "\n",
    "- it uses a **median** (an order statistic)\n",
    "- it is **non-smooth** and has **plateaus**\n",
    "- for many models, the objective is not convex\n",
    "\n",
    "Still, you *can* optimize it in low-level ways (typically derivative-free). We'll do two simple cases:\n",
    "\n",
    "1) the best **constant** predictor under MedAE (closed form)\n",
    "2) fitting a **line** by directly minimizing MedAE with a randomized search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Constant predictor: minimize MedAE(y, c)\n",
    "\n",
    "Consider the constant model $\\hat{y}_i = c$ for all $i$.\n",
    "\n",
    "The objective is:\n",
    "\n",
    "$$\n",
    "J(c) = \\mathrm{MedAE}(y, c) = \\operatorname{median}_{i} |y_i - c|\n",
    "$$\n",
    "\n",
    "Interpretation in 1D:\n",
    "\n",
    "- Let $r \\ge 0$.\n",
    "- The condition $J(c) \\le r$ means **at least half** of the points lie inside the interval $[c-r,\\, c+r]$.\n",
    "\n",
    "So minimizing $J(c)$ is equivalent to:\n",
    "\n",
    "> Find the **shortest interval** that contains at least half the samples, then place $c$ in the middle of that interval.\n",
    "\n",
    "Algorithm (odd $n$; NumPy/scikit-learn's median uses the same idea for even $n$):\n",
    "\n",
    "1. Sort $y_{(1)} \\le \\dots \\le y_{(n)}$\n",
    "2. Let $k = \\lceil n/2 \\rceil$\n",
    "3. Slide a window of size $k$ and compute widths:\n",
    "   $$\n",
    "   w_i = y_{(i+k-1)} - y_{(i)}, \\quad i = 1,\\dots,n-k+1\n",
    "   $$\n",
    "4. Pick the tightest window $i^* = \\arg\\min_i w_i$\n",
    "5. Set:\n",
    "   $$\n",
    "   c^* = \\frac{y_{(i^*)} + y_{(i^*+k-1)}}{2}\n",
    "   $$\n",
    "\n",
    "This is **different** from MAE: minimizing MAE over constants yields the (usual) median of $y$, while minimizing MedAE finds the center of the **densest half** of the data (a \"mode-like\" behavior).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_constant_medae(y):\n",
    "    \"\"\"Return (c_star, MedAE(y, c_star)) for the constant predictor y_hat=c.\n",
    "\n",
    "    Uses the shortest half-sample interval (window of size ceil(n/2)).\n",
    "    \"\"\"\n",
    "    y = np.asarray(y, dtype=float).ravel()\n",
    "    if y.size == 0:\n",
    "        raise ValueError('y must be non-empty')\n",
    "\n",
    "    y_sorted = np.sort(y)\n",
    "    n = y_sorted.size\n",
    "    k = n // 2 + 1  # ceil(n/2)\n",
    "\n",
    "    widths = y_sorted[k - 1 :] - y_sorted[: n - k + 1]\n",
    "    i = int(np.argmin(widths))\n",
    "\n",
    "    c_star = 0.5 * (y_sorted[i] + y_sorted[i + k - 1])\n",
    "    medae_star = float(np.median(np.abs(y - c_star)))\n",
    "    return c_star, medae_star\n",
    "\n",
    "\n",
    "# A two-cluster example (dense cluster on the right)\n",
    "y = np.array([0, 1, 2, 3, 100, 101, 102, 103, 104], dtype=float)\n",
    "\n",
    "c_median = float(np.median(y))  # minimizer of MAE over constants\n",
    "c_star, medae_star = best_constant_medae(y)\n",
    "\n",
    "c_grid = np.linspace(y.min() - 5, y.max() + 5, 800)\n",
    "loss = np.array([float(np.median(np.abs(y - c))) for c in c_grid])\n",
    "\n",
    "print(f'median(y) (MAE-optimal constant) = {c_median:.2f}')\n",
    "print(f'c* (MedAE-optimal constant)      = {c_star:.2f}')\n",
    "print(f'MedAE(y, c*) = {medae_star:.2f}')\n",
    "print(f'MedAE(y, median(y)) = {float(np.median(np.abs(y - c_median))):.2f}')\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=c_grid, y=loss, mode='lines', name='MedAE(y, c)'))\n",
    "fig.add_vline(\n",
    "    x=c_median,\n",
    "    line_dash='dot',\n",
    "    line_color='gray',\n",
    "    annotation_text=f'median(y)={c_median:.1f}',\n",
    ")\n",
    "fig.add_vline(\n",
    "    x=c_star,\n",
    "    line_dash='dash',\n",
    "    line_color='black',\n",
    "    annotation_text=f'c*={c_star:.1f}',\n",
    ")\n",
    "fig.update_layout(\n",
    "    title='Constant predictor: minimizing MedAE targets the densest half of y',\n",
    "    xaxis_title='constant prediction c',\n",
    "    yaxis_title='MedAE(y, c)',\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Fitting a line by directly minimizing MedAE\n",
    "\n",
    "Now consider a simple linear model:\n",
    "\n",
    "$$\n",
    "\\hat{y} = b_0 + b_1 x\n",
    "$$\n",
    "\n",
    "If we train by MedAE:\n",
    "\n",
    "$$\n",
    "J(b_0, b_1) = \\operatorname{median}_i |y_i - (b_0 + b_1 x_i)|\n",
    "$$\n",
    "\n",
    "This surface is typically **non-smooth** (lots of flat regions), so we'll use a very simple **randomized hill-climbing** optimizer:\n",
    "\n",
    "- start from an initial guess (we'll use OLS as a warm start)\n",
    "- randomly propose small changes to $(b_0, b_1)$\n",
    "- keep the proposal only if it reduces MedAE\n",
    "- slowly shrink the proposal scale\n",
    "\n",
    "This isn't production-grade optimization, but it shows how the metric can be used as a direct objective.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 180\n",
    "x = rng.uniform(-2, 2, size=n)\n",
    "\n",
    "b0_true, b1_true = 1.0, 2.0\n",
    "y_clean = b0_true + b1_true * x + rng.normal(0, 0.3, size=n)\n",
    "\n",
    "y = y_clean.copy()\n",
    "\n",
    "n_out = int(0.15 * n)\n",
    "out_idx = rng.choice(n, size=n_out, replace=False)\n",
    "y[out_idx] += rng.normal(0, 8.0, size=n_out)\n",
    "\n",
    "X = np.column_stack([np.ones_like(x), x])\n",
    "b0_ols, b1_ols = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "\n",
    "print(f'true params: b0={b0_true:.3f}, b1={b1_true:.3f}')\n",
    "print(f'OLS  params: b0={b0_ols:.3f}, b1={b1_ols:.3f}')\n",
    "\n",
    "is_outlier = np.zeros(n, dtype=bool)\n",
    "is_outlier[out_idx] = True\n",
    "colors = np.where(is_outlier, 'crimson', 'royalblue')\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        mode='markers',\n",
    "        name='observations',\n",
    "        marker=dict(color=colors, size=7, opacity=0.85),\n",
    "    )\n",
    ")\n",
    "fig.update_layout(title='Synthetic regression data with outliers', xaxis_title='x', yaxis_title='y')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medae_for_line(x, y, b0, b1):\n",
    "    y_hat = b0 + b1 * x\n",
    "    return float(np.median(np.abs(y - y_hat)))\n",
    "\n",
    "\n",
    "def fit_line_medae_hillclimb(\n",
    "    x,\n",
    "    y,\n",
    "    *,\n",
    "    b0_init=0.0,\n",
    "    b1_init=0.0,\n",
    "    n_steps=8000,\n",
    "    step0=1.5,\n",
    "    decay=0.9995,\n",
    "):\n",
    "    b0, b1 = float(b0_init), float(b1_init)\n",
    "    best = medae_for_line(x, y, b0, b1)\n",
    "\n",
    "    step_b0 = float(step0)\n",
    "    step_b1 = float(step0)\n",
    "\n",
    "    history = {\n",
    "        'step': [],\n",
    "        'b0': [],\n",
    "        'b1': [],\n",
    "        'medae': [],\n",
    "    }\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        cand_b0 = b0 + step_b0 * rng.normal()\n",
    "        cand_b1 = b1 + step_b1 * rng.normal()\n",
    "\n",
    "        cand = medae_for_line(x, y, cand_b0, cand_b1)\n",
    "        if cand < best:\n",
    "            b0, b1, best = cand_b0, cand_b1, cand\n",
    "\n",
    "        history['step'].append(t)\n",
    "        history['b0'].append(b0)\n",
    "        history['b1'].append(b1)\n",
    "        history['medae'].append(best)\n",
    "\n",
    "        step_b0 *= decay\n",
    "        step_b1 *= decay\n",
    "\n",
    "    return (b0, b1), history\n",
    "\n",
    "\n",
    "(b0_medae, b1_medae), hist = fit_line_medae_hillclimb(\n",
    "    x,\n",
    "    y,\n",
    "    b0_init=b0_ols,\n",
    "    b1_init=b1_ols,\n",
    "    n_steps=8000,\n",
    "    step0=1.5,\n",
    "    decay=0.9995,\n",
    ")\n",
    "\n",
    "\n",
    "def summarize(b0, b1):\n",
    "    y_hat = b0 + b1 * x\n",
    "    return {\n",
    "        'MedAE': float(np.median(np.abs(y - y_hat))),\n",
    "        'MAE': mean_absolute_error(y, y_hat),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y, y_hat)),\n",
    "    }\n",
    "\n",
    "\n",
    "print('OLS metrics:', summarize(b0_ols, b1_ols))\n",
    "print('MedAE-optimized metrics:', summarize(b0_medae, b1_medae))\n",
    "\n",
    "fig = px.line(\n",
    "    y=hist['medae'],\n",
    "    title='Hill-climbing: best MedAE so far',\n",
    "    labels={'index': 'step', 'y': 'best MedAE'},\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "x_line = np.linspace(x.min(), x.max(), 200)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y, mode='markers', name='data', marker=dict(color=colors, size=7, opacity=0.85)))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_line,\n",
    "        y=b0_ols + b1_ols * x_line,\n",
    "        mode='lines',\n",
    "        name='OLS (min MSE)',\n",
    "        line=dict(color='black', dash='dot'),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_line,\n",
    "        y=b0_medae + b1_medae * x_line,\n",
    "        mode='lines',\n",
    "        name='Min MedAE (hill-climb)',\n",
    "        line=dict(color='seagreen'),\n",
    "    )\n",
    ")\n",
    "fig.update_layout(title='Line fit: OLS vs directly minimizing MedAE', xaxis_title='x', yaxis_title='y')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the MedAE surface over (b0, b1) with the (downsampled) search path\n",
    "\n",
    "b0_grid = np.linspace(b0_ols - 4.0, b0_ols + 4.0, 160)\n",
    "b1_grid = np.linspace(b1_ols - 4.0, b1_ols + 4.0, 160)\n",
    "\n",
    "B0, B1 = np.meshgrid(b0_grid, b1_grid)\n",
    "residuals = y[None, None, :] - (B0[:, :, None] + B1[:, :, None] * x[None, None, :])\n",
    "Z = np.median(np.abs(residuals), axis=2)\n",
    "\n",
    "stride = max(1, len(hist['step']) // 150)\n",
    "b0_path = np.array(hist['b0'])[::stride]\n",
    "b1_path = np.array(hist['b1'])[::stride]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Contour(\n",
    "        x=b0_grid,\n",
    "        y=b1_grid,\n",
    "        z=Z,\n",
    "        contours_coloring='heatmap',\n",
    "        colorbar=dict(title='MedAE'),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=b0_path, y=b1_path, mode='lines', name='search path', line=dict(color='white')))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[b0_ols],\n",
    "        y=[b1_ols],\n",
    "        mode='markers',\n",
    "        name='OLS start',\n",
    "        marker=dict(color='black', symbol='x', size=10),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[b0_medae],\n",
    "        y=[b1_medae],\n",
    "        mode='markers',\n",
    "        name='best found',\n",
    "        marker=dict(color='lime', size=10),\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title='MedAE surface over (b0, b1): non-smooth & plateau-heavy',\n",
    "    xaxis_title='b0 (intercept)',\n",
    "    yaxis_title='b1 (slope)',\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Pros, cons, and when to use MedAE\n",
    "\n",
    "### Pros\n",
    "\n",
    "- **Robust to outliers**: the median ignores extreme errors until they affect >50% of samples.\n",
    "- **Interpretable units**: same unit as the target.\n",
    "- Measures **typical** performance (50th percentile), which can match user-facing targets (\"median miss\").\n",
    "\n",
    "### Cons / pitfalls\n",
    "\n",
    "- **Hides tail risk**: two models can have the same MedAE while one has much worse rare failures.\n",
    "- **Hard to optimize directly**: the median makes the objective non-smooth with plateaus; gradient methods don’t apply cleanly.\n",
    "- **No sample weights in sklearn**: “weighted median” is ambiguous and not provided.\n",
    "- Can be **unstable on small datasets** (the median jumps when a single point crosses the middle).\n",
    "\n",
    "### Good use cases\n",
    "\n",
    "- Regression with **heavy-tailed noise** / occasional gross outliers (sensor glitches, messy labels).\n",
    "- When “typical error” matters more than worst-case or average (e.g., median ETA error).\n",
    "- As a **validation metric** alongside MAE/RMSE/max error to capture multiple aspects of error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Exercises\n",
    "\n",
    "1. Create a dataset where 40% of points are extreme outliers. Verify MedAE barely moves, then repeat with 60% and observe the breakdown.\n",
    "2. Implement a *weighted* median absolute error (choose a clear weighted-median convention) and test it on toy data.\n",
    "3. Compare OLS vs MedAE-optimized line on data with asymmetric noise (one-sided outliers). Which metric better matches what you care about?\n",
    "\n",
    "## References\n",
    "\n",
    "- scikit-learn docs: https://scikit-learn.org/stable/modules/model_evaluation.html#median-absolute-error\n",
    "- Robust statistics (median, breakdown point): https://en.wikipedia.org/wiki/Robust_statistics\n",
    "- Rousseeuw, Leroy — *Robust Regression and Outlier Detection* (least-median ideas)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}