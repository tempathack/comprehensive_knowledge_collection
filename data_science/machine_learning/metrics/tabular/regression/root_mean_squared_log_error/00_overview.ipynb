{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f72f5ef3",
   "metadata": {},
   "source": [
    "# Root Mean Squared Logarithmic Error (RMSLE) — Regression Metric (From Scratch)\n",
    "\n",
    "RMSLE measures error **in log space**: it is the RMSE between $\\log(1 + y)$ and $\\log(1 + \\hat y)$.\n",
    "\n",
    "It is most useful when targets are **non-negative**, span **orders of magnitude**, and you care about **multiplicative / percentage-like** errors.\n",
    "\n",
    "**Goals**\n",
    "- Build intuition with numeric examples + Plotly visuals\n",
    "- Write RMSLE/MSLE in clear notation (including domain constraints)\n",
    "- Implement `root_mean_squared_log_error` in NumPy (from scratch) and validate vs scikit-learn\n",
    "- Show how RMSLE naturally leads to optimizing a model on a `log1p`-transformed target\n",
    "- Summarize pros/cons, good use cases, and common pitfalls\n",
    "\n",
    "## Quick import\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import root_mean_squared_log_error\n",
    "```\n",
    "\n",
    "Equivalent: `np.sqrt(mean_squared_log_error(...))`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5ff49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_squared_log_error,\n",
    "    root_mean_squared_error,\n",
    "    root_mean_squared_log_error,\n",
    ")\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a3919",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Regression setup: true targets $y$ and predictions $\\hat y$\n",
    "- Logarithms and the `log1p` / `expm1` trick:\n",
    "  - `log1p(y) = log(1 + y)` is stable when $y$ is near 0\n",
    "  - `expm1(z) = exp(z) - 1` is the inverse of `log1p`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73f39f0",
   "metadata": {},
   "source": [
    "## 1) Definition and notation\n",
    "\n",
    "Given $n$ samples with **non-negative** targets $y_i \\ge 0$ and predictions $\\hat y_i \\ge 0$, define the log-transformed values:\n",
    "\n",
    "$$t_i = \\log(1 + y_i), \\qquad \\hat t_i = \\log(1 + \\hat y_i)$$\n",
    "\n",
    "The **mean squared logarithmic error** (MSLE) is:\n",
    "\n",
    "$$\\mathrm{MSLE}(y, \\hat y) = \\frac{1}{n}\\sum_{i=1}^n (\\hat t_i - t_i)^2 = \\frac{1}{n}\\sum_{i=1}^n \\left(\\log(1 + \\hat y_i) - \\log(1 + y_i)\\right)^2$$\n",
    "\n",
    "The **root mean squared logarithmic error** (RMSLE) is:\n",
    "\n",
    "$$\\mathrm{RMSLE}(y, \\hat y) = \\sqrt{\\mathrm{MSLE}(y, \\hat y)}$$\n",
    "\n",
    "Weighted variant with sample weights $w_i \\ge 0$:\n",
    "\n",
    "$$\\mathrm{MSLE}_w = \\frac{\\sum_{i=1}^n w_i (\\hat t_i - t_i)^2}{\\sum_{i=1}^n w_i}, \\qquad \\mathrm{RMSLE}_w = \\sqrt{\\mathrm{MSLE}_w}$$\n",
    "\n",
    "Key identity (what makes this metric convenient):\n",
    "\n",
    "$$\\mathrm{RMSLE}(y, \\hat y) = \\mathrm{RMSE}(\\log(1+y), \\log(1+\\hat y))$$\n",
    "\n",
    "Notes:\n",
    "- `log` is the natural logarithm; using another base just scales the metric by a constant.\n",
    "- For multi-output regression, implementations typically compute RMSLE per output and then average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e340c96",
   "metadata": {},
   "source": [
    "## 2) Domain constraints and edge cases\n",
    "\n",
    "- **Non-negativity**: Most definitions (and scikit-learn) require $y \\ge 0$ and $\\hat y \\ge 0$.\n",
    "- **Zeros are fine**: `log1p(0) = 0`, which is why `log(1 + y)` is used instead of `log(y)`.\n",
    "- **Negative predictions**: A linear model can output negative values; for RMSLE you often\n",
    "  - use a model that enforces $\\hat y \\ge 0$ (e.g., predict in log space), or\n",
    "  - clip: $\\hat y \\leftarrow \\max(\\hat y, 0)$ at evaluation time (common in practice).\n",
    "- **Near zero, it behaves like squared error**: for small $y$, $\\log(1+y) \\approx y$.\n",
    "- **For large values, it behaves like squared relative error**: for large $y$, $\\log(1+y) \\approx \\log(y)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e0b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.array([0.0, 0.1, 1.0, 10.0, 100.0])\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"y\": vals,\n",
    "        \"log1p(y)\": np.log1p(vals),\n",
    "        \"expm1(log1p(y))\": np.expm1(np.log1p(vals)),\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8249abf6",
   "metadata": {},
   "source": [
    "## 3) Intuition: RMSLE cares about *ratios* (mostly)\n",
    "\n",
    "For large targets, the `+1` becomes negligible and:\n",
    "\n",
    "$$\\log(1 + \\hat y) - \\log(1 + y) \\approx \\log(\\hat y) - \\log(y) = \\log\\left(\\frac{\\hat y}{y}\\right)$$\n",
    "\n",
    "So for large $y$, a prediction that is off by a factor of $c$ (i.e., $\\hat y = c y$) has error approximately:\n",
    "\n",
    "$$\\left(\\log(c)\\right)^2$$\n",
    "\n",
    "This means:\n",
    "- Overpredicting by $\\times 2$ and underpredicting by $\\div 2$ have the **same** penalty (because $\\log(2)$ and $\\log(1/2) = -\\log(2)$ square to the same value).\n",
    "- The metric is much less dominated by very large targets than RMSE/MSE.\n",
    "\n",
    "For small targets, $\\log(1+y) \\approx y$, so the metric behaves closer to squared error on the original scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa30d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = np.logspace(-2, 2, 500)  # 0.01 .. 100\n",
    "y_trues = [0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "parts = []\n",
    "for y in y_trues:\n",
    "    y_pred = ratios * y\n",
    "    parts.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"ratio\": ratios,\n",
    "                \"sq_log_error\": (np.log1p(y_pred) - np.log1p(y)) ** 2,\n",
    "                \"series\": f\"y_true={y:g}\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "# large-y approximation: (log ratio)^2\n",
    "parts.append(\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"ratio\": ratios,\n",
    "            \"sq_log_error\": (np.log(ratios)) ** 2,\n",
    "            \"series\": \"(log ratio)^2 (large-y approx)\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "df_ratio = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "fig = px.line(\n",
    "    df_ratio,\n",
    "    x=\"ratio\",\n",
    "    y=\"sq_log_error\",\n",
    "    color=\"series\",\n",
    "    log_x=True,\n",
    "    title=\"Per-sample squared log error vs multiplicative ratio\",\n",
    "    labels={\n",
    "        \"ratio\": \"ratio = y_pred / y_true\",\n",
    "        \"sq_log_error\": \"(log1p(y_pred) - log1p(y_true))^2\",\n",
    "        \"series\": \"curve\",\n",
    "    },\n",
    ")\n",
    "fig.add_vline(x=1.0, line_dash=\"dash\", line_color=\"black\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa4d80d",
   "metadata": {},
   "source": [
    "## 4) A tiny worked example\n",
    "\n",
    "We'll compute RMSLE step-by-step and compare against scikit-learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0dfad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([0.0, 1.0, 10.0, 100.0])\n",
    "y_pred = np.array([0.0, 2.0, 8.0, 120.0])\n",
    "\n",
    "t_true = np.log1p(y_true)\n",
    "t_pred = np.log1p(y_pred)\n",
    "diff = t_pred - t_true\n",
    "\n",
    "msle = float(np.mean(diff**2))\n",
    "rmsle = float(np.sqrt(msle))\n",
    "\n",
    "print(\"t_true:\", t_true)\n",
    "print(\"t_pred:\", t_pred)\n",
    "print(\"diff:\", diff)\n",
    "print(\"MSLE:\", msle)\n",
    "print(\"RMSLE:\", rmsle)\n",
    "\n",
    "print(\"sklearn MSLE:\", mean_squared_log_error(y_true, y_pred))\n",
    "print(\"sklearn RMSLE:\", root_mean_squared_log_error(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5c5266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_example = pd.DataFrame(\n",
    "    {\n",
    "        \"i\": np.arange(len(y_true)),\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"log1p(y_true)\": t_true,\n",
    "        \"log1p(y_pred)\": t_pred,\n",
    "        \"sq_log_error\": diff**2,\n",
    "    }\n",
    ")\n",
    "\n",
    "fig = px.bar(\n",
    "    df_example,\n",
    "    x=\"i\",\n",
    "    y=\"sq_log_error\",\n",
    "    hover_data=[\"y_true\", \"y_pred\", \"log1p(y_true)\", \"log1p(y_pred)\"],\n",
    "    title=\"Per-sample MSLE contribution (squared log error)\",\n",
    "    labels={\"i\": \"sample index\", \"sq_log_error\": \"(log1p(y_pred) - log1p(y_true))^2\"},\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b623ce1",
   "metadata": {},
   "source": [
    "## 5) RMSLE vs RMSE: what changes when you take logs?\n",
    "\n",
    "Consider targets that span orders of magnitude.\n",
    "\n",
    "- With **RMSE**, a fixed *relative* error (say +20%) produces much larger absolute residuals for large targets, so large targets dominate the metric.\n",
    "- With **RMSLE**, a fixed *relative* error produces approximately the same log residual, so the contributions are more balanced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d1a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_scale = np.array([1.0, 10.0, 100.0, 1000.0])\n",
    "\n",
    "# Scenario A: same relative error (20% over)\n",
    "y_pred_rel = 1.2 * y_true_scale\n",
    "\n",
    "# Scenario B: same absolute error (+10)\n",
    "y_pred_abs = y_true_scale + 10.0\n",
    "\n",
    "def sq_error(y_t, y_p):\n",
    "    return (y_p - y_t) ** 2\n",
    "\n",
    "def sq_log_error(y_t, y_p):\n",
    "    return (np.log1p(y_p) - np.log1p(y_t)) ** 2\n",
    "\n",
    "df_scale = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"scenario\": \"20% over\",\n",
    "                \"y_true\": y_true_scale,\n",
    "                \"y_pred\": y_pred_rel,\n",
    "                \"squared error\": sq_error(y_true_scale, y_pred_rel),\n",
    "                \"squared log error\": sq_log_error(y_true_scale, y_pred_rel),\n",
    "            }\n",
    "        ),\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"scenario\": \"+10 absolute\",\n",
    "                \"y_true\": y_true_scale,\n",
    "                \"y_pred\": y_pred_abs,\n",
    "                \"squared error\": sq_error(y_true_scale, y_pred_abs),\n",
    "                \"squared log error\": sq_log_error(y_true_scale, y_pred_abs),\n",
    "            }\n",
    "        ),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "df_long = df_scale.melt(\n",
    "    id_vars=[\"scenario\", \"y_true\", \"y_pred\"],\n",
    "    value_vars=[\"squared error\", \"squared log error\"],\n",
    "    var_name=\"term\",\n",
    "    value_name=\"contribution\",\n",
    ")\n",
    "\n",
    "fig = px.bar(\n",
    "    df_long,\n",
    "    x=\"y_true\",\n",
    "    y=\"contribution\",\n",
    "    color=\"term\",\n",
    "    barmode=\"group\",\n",
    "    facet_col=\"scenario\",\n",
    "    log_y=True,\n",
    "    title=\"Per-sample contributions: RMSE/MSE vs RMSLE/MSLE\",\n",
    "    labels={\"y_true\": \"target (y_true)\", \"contribution\": \"contribution (log scale)\"},\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "for name, yp in [(\"20% over\", y_pred_rel), (\"+10 absolute\", y_pred_abs)]:\n",
    "    rmse = root_mean_squared_error(y_true_scale, yp)\n",
    "    rmsle = root_mean_squared_log_error(y_true_scale, yp)\n",
    "    print(f\"{name:>11} | RMSE={rmse:.4f} | RMSLE={rmsle:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f1848c",
   "metadata": {},
   "source": [
    "## 6) NumPy implementation (from scratch)\n",
    "\n",
    "We'll implement MSLE and RMSLE with scikit-learn-like handling:\n",
    "\n",
    "- 1D and 2D targets (`(n_samples,)` or `(n_samples, n_outputs)`)\n",
    "- Optional `sample_weight`\n",
    "- `multioutput` ∈ {`\"raw_values\"`, `\"uniform_average\"`} or explicit output weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c666b2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _as_2d(y):\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if y.ndim == 1:\n",
    "        return y.reshape(-1, 1)\n",
    "    if y.ndim == 2:\n",
    "        return y\n",
    "    raise ValueError(\"y must be 1D or 2D (n_samples,) or (n_samples, n_outputs).\")\n",
    "\n",
    "\n",
    "def _check_non_negative(y, *, name):\n",
    "    if np.any(y < 0):\n",
    "        raise ValueError(f\"{name} contains negative values; RMSLE/MSLE require y >= 0.\")\n",
    "\n",
    "\n",
    "def mean_squared_log_error_np(y_true, y_pred, *, sample_weight=None, multioutput=\"uniform_average\"):\n",
    "    \"\"\"Mean squared logarithmic error (MSLE).\n",
    "\n",
    "    MSLE(y, y_hat) = mean((log1p(y_hat) - log1p(y))^2)\n",
    "    \"\"\"\n",
    "    y_true_2d = _as_2d(y_true)\n",
    "    y_pred_2d = _as_2d(y_pred)\n",
    "\n",
    "    if y_true_2d.shape != y_pred_2d.shape:\n",
    "        raise ValueError(f\"shape mismatch: y_true{y_true_2d.shape} vs y_pred{y_pred_2d.shape}\")\n",
    "\n",
    "    _check_non_negative(y_true_2d, name=\"y_true\")\n",
    "    _check_non_negative(y_pred_2d, name=\"y_pred\")\n",
    "\n",
    "    t_true = np.log1p(y_true_2d)\n",
    "    t_pred = np.log1p(y_pred_2d)\n",
    "    residual = t_pred - t_true\n",
    "\n",
    "    if sample_weight is None:\n",
    "        msle_per_output = np.mean(residual**2, axis=0)\n",
    "    else:\n",
    "        w = np.asarray(sample_weight, dtype=float)\n",
    "        if w.ndim != 1:\n",
    "            raise ValueError(\"sample_weight must be 1D of shape (n_samples,).\")\n",
    "        if w.shape[0] != y_true_2d.shape[0]:\n",
    "            raise ValueError(\"sample_weight length must match n_samples.\")\n",
    "        w = w.reshape(-1, 1)\n",
    "        msle_per_output = np.sum(w * residual**2, axis=0) / np.sum(w, axis=0)\n",
    "\n",
    "    if multioutput == \"raw_values\":\n",
    "        return msle_per_output\n",
    "    if multioutput == \"uniform_average\":\n",
    "        return float(np.mean(msle_per_output))\n",
    "\n",
    "    weights = np.asarray(multioutput, dtype=float)\n",
    "    if weights.shape != (msle_per_output.shape[0],):\n",
    "        raise ValueError(\"multioutput weights must match n_outputs.\")\n",
    "    return float(np.average(msle_per_output, weights=weights))\n",
    "\n",
    "\n",
    "def root_mean_squared_log_error_np(\n",
    "    y_true, y_pred, *, sample_weight=None, multioutput=\"uniform_average\"\n",
    "):\n",
    "    \"\"\"Root mean squared logarithmic error (RMSLE): sqrt(MSLE).\"\"\"\n",
    "    msle_per_output = mean_squared_log_error_np(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        sample_weight=sample_weight,\n",
    "        multioutput=\"raw_values\",\n",
    "    )\n",
    "    rmsle_per_output = np.sqrt(msle_per_output)\n",
    "\n",
    "    if multioutput == \"raw_values\":\n",
    "        return rmsle_per_output\n",
    "    if multioutput == \"uniform_average\":\n",
    "        return float(np.mean(rmsle_per_output))\n",
    "\n",
    "    weights = np.asarray(multioutput, dtype=float)\n",
    "    if weights.shape != (rmsle_per_output.shape[0],):\n",
    "        raise ValueError(\"multioutput weights must match n_outputs.\")\n",
    "    return float(np.average(rmsle_per_output, weights=weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b8f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_rand = rng.lognormal(mean=1.2, sigma=0.9, size=(60, 3))\n",
    "y_pred_rand = y_true_rand * rng.lognormal(mean=0.0, sigma=0.3, size=y_true_rand.shape)\n",
    "\n",
    "print(\"ours raw:\", root_mean_squared_log_error_np(y_true_rand, y_pred_rand, multioutput=\"raw_values\"))\n",
    "print(\"sk   raw:\", root_mean_squared_log_error(y_true_rand, y_pred_rand, multioutput=\"raw_values\"))\n",
    "\n",
    "sample_w = rng.uniform(0.5, 2.0, size=y_true_rand.shape[0])\n",
    "print(\"ours weighted:\", root_mean_squared_log_error_np(y_true_rand, y_pred_rand, sample_weight=sample_w))\n",
    "print(\"sk   weighted:\", root_mean_squared_log_error(y_true_rand, y_pred_rand, sample_weight=sample_w))\n",
    "\n",
    "assert np.allclose(\n",
    "    root_mean_squared_log_error_np(y_true_rand, y_pred_rand, multioutput=\"raw_values\"),\n",
    "    root_mean_squared_log_error(y_true_rand, y_pred_rand, multioutput=\"raw_values\"),\n",
    ")\n",
    "assert np.isclose(\n",
    "    root_mean_squared_log_error_np(y_true_rand, y_pred_rand, sample_weight=sample_w),\n",
    "    root_mean_squared_log_error(y_true_rand, y_pred_rand, sample_weight=sample_w),\n",
    ")\n",
    "\n",
    "# Negative values should raise (to match sklearn)\n",
    "try:\n",
    "    root_mean_squared_log_error_np([0.0, 1.0], [0.0, -0.1])\n",
    "except ValueError as e:\n",
    "    print(\"caught:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84b6b9e",
   "metadata": {},
   "source": [
    "## 7) RMSLE as an objective: gradients and optimization\n",
    "\n",
    "Because the square root is monotonic, minimizing RMSLE is equivalent to minimizing MSLE.\n",
    "\n",
    "Let $\\Delta_i = \\log(1+\\hat y_i) - \\log(1+y_i)$. Then:\n",
    "\n",
    "$$\\mathrm{MSLE} = \\frac{1}{n}\\sum_{i=1}^n \\Delta_i^2$$\n",
    "\n",
    "Derivative w.r.t. a prediction $\\hat y_i$ (for $\\hat y_i > -1$):\n",
    "\n",
    "$$\\frac{\\partial\\,\\mathrm{MSLE}}{\\partial\\hat y_i} = \\frac{2}{n}\\,\\Delta_i\\,\\frac{1}{1+\\hat y_i}$$\n",
    "\n",
    "For RMSLE:\n",
    "\n",
    "$$\\frac{\\partial\\,\\mathrm{RMSLE}}{\\partial\\hat y_i} = \\frac{1}{n\\,\\mathrm{RMSLE}}\\,\\Delta_i\\,\\frac{1}{1+\\hat y_i}$$\n",
    "\n",
    "Practical takeaway:\n",
    "- There is an extra factor $\\frac{1}{1+\\hat y_i}$, so gradients are larger for small predictions.\n",
    "- A very common training trick is to optimize in log space: fit a model to $t = \\log(1+y)$ using standard squared error, then transform back with `expm1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d0fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic data with multiplicative noise (log-normal in y)\n",
    "n = 400\n",
    "x = rng.uniform(0.0, 6.0, size=n)\n",
    "\n",
    "# True relationship in log1p-space\n",
    "t = 1.5 + 1.0 * x + rng.normal(0.0, 0.35, size=n)  # t = log1p(y)\n",
    "y = np.expm1(t)\n",
    "\n",
    "# Train/test split\n",
    "perm = rng.permutation(n)\n",
    "cut = int(0.8 * n)\n",
    "tr, te = perm[:cut], perm[cut:]\n",
    "\n",
    "x_tr, y_tr = x[tr], y[tr]\n",
    "x_te, y_te = x[te], y[te]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca9901",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    x=x_tr,\n",
    "    y=y_tr,\n",
    "    opacity=0.7,\n",
    "    title=\"Synthetic regression data (y spans a wide range)\",\n",
    "    labels={\"x\": \"feature x\", \"y\": \"target y\"},\n",
    ")\n",
    "fig.update_yaxes(type=\"log\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f2d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_linear(x, w, b):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    return w * x + b\n",
    "\n",
    "\n",
    "def fit_linear_mse_gd(x, y, *, lr=5e-4, steps=600):\n",
    "    \"\"\"Fit y ≈ w x + b by minimizing MSE on y (gradient descent).\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "\n",
    "    w = 0.0\n",
    "    b = 0.0\n",
    "    n = x.shape[0]\n",
    "\n",
    "    hist = {\"mse\": [], \"rmsle\": [], \"w\": [], \"b\": []}\n",
    "\n",
    "    for _ in range(steps):\n",
    "        y_hat = predict_linear(x, w, b)\n",
    "        r = y_hat - y\n",
    "\n",
    "        mse = float(np.mean(r**2))\n",
    "\n",
    "        # RMSLE isn't defined for negative predictions in sklearn; clip for evaluation.\n",
    "        y_hat_clip = np.maximum(y_hat, 0.0)\n",
    "        rmsle = float(root_mean_squared_log_error_np(y, y_hat_clip))\n",
    "\n",
    "        grad_w = (2.0 / n) * float(np.dot(r, x))\n",
    "        grad_b = (2.0 / n) * float(np.sum(r))\n",
    "\n",
    "        w -= lr * grad_w\n",
    "        b -= lr * grad_b\n",
    "\n",
    "        hist[\"mse\"].append(mse)\n",
    "        hist[\"rmsle\"].append(rmsle)\n",
    "        hist[\"w\"].append(w)\n",
    "        hist[\"b\"].append(b)\n",
    "\n",
    "    return w, b, hist\n",
    "\n",
    "\n",
    "def fit_log1p_mse_gd(x, y, *, lr=0.05, steps=600):\n",
    "    \"\"\"Fit log1p(y) ≈ w x + b (equivalent to optimizing MSLE/RMSLE).\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    t = np.log1p(y)\n",
    "\n",
    "    w = 0.0\n",
    "    b = 0.0\n",
    "    n = x.shape[0]\n",
    "\n",
    "    hist = {\"mse_log\": [], \"mse_y\": [], \"rmsle\": [], \"w\": [], \"b\": []}\n",
    "\n",
    "    for _ in range(steps):\n",
    "        t_hat = predict_linear(x, w, b)  # model predicts log1p(y)\n",
    "        r = t_hat - t\n",
    "\n",
    "        mse_log = float(np.mean(r**2))\n",
    "\n",
    "        y_hat = np.expm1(t_hat)\n",
    "        y_hat = np.maximum(y_hat, 0.0)\n",
    "\n",
    "        mse_y = float(np.mean((y_hat - y) ** 2))\n",
    "        rmsle = float(root_mean_squared_log_error_np(y, y_hat))\n",
    "\n",
    "        grad_w = (2.0 / n) * float(np.dot(r, x))\n",
    "        grad_b = (2.0 / n) * float(np.sum(r))\n",
    "\n",
    "        w -= lr * grad_w\n",
    "        b -= lr * grad_b\n",
    "\n",
    "        hist[\"mse_log\"].append(mse_log)\n",
    "        hist[\"mse_y\"].append(mse_y)\n",
    "        hist[\"rmsle\"].append(rmsle)\n",
    "        hist[\"w\"].append(w)\n",
    "        hist[\"b\"].append(b)\n",
    "\n",
    "    return w, b, hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e826e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_y, b_y, hist_y = fit_linear_mse_gd(x_tr, y_tr)\n",
    "w_t, b_t, hist_t = fit_log1p_mse_gd(x_tr, y_tr)\n",
    "\n",
    "y_hat_te_mse = np.maximum(predict_linear(x_te, w_y, b_y), 0.0)\n",
    "y_hat_te_log = np.maximum(np.expm1(predict_linear(x_te, w_t, b_t)), 0.0)\n",
    "\n",
    "print(\"Test RMSLE (fit MSE on y):     \", root_mean_squared_log_error_np(y_te, y_hat_te_mse))\n",
    "print(\"Test RMSLE (fit on log1p(y)):\", root_mean_squared_log_error_np(y_te, y_hat_te_log))\n",
    "\n",
    "print(\"Test RMSE  (fit MSE on y):     \", root_mean_squared_error(y_te, y_hat_te_mse))\n",
    "print(\"Test RMSE  (fit on log1p(y)):\", root_mean_squared_error(y_te, y_hat_te_log))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist = pd.DataFrame(\n",
    "    {\n",
    "        \"step\": np.arange(len(hist_y[\"rmsle\"])),\n",
    "        \"RMSLE (fit MSE on y)\": hist_y[\"rmsle\"],\n",
    "        \"RMSLE (fit on log1p(y))\": hist_t[\"rmsle\"],\n",
    "    }\n",
    ")\n",
    "df_hist_long = df_hist.melt(id_vars=\"step\", var_name=\"model\", value_name=\"rmsle\")\n",
    "\n",
    "fig = px.line(\n",
    "    df_hist_long,\n",
    "    x=\"step\",\n",
    "    y=\"rmsle\",\n",
    "    color=\"model\",\n",
    "    title=\"Training curves (RMSLE evaluated on the train set)\",\n",
    "    labels={\"rmsle\": \"RMSLE\"},\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67e1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(\n",
    "    {\n",
    "        \"y_true\": np.concatenate([y_te, y_te]),\n",
    "        \"y_pred\": np.concatenate([y_hat_te_mse, y_hat_te_log]),\n",
    "        \"model\": np.repeat(\n",
    "            [\"fit MSE on y (linear)\", \"fit on log1p(y)\"],\n",
    "            repeats=len(y_te),\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "eps = 1e-6\n",
    "min_v = float(np.minimum(df_pred[\"y_true\"].min(), df_pred[\"y_pred\"].min()))\n",
    "max_v = float(np.maximum(df_pred[\"y_true\"].max(), df_pred[\"y_pred\"].max()))\n",
    "min_v = max(min_v, eps)\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_pred,\n",
    "    x=\"y_true\",\n",
    "    y=\"y_pred\",\n",
    "    color=\"model\",\n",
    "    opacity=0.7,\n",
    "    title=\"Test predictions: y_true vs y_pred\",\n",
    "    labels={\"y_true\": \"true y\", \"y_pred\": \"predicted y\"},\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[min_v, max_v],\n",
    "        y=[min_v, max_v],\n",
    "        mode=\"lines\",\n",
    "        name=\"y = x\",\n",
    "        line=dict(color=\"black\", dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "fig.update_xaxes(type=\"log\")\n",
    "fig.update_yaxes(type=\"log\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b7d175",
   "metadata": {},
   "source": [
    "## 8) Practical usage notes (scikit-learn)\n",
    "\n",
    "- If you want to optimize for RMSLE, a common baseline is:\n",
    "  1) transform targets with `log1p`\n",
    "  2) fit a standard regression model\n",
    "  3) invert predictions with `expm1`\n",
    "- To **avoid invalid values**, clip predictions to $\\hat y \\ge 0$ before computing RMSLE.\n",
    "\n",
    "Scikit-learn provides `TransformedTargetRegressor` to make the log/exp transform explicit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84a9c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_tr = x_tr.reshape(-1, 1)\n",
    "X_te = x_te.reshape(-1, 1)\n",
    "\n",
    "model = TransformedTargetRegressor(\n",
    "    regressor=LinearRegression(),\n",
    "    func=np.log1p,\n",
    "    inverse_func=np.expm1,\n",
    ")\n",
    "model.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred_te = model.predict(X_te)\n",
    "y_pred_te = np.clip(y_pred_te, 0.0, None)\n",
    "\n",
    "print(\"sklearn RMSLE:\", root_mean_squared_log_error(y_te, y_pred_te))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6f017c",
   "metadata": {},
   "source": [
    "## 9) Pros, cons, and when to use RMSLE\n",
    "\n",
    "**Pros**\n",
    "\n",
    "- Focuses on *multiplicative* errors: being off by a factor matters more than being off by a constant\n",
    "- Handles targets spanning orders of magnitude (less dominated by large absolute values)\n",
    "- Natural when noise is approximately log-normal / heteroscedastic (variance grows with the mean)\n",
    "- Easy to optimize by modeling $\\log(1+y)$ and using squared error there\n",
    "\n",
    "**Cons**\n",
    "\n",
    "- Requires non-negative targets and predictions (not suitable when $y$ can be negative)\n",
    "- Can overweight small targets: mistakes near zero matter a lot\n",
    "- Reported value is in log units (less directly interpretable than RMSE/MAE)\n",
    "- If you train in log space and then invert with `expm1`, predictions correspond more to a *median* than a *mean* in the original space (bias can appear)\n",
    "\n",
    "**Good default when**\n",
    "\n",
    "- Targets are counts/prices/sales/traffic/demand and you care about relative error\n",
    "- Targets have a heavy right tail and you want evaluation that doesn't get dominated by the largest cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba2ad29",
   "metadata": {},
   "source": [
    "## 10) Common pitfalls and diagnostics\n",
    "\n",
    "- **Invalid negatives**: RMSLE is not defined for negative values in most libraries; enforce $\\hat y \\ge 0$ (model choice or clipping).\n",
    "- **Zero-heavy targets**: inspect performance separately on $y=0$ vs $y>0$; RMSLE can behave differently near zero.\n",
    "- **Compare metrics**: always compare RMSLE with RMSE/MAE; choose based on the cost of absolute vs relative errors.\n",
    "- **Inspect residuals in log space**: if you optimize for RMSLE, plot $\\log(1+\\hat y) - \\log(1+y)$, not only $\\hat y - y$.\n",
    "- **Remember the +1**: the \"relative error\" intuition is best when targets are not tiny.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d3a3be",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1) Add support for `sample_weight` and explicit `multioutput` weights to the plotting examples (do some outputs matter more?).\n",
    "2) Create a dataset where the true noise is additive (not multiplicative) and compare RMSE vs RMSLE behavior.\n",
    "3) Show that for large $y$, MSLE is approximately the squared log-ratio: $(\\log(\\hat y/y))^2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddaeeb7",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- scikit-learn metrics API: https://scikit-learn.org/stable/api/sklearn.metrics.html\n",
    "- Kaggle discussions on RMSLE (common for count/price targets)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}