{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06cd2b39",
   "metadata": {},
   "source": [
    "# Yule–Simon distribution (`yulesimon`)\n",
    "\n",
    "The **Yule–Simon distribution** is a **heavy-tailed discrete** distribution on the positive integers.\n",
    "It’s a classic model for *rich-get-richer* / *preferential attachment* dynamics: a few categories become very large, while most stay small.\n",
    "\n",
    "## Learning goals\n",
    "- Recognize when Yule–Simon is a reasonable model for count data with a power-law tail.\n",
    "- Write the PMF/CDF in terms of Beta/Gamma functions (and understand the tail behavior).\n",
    "- Know which moments exist (and when the mean/variance/skewness/kurtosis are infinite).\n",
    "- Derive the expectation and variance via a Beta–geometric mixture representation.\n",
    "- Implement sampling **with NumPy only** and validate it with Monte Carlo simulation.\n",
    "- Use `scipy.stats.yulesimon` and `scipy.stats.fit` for evaluation, simulation, and parameter estimation.\n",
    "\n",
    "## Prerequisites\n",
    "- Discrete probability (PMF/CDF), expectation, variance\n",
    "- Comfort with logs and basic calculus\n",
    "- Familiarity with the Gamma/Beta functions is helpful (but introduced as needed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dd4c76",
   "metadata": {},
   "source": [
    "## Notebook roadmap\n",
    "\n",
    "1. Title & Classification\n",
    "2. Intuition & Motivation\n",
    "3. Formal Definition\n",
    "4. Moments & Properties\n",
    "5. Parameter Interpretation\n",
    "6. Derivations (Expectation, Variance, Likelihood)\n",
    "7. Sampling & Simulation (NumPy-only)\n",
    "8. Visualization (PMF, CDF, Monte Carlo)\n",
    "9. SciPy Integration\n",
    "10. Statistical Use Cases\n",
    "11. Pitfalls\n",
    "12. Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c84683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "from scipy import optimize, special, stats\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "\n",
    "SEED = 7\n",
    "rng = np.random.default_rng(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34aa52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import scipy\n",
    "import plotly\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"SciPy:\", scipy.__version__)\n",
    "print(\"Plotly:\", plotly.__version__)\n",
    "print(\"Seed:\", SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186cd16b",
   "metadata": {},
   "source": [
    "## 1) Title & Classification\n",
    "\n",
    "- **Name**: `yulesimon` (Yule–Simon distribution)\n",
    "- **Type**: **Discrete**\n",
    "- **Support** (SciPy `loc=0`): \\(k \\in \\{1,2,3,\\dots\\}\\)\n",
    "  - With a location shift `loc`, support becomes \\(k \\in \\{\\mathrm{loc}+1,\\, \\mathrm{loc}+2,\\, \\dots\\}\\).\n",
    "- **Parameter space**: \\(\\alpha > 0\\) (shape)\n",
    "\n",
    "Notation:\n",
    "- \\(K \\sim \\mathrm{YuleSimon}(\\alpha)\\).\n",
    "- SciPy uses the shape parameter name `alpha`: `scipy.stats.yulesimon(alpha, loc=0)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6d064e",
   "metadata": {},
   "source": [
    "## 2) Intuition & Motivation\n",
    "\n",
    "### What this distribution models\n",
    "The Yule–Simon distribution models **positive integer counts** with a **power-law (heavy) tail**:\n",
    "\n",
    "- many observations are small (1, 2, 3, …)\n",
    "- a non-negligible fraction are *very large*\n",
    "\n",
    "This pattern often comes from *cumulative advantage* dynamics:\n",
    "\n",
    "> items that are already frequent are more likely to be observed again.\n",
    "\n",
    "### Typical real-world use cases\n",
    "- **Word frequencies** in text (a few words are very common, most are rare)\n",
    "- **Citations** of scientific papers\n",
    "- **In-degree** in networks with preferential attachment (links to popular pages keep accumulating)\n",
    "- **Popularity** / **sales** counts (blockbusters vs the long tail)\n",
    "\n",
    "### Relations to other distributions\n",
    "- **Power laws / Pareto / Zipf**: Yule–Simon is a discrete distribution with a power-law tail.\n",
    "- **Mixture of geometric distributions**: if \\(P \\sim \\mathrm{Beta}(\\alpha,1)\\) and \\(K\\mid P \\sim \\mathrm{Geometric}(P)\\) on \\(\\{1,2,\\dots\\}\\), then \\(K\\) is Yule–Simon.\n",
    "- **Simon’s model** (preferential attachment with innovation) yields Yule–Simon-like frequency distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a4f3be",
   "metadata": {},
   "source": [
    "## 3) Formal Definition\n",
    "\n",
    "Let \\(K \\sim \\mathrm{YuleSimon}(\\alpha)\\) with \\(\\alpha>0\\) and support \\(k=1,2,\\dots\\).\n",
    "\n",
    "### PMF\n",
    "A standard closed form uses the **beta function** \\(B(\\cdot,\\cdot)\\):\n",
    "\n",
    "\\[\n",
    "\\mathbb{P}(K=k\\mid \\alpha)\n",
    "= \\alpha\\,B(k,\\alpha+1),\n",
    "\\qquad k=1,2,\\dots\n",
    "\\]\n",
    "\n",
    "Using \\(B(x,y)=\\frac{\\Gamma(x)\\Gamma(y)}{\\Gamma(x+y)}\\), this is equivalent to\n",
    "\n",
    "\\[\n",
    "\\mathbb{P}(K=k\\mid \\alpha)\n",
    "= \\alpha\\,\\frac{\\Gamma(k)\\Gamma(\\alpha+1)}{\\Gamma(k+\\alpha+1)}.\n",
    "\\]\n",
    "\n",
    "### CDF (and survival function)\n",
    "Because this is discrete, for real \\(x\\),\n",
    "\n",
    "\\[\n",
    "F(x)=\\mathbb{P}(K \\le x)=\\mathbb{P}(K \\le \\lfloor x\\rfloor).\n",
    "\\]\n",
    "\n",
    "For integer \\(k\\ge 1\\), a convenient closed form is\n",
    "\n",
    "\\[\n",
    "F(k)=1-\\mathbb{P}(K>k)\n",
    "=1-\\alpha\\,B(k+1,\\alpha)\n",
    "=1-k\\,B(k,\\alpha+1).\n",
    "\\]\n",
    "\n",
    "We will use the survival function form for numerical stability when \\(F(k)\\) is very close to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def validate_alpha(alpha: float) -> float:\n",
    "    alpha = float(alpha)\n",
    "    if not np.isfinite(alpha) or alpha <= 0:\n",
    "        raise ValueError(f\"alpha must be positive and finite; got {alpha!r}\")\n",
    "    return alpha\n",
    "\n",
    "\n",
    "_lgamma = np.vectorize(math.lgamma, otypes=[float])\n",
    "\n",
    "\n",
    "def yulesimon_logpmf(k, alpha: float) -> np.ndarray:\n",
    "    '''Log-PMF of Yule–Simon(alpha) at integer k >= 1.\n",
    "\n",
    "    Implemented with Python's `math.lgamma` (no SciPy special functions).\n",
    "    '''\n",
    "\n",
    "    alpha = validate_alpha(alpha)\n",
    "    k = np.asarray(k)\n",
    "    kf = k.astype(float)\n",
    "\n",
    "    out = np.full_like(kf, fill_value=-np.inf, dtype=float)\n",
    "    mask = (kf >= 1) & (kf == np.floor(kf))\n",
    "    if np.any(mask):\n",
    "        kv = kf[mask]\n",
    "        out[mask] = (\n",
    "            np.log(alpha)\n",
    "            + _lgamma(alpha + 1.0)\n",
    "            + _lgamma(kv)\n",
    "            - _lgamma(kv + alpha + 1.0)\n",
    "        )\n",
    "    return out\n",
    "\n",
    "\n",
    "def yulesimon_pmf(k, alpha: float) -> np.ndarray:\n",
    "    '''PMF of Yule–Simon(alpha) at k (returns 0 outside the support).'''\n",
    "    return np.exp(yulesimon_logpmf(k, alpha))\n",
    "\n",
    "\n",
    "def yulesimon_logsf(k, alpha: float) -> np.ndarray:\n",
    "    '''Log survival function log P(K > k) for integer k >= 0.\n",
    "\n",
    "    Uses: P(K > k) = alpha * B(k+1, alpha).\n",
    "    '''\n",
    "\n",
    "    alpha = validate_alpha(alpha)\n",
    "    k = np.asarray(k)\n",
    "    kf = k.astype(float)\n",
    "\n",
    "    out = np.full_like(kf, fill_value=-np.inf, dtype=float)\n",
    "\n",
    "    # For any k < 1, P(K > k) = 1 because the support starts at 1.\n",
    "    out[kf < 1] = 0.0\n",
    "\n",
    "    mask = (kf >= 1) & (kf == np.floor(kf))\n",
    "    if np.any(mask):\n",
    "        kv = kf[mask]\n",
    "        out[mask] = (\n",
    "            np.log(alpha)\n",
    "            + _lgamma(kv + 1.0)\n",
    "            + _lgamma(alpha)\n",
    "            - _lgamma(kv + alpha + 1.0)\n",
    "        )\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def yulesimon_sf(k, alpha: float) -> np.ndarray:\n",
    "    return np.exp(yulesimon_logsf(k, alpha))\n",
    "\n",
    "\n",
    "def yulesimon_cdf(x, alpha: float) -> np.ndarray:\n",
    "    '''CDF evaluated at real x via floor(x).'''\n",
    "\n",
    "    alpha = validate_alpha(alpha)\n",
    "    x = np.asarray(x)\n",
    "    k = np.floor(x)\n",
    "\n",
    "    out = np.zeros_like(k, dtype=float)\n",
    "    mask = k >= 1\n",
    "    if np.any(mask):\n",
    "        out[mask] = 1.0 - yulesimon_sf(k[mask], alpha)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388786e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity checks vs SciPy\n",
    "\n",
    "alpha = 2.5\n",
    "k = np.arange(1, 11)\n",
    "\n",
    "pmf_np = yulesimon_pmf(k, alpha)\n",
    "pmf_sp = stats.yulesimon.pmf(k, alpha)\n",
    "print(\"max |pmf numpy - scipy|:\", float(np.max(np.abs(pmf_np - pmf_sp))))\n",
    "\n",
    "x = np.array([-3.0, 0.0, 0.9, 1.0, 2.0, 5.0, 10.0])\n",
    "cdf_np = yulesimon_cdf(x, alpha)\n",
    "cdf_sp = stats.yulesimon.cdf(x, alpha)\n",
    "print(\"max |cdf numpy - scipy|:\", float(np.max(np.abs(cdf_np - cdf_sp))))\n",
    "\n",
    "# PMF should sum to 1; we can check this by truncating and adding the exact tail mass.\n",
    "K = 2000\n",
    "mass_trunc = yulesimon_pmf(np.arange(1, K + 1), alpha).sum()\n",
    "tail_mass = yulesimon_sf(K, alpha)\n",
    "print(\"mass_trunc + tail_mass:\", float(mass_trunc + tail_mass))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a4064",
   "metadata": {},
   "source": [
    "## 4) Moments & Properties\n",
    "\n",
    "### Existence of moments\n",
    "The Yule–Simon distribution is heavy-tailed. In fact, the **\\(m\\)-th raw moment** exists iff\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[K^m] < \\infty \\quad \\Longleftrightarrow \\quad \\alpha > m.\n",
    "\\]\n",
    "\n",
    "So:\n",
    "- mean exists only for \\(\\alpha>1\\)\n",
    "- variance exists only for \\(\\alpha>2\\)\n",
    "- skewness exists only for \\(\\alpha>3\\)\n",
    "- (excess) kurtosis exists only for \\(\\alpha>4\\)\n",
    "\n",
    "### Mean, variance, skewness, kurtosis\n",
    "For \\(\\alpha>1\\),\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[K] = \\frac{\\alpha}{\\alpha-1}.\n",
    "\\]\n",
    "\n",
    "For \\(\\alpha>2\\),\n",
    "\n",
    "\\[\n",
    "\\mathrm{Var}(K)=\\frac{\\alpha^2}{(\\alpha-1)^2(\\alpha-2)}.\n",
    "\\]\n",
    "\n",
    "For \\(\\alpha>3\\), the skewness is\n",
    "\n",
    "\\[\n",
    "\\gamma_1 = \\frac{(\\alpha+1)^2\\sqrt{\\alpha-2}}{\\alpha(\\alpha-3)}.\n",
    "\\]\n",
    "\n",
    "For \\(\\alpha>4\\), the **excess kurtosis** is\n",
    "\n",
    "\\[\n",
    "\\gamma_2 =\n",
    "\\frac{\\alpha^4 + 7\\alpha^3 - 9\\alpha^2 - 13\\alpha - 22}{\\alpha(\\alpha-3)(\\alpha-4)}.\n",
    "\\]\n",
    "\n",
    "(The kurtosis is \\(\\gamma_2 + 3\\).)\n",
    "\n",
    "### PGF / MGF / characteristic function\n",
    "A useful analytic object for discrete distributions is the probability generating function (PGF)\n",
    "\n",
    "\\[\n",
    "G(z)=\\mathbb{E}[z^K], \\qquad |z|<1.\n",
    "\\]\n",
    "\n",
    "For Yule–Simon,\n",
    "\n",
    "\\[\n",
    "G(z)=\\frac{\\alpha z}{\\alpha+1}\\,{}_2F_1(1,1;\\alpha+2;z),\n",
    "\\]\n",
    "\n",
    "where \\({}_2F_1\\) is the Gauss hypergeometric function.\n",
    "\n",
    "- The **MGF** is \\(M(t)=\\mathbb{E}[e^{tK}]=G(e^t)\\), which is finite for \\(t<0\\) (since \\(e^t<1\\)).\n",
    "  It diverges for any \\(t>0\\) because of the power-law tail.\n",
    "- The **characteristic function** is \\(\\varphi(t)=\\mathbb{E}[e^{itK}]=G(e^{it})\\).\n",
    "  It exists for all real \\(t\\), though numerical evaluation at \\(t=0\\) should be handled carefully.\n",
    "\n",
    "### Entropy\n",
    "The Shannon entropy is\n",
    "\n",
    "\\[\n",
    "H(K)=-\\sum_{k=1}^\\infty p(k)\\log p(k).\n",
    "\\]\n",
    "\n",
    "It is finite for all \\(\\alpha>0\\), but (to my knowledge) there is no simple closed form; we can evaluate it numerically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a31f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yulesimon_theoretical_stats(alpha: float) -> dict:\n",
    "    alpha = validate_alpha(alpha)\n",
    "\n",
    "    mean = np.inf if alpha <= 1 else alpha / (alpha - 1)\n",
    "    var = np.inf if alpha <= 2 else alpha**2 / ((alpha - 1) ** 2 * (alpha - 2))\n",
    "\n",
    "    skew = (\n",
    "        np.inf\n",
    "        if alpha <= 3\n",
    "        else ((alpha + 1) ** 2 * np.sqrt(alpha - 2)) / (alpha * (alpha - 3))\n",
    "    )\n",
    "\n",
    "    excess_kurt = (\n",
    "        np.inf\n",
    "        if alpha <= 4\n",
    "        else (alpha**4 + 7 * alpha**3 - 9 * alpha**2 - 13 * alpha - 22)\n",
    "        / (alpha * (alpha - 3) * (alpha - 4))\n",
    "    )\n",
    "    kurt = np.inf if alpha <= 4 else excess_kurt + 3\n",
    "\n",
    "    return {\n",
    "        \"alpha\": alpha,\n",
    "        \"mean\": mean,\n",
    "        \"var\": var,\n",
    "        \"skew\": skew,\n",
    "        \"kurt\": kurt,\n",
    "        \"excess_kurt\": excess_kurt,\n",
    "    }\n",
    "\n",
    "\n",
    "def yulesimon_pgf(z, alpha: float):\n",
    "    '''Probability generating function G(z)=E[z^K] for |z|<1.'''\n",
    "\n",
    "    alpha = validate_alpha(alpha)\n",
    "    z = np.asarray(z, dtype=complex)\n",
    "    return (alpha * z / (alpha + 1.0)) * special.hyp2f1(1.0, 1.0, alpha + 2.0, z)\n",
    "\n",
    "\n",
    "def yulesimon_mgf(t, alpha: float):\n",
    "    '''MGF M(t)=E[e^{tK}] (finite for t<0).'''\n",
    "\n",
    "    t = np.asarray(t, dtype=float)\n",
    "    if np.any(t >= 0):\n",
    "        raise ValueError(\"MGF diverges for t >= 0 (heavy tail); use t < 0\")\n",
    "    return yulesimon_pgf(np.exp(t), alpha)\n",
    "\n",
    "\n",
    "def yulesimon_cf(t, alpha: float):\n",
    "    '''Characteristic function phi(t)=E[e^{itK}].'''\n",
    "\n",
    "    t = np.asarray(t, dtype=float)\n",
    "    out = yulesimon_pgf(np.exp(1j * t), alpha)\n",
    "    out = np.where(t == 0, 1.0 + 0j, out)\n",
    "    return out\n",
    "\n",
    "\n",
    "for a in [1.5, 2.5, 5.0]:\n",
    "    mvsk = stats.yulesimon.stats(a, moments=\"mvsk\")\n",
    "    ent = stats.yulesimon.entropy(a)\n",
    "\n",
    "    print()\n",
    "    print(f\"alpha={a}\")\n",
    "    print(\"theory (closed form when finite):\", yulesimon_theoretical_stats(a))\n",
    "    print(\"SciPy stats (mean, var, skew, kurt):\", tuple(float(x) for x in mvsk))\n",
    "    print(\"SciPy entropy:\", float(ent))\n",
    "\n",
    "# MGF spot-check for a negative t\n",
    "alpha = 3.5\n",
    "t = -0.3\n",
    "print()\n",
    "print(\"MGF(t) at t=-0.3 (complex rounding):\", complex(yulesimon_mgf(t, alpha)))\n",
    "print(\"CF(t) at t=0.7:\", complex(yulesimon_cf(0.7, alpha)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ddde07",
   "metadata": {},
   "source": [
    "## 5) Parameter Interpretation\n",
    "\n",
    "The single shape parameter \\(\\alpha\\) controls **tail heaviness**.\n",
    "\n",
    "- Smaller \\(\\alpha\\) \\(\\Rightarrow\\) heavier tail (large counts become more likely).\n",
    "- Larger \\(\\alpha\\) \\(\\Rightarrow\\) faster decay and more mass near 1.\n",
    "\n",
    "Two useful facts:\n",
    "\n",
    "1. **Tail exponent**: as \\(k\\to\\infty\\),\n",
    "\n",
    "\\[\n",
    "\\mathbb{P}(K=k) \\sim \\alpha\\,\\Gamma(\\alpha+1)\\,k^{-(\\alpha+1)}.\n",
    "\\]\n",
    "\n",
    "So \\(\\alpha\\) directly controls the power-law exponent.\n",
    "\n",
    "2. **Moment thresholds**: the mean/variance/etc exist only when \\(\\alpha\\) is above the corresponding order.\n",
    "This matters in practice: for \\(\\alpha \\le 2\\), the empirical variance can be dominated by rare extreme samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08459e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape changes as alpha varies\n",
    "\n",
    "alphas = [0.7, 1.2, 2.5, 5.0, 10.0]\n",
    "k = np.arange(1, 60)\n",
    "\n",
    "fig = go.Figure()\n",
    "for a in alphas:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=k,\n",
    "            y=stats.yulesimon.pmf(k, a),\n",
    "            mode=\"lines+markers\",\n",
    "            name=f\"alpha={a}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Yule–Simon PMF for different α (log–log view)\",\n",
    "    xaxis_title=\"k\",\n",
    "    yaxis_title=\"P(K=k)\",\n",
    ")\n",
    "fig.update_xaxes(type=\"log\")\n",
    "fig.update_yaxes(type=\"log\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8fe1b6",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "A very convenient representation is a **Beta–geometric mixture**.\n",
    "\n",
    "### 6.1 PMF via a mixture\n",
    "Let\n",
    "- \\(P \\sim \\mathrm{Beta}(\\alpha, 1)\\) with density \\(f(p)=\\alpha p^{\\alpha-1}\\) on \\(0<p<1\\)\n",
    "- \\(K\\mid P=p \\sim \\mathrm{Geometric}(p)\\) on \\(\\{1,2,\\dots\\}\\), i.e.\n",
    "  \\(\\mathbb{P}(K=k\\mid p)=p(1-p)^{k-1}\\)\n",
    "\n",
    "Then the marginal PMF is\n",
    "\n",
    "\\[\n",
    "\\mathbb{P}(K=k)\n",
    "= \\int_0^1 p(1-p)^{k-1}\\,\\alpha p^{\\alpha-1}\\,dp\n",
    "= \\alpha\\int_0^1 p^{\\alpha}(1-p)^{k-1}\\,dp\n",
    "= \\alpha\\,B(k,\\alpha+1).\n",
    "\\]\n",
    "\n",
    "### 6.2 Expectation\n",
    "Using the law of total expectation and the fact that \\(\\mathbb{E}[K\\mid P=p]=1/p\\),\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[K] = \\mathbb{E}[\\mathbb{E}[K\\mid P]]\n",
    "= \\mathbb{E}\\left[\\frac{1}{P}\\right]\n",
    "= \\alpha\\int_0^1 p^{\\alpha-2}\\,dp\n",
    "= \\frac{\\alpha}{\\alpha-1},\n",
    "\\]\n",
    "\n",
    "which is finite only for \\(\\alpha>1\\).\n",
    "\n",
    "### 6.3 Variance\n",
    "Using the law of total variance,\n",
    "\n",
    "\\[\n",
    "\\mathrm{Var}(K)=\\mathbb{E}[\\mathrm{Var}(K\\mid P)] + \\mathrm{Var}(\\mathbb{E}[K\\mid P]).\n",
    "\\]\n",
    "\n",
    "For the geometric distribution on \\(\\{1,2,\\dots\\}\\),\n",
    "\\(\\mathrm{Var}(K\\mid p)=(1-p)/p^2\\) and \\(\\mathbb{E}[K\\mid p]=1/p\\). So\n",
    "\n",
    "\\[\n",
    "\\mathrm{Var}(K)=\\mathbb{E}\\left[\\frac{1-P}{P^2}\\right] + \\mathrm{Var}\\left(\\frac{1}{P}\\right)\n",
    "= \\frac{\\alpha^2}{(\\alpha-1)^2(\\alpha-2)},\n",
    "\\]\n",
    "\n",
    "finite only for \\(\\alpha>2\\).\n",
    "\n",
    "### 6.4 Likelihood\n",
    "Given i.i.d. data \\(k_1,\\dots,k_n\\) (each \\(k_i\\in\\{1,2,\\dots\\}\\)), the log-likelihood is\n",
    "\n",
    "\\[\n",
    "\\ell(\\alpha)\n",
    "= \\sum_{i=1}^n \\log \\mathbb{P}(K=k_i\\mid \\alpha)\n",
    "= n\\log\\alpha + n\\log\\Gamma(\\alpha+1)\n",
    "+ \\sum_{i=1}^n \\log\\Gamma(k_i)\n",
    "- \\sum_{i=1}^n \\log\\Gamma(k_i+\\alpha+1).\n",
    "\\]\n",
    "\n",
    "Differentiating gives the score equation (using the digamma function \\(\\psi=\\Gamma'/\\Gamma\\)):\n",
    "\n",
    "\\[\n",
    "\\frac{d\\ell}{d\\alpha}\n",
    "= \\frac{n}{\\alpha} + n\\psi(\\alpha+1) - \\sum_{i=1}^n \\psi(k_i+\\alpha+1) = 0,\n",
    "\\]\n",
    "\n",
    "which can be solved numerically for the MLE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fe163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yulesimon_loglik(alpha: float, data: np.ndarray) -> float:\n",
    "    '''Log-likelihood for i.i.d. sample from Yule–Simon(alpha).'''\n",
    "\n",
    "    alpha = validate_alpha(alpha)\n",
    "    data = np.asarray(data)\n",
    "\n",
    "    if np.any(data < 1) or np.any(np.floor(data) != data):\n",
    "        raise ValueError(\"All observations must be integers >= 1\")\n",
    "\n",
    "    n = data.size\n",
    "    return (\n",
    "        n * np.log(alpha)\n",
    "        + n * special.gammaln(alpha + 1.0)\n",
    "        + np.sum(special.gammaln(data))\n",
    "        - np.sum(special.gammaln(data + alpha + 1.0))\n",
    "    )\n",
    "\n",
    "\n",
    "def yulesimon_score(alpha: float, data: np.ndarray) -> float:\n",
    "    '''Derivative of log-likelihood w.r.t. alpha.'''\n",
    "\n",
    "    alpha = validate_alpha(alpha)\n",
    "    data = np.asarray(data)\n",
    "    n = data.size\n",
    "\n",
    "    return float(\n",
    "        n / alpha\n",
    "        + n * special.digamma(alpha + 1.0)\n",
    "        - np.sum(special.digamma(data + alpha + 1.0))\n",
    "    )\n",
    "\n",
    "\n",
    "# Fit alpha by MLE on simulated data\n",
    "alpha_true = 2.5\n",
    "n = 5000\n",
    "data = stats.yulesimon.rvs(alpha_true, size=n, random_state=rng)\n",
    "\n",
    "res = optimize.minimize_scalar(\n",
    "    lambda a: -yulesimon_loglik(a, data), bounds=(1e-6, 50.0), method=\"bounded\"\n",
    ")\n",
    "alpha_hat = float(res.x)\n",
    "\n",
    "fit_res = stats.fit(\n",
    "    stats.yulesimon,\n",
    "    data,\n",
    "    bounds={\"alpha\": (1e-6, 50.0), \"loc\": (0, 0)},\n",
    "    guess={\"alpha\": alpha_hat, \"loc\": 0},\n",
    ")\n",
    "\n",
    "print(\"alpha_true:\", alpha_true)\n",
    "print(\"alpha_hat (MLE via minimize_scalar):\", alpha_hat)\n",
    "print(\"score(alpha_hat):\", yulesimon_score(alpha_hat, data))\n",
    "print(\"SciPy stats.fit params:\", fit_res.params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673a432a",
   "metadata": {},
   "source": [
    "## 7) Sampling & Simulation (NumPy-only)\n",
    "\n",
    "Using the Beta–geometric mixture gives a simple sampler.\n",
    "\n",
    "1. Draw \\(U \\sim \\mathrm{Uniform}(0,1)\\) and set \\(P = U^{1/\\alpha}\\).\n",
    "   This works because if \\(P \\sim \\mathrm{Beta}(\\alpha,1)\\), then \\(P = U^{1/\\alpha}\\) in distribution.\n",
    "2. Given \\(P=p\\), draw \\(K\\mid P=p \\sim \\mathrm{Geometric}(p)\\) on \\(\\{1,2,\\dots\\}\\).\n",
    "\n",
    "For the geometric step we can use inverse transform sampling:\n",
    "\n",
    "\\[\n",
    "K = 1 + \\left\\lfloor \\frac{\\log V}{\\log(1-p)} \\right\\rfloor,\\qquad V\\sim \\mathrm{Uniform}(0,1),\n",
    "\\]\n",
    "\n",
    "(where \\(\\log(1-p)<0\\)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0cc88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yulesimon_rvs_numpy(alpha: float, size: int, rng: np.random.Generator | None = None):\n",
    "    '''Sample from Yule–Simon(alpha) using only NumPy + standard library math.\n",
    "\n",
    "    Returns samples on {1, 2, ...}.\n",
    "    '''\n",
    "\n",
    "    alpha = validate_alpha(alpha)\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    size = int(size)\n",
    "\n",
    "    # Step 1: P ~ Beta(alpha, 1) via inverse transform: P = U^(1/alpha)\n",
    "    u = rng.random(size)\n",
    "    u = np.clip(u, np.finfo(float).tiny, 1.0)\n",
    "    p = u ** (1.0 / alpha)\n",
    "\n",
    "    # Step 2: K | P=p ~ Geometric(p) on {1,2,...}\n",
    "    v = rng.random(size)\n",
    "    v = np.clip(v, np.finfo(float).tiny, 1.0)\n",
    "\n",
    "    # Use log1p(-p) for stability when p is small.\n",
    "    k = 1 + np.floor(np.log(v) / np.log1p(-p))\n",
    "    return k.astype(int)\n",
    "\n",
    "\n",
    "alpha = 2.5\n",
    "samples = yulesimon_rvs_numpy(alpha, size=200_000, rng=rng)\n",
    "\n",
    "print(\"min/max:\", int(samples.min()), int(samples.max()))\n",
    "print(\"sample mean:\", float(samples.mean()))\n",
    "print(\"sample var:\", float(samples.var()))\n",
    "print(\"theoretical:\", yulesimon_theoretical_stats(alpha))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7289564",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We’ll visualize:\n",
    "- the PMF (including a log–log view for tail behavior)\n",
    "- the CDF / survival function\n",
    "- Monte Carlo samples compared to the theoretical distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 2.5\n",
    "\n",
    "# PMF/CDF for small k\n",
    "k_small = np.arange(1, 31)\n",
    "pmf = stats.yulesimon.pmf(k_small, alpha)\n",
    "cdf = stats.yulesimon.cdf(k_small, alpha)\n",
    "\n",
    "fig_pmf = go.Figure()\n",
    "fig_pmf.add_trace(go.Bar(x=k_small, y=pmf, name=\"PMF\"))\n",
    "fig_pmf.update_layout(\n",
    "    title=f\"Yule–Simon PMF (alpha={alpha})\",\n",
    "    xaxis_title=\"k\",\n",
    "    yaxis_title=\"P(K=k)\",\n",
    ")\n",
    "fig_pmf.show()\n",
    "\n",
    "fig_cdf = go.Figure()\n",
    "fig_cdf.add_trace(go.Scatter(x=k_small, y=cdf, mode=\"lines+markers\", name=\"CDF\"))\n",
    "fig_cdf.update_layout(\n",
    "    title=f\"Yule–Simon CDF (alpha={alpha})\",\n",
    "    xaxis_title=\"k\",\n",
    "    yaxis_title=\"P(K ≤ k)\",\n",
    ")\n",
    "fig_cdf.show()\n",
    "\n",
    "# Monte Carlo vs theory (empirical CDF and survival)\n",
    "mc = stats.yulesimon.rvs(alpha, size=80_000, random_state=rng)\n",
    "mc_sorted = np.sort(mc)\n",
    "\n",
    "k_tail = np.arange(1, 200)\n",
    "emp_cdf = np.searchsorted(mc_sorted, k_tail, side=\"right\") / mc_sorted.size\n",
    "emp_sf = 1.0 - emp_cdf\n",
    "\n",
    "theo_sf = stats.yulesimon.sf(k_tail, alpha)\n",
    "\n",
    "fig_tail = go.Figure()\n",
    "fig_tail.add_trace(go.Scatter(x=k_tail, y=theo_sf, mode=\"lines\", name=\"theory sf\"))\n",
    "fig_tail.add_trace(\n",
    "    go.Scatter(x=k_tail, y=emp_sf, mode=\"markers\", name=\"empirical sf\", opacity=0.6)\n",
    ")\n",
    "fig_tail.update_layout(\n",
    "    title=f\"Survival function on log–log scale (alpha={alpha})\",\n",
    "    xaxis_title=\"k\",\n",
    "    yaxis_title=\"P(K > k)\",\n",
    ")\n",
    "fig_tail.update_xaxes(type=\"log\")\n",
    "fig_tail.update_yaxes(type=\"log\")\n",
    "fig_tail.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ccfcac",
   "metadata": {},
   "source": [
    "## 9) SciPy Integration\n",
    "\n",
    "SciPy implements this distribution as `scipy.stats.yulesimon` with shape parameter `alpha` and optional `loc`.\n",
    "\n",
    "Common methods:\n",
    "- `stats.yulesimon.pmf(k, alpha, loc=0)`\n",
    "- `stats.yulesimon.cdf(k, alpha, loc=0)`\n",
    "- `stats.yulesimon.rvs(alpha, loc=0, size=..., random_state=...)`\n",
    "\n",
    "For fitting, use `scipy.stats.fit` (note: the distribution object itself does not have a `.fit` method):\n",
    "- `stats.fit(stats.yulesimon, data, bounds=..., method='mle')`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776d8c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 2.5\n",
    "k = np.arange(1, 6)\n",
    "\n",
    "print(\"pmf:\", stats.yulesimon.pmf(k, alpha))\n",
    "print(\"cdf:\", stats.yulesimon.cdf(k, alpha))\n",
    "print(\"rvs:\", stats.yulesimon.rvs(alpha, size=10, random_state=rng))\n",
    "\n",
    "# Fit alpha (and optionally loc). Here we fix loc=0.\n",
    "data = stats.yulesimon.rvs(alpha, size=2000, random_state=rng)\n",
    "fit_res = stats.fit(\n",
    "    stats.yulesimon, data, bounds={\"alpha\": (1e-6, 50.0), \"loc\": (0, 0)}\n",
    ")\n",
    "print(\"fit params:\", fit_res.params)\n",
    "print(\"negative log-likelihood at fit:\", float(fit_res.nllf()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b494e",
   "metadata": {},
   "source": [
    "## 10) Statistical Use Cases\n",
    "\n",
    "### 10.1 Hypothesis testing / goodness-of-fit\n",
    "- **Goodness-of-fit**: fit \\(\\alpha\\) by MLE and compare observed frequencies to expected frequencies (e.g., a chi-square test with sensible binning, or a parametric bootstrap).\n",
    "- **Model comparison**: compare log-likelihoods / information criteria between heavy-tailed candidates (Yule–Simon, Zipf, negative binomial, etc.).\n",
    "\n",
    "### 10.2 Bayesian modeling\n",
    "In Bayesian settings, \\(\\alpha\\) can be given a prior (e.g., Gamma prior on \\(\\alpha\\)) and inferred from data using:\n",
    "- grid approximation (1D problems)\n",
    "- MCMC / HMC (more complex models)\n",
    "- variational inference (large-scale)\n",
    "\n",
    "The likelihood is easy to evaluate in log space, which is helpful for posterior computation.\n",
    "\n",
    "### 10.3 Generative modeling\n",
    "Yule–Simon shows up as the stationary/limiting distribution of **preferential attachment** mechanisms.\n",
    "A classic example is **Simon’s model**: with probability \\(p_{\\text{new}}\\) create a new category; otherwise, copy an existing category proportional to its current count.\n",
    "The induced category-size distribution has a Yule–Simon-like heavy tail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e12d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.1 Goodness-of-fit (illustration): chi-square with a tail bin\n",
    "\n",
    "alpha_true = 2.5\n",
    "n = 5000\n",
    "x = stats.yulesimon.rvs(alpha_true, size=n, random_state=rng)\n",
    "\n",
    "# Fit alpha by MLE (loc fixed at 0)\n",
    "res = optimize.minimize_scalar(\n",
    "    lambda a: -yulesimon_loglik(a, x), bounds=(1e-6, 50.0), method=\"bounded\"\n",
    ")\n",
    "alpha_hat = float(res.x)\n",
    "\n",
    "k_max = 12  # bins: 1..k_max-1, plus tail (>=k_max)\n",
    "obs = np.array([(x == k).sum() for k in range(1, k_max)] + [(x >= k_max).sum()])\n",
    "\n",
    "probs = np.append(\n",
    "    stats.yulesimon.pmf(np.arange(1, k_max), alpha_hat),\n",
    "    stats.yulesimon.sf(k_max - 1, alpha_hat),\n",
    ")\n",
    "exp = n * probs\n",
    "\n",
    "chi2, p_value = stats.chisquare(f_obs=obs, f_exp=exp)\n",
    "\n",
    "print(\"alpha_true:\", alpha_true)\n",
    "print(\"alpha_hat:\", alpha_hat)\n",
    "print(\"obs counts:\", obs)\n",
    "print(\"exp counts:\", np.round(exp, 2))\n",
    "print(\"chi2:\", float(chi2))\n",
    "print(\"p-value (naive df; alpha was estimated):\", float(p_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a8c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.2 Bayesian modeling (illustration): 1D grid posterior for alpha\n",
    "\n",
    "x = stats.yulesimon.rvs(2.5, size=1500, random_state=rng)\n",
    "\n",
    "alpha_grid = np.linspace(0.2, 10.0, 500)\n",
    "\n",
    "# Prior: Gamma(a=2, scale=2) (mean=4)\n",
    "log_prior = stats.gamma.logpdf(alpha_grid, a=2.0, scale=2.0)\n",
    "\n",
    "log_like = np.array([yulesimon_loglik(a, x) for a in alpha_grid])\n",
    "\n",
    "log_post = log_prior + log_like\n",
    "log_post -= np.max(log_post)\n",
    "post_unnorm = np.exp(log_post)\n",
    "\n",
    "# Normalize (continuous approximation)\n",
    "post = post_unnorm / np.trapz(post_unnorm, alpha_grid)\n",
    "\n",
    "alpha_map = float(alpha_grid[np.argmax(post)])\n",
    "alpha_mean = float(np.trapz(alpha_grid * post, alpha_grid))\n",
    "\n",
    "print(\"posterior MAP:\", alpha_map)\n",
    "print(\"posterior mean:\", alpha_mean)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=alpha_grid, y=post, mode=\"lines\", name=\"posterior\"))\n",
    "fig.add_vline(x=alpha_map, line_dash=\"dash\", line_color=\"black\", annotation_text=\"MAP\")\n",
    "fig.update_layout(\n",
    "    title=\"Posterior over α (grid approximation)\",\n",
    "    xaxis_title=\"alpha\",\n",
    "    yaxis_title=\"density\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d39de0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.3 Generative modeling: Simon's preferential-attachment process\n",
    "\n",
    "\n",
    "def simon_process_counts(T: int, p_new: float, rng: np.random.Generator) -> np.ndarray:\n",
    "    '''Simon's model.\n",
    "\n",
    "    At each step t:\n",
    "    - with probability p_new: create a new category\n",
    "    - otherwise: pick a previous token uniformly and copy its category\n",
    "\n",
    "    Copying a previous token chooses categories proportional to their current counts.\n",
    "    Returns the final category counts.\n",
    "    '''\n",
    "\n",
    "    if not (0.0 < p_new < 1.0):\n",
    "        raise ValueError(\"p_new must be in (0,1)\")\n",
    "\n",
    "    owners = np.empty(T, dtype=int)\n",
    "    counts = np.zeros(T, dtype=int)\n",
    "\n",
    "    owners[0] = 0\n",
    "    counts[0] = 1\n",
    "    n_types = 1\n",
    "\n",
    "    for t in range(1, T):\n",
    "        if rng.random() < p_new:\n",
    "            type_id = n_types\n",
    "            n_types += 1\n",
    "            counts[type_id] = 1\n",
    "        else:\n",
    "            type_id = owners[rng.integers(t)]\n",
    "            counts[type_id] += 1\n",
    "\n",
    "        owners[t] = type_id\n",
    "\n",
    "    return counts[:n_types]\n",
    "\n",
    "\n",
    "T = 50_000\n",
    "p_new = 0.2\n",
    "alpha_theory = 1.0 / (1.0 - p_new)\n",
    "\n",
    "counts = simon_process_counts(T=T, p_new=p_new, rng=rng)\n",
    "\n",
    "k = np.arange(1, 60)\n",
    "emp_pmf = np.array([(counts == kk).mean() for kk in k])\n",
    "theo_pmf = stats.yulesimon.pmf(k, alpha_theory)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=k, y=emp_pmf, mode=\"markers\", name=\"Simon empirical\", opacity=0.7)\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=k, y=theo_pmf, mode=\"lines\", name=f\"Yule–Simon α={alpha_theory:.3f}\"))\n",
    "fig.update_layout(\n",
    "    title=\"Category-size distribution from Simon's model vs Yule–Simon\",\n",
    "    xaxis_title=\"k (category size)\",\n",
    "    yaxis_title=\"fraction of categories of size k\",\n",
    ")\n",
    "fig.update_xaxes(type=\"log\")\n",
    "fig.update_yaxes(type=\"log\")\n",
    "fig.show()\n",
    "\n",
    "print(\"T:\", T)\n",
    "print(\"number of categories:\", counts.size)\n",
    "print(\"largest category size:\", int(counts.max()))\n",
    "print(\"alpha_theory (from p_new):\", alpha_theory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc218a2f",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Invalid parameters**: \\(\\alpha\\) must be positive. In SciPy, passing non-positive values will produce errors or `nan`.\n",
    "- **Infinite moments**: remember the thresholds:\n",
    "  - \\(\\alpha\\le 1\\): mean is infinite\n",
    "  - \\(\\alpha\\le 2\\): variance is infinite\n",
    "  - \\(\\alpha\\le 3\\): skewness is infinite\n",
    "  - \\(\\alpha\\le 4\\): kurtosis is infinite\n",
    "\n",
    "  In finite samples you will still get finite empirical moments, but they can be extremely unstable.\n",
    "- **Numerical issues**:\n",
    "  - For large \\(k\\), the PMF is tiny; compute in log space (`logpmf`) when doing likelihood work.\n",
    "  - For large \\(k\\), the CDF can be extremely close to 1; using `sf`/`logsf` is usually more stable.\n",
    "  - SciPy’s entropy and higher moments may warn about slow convergence for heavy tails.\n",
    "- **Sampling extremes**: because of the heavy tail, maximum values in a sample can be surprisingly large even when the mean is finite.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e908157f",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `yulesimon` is a **discrete, heavy-tailed** distribution on \\(\\{1,2,\\dots\\}\\) with shape parameter \\(\\alpha>0\\).\n",
    "- The PMF is \\(p(k)=\\alpha B(k,\\alpha+1)\\) and the CDF has a simple survival-function form \\(\\mathbb{P}(K>k)=\\alpha B(k+1,\\alpha)\\).\n",
    "- The \\(m\\)-th moment exists iff \\(\\alpha>m\\); in particular, mean requires \\(\\alpha>1\\) and variance requires \\(\\alpha>2\\).\n",
    "- A clean sampler comes from the **Beta–geometric mixture**: \\(P\\sim\\mathrm{Beta}(\\alpha,1)\\), then \\(K\\mid P\\sim\\mathrm{Geometric}(P)\\).\n",
    "- SciPy’s `stats.yulesimon` provides PMF/CDF/SF/RVS, and `stats.fit` can estimate parameters by MLE.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
