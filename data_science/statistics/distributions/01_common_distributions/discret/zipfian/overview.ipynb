{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cda6f061",
   "metadata": {},
   "source": [
    "# Zipfian distribution (`zipfian`)\n",
    "\n",
    "The **Zipfian** distribution is a **discrete power-law** distribution over **ranks**. It is commonly used when a few items are very frequent (low ranks) and many items are rare (high ranks).\n",
    "\n",
    "Throughout, we’ll use SciPy’s parameterization `scipy.stats.zipfian(a, n)`, which is a **finite-support** (truncated) Zipf law on ranks $\\{1,\\dots,n\\}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d1e3b",
   "metadata": {},
   "source": [
    "## Notebook roadmap\n",
    "\n",
    "1. Define the distribution (PMF/CDF) and connect it to Zipf’s law.\n",
    "2. Work out moments/properties (including when moments exist in the $n\\to\\infty$ limit).\n",
    "3. Derive likelihood and a practical MLE for the exponent.\n",
    "4. Implement NumPy-only sampling via inverse transform.\n",
    "5. Visualize PMF/CDF and Monte Carlo behavior.\n",
    "6. Use SciPy’s `zipfian` for evaluation, sampling, and fitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5198b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "\n",
    "SEED = 7\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "print(\"numpy:\", np.__version__)\n",
    "import scipy\n",
    "print(\"scipy:\", scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7499050",
   "metadata": {},
   "source": [
    "## 1) Title & Classification\n",
    "\n",
    "- **Name**: `zipfian` (Zipfian / truncated Zipf law)\n",
    "- **Type**: **Discrete**\n",
    "- **Support** (SciPy default `loc=0`):\n",
    "\n",
    "  $$\\mathcal{S}=\\{1,2,\\dots,n\\}$$\n",
    "\n",
    "  With a location shift `loc`, the support becomes $\\{\\text{loc}+1,\\dots,\\text{loc}+n\\}$.\n",
    "\n",
    "- **Parameter space** (SciPy):\n",
    "\n",
    "  $$a>0,\\qquad n\\in\\{1,2,3,\\dots\\}$$\n",
    "\n",
    "  where:\n",
    "  - $a$ is the **exponent** (controls tail heaviness)\n",
    "  - $n$ is the **maximum rank** (finite truncation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008180e7",
   "metadata": {},
   "source": [
    "## 2) Intuition & Motivation\n",
    "\n",
    "### What it models\n",
    "A Zipfian distribution models **ranked outcomes** where the probability of rank $k$ decays approximately like a **power law**:\n",
    "\n",
    "$$\\Pr(X=k) \\propto k^{-a}. $$\n",
    "\n",
    "This captures “**few head, long tail**” behavior: rank 1 is common, rank 2 is less common, and so on, with many rare high-rank outcomes.\n",
    "\n",
    "### Typical real-world use cases\n",
    "- **Word frequencies** (Zipf’s law): common words occur extremely often; most words are rare.\n",
    "- **Popularity / demand**: product views, song plays, page visits (ranked by popularity).\n",
    "- **Discrete heavy tails with a hard cutoff**: when only the top $n$ ranks are possible (finite catalog / vocabulary).\n",
    "\n",
    "### Relations to other distributions\n",
    "- **`scipy.stats.zipf`**: the *infinite-support* Zipf / zeta distribution on $\\{1,2,\\dots\\}$.\n",
    "- **Pareto** (continuous analogue): power law on $[x_{\\min},\\infty)$.\n",
    "- **Truncation**: `zipfian` is essentially a **truncated power law**; as $n\\to\\infty$ and $a>1$, it approaches the zeta distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331040d1",
   "metadata": {},
   "source": [
    "## 3) Formal Definition\n",
    "\n",
    "Define the **generalized harmonic number**\n",
    "\n",
    "$$H_{n,a}=\\sum_{j=1}^{n} j^{-a}. $$\n",
    "\n",
    "### PMF\n",
    "For $k\\in\\{1,\\dots,n\\}$,\n",
    "\n",
    "$$\\Pr(X=k\\mid a,n) = \\frac{k^{-a}}{H_{n,a}}. $$\n",
    "\n",
    "(And $\\Pr(X=k)=0$ outside the support.)\n",
    "\n",
    "### CDF\n",
    "For real $x$,\n",
    "\n",
    "$$F(x)=\\Pr(X\\le x)=\\begin{cases}\n",
    "0, & x<1\\\\\n",
    "\\frac{1}{H_{n,a}}\\sum_{j=1}^{\\lfloor x\\rfloor} j^{-a}, & 1\\le x<n\\\\\n",
    "1, & x\\ge n.\n",
    "\\end{cases}$$\n",
    "\n",
    "Because the distribution is discrete, the CDF is a **step function**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51b521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_a_n(a, n):\n",
    "    a = float(a)\n",
    "    if not np.isfinite(a) or a <= 0.0:\n",
    "        raise ValueError(\"a must be a finite float > 0\")\n",
    "\n",
    "    if isinstance(n, bool) or not isinstance(n, (int, np.integer)):\n",
    "        raise TypeError(\"n must be an integer\")\n",
    "    n_int = int(n)\n",
    "    if n_int < 1:\n",
    "        raise ValueError(\"n must be >= 1\")\n",
    "\n",
    "    return a, n_int\n",
    "\n",
    "\n",
    "def _logsumexp_np(log_w: np.ndarray) -> float:\n",
    "    # NumPy-only stable log-sum-exp for 1D arrays.\n",
    "    log_w = np.asarray(log_w, dtype=float)\n",
    "    m = np.max(log_w)\n",
    "    if not np.isfinite(m):\n",
    "        return float(m)\n",
    "    return float(m + np.log(np.sum(np.exp(log_w - m))))\n",
    "\n",
    "\n",
    "def zipfian_logZ(a: float, n: int) -> float:\n",
    "    # log H_{n,a} computed stably.\n",
    "    a, n = _validate_a_n(a, n)\n",
    "    ks = np.arange(1, n + 1, dtype=float)\n",
    "    return _logsumexp_np(-a * np.log(ks))\n",
    "\n",
    "\n",
    "def zipfian_logpmf(k, a: float, n: int):\n",
    "    # Log PMF for the Zipfian distribution on {1,...,n}.\n",
    "    a, n = _validate_a_n(a, n)\n",
    "\n",
    "    k_arr = np.asarray(k)\n",
    "    out = np.full(k_arr.shape, -np.inf, dtype=float)\n",
    "\n",
    "    k_int = k_arr.astype(int)\n",
    "    valid = (k_int == k_arr) & (k_int >= 1) & (k_int <= n)\n",
    "    if not np.any(valid):\n",
    "        return out\n",
    "\n",
    "    logZ = zipfian_logZ(a, n)\n",
    "    out[valid] = -a * np.log(k_int[valid]) - logZ\n",
    "    return out\n",
    "\n",
    "\n",
    "def zipfian_pmf(k, a: float, n: int):\n",
    "    return np.exp(zipfian_logpmf(k, a, n))\n",
    "\n",
    "\n",
    "def zipfian_pmf_array(a: float, n: int):\n",
    "    # Return support ks and PMF values as arrays.\n",
    "    a, n = _validate_a_n(a, n)\n",
    "\n",
    "    ks = np.arange(1, n + 1)\n",
    "    logZ = zipfian_logZ(a, n)\n",
    "    pmf = np.exp(-a * np.log(ks) - logZ)\n",
    "    pmf = pmf / pmf.sum()  # guard against floating drift\n",
    "    return ks, pmf\n",
    "\n",
    "\n",
    "def zipfian_cdf(x, a: float, n: int):\n",
    "    # CDF as a step function using the PMF array.\n",
    "    a, n = _validate_a_n(a, n)\n",
    "\n",
    "    x_arr = np.asarray(x)\n",
    "    ks, pmf = zipfian_pmf_array(a, n)\n",
    "    cdf_vals = np.cumsum(pmf)\n",
    "    cdf_vals = np.clip(cdf_vals, 0.0, 1.0)\n",
    "\n",
    "    k = np.floor(x_arr).astype(int)\n",
    "    out = np.zeros_like(x_arr, dtype=float)\n",
    "\n",
    "    out[x_arr >= n] = 1.0\n",
    "\n",
    "    inside = (x_arr >= 1) & (x_arr < n)\n",
    "    if np.any(inside):\n",
    "        out[inside] = cdf_vals[k[inside] - 1]\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Quick sanity check\n",
    "a, n = 1.3, 20\n",
    "ks, pmf = zipfian_pmf_array(a, n)\n",
    "print(\"sum pmf:\", pmf.sum())\n",
    "print(\"cdf(n):\", zipfian_cdf(n, a, n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f11c7",
   "metadata": {},
   "source": [
    "## 4) Moments & Properties\n",
    "\n",
    "A convenient way to express moments uses the generalized harmonic numbers.\n",
    "\n",
    "### Raw moments\n",
    "For integer $m\\ge 0$,\n",
    "\n",
    "$$\\mathbb{E}[X^m]=\\sum_{k=1}^{n} k^m\\,\\frac{k^{-a}}{H_{n,a}} = \\frac{\\sum_{k=1}^{n} k^{m-a}}{H_{n,a}} = \\frac{H_{n,a-m}}{H_{n,a}}. $$\n",
    "\n",
    "In particular:\n",
    "\n",
    "$$\\mathbb{E}[X]=\\frac{H_{n,a-1}}{H_{n,a}},\\qquad \\mathbb{E}[X^2]=\\frac{H_{n,a-2}}{H_{n,a}}. $$\n",
    "\n",
    "### Mean and variance\n",
    "\n",
    "$$\\mathrm{Var}(X)=\\mathbb{E}[X^2]-\\mathbb{E}[X]^2. $$\n",
    "\n",
    "Because `zipfian` has **finite support**, *all* moments exist for any $a>0$. However, in the limit $n\\to\\infty$ (the zeta distribution), normalization requires $a>1$ and higher moments require progressively larger $a$.\n",
    "\n",
    "### MGF and characteristic function\n",
    "With finite support,\n",
    "\n",
    "$$M_X(t)=\\mathbb{E}[e^{tX}]=\\sum_{k=1}^{n} e^{tk}\\,\\frac{k^{-a}}{H_{n,a}},$$\n",
    "\n",
    "$$\\varphi_X(t)=\\mathbb{E}[e^{itX}]=\\sum_{k=1}^{n} e^{itk}\\,\\frac{k^{-a}}{H_{n,a}}. $$\n",
    "\n",
    "### Entropy\n",
    "\n",
    "$$\\mathcal{H}(X)=-\\sum_{k=1}^{n} p_k\\log p_k. $$\n",
    "\n",
    "Using $\\log p_k=-a\\log k-\\log H_{n,a}$, we can rewrite\n",
    "\n",
    "$$\\mathcal{H}(X)=\\log H_{n,a} + a\\,\\mathbb{E}[\\log X]. $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268f04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipfian_raw_moment(m: int, a: float, n: int) -> float:\n",
    "    a, n = _validate_a_n(a, n)\n",
    "\n",
    "    ks = np.arange(1, n + 1, dtype=float)\n",
    "    logk = np.log(ks)\n",
    "    logZ = zipfian_logZ(a, n)\n",
    "\n",
    "    # E[X^m] = sum exp((m-a) log k - logZ)\n",
    "    return float(np.exp(_logsumexp_np((m - a) * logk) - logZ))\n",
    "\n",
    "\n",
    "def zipfian_moments(a: float, n: int):\n",
    "    a, n = _validate_a_n(a, n)\n",
    "\n",
    "    m1 = zipfian_raw_moment(1, a, n)\n",
    "    m2 = zipfian_raw_moment(2, a, n)\n",
    "    m3 = zipfian_raw_moment(3, a, n)\n",
    "    m4 = zipfian_raw_moment(4, a, n)\n",
    "\n",
    "    var = m2 - m1**2\n",
    "\n",
    "    if var <= 0.0:\n",
    "        skew = float(\"nan\")\n",
    "        excess_kurt = float(\"nan\")\n",
    "    else:\n",
    "        mu3 = m3 - 3.0 * m1 * m2 + 2.0 * m1**3\n",
    "        mu4 = m4 - 4.0 * m1 * m3 + 6.0 * (m1**2) * m2 - 3.0 * m1**4\n",
    "\n",
    "        skew = mu3 / (var ** 1.5)\n",
    "        excess_kurt = mu4 / (var**2) - 3.0\n",
    "\n",
    "    return {\n",
    "        \"mean\": m1,\n",
    "        \"var\": var,\n",
    "        \"skew\": skew,\n",
    "        \"kurtosis\": excess_kurt + 3.0,\n",
    "        \"excess_kurt\": excess_kurt,\n",
    "    }\n",
    "\n",
    "\n",
    "def zipfian_expected_log(a: float, n: int) -> float:\n",
    "    ks, pmf = zipfian_pmf_array(a, n)\n",
    "    return float(np.sum(pmf * np.log(ks)))\n",
    "\n",
    "\n",
    "def zipfian_entropy(a: float, n: int, *, base=math.e) -> float:\n",
    "    ks, pmf = zipfian_pmf_array(a, n)\n",
    "    mask = pmf > 0\n",
    "    H_nats = -np.sum(pmf[mask] * np.log(pmf[mask]))\n",
    "\n",
    "    if base == math.e:\n",
    "        return float(H_nats)\n",
    "    return float(H_nats / math.log(base))\n",
    "\n",
    "\n",
    "def zipfian_log_mgf(t: float, a: float, n: int) -> float:\n",
    "    a, n = _validate_a_n(a, n)\n",
    "\n",
    "    ks = np.arange(1, n + 1, dtype=float)\n",
    "    logZ = zipfian_logZ(a, n)\n",
    "    logp = -a * np.log(ks) - logZ\n",
    "\n",
    "    return _logsumexp_np(logp + t * ks)\n",
    "\n",
    "\n",
    "def zipfian_mgf(t: float, a: float, n: int) -> float:\n",
    "    return float(np.exp(zipfian_log_mgf(t, a, n)))\n",
    "\n",
    "\n",
    "def zipfian_cf(t: float, a: float, n: int) -> complex:\n",
    "    a, n = _validate_a_n(a, n)\n",
    "\n",
    "    ks = np.arange(1, n + 1, dtype=float)\n",
    "    logZ = zipfian_logZ(a, n)\n",
    "    logp = -a * np.log(ks) - logZ\n",
    "\n",
    "    return np.sum(np.exp(logp) * np.exp(1j * t * ks))\n",
    "\n",
    "\n",
    "a, n = 1.2, 50\n",
    "mom = zipfian_moments(a, n)\n",
    "H_direct = zipfian_entropy(a, n)\n",
    "H_via_formula = zipfian_logZ(a, n) + a * zipfian_expected_log(a, n)\n",
    "\n",
    "{\n",
    "    **mom,\n",
    "    \"entropy_nats\": H_direct,\n",
    "    \"entropy_nats_check\": float(H_via_formula),\n",
    "    \"mgf(t=0.1)\": zipfian_mgf(0.1, a, n),\n",
    "    \"cf(t=1.0)\": zipfian_cf(1.0, a, n),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226ca3ee",
   "metadata": {},
   "source": [
    "## 5) Parameter Interpretation\n",
    "\n",
    "- **Exponent $a$ (tail heaviness)**\n",
    "  - Smaller $a$ (closer to 0) makes the distribution **flatter** (closer to uniform on $\\{1,\\dots,n\\}$).\n",
    "  - Larger $a$ concentrates mass on small ranks; the tail decays faster.\n",
    "\n",
    "- **Truncation $n$ (maximum rank)**\n",
    "  - Increasing $n$ extends the tail to allow rarer outcomes.\n",
    "  - For fixed $a$, increasing $n$ increases the normalizer $H_{n,a}$, so the probabilities of low ranks decrease slightly.\n",
    "\n",
    "A common diagnostic is a **log–log plot** of PMF vs rank: power laws appear approximately linear with slope $-a$ (up to truncation effects).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e49f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fixed = 80\n",
    "a_values = [0.6, 1.0, 1.6, 2.5]\n",
    "\n",
    "n_values = [20, 80, 300]\n",
    "a_fixed = 1.2\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\n",
    "        f\"PMF vs a (n={n_fixed})\",\n",
    "        f\"PMF vs n (a={a_fixed})\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Left: vary a\n",
    "ks = np.arange(1, n_fixed + 1)\n",
    "for a_ in a_values:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=ks,\n",
    "            y=zipfian_pmf(ks, a_, n_fixed),\n",
    "            mode=\"markers+lines\",\n",
    "            name=f\"a={a_}\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "# Right: vary n\n",
    "for n_ in n_values:\n",
    "    ks_ = np.arange(1, n_ + 1)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=ks_,\n",
    "            y=zipfian_pmf(ks_, a_fixed, n_),\n",
    "            mode=\"markers+lines\",\n",
    "            name=f\"n={n_}\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(title_text=\"rank k\", type=\"log\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"P(X=k)\", type=\"log\", row=1, col=1)\n",
    "\n",
    "fig.update_xaxes(title_text=\"rank k\", type=\"log\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"P(X=k)\", type=\"log\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(title=\"Zipfian PMF: shape changes\", legend_title_text=\"parameter\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23332eba",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### Expectation\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[X]\n",
    "&= \\sum_{k=1}^{n} k\\,\\Pr(X=k)\n",
    "= \\sum_{k=1}^{n} k\\,\\frac{k^{-a}}{H_{n,a}}\\\\\n",
    "&= \\frac{\\sum_{k=1}^{n} k^{1-a}}{H_{n,a}}\n",
    "= \\frac{H_{n,a-1}}{H_{n,a}}.\n",
    "\\end{aligned}\n",
    "\n",
    "### Variance\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mathrm{Var}(X)\n",
    "&= \\mathbb{E}[X^2]-\\mathbb{E}[X]^2\n",
    "= \\frac{H_{n,a-2}}{H_{n,a}} - \\left(\\frac{H_{n,a-1}}{H_{n,a}}\\right)^2.\n",
    "\\end{aligned}\n",
    "\n",
    "### Likelihood (i.i.d. data)\n",
    "Let $x_1,\\dots,x_m$ be i.i.d. with $x_i\\in\\{1,\\dots,n\\}$. The log-likelihood for $a$ (with $n$ treated as known) is\n",
    "\n",
    "\\begin{aligned}\n",
    "\\ell(a) &= \\sum_{i=1}^{m}\\log\\Pr(X=x_i\\mid a,n)\\\\\n",
    "&= \\sum_{i=1}^{m}\\left(-a\\log x_i-\\log H_{n,a}\\right)\\\\\n",
    "&= -a\\sum_{i=1}^{m}\\log x_i - m\\log H_{n,a}.\n",
    "\\end{aligned}\n",
    "\n",
    "If $n$ is unknown but the support is truncated, we must have $n\\ge\\max_i x_i$. For any fixed $a>0$, $H_{n,a}$ is **increasing** in $n$, which makes the likelihood **decrease** in $n$. Hence the MLE for $n$ is often the boundary:\n",
    "\n",
    "$$\\hat n = \\max_i x_i.$$\n",
    "\n",
    "(Practically, $n$ is usually known from context: vocabulary size, catalog size, maximum rank considered, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708771d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_sample(data, n: int) -> np.ndarray:\n",
    "    if isinstance(n, bool) or not isinstance(n, (int, np.integer)):\n",
    "        raise TypeError(\"n must be an integer\")\n",
    "    n = int(n)\n",
    "\n",
    "    x = np.asarray(data)\n",
    "    if x.ndim != 1:\n",
    "        x = x.ravel()\n",
    "\n",
    "    if np.issubdtype(x.dtype, np.integer):\n",
    "        x_int = x.astype(int)\n",
    "    else:\n",
    "        if np.any(np.floor(x) != x):\n",
    "            raise ValueError(\"data must be integer-valued\")\n",
    "        x_int = x.astype(int)\n",
    "\n",
    "    if np.any(x_int < 1) or np.any(x_int > n):\n",
    "        raise ValueError(f\"all observations must be in {{1,...,{n}}}\")\n",
    "\n",
    "    return x_int\n",
    "\n",
    "\n",
    "def zipfian_loglik(a: float, data: np.ndarray, n: int) -> float:\n",
    "    a, n = _validate_a_n(a, n)\n",
    "    x = _validate_sample(data, n)\n",
    "\n",
    "    m = x.size\n",
    "    return float(-a * np.sum(np.log(x)) - m * zipfian_logZ(a, n))\n",
    "\n",
    "\n",
    "def zipfian_mle_a(data: np.ndarray, n: int, *, bounds=(1e-3, 10.0)):\n",
    "    # MLE for a with fixed n via 1D optimization.\n",
    "    _, n = _validate_a_n(1.0, n)  # validate n\n",
    "    x = _validate_sample(data, n)\n",
    "\n",
    "    def nll(a):\n",
    "        if a <= 0:\n",
    "            return np.inf\n",
    "        return -zipfian_loglik(a, x, n)\n",
    "\n",
    "    res = minimize_scalar(nll, bounds=bounds, method=\"bounded\")\n",
    "    return float(res.x), res\n",
    "\n",
    "\n",
    "# Demo: generate data and recover a\n",
    "true_a, true_n = 1.35, 60\n",
    "x = stats.zipfian.rvs(true_a, true_n, size=20_000, random_state=rng)\n",
    "\n",
    "# If n is unknown, a common MLE choice is n_hat = max(x)\n",
    "n_hat = int(x.max())\n",
    "a_hat, opt_res = zipfian_mle_a(x, n_hat)\n",
    "\n",
    "{\n",
    "    \"true_a\": true_a,\n",
    "    \"true_n\": true_n,\n",
    "    \"n_hat\": n_hat,\n",
    "    \"a_hat\": a_hat,\n",
    "    \"optimizer_success\": opt_res.success,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460fbec8",
   "metadata": {},
   "source": [
    "## 7) Sampling & Simulation (NumPy-only)\n",
    "\n",
    "Because the support is finite, the most direct NumPy-only sampler uses **inverse transform sampling**:\n",
    "\n",
    "1. Compute the PMF $p_k$ on $k=1,\\dots,n$.\n",
    "2. Compute the CDF $c_k = \\sum_{j\\le k} p_j$.\n",
    "3. Draw $U\\sim\\mathrm{Uniform}(0,1)$.\n",
    "4. Return the smallest $k$ such that $c_k\\ge U$.\n",
    "\n",
    "This is:\n",
    "- **$\\mathcal{O}(n)$** to build the CDF (once per parameter setting)\n",
    "- **$\\mathcal{O}(\\log n)$** per sample using `np.searchsorted`\n",
    "\n",
    "For very large $n$ with repeated sampling, an **alias method** can reduce per-sample cost to $\\mathcal{O}(1)$ after an $\\mathcal{O}(n)$ preprocessing step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b4058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_zipfian_numpy(a: float, n: int, size, rng: np.random.Generator) -> np.ndarray:\n",
    "    a, n = _validate_a_n(a, n)\n",
    "\n",
    "    if isinstance(size, tuple):\n",
    "        out_shape = size\n",
    "        size_int = int(np.prod(size))\n",
    "    else:\n",
    "        size_int = int(size)\n",
    "        out_shape = (size_int,)\n",
    "\n",
    "    if size_int < 0:\n",
    "        raise ValueError(\"size must be non-negative\")\n",
    "\n",
    "    ks, pmf = zipfian_pmf_array(a, n)\n",
    "    cdf = np.cumsum(pmf)\n",
    "    cdf[-1] = 1.0  # guard against floating drift\n",
    "\n",
    "    u = rng.random(size_int)\n",
    "    samples = ks[np.searchsorted(cdf, u, side=\"left\")]\n",
    "    return samples.reshape(out_shape)\n",
    "\n",
    "\n",
    "a, n = 1.2, 80\n",
    "samples = sample_zipfian_numpy(a, n, size=100_000, rng=rng)\n",
    "\n",
    "mom = zipfian_moments(a, n)\n",
    "\n",
    "{\n",
    "    \"theory_mean\": mom[\"mean\"],\n",
    "    \"mc_mean\": float(samples.mean()),\n",
    "    \"theory_var\": mom[\"var\"],\n",
    "    \"mc_var\": float(samples.var(ddof=0)),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64b56af",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We’ll visualize:\n",
    "- the **PMF** (often most informative on a log–log scale)\n",
    "- the **CDF** (step function)\n",
    "- **Monte Carlo samples**: empirical frequencies vs theoretical PMF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fcad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, n = 1.25, 100\n",
    "ks, pmf = zipfian_pmf_array(a, n)\n",
    "\n",
    "# CDF values on the support\n",
    "cdf = np.cumsum(pmf)\n",
    "\n",
    "# Monte Carlo frequencies\n",
    "m = 60_000\n",
    "samps = sample_zipfian_numpy(a, n, size=m, rng=rng)\n",
    "counts = np.bincount(samps, minlength=n + 1)[1:]\n",
    "emp_pmf = counts / counts.sum()\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=3,\n",
    "    subplot_titles=(\n",
    "        \"PMF (log–log)\",\n",
    "        \"CDF\",\n",
    "        \"Empirical vs theoretical PMF\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# PMF\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=ks, y=pmf, mode=\"markers+lines\", name=\"theory\"),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.update_xaxes(type=\"log\", title_text=\"rank k\", row=1, col=1)\n",
    "fig.update_yaxes(type=\"log\", title_text=\"P(X=k)\", row=1, col=1)\n",
    "\n",
    "# CDF\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=ks, y=cdf, mode=\"lines\", name=\"CDF\"),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "fig.update_xaxes(title_text=\"k\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"P(X≤k)\", row=1, col=2)\n",
    "\n",
    "# Empirical vs theoretical\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=ks,\n",
    "        y=emp_pmf,\n",
    "        mode=\"markers\",\n",
    "        name=\"empirical\",\n",
    "        opacity=0.6,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=3,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=ks,\n",
    "        y=pmf,\n",
    "        mode=\"lines\",\n",
    "        name=\"theory\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=3,\n",
    ")\n",
    "fig.update_xaxes(type=\"log\", title_text=\"rank k\", row=1, col=3)\n",
    "fig.update_yaxes(type=\"log\", title_text=\"probability\", row=1, col=3)\n",
    "\n",
    "fig.update_layout(title=f\"Zipfian(a={a}, n={n})\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5579c7",
   "metadata": {},
   "source": [
    "## 9) SciPy Integration\n",
    "\n",
    "SciPy provides the Zipfian distribution as `scipy.stats.zipfian`.\n",
    "\n",
    "Common methods:\n",
    "- PMF / CDF: `stats.zipfian.pmf`, `stats.zipfian.cdf`\n",
    "- Sampling: `stats.zipfian.rvs`\n",
    "- Fitting: `scipy.stats.fit(stats.zipfian, data, ...)`\n",
    "\n",
    "Notes:\n",
    "- `zipfian(a, n)` is **finite-support** on $\\{1,\\dots,n\\}$.\n",
    "- `zipf(a)` is the **infinite-support** zeta distribution (requires $a>1$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83074294",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, n = 1.3, 50\n",
    "\n",
    "dist = stats.zipfian(a, n)  # frozen distribution\n",
    "print(\"support:\", dist.support())\n",
    "print(\"pmf([1,2,10]):\", dist.pmf([1, 2, 10]))\n",
    "print(\"cdf([1,2,10]):\", dist.cdf([1, 2, 10]))\n",
    "\n",
    "rvs = dist.rvs(size=10, random_state=rng)\n",
    "print(\"rvs:\", rvs)\n",
    "\n",
    "# Moments from SciPy\n",
    "mean_s, var_s, skew_s, kurt_s = stats.zipfian.stats(a, n, moments=\"mvsk\")\n",
    "print(\"SciPy mean/var/skew/kurtosis:\", mean_s, var_s, skew_s, kurt_s)\n",
    "\n",
    "# Fit (MLE by default)\n",
    "data = stats.zipfian.rvs(1.25, 80, size=15_000, random_state=rng)\n",
    "fit_res = stats.fit(stats.zipfian, data, bounds={\"a\": (0.05, 10.0), \"n\": (2, 500)})\n",
    "print(fit_res)\n",
    "print(\"a_hat, n_hat:\", fit_res.params.a, fit_res.params.n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f203f9cd",
   "metadata": {},
   "source": [
    "## 10) Statistical Use Cases\n",
    "\n",
    "### A) Hypothesis testing (goodness-of-fit)\n",
    "A common question: *does a Zipfian model explain these ranks?*\n",
    "\n",
    "A simple approach:\n",
    "1. Fit $a$ (and possibly $n$).\n",
    "2. Compare observed counts to expected counts under the fitted model.\n",
    "3. Use a **chi-square** test (or a likelihood-ratio / G-test).\n",
    "\n",
    "Because parameters are estimated from the same data, classical p-values can be optimistic; a more careful approach uses a **parametric bootstrap**.\n",
    "\n",
    "### B) Bayesian modeling\n",
    "Treat $a$ as unknown with a prior, e.g. $a\\sim\\mathrm{Gamma}(\\alpha_0,\\beta_0)$. Then\n",
    "\n",
    "$$p(a\\mid x) \\propto p(x\\mid a)\\,p(a).$$\n",
    "\n",
    "For 1D $a$, a grid posterior is straightforward.\n",
    "\n",
    "### C) Generative modeling\n",
    "Zipfian sampling is a standard building block for synthetic datasets with:\n",
    "- head–tail imbalance\n",
    "- realistic rank-frequency behavior\n",
    "\n",
    "Examples include generating synthetic word IDs, item popularity, or request patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c29a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Chi-square goodness-of-fit demo\n",
    "true_a, true_n = 1.15, 25\n",
    "x = stats.zipfian.rvs(true_a, true_n, size=30_000, random_state=rng)\n",
    "\n",
    "# Fit a with n fixed (here: assume n known)\n",
    "a_hat, _ = zipfian_mle_a(x, true_n, bounds=(0.05, 5.0))\n",
    "\n",
    "obs = np.bincount(x, minlength=true_n + 1)[1:]\n",
    "ks, pmf_hat = zipfian_pmf_array(a_hat, true_n)\n",
    "exp = x.size * pmf_hat\n",
    "\n",
    "chi2_stat, p_value = stats.chisquare(f_obs=obs, f_exp=exp)\n",
    "{\n",
    "    \"true_a\": true_a,\n",
    "    \"a_hat\": a_hat,\n",
    "    \"chi2\": float(chi2_stat),\n",
    "    \"p_value_naive\": float(p_value),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185a9085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) Bayesian modeling of a via a grid posterior (n fixed)\n",
    "\n",
    "x = stats.zipfian.rvs(1.3, 60, size=8_000, random_state=rng)\n",
    "n = 60\n",
    "\n",
    "# Prior: Gamma(alpha0, rate=beta0)\n",
    "alpha0, beta0 = 2.0, 1.0\n",
    "\n",
    "a_grid = np.linspace(0.2, 4.0, 500)\n",
    "log_prior = stats.gamma.logpdf(a_grid, a=alpha0, scale=1.0 / beta0)\n",
    "log_like = np.array([zipfian_loglik(a, x, n) for a in a_grid])\n",
    "log_post_unnorm = log_prior + log_like\n",
    "\n",
    "# Normalize on the grid\n",
    "logZ_post = _logsumexp_np(log_post_unnorm)\n",
    "post = np.exp(log_post_unnorm - logZ_post)\n",
    "post = post / post.sum()\n",
    "\n",
    "post_mean = float(np.sum(a_grid * post))\n",
    "post_cdf = np.cumsum(post)\n",
    "ci_low = float(a_grid[np.searchsorted(post_cdf, 0.05)])\n",
    "ci_high = float(a_grid[np.searchsorted(post_cdf, 0.95)])\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[go.Scatter(x=a_grid, y=post, mode=\"lines\", name=\"posterior\")],\n",
    "    layout=dict(\n",
    "        title=f\"Posterior over a (n={n}, Gamma({alpha0},{beta0}) prior)\",\n",
    "        xaxis_title=\"a\",\n",
    "        yaxis_title=\"density (grid-normalized)\",\n",
    "    ),\n",
    ")\n",
    "fig.add_vline(x=post_mean, line_dash=\"dash\", line_color=\"black\")\n",
    "fig.add_vrect(x0=ci_low, x1=ci_high, fillcolor=\"gray\", opacity=0.2, line_width=0)\n",
    "fig.show()\n",
    "\n",
    "{\"posterior_mean\": post_mean, \"90%_credible_interval\": (ci_low, ci_high)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C) Generative modeling: synthetic rank-frequency data\n",
    "\n",
    "a, n_vocab = 1.1, 2_000\n",
    "n_tokens = 120_000\n",
    "ranks = sample_zipfian_numpy(a, n_vocab, size=n_tokens, rng=rng)\n",
    "\n",
    "counts = np.bincount(ranks, minlength=n_vocab + 1)[1:]\n",
    "freq = counts / counts.sum()\n",
    "rank = np.arange(1, n_vocab + 1)\n",
    "\n",
    "# Theoretical PMF for comparison\n",
    "_, pmf_theory = zipfian_pmf_array(a, n_vocab)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=rank, y=freq, mode=\"markers\", name=\"empirical\", opacity=0.6))\n",
    "fig.add_trace(go.Scatter(x=rank, y=pmf_theory, mode=\"lines\", name=\"theory\"))\n",
    "\n",
    "fig.update_xaxes(type=\"log\", title_text=\"rank\")\n",
    "fig.update_yaxes(type=\"log\", title_text=\"frequency\")\n",
    "fig.update_layout(title=\"Synthetic rank-frequency (log–log)\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58405e9e",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Invalid parameters**\n",
    "  - SciPy’s `zipfian` expects **`a > 0`** and **integer `n >= 1`**.\n",
    "  - If you treat $n$ as unknown from i.i.d. data, the likelihood typically pushes to $\\hat n = \\max x_i$ (a boundary estimate). In practice, choose $n$ from domain knowledge.\n",
    "\n",
    "- **Numerical issues**\n",
    "  - For large $n$ or extreme $a$, naive computations of $k^{-a}$ can underflow/overflow. Using **log-space** (as in `zipfian_logpmf`) is more stable.\n",
    "  - Building the full PMF/CDF is $\\mathcal{O}(n)$ memory/time. For very large $n$ and repeated sampling, consider alias sampling or SciPy’s implementation.\n",
    "\n",
    "- **Model mismatch**\n",
    "  - Many empirical “Zipf-like” datasets deviate in the head or tail (mixtures, cutoffs, measurement bias). Always inspect residuals / goodness-of-fit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1521990c",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `zipfian(a, n)` is a **discrete truncated power law** on ranks $\\{1,\\dots,n\\}$ with PMF $p_k \\propto k^{-a}$.\n",
    "- The normalizer is the generalized harmonic number $H_{n,a}$.\n",
    "- Finite support implies **all moments exist**, with compact expressions via harmonic numbers.\n",
    "- Inverse-CDF sampling gives a simple **NumPy-only** sampler.\n",
    "- SciPy’s `scipy.stats.zipfian` provides PMF/CDF/RVS and MLE-style fitting via `scipy.stats.fit`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}