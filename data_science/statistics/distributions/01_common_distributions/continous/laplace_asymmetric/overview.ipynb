{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6a9c3f1",
   "metadata": {},
   "source": [
    "# Asymmetric Laplace Distribution (`laplace_asymmetric`)\n",
    "\n",
    "The **asymmetric Laplace distribution** (also called the **two-sided exponential**) is a continuous distribution with **exponential tails** on both sides of its mode, but with **different decay rates** on the left and right.\n",
    "\n",
    "It is a convenient model for **skewed, heavy-tailed noise** and appears prominently as a likelihood for **quantile regression**.\n",
    "\n",
    "This notebook follows SciPy's parameterization: `scipy.stats.laplace_asymmetric(kappa, loc, scale)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3d9c2a",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "By the end you should be able to:\n",
    "\n",
    "- Write the PDF/CDF (standard and location-scale forms) and understand the role of `kappa`, `loc`, and `scale`.\n",
    "- Compute and interpret **mean**, **variance**, **skewness**, **kurtosis**, the **MGF/characteristic function**, and **entropy**.\n",
    "- Derive the likelihood and connect it to the **quantile-regression check loss**.\n",
    "- Sample efficiently with a **NumPy-only** algorithm and validate results by simulation.\n",
    "- Use SciPy's `laplace_asymmetric` for evaluation, sampling, and parameter fitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a8b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Plotly rendering (CKC convention)\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "# Reproducibility\n",
    "rng = np.random.default_rng(7)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "print(\"Python\", platform.python_version())\n",
    "print(\"NumPy\", np.__version__)\n",
    "print(\"SciPy\", scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a4f5c2",
   "metadata": {},
   "source": [
    "## 1) Title & Classification\n",
    "\n",
    "- **Name**: `laplace_asymmetric` (Asymmetric Laplace; SciPy: `scipy.stats.laplace_asymmetric`)\n",
    "- **Type**: **Continuous**\n",
    "- **Support**: $x \\in (-\\infty, \\infty)$\n",
    "- **Parameter space**:\n",
    "  - Shape: $\\kappa > 0$\n",
    "  - Location: $\\mathrm{loc} \\in \\mathbb{R}$\n",
    "  - Scale: $\\mathrm{scale} > 0$\n",
    "\n",
    "We'll often write the standardized variable\n",
    "$$\n",
    "Y = \\frac{X-\\mathrm{loc}}{\\mathrm{scale}},\n",
    "$$\n",
    "so the standardized distribution corresponds to `loc=0`, `scale=1`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c21b9e4",
   "metadata": {},
   "source": [
    "## 2) Intuition & Motivation\n",
    "\n",
    "### 2.1 What it models\n",
    "\n",
    "The asymmetric Laplace distribution is a natural model when:\n",
    "\n",
    "- deviations to the left and right of a typical value have **different rates** (asymmetry), and\n",
    "- tails are heavier than Gaussian but still **exponential** (robustness to outliers).\n",
    "\n",
    "A helpful mental picture: it is the distribution you get when you glue together **two exponentials** at a point (the mode), allowing different decay on each side.\n",
    "\n",
    "### 2.2 Typical real-world use cases\n",
    "\n",
    "- **Quantile regression**: using an asymmetric Laplace likelihood makes the MLE for the location parameter align with a chosen **quantile** (more below).\n",
    "- **Skewed residuals**: economics/finance (returns or spreads), operations (delays), or any setting where errors are not symmetric.\n",
    "- **Robust modeling**: like Laplace noise but allowing one-sided outliers to be more likely.\n",
    "\n",
    "### 2.3 Relations to other distributions\n",
    "\n",
    "- If $\\kappa = 1$, the distribution reduces to the **Laplace** (double-exponential) distribution.\n",
    "- Conditional on the sign relative to the mode, the distribution is **exponential**:\n",
    "  - right side decays with rate $\\kappa$ (in standardized form),\n",
    "  - left side decays with rate $1/\\kappa$.\n",
    "- **Generative representation** (standardized form):\n",
    "  $$\n",
    "  X = Y - Z,\\quad Y\\sim\\mathrm{Exp}(\\text{rate}=\\kappa),\\; Z\\sim\\mathrm{Exp}(\\text{rate}=1/\\kappa),\\; Y\\perp Z.\n",
    "  $$\n",
    "  This representation is great for sampling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c9a1b7",
   "metadata": {},
   "source": [
    "## 3) Formal Definition\n",
    "\n",
    "SciPy defines the **standardized** asymmetric Laplace distribution (with `loc=0`, `scale=1`) via the PDF\n",
    "\n",
    "$$\n",
    "f(x;\\kappa) =\n",
    "\\begin{cases}\n",
    "\\dfrac{1}{\\kappa+\\kappa^{-1}}\\,\\exp(-\\kappa x), & x\\ge 0\\\\\n",
    "\\dfrac{1}{\\kappa+\\kappa^{-1}}\\,\\exp(x/\\kappa), & x< 0\n",
    "\\end{cases}\n",
    "\\qquad \\kappa>0.\n",
    "$$\n",
    "\n",
    "### 3.1 CDF (standardized)\n",
    "\n",
    "Integrating the PDF gives\n",
    "\n",
    "$$\n",
    "F(x;\\kappa) =\n",
    "\\begin{cases}\n",
    "\\dfrac{\\kappa^2}{1+\\kappa^2}\\,\\exp(x/\\kappa), & x<0\\\\\n",
    "1 - \\dfrac{1}{1+\\kappa^2}\\,\\exp(-\\kappa x), & x\\ge 0.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Note the jump point is smooth at $x=0$ (the CDF is continuous) and\n",
    "$$\n",
    "F(0;\\kappa) = \\frac{\\kappa^2}{1+\\kappa^2}.\n",
    "$$\n",
    "\n",
    "### 3.2 Location-scale form\n",
    "\n",
    "With `loc` and `scale`, SciPy uses the standard location-scale transformation:\n",
    "$$\n",
    "Y = \\frac{X-\\mathrm{loc}}{\\mathrm{scale}}\\sim\\text{standardized AL}(\\kappa).\n",
    "$$\n",
    "So\n",
    "\n",
    "$$\n",
    "f_X(x;\\kappa,\\mathrm{loc},\\mathrm{scale}) = \\frac{1}{\\mathrm{scale}}\\,f_Y\\!\\left(\\frac{x-\\mathrm{loc}}{\\mathrm{scale}};\\kappa\\right),\n",
    "$$\n",
    "and similarly for the CDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4c2d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_kappa_scale(kappa: float, scale: float) -> None:\n",
    "    if kappa <= 0:\n",
    "        raise ValueError(\"kappa must be > 0\")\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "\n",
    "def laplace_asymmetric_pdf(\n",
    "    x: np.ndarray,\n",
    "    kappa: float,\n",
    "    loc: float = 0.0,\n",
    "    scale: float = 1.0,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Asymmetric Laplace PDF (SciPy parameterization) implemented with NumPy.\"\"\"\n",
    "    _validate_kappa_scale(kappa, scale)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = (x - loc) / scale\n",
    "    c = 1.0 / (kappa + 1.0 / kappa)\n",
    "    core = np.where(y >= 0, np.exp(-kappa * y), np.exp(y / kappa))\n",
    "    return (c / scale) * core\n",
    "\n",
    "\n",
    "def laplace_asymmetric_logpdf(\n",
    "    x: np.ndarray,\n",
    "    kappa: float,\n",
    "    loc: float = 0.0,\n",
    "    scale: float = 1.0,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Log-PDF, useful for numerical stability in the tails.\"\"\"\n",
    "    _validate_kappa_scale(kappa, scale)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = (x - loc) / scale\n",
    "    log_norm = -np.log(scale) - np.log(kappa + 1.0 / kappa)\n",
    "    return log_norm + np.where(y >= 0, -kappa * y, y / kappa)\n",
    "\n",
    "\n",
    "def laplace_asymmetric_cdf(\n",
    "    x: np.ndarray,\n",
    "    kappa: float,\n",
    "    loc: float = 0.0,\n",
    "    scale: float = 1.0,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Asymmetric Laplace CDF (SciPy parameterization) implemented with NumPy.\"\"\"\n",
    "    _validate_kappa_scale(kappa, scale)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = (x - loc) / scale\n",
    "    denom = 1.0 + kappa**2\n",
    "    left = (kappa**2 / denom) * np.exp(y / kappa)\n",
    "    right = 1.0 - np.exp(-kappa * y) / denom\n",
    "    return np.where(y < 0, left, right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks against SciPy\n",
    "\n",
    "kappa = 2.0\n",
    "loc = 0.5\n",
    "scale = 1.3\n",
    "\n",
    "x = np.linspace(loc - 20 * scale, loc + 20 * scale, 20_001)\n",
    "\n",
    "pdf_np = laplace_asymmetric_pdf(x, kappa, loc=loc, scale=scale)\n",
    "cdf_np = laplace_asymmetric_cdf(x, kappa, loc=loc, scale=scale)\n",
    "\n",
    "pdf_sp = stats.laplace_asymmetric.pdf(x, kappa, loc=loc, scale=scale)\n",
    "cdf_sp = stats.laplace_asymmetric.cdf(x, kappa, loc=loc, scale=scale)\n",
    "\n",
    "print(\"Approx integral of PDF (trapz):\", np.trapz(pdf_np, x))\n",
    "print(\"CDF endpoints (NumPy):\", float(cdf_np[0]), float(cdf_np[-1]))\n",
    "print(\"max |pdf diff|:\", float(np.max(np.abs(pdf_np - pdf_sp))))\n",
    "print(\"max |cdf diff|:\", float(np.max(np.abs(cdf_np - cdf_sp))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a1b2d",
   "metadata": {},
   "source": [
    "## 4) Moments & Properties\n",
    "\n",
    "Let $X \\sim \\texttt{laplace\\_asymmetric}(\\kappa, \\mathrm{loc}, \\mathrm{scale})$ in SciPy's parameterization.\n",
    "\n",
    "### 4.1 Mean and variance\n",
    "\n",
    "For the standardized case (`loc=0`, `scale=1`):\n",
    "$$\n",
    "\\mathbb{E}[X] = \\frac{1}{\\kappa} - \\kappa,\\qquad \\mathrm{Var}(X)=\\kappa^2 + \\kappa^{-2}.\n",
    "$$\n",
    "\n",
    "With location and scale:\n",
    "$$\n",
    "\\mathbb{E}[X] = \\mathrm{loc} + \\mathrm{scale}\\left(\\frac{1}{\\kappa} - \\kappa\\right),\\qquad\n",
    "\\mathrm{Var}(X)=\\mathrm{scale}^2\\left(\\kappa^2 + \\kappa^{-2}\\right).\n",
    "$$\n",
    "\n",
    "### 4.2 Skewness and kurtosis\n",
    "\n",
    "Skewness and kurtosis do not depend on `loc` or `scale` (for positive scale). In SciPy's convention, `stats(..., moments='k')` returns **excess kurtosis**.\n",
    "\n",
    "$$\n",
    "\\gamma_1 = \\frac{2(1-\\kappa^6)}{(1+\\kappa^4)^{3/2}},\n",
    "\\qquad\n",
    "\\gamma_2 = \\frac{6(1+\\kappa^8)}{(1+\\kappa^4)^2}.\n",
    "$$\n",
    "\n",
    "### 4.3 MGF and characteristic function\n",
    "\n",
    "For the standardized distribution,\n",
    "$$\n",
    "M_X(t)=\\mathbb{E}[e^{tX}] = \\frac{1}{(\\kappa-t)(\\kappa^{-1}+t)},\n",
    "\\qquad t\\in\\left(-\\frac{1}{\\kappa},\\kappa\\right).\n",
    "$$\n",
    "\n",
    "With location and scale:\n",
    "$$\n",
    "M_X(t)=\\frac{\\exp(\\mathrm{loc}\\,t)}{\\bigl(\\kappa-\\mathrm{scale}\\,t\\bigr)\\bigl(\\kappa^{-1}+\\mathrm{scale}\\,t\\bigr)},\n",
    "\\qquad t\\in\\left(-\\frac{1}{\\kappa\\,\\mathrm{scale}},\\frac{\\kappa}{\\mathrm{scale}}\\right).\n",
    "$$\n",
    "\n",
    "The characteristic function is obtained by substituting $t\\mapsto it$.\n",
    "\n",
    "### 4.4 Entropy\n",
    "\n",
    "The differential entropy is\n",
    "$$\n",
    "H(X) = 1 + \\log\\bigl(\\mathrm{scale}(\\kappa+\\kappa^{-1})\\bigr).\n",
    "$$\n",
    "\n",
    "### 4.5 A useful fact: what does `loc` represent?\n",
    "\n",
    "In this parameterization, the density is maximized at `loc`, so `loc` is the **mode**.\n",
    "\n",
    "Also,\n",
    "$$\n",
    "F(\\mathrm{loc}) = \\frac{\\kappa^2}{1+\\kappa^2},\n",
    "$$\n",
    "so `loc` is a fixed **quantile** that depends on $\\kappa$ (it is the median only when $\\kappa=1$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f7a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_asymmetric_moments(\n",
    "    kappa: float,\n",
    "    loc: float = 0.0,\n",
    "    scale: float = 1.0,\n",
    ") -> tuple[float, float, float, float]:\n",
    "    \"\"\"Return mean, variance, skewness, and excess kurtosis.\"\"\"\n",
    "    _validate_kappa_scale(kappa, scale)\n",
    "    mean0 = 1.0 / kappa - kappa\n",
    "    var0 = kappa**2 + 1.0 / (kappa**2)\n",
    "    skew = 2.0 * (1.0 - kappa**6) / (1.0 + kappa**4) ** 1.5\n",
    "    kurt_excess = 6.0 * (1.0 + kappa**8) / (1.0 + kappa**4) ** 2\n",
    "    mean = loc + scale * mean0\n",
    "    var = (scale**2) * var0\n",
    "    return float(mean), float(var), float(skew), float(kurt_excess)\n",
    "\n",
    "\n",
    "def laplace_asymmetric_entropy(kappa: float, scale: float = 1.0) -> float:\n",
    "    _validate_kappa_scale(kappa, scale)\n",
    "    return float(1.0 + np.log(scale * (kappa + 1.0 / kappa)))\n",
    "\n",
    "\n",
    "# Compare to SciPy\n",
    "kappa = 0.7\n",
    "loc = -1.0\n",
    "scale = 2.0\n",
    "\n",
    "mean, var, skew, kurt = laplace_asymmetric_moments(kappa, loc=loc, scale=scale)\n",
    "mean_sp, var_sp, skew_sp, kurt_sp = stats.laplace_asymmetric.stats(\n",
    "    kappa, loc=loc, scale=scale, moments=\"mvsk\"\n",
    ")\n",
    "\n",
    "print(\"mean      (theory, SciPy):\", mean, float(mean_sp))\n",
    "print(\"variance  (theory, SciPy):\", var, float(var_sp))\n",
    "print(\"skewness  (theory, SciPy):\", skew, float(skew_sp))\n",
    "print(\"kurtosis* (theory, SciPy):\", kurt, float(kurt_sp), \"(*excess)\")\n",
    "\n",
    "print(\"entropy   (theory, SciPy):\", laplace_asymmetric_entropy(kappa, scale), float(stats.laplace_asymmetric.entropy(kappa, scale=scale)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2c9e1f",
   "metadata": {},
   "source": [
    "## 5) Parameter Interpretation\n",
    "\n",
    "SciPy uses three parameters:\n",
    "\n",
    "- **`kappa` (shape, $\\kappa>0$)** controls **asymmetry**.\n",
    "  - Right side (`x >= loc`) decays like $\\exp\\{-\\kappa (x-\\mathrm{loc})/\\mathrm{scale}\\}$.\n",
    "  - Left side (`x < loc`) decays like $\\exp\\{(x-\\mathrm{loc})/(\\kappa\\,\\mathrm{scale})\\}$.\n",
    "  - If $\\kappa>1$: **left tail is heavier** and the mean is below the mode.\n",
    "  - If $\\kappa<1$: **right tail is heavier** and the mean is above the mode.\n",
    "- **`loc`** shifts the distribution; it is the **mode** (the kink point where the two exponentials meet).\n",
    "- **`scale` (positive)** stretches distances from `loc` linearly.\n",
    "\n",
    "A common confusion: some references use a parameter that is the **reciprocal** of SciPy's `scale`. Always check parameterization when moving between sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape changes as kappa varies (loc=0, scale=1)\n",
    "\n",
    "loc = 0.0\n",
    "scale = 1.0\n",
    "kappas = [0.5, 1.0, 2.0]\n",
    "\n",
    "x = np.linspace(-8, 8, 2000)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"PDF\", \"CDF\"))\n",
    "\n",
    "for k in kappas:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=x, y=laplace_asymmetric_pdf(x, k, loc=loc, scale=scale), mode=\"lines\", name=f\"kappa={k}\"),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=x, y=laplace_asymmetric_cdf(x, k, loc=loc, scale=scale), mode=\"lines\", name=f\"kappa={k}\", showlegend=False),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "\n",
    "fig.add_vline(x=loc, line_dash=\"dot\", line_color=\"gray\")\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"f(x)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"F(x)\", row=1, col=2)\n",
    "fig.update_layout(title=\"Asymmetric Laplace: effect of kappa (loc=0, scale=1)\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3c1d8e",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "We'll sketch the key derivations in the standardized case (`loc=0`, `scale=1`) and then apply location/scale transformations.\n",
    "\n",
    "### 6.1 Expectation\n",
    "\n",
    "Using the piecewise PDF with normalization constant $c = 1/(\\kappa+\\kappa^{-1})$:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X]\n",
    "= \\int_{0}^{\\infty} x\\,c\\,e^{-\\kappa x}\\,dx + \\int_{-\\infty}^{0} x\\,c\\,e^{x/\\kappa}\\,dx.\n",
    "$$\n",
    "\n",
    "We can use standard Gamma integrals:\n",
    "\n",
    "$$\n",
    "\\int_{0}^{\\infty} x e^{-\\kappa x} dx = \\frac{1}{\\kappa^2},\n",
    "\\qquad\n",
    "\\int_{-\\infty}^{0} x e^{x/\\kappa} dx = -\\kappa^2,\n",
    "$$\n",
    "\n",
    "so\n",
    "$$\n",
    "\\mathbb{E}[X] = c\\left(\\frac{1}{\\kappa^2} - \\kappa^2\\right)=\\frac{1}{\\kappa}-\\kappa.\n",
    "$$\n",
    "\n",
    "### 6.2 Variance\n",
    "\n",
    "Using the exponential-difference representation\n",
    "$X = Y - Z$ with $Y\\sim\\mathrm{Exp}(\\kappa)$ and $Z\\sim\\mathrm{Exp}(1/\\kappa)$ independent,\n",
    "\n",
    "$$\n",
    "\\mathrm{Var}(X) = \\mathrm{Var}(Y) + \\mathrm{Var}(Z) = \\frac{1}{\\kappa^2} + \\kappa^2.\n",
    "$$\n",
    "\n",
    "### 6.3 Likelihood\n",
    "\n",
    "Given i.i.d. data $x_1,\\dots,x_n$ and parameters $(\\kappa,\\mathrm{loc},\\mathrm{scale})$, the log-likelihood is\n",
    "\n",
    "$$\n",
    "\\ell = -n\\log\\bigl(\\mathrm{scale}(\\kappa+\\kappa^{-1})\\bigr)\n",
    " - \\sum_{i: x_i\\ge \\mathrm{loc}} \\frac{\\kappa(x_i-\\mathrm{loc})}{\\mathrm{scale}}\n",
    " - \\sum_{i: x_i< \\mathrm{loc}} \\frac{(\\mathrm{loc}-x_i)}{\\kappa\\,\\mathrm{scale}}.\n",
    "$$\n",
    "\n",
    "Up to constants, the negative log-likelihood is a **weighted absolute deviation** loss.\n",
    "\n",
    "Define\n",
    "$$\n",
    "\\tau = \\frac{\\kappa^2}{1+\\kappa^2}.\n",
    "$$\n",
    "Then the same loss can be written (up to a positive scalar factor) as the **quantile regression check loss**\n",
    "$\\rho_\\tau(u)=u(\\tau-\\mathbf{1}\\{u<0\\})$ applied to residuals $u=(x-\\mathrm{loc})/\\mathrm{scale}$.\n",
    "\n",
    "This is why asymmetric Laplace likelihoods are closely tied to quantile regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_asymmetric_nll(\n",
    "    x: np.ndarray,\n",
    "    kappa: float,\n",
    "    loc: float,\n",
    "    scale: float,\n",
    ") -> float:\n",
    "    \"\"\"Negative log-likelihood for i.i.d. observations x (NumPy implementation).\"\"\"\n",
    "    _validate_kappa_scale(kappa, scale)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = (x - loc) / scale\n",
    "\n",
    "    # Weighted absolute deviation term\n",
    "    loss = np.where(y >= 0, kappa * y, -y / kappa)\n",
    "\n",
    "    return float(x.size * (np.log(scale) + np.log(kappa + 1.0 / kappa)) + np.sum(loss))\n",
    "\n",
    "\n",
    "kappa = 2.0\n",
    "tau = kappa**2 / (1.0 + kappa**2)\n",
    "print(\"For kappa=2, tau = kappa^2/(1+kappa^2) =\", tau)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d7c6b",
   "metadata": {},
   "source": [
    "## 7) Sampling & Simulation\n",
    "\n",
    "### NumPy-only algorithm (difference of exponentials)\n",
    "\n",
    "Use the representation (standardized form):\n",
    "$$\n",
    "X = Y - Z,\\quad Y\\sim\\mathrm{Exp}(\\text{rate}=\\kappa),\\; Z\\sim\\mathrm{Exp}(\\text{rate}=1/\\kappa),\\; Y\\perp Z.\n",
    "$$\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Sample $Y$ from an exponential with mean $1/\\kappa$.\n",
    "2. Sample $Z$ from an exponential with mean $\\kappa$.\n",
    "3. Return $X = \\mathrm{loc} + \\mathrm{scale}\\,(Y - Z)$.\n",
    "\n",
    "This is fast, vectorized, and requires only `numpy.random.Generator.exponential`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4c6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_asymmetric_rvs_numpy(\n",
    "    rng: np.random.Generator,\n",
    "    kappa: float,\n",
    "    loc: float = 0.0,\n",
    "    scale: float = 1.0,\n",
    "    size: int | tuple[int, ...] = 1,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Generate random variates using only NumPy.\n",
    "\n",
    "    Uses: X = loc + scale * (Y - Z),\n",
    "    where Y ~ Exp(rate=kappa) and Z ~ Exp(rate=1/kappa) independent.\n",
    "    \"\"\"\n",
    "    _validate_kappa_scale(kappa, scale)\n",
    "\n",
    "    # NumPy parameterizes exponential by its mean (scale = 1/rate).\n",
    "    y = rng.exponential(scale=1.0 / kappa, size=size)\n",
    "    z = rng.exponential(scale=kappa, size=size)\n",
    "    return loc + scale * (y - z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e2d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo validation: moments\n",
    "\n",
    "kappa = 2.0\n",
    "loc = 0.0\n",
    "scale = 1.0\n",
    "\n",
    "n = 300_000\n",
    "x_samp = laplace_asymmetric_rvs_numpy(rng, kappa, loc=loc, scale=scale, size=n)\n",
    "\n",
    "mean_th, var_th, skew_th, kurt_th = laplace_asymmetric_moments(kappa, loc=loc, scale=scale)\n",
    "\n",
    "print(\"sample mean   \", float(np.mean(x_samp)), \"theory\", mean_th)\n",
    "print(\"sample var    \", float(np.var(x_samp)), \"theory\", var_th)\n",
    "print(\"sample skew   \", float(stats.skew(x_samp)), \"theory\", skew_th)\n",
    "print(\"sample kurt*  \", float(stats.kurtosis(x_samp, fisher=True)), \"theory\", kurt_th, \"(*excess)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a6c5d",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We'll visualize:\n",
    "\n",
    "- the **PDF** and **CDF** for a chosen parameter set\n",
    "- **Monte Carlo samples** via histogram (PDF overlay)\n",
    "- **empirical CDF** vs theoretical CDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e2d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = 2.0\n",
    "loc = 0.0\n",
    "scale = 1.0\n",
    "\n",
    "n = 120_000\n",
    "x_samp = laplace_asymmetric_rvs_numpy(rng, kappa, loc=loc, scale=scale, size=n)\n",
    "\n",
    "x_grid = np.linspace(-8, 8, 2000)\n",
    "pdf = laplace_asymmetric_pdf(x_grid, kappa, loc=loc, scale=scale)\n",
    "cdf = laplace_asymmetric_cdf(x_grid, kappa, loc=loc, scale=scale)\n",
    "\n",
    "# Empirical CDF\n",
    "x_sorted = np.sort(x_samp)\n",
    "ecdf = np.arange(1, n + 1) / n\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=2,\n",
    "    subplot_titles=(\n",
    "        \"PDF\", \"Histogram + PDF overlay\", \"CDF\", \"Empirical CDF vs theoretical\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# PDF\n",
    "fig.add_trace(go.Scatter(x=x_grid, y=pdf, mode=\"lines\", name=\"pdf\"), row=1, col=1)\n",
    "\n",
    "# Histogram + PDF\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=x_samp,\n",
    "        nbinsx=120,\n",
    "        histnorm=\"probability density\",\n",
    "        opacity=0.45,\n",
    "        name=\"samples\",\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x_grid, y=pdf, mode=\"lines\", name=\"pdf overlay\", line=dict(color=\"black\")),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "# CDF\n",
    "fig.add_trace(go.Scatter(x=x_grid, y=cdf, mode=\"lines\", name=\"cdf\", showlegend=False), row=2, col=1)\n",
    "\n",
    "# Empirical vs theoretical\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x_sorted, y=ecdf, mode=\"lines\", name=\"empirical\", showlegend=False),\n",
    "    row=2,\n",
    "    col=2,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x_grid, y=cdf, mode=\"lines\", name=\"theoretical\", line=dict(color=\"black\", dash=\"dash\"), showlegend=False),\n",
    "    row=2,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "for r in [1, 2]:\n",
    "    for c in [1, 2]:\n",
    "        fig.update_xaxes(title_text=\"x\", row=r, col=c)\n",
    "\n",
    "fig.update_yaxes(title_text=\"f(x)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"density\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"F(x)\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"probability\", row=2, col=2)\n",
    "\n",
    "fig.update_layout(title=f\"Asymmetric Laplace visuals (kappa={kappa}, loc={loc}, scale={scale})\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3c4d5",
   "metadata": {},
   "source": [
    "## 9) SciPy Integration\n",
    "\n",
    "SciPy provides `scipy.stats.laplace_asymmetric` with the usual `rv_continuous` interface:\n",
    "\n",
    "- `laplace_asymmetric.pdf(x, kappa, loc=0, scale=1)`\n",
    "- `laplace_asymmetric.cdf(x, kappa, loc=0, scale=1)`\n",
    "- `laplace_asymmetric.rvs(kappa, loc=0, scale=1, size=..., random_state=...)`\n",
    "- `laplace_asymmetric.fit(data)` (MLE)\n",
    "\n",
    "As always in SciPy, you can **freeze** parameters: `rv = laplace_asymmetric(kappa, loc=..., scale=...)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4c3b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import laplace_asymmetric\n",
    "\n",
    "kappa_true = 1.7\n",
    "loc_true = 0.8\n",
    "scale_true = 0.6\n",
    "\n",
    "data = laplace_asymmetric.rvs(\n",
    "    kappa_true,\n",
    "    loc=loc_true,\n",
    "    scale=scale_true,\n",
    "    size=5000,\n",
    "    random_state=rng,\n",
    ")\n",
    "\n",
    "# Fit returns (kappa_hat, loc_hat, scale_hat)\n",
    "kappa_hat, loc_hat, scale_hat = laplace_asymmetric.fit(data)\n",
    "print(\"true params:\", (kappa_true, loc_true, scale_true))\n",
    "print(\"fit  params:\", (float(kappa_hat), float(loc_hat), float(scale_hat)))\n",
    "\n",
    "# Frozen distribution object\n",
    "rv = laplace_asymmetric(kappa_hat, loc=loc_hat, scale=scale_hat)\n",
    "\n",
    "x = np.linspace(np.percentile(data, 0.5), np.percentile(data, 99.5), 800)\n",
    "pdf_hat = rv.pdf(x)\n",
    "cdf_hat = rv.cdf(x)\n",
    "\n",
    "print(\"pdf(x) shape:\", pdf_hat.shape)\n",
    "print(\"cdf(x) in [0,1]?:\", float(np.min(cdf_hat)), float(np.max(cdf_hat)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8b7c6d",
   "metadata": {},
   "source": [
    "## 10) Statistical Use Cases\n",
    "\n",
    "### 10.1 Hypothesis testing (example: symmetry)\n",
    "\n",
    "A simple question is whether the distribution is symmetric, i.e. $\\kappa=1$.\n",
    "One approach is a **likelihood ratio test** comparing:\n",
    "\n",
    "- $H_0$: $\\kappa = 1$ (symmetric Laplace)\n",
    "- $H_1$: $\\kappa$ free\n",
    "\n",
    "Under standard regularity conditions, the LRT statistic is asymptotically $\\chi^2_1$.\n",
    "\n",
    "### 10.2 Bayesian modeling\n",
    "\n",
    "The asymmetric Laplace is often used as a likelihood when you want the location parameter to represent a **target quantile**. With an appropriate mapping between $\\kappa$ and $\\tau$, the negative log-likelihood is proportional to the **check loss** used in quantile regression.\n",
    "\n",
    "In a Bayesian setting, you might put priors on:\n",
    "\n",
    "- `loc` (e.g. normal prior)\n",
    "- `scale` (e.g. half-normal or half-Cauchy)\n",
    "- `kappa` (e.g. log-normal, since $\\kappa>0$)\n",
    "\n",
    "### 10.3 Generative modeling\n",
    "\n",
    "Asymmetric Laplace noise is a useful alternative to Gaussian noise in generative models when you want **robustness** (exponential tails) and **asymmetry** (one-sided outliers more common).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b2a1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood ratio test (LRT) for symmetry: kappa = 1\n",
    "\n",
    "kappa_true = 2.0\n",
    "loc_true = 0.2\n",
    "scale_true = 1.1\n",
    "\n",
    "n = 3000\n",
    "x = laplace_asymmetric.rvs(\n",
    "    kappa_true,\n",
    "    loc=loc_true,\n",
    "    scale=scale_true,\n",
    "    size=n,\n",
    "    random_state=rng,\n",
    ")\n",
    "\n",
    "# H1: free kappa\n",
    "k1, loc1, s1 = laplace_asymmetric.fit(x)\n",
    "ll1 = float(np.sum(laplace_asymmetric.logpdf(x, k1, loc=loc1, scale=s1)))\n",
    "\n",
    "# H0: fix kappa=1 (SciPy convention: first shape param fixed via f0)\n",
    "k0, loc0, s0 = laplace_asymmetric.fit(x, f0=1.0)\n",
    "ll0 = float(np.sum(laplace_asymmetric.logpdf(x, k0, loc=loc0, scale=s0)))\n",
    "\n",
    "lrt = 2.0 * (ll1 - ll0)\n",
    "p_value = float(chi2.sf(lrt, df=1))\n",
    "\n",
    "print(\"H1 fit (kappa, loc, scale):\", float(k1), float(loc1), float(s1))\n",
    "print(\"H0 fit (kappa fixed=1):    \", float(k0), float(loc0), float(s0))\n",
    "print(\"LRT statistic:\", lrt)\n",
    "print(\"Approx p-value (chi2_1):\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2b3c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection to quantiles: for fixed kappa and scale, the MLE of loc is a tau-quantile.\n",
    "\n",
    "kappa = 2.0\n",
    "scale = 1.0\n",
    "tau = kappa**2 / (1.0 + kappa**2)\n",
    "\n",
    "# Data do not have to be ALD for this optimization identity to make sense.\n",
    "data = rng.normal(loc=1.0, scale=2.0, size=400)\n",
    "\n",
    "grid = np.linspace(np.percentile(data, 1), np.percentile(data, 99), 500)\n",
    "nll_vals = np.array([laplace_asymmetric_nll(data, kappa, loc=g, scale=scale) for g in grid])\n",
    "\n",
    "loc_hat_grid = float(grid[np.argmin(nll_vals)])\n",
    "loc_tau_quantile = float(np.quantile(data, tau))\n",
    "\n",
    "print(\"tau:\", tau)\n",
    "print(\"argmin NLL over grid:\", loc_hat_grid)\n",
    "print(\"empirical tau-quantile:\", loc_tau_quantile)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=grid, y=nll_vals, mode=\"lines\", name=\"NLL(loc)\"))\n",
    "fig.add_vline(x=loc_hat_grid, line_dash=\"dash\", line_color=\"green\", annotation_text=\"MLE loc (grid)\")\n",
    "fig.add_vline(x=loc_tau_quantile, line_dash=\"dot\", line_color=\"red\", annotation_text=\"tau-quantile\")\n",
    "fig.update_layout(\n",
    "    title=f\"Asymmetric Laplace NLL as a function of loc (kappa={kappa}, tau={tau:.3f})\",\n",
    "    xaxis_title=\"loc\",\n",
    "    yaxis_title=\"negative log-likelihood\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d2c3b4",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Parameterization mismatches**: other sources may swap rate/scale conventions; SciPy notes some references use the reciprocal of `scale`.\n",
    "- **Interpreting `loc`**: here `loc` is the **mode**, not the mean (unless $\\kappa=1$).\n",
    "- **Invalid parameters**: require `kappa > 0` and `scale > 0`.\n",
    "- **Numerical issues in tails**: prefer `logpdf` over `pdf` when working with extreme values (to avoid underflow).\n",
    "- **MGF domain**: the MGF exists only for $t\\in(-1/(\\kappa\\,\\mathrm{scale}),\\kappa/\\mathrm{scale})$.\n",
    "- **Fitting**: `fit` is an MLE routine; for small samples or extreme asymmetry it can be unstable. Use diagnostics (QQ plots, residual checks) and consider robust alternatives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3d2e1f",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `laplace_asymmetric` is a **continuous** two-sided exponential distribution with **asymmetric tails** controlled by $\\kappa$.\n",
    "- In SciPy's parameterization, `loc` is the **mode**, and the mean is `loc + scale*(1/kappa - kappa)`.\n",
    "- Moments are available in closed form; skewness changes sign around $\\kappa=1$.\n",
    "- Sampling is easy via a **difference of exponentials** (NumPy-only).\n",
    "- The likelihood corresponds (up to constants) to a **weighted absolute deviation** / **quantile regression check loss**.\n",
    "- SciPy provides `pdf`, `cdf`, `rvs`, and `fit` via `scipy.stats.laplace_asymmetric`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6e5d4c",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- SciPy docs: `scipy.stats.laplace_asymmetric`\n",
    "- Wikipedia: \"Asymmetric Laplace distribution\"\n",
    "- Kozubowski & Podg\\u00f3rski (2000): *A Multivariate and Asymmetric Generalization of Laplace Distribution*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
