{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7c2a9d1",
   "metadata": {},
   "source": [
    "# Landau distribution\n",
    "\n",
    "The **Landau** distribution is a highly right-skewed, heavy-tailed continuous distribution that appears famously in **high-energy physics**: it models the stochastic energy loss of a fast charged particle traversing a *thin absorber* (\"Landau straggling\").\n",
    "\n",
    "Unlike many familiar distributions, the Landau distribution has **no finite mean or variance**, so estimation and testing should lean on **robust summaries** like the median, quantiles, and likelihood-based methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2e6f4a",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "- Know the **definition** (PDF as an integral) and the **support/parameters**.\n",
    "- Build intuition from the **energy-loss** origin and connect it to **stable laws**.\n",
    "- Understand which **moments do not exist** and which summaries still do (median/quantiles).\n",
    "- Implement **NumPy-only sampling** via the Chambers–Mallows–Stuck method.\n",
    "- Visualize the **PDF/CDF** and typical Monte Carlo behavior.\n",
    "- Use `scipy.stats.landau` for `pdf`, `cdf`, `rvs`, and `fit`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy.stats import landau, moyal, norm\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "rng = np.random.default_rng(7)\n",
    "\n",
    "print(\"Python\", platform.python_version())\n",
    "print(\"NumPy\", np.__version__)\n",
    "print(\"SciPy\", scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d4f8b1",
   "metadata": {},
   "source": [
    "## 1) Title & classification\n",
    "\n",
    "- **Name**: `landau`\n",
    "- **Type**: continuous\n",
    "- **Support**: $x \\in (-\\infty, \\infty)$\n",
    "- **Parameter space (SciPy)**: `loc` $\\in \\mathbb{R}$, `scale` $>0$ (no shape parameters)\n",
    "\n",
    "SciPy’s parameterization uses the usual location/scale transform:\n",
    "\n",
    "$$f(x;\\,\\mathrm{loc},\\mathrm{scale}) = \\frac{1}{\\mathrm{scale}}\\,f\\!\\left(\\frac{x-\\mathrm{loc}}{\\mathrm{scale}}\\right).$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a0c3d2",
   "metadata": {},
   "source": [
    "## 2) Intuition & motivation\n",
    "\n",
    "### What this distribution models\n",
    "Landau derived this distribution (1944) as an approximation to the **energy loss by ionization** of a fast charged particle in a *thin* layer of material.\n",
    "\n",
    "- The particle undergoes **many small energy transfers** (ionizations).\n",
    "- Occasionally, it produces a **rare large transfer** (a \"delta ray\").\n",
    "- Those rare events create a **long right tail**: extreme losses happen infrequently but are much larger than typical losses.\n",
    "\n",
    "### Typical real-world use cases\n",
    "- High-energy physics: modeling **$\\mathrm{d}E/\\mathrm{d}x$** in tracking detectors.\n",
    "- Radiation/particle instrumentation: charge deposition in silicon sensors.\n",
    "- Any setting where outcomes are mostly moderate but have **rare, very large positive excursions**.\n",
    "\n",
    "### Relations to other distributions\n",
    "- **Stable laws**: Landau is a special case of a **$\\alpha$-stable** distribution with stability index $\\alpha=1$ and maximal right skew.\n",
    "- **Cauchy**: also $\\alpha=1$ stable, but symmetric (no skew). Landau is its strongly skewed cousin.\n",
    "- **Moyal distribution**: a convenient analytic approximation to Landau often used in detector physics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c7d5e1",
   "metadata": {},
   "source": [
    "## 3) Formal definition\n",
    "\n",
    "### PDF\n",
    "A standard (\"unit\") Landau random variable has density\n",
    "\n",
    "$$f(x) = \\frac{1}{\\pi}\\int_0^\\infty \\exp\\bigl(-t\\log t - x t\\bigr)\\,\\sin(\\pi t)\\,dt, \\qquad x\\in\\mathbb{R}.$$\n",
    "\n",
    "This integral definition is typical: the Landau PDF has **no simple closed form** in elementary functions.\n",
    "\n",
    "### CDF\n",
    "The CDF is defined in the usual way:\n",
    "\n",
    "$$F(x) = \\int_{-\\infty}^{x} f(u)\\,du.$$\n",
    "\n",
    "In practice, $F$ and $f$ are evaluated numerically; SciPy delegates these computations to the **Boost** special functions implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e8f4a0",
   "metadata": {},
   "source": [
    "## 4) Moments & properties\n",
    "\n",
    "### Mean/variance/skewness/kurtosis\n",
    "- **Mean**: does not exist (diverges).\n",
    "- **Variance**: does not exist (diverges).\n",
    "- **Skewness/kurtosis**: undefined because they require finite moments.\n",
    "\n",
    "Robust summaries that *do* exist and are useful:\n",
    "- **Median** and other **quantiles**.\n",
    "- **Mode** (maximum of the PDF).\n",
    "\n",
    "### MGF / characteristic function\n",
    "- The **MGF** $M(t)=\\mathbb{E}[e^{tX}]$ does not exist for any $t>0$ due to the heavy right tail (so it is not defined in a neighborhood of 0).\n",
    "- The **characteristic function** $\\varphi(t)=\\mathbb{E}[e^{itX}]$ exists for all $t$.\n",
    "\n",
    "A standard Landau characteristic function can be written (with $\\varphi(0)=1$):\n",
    "\n",
    "$$\\varphi(t)=\\exp\\left(-|t|\\left[1 + i\\,\\frac{2}{\\pi}\\,\\operatorname{sign}(t)\\,\\log|t|\\right]\\right).$$\n",
    "\n",
    "### Entropy\n",
    "There is no commonly used simple closed form; SciPy can evaluate it numerically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1f0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic numerical summaries for the *standard* Landau (loc=0, scale=1)\n",
    "\n",
    "mean, var, skew, kurt = landau.stats(moments=\"mvsk\")\n",
    "median0 = float(landau.median())\n",
    "q25_0, q75_0 = landau.ppf([0.25, 0.75])\n",
    "iqr0 = float(q75_0 - q25_0)\n",
    "f0_at_median = float(landau.pdf(median0))\n",
    "entropy0 = float(landau.entropy())\n",
    "\n",
    "print(\"mean, var, skew, kurt:\", mean, var, skew, kurt)\n",
    "print(\"median:\", median0)\n",
    "print(\"IQR:\", iqr0)\n",
    "print(\"pdf(median):\", f0_at_median)\n",
    "print(\"entropy:\", entropy0)\n",
    "\n",
    "# Mode via 1D optimization of the logpdf\n",
    "res = optimize.minimize_scalar(lambda x: -landau.logpdf(x), bracket=(-5, -0.5, 5), method=\"Brent\")\n",
    "mode0 = float(res.x)\n",
    "print(\"mode (approx):\", mode0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f2c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def landau_cf_standard(t: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Characteristic function of the standard Landau distribution.\"\"\"\n",
    "\n",
    "    t = np.asarray(t, dtype=float)\n",
    "    out = np.empty_like(t, dtype=np.complex128)\n",
    "    mask0 = t == 0\n",
    "    out[mask0] = 1.0 + 0.0j\n",
    "    tt = t[~mask0]\n",
    "    out[~mask0] = np.exp(\n",
    "        -np.abs(tt)\n",
    "        * (1.0 + 1j * (2.0 / np.pi) * np.sign(tt) * np.log(np.abs(tt)))\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "# Visualize Re/Im of φ(t)\n",
    "t = np.linspace(-12, 12, 3001)\n",
    "phi = landau_cf_standard(t)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Re φ(t)\", \"Im φ(t)\"))\n",
    "fig.add_trace(go.Scatter(x=t, y=np.real(phi), mode=\"lines\"), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=t, y=np.imag(phi), mode=\"lines\"), row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"t\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"t\", row=1, col=2)\n",
    "fig.update_layout(width=950, height=350, showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "print(\"|φ(t)| = exp(-|t|)  (the magnitude ignores the log phase term)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a8b2e7",
   "metadata": {},
   "source": [
    "## 5) Parameter interpretation\n",
    "\n",
    "SciPy uses the standard location/scale transform:\n",
    "\n",
    "$$X \\sim \\mathrm{Landau}(\\mathrm{loc},\\mathrm{scale}) \\quad\\Longleftrightarrow\\quad X = \\mathrm{loc} + \\mathrm{scale}\\,Z, \\; Z\\sim\\mathrm{Landau}(0,1).$$\n",
    "\n",
    "So:\n",
    "- `loc` shifts the distribution horizontally.\n",
    "- `scale` stretches it: quantiles, median and mode all scale linearly.\n",
    "\n",
    "### A common alternative parameterization\n",
    "Because the Landau law is **1-stable**, many references use a parameter pair $(\\mu, c)$ in which the **stable addition rules** are simple. In that parameterization, the scale also induces a location correction when converted to SciPy’s `(loc, scale)`:\n",
    "\n",
    "$$\\mathrm{loc} = \\mu + \\frac{2c}{\\pi}\\log c, \\qquad \\mathrm{scale}=c,$$\n",
    "\n",
    "or equivalently\n",
    "\n",
    "$$\\mu = \\mathrm{loc} - \\frac{2\\,\\mathrm{scale}}{\\pi}\\log(\\mathrm{scale}).$$\n",
    "\n",
    "We'll exploit this in the **generative** section when adding independent Landau variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b7c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How loc and scale change the shape\n\n\ndef plot_landau_parameter_effects() -> None:\n    x = np.linspace(-5, 20, 4000)\n\n    fig = make_subplots(\n        rows=1,\n        cols=2,\n        subplot_titles=(\"Varying loc (scale=1)\", \"Varying scale (loc=0)\"),\n    )\n\n    for loc in [-2.0, 0.0, 2.0]:\n        fig.add_trace(\n            go.Scatter(x=x, y=landau.pdf(x, loc=loc, scale=1.0), mode=\"lines\", name=f\"loc={loc}\"),\n            row=1,\n            col=1,\n        )\n\n    for scale in [0.5, 1.0, 2.0]:\n        fig.add_trace(\n            go.Scatter(x=x, y=landau.pdf(x, loc=0.0, scale=scale), mode=\"lines\", name=f\"scale={scale}\"),\n            row=1,\n            col=2,\n        )\n\n    fig.update_xaxes(title_text=\"x\", row=1, col=1)\n    fig.update_yaxes(title_text=\"density\", row=1, col=1)\n    fig.update_xaxes(title_text=\"x\", row=1, col=2)\n    fig.update_yaxes(title_text=\"density\", row=1, col=2)\n    fig.update_layout(width=1050, height=420)\n    fig.show()\n\n\nplot_landau_parameter_effects()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c3a2b",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### Tail behavior (key fact)\n",
    "A crucial asymptotic for the standard Landau density is the **power-law right tail**:\n",
    "\n",
    "$$f(x) \\sim \\frac{2}{\\pi x^2} \\quad (x\\to\\infty), \\qquad \\mathbb{P}(X>x) \\sim \\frac{2}{\\pi x}.$$\n",
    "\n",
    "This is the source of divergent moments.\n",
    "\n",
    "### Expectation (why the mean does not exist)\n",
    "A (finite) mean requires\n",
    "\n",
    "$$\\int_{0}^{\\infty} x\\,f(x)\\,dx < \\infty.$$\n",
    "\n",
    "But with the tail approximation $x f(x) \\sim \\tfrac{2}{\\pi x}$, we get\n",
    "\n",
    "$$\\int^\\infty \\frac{1}{x}\\,dx = \\infty,$$\n",
    "\n",
    "so the mean diverges (logarithmically).\n",
    "\n",
    "### Variance (why it does not exist)\n",
    "Similarly, $\\mathbb{E}[X^2]$ would require\n",
    "\n",
    "$$\\int_0^{\\infty} x^2 f(x)\\,dx < \\infty,$$\n",
    "\n",
    "but $x^2 f(x) \\to 2/\\pi$, so the integral diverges like $\\int^\\infty 1\\,dx$.\n",
    "\n",
    "### Likelihood (loc/scale)\n",
    "For i.i.d. data $x_1,\\dots,x_n$ from $\\mathrm{Landau}(\\mathrm{loc},\\mathrm{scale})$, the log-likelihood is\n",
    "\n",
    "$$\\ell(\\mathrm{loc},\\mathrm{scale}) = \\sum_{i=1}^n \\log f\\!\\left(\\frac{x_i-\\mathrm{loc}}{\\mathrm{scale}}\\right) - n\\log(\\mathrm{scale}).$$\n",
    "\n",
    "There is no closed-form MLE; we typically optimize it numerically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b9c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerically verify the right-tail constants using SciPy\n",
    "\n",
    "x = np.logspace(0, 6, 200)  # 1 ... 1e6\n",
    "tail_pdf_const = landau.pdf(x) * x**2\n",
    "tail_sf_const = landau.sf(x) * x\n",
    "limit = 2.0 / np.pi\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(r\"x^2 f(x) → 2/π\", r\"x·P(X>x) → 2/π\"),\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=x, y=tail_pdf_const, mode=\"lines\"), row=1, col=1)\n",
    "fig.add_hline(y=limit, line=dict(dash=\"dash\"), row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"x\", type=\"log\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=r\"x^2 f(x)\", row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=tail_sf_const, mode=\"lines\"), row=1, col=2)\n",
    "fig.add_hline(y=limit, line=dict(dash=\"dash\"), row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"x\", type=\"log\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=r\"x·sf(x)\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(width=1050, height=420, showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "print(\"2/π ≈\", limit)\n",
    "print(\"x^2 f(x) at 1e6:\", float(tail_pdf_const[-1]))\n",
    "print(\"x·sf(x) at 1e6:\", float(tail_sf_const[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def landau_loglik(x: np.ndarray, loc: float, scale: float) -> float:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if scale <= 0:\n",
    "        return -np.inf\n",
    "    return float(np.sum(landau.logpdf(x, loc=loc, scale=scale)))\n",
    "\n",
    "\n",
    "def landau_loc_scale_init(x: np.ndarray) -> tuple[float, float]:\n",
    "    \"\"\"Robust initializer based on median and IQR scaling.\"\"\"\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n    med = float(np.median(x))\n    q25, q75 = np.quantile(x, [0.25, 0.75])\n    scale_init = float(max((q75 - q25) / iqr0, 1e-6))\n    loc_init = float(med - scale_init * median0)\n    return loc_init, scale_init\n",
    "\n",
    "\n",
    "def landau_mle_scipy(x: np.ndarray) -> tuple[float, float]:\n",
    "    \"\"\"MLE via SciPy optimizer on (loc, log_scale).\"\"\"\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    def nll(theta: np.ndarray) -> float:\n",
    "        loc = float(theta[0])\n",
    "        scale = float(np.exp(theta[1]))\n",
    "        return -landau_loglik(x, loc=loc, scale=scale)\n",
    "\n",
    "    loc0, scale0 = landau_loc_scale_init(x)\n",
    "\n",
    "    res = optimize.minimize(\n",
    "        nll,\n",
    "        x0=np.array([loc0, np.log(scale0)]),\n",
    "        method=\"Nelder-Mead\",\n",
    "        options={\"maxiter\": 4000},\n",
    "    )\n",
    "    loc_hat, log_scale_hat = res.x\n",
    "    return float(loc_hat), float(np.exp(log_scale_hat))\n",
    "\n",
    "\n",
    "# Demonstrate likelihood estimation\n",
    "true_loc, true_scale = 0.8, 1.2\n",
    "x_sample = landau.rvs(loc=true_loc, scale=true_scale, size=600, random_state=rng)\n",
    "\n",
    "loc_hat, scale_hat = landau_mle_scipy(x_sample)\n",
    "loc_init, scale_init = landau_loc_scale_init(x_sample)\n",
    "\n",
    "print(\"true (loc, scale) =\", (true_loc, true_scale))\n",
    "print(\"init (loc, scale) =\", (loc_init, scale_init))\n",
    "print(\"MLE  (loc, scale) =\", (loc_hat, scale_hat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2c1a9b",
   "metadata": {},
   "source": [
    "## 7) Sampling & simulation (NumPy-only)\n",
    "\n",
    "The Landau distribution is a special case of a **stable** distribution ($\\alpha=1$). A practical way to sample it is the **Chambers–Mallows–Stuck (CMS)** method.\n",
    "\n",
    "For the standard Landau, CMS (specialized to $\\alpha=1$ and maximal right skew) can be written:\n",
    "\n",
    "1. Draw $U \\sim \\mathrm{Unif}(-\\pi/2,\\pi/2)$ and $W \\sim \\mathrm{Exp}(1)$ independently.\n",
    "2. Return\n",
    "\n",
    "$$X = \\frac{2}{\\pi}\\left[(\\tfrac{\\pi}{2}+U)\\tan U\\; -\\; \\log\\left(\\frac{(\\pi/2)\\,W\\cos U}{\\tfrac{\\pi}{2}+U}\\right)\\right].$$\n",
    "\n",
    "Then apply location/scale: $\\;\\mathrm{loc} + \\mathrm{scale}\\,X$.\n",
    "\n",
    "Numerically, we clip $U$ away from $\\pm\\pi/2$ to avoid overflow in `tan` and `cos`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3d1f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def landau_rvs_numpy(\n",
    "    rng: np.random.Generator,\n",
    "    size: int,\n",
    "    loc: float = 0.0,\n",
    "    scale: float = 1.0,\n",
    "    eps: float = 1e-12,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"NumPy-only sampler for Landau via the CMS method.\n",
    "\n",
    "    Parameters match SciPy's (loc, scale) transform.\n",
    "    \"\"\"\n",
    "\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "    if not (0 < eps < 1e-2):\n",
    "        raise ValueError(\"eps must be small and positive\")\n",
    "\n",
    "    u = rng.random(size)\n",
    "    u = np.clip(u, eps, 1.0 - eps)\n",
    "    U = (u - 0.5) * np.pi  # in (-π/2, π/2)\n",
    "    W = rng.exponential(1.0, size=size)\n",
    "\n",
    "    x0 = (2.0 / np.pi) * (\n",
    "        (np.pi / 2.0 + U) * np.tan(U)\n",
    "        - np.log(((np.pi / 2.0) * W * np.cos(U)) / (np.pi / 2.0 + U))\n",
    "    )\n",
    "\n",
    "    return loc + scale * x0\n",
    "\n",
    "\n",
    "# Quick validation against SciPy percentiles\n",
    "n = 250_000\n",
    "x = landau_rvs_numpy(rng, n)\n",
    "qs = np.array([0.01, 0.1, 0.5, 0.9, 0.99])\n",
    "emp = np.quantile(x, qs)\n",
    "the = landau.ppf(qs)\n",
    "\n",
    "print(\"quantiles:\", qs)\n",
    "print(\"empirical:\", emp)\n",
    "print(\"theory   :\", the)\n",
    "print(\"diff     :\", emp - the)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f3c2d",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We'll visualize:\n",
    "- the **PDF** and **CDF** of the standard Landau\n",
    "- a **histogram of Monte Carlo samples** with PDF overlay\n",
    "- the instability of the **sample mean** (a symptom of the missing expectation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF and CDF (standard Landau)\n",
    "\n",
    "xgrid = np.linspace(-5, 20, 5000)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"PDF\", \"CDF\"))\n",
    "fig.add_trace(go.Scatter(x=xgrid, y=landau.pdf(xgrid), mode=\"lines\", name=\"pdf\"), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=xgrid, y=landau.cdf(xgrid), mode=\"lines\", name=\"cdf\"), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"f(x)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"F(x)\", row=1, col=2)\n",
    "fig.update_layout(width=950, height=380, showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "print(\"0.99 quantile:\", float(landau.ppf(0.99)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo: histogram + PDF overlay (clipped for readability)\n",
    "\n",
    "n = 200_000\n",
    "x = landau_rvs_numpy(rng, n)\n",
    "\n",
    "clip_lo, clip_hi = -5.0, 20.0\n",
    "x_vis = x[(x >= clip_lo) & (x <= clip_hi)]\n",
    "fraction_clipped = 1.0 - (len(x_vis) / len(x))\n",
    "\n",
    "xbins = np.linspace(clip_lo, clip_hi, 140)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=x_vis,\n",
    "        xbins=dict(start=clip_lo, end=clip_hi, size=xbins[1] - xbins[0]),\n",
    "        histnorm=\"probability density\",\n",
    "        name=\"samples\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=xgrid,\n",
    "        y=landau.pdf(xgrid),\n",
    "        mode=\"lines\",\n",
    "        line=dict(width=3),\n",
    "        name=\"true pdf\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=f\"Landau samples (n={n:,}) — histogram clipped to [{clip_lo}, {clip_hi}]\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"density\",\n",
    "    width=950,\n",
    "    height=450,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"fraction clipped:\", fraction_clipped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b2c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running mean is unstable; robust location estimates behave better\n",
    "\n",
    "n = 60_000\n",
    "x = landau_rvs_numpy(rng, n)\n",
    "\n",
    "running_mean = np.cumsum(x) / (np.arange(n) + 1)\n",
    "\n",
    "# For comparison: mean after clipping the extreme right tail\n",
    "clip = 50.0\n",
    "x_clip = np.clip(x, -np.inf, clip)\n",
    "running_mean_clip = np.cumsum(x_clip) / (np.arange(n) + 1)\n",
    "\n",
    "# Approximate running median using block medians\n",
    "block = 250\n",
    "m = n // block\n",
    "block_medians = np.array([np.median(x[i * block : (i + 1) * block]) for i in range(m)])\n",
    "avg_block_median = np.cumsum(block_medians) / (np.arange(m) + 1)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    vertical_spacing=0.12,\n",
    "    subplot_titles=(\n",
    "        \"Running mean (unclipped vs clipped)\",\n",
    "        f\"Average of block medians (block={block})\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(x=np.arange(n), y=running_mean, mode=\"lines\", name=\"mean\"), row=1, col=1)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(n), y=running_mean_clip, mode=\"lines\", name=f\"mean clipped @ {clip}\"),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.update_yaxes(title_text=\"mean\", row=1, col=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(m) * block, y=avg_block_median, mode=\"lines\", name=\"avg block median\"),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "fig.update_xaxes(title_text=\"sample index\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"location\", row=2, col=1)\n",
    "\n",
    "fig.update_layout(width=950, height=650)\n",
    "fig.show()\n",
    "\n",
    "print(\"sample median:\", float(np.median(x)))\n",
    "print(\"sample mean:\", float(np.mean(x)))\n",
    "print(\"max sample:\", float(np.max(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2c1b0a",
   "metadata": {},
   "source": [
    "## 9) SciPy integration (`scipy.stats.landau`)\n",
    "\n",
    "Key methods (no shape parameters):\n",
    "- `landau.pdf(x, loc, scale)`\n",
    "- `landau.cdf(x, loc, scale)`\n",
    "- `landau.ppf(q, loc, scale)`\n",
    "- `landau.rvs(loc, scale, size, random_state)`\n",
    "- `landau.fit(data)`  (MLE for `loc`, `scale`)\n",
    "\n",
    "Remember: `landau.stats(moments='mv')` returns `nan` because the mean/variance are not finite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic SciPy usage\n",
    "\n",
    "loc, scale = 1.3, 0.7\n",
    "x = np.array([-1.0, 0.0, 1.0, 5.0])\n",
    "\n",
    "print(\"pdf:\", landau.pdf(x, loc=loc, scale=scale))\n",
    "print(\"cdf:\", landau.cdf(x, loc=loc, scale=scale))\n",
    "\n",
    "samples = landau.rvs(loc=loc, scale=scale, size=5, random_state=rng)\n",
    "print(\"rvs:\", samples)\n",
    "\n",
    "# Fit (MLE) from synthetic data\n",
    "n = 8_000\n",
    "true_loc, true_scale = -0.5, 1.1\n",
    "data = landau.rvs(loc=true_loc, scale=true_scale, size=n, random_state=rng)\n",
    "\n",
    "loc_fit, scale_fit = landau.fit(data)  # returns (loc, scale)\n",
    "loc_iqr, scale_iqr = landau_loc_scale_init(data)\n",
    "\n",
    "print(\"true (loc, scale) =\", (true_loc, true_scale))\n",
    "print(\"fit  (loc, scale) =\", (float(loc_fit), float(scale_fit)))\n",
    "print(\"IQR  (loc, scale) =\", (loc_iqr, scale_iqr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4",
   "metadata": {},
   "source": [
    "## 10) Statistical use cases\n",
    "\n",
    "### Hypothesis testing\n",
    "Because the mean is undefined, tests based on $\\bar{X}$ (e.g. t-tests) are inappropriate.\n",
    "\n",
    "A robust alternative is to test **location** using the **sample median**. For a continuous distribution with median $m$ and density $f(m)>0$:\n",
    "\n",
    "$$\\tilde{X} \\approx \\mathcal{N}\\left(m,\\ \\frac{1}{4n f(m)^2}\\right).$$\n",
    "\n",
    "For $X\\sim\\mathrm{Landau}(\\mathrm{loc},\\mathrm{scale})$:\n",
    "- median is $m = \\mathrm{loc} + \\mathrm{scale}\\,m_0$ where $m_0$ is the standard median\n",
    "- density at the median is $f(m)=f_0(m_0)/\\mathrm{scale}$\n",
    "\n",
    "### Bayesian modeling\n",
    "- Landau likelihood can model **right-skewed, heavy-tailed errors**.\n",
    "- There is no conjugacy; practical inference uses **MCMC** or **grid** methods in low dimensions.\n",
    "\n",
    "### Generative modeling\n",
    "Landau is **stable** (index $\\alpha=1$), so sums of independent Landau variables remain Landau, but you must be careful about parameterizations. In the $(\\mu,c)$ parameterization, addition is simple:\n",
    "\n",
    "$$X\\sim(\\mu_1,c_1),\\ Y\\sim(\\mu_2,c_2)\\ \\Rightarrow\\ X+Y\\sim(\\mu_1+\\mu_2,\\ c_1+c_2).$$\n",
    "\n",
    "Converting back to SciPy `(loc, scale)` introduces the log-shift described in Section 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c3b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location test via the sample median (known scale)\n",
    "\n",
    "def median_z_test_landau_location(\n",
    "    x: np.ndarray,\n",
    "    loc_null: float,\n",
    "    scale: float,\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"Approximate two-sided z-test for the location using the sample median.\"\"\"\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    n = x.size\n",
    "    med = float(np.median(x))\n",
    "\n",
    "    # Under H0: median = loc_null + scale * median0\n",
    "    m_null = loc_null + scale * median0\n",
    "    se = scale / (2.0 * np.sqrt(n) * f0_at_median)\n",
    "\n",
    "    z = (med - m_null) / se\n",
    "    p = 2.0 * (1.0 - norm.cdf(abs(z)))\n",
    "    return float(z), float(p)\n",
    "\n",
    "\n",
    "n = 401\n",
    "scale = 1.0\n",
    "\n",
    "# Under H0\n",
    "x_h0 = landau.rvs(loc=0.0, scale=scale, size=n, random_state=rng)\n",
    "print(\"H0 example:\", median_z_test_landau_location(x_h0, loc_null=0.0, scale=scale))\n",
    "\n",
    "# Under H1 (shifted)\n",
    "x_h1 = landau.rvs(loc=0.8, scale=scale, size=n, random_state=rng)\n",
    "print(\"H1 example:\", median_z_test_landau_location(x_h1, loc_null=0.0, scale=scale))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple Bayesian example: posterior over loc with known scale (grid approximation)\n",
    "\n",
    "tau = 2.0  # prior std for loc\n",
    "true_loc, scale = 1.0, 1.0\n",
    "\n",
    "x = landau.rvs(loc=true_loc, scale=scale, size=60, random_state=rng)\n",
    "\n",
    "# Grid over loc near a robust center\n",
    "center = float(np.median(x) - scale * median0)\n",
    "grid = np.linspace(center - 6.0, center + 6.0, 5001)\n",
    "dx = grid[1] - grid[0]\n",
    "\n",
    "log_prior = norm.logpdf(grid, loc=0.0, scale=tau)\n",
    "log_like = np.sum(landau.logpdf(x[:, None], loc=grid[None, :], scale=scale), axis=0)\n",
    "log_post = log_prior + log_like\n",
    "\n",
    "# stabilize + normalize\n",
    "log_post -= np.max(log_post)\n",
    "post = np.exp(log_post)\n",
    "post /= np.trapz(post, grid)\n",
    "\n",
    "post_cdf = np.cumsum(post) * dx\n",
    "post_cdf /= post_cdf[-1]\n",
    "\n",
    "loc_map = float(grid[np.argmax(post)])\n",
    "loc_med = float(np.interp(0.5, post_cdf, grid))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=grid, y=post, mode=\"lines\", name=\"posterior\"))\n",
    "fig.add_vline(x=true_loc, line=dict(dash=\"dash\"), annotation_text=\"true loc\")\n",
    "fig.add_vline(x=loc_map, line=dict(dash=\"dot\"), annotation_text=\"MAP\")\n",
    "fig.add_vline(x=loc_med, line=dict(dash=\"dot\"), annotation_text=\"posterior median\")\n",
    "fig.update_layout(\n",
    "    title=\"Posterior over loc (Landau likelihood, Normal prior; scale known)\",\n",
    "    xaxis_title=\"loc\",\n",
    "    yaxis_title=\"density\",\n",
    "    width=950,\n",
    "    height=420,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"true loc:\", true_loc)\n",
    "print(\"MAP:\", loc_map)\n",
    "print(\"posterior median:\", loc_med)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e1d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative property: (μ, c) stable addition vs SciPy's (loc, scale)\n",
    "\n",
    "def loc_to_mu(loc: float, scale: float) -> float:\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "    return float(loc - (2.0 * scale / np.pi) * np.log(scale))\n",
    "\n",
    "\n",
    "def mu_to_loc(mu: float, scale: float) -> float:\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "    return float(mu + (2.0 * scale / np.pi) * np.log(scale))\n",
    "\n",
    "\n",
    "loc1, c1 = 0.0, 1.0\n",
    "loc2, c2 = 0.0, 2.0\n",
    "\n",
    "n = 250_000\n",
    "x = landau_rvs_numpy(rng, n, loc=loc1, scale=c1)\n",
    "y = landau_rvs_numpy(rng, n, loc=loc2, scale=c2)\n",
    "z = x + y\n",
    "\n",
    "# Convert to (μ, c), add, then convert back\n",
    "mu1, mu2 = loc_to_mu(loc1, c1), loc_to_mu(loc2, c2)\n",
    "mu_z = mu1 + mu2\n",
    "c_z = c1 + c2\n",
    "loc_z = mu_to_loc(mu_z, c_z)\n",
    "\n",
    "qs = [0.1, 0.5, 0.9]\n",
    "q_emp = np.quantile(z, qs)\n",
    "q_naive = landau.ppf(qs, loc=loc1 + loc2, scale=c_z)\n",
    "q_corr = landau.ppf(qs, loc=loc_z, scale=c_z)\n",
    "\n",
    "print(\"empirical quantiles:\", q_emp)\n",
    "print(\"naive (loc add)  :\", q_naive)\n",
    "print(\"corrected        :\", q_corr)\n",
    "print(\"corrected loc_z  :\", loc_z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1bb2cc",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Do not use the sample mean/variance** as estimators; they are unstable because the corresponding moments do not exist.\n",
    "- **Underflow in the far left tail**: `pdf(x)` can become numerically 0 for large negative `x`. Prefer `logpdf` for inference.\n",
    "- **Parameter validity**: `scale` must be strictly positive.\n",
    "- **Fitting**: MLE can be sensitive with small samples because a few large values dominate the likelihood. Use robust initializations (median/IQR).\n",
    "- **Visualization**: histograms need clipping or log axes to avoid being dominated by rare extreme values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2dd3ee",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `landau` is a **continuous**, highly **right-skewed** distribution with a **power-law right tail**.\n",
    "- **Mean and variance do not exist**; prefer **median/quantiles** and likelihood-based modeling.\n",
    "- Sampling is convenient via the **CMS stable-variable algorithm** (NumPy-only).\n",
    "- SciPy’s `scipy.stats.landau` provides accurate `pdf/cdf/ppf/rvs/fit` implementations.\n",
    "- When adding Landau variables, be careful about parameterization: the $(\\mu,c)$ form adds cleanly, and it maps to SciPy’s `(loc, scale)` with a log shift.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
