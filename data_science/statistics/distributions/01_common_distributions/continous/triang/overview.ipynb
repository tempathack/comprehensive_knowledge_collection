{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triangular Distribution (`triang`)\n",
    "\n",
    "The triangular distribution is a simple **bounded** continuous distribution specified by a **minimum** \\(a\\), a **most likely value** (mode) \\(m\\), and a **maximum** \\(b\\).\n",
    "\n",
    "It’s popular in simulation and decision analysis when you can elicit \\((a,m,b)\\) from domain experts but don’t have enough data (or justification) for a richer family.\n",
    "\n",
    "Throughout this notebook we use the **non-degenerate** case \\(a < m < b\\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook roadmap\n",
    "1) Title & classification\n",
    "2) Intuition & motivation\n",
    "3) Formal definition (PDF/CDF)\n",
    "4) Moments & properties\n",
    "5) Parameter interpretation\n",
    "6) Derivations (\\(\\mathbb{E}[X]\\), \\(\\mathrm{Var}(X)\\), likelihood)\n",
    "7) Sampling & simulation (NumPy-only)\n",
    "8) Visualization (PDF, CDF, Monte Carlo)\n",
    "9) SciPy integration (`scipy.stats.triang`)\n",
    "10) Statistical use cases\n",
    "11) Pitfalls\n",
    "12) Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy.stats import triang as triang_dist\n",
    "from scipy.stats import norm\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "\n",
    "# Record versions for reproducibility (useful when numerical details matter).\n",
    "VERSIONS = {\"numpy\": np.__version__, \"scipy\": scipy.__version__, \"plotly\": plotly.__version__}\n",
    "VERSIONS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites & notation\n",
    "\n",
    "**Prerequisites**\n",
    "- comfort with basic calculus (piecewise integrals)\n",
    "- basic probability (PDF/CDF, expectation)\n",
    "\n",
    "**Two parameterizations**\n",
    "\n",
    "1) **Endpoint + mode** (used in this notebook):\n",
    "- \\(a\\): lower bound\n",
    "- \\(m\\): mode (most likely value)\n",
    "- \\(b\\): upper bound\n",
    "\n",
    "with \\(a < m < b\\) and support \\(x\\in[a,b]\\).\n",
    "\n",
    "2) **SciPy** (`scipy.stats.triang`) uses:\n",
    "- shape \\(c\\in(0,1)\\) = *mode location as a fraction of the interval*\n",
    "- `loc` \\(\\in\\mathbb{R}\\)\n",
    "- `scale` \\(>0\\)\n",
    "\n",
    "Mapping:\n",
    "\\[\n",
    "\\text{loc}=a,\\quad \\text{scale}=b-a,\\quad c=\\frac{m-a}{b-a},\\quad m=a+c\\,(b-a).\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Title & Classification\n",
    "\n",
    "- **Name**: `triang` (Triangular distribution)\n",
    "- **Type**: **continuous**\n",
    "- **Support**: \\(x \\in [a,b]\\)\n",
    "- **Parameter space** (endpoint + mode form):\n",
    "  - \\(a < b\\)\n",
    "  - \\(a < m < b\\)\n",
    "\n",
    "SciPy parameter space:\n",
    "- \\(c \\in (0,1)\\), `loc` \\(\\in\\mathbb{R}\\), `scale` \\(>0\\)\n",
    "- support is \\(x\\in[\\text{loc},\\text{loc}+\\text{scale}]\\)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Intuition & Motivation\n",
    "\n",
    "### What it models\n",
    "A triangular distribution encodes a **bounded uncertainty** with a single most-likely value:\n",
    "- you believe values cannot go below \\(a\\) or above \\(b\\)\n",
    "- values near \\(m\\) are most plausible\n",
    "- plausibility changes **linearly** as you move away from \\(m\\)\n",
    "\n",
    "### Typical real-world use cases\n",
    "- **Project planning / PERT-style estimation**: durations with (min, most likely, max)\n",
    "- **Risk analysis**: costs, demand, supply with hard bounds and a best guess\n",
    "- **Monte Carlo simulation**: quick, interpretable priors for bounded variables\n",
    "- **Measurement / rounding uncertainty**: bounded error with a most likely offset\n",
    "\n",
    "### Relations to other distributions\n",
    "- **Uniform**: if you only know \\([a,b]\\) but not a “most likely” value, the uniform is a natural baseline.\n",
    "- **Symmetric triangular**: when \\(m=(a+b)/2\\), the distribution is symmetric (skewness 0).\n",
    "- **Irwin–Hall (sum of uniforms)**: if \\(U_1,U_2\\stackrel{iid}{\\sim}\\text{Unif}(0,1)\\), then \\(U_1+U_2\\) has a symmetric triangular density on \\([0,2]\\).\n",
    "- **Beta / PERT**: Beta-PERT is a smoother alternative that also uses (min, mode, max) but yields differentiable densities.\n",
    "- **Piecewise-Beta view**: the left side behaves like a scaled \\(\\text{Beta}(2,1)\\), the right side like a scaled \\(\\text{Beta}(1,2)\\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Formal Definition\n",
    "\n",
    "Let \\(X\\sim\\text{Triang}(a,m,b)\\) with \\(a<m<b\\).\n",
    "\n",
    "### PDF\n",
    "The density is piecewise linear:\n",
    "\n",
    "\\[\n",
    "f(x\\mid a,m,b) =\n",
    "\\begin{cases}\n",
    "\\dfrac{2(x-a)}{(b-a)(m-a)}, & a\\le x\\le m,\\\\[6pt]\n",
    "\\dfrac{2(b-x)}{(b-a)(b-m)}, & m< x\\le b,\\\\[6pt]\n",
    "0, & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "\\]\n",
    "\n",
    "The maximum density (at \\(x=m\\)) is always \\(\\;\\frac{2}{b-a}\\;\\) because the graph is a triangle with base \\(b-a\\) and area 1.\n",
    "\n",
    "### CDF\n",
    "\\[\n",
    "F(x\\mid a,m,b)=\n",
    "\\begin{cases}\n",
    "0, & x<a,\\\\[6pt]\n",
    "\\dfrac{(x-a)^2}{(b-a)(m-a)}, & a\\le x\\le m,\\\\[8pt]\n",
    "1-\\dfrac{(b-x)^2}{(b-a)(b-m)}, & m< x\\le b,\\\\[8pt]\n",
    "1, & x>b.\n",
    "\\end{cases}\n",
    "\\]\n",
    "\n",
    "We’ll implement these directly in NumPy and compare to `scipy.stats.triang`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_triang_params(a: float, m: float, b: float) -> None:\n",
    "    if not (np.isfinite(a) and np.isfinite(m) and np.isfinite(b)):\n",
    "        raise ValueError(\"Parameters must be finite.\")\n",
    "    if not (a < m < b):\n",
    "        raise ValueError(\"Require a < m < b (non-degenerate triangular distribution).\")\n",
    "\n",
    "\n",
    "def triang_params_to_scipy(a: float, m: float, b: float) -> tuple[float, float, float]:\n",
    "    '''Map (a, m, b) -> (c, loc, scale) for scipy.stats.triang.'''\n",
    "    _validate_triang_params(a, m, b)\n",
    "    scale = b - a\n",
    "    c = (m - a) / scale\n",
    "    return float(c), float(a), float(scale)\n",
    "\n",
    "\n",
    "def scipy_params_to_triang(c: float, loc: float, scale: float) -> tuple[float, float, float]:\n",
    "    '''Map (c, loc, scale) from scipy.stats.triang -> (a, m, b).'''\n",
    "    if not (np.isfinite(c) and np.isfinite(loc) and np.isfinite(scale)):\n",
    "        raise ValueError(\"Parameters must be finite.\")\n",
    "    if not (0.0 < c < 1.0):\n",
    "        raise ValueError(\"Require 0 < c < 1 for a non-degenerate mode inside the interval.\")\n",
    "    if not (scale > 0.0):\n",
    "        raise ValueError(\"Require scale > 0.\")\n",
    "    a = loc\n",
    "    b = loc + scale\n",
    "    m = loc + c * scale\n",
    "    return float(a), float(m), float(b)\n",
    "\n",
    "\n",
    "def triang_pdf(x: np.ndarray, a: float, m: float, b: float) -> np.ndarray:\n",
    "    '''PDF of Triang(a, m, b) evaluated at x (NumPy-only).'''\n",
    "    _validate_triang_params(a, m, b)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    pdf = np.zeros_like(x, dtype=float)\n",
    "    left = (x >= a) & (x <= m)\n",
    "    right = (x > m) & (x <= b)\n",
    "\n",
    "    pdf[left] = 2.0 * (x[left] - a) / ((b - a) * (m - a))\n",
    "    pdf[right] = 2.0 * (b - x[right]) / ((b - a) * (b - m))\n",
    "    return pdf\n",
    "\n",
    "\n",
    "def triang_cdf(x: np.ndarray, a: float, m: float, b: float) -> np.ndarray:\n",
    "    '''CDF of Triang(a, m, b) evaluated at x (NumPy-only).'''\n",
    "    _validate_triang_params(a, m, b)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    cdf = np.zeros_like(x, dtype=float)\n",
    "\n",
    "    left = (x >= a) & (x <= m)\n",
    "    right = (x > m) & (x <= b)\n",
    "    above = x > b\n",
    "\n",
    "    cdf[left] = (x[left] - a) ** 2 / ((b - a) * (m - a))\n",
    "    cdf[right] = 1.0 - (b - x[right]) ** 2 / ((b - a) * (b - m))\n",
    "    cdf[above] = 1.0\n",
    "    return cdf\n",
    "\n",
    "\n",
    "def triang_ppf(u: np.ndarray, a: float, m: float, b: float) -> np.ndarray:\n",
    "    '''Inverse CDF (percent point function) of Triang(a, m, b) (NumPy-only).'''\n",
    "    _validate_triang_params(a, m, b)\n",
    "    u = np.asarray(u, dtype=float)\n",
    "    if np.any((u < 0.0) | (u > 1.0)):\n",
    "        raise ValueError(\"u must lie in [0,1].\")\n",
    "\n",
    "    p = (m - a) / (b - a)  # F(m)\n",
    "\n",
    "    x = np.empty_like(u, dtype=float)\n",
    "    left = u < p\n",
    "    right = ~left\n",
    "\n",
    "    x[left] = a + np.sqrt(u[left] * (b - a) * (m - a))\n",
    "    x[right] = b - np.sqrt((1.0 - u[right]) * (b - a) * (b - m))\n",
    "    return x\n",
    "\n",
    "\n",
    "def triang_rvs_numpy(size: int, a: float, m: float, b: float, rng: np.random.Generator) -> np.ndarray:\n",
    "    '''Random variates from Triang(a, m, b) using inverse transform sampling (NumPy-only).'''\n",
    "    u = rng.random(size)\n",
    "    return triang_ppf(u, a, m, b)\n",
    "\n",
    "\n",
    "def triang_mean(a: float, m: float, b: float) -> float:\n",
    "    _validate_triang_params(a, m, b)\n",
    "    return float((a + m + b) / 3.0)\n",
    "\n",
    "\n",
    "def triang_second_moment(a: float, m: float, b: float) -> float:\n",
    "    _validate_triang_params(a, m, b)\n",
    "    return float((a * a + b * b + m * m + a * b + a * m + b * m) / 6.0)\n",
    "\n",
    "\n",
    "def triang_variance(a: float, m: float, b: float) -> float:\n",
    "    _validate_triang_params(a, m, b)\n",
    "    return float((a * a + b * b + m * m - a * b - a * m - b * m) / 18.0)\n",
    "\n",
    "\n",
    "def triang_skewness(a: float, m: float, b: float) -> float:\n",
    "    _validate_triang_params(a, m, b)\n",
    "    delta = a * a + b * b + m * m - a * b - a * m - b * m\n",
    "    num = math.sqrt(2.0) * (a + b - 2.0 * m) * (2.0 * a - b - m) * (a - 2.0 * b + m)\n",
    "    den = 5.0 * (delta ** 1.5)\n",
    "    return float(num / den)\n",
    "\n",
    "\n",
    "def triang_excess_kurtosis() -> float:\n",
    "    # Property of the triangular family: constant excess kurtosis.\n",
    "    return float(-3.0 / 5.0)\n",
    "\n",
    "\n",
    "def triang_entropy(a: float, b: float) -> float:\n",
    "    '''Differential entropy in nats; depends only on the interval length (b-a).'''\n",
    "    if not (np.isfinite(a) and np.isfinite(b)):\n",
    "        raise ValueError(\"Parameters must be finite.\")\n",
    "    if not (b > a):\n",
    "        raise ValueError(\"Require b > a.\")\n",
    "    return float(0.5 + math.log((b - a) / 2.0))\n",
    "\n",
    "\n",
    "def triang_mgf(t: np.ndarray, a: float, m: float, b: float) -> np.ndarray:\n",
    "    '''Moment generating function M(t)=E[e^{tX}] (NumPy-only).\n",
    "\n",
    "    Closed form for t != 0; uses a 2nd-order Taylor expansion for small |t| to avoid cancellation.\n",
    "    '''\n",
    "\n",
    "    _validate_triang_params(a, m, b)\n",
    "    t = np.asarray(t, dtype=float)\n",
    "\n",
    "    out = np.empty_like(t, dtype=float)\n",
    "    small = np.abs(t) < 1e-6\n",
    "\n",
    "    if np.any(small):\n",
    "        mu = triang_mean(a, m, b)\n",
    "        ex2 = triang_second_moment(a, m, b)\n",
    "        ts = t[small]\n",
    "        out[small] = 1.0 + mu * ts + 0.5 * ex2 * (ts**2)\n",
    "\n",
    "    if np.any(~small):\n",
    "        tt = t[~small]\n",
    "        num = 2.0 * ((b - m) * np.exp(tt * a) + (m - a) * np.exp(tt * b) - (b - a) * np.exp(tt * m))\n",
    "        den = (b - a) * (b - m) * (m - a) * (tt**2)\n",
    "        out[~small] = num / den\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def triang_cf(omega: np.ndarray, a: float, m: float, b: float) -> np.ndarray:\n",
    "    '''Characteristic function φ(ω)=E[e^{i ω X}] (NumPy-only).'''\n",
    "\n",
    "    _validate_triang_params(a, m, b)\n",
    "    omega = np.asarray(omega, dtype=float)\n",
    "\n",
    "    out = np.empty_like(omega, dtype=complex)\n",
    "    small = np.abs(omega) < 1e-6\n",
    "\n",
    "    if np.any(small):\n",
    "        mu = triang_mean(a, m, b)\n",
    "        ex2 = triang_second_moment(a, m, b)\n",
    "        w = omega[small]\n",
    "        out[small] = 1.0 + 1j * mu * w - 0.5 * ex2 * (w**2)\n",
    "\n",
    "    if np.any(~small):\n",
    "        w = omega[~small]\n",
    "        num = 2.0 * ((b - m) * np.exp(1j * w * a) + (m - a) * np.exp(1j * w * b) - (b - a) * np.exp(1j * w * m))\n",
    "        den = (b - a) * (b - m) * (m - a) * ((1j * w) ** 2)\n",
    "        out[~small] = num / den\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def triang_loglik(a: float, m: float, b: float, x: np.ndarray) -> float:\n",
    "    '''Log-likelihood for i.i.d. observations x under Triang(a, m, b).'''\n",
    "\n",
    "    _validate_triang_params(a, m, b)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    # Strict interior support avoids log(0).\n",
    "    if np.any((x <= a) | (x >= b)):\n",
    "        return -np.inf\n",
    "\n",
    "    left = x <= m\n",
    "    right = ~left\n",
    "\n",
    "    n = x.size\n",
    "    n_left = int(left.sum())\n",
    "    n_right = n - n_left\n",
    "\n",
    "    ll = n * math.log(2.0) - n * math.log(b - a)\n",
    "    ll += float(np.sum(np.log(x[left] - a)) - n_left * math.log(m - a))\n",
    "    ll += float(np.sum(np.log(b - x[right])) - n_right * math.log(b - m))\n",
    "\n",
    "    return float(ll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks: compare our NumPy formulas to SciPy.\n",
    "\n",
    "a, m, b = -1.0, 0.3, 2.0\n",
    "c, loc, scale = triang_params_to_scipy(a, m, b)\n",
    "rv = triang_dist(c, loc=loc, scale=scale)\n",
    "\n",
    "x = np.linspace(a - 0.5, b + 0.5, 800)\n",
    "\n",
    "pdf_np = triang_pdf(x, a, m, b)\n",
    "cdf_np = triang_cdf(x, a, m, b)\n",
    "\n",
    "pdf_sp = rv.pdf(x)\n",
    "cdf_sp = rv.cdf(x)\n",
    "\n",
    "print(\"pdf max abs diff:\", float(np.max(np.abs(pdf_np - pdf_sp))))\n",
    "print(\"cdf max abs diff:\", float(np.max(np.abs(cdf_np - cdf_sp))))\n",
    "\n",
    "mu_np = triang_mean(a, m, b)\n",
    "var_np = triang_variance(a, m, b)\n",
    "skew_np = triang_skewness(a, m, b)\n",
    "kurt_np = triang_excess_kurtosis()\n",
    "\n",
    "mu_sp, var_sp, skew_sp, kurt_sp = rv.stats(moments=\"mvsk\")\n",
    "\n",
    "print(\"mean   (np, scipy):\", mu_np, float(mu_sp))\n",
    "print(\"var    (np, scipy):\", var_np, float(var_sp))\n",
    "print(\"skew   (np, scipy):\", skew_np, float(skew_sp))\n",
    "print(\"kurt   (np, scipy):\", kurt_np, float(kurt_sp))\n",
    "\n",
    "print(\"entropy (np, scipy):\", triang_entropy(a, b), float(rv.entropy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Moments & Properties\n",
    "\n",
    "Because the support is bounded, **all moments exist** and the MGF exists for all real \\(t\\).\n",
    "\n",
    "### Mean and variance\n",
    "\\[\n",
    "\\mathbb{E}[X] = \\frac{a+m+b}{3},\n",
    "\\qquad\n",
    "\\mathrm{Var}(X) = \\frac{a^2+b^2+m^2-ab-am-bm}{18}.\n",
    "\\]\n",
    "\n",
    "A convenient second moment (useful for Taylor expansions):\n",
    "\\[\n",
    "\\mathbb{E}[X^2] = \\frac{a^2+b^2+m^2+ab+am+bm}{6}.\n",
    "\\]\n",
    "\n",
    "### Skewness and kurtosis\n",
    "Skewness (third standardized moment) is:\n",
    "\\[\n",
    "\\gamma_1 =\n",
    "\\frac{\\sqrt{2}\\,(a+b-2m)\\,(2a-b-m)\\,(a-2b+m)}{5\\,\\big(a^2+b^2+m^2-ab-am-bm\\big)^{3/2}}.\n",
    "\\]\n",
    "\n",
    "Excess kurtosis is constant for the whole family:\n",
    "\\[\n",
    "\\gamma_2 = -\\frac{3}{5}.\n",
    "\\]\n",
    "\n",
    "### MGF and characteristic function\n",
    "For \\(t\\neq 0\\), the MGF has a compact closed form:\n",
    "\\[\n",
    "M(t)=\\mathbb{E}[e^{tX}] =\n",
    "\\frac{2\\Big((b-m)e^{ta} + (m-a)e^{tb} - (b-a)e^{tm}\\Big)}{(b-a)(b-m)(m-a)\\,t^2}.\n",
    "\\]\n",
    "\n",
    "The characteristic function is \\(\\varphi(\\omega)=M(i\\omega)\\).\n",
    "\n",
    "### Entropy\n",
    "The differential entropy (in **nats**) depends only on the interval length:\n",
    "\\[\n",
    "H(X)=\\frac12 + \\log\\Big(\\frac{b-a}{2}\\Big).\n",
    "\\]\n",
    "\n",
    "So entropy does **not** depend on the mode location \\(m\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, m, b = 0.0, 0.2, 1.0\n",
    "\n",
    "print(\"mean:\", triang_mean(a, m, b))\n",
    "print(\"var:\", triang_variance(a, m, b))\n",
    "print(\"skew:\", triang_skewness(a, m, b))\n",
    "print(\"excess kurtosis:\", triang_excess_kurtosis())\n",
    "print(\"entropy:\", triang_entropy(a, b))\n",
    "\n",
    "# MGF/CF demo: recover mean as M'(0) and show |φ(ω)| ≤ 1\n",
    "\n",
    "t_grid = np.array([-1e-4, 0.0, 1e-4])\n",
    "mgf_vals = triang_mgf(t_grid, a, m, b)\n",
    "\n",
    "# Centered finite-difference slope at 0\n",
    "mean_fd = (mgf_vals[-1] - mgf_vals[0]) / (t_grid[-1] - t_grid[0])\n",
    "print(\"mean from finite diff M'(0):\", float(mean_fd))\n",
    "\n",
    "w = np.linspace(0, 60, 300)\n",
    "phi = triang_cf(w, a, m, b)\n",
    "print(\"max |phi(ω)|:\", float(np.max(np.abs(phi))))\n",
    "\n",
    "# Compare to SciPy\n",
    "c, loc, scale = triang_params_to_scipy(a, m, b)\n",
    "rv = triang_dist(c, loc=loc, scale=scale)\n",
    "print(\"SciPy mvsk:\", tuple(float(v) for v in rv.stats(moments=\"mvsk\")))\n",
    "print(\"SciPy entropy:\", float(rv.entropy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Parameter Interpretation\n",
    "\n",
    "- \\(a\\) (**lower bound**) shifts the distribution left/right.\n",
    "- \\(b\\) (**upper bound**) sets the right endpoint.\n",
    "- The **scale** is \\(b-a\\): widening the interval spreads the distribution and increases variance \\(\\propto (b-a)^2\\).\n",
    "- \\(m\\) (**mode**) controls **asymmetry**:\n",
    "  - if \\(m\\) is close to \\(a\\), most mass is near the left endpoint with a long right tail (positive skew)\n",
    "  - if \\(m\\) is close to \\(b\\), the distribution is negatively skewed\n",
    "  - if \\(m=(a+b)/2\\), the distribution is symmetric\n",
    "\n",
    "A nice geometric fact: the peak height \\(f(m)=2/(b-a)\\) depends only on the interval length, not on \\(m\\). Moving \\(m\\) changes the **slopes** of the two sides.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 0.0, 1.0\n",
    "m_values = [0.05, 0.2, 0.5, 0.8, 0.95]\n",
    "\n",
    "x = np.linspace(a, b, 600)\n",
    "fig = go.Figure()\n",
    "\n",
    "for m in m_values:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=triang_pdf(x, a, m, b),\n",
    "            mode=\"lines\",\n",
    "            name=f\"m={m:.2f}, skew={triang_skewness(a, m, b):+.3f}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(title=\"Triangular PDF for different mode locations (a=0, b=1)\", xaxis_title=\"x\", yaxis_title=\"pdf\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### Expectation\n",
    "The PDF graph is a triangle with vertices \\((a,0)\\), \\((m, 2/(b-a))\\), \\((b,0)\\). The x-coordinate of a triangle’s centroid is the average of the vertices’ x-coordinates, so:\n",
    "\\[\n",
    "\\mathbb{E}[X] = \\frac{a+m+b}{3}.\n",
    "\\]\n",
    "\n",
    "### Variance\n",
    "Compute the second moment via piecewise integration:\n",
    "\\[\n",
    "\\mathbb{E}[X^2] = \\int_a^m x^2\\,\\frac{2(x-a)}{(b-a)(m-a)}\\,dx\n",
    "+ \\int_m^b x^2\\,\\frac{2(b-x)}{(b-a)(b-m)}\\,dx\n",
    "= \\frac{a^2+b^2+m^2+ab+am+bm}{6}.\n",
    "\\]\n",
    "\n",
    "Then\n",
    "\\[\n",
    "\\mathrm{Var}(X)=\\mathbb{E}[X^2]-\\mathbb{E}[X]^2\n",
    "=\\frac{a^2+b^2+m^2-ab-am-bm}{18}.\n",
    "\\]\n",
    "\n",
    "### Likelihood (i.i.d. sample)\n",
    "For observations \\(x_1,\\dots,x_n\\) inside \\((a,b)\\), the log-likelihood is a sum of two parts depending on whether \\(x_i\\le m\\) or \\(x_i>m\\):\n",
    "\\[\n",
    "\\ell(a,m,b) = \\sum_{i=1}^n \\log f(x_i\\mid a,m,b).\n",
    "\\]\n",
    "\n",
    "Let \\(\\mathcal{L}=\\{i:x_i\\le m\\}\\) and \\(\\mathcal{R}=\\{i:x_i>m\\}\\). Using the PDF definition:\n",
    "\\[\n",
    "\\ell(a,m,b)= n\\log 2 - n\\log(b-a)\n",
    "- |\\mathcal{L}|\\log(m-a) - |\\mathcal{R}|\\log(b-m)\n",
    "+ \\sum_{i\\in\\mathcal{L}} \\log(x_i-a) + \\sum_{i\\in\\mathcal{R}} \\log(b-x_i).\n",
    "\\]\n",
    "\n",
    "Because the partition \\(\\mathcal{L}/\\mathcal{R}\\) changes when \\(m\\) crosses a data point, the likelihood is **not smooth** in \\(m\\); derivative-free optimizers are often convenient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triang_fit_mle(x: np.ndarray) -> dict:\n",
    "    '''Simple MLE fit for (a, m, b) using a reparameterization and Nelder–Mead.'''\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if x.ndim != 1:\n",
    "        raise ValueError(\"x must be 1D\")\n",
    "    if not np.all(np.isfinite(x)):\n",
    "        raise ValueError(\"x must be finite\")\n",
    "\n",
    "    xmin = float(np.min(x))\n",
    "    xmax = float(np.max(x))\n",
    "    span = xmax - xmin\n",
    "    if span <= 0:\n",
    "        raise ValueError(\"Need at least two distinct points to fit Triang.\")\n",
    "\n",
    "    # Initial guess: slightly extend beyond the data range to avoid log(0).\n",
    "    a0 = xmin - 0.05 * span\n",
    "    b0 = xmax + 0.05 * span\n",
    "    scale0 = b0 - a0\n",
    "\n",
    "    mu = float(np.mean(x))\n",
    "    c0 = float(np.clip((mu - a0) / scale0, 1e-3, 1 - 1e-3))\n",
    "\n",
    "    # Parameterization:\n",
    "    # a = a\n",
    "    # scale = exp(s)\n",
    "    # c = (tanh(u)+1)/2  in (0,1)\n",
    "    theta0 = np.array([a0, math.log(scale0), math.atanh(2 * c0 - 1)])\n",
    "\n",
    "    def unpack(theta: np.ndarray) -> tuple[float, float, float]:\n",
    "        a, s, u = theta\n",
    "        scale = float(math.exp(s))\n",
    "        c = float(0.5 * (math.tanh(u) + 1.0))\n",
    "        b = a + scale\n",
    "        m = a + c * scale\n",
    "        return float(a), float(m), float(b)\n",
    "\n",
    "    def nll(theta: np.ndarray) -> float:\n",
    "        a, m, b = unpack(theta)\n",
    "        ll = triang_loglik(a, m, b, x)\n",
    "        return np.inf if not np.isfinite(ll) else -ll\n",
    "\n",
    "    res = optimize.minimize(nll, theta0, method=\"Nelder-Mead\", options={\"maxiter\": 5000})\n",
    "    a_hat, m_hat, b_hat = unpack(res.x)\n",
    "    return {\n",
    "        \"a\": a_hat,\n",
    "        \"m\": m_hat,\n",
    "        \"b\": b_hat,\n",
    "        \"success\": bool(res.success),\n",
    "        \"nll\": float(res.fun),\n",
    "        \"message\": str(res.message),\n",
    "    }\n",
    "\n",
    "\n",
    "# Fit demo on synthetic data\n",
    "true_a, true_m, true_b = 0.0, 0.3, 1.0\n",
    "x = triang_rvs_numpy(2000, true_a, true_m, true_b, rng=rng)\n",
    "\n",
    "fit = triang_fit_mle(x)\n",
    "fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Sampling & Simulation (NumPy-only)\n",
    "\n",
    "### Inverse transform sampling\n",
    "If \\(U\\sim\\text{Unif}(0,1)\\), then \\(X=F^{-1}(U)\\) has the desired distribution.\n",
    "\n",
    "For the triangular CDF, define the split point:\n",
    "\\[\n",
    "p = F(m)=\\frac{m-a}{b-a}.\n",
    "\\]\n",
    "\n",
    "Then the inverse CDF is:\n",
    "\\[\n",
    "F^{-1}(u)=\n",
    "\\begin{cases}\n",
    " a + \\sqrt{u\\,(b-a)(m-a)}, & 0\\le u < p,\\\\[6pt]\n",
    " b - \\sqrt{(1-u)\\,(b-a)(b-m)}, & p\\le u\\le 1.\n",
    "\\end{cases}\n",
    "\\]\n",
    "\n",
    "This is exactly what `triang_ppf` implements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, m, b = 2.0, 3.0, 10.0\n",
    "n = 200_000\n",
    "samples = triang_rvs_numpy(n, a, m, b, rng=rng)\n",
    "\n",
    "print(\"sample mean vs theory:\", float(samples.mean()), triang_mean(a, m, b))\n",
    "print(\"sample var  vs theory:\", float(samples.var()), triang_variance(a, m, b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We’ll visualize:\n",
    "- the **PDF** (piecewise linear)\n",
    "- the **CDF** (piecewise quadratic)\n",
    "- a **Monte Carlo histogram** with the theoretical PDF overlaid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, m, b = 0.0, 0.3, 1.0\n",
    "c, loc, scale = triang_params_to_scipy(a, m, b)\n",
    "rv = triang_dist(c, loc=loc, scale=scale)\n",
    "\n",
    "x = np.linspace(a, b, 700)\n",
    "\n",
    "# PDF\n",
    "fig_pdf = go.Figure()\n",
    "fig_pdf.add_trace(go.Scatter(x=x, y=triang_pdf(x, a, m, b), mode=\"lines\", name=\"NumPy PDF\"))\n",
    "fig_pdf.add_trace(go.Scatter(x=x, y=rv.pdf(x), mode=\"lines\", name=\"SciPy PDF\", line=dict(dash=\"dash\")))\n",
    "fig_pdf.update_layout(title=\"Triangular PDF\", xaxis_title=\"x\", yaxis_title=\"pdf\")\n",
    "\n",
    "# CDF\n",
    "fig_cdf = go.Figure()\n",
    "fig_cdf.add_trace(go.Scatter(x=x, y=triang_cdf(x, a, m, b), mode=\"lines\", name=\"NumPy CDF\"))\n",
    "fig_cdf.add_trace(go.Scatter(x=x, y=rv.cdf(x), mode=\"lines\", name=\"SciPy CDF\", line=dict(dash=\"dash\")))\n",
    "fig_cdf.update_layout(title=\"Triangular CDF\", xaxis_title=\"x\", yaxis_title=\"cdf\")\n",
    "\n",
    "# Monte Carlo\n",
    "n = 60_000\n",
    "s = triang_rvs_numpy(n, a, m, b, rng=rng)\n",
    "\n",
    "fig_mc = px.histogram(s, nbins=60, histnorm=\"probability density\", title=\"Monte Carlo samples\")\n",
    "fig_mc.add_trace(go.Scatter(x=x, y=triang_pdf(x, a, m, b), mode=\"lines\", name=\"theoretical pdf\"))\n",
    "fig_mc.update_layout(xaxis_title=\"x\", yaxis_title=\"density\")\n",
    "\n",
    "fig_pdf.show()\n",
    "fig_cdf.show()\n",
    "fig_mc.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) SciPy Integration\n",
    "\n",
    "`scipy.stats.triang` implements the triangular family with the standard frozen-distribution API:\n",
    "- `pdf`, `cdf`, `ppf`\n",
    "- `rvs`\n",
    "- `stats`, `entropy`\n",
    "- `fit` (MLE)\n",
    "\n",
    "Remember SciPy’s shape parameter is **not the mode**; it’s the normalized mode location \\(c=(m-a)/(b-a)\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, m, b = -1.0, 0.2, 2.5\n",
    "c, loc, scale = triang_params_to_scipy(a, m, b)\n",
    "\n",
    "rv = triang_dist(c, loc=loc, scale=scale)\n",
    "\n",
    "x = np.linspace(a, b, 6)\n",
    "print(\"x:\", x)\n",
    "print(\"pdf:\", rv.pdf(x))\n",
    "print(\"cdf:\", rv.cdf(x))\n",
    "print(\"rvs(5):\", rv.rvs(size=5, random_state=rng))\n",
    "\n",
    "# Fit example (MLE)\n",
    "data = rv.rvs(size=3000, random_state=rng)\n",
    "\n",
    "c_hat, loc_hat, scale_hat = triang_dist.fit(data)\n",
    "a_hat, m_hat, b_hat = scipy_params_to_triang(c_hat, loc_hat, scale_hat)\n",
    "\n",
    "print(\"SciPy fit (c, loc, scale):\", (float(c_hat), float(loc_hat), float(scale_hat)))\n",
    "print(\"SciPy fit mapped (a, m, b):\", (a_hat, m_hat, b_hat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Statistical Use Cases\n",
    "\n",
    "### Hypothesis testing\n",
    "If parameters are known *a priori*, you can test whether data plausibly came from \\(\\text{Triang}(a,m,b)\\) using a one-sample goodness-of-fit test (e.g. Kolmogorov–Smirnov).\n",
    "\n",
    "If you **estimate parameters from the same data**, classical KS p-values are no longer exact (the null is “composite”). In that case, use a **parametric bootstrap** for calibrated p-values.\n",
    "\n",
    "### Bayesian modeling\n",
    "Triangular distributions make convenient **bounded priors** when you have expert knowledge in (min, mode, max) form.\n",
    "\n",
    "### Generative modeling\n",
    "They are useful building blocks in simulation pipelines whenever you need:\n",
    "- bounded support\n",
    "- a single mode\n",
    "- a simple sampling routine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis testing demo (parameters known): KS test\n",
    "from scipy.stats import kstest\n",
    "\n",
    "a, m, b = 0.0, 0.3, 1.0\n",
    "c, loc, scale = triang_params_to_scipy(a, m, b)\n",
    "rv = triang_dist(c, loc=loc, scale=scale)\n",
    "\n",
    "x = rv.rvs(size=400, random_state=rng)\n",
    "stat, pval = kstest(x, rv.cdf)\n",
    "print(\"KS statistic:\", float(stat))\n",
    "print(\"p-value:\", float(pval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian modeling demo: triangular prior + normal likelihood (grid posterior)\n",
    "\n",
    "# Unknown parameter theta, prior Triang(a,m,b)\n",
    "a, m, b = 0.0, 0.6, 1.0\n",
    "sigma = 0.12\n",
    "obs = 0.72\n",
    "\n",
    "theta = np.linspace(a, b, 2000)\n",
    "prior = triang_pdf(theta, a, m, b)\n",
    "lik = norm.pdf(obs, loc=theta, scale=sigma)\n",
    "post_unnorm = prior * lik\n",
    "post = post_unnorm / np.trapz(post_unnorm, theta)\n",
    "\n",
    "# Summaries\n",
    "post_mean = float(np.trapz(theta * post, theta))\n",
    "post_cdf = np.cumsum(post) * (theta[1] - theta[0])\n",
    "post_median = float(theta[np.searchsorted(post_cdf, 0.5)])\n",
    "\n",
    "print(\"posterior mean:\", post_mean)\n",
    "print(\"posterior median:\", post_median)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=theta, y=prior, mode=\"lines\", name=\"prior (triangular)\"))\n",
    "fig.add_trace(go.Scatter(x=theta, y=lik / np.trapz(lik, theta), mode=\"lines\", name=\"likelihood (normalized)\", line=dict(dash=\"dash\")))\n",
    "fig.add_trace(go.Scatter(x=theta, y=post, mode=\"lines\", name=\"posterior\"))\n",
    "fig.add_vline(x=obs, line_dash=\"dot\", line_color=\"gray\")\n",
    "fig.update_layout(title=\"Bayesian update with triangular prior\", xaxis_title=\"theta\", yaxis_title=\"density\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative modeling demo: bounded task durations and project totals\n",
    "\n",
    "# Each task duration is modeled with (min, mode, max)\n",
    "a, m, b = 2.0, 3.0, 10.0\n",
    "n_projects = 30_000\n",
    "n_tasks = 6\n",
    "\n",
    "durations = triang_rvs_numpy(n_projects * n_tasks, a, m, b, rng=rng).reshape(n_projects, n_tasks)\n",
    "project_total = durations.sum(axis=1)\n",
    "\n",
    "fig = px.histogram(project_total, nbins=60, title=f\"Total duration for {n_tasks} triangular tasks\")\n",
    "fig.update_layout(xaxis_title=\"total time\", yaxis_title=\"count\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Invalid parameters**: you need \\(a<m<b\\). Values too close together make denominators tiny.\n",
    "- **Support is closed but the PDF is 0 at the endpoints**: if your data includes exact endpoints, the continuous model assigns probability 0, yielding \\(-\\infty\\) log-likelihood.\n",
    "- **SciPy parameterization**: `scipy.stats.triang(c, loc, scale)` uses \\(c\\) as a *fraction* of the interval, not the mode.\n",
    "- **MLE non-smoothness**: the likelihood changes form when \\(m\\) crosses a data point; derivative-free optimization is often easier.\n",
    "- **MGF/CF numerical cancellation**: the closed forms divide by \\(t^2\\) and can lose precision near 0; a Taylor expansion (as implemented above) stabilizes evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `triang` is a **continuous**, **bounded** distribution on \\([a,b]\\) with a single mode \\(m\\).\n",
    "- The PDF is **piecewise linear** and the CDF is **piecewise quadratic**.\n",
    "- Mean and variance have simple closed forms: \\(\\mathbb{E}[X]=(a+m+b)/3\\), \\(\\mathrm{Var}(X)=(a^2+b^2+m^2-ab-am-bm)/18\\).\n",
    "- Excess kurtosis is constant \\(-3/5\\), and differential entropy depends only on \\(b-a\\).\n",
    "- Sampling is easy via inverse CDF; SciPy provides a full-featured implementation via `scipy.stats.triang`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
