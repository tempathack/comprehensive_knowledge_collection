{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Left-skewed Lévy distribution (`levy_l`)\n",
    "\n",
    "`scipy.stats.levy_l` is a **continuous** distribution with support $(-\\infty, \\mathrm{loc})$ (standard: $(-\\infty, 0)$). It is extremely **heavy-tailed**: the mean and variance do not exist as finite numbers.\n",
    "\n",
    "A useful generative story is a simple transformation of a standard normal: if $Z\\sim\\mathcal{N}(0,1)$ then\n",
    "\n",
    "$$X = \\mathrm{loc} - \\frac{\\mathrm{scale}}{Z^2}$$\n",
    "\n",
    "has the `levy_l` distribution.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "- Write down the PDF/CDF and connect the CDF to the normal CDF / error function.\n",
    "- Understand the relationship to `levy`, `levy_stable`, and the inverse-gamma family.\n",
    "- See why moments diverge and which summaries remain meaningful (quantiles, median).\n",
    "- Implement NumPy-only sampling and validate against SciPy.\n",
    "- Fit parameters and use the distribution in simple inference workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import scipy\n",
    "from scipy import optimize, special\n",
    "from scipy.stats import levy_l as levy_l_dist\n",
    "from scipy.stats import norm\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Record versions for reproducibility (useful when numerical details matter).\n",
    "VERSIONS = {\"numpy\": np.__version__, \"scipy\": scipy.__version__, \"plotly\": plotly.__version__}\n",
    "VERSIONS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Title & Classification\n",
    "\n",
    "- **Name**: `levy_l` (left-skewed Lévy distribution; SciPy: `scipy.stats.levy_l`)\n",
    "- **Type**: continuous\n",
    "- **Support**:\n",
    "  - Standard form: $x<0$\n",
    "  - With `loc`, `scale`: $x < \\mathrm{loc}$\n",
    "- **Parameter space** (SciPy location/scale form):\n",
    "  - $\\mathrm{loc}\\in\\mathbb{R}$\n",
    "  - $\\mathrm{scale}>0$\n",
    "\n",
    "There are **no additional shape parameters**; `levy_l` is a 2-parameter location/scale family.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Intuition & Motivation\n",
    "\n",
    "### What it models\n",
    "`levy_l` is a one-sided (fully left-skewed) **stable** distribution with stability index $\\alpha=1/2$.\n",
    "It places most of its mass near the upper end of its support (near `loc`), but has a **very heavy left tail**. In practice this means:\n",
    "\n",
    "- You typically see many values close-ish to `loc`.\n",
    "- Rarely, you can see **enormous negative outliers**.\n",
    "- Classical summaries that rely on finite moments (mean/variance) are unreliable.\n",
    "\n",
    "### Typical real-world use cases\n",
    "\n",
    "- **First-passage times (Lévy)**: the (right-skewed) Lévy distribution arises as the distribution of the first time a driftless Brownian motion hits a fixed positive level. `levy_l` is the **mirror image**, useful when modeling an upper-bounded quantity with heavy lower tail.\n",
    "- **One-sided heavy-tailed noise**: as a component in mixture models for data with rare but extreme negative shocks.\n",
    "- **Stable-process building block**: `levy_l` corresponds to the fully left-skewed $\\alpha=1/2$ stable law (see `scipy.stats.levy_stable`).\n",
    "\n",
    "### Relations to other distributions\n",
    "\n",
    "- **Mirror of `levy`**: if $Y\\sim\\texttt{levy}(0,1)$ then $-Y\\sim\\texttt{levy\\_l}(0,1)$. More generally,\n",
    "  $$X\\sim\\texttt{levy\\_l}(\\mathrm{loc},\\mathrm{scale}) \\iff \\mathrm{loc}-X\\sim\\texttt{levy}(0,\\mathrm{scale}).$$\n",
    "- **Inverse-gamma**: if $X\\sim\\texttt{levy\\_l}(\\mathrm{loc},\\mathrm{scale})$ then $\\mathrm{loc}-X$ follows an inverse-gamma distribution with shape $\\alpha=\\tfrac12$ and scale parameter $\\beta=\\tfrac{\\mathrm{scale}}{2}$.\n",
    "- **Stable law**: `levy_l` is the same as `levy_stable` with parameters $(\\alpha,\\beta)=(1/2,-1)$ (up to SciPy's parameterization conventions).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Formal Definition\n",
    "\n",
    "### PDF\n",
    "In SciPy's location/scale form, for $x<\\mathrm{loc}$,\n",
    "\n",
    "$$\n",
    "f(x;\\mathrm{loc},\\mathrm{scale})\n",
    "= \\sqrt{\\frac{\\mathrm{scale}}{2\\pi}}\\,\\frac{\\exp\\!\\left(-\\frac{\\mathrm{scale}}{2(\\mathrm{loc}-x)}\\right)}{(\\mathrm{loc}-x)^{3/2}}.\n",
    "$$\n",
    "\n",
    "and $f(x)=0$ for $x\\ge\\mathrm{loc}$.\n",
    "\n",
    "The standard form (`loc=0`, `scale=1`) simplifies to\n",
    "\n",
    "$$\n",
    "f(x)=\\frac{1}{|x|\\sqrt{2\\pi|x|}}\\exp\\!\\left(-\\frac{1}{2|x|}\\right),\\qquad x<0.\n",
    "$$\n",
    "\n",
    "### CDF\n",
    "For $x<\\mathrm{loc}$,\n",
    "\n",
    "$$\n",
    "F(x;\\mathrm{loc},\\mathrm{scale})\n",
    "= 2\\,\\Phi\\!\\left(\\sqrt{\\frac{\\mathrm{scale}}{\\mathrm{loc}-x}}\\right) - 1\n",
    "= \\operatorname{erf}\\!\\left(\\sqrt{\\frac{\\mathrm{scale}}{2(\\mathrm{loc}-x)}}\\right),\n",
    "$$\n",
    "\n",
    "and $F(x)=1$ for $x\\ge\\mathrm{loc}$. Here $\\Phi$ is the standard normal CDF and $\\operatorname{erf}$ is the error function.\n",
    "\n",
    "### Quantile function (PPF)\n",
    "For $q\\in(0,1)$, let $z = \\Phi^{-1}\\!\\left(\\tfrac{q+1}{2}\\right)$. Then\n",
    "\n",
    "$$\n",
    "F^{-1}(q) = \\mathrm{loc} - \\frac{\\mathrm{scale}}{z^2}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levy_l_logpdf(x: np.ndarray, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Log-PDF of levy_l(loc, scale) evaluated at x.\n",
    "\n",
    "    SciPy's support is x < loc with scale > 0.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    if not np.isfinite(loc):\n",
    "        raise ValueError(\"loc must be finite\")\n",
    "    if not np.isfinite(scale) or scale <= 0:\n",
    "        raise ValueError(\"scale must be positive and finite\")\n",
    "\n",
    "    y = loc - x\n",
    "    out = np.full_like(x, fill_value=-np.inf, dtype=float)\n",
    "    mask = y > 0\n",
    "    yy = y[mask]\n",
    "    out[mask] = (\n",
    "        0.5 * np.log(scale)\n",
    "        - 0.5 * np.log(2 * np.pi)\n",
    "        - 1.5 * np.log(yy)\n",
    "        - scale / (2 * yy)\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def levy_l_pdf(x: np.ndarray, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"PDF of levy_l(loc, scale) evaluated at x.\"\"\"\n",
    "    return np.exp(levy_l_logpdf(x, loc=loc, scale=scale))\n",
    "\n",
    "\n",
    "def levy_l_cdf(x: np.ndarray, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"CDF of levy_l(loc, scale) evaluated at x.\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    if not np.isfinite(loc):\n",
    "        raise ValueError(\"loc must be finite\")\n",
    "    if not np.isfinite(scale) or scale <= 0:\n",
    "        raise ValueError(\"scale must be positive and finite\")\n",
    "\n",
    "    y = loc - x\n",
    "    out = np.zeros_like(x, dtype=float)\n",
    "    mask = y > 0\n",
    "    yy = y[mask]\n",
    "    out[mask] = special.erf(np.sqrt(scale / (2 * yy)))\n",
    "    out[~mask] = 1.0\n",
    "    return out\n",
    "\n",
    "\n",
    "def levy_l_ppf(q: np.ndarray, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Quantile function (inverse CDF) for levy_l(loc, scale).\"\"\"\n",
    "    q = np.asarray(q, dtype=float)\n",
    "\n",
    "    if not np.isfinite(loc):\n",
    "        raise ValueError(\"loc must be finite\")\n",
    "    if not np.isfinite(scale) or scale <= 0:\n",
    "        raise ValueError(\"scale must be positive and finite\")\n",
    "\n",
    "    if np.any((q <= 0) | (q >= 1)):\n",
    "        raise ValueError(\"q must lie strictly in (0, 1)\")\n",
    "\n",
    "    z = norm.ppf((q + 1.0) / 2.0)\n",
    "    return loc - scale / (z * z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: our formulas match SciPy.\n",
    "loc, scale = -1.2, 2.5\n",
    "\n",
    "# Use a truncated range because levy_l is extremely heavy-tailed.\n",
    "x = np.linspace(\n",
    "    levy_l_dist.ppf(0.45, loc=loc, scale=scale),\n",
    "    levy_l_dist.ppf(0.999, loc=loc, scale=scale),\n",
    "    25,\n",
    ")\n",
    "\n",
    "pdf_max_err = np.max(np.abs(levy_l_pdf(x, loc=loc, scale=scale) - levy_l_dist.pdf(x, loc=loc, scale=scale)))\n",
    "cdf_max_err = np.max(np.abs(levy_l_cdf(x, loc=loc, scale=scale) - levy_l_dist.cdf(x, loc=loc, scale=scale)))\n",
    "\n",
    "q = np.linspace(0.05, 0.95, 7)\n",
    "ppf_max_err = np.max(np.abs(levy_l_ppf(q, loc=loc, scale=scale) - levy_l_dist.ppf(q, loc=loc, scale=scale)))\n",
    "roundtrip_max_err = np.max(np.abs(levy_l_cdf(levy_l_ppf(q, loc=loc, scale=scale), loc=loc, scale=scale) - q))\n",
    "\n",
    "pdf_max_err, cdf_max_err, ppf_max_err, roundtrip_max_err\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Moments & Properties\n",
    "\n",
    "### Mean, variance, skewness, kurtosis\n",
    "\n",
    "`levy_l` is so heavy-tailed that the usual raw moments do not exist as finite numbers.\n",
    "\n",
    "- **Mean**: diverges (for the standard form it diverges to $-\\infty$)\n",
    "- **Variance**: infinite\n",
    "- **Skewness / kurtosis**: undefined\n",
    "\n",
    "What *does* remain well-behaved:\n",
    "\n",
    "- Quantiles (including the median)\n",
    "- Tail probabilities (via CDF/SF)\n",
    "\n",
    "A useful reparameterization is $Y = \\mathrm{loc} - X > 0$. Then $Y$ has the (right) Lévy distribution and can be viewed as an **inverse-gamma** random variable with shape $\\alpha=1/2$:\n",
    "\n",
    "$$Y \\sim \\mathrm{InvGamma}\\left(\\alpha=\\tfrac12,\\;\\beta=\\tfrac{\\mathrm{scale}}{2}\\right).$$\n",
    "\n",
    "From inverse-gamma moment conditions, $\\mathbb{E}[Y^p]$ exists iff $p<\\alpha=1/2$.\n",
    "\n",
    "### MGF / characteristic function\n",
    "\n",
    "Because the mean is infinite, the moment generating function is **not finite in any neighborhood of 0**. However, since the support is bounded above, the one-sided MGF exists for $t>0$:\n",
    "\n",
    "$$\n",
    "M_X(t)=\\mathbb{E}[e^{tX}] = \\exp\\!\\left(t\\,\\mathrm{loc} - \\sqrt{2\\,\\mathrm{scale}\\,t}\\right),\\qquad t>0.\n",
    "$$\n",
    "\n",
    "The characteristic function exists for all real $t$:\n",
    "\n",
    "$$\n",
    "\\varphi_X(t) = \\mathbb{E}[e^{itX}] = \\exp\\!\\left(i t\\,\\mathrm{loc} - \\sqrt{2 i\\,\\mathrm{scale}\\,t}\\right),\n",
    "$$\n",
    "\n",
    "where $\\sqrt{\\cdot}$ is the principal complex square root.\n",
    "\n",
    "### Entropy\n",
    "\n",
    "The differential entropy is finite and has a closed form via the inverse-gamma identity above:\n",
    "\n",
    "$$\n",
    "h(X) = h(\\texttt{levy\\_l}(0,1)) + \\log(\\mathrm{scale}),\n",
    "\\qquad\n",
    "h(\\texttt{levy\\_l}(0,1)) = \\frac12 + \\log(4\\sqrt{\\pi}) + \\frac{3}{2}\\,\\gamma,\n",
    "$$\n",
    "\n",
    "with $\\gamma\\approx 0.57721$ the Euler–Mascheroni constant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc, scale = 0.0, 1.0\n",
    "mean, var, skew, kurt = levy_l_dist.stats(loc=loc, scale=scale, moments=\"mvsk\")\n",
    "entropy_scipy = levy_l_dist.entropy(loc=loc, scale=scale)\n",
    "\n",
    "entropy_closed = (0.5 + np.log(4 * np.sqrt(np.pi)) + 1.5 * np.euler_gamma) + np.log(scale)\n",
    "\n",
    "mean, var, skew, kurt, entropy_scipy, entropy_closed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Parameter Interpretation\n",
    "\n",
    "- `loc` is an **upper endpoint**: samples always satisfy $X<\\mathrm{loc}$.\n",
    "- `scale` controls how far below `loc` the distribution typically lies and how heavy the tail is. Larger `scale` pushes mass further left and makes extreme negative values more likely.\n",
    "\n",
    "Because `levy_l` is a location/scale family, changing `loc` shifts the distribution; changing `scale` stretches it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF for varying scale (truncate the far tail so the main shape is visible).\n",
    "loc = 0.0\n",
    "scale_values = [0.5, 1.0, 2.0, 5.0]\n",
    "\n",
    "q_lo, q_hi = 0.4, 0.9995\n",
    "x_min = levy_l_dist.ppf(q_lo, loc=loc, scale=max(scale_values))\n",
    "x_max = levy_l_dist.ppf(q_hi, loc=loc, scale=min(scale_values))\n",
    "x = np.linspace(x_min, x_max, 900)\n",
    "\n",
    "fig = go.Figure()\n",
    "for s in scale_values:\n",
    "    fig.add_trace(go.Scatter(x=x, y=levy_l_dist.pdf(x, loc=loc, scale=s), name=f\"scale={s}\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"levy_l PDF (varying scale; tail truncated)\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"pdf\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDF for varying loc (scale fixed).\n",
    "scale = 1.0\n",
    "loc_values = [-2.0, 0.0, 2.0]\n",
    "\n",
    "q_lo, q_hi = 0.4, 0.9995\n",
    "x_min = min(levy_l_dist.ppf(q_lo, loc=mu, scale=scale) for mu in loc_values)\n",
    "x_max = max(levy_l_dist.ppf(q_hi, loc=mu, scale=scale) for mu in loc_values)\n",
    "x = np.linspace(x_min, x_max, 900)\n",
    "\n",
    "fig = go.Figure()\n",
    "for mu in loc_values:\n",
    "    fig.add_trace(go.Scatter(x=x, y=levy_l_dist.cdf(x, loc=mu, scale=scale), name=f\"loc={mu}\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"levy_l CDF (varying loc; scale fixed)\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"cdf\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### 6.1 From a standard normal to `levy_l`\n",
    "\n",
    "Let $Z\\sim\\mathcal{N}(0,1)$ and define $Y=1/Z^2$ (so $Y>0$). For $y>0$,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{P}(Y \\le y)\n",
    "  &= \\mathbb{P}\\left(\\frac{1}{Z^2} \\le y\\right)\n",
    "   = \\mathbb{P}\\left(|Z| \\ge \\frac{1}{\\sqrt{y}}\\right)\n",
    "   = 2\\,\\Phi\\!\\left(-\\frac{1}{\\sqrt{y}}\\right).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Differentiating gives\n",
    "\n",
    "$$\n",
    "f_Y(y) = \\frac{1}{\\sqrt{2\\pi}}\\,y^{-3/2}\\,\\exp\\!\\left(-\\frac{1}{2y}\\right),\\qquad y>0,\n",
    "$$\n",
    "\n",
    "which is the (right-skewed) Lévy distribution. Now set $X = -Y$, so $X<0$ and $X$ has the standard `levy_l` PDF.\n",
    "\n",
    "Finally, apply location/scale:\n",
    "\n",
    "$$X_{\\mathrm{loc},\\mathrm{scale}} = \\mathrm{loc} + \\mathrm{scale}\\,X = \\mathrm{loc} - \\frac{\\mathrm{scale}}{Z^2}.$$\n",
    "\n",
    "### 6.2 Expectation and variance diverge\n",
    "\n",
    "For large negative $x$ (equivalently large $y=\\mathrm{loc}-x$), the exponential term in the PDF is essentially 1, so\n",
    "\n",
    "$$\n",
    "f(x) \\sim \\sqrt{\\frac{\\mathrm{scale}}{2\\pi}}\\,(\\mathrm{loc}-x)^{-3/2}.\n",
    "$$\n",
    "\n",
    "Then the mean integral behaves like\n",
    "\n",
    "$$\\int_{-\\infty} x\\,f(x)\\,dx \\sim -\\int^{\\infty} u\\,u^{-3/2}\\,du = -\\int^{\\infty} u^{-1/2}\\,du,$$\n",
    "\n",
    "which diverges. Similarly, the second moment behaves like $\\int u^{1/2} du$ and diverges as well.\n",
    "\n",
    "### 6.3 Likelihood (i.i.d. sample) and profile MLE\n",
    "\n",
    "Given observations $x_1,\\dots,x_n$ and parameters with $\\mathrm{loc} > \\max_i x_i$ and $\\mathrm{scale}>0$, define $y_i=\\mathrm{loc}-x_i>0$. The log-likelihood is\n",
    "\n",
    "$$\n",
    "\\ell(\\mathrm{loc},\\mathrm{scale})\n",
    "  = \\frac{n}{2}\\log\\mathrm{scale}\n",
    "    - \\frac{3}{2}\\sum_{i=1}^n\\log y_i\n",
    "    - \\frac{\\mathrm{scale}}{2}\\sum_{i=1}^n\\frac{1}{y_i}\n",
    "    - \\frac{n}{2}\\log(2\\pi).\n",
    "$$\n",
    "\n",
    "If `loc` is held fixed, maximizing over `scale` has a closed form:\n",
    "\n",
    "$$\\widehat{\\mathrm{scale}}(\\mathrm{loc}) = \\frac{n}{\\sum_{i=1}^n 1/y_i}.$$\n",
    "\n",
    "Plugging this into $\\ell$ gives a 1D **profile** log-likelihood in `loc`, which can be optimized numerically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_mle_given_loc(loc: float, x: np.ndarray) -> float:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = loc - x\n",
    "    if np.any(y <= 0):\n",
    "        return np.nan\n",
    "    return len(x) / np.sum(1.0 / y)\n",
    "\n",
    "\n",
    "def levy_l_loglik(loc: float, scale: float, x: np.ndarray) -> float:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = loc - x\n",
    "    if scale <= 0 or np.any(y <= 0):\n",
    "        return -np.inf\n",
    "\n",
    "    n = len(x)\n",
    "    return (\n",
    "        0.5 * n * np.log(scale)\n",
    "        - 1.5 * np.sum(np.log(y))\n",
    "        - 0.5 * scale * np.sum(1.0 / y)\n",
    "        - 0.5 * n * np.log(2 * np.pi)\n",
    "    )\n",
    "\n",
    "\n",
    "def profile_loglik(loc: float, x: np.ndarray) -> float:\n",
    "    s_hat = scale_mle_given_loc(loc, x)\n",
    "    if not np.isfinite(s_hat):\n",
    "        return -np.inf\n",
    "    return levy_l_loglik(loc, s_hat, x)\n",
    "\n",
    "\n",
    "# Demonstration: profile MLE vs SciPy's fit\n",
    "loc_true, scale_true = -1.0, 2.0\n",
    "x = levy_l_dist.rvs(loc=loc_true, scale=scale_true, size=3000, random_state=rng)\n",
    "\n",
    "loc_fit, scale_fit = levy_l_dist.fit(x)\n",
    "\n",
    "max_x = np.max(x)\n",
    "eps = 1e-12\n",
    "lower = max_x + eps\n",
    "gap = float(np.median(max_x - x))\n",
    "upper = max_x + 50.0 * max(gap, 1e-3)\n",
    "\n",
    "res = optimize.minimize_scalar(lambda mu: -profile_loglik(mu, x), bounds=(lower, upper), method=\"bounded\")\n",
    "loc_mle = float(res.x)\n",
    "scale_mle = float(scale_mle_given_loc(loc_mle, x))\n",
    "\n",
    "{\n",
    "    \"true\": (loc_true, scale_true),\n",
    "    \"scipy_fit\": (loc_fit, scale_fit),\n",
    "    \"profile_mle\": (loc_mle, scale_mle),\n",
    "    \"optimizer_success\": bool(res.success),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Sampling & Simulation\n",
    "\n",
    "### NumPy-only sampling algorithm\n",
    "\n",
    "Using the normal transformation:\n",
    "\n",
    "1. Sample $Z\\sim\\mathcal{N}(0,1)$.\n",
    "2. Return $X = \\mathrm{loc} - \\mathrm{scale}/Z^2$.\n",
    "\n",
    "This produces an exact sample from `levy_l(loc, scale)`.\n",
    "\n",
    "Because $Z$ can be arbitrarily close to 0, this algorithm sometimes produces **enormous negative values**. That is expected (it is the heavy tail).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levy_l_rvs_numpy(\n",
    "    loc: float = 0.0,\n",
    "    scale: float = 1.0,\n",
    "    size=1,\n",
    "    *,\n",
    "    rng: np.random.Generator | None = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Sample from levy_l(loc, scale) using NumPy only.\"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    if not np.isfinite(loc):\n",
    "        raise ValueError(\"loc must be finite\")\n",
    "    if not np.isfinite(scale) or scale <= 0:\n",
    "        raise ValueError(\"scale must be positive and finite\")\n",
    "\n",
    "    z = rng.standard_normal(size)\n",
    "\n",
    "    # Exact zeros are extremely rare but would cause division by zero.\n",
    "    if np.ndim(z) == 0:\n",
    "        while z == 0:\n",
    "            z = rng.standard_normal()\n",
    "        return loc - scale / (z * z)\n",
    "\n",
    "    while True:\n",
    "        mask = z == 0\n",
    "        if not np.any(mask):\n",
    "            break\n",
    "        z[mask] = rng.standard_normal(np.sum(mask))\n",
    "\n",
    "    return loc - scale / (z * z)\n",
    "\n",
    "\n",
    "# Quick check: quantiles match SciPy.\n",
    "loc, scale = 0.0, 1.0\n",
    "samples = levy_l_rvs_numpy(loc=loc, scale=scale, size=200_000, rng=rng)\n",
    "q = np.array([0.1, 0.5, 0.9])\n",
    "np.quantile(samples, q), levy_l_dist.ppf(q, loc=loc, scale=scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "Because `levy_l` is extremely heavy-tailed, plots are often most informative on a **truncated quantile range** (e.g., showing only the upper 60% of the distribution).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc, scale = 0.0, 1.0\n",
    "\n",
    "x = np.linspace(\n",
    "    levy_l_dist.ppf(0.4, loc=loc, scale=scale),\n",
    "    levy_l_dist.ppf(0.999, loc=loc, scale=scale),\n",
    "    900,\n",
    ")\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"PDF (truncated)\", \"CDF (truncated)\"))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x, y=levy_l_dist.pdf(x, loc=loc, scale=scale), name=\"SciPy pdf\"),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=levy_l_pdf(x, loc=loc, scale=scale),\n",
    "        name=\"Formula pdf\",\n",
    "        line=dict(dash=\"dash\"),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x, y=levy_l_dist.cdf(x, loc=loc, scale=scale), name=\"SciPy cdf\"),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=levy_l_cdf(x, loc=loc, scale=scale),\n",
    "        name=\"Formula cdf\",\n",
    "        line=dict(dash=\"dash\"),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"density\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"cdf\", row=1, col=2)\n",
    "fig.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Monte Carlo samples (NumPy-only) with a truncated histogram for visualization.\n",
    "n = 300_000\n",
    "samples = levy_l_rvs_numpy(loc=loc, scale=scale, size=n, rng=rng)\n",
    "\n",
    "lo, hi = x[0], x[-1]\n",
    "samples_trunc = samples[(samples >= lo) & (samples <= hi)]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=samples_trunc,\n",
    "        nbinsx=80,\n",
    "        histnorm=\"probability density\",\n",
    "        name=f\"MC histogram (n={n:,}, truncated)\",\n",
    "        opacity=0.5,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=x, y=levy_l_dist.pdf(x, loc=loc, scale=scale), name=\"SciPy pdf\"))\n",
    "fig.update_layout(title=\"Monte Carlo samples (tail truncated for plotting)\", xaxis_title=\"x\", yaxis_title=\"density\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) SciPy Integration\n",
    "\n",
    "`scipy.stats.levy_l` provides the usual distribution API:\n",
    "\n",
    "- `levy_l.pdf(x, loc=0, scale=1)`\n",
    "- `levy_l.cdf(x, loc=0, scale=1)`\n",
    "- `levy_l.rvs(loc=0, scale=1, size=..., random_state=...)`\n",
    "- `levy_l.fit(data, ...)` (MLE)\n",
    "\n",
    "A common pattern is to **freeze** the distribution: `rv = levy_l(loc=..., scale=...)`, then call `rv.pdf`, `rv.cdf`, `rv.rvs`, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_true, scale_true = -1.0, 2.0\n",
    "x = levy_l_dist.rvs(loc=loc_true, scale=scale_true, size=5000, random_state=rng)\n",
    "\n",
    "# Fit both parameters.\n",
    "loc_hat, scale_hat = levy_l_dist.fit(x)\n",
    "\n",
    "# Fit with loc fixed (useful when loc is known from the problem).\n",
    "loc_hat_fixed, scale_hat_fixed = levy_l_dist.fit(x, floc=loc_true)\n",
    "\n",
    "# Example evaluations\n",
    "rv = levy_l_dist(loc=loc_hat, scale=scale_hat)\n",
    "x0 = np.array([loc_hat - 0.1, loc_hat - 1.0, loc_hat - 10.0])\n",
    "\n",
    "{\n",
    "    \"true\": (loc_true, scale_true),\n",
    "    \"fit\": (loc_hat, scale_hat),\n",
    "    \"fit_floc\": (loc_hat_fixed, scale_hat_fixed),\n",
    "    \"pdf(x0)\": rv.pdf(x0),\n",
    "    \"cdf(x0)\": rv.cdf(x0),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Statistical Use Cases\n",
    "\n",
    "### Hypothesis testing (goodness-of-fit)\n",
    "\n",
    "If you have **specified** parameters (not estimated from the same sample), you can use a goodness-of-fit test such as Kolmogorov–Smirnov (KS).\n",
    "\n",
    "Caveat: if you estimate parameters from the data and then run KS on the same data, the usual p-values are no longer exact (you need a corrected procedure or a bootstrap).\n",
    "\n",
    "### Bayesian modeling\n",
    "\n",
    "If `loc` is known, the likelihood for `scale` has a convenient form. With $y_i=\\mathrm{loc}-x_i>0$:\n",
    "\n",
    "$$p(x_{1:n}\\mid\\mathrm{scale}) \\propto \\mathrm{scale}^{n/2}\\,\\exp\\!\\left(-\\frac{\\mathrm{scale}}{2}\\sum_{i=1}^n \\frac{1}{y_i}\\right).$$\n",
    "\n",
    "So a **Gamma prior** on `scale` is conjugate.\n",
    "\n",
    "### Generative modeling\n",
    "\n",
    "Because the distribution is supported on $(-\\infty,\\mathrm{loc})$, it naturally models **one-sided negative shocks**. Summing i.i.d. draws produces a process with rare, very large downward jumps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis testing example: KS test when parameters are known.\n",
    "from scipy.stats import kstest\n",
    "\n",
    "loc_true, scale_true = 0.0, 1.5\n",
    "x = levy_l_dist.rvs(loc=loc_true, scale=scale_true, size=1500, random_state=rng)\n",
    "\n",
    "stat, pvalue = kstest(x, \"levy_l\", args=(loc_true, scale_true))\n",
    "stat, pvalue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian modeling example: conjugate Gamma posterior for scale when loc is known.\n",
    "from scipy.stats import gamma\n",
    "\n",
    "loc = 0.0\n",
    "scale_true = 2.0\n",
    "x = levy_l_dist.rvs(loc=loc, scale=scale_true, size=300, random_state=rng)\n",
    "y = loc - x\n",
    "\n",
    "# Prior: scale ~ Gamma(alpha0, rate=beta0)\n",
    "alpha0, beta0 = 2.0, 1.0\n",
    "\n",
    "alpha_post = alpha0 + len(x) / 2.0\n",
    "beta_post = beta0 + 0.5 * np.sum(1.0 / y)\n",
    "\n",
    "# SciPy's gamma uses a 'scale' parameter = 1/rate.\n",
    "prior = gamma(a=alpha0, scale=1.0 / beta0)\n",
    "post = gamma(a=alpha_post, scale=1.0 / beta_post)\n",
    "\n",
    "post_mean = post.mean()\n",
    "post_ci = post.ppf([0.05, 0.95])\n",
    "\n",
    "grid = np.linspace(post.ppf(0.001), post.ppf(0.999), 600)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=grid, y=prior.pdf(grid), name=\"prior\", line=dict(dash=\"dot\")))\n",
    "fig.add_trace(go.Scatter(x=grid, y=post.pdf(grid), name=\"posterior\"))\n",
    "fig.add_vline(x=scale_true, line_dash=\"dash\", line_color=\"black\", annotation_text=\"true scale\")\n",
    "fig.update_layout(\n",
    "    title=f\"Posterior for scale (loc known). Posterior mean={post_mean:.3f}, 90% CI=[{post_ci[0]:.3f}, {post_ci[1]:.3f}]\",\n",
    "    xaxis_title=\"scale\",\n",
    "    yaxis_title=\"density\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative modeling example: a process with one-sided heavy-tailed negative shocks.\n",
    "n_steps = 200\n",
    "shock_scale = 0.15\n",
    "\n",
    "shocks = levy_l_rvs_numpy(loc=0.0, scale=shock_scale, size=n_steps, rng=rng)\n",
    "path = np.cumsum(shocks)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Shocks\", \"Cumulative sum\"))\n",
    "fig.add_trace(go.Scatter(y=shocks, mode=\"lines+markers\", name=\"shocks\"), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(y=path, mode=\"lines+markers\", name=\"path\"), row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"time\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"time\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"value\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"value\", row=1, col=2)\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Invalid parameters**: `scale` must be strictly positive; the density is defined only for $x<\\mathrm{loc}$.\n",
    "- **Infinite moments**: sample means/variances are unstable and can be dominated by rare extreme values.\n",
    "- **Visualization requires care**: a few samples can be extremely negative; use truncation or log-scaled tail plots.\n",
    "- **Numerical issues**:\n",
    "  - For $x$ extremely close to `loc`, the PDF involves an $\\exp(-\\mathrm{scale}/(2(\\mathrm{loc}-x)))$ term that can underflow; use `logpdf` when possible.\n",
    "  - `ppf(q)` for very small $q$ produces extremely large magnitudes; avoid evaluating at $q\\approx 0$ in finite precision.\n",
    "- **Fitting**: MLE is sensitive to tail observations; consider fixing `loc` when known or using robust / Bayesian approaches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `levy_l` is a left-skewed, one-sided **stable** distribution with support $(-\\infty,\\mathrm{loc})$.\n",
    "- It is the mirror of `levy`: $\\mathrm{loc}-X$ is (right) Lévy and can be seen as an inverse-gamma with shape $1/2$.\n",
    "- Mean/variance (and higher raw moments) diverge; quantiles and tail probabilities are the right tools.\n",
    "- Exact NumPy-only sampling is easy via $X=\\mathrm{loc}-\\mathrm{scale}/Z^2$ with $Z\\sim\\mathcal{N}(0,1)$.\n",
    "- SciPy provides evaluation, simulation, and MLE fitting through `scipy.stats.levy_l`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
