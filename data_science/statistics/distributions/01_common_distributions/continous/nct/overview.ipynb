{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a312fa",
   "metadata": {},
   "source": [
    "# `nct` (Noncentral t) distribution\n",
    "\n",
    "The **noncentral t distribution** is what you get when a *t-statistic is evaluated under an alternative hypothesis* (i.e., when the true mean is not equal to the null mean).\n",
    "It generalizes Student's t by introducing a **noncentrality parameter** that shifts the underlying normal component and typically induces **skewness**.\n",
    "\n",
    "A clean way to remember it:\n",
    "\n",
    "- central t: $T = Z/\\sqrt{V/\\nu}$ with $Z\\sim\\mathcal N(0,1)$\n",
    "- noncentral t: $T = (Z+\\delta)/\\sqrt{V/\\nu}$ with $Z\\sim\\mathcal N(0,1)$\n",
    "\n",
    "where $V\\sim\\chi^2_{\\nu}$ is independent of $Z$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e593d520",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "- Classify and parameterize `nct`: support, parameters, and limiting cases.\n",
    "- Use the **stochastic construction** to derive mean/variance and understand moment existence.\n",
    "- Implement **NumPy-only sampling** from first principles.\n",
    "- Visualize PDF/CDF and validate Monte Carlo simulations.\n",
    "- Use `scipy.stats.nct` for `pdf`, `cdf`, `rvs`, and `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c558472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import scipy\n",
    "from scipy import optimize, special\n",
    "from scipy.stats import chi2, nct, norm, t\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "rng = np.random.default_rng(7)\n",
    "\n",
    "print(\"Python\", platform.python_version())\n",
    "print(\"NumPy\", np.__version__)\n",
    "print(\"SciPy\", scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3775cc",
   "metadata": {},
   "source": [
    "## 1) Title & classification\n",
    "\n",
    "- **Name**: `nct` (noncentral t distribution)\n",
    "- **Type**: **continuous** distribution\n",
    "- **Support**: $x \\in (-\\infty, \\infty)$\n",
    "- **Parameter space**:\n",
    "  - degrees of freedom $\\nu > 0$\n",
    "  - noncentrality $\\delta \\in \\mathbb R$\n",
    "\n",
    "We write:\n",
    "\n",
    "$$\n",
    "T \\sim \\mathrm{NCT}(\\nu, \\delta).\n",
    "$$\n",
    "\n",
    "In SciPy, the standardized form is `scipy.stats.nct(df=nu, nc=delta)` (with optional `loc` and `scale`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b3621e",
   "metadata": {},
   "source": [
    "## 2) Intuition & motivation\n",
    "\n",
    "### 2.1 What it models\n",
    "The noncentral t distribution models a **signal-to-noise ratio with estimated noise**.\n",
    "It is the sampling distribution of the usual t-statistic when the true mean is *not* the null mean.\n",
    "\n",
    "A one-sample setup makes this concrete:\n",
    "\n",
    "- data: $X_1,\\dots,X_n \\stackrel{\\text{iid}}{\\sim} \\mathcal N(\\mu,\\sigma^2)$\n",
    "- test statistic: $T = \\dfrac{\\bar X - \\mu_0}{S/\\sqrt{n}}$\n",
    "\n",
    "If $\\mu \\neq \\mu_0$, then\n",
    "\n",
    "$$\n",
    "T \\sim \\mathrm{NCT}(\\nu=n-1,\\; \\delta=\\sqrt{n}\\,\\tfrac{\\mu-\\mu_0}{\\sigma}).\n",
    "$$\n",
    "\n",
    "### 2.2 Typical real-world use cases\n",
    "- **Power analysis** for t-tests (probability of rejecting the null under a specific effect size).\n",
    "- **A/B testing** with approximately normal outcomes (means) and unknown variance.\n",
    "- **Design of experiments**: translate a practically meaningful effect into power curves.\n",
    "- **Effect size modeling**: sampling distribution of standardized mean differences.\n",
    "\n",
    "### 2.3 Relations to other distributions\n",
    "- **Student's t**: $\\delta=0$ gives the central t distribution with $\\nu$ degrees of freedom.\n",
    "- **Normal limit**: as $\\nu\\to\\infty$, $V/\\nu\\to 1$ and $T\\Rightarrow \\mathcal N(\\delta,1)$.\n",
    "- **Noncentral F**: if $T\\sim\\mathrm{NCT}(\\nu,\\delta)$, then $T^2 \\sim \\mathrm{NCF}(1,\\nu,\\lambda=\\delta^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d966aefd",
   "metadata": {},
   "source": [
    "## 3) Formal definition\n",
    "\n",
    "Let $\\phi$ and $\\Phi$ be the standard normal PDF/CDF:\n",
    "\n",
    "$$\n",
    "\\phi(z)=\\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\tfrac{1}{2}z^2\\right),\n",
    "\\qquad\n",
    "\\Phi(z)=\\int_{-\\infty}^z \\phi(t)\\,dt.\n",
    "$$\n",
    "\n",
    "Let $Z\\sim\\mathcal N(0,1)$ and $V\\sim\\chi^2_{\\nu}$ be independent, with $\\nu>0$.\n",
    "Define\n",
    "\n",
    "$$\n",
    "T = \\frac{Z+\\delta}{\\sqrt{V/\\nu}},\\qquad \\delta\\in\\mathbb R.\n",
    "$$\n",
    "\n",
    "Then $T\\sim\\mathrm{NCT}(\\nu,\\delta)$.\n",
    "\n",
    "### 3.1 Conditional (mixture) view\n",
    "Conditioning on $V=v$, we have $\\sqrt{V/\\nu}=\\sqrt{v/\\nu}=s$ (a constant), so\n",
    "\n",
    "$$\n",
    "T\\mid V=v \\;=\\; \\frac{Z+\\delta}{s} \\sim \\mathcal N\\Bigl(\\delta\\sqrt{\\tfrac{\\nu}{v}},\\; \\tfrac{\\nu}{v}\\Bigr).\n",
    "$$\n",
    "\n",
    "### 3.2 PDF (integral representation)\n",
    "Write the chi-square density\n",
    "\n",
    "$$\n",
    "f_{\\chi^2_{\\nu}}(v)=\\frac{1}{2^{\\nu/2}\\Gamma(\\nu/2)}\\,v^{\\nu/2-1}e^{-v/2},\\qquad v>0.\n",
    "$$\n",
    "\n",
    "Using the conditional normal density and integrating out $V$ gives an explicit representation:\n",
    "\n",
    "$$\n",
    " f_T(t\\mid \\nu,\\delta)\n",
    " =\\int_0^{\\infty} \\sqrt{\\tfrac{v}{\\nu}}\\;\\phi\\!\\left(t\\sqrt{\\tfrac{v}{\\nu}}-\\delta\\right)\\; f_{\\chi^2_{\\nu}}(v)\\,dv.\n",
    "$$\n",
    "\n",
    "Closed forms exist in terms of special functions / infinite series; numerical libraries (SciPy) evaluate the PDF using specialized routines.\n",
    "\n",
    "### 3.3 CDF (integral representation)\n",
    "Similarly, the conditional CDF is normal, so\n",
    "\n",
    "$$\n",
    " F_T(t\\mid \\nu,\\delta)\n",
    " =\\int_0^{\\infty} \\Phi\\!\\left(t\\sqrt{\\tfrac{v}{\\nu}}-\\delta\\right)\\; f_{\\chi^2_{\\nu}}(v)\\,dv.\n",
    "$$\n",
    "\n",
    "SciPy exposes a dedicated special function for the CDF: `scipy.special.nctdtr(df, nc, x)`.\n",
    "\n",
    "### 3.4 Quantiles\n",
    "There is no simple closed form for the PPF $F^{-1}(p)$; it is computed numerically (e.g. `nct.ppf`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nct_pdf(x: np.ndarray, df: float, nc: float) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    return nct.pdf(x, df, nc)\n",
    "\n",
    "\n",
    "def nct_logpdf(x: np.ndarray, df: float, nc: float) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    return nct.logpdf(x, df, nc)\n",
    "\n",
    "\n",
    "def nct_cdf(x: np.ndarray, df: float, nc: float) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    # Same as nct.cdf, but explicitly shows the specialized implementation SciPy uses.\n",
    "    return special.nctdtr(df, nc, x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bbfbf2",
   "metadata": {},
   "source": [
    "## 4) Moments & properties\n",
    "\n",
    "A key structural fact from the definition is that\n",
    "\n",
    "$$\n",
    "T = \\underbrace{\\sqrt{\\tfrac{\\nu}{V}}}_{S}\\;\\underbrace{(Z+\\delta)}_{Y},\n",
    "\\qquad S \\perp Y,\n",
    "$$\n",
    "\n",
    "where $Y\\sim\\mathcal N(\\delta,1)$ and $V\\sim\\chi^2_{\\nu}$.\n",
    "This lets you compute moments by separating them:\n",
    "\n",
    "$$\n",
    "\\mathbb E[T^k] = \\mathbb E[S^k]\\,\\mathbb E[Y^k],\\quad \\text{when the moment exists.}\n",
    "$$\n",
    "\n",
    "### 4.1 Existence of moments\n",
    "Because $S^k=(\\nu/V)^{k/2}$, the moment $\\mathbb E[S^k]$ exists iff $\\nu>k$.\n",
    "Therefore:\n",
    "\n",
    "- mean exists for $\\nu>1$\n",
    "- variance exists for $\\nu>2$\n",
    "- skewness exists for $\\nu>3$\n",
    "- kurtosis exists for $\\nu>4$\n",
    "\n",
    "### 4.2 Mean and variance\n",
    "Using independence:\n",
    "\n",
    "$$\n",
    "\\mathbb E[T] = \\mathbb E[Y]\\,\\mathbb E[S]\n",
    "= \\delta\\,\\mathbb E\\left[\\left(\\tfrac{\\nu}{V}\\right)^{1/2}\\right]\n",
    "= \\delta\\,\\sqrt{\\tfrac{\\nu}{2}}\\,\\frac{\\Gamma\\bigl((\\nu-1)/2\\bigr)}{\\Gamma\\bigl(\\nu/2\\bigr)},\\qquad \\nu>1.\n",
    "$$\n",
    "\n",
    "Also\n",
    "\n",
    "$$\n",
    "\\mathbb E[T^2] = \\mathbb E[Y^2] \\, \\mathbb E\\left[\\tfrac{\\nu}{V}\\right]\n",
    "= (1+\\delta^2)\\,\\frac{\\nu}{\\nu-2},\\qquad \\nu>2.\n",
    "$$\n",
    "\n",
    "So\n",
    "\n",
    "$$\n",
    "\\mathrm{Var}(T)=\\frac{\\nu(1+\\delta^2)}{\\nu-2}-\\Bigl(\\mathbb E[T]\\Bigr)^2,\\qquad \\nu>2.\n",
    "$$\n",
    "\n",
    "### 4.3 Skewness and kurtosis\n",
    "Raw moments of $Y\\sim\\mathcal N(\\delta,1)$ up to order 4 are\n",
    "\n",
    "- $\\mathbb E[Y]=\\delta$\n",
    "- $\\mathbb E[Y^2]=\\delta^2+1$\n",
    "- $\\mathbb E[Y^3]=\\delta^3+3\\delta$\n",
    "- $\\mathbb E[Y^4]=\\delta^4+6\\delta^2+3$\n",
    "\n",
    "Combine them with\n",
    "\n",
    "$$\n",
    "\\mathbb E[S^k] = (\\nu/2)^{k/2}\\,\\frac{\\Gamma((\\nu-k)/2)}{\\Gamma(\\nu/2)}\\qquad (\\nu>k)\n",
    "$$\n",
    "\n",
    "to get $\\mathbb E[T^k]$, then convert to central moments.\n",
    "\n",
    "### 4.4 MGF and characteristic function\n",
    "- **MGF**: like Student's t, `nct` has **polynomial tails**, so the MGF does **not** exist (is infinite) for any nonzero argument.\n",
    "- **Characteristic function**: it exists for all real $\\omega$ and can be written via the conditional normal form:\n",
    "\n",
    "$$\n",
    "\\varphi_T(\\omega)=\\mathbb E\\bigl[e^{i\\omega T}\\bigr]\n",
    "=\\mathbb E_V\\left[\\exp\\Bigl(i\\omega\\,\\delta\\sqrt{\\tfrac{\\nu}{V}} - \\tfrac{1}{2}\\omega^2\\tfrac{\\nu}{V}\\Bigr)\\right].\n",
    "$$\n",
    "\n",
    "This expectation has closed forms in special functions, but is typically evaluated numerically.\n",
    "\n",
    "### 4.5 Entropy\n",
    "There is no simple closed form for the differential entropy; in practice it is computed numerically (e.g. `nct.entropy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6891717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _e_scaled_inv_chi_power(df: float, k: int) -> float:\n",
    "    \"\"\"E[(df/V)^(k/2)] for V ~ chi2(df). Exists iff df > k.\"\"\"\n",
    "    if df <= k:\n",
    "        return np.nan\n",
    "    return (df / 2) ** (k / 2) * special.gamma((df - k) / 2) / special.gamma(df / 2)\n",
    "\n",
    "\n",
    "def nct_moments_closed_form(df: float, nc: float):\n",
    "    \"\"\"Mean/variance/skewness/excess kurtosis from the stochastic representation.\n",
    "\n",
    "    Returns (mean, var, skew, exkurt). Values are NaN when the moment does not exist.\n",
    "    \"\"\"\n",
    "    # Moments of Y ~ Normal(nc, 1)\n",
    "    y1 = nc\n",
    "    y2 = nc**2 + 1.0\n",
    "    y3 = nc**3 + 3.0 * nc\n",
    "    y4 = nc**4 + 6.0 * nc**2 + 3.0\n",
    "\n",
    "    s1 = _e_scaled_inv_chi_power(df, 1)\n",
    "    s2 = _e_scaled_inv_chi_power(df, 2)\n",
    "    s3 = _e_scaled_inv_chi_power(df, 3)\n",
    "    s4 = _e_scaled_inv_chi_power(df, 4)\n",
    "\n",
    "    m1 = y1 * s1 if df > 1 else np.nan\n",
    "    m2 = y2 * s2 if df > 2 else np.nan\n",
    "    m3 = y3 * s3 if df > 3 else np.nan\n",
    "    m4 = y4 * s4 if df > 4 else np.nan\n",
    "\n",
    "    if not np.isfinite(m1) or not np.isfinite(m2):\n",
    "        return m1, np.nan, np.nan, np.nan\n",
    "\n",
    "    var = m2 - m1**2\n",
    "    if not np.isfinite(var) or var <= 0:\n",
    "        return m1, var, np.nan, np.nan\n",
    "\n",
    "    if not np.isfinite(m3):\n",
    "        return m1, var, np.nan, np.nan\n",
    "\n",
    "    mu3 = m3 - 3 * m1 * m2 + 2 * m1**3\n",
    "    skew = mu3 / (var ** 1.5)\n",
    "\n",
    "    if not np.isfinite(m4):\n",
    "        return m1, var, skew, np.nan\n",
    "\n",
    "    mu4 = m4 - 4 * m1 * m3 + 6 * (m1**2) * m2 - 3 * m1**4\n",
    "    exkurt = mu4 / (var**2) - 3\n",
    "\n",
    "    return m1, var, skew, exkurt\n",
    "\n",
    "\n",
    "# Quick numeric cross-check vs SciPy (avoid nc==0 exactly due to a corner-case in some SciPy versions)\n",
    "for df, nc in [(10.0, 1.2), (6.0, 0.1), (3.5, -1.0)]:\n",
    "    m, v, s, k = nct_moments_closed_form(df, nc)\n",
    "    m_s, v_s, s_s, k_s = nct.stats(df, nc, moments=\"mvsk\")\n",
    "    print(f\"df={df:>4}, nc={nc:>5} | closed-form mvsk = {m: .6f}, {v: .6f}, {s: .6f}, {k: .6f}\")\n",
    "    print(f\"                scipy     mvsk = {m_s: .6f}, {v_s: .6f}, {s_s: .6f}, {k_s: .6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ed7a66",
   "metadata": {},
   "source": [
    "## 5) Parameter interpretation\n",
    "\n",
    "### 5.1 Degrees of freedom $\\nu$\n",
    "- Controls **tail heaviness** (smaller $\\nu$ â‡’ heavier tails, more extreme values).\n",
    "- Determines which moments exist: the $k$-th moment requires $\\nu>k$.\n",
    "- As $\\nu\\to\\infty$, the randomness in $\\sqrt{V/\\nu}$ vanishes and the distribution approaches $\\mathcal N(\\delta,1)$.\n",
    "\n",
    "### 5.2 Noncentrality $\\delta$\n",
    "- Shifts the underlying normal component $Z+\\delta$.\n",
    "- Typically induces **skewness** (unless $\\delta=0$, where the distribution is symmetric).\n",
    "- In hypothesis testing, $\\delta$ is a **standardized effect size multiplied by** $\\sqrt{n}$.\n",
    "\n",
    "We'll visualize these effects next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf883f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-8, 8, 1200)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Vary df (nc fixed)\", \"Vary nc (df fixed)\"),\n",
    ")\n",
    "\n",
    "# Left: varying df\n",
    "nc_fixed = 1.5\n",
    "for df in [2.5, 5, 15, 80]:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=x, y=nct_pdf(x, df, nc_fixed), name=f\"df={df}, nc={nc_fixed}\", mode=\"lines\"),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "# Right: varying nc\n",
    "df_fixed = 10\n",
    "for nc in [-3, -1.5, 0.0, 1.5, 3.0]:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=x, y=nct_pdf(x, df_fixed, nc), name=f\"df={df_fixed}, nc={nc}\", mode=\"lines\"),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=420, width=980, title_text=\"Noncentral t: PDF shape changes\")\n",
    "fig.update_xaxes(title_text=\"x\")\n",
    "fig.update_yaxes(title_text=\"density\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab40555",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### 6.1 Expectation\n",
    "Start from the stochastic construction\n",
    "\n",
    "$$\n",
    "T=\\sqrt{\\tfrac{\\nu}{V}}(Z+\\delta),\\qquad Z\\perp V.\n",
    "$$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\mathbb E[T]=\\mathbb E[Z+\\delta]\\;\\mathbb E\\left[\\left(\\tfrac{\\nu}{V}\\right)^{1/2}\\right]\n",
    "=\\delta\\;\\mathbb E\\left[\\left(\\tfrac{\\nu}{V}\\right)^{1/2}\\right],\n",
    "$$\n",
    "\n",
    "since $\\mathbb E[Z]=0$.\n",
    "Because $V\\sim\\chi^2_{\\nu}=\\mathrm{Gamma}(k=\\nu/2,\\theta=2)$, for $\\nu>1$\n",
    "\n",
    "$$\n",
    "\\mathbb E[V^{-1/2}] = 2^{-1/2}\\,\\frac{\\Gamma((\\nu-1)/2)}{\\Gamma(\\nu/2)}.\n",
    "$$\n",
    "\n",
    "Multiplying by $\\sqrt{\\nu}$ gives\n",
    "\n",
    "$$\n",
    "\\mathbb E[T]=\\delta\\,\\sqrt{\\tfrac{\\nu}{2}}\\,\\frac{\\Gamma((\\nu-1)/2)}{\\Gamma(\\nu/2)}.\n",
    "$$\n",
    "\n",
    "### 6.2 Variance\n",
    "Compute the second raw moment (exists for $\\nu>2$):\n",
    "\n",
    "$$\n",
    "\\mathbb E[T^2] = \\mathbb E[(Z+\\delta)^2]\\,\\mathbb E\\left[\\tfrac{\\nu}{V}\\right]\n",
    "= (1+\\delta^2)\\,\\frac{\\nu}{\\nu-2},\n",
    "$$\n",
    "\n",
    "since $\\mathbb E[(Z+\\delta)^2]=1+\\delta^2$ and $\\mathbb E[1/V]=1/(\\nu-2)$ for $V\\sim\\chi^2_{\\nu}$.\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\mathrm{Var}(T)=\\mathbb E[T^2]-\\bigl(\\mathbb E[T]\\bigr)^2.\n",
    "$$\n",
    "\n",
    "### 6.3 Likelihood\n",
    "For i.i.d. observations $t_1,\\dots,t_n$ from $\\mathrm{NCT}(\\nu,\\delta)$, the likelihood is\n",
    "\n",
    "$$\n",
    "L(\\nu,\\delta\\mid t_{1:n}) = \\prod_{i=1}^n f_T(t_i\\mid\\nu,\\delta),\n",
    "$$\n",
    "\n",
    "and the log-likelihood is\n",
    "\n",
    "$$\n",
    "\\ell(\\nu,\\delta\\mid t_{1:n}) = \\sum_{i=1}^n \\log f_T(t_i\\mid\\nu,\\delta).\n",
    "$$\n",
    "\n",
    "There is no closed-form MLE for $(\\nu,\\delta)$ in general; numerical optimization is used (e.g. `nct.fit`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac917da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nct_neg_loglik(params: np.ndarray, data: np.ndarray) -> float:\n",
    "    df, nc = float(params[0]), float(params[1])\n",
    "    if not np.isfinite(df) or df <= 0 or not np.isfinite(nc):\n",
    "        return np.inf\n",
    "    return -float(np.sum(nct_logpdf(data, df, nc)))\n",
    "\n",
    "\n",
    "# Synthetic example: recover parameters via numerical MLE\n",
    "true_df, true_nc = 8.0, 1.25\n",
    "sample = nct.rvs(true_df, true_nc, size=1500, random_state=rng)\n",
    "\n",
    "res = optimize.minimize(\n",
    "    nct_neg_loglik,\n",
    "    x0=np.array([10.0, 0.5]),\n",
    "    args=(sample,),\n",
    "    bounds=[(1e-6, None), (None, None)],\n",
    ")\n",
    "\n",
    "print(\"True   (df, nc):\", (true_df, true_nc))\n",
    "print(\"MLE    (df, nc):\", tuple(res.x))\n",
    "print(\"Success:\", res.success)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3422b0c",
   "metadata": {},
   "source": [
    "## 7) Sampling & simulation (NumPy-only)\n",
    "\n",
    "The construction $T=(Z+\\delta)/\\sqrt{V/\\nu}$ immediately gives a simple sampler:\n",
    "\n",
    "1. Sample $Z\\sim\\mathcal N(0,1)$.\n",
    "2. Sample $V\\sim\\chi^2_{\\nu}$ independently.\n",
    "3. Return $T=(Z+\\delta)/\\sqrt{V/\\nu}$.\n",
    "\n",
    "NumPy can sample both normals and chi-square variables, so this is a true \"from-scratch\" simulator in the sense that it does *not* call `scipy.stats.nct.rvs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21104003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nct_rvs_numpy(df: float, nc: float, size: int, rng: np.random.Generator) -> np.ndarray:\n",
    "    if df <= 0:\n",
    "        raise ValueError(\"df must be > 0\")\n",
    "    z = rng.standard_normal(size) + nc\n",
    "    v = rng.chisquare(df, size=size)\n",
    "    return z / np.sqrt(v / df)\n",
    "\n",
    "\n",
    "# Sanity-check: Monte Carlo mean/variance vs theory\n",
    "df, nc = 10.0, 1.2\n",
    "x_mc = nct_rvs_numpy(df, nc, size=300_000, rng=rng)\n",
    "\n",
    "m_theory, v_theory, *_ = nct_moments_closed_form(df, nc)\n",
    "\n",
    "print(\"MC mean/var:\", float(x_mc.mean()), float(x_mc.var()))\n",
    "print(\"Theory mean/var:\", float(m_theory), float(v_theory))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a86ec61",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We'll plot:\n",
    "\n",
    "- the **PDF** and a Monte Carlo **histogram**\n",
    "- the **CDF** and an empirical CDF from samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331e9348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(x: np.ndarray):\n",
    "    xs = np.sort(np.asarray(x, dtype=float))\n",
    "    ps = (np.arange(1, xs.size + 1) / xs.size)\n",
    "    return xs, ps\n",
    "\n",
    "\n",
    "df, nc = 8.0, 1.5\n",
    "x_grid = np.linspace(-8, 8, 1500)\n",
    "\n",
    "samples = nct_rvs_numpy(df, nc, size=80_000, rng=rng)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"PDF + Monte Carlo histogram\", \"CDF + empirical CDF\"),\n",
    ")\n",
    "\n",
    "# PDF + histogram\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=samples,\n",
    "        nbinsx=120,\n",
    "        histnorm=\"probability density\",\n",
    "        name=\"samples\",\n",
    "        opacity=0.55,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x_grid, y=nct_pdf(x_grid, df, nc), name=\"theoretical PDF\", mode=\"lines\"),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# CDF + ECDF\n",
    "xs, ps = ecdf(samples)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x_grid, y=nct_cdf(x_grid, df, nc), name=\"theoretical CDF\", mode=\"lines\"),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=xs[::50], y=ps[::50], name=\"empirical CDF\", mode=\"markers\", marker=dict(size=4)),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_layout(height=430, width=980, title_text=f\"Noncentral t (df={df}, nc={nc})\")\n",
    "fig.update_xaxes(title_text=\"x\")\n",
    "fig.update_yaxes(title_text=\"density\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"F(x)\", row=1, col=2)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4d5e29",
   "metadata": {},
   "source": [
    "## 9) SciPy integration (`scipy.stats.nct`)\n",
    "\n",
    "SciPy provides the noncentral t distribution as `scipy.stats.nct`.\n",
    "\n",
    "Key methods:\n",
    "\n",
    "- `nct.pdf(x, df, nc)`, `nct.logpdf(...)`\n",
    "- `nct.cdf(x, df, nc)`, `nct.sf(...)` (survival)\n",
    "- `nct.rvs(df, nc, size=..., random_state=...)`\n",
    "- `nct.fit(data, ...)` (MLE)\n",
    "\n",
    "SciPy also supports `loc` and `scale`, i.e. $X = \\mathrm{loc} + \\mathrm{scale}\\cdot T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, nc = 12.0, -0.75\n",
    "x = np.array([-2.0, 0.0, 2.0])\n",
    "\n",
    "print(\"pdf:\", nct.pdf(x, df, nc))\n",
    "print(\"cdf:\", nct.cdf(x, df, nc))\n",
    "print(\"rvs:\", nct.rvs(df, nc, size=5, random_state=rng))\n",
    "print(\"entropy:\", nct.entropy(df, nc))\n",
    "\n",
    "# Fit example (standardized loc=0, scale=1)\n",
    "data = nct.rvs(9.0, 1.1, size=4000, random_state=rng)\n",
    "df_hat, nc_hat, loc_hat, scale_hat = nct.fit(data, floc=0.0, fscale=1.0)\n",
    "\n",
    "print(\"fit df, nc:\", df_hat, nc_hat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b935c3d",
   "metadata": {},
   "source": [
    "## 10) Statistical use cases\n",
    "\n",
    "### 10.1 Hypothesis testing: power of a t-test\n",
    "For a two-sided one-sample t-test at level $\\alpha$, the rejection region is\n",
    "\n",
    "$$\n",
    "|T| > t_{1-\\alpha/2,\\,\\nu},\\qquad \\nu=n-1.\n",
    "$$\n",
    "\n",
    "Under the alternative, $T\\sim\\mathrm{NCT}(\\nu,\\delta)$ with $\\delta=\\sqrt{n}(\\mu-\\mu_0)/\\sigma$.\n",
    "So the power is\n",
    "\n",
    "$$\n",
    "\\mathsf{Power} = \\mathbb P(T>c) + \\mathbb P(T<-c),\\quad c=t_{1-\\alpha/2,\\nu}.\n",
    "$$\n",
    "\n",
    "### 10.2 Bayesian modeling: predictive distribution of a t-statistic\n",
    "If you put a prior on the effect size (hence on $\\delta$), then the **predictive distribution** of the t-statistic is a **mixture of noncentral t distributions**:\n",
    "\n",
    "$$\n",
    "T \\mid \\delta \\sim \\mathrm{NCT}(\\nu,\\delta),\\qquad \\delta \\sim p(\\delta).\n",
    "$$\n",
    "\n",
    "This mixture is rarely available in closed form, but it is straightforward to sample.\n",
    "\n",
    "### 10.3 Generative modeling\n",
    "`nct` is a natural generator for **t-statistics / z-like scores** under alternatives.\n",
    "From that you can simulate p-value distributions, power curves, and multiple-testing behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be55c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_two_sided_t(n: int, alpha: float, mu_minus_mu0: float, sigma: float = 1.0) -> float:\n",
    "    df = n - 1\n",
    "    delta = np.sqrt(n) * (mu_minus_mu0 / sigma)\n",
    "    crit = t.isf(alpha / 2, df)\n",
    "    return float(nct.sf(crit, df, delta) + nct.cdf(-crit, df, delta))\n",
    "\n",
    "\n",
    "alpha = 0.05\n",
    "n = 20\n",
    "sig = 1.0\n",
    "\n",
    "effects = np.linspace(0.0, 1.2, 61)\n",
    "powers = np.array([power_two_sided_t(n, alpha, eff, sigma=sig) for eff in effects])\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[go.Scatter(x=effects, y=powers, mode=\"lines\", name=\"power\")],\n",
    "    layout=go.Layout(\n",
    "        title=f\"Two-sided one-sample t-test power (n={n}, alpha={alpha})\",\n",
    "        xaxis_title=\"effect (mu - mu0) in units of sigma\",\n",
    "        yaxis_title=\"power\",\n",
    "        yaxis=dict(range=[0, 1]),\n",
    "    ),\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb1e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian-flavored example: predictive distribution of T under a prior on the standardized effect d\n",
    "# d = (mu - mu0)/sigma, delta = sqrt(n)*d\n",
    "\n",
    "n = 20\n",
    "nu = n - 1\n",
    "\n",
    "tau = 0.4  # prior std on standardized effect size d\n",
    "m = 120_000\n",
    "\n",
    "# Prior on effect size -> prior on delta\n",
    "prior_d = rng.normal(0.0, tau, size=m)\n",
    "prior_delta = np.sqrt(n) * prior_d\n",
    "\n",
    "# Predictive sampling: sample delta, then sample T | delta ~ nct(nu, delta)\n",
    "# (NumPy-only sampler using the nct construction)\n",
    "z = rng.standard_normal(m) + prior_delta\n",
    "v = rng.chisquare(nu, size=m)\n",
    "t_pred = z / np.sqrt(v / nu)\n",
    "\n",
    "a = 0.05\n",
    "crit = t.isf(a / 2, nu)\n",
    "print(\"Prior predictive P(reject H0):\", float((np.abs(t_pred) > crit).mean()))\n",
    "\n",
    "xg = np.linspace(-6, 6, 900)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=t_pred,\n",
    "        nbinsx=140,\n",
    "        histnorm=\"probability density\",\n",
    "        name=\"prior-predictive samples\",\n",
    "        opacity=0.6,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=xg, y=t.pdf(xg, nu), name=\"central t (delta=0)\", mode=\"lines\"))\n",
    "fig.update_layout(\n",
    "    title=f\"Prior predictive distribution of T (nu={nu}, prior d ~ N(0, {tau}^2))\",\n",
    "    xaxis_title=\"t statistic\",\n",
    "    yaxis_title=\"density\",\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd92a5",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Parameter constraints**: $\\nu>0$. Many summary statistics require stronger conditions (e.g. variance needs $\\nu>2$).\n",
    "- **Skewness and asymmetry**: when $\\delta\\neq 0$, the distribution is not symmetric; don't reuse symmetric t heuristics.\n",
    "- **Extreme tails**: for small $\\nu$, Monte Carlo samples can be very large; use robust summaries (quantiles) and sufficient sample sizes.\n",
    "- **Numerical issues**: evaluating the PDF/CDF for very large $|\\delta|$ or very small $\\nu$ can be challenging; prefer library implementations (`special.nctdtr`, `nct.logpdf`).\n",
    "- **MLE fitting**: `nct.fit` is a nonconvex numerical optimization; it can be sensitive to starting values and may converge to poor local optima."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5e0b50",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `nct` is a **continuous** distribution on $\\mathbb R$ with parameters $\\nu>0$ (degrees of freedom) and $\\delta\\in\\mathbb R$ (noncentrality).\n",
    "- It is the distribution of a **t-statistic under an alternative**: $T=(Z+\\delta)/\\sqrt{V/\\nu}$.\n",
    "- Moments exist only when $\\nu$ is large enough (mean: $\\nu>1$, variance: $\\nu>2$, etc.).\n",
    "- Sampling is easy from first principles with NumPy (normal + chi-square).\n",
    "- `scipy.stats.nct` provides stable numerical evaluation (`pdf`, `cdf`) and estimation (`fit`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}