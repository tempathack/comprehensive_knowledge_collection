{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e7b2f1a",
   "metadata": {},
   "source": [
    "# Truncated Exponential Distribution (`truncexpon`)\n",
    "\n",
    "The truncated exponential distribution is what you get when you take an **exponential waiting time** and then **condition it to lie in a finite interval**.\n",
    "\n",
    "It is a natural model for positive quantities that are approximately exponential, but where a **hard maximum** exists (timeouts, finite observation windows, physical limits). SciPy exposes this distribution as `scipy.stats.truncexpon`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1d0af",
   "metadata": {},
   "source": [
    "## What you’ll learn\n",
    "\n",
    "- How `truncexpon` relates to the exponential distribution (conditioning/truncation)\n",
    "- PDF, CDF, inverse CDF, and how to sample it with NumPy only\n",
    "- Closed-form mean/variance and how to compute higher moments stably\n",
    "- How SciPy parameterizes `truncexpon`, including fitting\n",
    "- Practical modeling and inference patterns (likelihood, testing, Bayesian grids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b387e37",
   "metadata": {},
   "source": [
    "## Notebook roadmap\n",
    "1) Title & classification\n",
    "2) Intuition & motivation\n",
    "3) Formal definition (PDF/CDF)\n",
    "4) Moments & properties\n",
    "5) Parameter interpretation\n",
    "6) Derivations (expectation, variance, likelihood)\n",
    "7) Sampling & simulation (NumPy-only)\n",
    "8) Visualization (PDF, CDF, Monte Carlo)\n",
    "9) SciPy integration (`scipy.stats.truncexpon`)\n",
    "10) Statistical use cases\n",
    "11) Pitfalls\n",
    "12) Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d7451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "SEED = 7\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "\n",
    "print(\"numpy \", np.__version__)\n",
    "print(\"scipy \", scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a4b6bb",
   "metadata": {},
   "source": [
    "## Prerequisites & notation\n",
    "\n",
    "**Prerequisites**\n",
    "- comfort with basic calculus (integration by parts)\n",
    "- basic probability (PDF/CDF, expectation)\n",
    "- familiarity with numerical stability (`expm1`, `log1p`) is helpful\n",
    "\n",
    "**Two parameterizations**\n",
    "\n",
    "1) **Rate/truncation form** (common in probability texts)\n",
    "\n",
    "- Rate: \\(\\lambda > 0\\)\n",
    "- Upper truncation: \\(B > 0\\)\n",
    "- Support: \\(x \\in [0, B]\\)\n",
    "\n",
    "2) **SciPy form** (`scipy.stats.truncexpon`)\n",
    "\n",
    "- Shape: \\(b > 0\\) (dimensionless)\n",
    "- Location: \\(\\mathrm{loc} \\in \\mathbb{R}\\)\n",
    "- Scale: \\(\\mathrm{scale} > 0\\)\n",
    "- Support: \\(x \\in [\\mathrm{loc},\\; \\mathrm{loc} + b\\,\\mathrm{scale}]\\)\n",
    "\n",
    "The mapping between the two is:\n",
    "\n",
    "- \\(\\lambda = 1/\\mathrm{scale}\\)\n",
    "- \\(B = b\\,\\mathrm{scale}\\)\n",
    "- shift by `loc` if the lower endpoint is not zero\n",
    "\n",
    "So you can interpret \\(b = \\lambda B\\) as **\"how many exponential scales fit inside the truncation window\"**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f4ea88",
   "metadata": {},
   "source": [
    "## 1) Title & classification\n",
    "\n",
    "- **Name**: `truncexpon` (truncated exponential)\n",
    "- **Type**: **continuous**\n",
    "- **Support**:\n",
    "  - canonical: \\(x \\in [0, B]\\)\n",
    "  - SciPy: \\(x \\in [\\mathrm{loc},\\; \\mathrm{loc} + b\\,\\mathrm{scale}]\\)\n",
    "- **Parameter space**:\n",
    "  - canonical: \\(\\lambda \\in (0,\\infty)\\), \\(B \\in (0,\\infty)\\)\n",
    "  - SciPy: \\(b \\in (0,\\infty)\\), `loc` \\(\\in \\mathbb{R}\\), `scale` \\(\\in (0,\\infty)\\)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ceba88",
   "metadata": {},
   "source": [
    "## 2) Intuition & motivation\n",
    "\n",
    "### What it models\n",
    "Start with an exponential waiting time \\(Y \\sim \\mathrm{Exp}(\\lambda)\\) (memoryless waiting time).\n",
    "Now impose a **hard maximum** \\(B\\) and look at the conditional distribution:\n",
    "\n",
    "\\[\n",
    "X \\;=\\; Y \\mid (Y \\le B).\n",
    "\\]\n",
    "\n",
    "That is exactly the truncated exponential.\n",
    "\n",
    "### Typical real-world use cases\n",
    "- **Timeout-limited durations**: network requests or jobs that are aborted at a timeout\n",
    "- **Finite observation windows**: inter-arrival times observed only up to the end of a study period\n",
    "- **Physical constraints**: decay/lifetime-like mechanisms with an imposed maximum by design\n",
    "- **Simulation of bounded positive features**: bounded right-skewed variables\n",
    "\n",
    "### Relations to other distributions\n",
    "- **Exponential**: as \\(B \\to \\infty\\) (or \\(b \\to \\infty\\)), `truncexpon` approaches the exponential distribution.\n",
    "- **Uniform**: as \\(B \\to 0\\) (or \\(b \\to 0\\)), the density becomes nearly constant on \\([0,B]\\), approaching a uniform distribution.\n",
    "- **Truncation vs censoring**: truncated means values above \\(B\\) are *not present* (conditioned away). Censoring means you know an observation exceeded \\(B\\) but not its exact value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798f3f2",
   "metadata": {},
   "source": [
    "## 3) Formal definition\n",
    "\n",
    "### PDF (rate/truncation form)\n",
    "Let \\(X\\) be an exponential random variable with rate \\(\\lambda\\), conditioned to lie in \\([0,B]\\).\n",
    "Define the normalizing constant:\n",
    "\n",
    "\\[\n",
    "Z(\\lambda, B) = \\mathbb{P}(Y\\le B) = 1 - e^{-\\lambda B}.\n",
    "\\]\n",
    "\n",
    "Then the PDF is\n",
    "\n",
    "\\[\n",
    "f(x\\mid \\lambda,B) =\n",
    "\\begin{cases}\n",
    "\\dfrac{\\lambda e^{-\\lambda x}}{1 - e^{-\\lambda B}}, & 0\\le x\\le B \\\\\n",
    "0, & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "\\]\n",
    "\n",
    "### CDF\n",
    "\\[\n",
    "F(x\\mid \\lambda,B) =\n",
    "\\begin{cases}\n",
    "0, & x < 0 \\\\\n",
    "\\dfrac{1 - e^{-\\lambda x}}{1 - e^{-\\lambda B}}, & 0\\le x\\le B \\\\\n",
    "1, & x > B.\n",
    "\\end{cases}\n",
    "\\]\n",
    "\n",
    "### Inverse CDF (for sampling)\n",
    "For \\(U\\sim\\mathrm{Uniform}(0,1)\\), solve \\(U = F(X)\\):\n",
    "\n",
    "\\[\n",
    "U = \\frac{1 - e^{-\\lambda X}}{1 - e^{-\\lambda B}}\n",
    "\\;\\Rightarrow\\;\n",
    "X = -\\frac{1}{\\lambda}\\ln\\Big(1 - U\\,(1 - e^{-\\lambda B})\\Big).\n",
    "\\]\n",
    "\n",
    "### SciPy parameterization\n",
    "SciPy’s base distribution is the \\(\\lambda=1\\) version truncated at \\(b\\): support \\([0,b]\\).\n",
    "With `loc` and `scale`, SciPy uses\n",
    "\n",
    "- \\(x = \\mathrm{loc} + \\mathrm{scale}\\,z\\)\n",
    "- \\(z \\in [0,b]\\)\n",
    "\n",
    "So the support is \\([\\mathrm{loc},\\; \\mathrm{loc} + b\\,\\mathrm{scale}]\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _one_minus_exp_neg(x: np.ndarray | float) -> np.ndarray | float:\n",
    "    \"\"\"Compute 1 - exp(-x) stably for x>=0.\"\"\"\n",
    "    return -np.expm1(-x)\n",
    "\n",
    "\n",
    "def truncexpon_pdf(x: np.ndarray | float, b: float, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"PDF for SciPy-style truncexpon(b, loc, scale). NumPy-only, vectorized.\"\"\"\n",
    "    if not (b > 0):\n",
    "        raise ValueError(\"b must be > 0\")\n",
    "    if not (scale > 0):\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    z = (x - loc) / scale\n",
    "    in_support = (z >= 0.0) & (z <= b)\n",
    "\n",
    "    Z = _one_minus_exp_neg(b)  # 1 - exp(-b)\n",
    "    out = np.zeros_like(z)\n",
    "    out[in_support] = np.exp(-z[in_support]) / (scale * Z)\n",
    "    return out\n",
    "\n",
    "\n",
    "def truncexpon_cdf(x: np.ndarray | float, b: float, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"CDF for SciPy-style truncexpon(b, loc, scale). NumPy-only, vectorized.\"\"\"\n",
    "    if not (b > 0):\n",
    "        raise ValueError(\"b must be > 0\")\n",
    "    if not (scale > 0):\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    z = (x - loc) / scale\n",
    "\n",
    "    Z = _one_minus_exp_neg(b)\n",
    "    out = np.zeros_like(z)\n",
    "\n",
    "    out = np.where(z < 0.0, 0.0, out)\n",
    "    out = np.where(z >= b, 1.0, out)\n",
    "\n",
    "    mid = (z >= 0.0) & (z < b)\n",
    "    out[mid] = _one_minus_exp_neg(z[mid]) / Z\n",
    "    return out\n",
    "\n",
    "\n",
    "def truncexpon_ppf(u: np.ndarray | float, b: float, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Inverse CDF (PPF) for SciPy-style truncexpon(b, loc, scale).\"\"\"\n",
    "    if not (b > 0):\n",
    "        raise ValueError(\"b must be > 0\")\n",
    "    if not (scale > 0):\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    u = np.asarray(u, dtype=float)\n",
    "    if np.any((u < 0) | (u > 1)):\n",
    "        raise ValueError(\"u must be in [0, 1]\")\n",
    "\n",
    "    Z = _one_minus_exp_neg(b)\n",
    "    z = -np.log1p(-u * Z)  # stable: -log(1 - u*(1-exp(-b)))\n",
    "    return loc + scale * z\n",
    "\n",
    "\n",
    "def truncexpon_rvs_np(\n",
    "    n: int,\n",
    "    b: float,\n",
    "    loc: float = 0.0,\n",
    "    scale: float = 1.0,\n",
    "    rng: np.random.Generator | None = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"NumPy-only sampling via inverse transform.\"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    u = rng.random(n)\n",
    "    return truncexpon_ppf(u, b=b, loc=loc, scale=scale)\n",
    "\n",
    "\n",
    "def truncexpon_raw_moments_std(b: float, max_k: int = 4) -> list[float]:\n",
    "    \"\"\"Raw moments E[Z^k] for Z ~ truncexpon(b, loc=0, scale=1).\n",
    "\n",
    "    Uses integer-k closed forms:\n",
    "      ∫_0^b x^k e^{-x} dx = k! - e^{-b} * P_k(b)\n",
    "    where P_k is a degree-k polynomial with factorial-like coefficients.\n",
    "    \"\"\"\n",
    "    if not (b > 0):\n",
    "        raise ValueError(\"b must be > 0\")\n",
    "    if max_k < 1:\n",
    "        raise ValueError(\"max_k must be >= 1\")\n",
    "\n",
    "    q = math.exp(-b)\n",
    "    Z = -math.expm1(-b)\n",
    "\n",
    "    moments: list[float] = []\n",
    "\n",
    "    if max_k >= 1:\n",
    "        m1 = (1.0 - (b + 1.0) * q) / Z\n",
    "        moments.append(m1)\n",
    "    if max_k >= 2:\n",
    "        m2 = (2.0 - (b * b + 2.0 * b + 2.0) * q) / Z\n",
    "        moments.append(m2)\n",
    "    if max_k >= 3:\n",
    "        m3 = (6.0 - (b**3 + 3.0 * b * b + 6.0 * b + 6.0) * q) / Z\n",
    "        moments.append(m3)\n",
    "    if max_k >= 4:\n",
    "        m4 = (24.0 - (b**4 + 4.0 * b**3 + 12.0 * b * b + 24.0 * b + 24.0) * q) / Z\n",
    "        moments.append(m4)\n",
    "\n",
    "    return moments\n",
    "\n",
    "\n",
    "def truncexpon_mean_var_skew_kurt(b: float) -> tuple[float, float, float, float]:\n",
    "    \"\"\"Mean, variance, skewness, (excess) kurtosis for Z ~ truncexpon(b,0,1).\"\"\"\n",
    "    m1, m2, m3, m4 = truncexpon_raw_moments_std(b, max_k=4)\n",
    "    var = m2 - m1**2\n",
    "    if var <= 0:\n",
    "        raise FloatingPointError(\"non-positive variance\")\n",
    "\n",
    "    mu3 = m3 - 3 * m2 * m1 + 2 * m1**3\n",
    "    mu4 = m4 - 4 * m3 * m1 + 6 * m2 * m1**2 - 3 * m1**4\n",
    "\n",
    "    skew = mu3 / (var ** 1.5)\n",
    "    kurt = mu4 / (var**2)\n",
    "    excess_kurt = kurt - 3.0\n",
    "    return m1, var, skew, excess_kurt\n",
    "\n",
    "\n",
    "def truncexpon_entropy_std(b: float) -> float:\n",
    "    \"\"\"Differential entropy for Z ~ truncexpon(b,0,1) in nats.\"\"\"\n",
    "    mean, _, _, _ = truncexpon_mean_var_skew_kurt(b)\n",
    "    # h = E[X] + log(1 - exp(-b))\n",
    "    return mean + math.log(-math.expm1(-b))\n",
    "\n",
    "\n",
    "def truncexpon_mgf(t: np.ndarray | float, lam: float, B: float) -> np.ndarray:\n",
    "    \"\"\"MGF for X ~ Exp(lam) conditioned on X<=B (finite B).\"\"\"\n",
    "    if not (lam > 0):\n",
    "        raise ValueError(\"lam must be > 0\")\n",
    "    if not (B > 0):\n",
    "        raise ValueError(\"B must be > 0\")\n",
    "\n",
    "    t = np.asarray(t, dtype=complex)\n",
    "    Z = _one_minus_exp_neg(lam * B)\n",
    "\n",
    "    denom = lam - t\n",
    "    out = np.empty_like(t)\n",
    "\n",
    "    close = np.isclose(denom, 0.0)\n",
    "    out[close] = (lam * B) / Z\n",
    "\n",
    "    not_close = ~close\n",
    "    out[not_close] = (lam / denom[not_close]) * _one_minus_exp_neg(denom[not_close] * B) / Z\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bff7df7",
   "metadata": {},
   "source": [
    "## 4) Moments & properties\n",
    "\n",
    "Let \\(X \\sim \\mathrm{TruncExp}(\\lambda,B)\\) as defined above.\n",
    "Write \\(b = \\lambda B\\) and note \\(b\\) is dimensionless.\n",
    "\n",
    "### Mean and variance\n",
    "A convenient closed form is:\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[X] = \\frac{1}{\\lambda} - \\frac{B}{e^{\\lambda B} - 1}.\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "\\mathrm{Var}(X) = \\frac{1}{\\lambda^2}\\left(1 - \\frac{b^2 e^{b}}{(e^{b}-1)^2}\\right),\\quad b=\\lambda B.\n",
    "\\]\n",
    "\n",
    "As checks:\n",
    "- as \\(B\\to\\infty\\) (\\(b\\to\\infty\\)), the formulas approach the exponential mean \\(1/\\lambda\\) and variance \\(1/\\lambda^2\\)\n",
    "- as \\(B\\to 0\\), the distribution approaches \\(\\mathrm{Unif}(0,B)\\)\n",
    "\n",
    "### Higher moments, skewness, kurtosis\n",
    "For the **standardized SciPy base** \\(Z \\sim \\mathrm{truncexpon}(b,0,1)\\) (i.e. \\(\\lambda=1\\), \\(B=b\\)), raw moments have closed forms:\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[Z^k] = \\frac{\\int_0^b x^k e^{-x}dx}{1-e^{-b}} = \\frac{\\gamma(k+1,b)}{1-e^{-b}},\n",
    "\\]\n",
    "\n",
    "and for integer \\(k\\) these simplify to polynomials times \\(e^{-b}\\). From raw moments you can compute skewness and kurtosis.\n",
    "\n",
    "Scaling by `scale` and shifting by `loc` affects mean/variance in the usual way; **skewness and kurtosis are invariant under positive scaling and shifts**.\n",
    "\n",
    "### MGF and characteristic function\n",
    "For \\(t \\ne \\lambda\\):\n",
    "\n",
    "\\[\n",
    "M_X(t) = \\mathbb{E}[e^{tX}] = \\frac{\\lambda}{\\lambda - t}\\,\\frac{1 - e^{-(\\lambda-t)B}}{1 - e^{-\\lambda B}}.\n",
    "\\]\n",
    "\n",
    "The characteristic function is \\(\\varphi_X(\\omega) = M_X(i\\omega)\\).\n",
    "\n",
    "### Entropy (differential, in nats)\n",
    "Using \\(\\log f(x) = \\log\\lambda - \\lambda x - \\log(1-e^{-\\lambda B})\\),\n",
    "\n",
    "\\[\n",
    "H(X) = -\\mathbb{E}[\\log f(X)] = -\\log\\lambda + \\lambda\\,\\mathbb{E}[X] + \\log(1-e^{-\\lambda B}).\n",
    "\\]\n",
    "\n",
    "### Other properties\n",
    "- **Mode**: at the left endpoint (\\(0\\) or `loc`)\n",
    "- **Not memoryless**: truncation breaks the strict memoryless property\n",
    "- **Limits**:\n",
    "  - \\(b\\to\\infty\\): exponential\n",
    "  - \\(b\\to 0\\): approximately uniform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24ecf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_values = [0.3, 1.0, 3.0, 10.0]\n",
    "\n",
    "rows = []\n",
    "for b in b_values:\n",
    "    mean, var, skew, exkurt = truncexpon_mean_var_skew_kurt(b)\n",
    "    ent = truncexpon_entropy_std(b)\n",
    "\n",
    "    dist = stats.truncexpon(b)\n",
    "    sci_mean, sci_var, sci_skew, sci_exkurt = dist.stats(moments=\"mvsk\")\n",
    "    sci_ent = dist.entropy()\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"b\": b,\n",
    "            \"mean (ours)\": float(mean),\n",
    "            \"mean (scipy)\": float(sci_mean),\n",
    "            \"var (ours)\": float(var),\n",
    "            \"var (scipy)\": float(sci_var),\n",
    "            \"skew (ours)\": float(skew),\n",
    "            \"skew (scipy)\": float(sci_skew),\n",
    "            \"exkurt (ours)\": float(exkurt),\n",
    "            \"exkurt (scipy)\": float(sci_exkurt),\n",
    "            \"entropy (ours)\": float(ent),\n",
    "            \"entropy (scipy)\": float(sci_ent),\n",
    "        }\n",
    "    )\n",
    "\n",
    "px.table(rows).update_layout(title=\"Moments/entropy: NumPy formulas vs SciPy\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7393b86d",
   "metadata": {},
   "source": [
    "## 5) Parameter interpretation\n",
    "\n",
    "### Shape `b` (SciPy)\n",
    "In the SciPy base distribution (`loc=0`, `scale=1`), the support is \\([0,b]\\). So:\n",
    "\n",
    "- larger `b` means **less truncation**, more like a full exponential\n",
    "- smaller `b` means **strong truncation**, approaching a uniform distribution on \\([0,b]\\)\n",
    "\n",
    "In the rate/truncation form, `b` corresponds to \\(b=\\lambda B\\): truncation measured in **units of the exponential scale**.\n",
    "\n",
    "### `scale`\n",
    "`scale` stretches the distribution: if \\(Z\\) is the base distribution on \\([0,b]\\), then\n",
    "\\(X = \\mathrm{loc} + \\mathrm{scale}\\cdot Z\\).\n",
    "\n",
    "- Increasing `scale` increases all lengths (mean, standard deviation) proportionally.\n",
    "- Skewness and kurtosis do not change with `scale`.\n",
    "\n",
    "### `loc`\n",
    "`loc` shifts the distribution and the support by a constant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9bf8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 8, 600)\n",
    "\n",
    "b_list = [0.5, 1.5, 4.0, 10.0]\n",
    "fig = go.Figure()\n",
    "for b in b_list:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=truncexpon_pdf(x, b=b, loc=0.0, scale=1.0),\n",
    "            mode=\"lines\",\n",
    "            name=f\"b={b:g}\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_vline(x=b, line_dash=\"dot\", opacity=0.25)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Truncated exponential PDF (loc=0, scale=1) for different b\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"f(x)\",\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0c51af",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "We sketch the key derivations for the **rate/truncation** form.\n",
    "\n",
    "### Expectation\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[X] = \\int_0^B x\\,\\frac{\\lambda e^{-\\lambda x}}{1-e^{-\\lambda B}}\\,dx.\n",
    "\\]\n",
    "\n",
    "Compute the numerator via integration by parts. Let \\(u=x\\), \\(dv=\\lambda e^{-\\lambda x}\\,dx\\), so \\(du=dx\\) and \\(v=-e^{-\\lambda x}\\):\n",
    "\n",
    "\\[\n",
    "\\int_0^B x\\,\\lambda e^{-\\lambda x}\\,dx\n",
    "= \\left[-x e^{-\\lambda x}\\right]_0^B + \\int_0^B e^{-\\lambda x}\\,dx\n",
    "= -B e^{-\\lambda B} + \\frac{1-e^{-\\lambda B}}{\\lambda}.\n",
    "\\]\n",
    "\n",
    "Divide by \\(1-e^{-\\lambda B}\\):\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[X] = \\frac{1}{\\lambda} - \\frac{B e^{-\\lambda B}}{1-e^{-\\lambda B}} = \\frac{1}{\\lambda} - \\frac{B}{e^{\\lambda B}-1}.\n",
    "\\]\n",
    "\n",
    "### Second moment and variance\n",
    "Similarly,\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[X^2] = \\int_0^B x^2\\,\\frac{\\lambda e^{-\\lambda x}}{1-e^{-\\lambda B}}\\,dx\n",
    "= \\frac{2}{\\lambda^2} - \\frac{B^2 + 2B/\\lambda}{e^{\\lambda B}-1}.\n",
    "\\]\n",
    "\n",
    "Then \\(\\mathrm{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\\), which simplifies to\n",
    "\n",
    "\\[\n",
    "\\mathrm{Var}(X) = \\frac{1}{\\lambda^2}\\left(1 - \\frac{(\\lambda B)^2 e^{\\lambda B}}{(e^{\\lambda B}-1)^2}\\right).\n",
    "\\]\n",
    "\n",
    "### Likelihood\n",
    "Given i.i.d. observations \\(x_1,\\dots,x_n\\in[0,B]\\), the log-likelihood for \\(\\lambda\\) (with \\(B\\) fixed) is:\n",
    "\n",
    "\\[\n",
    "\\ell(\\lambda) = \\sum_{i=1}^n \\log f(x_i\\mid\\lambda,B)\n",
    "= n\\log\\lambda - \\lambda\\sum_i x_i - n\\log(1-e^{-\\lambda B}).\n",
    "\\]\n",
    "\n",
    "Setting the derivative to zero yields an equation for the MLE \\(\\hat\\lambda\\):\n",
    "\n",
    "\\[\n",
    "0 = \\frac{n}{\\lambda} - \\sum_i x_i - n\\,\\frac{B e^{-\\lambda B}}{1-e^{-\\lambda B}}.\n",
    "\\]\n",
    "\n",
    "There is generally **no closed form**, but the objective is smooth and easy to optimize numerically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncexp_loglik_lambda(x: np.ndarray, lam: float, B: float) -> float:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if not (lam > 0):\n",
    "        return -np.inf\n",
    "    if not (B > 0):\n",
    "        return -np.inf\n",
    "    if np.any((x < 0) | (x > B)):\n",
    "        return -np.inf\n",
    "\n",
    "    # log f = log lam - lam x - log(1-exp(-lam B))\n",
    "    # use log1p/expm1 for stability\n",
    "    logZ = np.log(_one_minus_exp_neg(lam * B))\n",
    "    return float(x.size * np.log(lam) - lam * x.sum() - x.size * logZ)\n",
    "\n",
    "\n",
    "# Demonstration: simulate data with known (lam,B) and estimate lam by MLE\n",
    "lam_true = 1.4\n",
    "B = 2.5\n",
    "\n",
    "# In SciPy form: scale=1/lam, b=lam*B\n",
    "b = lam_true * B\n",
    "x = truncexpon_rvs_np(n=800, b=b, loc=0.0, scale=1 / lam_true, rng=rng)\n",
    "\n",
    "def neg_loglik(lam: float) -> float:\n",
    "    return -truncexp_loglik_lambda(x, lam=lam, B=B)\n",
    "\n",
    "res = minimize_scalar(neg_loglik, bounds=(1e-6, 20.0), method=\"bounded\")\n",
    "lam_hat = float(res.x)\n",
    "\n",
    "lam_true, lam_hat, res.success\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112d1e63",
   "metadata": {},
   "source": [
    "## 7) Sampling & simulation (NumPy-only)\n",
    "\n",
    "Inverse transform sampling uses the inverse CDF derived earlier.\n",
    "\n",
    "For SciPy parameters (`b`, `loc`, `scale`):\n",
    "\n",
    "\\[\n",
    "X = \\mathrm{loc} + \\mathrm{scale}\\cdot \\Big[-\\ln(1 - U(1-e^{-b}))\\Big],\\quad U\\sim\\mathrm{Unif}(0,1).\n",
    "\\]\n",
    "\n",
    "**Numerical note:** compute \\(1-e^{-b}\\) with `-expm1(-b)` and use `log1p` for the log.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c0b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 3.0\n",
    "u_grid = np.linspace(0.001, 0.999, 1000)\n",
    "\n",
    "ppf_ours = truncexpon_ppf(u_grid, b=b, loc=0.0, scale=1.0)\n",
    "ppf_scipy = stats.truncexpon(b).ppf(u_grid)\n",
    "\n",
    "np.max(np.abs(ppf_ours - ppf_scipy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c73a95",
   "metadata": {},
   "source": [
    "## 8) Visualization (PDF, CDF, Monte Carlo)\n",
    "\n",
    "We’ll visualize:\n",
    "- the PDF and CDF for multiple `b`\n",
    "- Monte Carlo samples vs the theoretical density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb27c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_list = [0.5, 1.0, 3.0, 8.0]\n",
    "x = np.linspace(0, 8, 800)\n",
    "\n",
    "fig_pdf = go.Figure()\n",
    "fig_cdf = go.Figure()\n",
    "\n",
    "for b in b_list:\n",
    "    fig_pdf.add_trace(\n",
    "        go.Scatter(x=x, y=truncexpon_pdf(x, b=b), mode=\"lines\", name=f\"b={b:g}\")\n",
    "    )\n",
    "    fig_cdf.add_trace(\n",
    "        go.Scatter(x=x, y=truncexpon_cdf(x, b=b), mode=\"lines\", name=f\"b={b:g}\")\n",
    "    )\n",
    "\n",
    "fig_pdf.update_layout(title=\"PDF for different b (loc=0, scale=1)\", xaxis_title=\"x\", yaxis_title=\"f(x)\")\n",
    "fig_cdf.update_layout(title=\"CDF for different b (loc=0, scale=1)\", xaxis_title=\"x\", yaxis_title=\"F(x)\")\n",
    "\n",
    "fig_pdf.show()\n",
    "fig_cdf.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d9ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo vs theoretical\n",
    "b = 3.0\n",
    "n = 60_000\n",
    "x_samp = truncexpon_rvs_np(n=n, b=b, rng=rng)\n",
    "\n",
    "grid = np.linspace(0, b, 600)\n",
    "pdf_grid = truncexpon_pdf(grid, b=b)\n",
    "\n",
    "hist_y, hist_edges = np.histogram(x_samp, bins=70, range=(0, b), density=True)\n",
    "hist_x = 0.5 * (hist_edges[:-1] + hist_edges[1:])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=hist_x, y=hist_y, name=\"Monte Carlo (density)\", opacity=0.55))\n",
    "fig.add_trace(go.Scatter(x=grid, y=pdf_grid, mode=\"lines\", name=\"Theoretical PDF\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Monte Carlo vs PDF (b={b:g}, n={n:,})\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"density\",\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Moment check\n",
    "mean_theory, var_theory, *_ = truncexpon_mean_var_skew_kurt(b)\n",
    "mean_mc = float(x_samp.mean())\n",
    "var_mc = float(x_samp.var())\n",
    "\n",
    "mean_theory, mean_mc, var_theory, var_mc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae17c3b",
   "metadata": {},
   "source": [
    "## 9) SciPy integration (`scipy.stats.truncexpon`)\n",
    "\n",
    "SciPy exposes this distribution as `scipy.stats.truncexpon`.\n",
    "\n",
    "Key points:\n",
    "- Shape parameter: `b`\n",
    "- Location/scale: `loc`, `scale`\n",
    "- Support: \\([\\mathrm{loc},\\; \\mathrm{loc}+b\\,\\mathrm{scale}]\\)\n",
    "\n",
    "Useful methods:\n",
    "- `pdf`, `logpdf`\n",
    "- `cdf`, `ppf`\n",
    "- `rvs`\n",
    "- `stats(moments=\"mvsk\")`\n",
    "- `fit` (MLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f664818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_true, loc_true, scale_true = 4.0, 1.5, 2.0\n",
    "dist = stats.truncexpon(b_true, loc=loc_true, scale=scale_true)\n",
    "\n",
    "x0 = np.array([loc_true, loc_true + 0.5 * scale_true, loc_true + b_true * scale_true])\n",
    "\n",
    "pd = dist.pdf(x0)\n",
    "cd = dist.cdf(x0)\n",
    "rv = dist.rvs(size=5, random_state=rng)\n",
    "\n",
    "pd, cd, rv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe20914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter fitting example\n",
    "n = 2_000\n",
    "x = stats.truncexpon(b_true, loc=loc_true, scale=scale_true).rvs(size=n, random_state=rng)\n",
    "\n",
    "# Fitting all params can be hard; fixing loc when known often helps.\n",
    "b_hat1, loc_hat1, scale_hat1 = stats.truncexpon.fit(x)\n",
    "b_hat2, loc_hat2, scale_hat2 = stats.truncexpon.fit(x, floc=loc_true)\n",
    "\n",
    "(\n",
    "    (b_true, loc_true, scale_true),\n",
    "    (b_hat1, loc_hat1, scale_hat1),\n",
    "    (b_hat2, loc_hat2, scale_hat2),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf6a3d1",
   "metadata": {},
   "source": [
    "## 10) Statistical use cases\n",
    "\n",
    "### A) Hypothesis testing\n",
    "If a truncation point \\(B\\) is known (e.g., a fixed timeout), you can test hypotheses about the rate \\(\\lambda\\) using a likelihood ratio test:\n",
    "\n",
    "- \\(H_0: \\lambda=\\lambda_0\\)\n",
    "- \\(H_1: \\lambda\\) free\n",
    "\n",
    "The test statistic is \\(2(\\ell(\\hat\\lambda)-\\ell(\\lambda_0))\\), which is asymptotically \\(\\chi^2_1\\) under regularity conditions.\n",
    "\n",
    "### B) Bayesian modeling\n",
    "Truncated exponentials show up naturally when a prior or likelihood is exponential-like but constrained:\n",
    "\n",
    "- bounded waiting times (timeouts)\n",
    "- bounded survival times due to study design\n",
    "\n",
    "A Gamma prior for \\(\\lambda\\) is no longer strictly conjugate because of the \\(\\log(1-e^{-\\lambda B})\\) term, but you can still compute a posterior numerically (grid, MCMC).\n",
    "\n",
    "### C) Generative modeling\n",
    "Use `truncexpon` to generate **bounded, right-skewed** features. It can also be a component of mixture models (e.g., two populations with different scales but the same timeout).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bd7bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Likelihood ratio test for λ with known truncation B\n",
    "lam_true = 1.4\n",
    "B = 2.5\n",
    "n = 600\n",
    "\n",
    "b = lam_true * B\n",
    "x = truncexpon_rvs_np(n=n, b=b, loc=0.0, scale=1 / lam_true, rng=rng)\n",
    "\n",
    "def mle_lambda_given_B(x: np.ndarray, B: float) -> float:\n",
    "    def nll(lam: float) -> float:\n",
    "        return -truncexp_loglik_lambda(x, lam=lam, B=B)\n",
    "\n",
    "    res = minimize_scalar(nll, bounds=(1e-6, 50.0), method=\"bounded\")\n",
    "    return float(res.x)\n",
    "\n",
    "\n",
    "lam_hat = mle_lambda_given_B(x, B=B)\n",
    "\n",
    "lam0 = 1.0\n",
    "ll_hat = truncexp_loglik_lambda(x, lam=lam_hat, B=B)\n",
    "ll_0 = truncexp_loglik_lambda(x, lam=lam0, B=B)\n",
    "\n",
    "lrt = 2 * (ll_hat - ll_0)\n",
    "p_value = 1 - stats.chi2(df=1).cdf(lrt)\n",
    "\n",
    "lam_true, lam_hat, lrt, p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df850cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) Bayesian grid posterior for λ (not conjugate due to truncation term)\n",
    "x = x  # from the previous cell\n",
    "\n",
    "# Prior: λ ~ Gamma(alpha0, beta0) with rate beta0\n",
    "alpha0 = 2.0\n",
    "beta0 = 1.0\n",
    "\n",
    "lam_grid = np.linspace(0.05, 6.0, 600)\n",
    "\n",
    "log_prior = stats.gamma(a=alpha0, scale=1 / beta0).logpdf(lam_grid)\n",
    "log_like = np.array([truncexp_loglik_lambda(x, lam=float(l), B=B) for l in lam_grid])\n",
    "\n",
    "log_post_unnorm = log_prior + log_like\n",
    "log_post_unnorm -= log_post_unnorm.max()\n",
    "\n",
    "post_unnorm = np.exp(log_post_unnorm)\n",
    "post = post_unnorm / np.trapz(post_unnorm, lam_grid)\n",
    "\n",
    "fig = px.line(x=lam_grid, y=post, title=\"Posterior over λ (grid approximation)\")\n",
    "fig.update_layout(xaxis_title=\"λ\", yaxis_title=\"posterior density\")\n",
    "fig.add_vline(x=lam_true, line_dash=\"dot\", opacity=0.35)\n",
    "fig.add_vline(x=lam_hat, line_dash=\"dash\", opacity=0.35)\n",
    "fig.show()\n",
    "\n",
    "lam_post_mean = float(np.trapz(lam_grid * post, lam_grid))\n",
    "lam_post_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f44d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C) Simple mixture generation example\n",
    "n = 20_000\n",
    "B = 2.0\n",
    "\n",
    "lam1, lam2 = 0.8, 2.0\n",
    "w = 0.6\n",
    "\n",
    "u = rng.random(n)\n",
    "comp = (u < w)\n",
    "\n",
    "x1 = truncexpon_rvs_np(n=comp.sum(), b=lam1 * B, scale=1 / lam1, rng=rng)\n",
    "x2 = truncexpon_rvs_np(n=(~comp).sum(), b=lam2 * B, scale=1 / lam2, rng=rng)\n",
    "x_mix = np.empty(n)\n",
    "x_mix[comp] = x1\n",
    "x_mix[~comp] = x2\n",
    "\n",
    "fig = px.histogram(x_mix, nbins=80, histnorm=\"probability density\", title=\"Mixture of two truncated exponentials\")\n",
    "fig.update_layout(xaxis_title=\"x\", yaxis_title=\"density\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cb3c18",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Invalid parameters**: `b <= 0` or `scale <= 0` is invalid. Always validate.\n",
    "- **Truncation vs censoring**:\n",
    "  - truncated: you only see samples \\(\\le B\\) because the model is conditional on that event\n",
    "  - censored: you may observe \"\\(>B\\)\" without the exact value; the likelihood is different\n",
    "- **Numerical stability**:\n",
    "  - use `-expm1(-b)` for \\(1-e^{-b}\\) when `b` is small\n",
    "  - use `log1p` for \\(\\log(1-u(1-e^{-b}))\\)\n",
    "  - prefer `logpdf` when densities are extremely small\n",
    "- **Fitting**:\n",
    "  - estimating `loc`, `scale`, and `b` jointly can be unstable\n",
    "  - when the truncation endpoint is known (timeouts), fix it via `floc`/`fscale` or by reparameterizing\n",
    "- **Goodness-of-fit with fitted parameters**: classical KS p-values are not exact after parameter fitting; consider bootstrap if you need calibrated p-values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d49c6b0",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `truncexpon` is a **continuous** distribution: an exponential waiting time **conditioned** to lie in a finite interval.\n",
    "- Canonical PDF/CDF on \\([0,B]\\):\n",
    "  \\(f(x)=\\lambda e^{-\\lambda x}/(1-e^{-\\lambda B})\\), \\(F(x)=(1-e^{-\\lambda x})/(1-e^{-\\lambda B})\\).\n",
    "- Mean/variance have closed forms; skewness/kurtosis depend only on the dimensionless truncation \\(b=\\lambda B\\).\n",
    "- Sampling is easy with inverse CDF and can be implemented with NumPy only.\n",
    "- In SciPy: `stats.truncexpon(b, loc=..., scale=...)` with support \\([\\mathrm{loc}, \\mathrm{loc}+b\\,\\mathrm{scale}]\\).\n",
    "- Inference often requires numerical optimization (MLE) or numerical Bayes (grids/MCMC) because truncation breaks some convenient conjugacies.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}