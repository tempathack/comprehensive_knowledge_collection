{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2a8c4d1",
   "metadata": {},
   "source": [
    "# Exponential power distribution (`exponpow`)\n",
    "\n",
    "SciPy’s `exponpow` is a **continuous** distribution on $[0,\\infty)$ with a tunable *near-zero behavior* and an extremely light (double-exponential) right tail.\n",
    "\n",
    "A particularly useful generative story is:\n",
    "\n",
    "$$\n",
    "E \\sim \\mathrm{Exp}(1),\\quad X = \\bigl(\\log(1+E)\\bigr)^{1/b}\n",
    "\\ \\Longrightarrow\\ X \\sim \\mathrm{exponpow}(b).\n",
    "$$\n",
    "\n",
    "Equivalently,\n",
    "\n",
    "$$\n",
    "X^b \\sim \\mathrm{Gompertz}(c=1)\n",
    "\\quad\\text{and}\\quad\n",
    "\\exp(X^b)-1 \\sim \\mathrm{Exp}(1).\n",
    "$$\n",
    "\n",
    "**Important:** this is *not* the symmetric “exponential power / generalized normal” distribution (a common naming collision).\n",
    "\n",
    "---\n",
    "\n",
    "## Learning goals\n",
    "- write down the PDF/CDF and inverse CDF (PPF)\n",
    "- understand the link to the Gompertz and exponential distributions\n",
    "- compute moments, MGF/CF, and entropy via stable integral representations\n",
    "- implement NumPy-only sampling (inverse transform / exponential transform)\n",
    "- use `scipy.stats.exponpow` for `pdf`, `cdf`, `rvs`, and `fit`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f3aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.integrate import quad\n",
    "from scipy.stats import exponpow as exponpow_sp\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "rng = np.random.default_rng(7)\n",
    "\n",
    "TINY = np.finfo(float).tiny\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37b7fd",
   "metadata": {},
   "source": [
    "## 1) Title & classification\n",
    "\n",
    "- **Name**: `exponpow` (SciPy: `scipy.stats.exponpow`)\n",
    "- **Type**: continuous distribution\n",
    "- **Standard support**: $x \\in [0,\\infty)$\n",
    "- **Parameter space (standard)**: shape parameter $b>0$\n",
    "- **SciPy location–scale form**:\n",
    "  - `b > 0` (shape)\n",
    "  - `loc \\in \\mathbb{R}`\n",
    "  - `scale > 0`\n",
    "- **Support with `loc`/`scale`**: $x \\in [\\mathrm{loc},\\infty)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16da6ed6",
   "metadata": {},
   "source": [
    "## 2) Intuition & motivation\n",
    "\n",
    "### What it models\n",
    "`exponpow` is a distribution for a **nonnegative** quantity (think: a time, a positive magnitude, a delay) with an **increasing hazard**.\n",
    "\n",
    "In the standardized form, the **survival function** is\n",
    "$$\n",
    "S(x) = \\mathbb{P}(X>x) = \\exp\\bigl(1-\\exp(x^b)\\bigr),\\qquad x\\ge 0,\n",
    "$$\n",
    "so the **hazard function** is\n",
    "$$\n",
    "h(x) = \\frac{f(x)}{S(x)} = b\\,x^{b-1}\\,\\exp(x^b).\n",
    "$$\n",
    "This grows very quickly for large $x$, which implies an extremely light right tail.\n",
    "\n",
    "### Typical real-world use cases\n",
    "This distribution is less common than Exponential/Gamma/Weibull, but it can be useful when:\n",
    "- you need a **strictly nonnegative** model\n",
    "- the event rate (hazard) should **increase sharply** with time (strong “aging”)\n",
    "- you want a **very light tail** (extremes are *much* rarer than under Weibull/Gamma)\n",
    "\n",
    "### Relations to other distributions (key for intuition)\n",
    "A clean way to understand `exponpow` is via transformations:\n",
    "\n",
    "1) If $X\\sim\\mathrm{exponpow}(b)$ (standard), then\n",
    "$$\n",
    "Y = X^b \\sim \\mathrm{Gompertz}(c=1)\n",
    "\\quad\\text{with density}\\quad\n",
    "f_Y(y)=\\exp\\bigl(1+y-\\exp(y)\\bigr),\\ y\\ge 0.\n",
    "$$\n",
    "\n",
    "2) If $U=\\exp(X^b)-1$, then\n",
    "$$\n",
    "U \\sim \\mathrm{Exp}(1).\n",
    "$$\n",
    "\n",
    "3) Special case: **$b=1$ gives Gompertz**.\n",
    "$$\n",
    "f(x;1) = \\exp\\bigl(1+x-\\exp(x)\\bigr),\\quad x\\ge 0.\n",
    "$$\n",
    "\n",
    "These relationships give an immediate **NumPy-only sampler** and stable formulas for moments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66be2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_exponpow_params(b: float, scale: float = 1.0) -> None:\n",
    "    if not (b > 0):\n",
    "        raise ValueError(\"b must be > 0\")\n",
    "    if not (scale > 0):\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "\n",
    "def exponpow_logpdf(x, b: float, loc: float = 0.0, scale: float = 1.0):\n",
    "    \"\"\"Log-PDF of exponpow in SciPy's (b, loc, scale) parameterization (NumPy-only).\"\"\"\n",
    "    _validate_exponpow_params(float(b), float(scale))\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    z = (x - loc) / scale\n",
    "\n",
    "    out = np.full_like(z, -np.inf, dtype=float)\n",
    "    mask = z >= 0\n",
    "    zz = z[mask]\n",
    "    zb = zz**b\n",
    "\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\", over=\"ignore\", under=\"ignore\"):\n",
    "        if b == 1.0:\n",
    "            logz_term = 0.0\n",
    "        else:\n",
    "            logz_term = (b - 1.0) * np.log(zz)\n",
    "        logpdf = 1.0 + np.log(b) + logz_term + zb - np.exp(zb) - np.log(scale)\n",
    "\n",
    "    out[mask] = logpdf\n",
    "    return out\n",
    "\n",
    "\n",
    "def exponpow_pdf(x, b: float, loc: float = 0.0, scale: float = 1.0):\n",
    "    \"\"\"PDF of exponpow in SciPy's (b, loc, scale) parameterization (NumPy-only).\"\"\"\n",
    "    return np.exp(exponpow_logpdf(x, b=b, loc=loc, scale=scale))\n",
    "\n",
    "\n",
    "def exponpow_cdf(x, b: float, loc: float = 0.0, scale: float = 1.0):\n",
    "    \"\"\"CDF of exponpow in SciPy's (b, loc, scale) parameterization (NumPy-only).\"\"\"\n",
    "    _validate_exponpow_params(float(b), float(scale))\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    z = (x - loc) / scale\n",
    "\n",
    "    out = np.zeros_like(z, dtype=float)\n",
    "    mask = z >= 0\n",
    "    zz = z[mask]\n",
    "\n",
    "    with np.errstate(over=\"ignore\", under=\"ignore\", invalid=\"ignore\"):\n",
    "        out[mask] = -np.expm1(-np.expm1(zz**b))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def exponpow_ppf(q, b: float, loc: float = 0.0, scale: float = 1.0):\n",
    "    \"\"\"Inverse CDF (PPF) for q in [0, 1] (NumPy-only).\"\"\"\n",
    "    _validate_exponpow_params(float(b), float(scale))\n",
    "    q = np.asarray(q, dtype=float)\n",
    "    if np.any((q < 0) | (q > 1)):\n",
    "        raise ValueError(\"q must be in [0, 1]\")\n",
    "\n",
    "    z = np.empty_like(q, dtype=float)\n",
    "    z[q == 1.0] = np.inf\n",
    "    inner = q < 1.0\n",
    "\n",
    "    # Stable form: log(1 - log(1-q)) implemented as log1p(-log1p(-q)).\n",
    "    z[inner] = np.power(np.log1p(-np.log1p(-q[inner])), 1.0 / b)\n",
    "\n",
    "    return loc + scale * z\n",
    "\n",
    "\n",
    "def sample_exponpow(size: int, b: float, loc: float = 0.0, scale: float = 1.0, rng=None):\n",
    "    \"\"\"Sample from exponpow(b, loc, scale) using a NumPy-only transform.\"\"\"\n",
    "    _validate_exponpow_params(float(b), float(scale))\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    u = rng.random(size)\n",
    "    e = -np.log1p(-u)         # Exp(1)\n",
    "    y = np.log1p(e)           # Gompertz(c=1)\n",
    "    z = y ** (1.0 / b)        # exponpow(b)\n",
    "    return loc + scale * z\n",
    "\n",
    "\n",
    "def exponpow_raw_moment(k: int, b: float) -> float:\n",
    "    \"\"\"Raw moment E[X^k] for standard exponpow(b), using the Exp-transform integral.\"\"\"\n",
    "    _validate_exponpow_params(float(b), 1.0)\n",
    "    if k < 0:\n",
    "        raise ValueError(\"k must be >= 0\")\n",
    "    if k == 0:\n",
    "        return 1.0\n",
    "\n",
    "    power = k / b\n",
    "\n",
    "    def integrand(u):\n",
    "        return np.power(np.log1p(u), power) * np.exp(-u)\n",
    "\n",
    "    val, _ = quad(integrand, 0.0, np.inf, epsabs=1e-12, epsrel=1e-10, limit=200)\n",
    "    return float(val)\n",
    "\n",
    "\n",
    "def exponpow_mgf(t: float, b: float) -> float:\n",
    "    \"\"\"MGF M(t)=E[e^{tX}] for standard exponpow(b), computed by quadrature.\"\"\"\n",
    "    _validate_exponpow_params(float(b), 1.0)\n",
    "\n",
    "    def integrand(u):\n",
    "        x = np.power(np.log1p(u), 1.0 / b)\n",
    "        return np.exp(t * x - u)\n",
    "\n",
    "    val, _ = quad(integrand, 0.0, np.inf, epsabs=1e-12, epsrel=1e-10, limit=200)\n",
    "    return float(val)\n",
    "\n",
    "\n",
    "def exponpow_cf(omega: float, b: float) -> complex:\n",
    "    \"\"\"Characteristic function φ(ω)=E[e^{iωX}] for standard exponpow(b), by quadrature.\"\"\"\n",
    "    _validate_exponpow_params(float(b), 1.0)\n",
    "\n",
    "    def integrand_re(u):\n",
    "        x = np.power(np.log1p(u), 1.0 / b)\n",
    "        return np.cos(omega * x) * np.exp(-u)\n",
    "\n",
    "    def integrand_im(u):\n",
    "        x = np.power(np.log1p(u), 1.0 / b)\n",
    "        return np.sin(omega * x) * np.exp(-u)\n",
    "\n",
    "    re, _ = quad(integrand_re, 0.0, np.inf, epsabs=1e-12, epsrel=1e-10, limit=200)\n",
    "    im, _ = quad(integrand_im, 0.0, np.inf, epsabs=1e-12, epsrel=1e-10, limit=200)\n",
    "    return complex(re, im)\n",
    "\n",
    "\n",
    "def exponpow_entropy(b: float) -> float:\n",
    "    \"\"\"Differential entropy of standard exponpow(b), computed by quadrature.\"\"\"\n",
    "    _validate_exponpow_params(float(b), 1.0)\n",
    "\n",
    "    def integrand(u):\n",
    "        x = np.power(np.log1p(u), 1.0 / b)\n",
    "        if b == 1.0:\n",
    "            logpdf = np.log(b) + np.log1p(u) - u\n",
    "        else:\n",
    "            logpdf = np.log(b) + (b - 1.0) * np.log(x) + np.log1p(u) - u\n",
    "        return -logpdf * np.exp(-u)\n",
    "\n",
    "    h, _ = quad(integrand, 0.0, np.inf, epsabs=1e-12, epsrel=1e-10, limit=200)\n",
    "    return float(h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c3f41",
   "metadata": {},
   "source": [
    "## 3) Formal definition\n",
    "\n",
    "### Standard form\n",
    "Support: $x\\ge 0$, shape parameter $b>0$.\n",
    "\n",
    "**PDF**\n",
    "$$\n",
    "f(x;b) = b\\,x^{b-1}\\,\\exp\\bigl(1 + x^b - \\exp(x^b)\\bigr),\\qquad x\\ge 0.\n",
    "$$\n",
    "\n",
    "**CDF**\n",
    "$$\n",
    "F(x;b)=\\begin{cases}\n",
    "0, & x<0,\\\\\n",
    "1-\\exp\\bigl(-(\\exp(x^b)-1)\\bigr) = 1-\\exp\\bigl(1-\\exp(x^b)\\bigr), & x\\ge 0.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Survival**\n",
    "$$\n",
    "S(x;b)=\\exp\\bigl(1-\\exp(x^b)\\bigr),\\qquad x\\ge 0.\n",
    "$$\n",
    "\n",
    "**Inverse CDF (PPF)** for $q\\in(0,1)$:\n",
    "$$\n",
    "F^{-1}(q;b) = \\Bigl[\\log\\bigl(1-\\log(1-q)\\bigr)\\Bigr]^{1/b}.\n",
    "$$\n",
    "\n",
    "### Location–scale form (SciPy)\n",
    "If $Y\\sim\\mathrm{exponpow}(b)$ in standard form and $X = \\mathrm{loc}+\\mathrm{scale}\\,Y$ with $\\mathrm{scale}>0$, then\n",
    "$$\n",
    "f_X(x;b,\\mathrm{loc},\\mathrm{scale}) = \\frac{1}{\\mathrm{scale}}\\, f_Y\\!\\left(\\frac{x-\\mathrm{loc}}{\\mathrm{scale}};b\\right),\n",
    "\\qquad\n",
    "F_X(x;b,\\mathrm{loc},\\mathrm{scale}) = F_Y\\!\\left(\\frac{x-\\mathrm{loc}}{\\mathrm{scale}};b\\right),\n",
    "$$\n",
    "with support $x\\ge \\mathrm{loc}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5861e3",
   "metadata": {},
   "source": [
    "## 4) Moments & properties\n",
    "\n",
    "### Existence of moments\n",
    "The right tail behaves like $\\exp(-\\exp(x^b))$, so it is **super-light**: all positive moments exist, and the MGF exists for all real $t$.\n",
    "\n",
    "Near $0$, the PDF behaves like $f(x;b)\\approx b\\,x^{b-1}$, so the density:\n",
    "- **diverges** at 0 if $0<b<1$\n",
    "- is **finite** at 0 if $b=1$\n",
    "- is **0** at 0 if $b>1$\n",
    "\n",
    "### A very useful transform (turns everything into an Exp integral)\n",
    "Let\n",
    "$$\n",
    "U = \\exp(X^b)-1.\n",
    "$$\n",
    "Then one can show $U\\sim\\mathrm{Exp}(1)$ and\n",
    "$$\n",
    "X = \\bigl(\\log(1+U)\\bigr)^{1/b}.\n",
    "$$\n",
    "\n",
    "This gives raw moments (for integer $k\\ge 0$):\n",
    "$$\n",
    "\\mathbb{E}[X^k] = \\int_{0}^{\\infty} \\bigl(\\log(1+u)\\bigr)^{k/b}\\,e^{-u}\\,du.\n",
    "$$\n",
    "\n",
    "From raw moments $m_k=\\mathbb{E}[X^k]$:\n",
    "- mean $\\mu=m_1$\n",
    "- variance $\\sigma^2=m_2-m_1^2$\n",
    "- skewness $\\gamma_1 = \\mu_3/\\sigma^3$ where $\\mu_3=m_3-3m_2m_1+2m_1^3$\n",
    "- excess kurtosis $\\gamma_2 = \\mu_4/\\sigma^4 - 3$ where $\\mu_4=m_4-4m_3m_1+6m_2m_1^2-3m_1^4$\n",
    "\n",
    "### MGF / characteristic function\n",
    "Using the same transform,\n",
    "$$\n",
    "M(t)=\\mathbb{E}[e^{tX}] = \\int_{0}^{\\infty} \\exp\\Bigl(t\\,\\bigl(\\log(1+u)\\bigr)^{1/b}\\Bigr)\\,e^{-u}\\,du,\n",
    "$$\n",
    "which is finite for all real $t$.\n",
    "\n",
    "The characteristic function is\n",
    "$$\n",
    "\\varphi(\\omega)=\\mathbb{E}[e^{i\\omega X}] = \\int_{0}^{\\infty} \\exp\\Bigl(i\\omega\\,\\bigl(\\log(1+u)\\bigr)^{1/b}\\Bigr)\\,e^{-u}\\,du.\n",
    "$$\n",
    "\n",
    "### Entropy\n",
    "The differential entropy is\n",
    "$$\n",
    "h(X) = -\\int_0^{\\infty} f(x)\\,\\log f(x)\\,dx,\n",
    "$$\n",
    "which can be evaluated stably via the same $U\\sim\\mathrm{Exp}(1)$ transform:\n",
    "$$\n",
    "h(X) = -\\int_0^{\\infty} \\log f\\bigl((\\log(1+u))^{1/b}\\bigr)\\,e^{-u}\\,du.\n",
    "$$\n",
    "\n",
    "For the location–scale family, entropy shifts by $\\log(\\mathrm{scale})$:\n",
    "$$\n",
    "h(\\mathrm{loc}+\\mathrm{scale}\\,Y) = h(Y) + \\log(\\mathrm{scale}).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f9a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical moments/properties for one shape value, and cross-check against SciPy\n",
    "b0 = 2.0\n",
    "\n",
    "m1 = exponpow_raw_moment(1, b0)\n",
    "m2 = exponpow_raw_moment(2, b0)\n",
    "m3 = exponpow_raw_moment(3, b0)\n",
    "m4 = exponpow_raw_moment(4, b0)\n",
    "\n",
    "var = m2 - m1**2\n",
    "mu3 = m3 - 3 * m2 * m1 + 2 * m1**3\n",
    "mu4 = m4 - 4 * m3 * m1 + 6 * m2 * m1**2 - 3 * m1**4\n",
    "\n",
    "skew = mu3 / (var ** 1.5)\n",
    "kurt_excess = mu4 / (var**2) - 3\n",
    "\n",
    "entropy_num = exponpow_entropy(b0)\n",
    "\n",
    "mean_s, var_s, skew_s, kurt_excess_s = exponpow_sp.stats(b0, moments=\"mvsk\")\n",
    "entropy_s = exponpow_sp.entropy(b0)\n",
    "\n",
    "print(f\"b = {b0}\")\n",
    "print(\"mean (quad)     :\", m1)\n",
    "print(\"mean (SciPy)    :\", float(mean_s))\n",
    "print(\"var  (quad)     :\", var)\n",
    "print(\"var  (SciPy)    :\", float(var_s))\n",
    "print(\"skew (quad)     :\", skew)\n",
    "print(\"skew (SciPy)    :\", float(skew_s))\n",
    "print(\"kurt excess (quad) :\", kurt_excess)\n",
    "print(\"kurt excess (SciPy):\", float(kurt_excess_s))\n",
    "print(\"entropy (quad)  :\", entropy_num)\n",
    "print(\"entropy (SciPy) :\", float(entropy_s))\n",
    "\n",
    "# MGF/CF checks (quadrature vs Monte Carlo)\n",
    "t1, t2 = 1.0, -1.0\n",
    "mgf_t1 = exponpow_mgf(t1, b0)\n",
    "mgf_t2 = exponpow_mgf(t2, b0)\n",
    "cf_w1 = exponpow_cf(1.0, b0)\n",
    "\n",
    "n_mc = 200_000\n",
    "x_mc = sample_exponpow(n_mc, b=b0, rng=rng)\n",
    "mgf_mc_t1 = float(np.mean(np.exp(t1 * x_mc)))\n",
    "mgf_mc_t2 = float(np.mean(np.exp(t2 * x_mc)))\n",
    "cf_mc_w1 = complex(np.mean(np.exp(1j * 1.0 * x_mc)))\n",
    "\n",
    "print(\"\\nMGF/CF sanity checks\")\n",
    "print(\"M(1)  quad / MC:\", mgf_t1, mgf_mc_t1)\n",
    "print(\"M(-1) quad / MC:\", mgf_t2, mgf_mc_t2)\n",
    "print(\"phi(1) quad / MC:\", cf_w1, cf_mc_w1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d6503c",
   "metadata": {},
   "source": [
    "## 5) Parameter interpretation\n",
    "\n",
    "### Shape parameter $b$\n",
    "A very interpretable view is:\n",
    "$$\n",
    "X = Y^{1/b},\\qquad Y\\sim\\mathrm{Gompertz}(c=1).\n",
    "$$\n",
    "\n",
    "So $b$ simply controls a **power transform** of a fixed base distribution.\n",
    "\n",
    "- If **$b>1$**, then $1/b<1$ and you take a root: values are pulled toward 1, and the distribution becomes more concentrated.\n",
    "- If **$b=1$**, you get the base Gompertz distribution.\n",
    "- If **$0<b<1$**, then $1/b>1$ and you take a power: small values shrink further toward 0 and large values expand, increasing spread.\n",
    "\n",
    "Near $0$, $f(x;b)\\approx b x^{b-1}$, so $b$ also controls whether the density is spiky at 0.\n",
    "\n",
    "### `loc` and `scale`\n",
    "SciPy uses the standard location–scale family:\n",
    "$$\n",
    "X = \\mathrm{loc} + \\mathrm{scale}\\,Y,\\qquad Y\\sim\\mathrm{exponpow}(b),\\ \\mathrm{scale}>0.\n",
    "$$\n",
    "- `loc` shifts the distribution to start at `loc`.\n",
    "- `scale` stretches the $x$-axis and rescales the density height by $1/\\mathrm{scale}`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape changes as b varies (standardized distribution)\n",
    "bs = [0.5, 1.0, 2.0, 5.0]\n",
    "x_max = float(exponpow_ppf(0.999, b=min(bs)))\n",
    "x = np.linspace(0.0, x_max, 900)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=[\"PDF\", \"CDF\"])\n",
    "for b in bs:\n",
    "    fig.add_trace(go.Scatter(x=x, y=exponpow_pdf(x, b=b), mode=\"lines\", name=f\"b={b}\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=x, y=exponpow_cdf(x, b=b), mode=\"lines\", showlegend=False), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"density\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"probability\", row=1, col=2)\n",
    "fig.update_layout(width=1050, height=380, legend_title_text=\"shape\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3ce8ff",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### Expectation (and all raw moments)\n",
    "Start from the definition:\n",
    "$$\n",
    "\\mathbb{E}[X^k] = \\int_0^{\\infty} x^k\\,f(x;b)\\,dx.\n",
    "$$\n",
    "Use the substitution\n",
    "$$\n",
    "u = \\exp(x^b)-1\\quad\\Rightarrow\\quad du = b\\,x^{b-1}\\,\\exp(x^b)\\,dx.\n",
    "$$\n",
    "Now rewrite the density:\n",
    "$$\n",
    "f(x;b) = b\\,x^{b-1}\\,\\exp(x^b)\\,\\exp\\bigl(1-\\exp(x^b)\\bigr)\n",
    "       = du\\,\\exp\\bigl(-(\\exp(x^b)-1)\\bigr)\n",
    "       = e^{-u}\\,du.\n",
    "$$\n",
    "Also $x^b=\\log(1+u)$, so $x=(\\log(1+u))^{1/b}$. Therefore:\n",
    "$$\n",
    "\\mathbb{E}[X^k] = \\int_0^{\\infty} \\bigl(\\log(1+u)\\bigr)^{k/b}\\,e^{-u}\\,du.\n",
    "$$\n",
    "\n",
    "### Variance\n",
    "Compute $m_1=\\mathbb{E}[X]$ and $m_2=\\mathbb{E}[X^2]$ using the integral above, then\n",
    "$$\n",
    "\\mathrm{Var}(X) = m_2 - m_1^2.\n",
    "$$\n",
    "\n",
    "### Likelihood (i.i.d. sample)\n",
    "Let $x_1,\\dots,x_n$ be i.i.d. observations and define $z_i=(x_i-\\mathrm{loc})/\\mathrm{scale}$.\n",
    "\n",
    "The log-likelihood for parameters $(b,\\mathrm{loc},\\mathrm{scale})$ with $b>0$ and $\\mathrm{scale}>0$ is\n",
    "$$\n",
    "\\ell(b,\\mathrm{loc},\\mathrm{scale})\n",
    "= \\sum_{i=1}^n \\log f_X(x_i)\n",
    "= n\\,(1+\\log b-\\log\\mathrm{scale})\n",
    "  + (b-1)\\sum_{i=1}^n \\log z_i\n",
    "  + \\sum_{i=1}^n z_i^b\n",
    "  - \\sum_{i=1}^n \\exp(z_i^b),\n",
    "$$\n",
    "with the **support constraint** $z_i\\ge 0$ for all $i$ (otherwise the likelihood is 0).\n",
    "\n",
    "Because of the $\\exp(z_i^b)$ term, maximizing this likelihood typically requires numerical optimization and careful handling of overflow/underflow (use `logpdf`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b5945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick numerical sanity check: integrate PDF over a high-quantile range\n",
    "b_check = 2.0\n",
    "q = 0.999999\n",
    "x_max = float(exponpow_ppf(q, b=b_check))\n",
    "x = np.linspace(0.0, x_max, 500_000)\n",
    "pdf = exponpow_pdf(x, b=b_check)\n",
    "\n",
    "mass = float(np.trapz(pdf, x))\n",
    "mean_trunc = float(np.trapz(x * pdf, x))\n",
    "var_trunc = float(np.trapz((x - mean_trunc) ** 2 * pdf, x))\n",
    "\n",
    "print(\"target mass ~\", q)\n",
    "print(\"mass (trapezoid)\", mass)\n",
    "print(\"mean (trunc)    \", mean_trunc)\n",
    "print(\"var  (trunc)    \", var_trunc)\n",
    "print(\"mean (quad)     \", exponpow_raw_moment(1, b_check))\n",
    "print(\"var  (quad)     \", exponpow_raw_moment(2, b_check) - exponpow_raw_moment(1, b_check) ** 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b38ce8",
   "metadata": {},
   "source": [
    "## 7) Sampling & simulation (NumPy-only)\n",
    "\n",
    "### Algorithm (inverse transform via an exponential)\n",
    "Use the transform $U=\\exp(X^b)-1$.\n",
    "\n",
    "1) Sample $U\\sim\\mathrm{Exp}(1)$ using a uniform $V\\sim\\mathrm{Uniform}(0,1)$:\n",
    "$$\n",
    "U = -\\log(1-V).\n",
    "$$\n",
    "2) Set $Y=\\log(1+U)$ (then $Y\\sim\\mathrm{Gompertz}(1)$).\n",
    "\n",
    "3) Return $X=Y^{1/b}$.\n",
    "\n",
    "This is equivalent to using the analytic PPF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b58c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 120_000\n",
    "b_samp = 2.0\n",
    "x = sample_exponpow(n, b=b_samp, rng=rng)\n",
    "\n",
    "# Transform check: U = exp(X^b) - 1 should be Exp(1)\n",
    "u = np.expm1(x**b_samp)\n",
    "print(\"X mean ~\", x.mean())\n",
    "print(\"X var  ~\", x.var())\n",
    "print(\"U mean ~\", u.mean(), \"(Exp(1) mean is 1)\")\n",
    "print(\"U var  ~\", u.var(), \"(Exp(1) var is 1)\")\n",
    "\n",
    "# Equivalence check: PPF matches the Exp-transform when driven by the same Uniform(0,1)\n",
    "q = rng.random(n)\n",
    "x_ppf = exponpow_ppf(q, b=b_samp)\n",
    "e = -np.log1p(-q)\n",
    "x_transform = np.power(np.log1p(e), 1.0 / b_samp)\n",
    "print(\"max |ppf - transform|:\", float(np.max(np.abs(x_ppf - x_transform))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b00c407",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "Below are:\n",
    "- the analytic PDF and CDF (NumPy-only implementations)\n",
    "- a Monte Carlo histogram overlaid with the PDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f21b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_vis = 2.0\n",
    "x_max = float(exponpow_ppf(0.999, b=b_vis))\n",
    "x_grid = np.linspace(0.0, x_max, 900)\n",
    "\n",
    "pdf_grid = exponpow_pdf(x_grid, b=b_vis)\n",
    "cdf_grid = exponpow_cdf(x_grid, b=b_vis)\n",
    "\n",
    "samples = sample_exponpow(80_000, b=b_vis, rng=rng)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=3, subplot_titles=[\"PDF\", \"CDF\", \"Samples (hist) + PDF\"])\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x_grid, y=pdf_grid, mode=\"lines\", name=\"pdf\"), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=x_grid, y=cdf_grid, mode=\"lines\", name=\"cdf\"), row=1, col=2)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=samples, nbinsx=70, histnorm=\"probability density\", name=\"samples\", opacity=0.6),\n",
    "    row=1,\n",
    "    col=3,\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=x_grid, y=pdf_grid, mode=\"lines\", name=\"pdf\"), row=1, col=3)\n",
    "\n",
    "for c in [1, 2, 3]:\n",
    "    fig.update_xaxes(title_text=\"x\", row=1, col=c)\n",
    "fig.update_yaxes(title_text=\"density\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"probability\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"density\", row=1, col=3)\n",
    "\n",
    "fig.update_layout(width=1100, height=380, showlegend=False)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d862b7",
   "metadata": {},
   "source": [
    "## 9) SciPy integration (`scipy.stats.exponpow`)\n",
    "\n",
    "`scipy.stats.exponpow` exposes the standardized distribution with a shape parameter `b`, plus `loc` and `scale`.\n",
    "\n",
    "Common methods:\n",
    "- `exponpow_sp.pdf(x, b, loc=..., scale=...)`\n",
    "- `exponpow_sp.cdf(x, b, loc=..., scale=...)`\n",
    "- `exponpow_sp.rvs(b, loc=..., scale=..., size=..., random_state=...)`\n",
    "- `exponpow_sp.fit(data)` → estimates `(b, loc, scale)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match our NumPy-only PDF/CDF to SciPy (standard case)\n",
    "x = np.linspace(0.0, 2.0, 11)\n",
    "b = 2.0\n",
    "\n",
    "pdf_diff = np.max(np.abs(exponpow_pdf(x, b=b) - exponpow_sp.pdf(x, b)))\n",
    "cdf_diff = np.max(np.abs(exponpow_cdf(x, b=b) - exponpow_sp.cdf(x, b)))\n",
    "\n",
    "print(\"max |pdf - scipy|:\", float(pdf_diff))\n",
    "print(\"max |cdf - scipy|:\", float(cdf_diff))\n",
    "\n",
    "# Demonstrate rvs + fit on location-scale data\n",
    "b_true, loc_true, scale_true = 2.3, -0.4, 1.7\n",
    "data = exponpow_sp.rvs(b_true, loc=loc_true, scale=scale_true, size=2500, random_state=rng)\n",
    "\n",
    "b_hat, loc_hat, scale_hat = exponpow_sp.fit(data)\n",
    "\n",
    "print(\"\\ntrue (b, loc, scale):\", (b_true, loc_true, scale_true))\n",
    "print(\"fit  (b, loc, scale):\", (b_hat, loc_hat, scale_hat))\n",
    "\n",
    "# Visualize fitted vs true PDF\n",
    "x_grid = np.linspace(np.min(data), np.quantile(data, 0.999), 700)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=data, nbinsx=70, histnorm=\"probability density\", name=\"data\", opacity=0.55))\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x_grid, y=exponpow_sp.pdf(x_grid, b_true, loc=loc_true, scale=scale_true), mode=\"lines\", name=\"true pdf\")\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x_grid, y=exponpow_sp.pdf(x_grid, b_hat, loc=loc_hat, scale=scale_hat), mode=\"lines\", name=\"fit pdf\")\n",
    ")\n",
    "fig.update_layout(width=950, height=420, title=\"SciPy fit: true vs fitted PDF\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9c28d",
   "metadata": {},
   "source": [
    "## 10) Statistical use cases\n",
    "\n",
    "### Hypothesis testing\n",
    "A typical question is goodness-of-fit: *does an `exponpow` model plausibly generate this data?*\n",
    "\n",
    "A common test statistic is the Kolmogorov–Smirnov (KS) distance. If you estimate parameters from the data (via `fit`) and then run a vanilla KS test, the p-value is not exact.\n",
    "\n",
    "A practical workaround is a **parametric bootstrap** that repeats the fitting step on simulated data.\n",
    "\n",
    "### Bayesian modeling\n",
    "`exponpow` can be used as a likelihood/prior over nonnegative quantities. Because it has a single shape parameter $b$, it is convenient to demonstrate a 1D grid posterior.\n",
    "\n",
    "### Generative modeling\n",
    "In simulation pipelines, `exponpow` provides a flexible way to generate nonnegative magnitudes with a controllable spike at 0 (via $b$) and a very light tail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c4b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Hypothesis testing: parametric bootstrap KS for fitted exponpow\n",
    "\n",
    "def ks_statistic_to_fitted_exponpow(sample):\n",
    "    b_hat, loc_hat, scale_hat = exponpow_sp.fit(sample)\n",
    "    fitted = exponpow_sp(b_hat, loc=loc_hat, scale=scale_hat)\n",
    "    return stats.kstest(sample, fitted.cdf).statistic\n",
    "\n",
    "\n",
    "n = 350\n",
    "b_true, loc_true, scale_true = 2.0, 0.3, 1.1\n",
    "x_obs = exponpow_sp.rvs(b_true, loc=loc_true, scale=scale_true, size=n, random_state=rng)\n",
    "\n",
    "D_obs = ks_statistic_to_fitted_exponpow(x_obs)\n",
    "\n",
    "B = 250  # keep modest for notebook runtime\n",
    "b_hat, loc_hat, scale_hat = exponpow_sp.fit(x_obs)\n",
    "fitted = exponpow_sp(b_hat, loc=loc_hat, scale=scale_hat)\n",
    "\n",
    "Ds = np.empty(B)\n",
    "for j in range(B):\n",
    "    sim = fitted.rvs(size=n, random_state=rng)\n",
    "    Ds[j] = ks_statistic_to_fitted_exponpow(sim)\n",
    "\n",
    "p_boot = (np.sum(Ds >= D_obs) + 1) / (B + 1)\n",
    "\n",
    "print(\"KS statistic (observed):\", D_obs)\n",
    "print(\"bootstrap p-value      :\", p_boot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a5d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) Bayesian modeling: grid posterior for b (loc/scale assumed known)\n",
    "\n",
    "b_true = 2.0\n",
    "x_obs = sample_exponpow(140, b=b_true, rng=rng)  # standard (loc=0, scale=1)\n",
    "\n",
    "grid = np.linspace(0.25, 6.0, 800)\n",
    "\n",
    "# Log-likelihood under our NumPy-only logpdf\n",
    "loglike = np.array([exponpow_logpdf(x_obs, b=b).sum() for b in grid])\n",
    "\n",
    "# A simple (improper) log-uniform prior: p(b) ∝ 1/b over the grid\n",
    "logprior = -np.log(grid)\n",
    "\n",
    "logpost = loglike + logprior\n",
    "logpost -= logpost.max()  # stabilize\n",
    "post = np.exp(logpost)\n",
    "post /= np.trapz(post, grid)\n",
    "\n",
    "b_map = float(grid[np.argmax(post)])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=grid, y=post, mode=\"lines\", name=\"posterior\"))\n",
    "fig.add_vline(x=b_true, line_dash=\"dash\", line_color=\"black\", annotation_text=\"true b\")\n",
    "fig.add_vline(x=b_map, line_dash=\"dot\", line_color=\"red\", annotation_text=\"MAP\")\n",
    "fig.update_layout(width=950, height=380, title=\"Posterior over b (standard case)\", xaxis_title=\"b\", yaxis_title=\"density\")\n",
    "fig.show()\n",
    "\n",
    "print(\"true b:\", b_true)\n",
    "print(\"MAP b :\", b_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C) Generative modeling: 2D radial noise with exponpow-distributed radius\n",
    "\n",
    "def radial_noise(n: int, b: float, scale: float, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    theta = rng.uniform(0.0, 2 * np.pi, size=n)\n",
    "    r = sample_exponpow(n, b=b, scale=scale, rng=rng)\n",
    "    x = r * np.cos(theta)\n",
    "    y = r * np.sin(theta)\n",
    "    return x, y, r\n",
    "\n",
    "\n",
    "n = 3000\n",
    "scale = 0.35\n",
    "b_small, b_large = 0.5, 5.0\n",
    "\n",
    "x1, y1, r1 = radial_noise(n, b=b_small, scale=scale, rng=rng)\n",
    "x2, y2, r2 = radial_noise(n, b=b_large, scale=scale, rng=rng)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=2,\n",
    "    subplot_titles=[f\"scatter (b={b_small})\", f\"scatter (b={b_large})\", \"radius histogram\", \"\"],\n",
    "    row_heights=[0.7, 0.3],\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x1, y=y1, mode=\"markers\", marker=dict(size=3, opacity=0.45), name=f\"b={b_small}\"),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x2, y=y2, mode=\"markers\", marker=dict(size=3, opacity=0.45), name=f\"b={b_large}\"),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=r1, nbinsx=60, histnorm=\"probability density\", opacity=0.55, name=f\"b={b_small}\"),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=r2, nbinsx=60, histnorm=\"probability density\", opacity=0.55, name=f\"b={b_large}\"),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"y\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"y\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"radius\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"density\", row=2, col=1)\n",
    "\n",
    "fig.update_layout(width=1050, height=750, title=\"Exponpow as a generative prior for nonnegative magnitudes\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64db1f1",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Parameter validity:** `b` must be strictly positive; `scale` must be strictly positive.\n",
    "- **Support:** in the location–scale form, the support is $x\\ge\\mathrm{loc}$. For $x<\\mathrm{loc}$, the PDF is 0 and `logpdf` is $-\\infty$.\n",
    "- **Naming collision:** SciPy’s `exponpow` is not the symmetric generalized-normal “exponential power” distribution.\n",
    "- **Overflow/underflow:** terms like $\\exp(x^b)$ explode quickly; for large $x$ use `logpdf` rather than `pdf`.\n",
    "- **Zeros in data:** if $0<b<1$, the density diverges at 0; exact zeros (from rounding/thresholding) can strongly affect fitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d665c9",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `exponpow` is a **continuous** distribution on $[0,\\infty)$ with a single shape parameter $b$.\n",
    "- The survival function is $S(x)=\\exp(1-\\exp(x^b))$, giving an **extremely light** tail and an **increasing hazard**.\n",
    "- The transform $U=\\exp(X^b)-1$ yields $U\\sim\\mathrm{Exp}(1)$, which provides:\n",
    "  - a clean NumPy-only sampler\n",
    "  - stable integral formulas for moments, MGF/CF, and entropy\n",
    "- SciPy provides `scipy.stats.exponpow` for evaluation, sampling, and fitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}