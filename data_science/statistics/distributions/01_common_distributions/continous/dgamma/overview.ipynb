{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb0d6c3f",
   "metadata": {},
   "source": [
    "# `dgamma` (Double Gamma) Distribution\n",
    "\n",
    "`scipy.stats.dgamma` is the **double gamma** distribution: a symmetric, continuous distribution on $\\mathbb{R}$ whose **absolute value is Gamma**.\n",
    "\n",
    "A convenient generative story is:\n",
    "\n",
    "1) Draw a magnitude $Y \\sim \\mathrm{Gamma}(a, \\text{scale}=1)$ on $[0,\\infty)$.\n",
    "2) Draw a sign $S \\in \\{+1,-1\\}$ with $\\mathbb{P}(S=+1)=\\mathbb{P}(S=-1)=\\tfrac12$.\n",
    "3) Set $X = S\\,Y$.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning goals\n",
    "- Understand what `dgamma` models and how it relates to Gamma and Laplace.\n",
    "- Write down the PDF/CDF in clean LaTeX and connect them to incomplete gamma functions.\n",
    "- Derive mean/variance and the likelihood for the shape parameter.\n",
    "- Implement **NumPy-only** sampling (Marsaglia–Tsang for Gamma + random sign).\n",
    "- Visualize PDF, CDF, and Monte Carlo samples; then use `scipy.stats.dgamma` for `pdf`, `cdf`, `rvs`, and `fit`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4142f4",
   "metadata": {},
   "source": [
    "## Notebook roadmap\n",
    "1) Title & classification\n",
    "2) Intuition & motivation\n",
    "3) Formal definition (PDF/CDF)\n",
    "4) Moments & properties (MGF/CF/entropy)\n",
    "5) Parameter interpretation (shape changes)\n",
    "6) Derivations (mean/variance/likelihood)\n",
    "7) Sampling & simulation (NumPy-only)\n",
    "8) Visualization (PDF/CDF/samples)\n",
    "9) SciPy integration (`scipy.stats.dgamma`)\n",
    "10) Statistical use cases (testing/Bayes/generative)\n",
    "11) Pitfalls\n",
    "12) Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ce4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "import scipy\n",
    "from scipy import special\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.stats import dgamma, kstest, laplace, norm\n",
    "\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "SEED = 7\n",
    "np.random.seed(SEED)\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"scipy\", scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a08d6f",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Comfort with basic probability (PDF/CDF, expectation, variance)\n",
    "- Familiarity with Gamma functions and the idea of *regularized* incomplete gamma functions (we’ll define what we need)\n",
    "- Basic numerical computing with NumPy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce4f5f8",
   "metadata": {},
   "source": [
    "## 1) Title & Classification\n",
    "\n",
    "- **Distribution name**: `dgamma` (double gamma)\n",
    "- **Type**: **continuous**\n",
    "- **Support**: $x \\in \\mathbb{R}$\n",
    "- **Shape parameter**: $a > 0$\n",
    "\n",
    "SciPy uses the common *location-scale* convention:\n",
    "\n",
    "$$\n",
    "X \\sim \\texttt{dgamma}(a, \\text{loc}, \\text{scale})\n",
    "\\quad\\Longleftrightarrow\\quad\n",
    "X = \\text{loc} + \\text{scale}\\cdot Z,\n",
    "\\; Z \\sim \\texttt{dgamma}(a, 0, 1),\\; \\text{scale} > 0.\n",
    "$$\n",
    "\n",
    "In this notebook we focus on the **standard form** ($\\text{loc}=0$, $\\text{scale}=1$) unless otherwise stated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ba9460",
   "metadata": {},
   "source": [
    "## 2) Intuition & Motivation\n",
    "\n",
    "The double gamma distribution is best understood by splitting it into **sign** and **magnitude**:\n",
    "\n",
    "- The **magnitude** $|X|$ follows a Gamma distribution.\n",
    "- The **sign** is a fair coin flip.\n",
    "\n",
    "So `dgamma` is a natural model when:\n",
    "\n",
    "- You want a **symmetric** distribution around 0\n",
    "- With **exponential tails** (like Laplace), but with extra flexibility near $0$\n",
    "\n",
    "### Typical use cases\n",
    "- **Error/noise modeling** when residuals are symmetric but not well captured by a Normal (heavier center and exponential tails).\n",
    "- **Robust modeling**: compared to Gaussian noise, exponential tails reduce the influence of large deviations.\n",
    "- **Bayesian priors / regularization**: `dgamma` generalizes the Laplace prior (the L1/\"lasso\" prior) and can make the prior either more concentrated at 0 ($a<1$) or even **repel** 0 ($a>1$).\n",
    "\n",
    "### Relations to other distributions\n",
    "- If $a=1$, `dgamma` becomes the **Laplace** distribution with scale 1:\n",
    "  $$f(x; a=1) = \\tfrac12 e^{-|x|}.$$ \n",
    "- $|X| \\sim \\mathrm{Gamma}(a, 1)$.\n",
    "- For $a>1$, the distribution becomes **bimodal** with modes near $\\pm(a-1)$ (because the Gamma magnitude has mode at $a-1$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3d7a64",
   "metadata": {},
   "source": [
    "## 3) Formal Definition\n",
    "\n",
    "### 3.1 PDF\n",
    "\n",
    "For shape parameter $a>0$, the standard `dgamma` PDF is\n",
    "\n",
    "$$\n",
    "f(x; a)\n",
    "=\n",
    "\\frac{1}{2\\,\\Gamma(a)}\\,|x|^{a-1} e^{-|x|},\n",
    "\\quad x\\in\\mathbb{R},\\; a>0.\n",
    "$$\n",
    "\n",
    "This is an **even** function ($f(x)=f(-x)$), so the distribution is symmetric around 0.\n",
    "\n",
    "### 3.2 CDF\n",
    "\n",
    "Let $P(a, z)$ denote the *regularized lower incomplete gamma function*\n",
    "\n",
    "$$\n",
    "P(a, z) = \\frac{\\gamma(a, z)}{\\Gamma(a)},\n",
    "\\quad z\\ge 0.\n",
    "$$\n",
    "\n",
    "Then the `dgamma` CDF can be written compactly as\n",
    "\n",
    "$$\n",
    "F(x; a)\n",
    "=\n",
    "\\frac12\\Big(1 + \\operatorname{sign}(x)\\,P(a, |x|)\\Big),\n",
    "$$\n",
    "\n",
    "with $\\operatorname{sign}(0)=0$ so $F(0)=\\tfrac12$.\n",
    "\n",
    "Equivalently (piecewise):\n",
    "\n",
    "$$\n",
    "F(x;a)=\\begin{cases}\n",
    "\\tfrac12\\big(1 - P(a,|x|)\\big), & x<0,\\\\\n",
    "\\tfrac12, & x=0,\\\\\n",
    "\\tfrac12\\big(1 + P(a,x)\\big), & x>0.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "SciPy implements $P(a,z)$ as `scipy.special.gammainc(a, z)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77446d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgamma_logpdf_standard(x: np.ndarray, a: float) -> np.ndarray:\n",
    "    \"\"\"Log-PDF of standard dgamma(a) with loc=0, scale=1.\n",
    "\n",
    "    This is implemented explicitly (rather than calling SciPy) to make the\n",
    "    formula transparent and to highlight the behavior at x=0.\n",
    "    \"\"\"\n",
    "    if not (a > 0):\n",
    "        raise ValueError(\"a must be > 0\")\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    ax = np.abs(x)\n",
    "    out = np.empty_like(ax)\n",
    "\n",
    "    log_norm = -math.log(2.0) - special.gammaln(a)\n",
    "\n",
    "    pos = ax > 0\n",
    "    out[pos] = (a - 1.0) * np.log(ax[pos]) - ax[pos] + log_norm\n",
    "\n",
    "    # Handle x=0 explicitly to avoid the indeterminate 0 * log(0) when a=1.\n",
    "    zero = ~pos\n",
    "    if np.any(zero):\n",
    "        if a < 1:\n",
    "            out[zero] = np.inf\n",
    "        elif a == 1:\n",
    "            out[zero] = -math.log(2.0)\n",
    "        else:\n",
    "            out[zero] = -np.inf\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def dgamma_pdf_standard(x: np.ndarray, a: float) -> np.ndarray:\n",
    "    return np.exp(dgamma_logpdf_standard(x, a))\n",
    "\n",
    "\n",
    "def dgamma_cdf_standard(x: np.ndarray, a: float) -> np.ndarray:\n",
    "    if not (a > 0):\n",
    "        raise ValueError(\"a must be > 0\")\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    P = special.gammainc(a, np.abs(x))  # regularized lower incomplete gamma\n",
    "    return 0.5 * (1.0 + np.sign(x) * P)\n",
    "\n",
    "\n",
    "# Quick consistency check against SciPy\n",
    "xs = np.array([-2.0, -0.5, 0.0, 0.5, 2.0])\n",
    "a0 = 2.0\n",
    "print(\"pdf max abs diff:\", np.max(np.abs(dgamma_pdf_standard(xs, a0) - dgamma.pdf(xs, a0))))\n",
    "print(\"cdf max abs diff:\", np.max(np.abs(dgamma_cdf_standard(xs, a0) - dgamma.cdf(xs, a0))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b398db2",
   "metadata": {},
   "source": [
    "## 4) Moments & Properties\n",
    "\n",
    "Because `dgamma` is symmetric, **all odd moments are 0** (when they exist). Even moments match those of the Gamma magnitude.\n",
    "\n",
    "### 4.1 Mean, variance, skewness, kurtosis\n",
    "- **Mean**: $\\mathbb{E}[X]=0$.\n",
    "- **Variance**:\n",
    "  $$\\mathrm{Var}(X)=\\mathbb{E}[X^2]=\\frac{\\Gamma(a+2)}{\\Gamma(a)} = a(a+1).$$\n",
    "- **Skewness**: $0$.\n",
    "- **Kurtosis** (non-excess):\n",
    "  $$\\kappa = \\frac{\\mathbb{E}[X^4]}{\\mathrm{Var}(X)^2} = \\frac{\\Gamma(a+4)/\\Gamma(a)}{\\big(a(a+1)\\big)^2} = \\frac{(a+2)(a+3)}{a(a+1)}.$$\n",
    "  Excess kurtosis is $\\kappa - 3$.\n",
    "\n",
    "More generally, for $n\\in\\mathbb{N}$:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^{2n}] = \\frac{\\Gamma(a+2n)}{\\Gamma(a)},\n",
    "\\qquad\n",
    "\\mathbb{E}[X^{2n+1}] = 0.\n",
    "$$\n",
    "\n",
    "### 4.2 MGF and characteristic function\n",
    "\n",
    "Using the sign/magnitude representation with $Y\\sim\\mathrm{Gamma}(a,1)$ and $S\\in\\{\\pm1\\}$:\n",
    "\n",
    "$$\n",
    "M_X(t)=\\mathbb{E}[e^{tX}] = \\tfrac12\\,(1-t)^{-a} + \\tfrac12\\,(1+t)^{-a},\n",
    "\\quad |t|<1.\n",
    "$$\n",
    "\n",
    "The characteristic function is\n",
    "\n",
    "$$\n",
    "\\varphi_X(\\omega)=\\mathbb{E}[e^{i\\omega X}] = \\tfrac12\\,(1-i\\omega)^{-a} + \\tfrac12\\,(1+i\\omega)^{-a}.\n",
    "$$\n",
    "\n",
    "### 4.3 Differential entropy\n",
    "\n",
    "The positive and negative halves of the distribution live on essentially disjoint supports, so the entropy decomposes into\n",
    "\n",
    "$$\n",
    "h(X) = h(Y) + \\log 2,\n",
    "$$\n",
    "\n",
    "where $Y\\sim\\mathrm{Gamma}(a,1)$.\n",
    "\n",
    "For $\\mathrm{Gamma}(a, \\text{scale}=1)$, the differential entropy is\n",
    "\n",
    "$$\n",
    "h(Y) = a + \\log\\Gamma(a) + (1-a)\\,\\psi(a),\n",
    "$$\n",
    "\n",
    "with $\\psi$ the digamma function. Therefore\n",
    "\n",
    "$$\n",
    "h(X) = \\log 2 + a + \\log\\Gamma(a) + (1-a)\\,\\psi(a).\n",
    "$$\n",
    "\n",
    "(All entropies here are in **nats**.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a506e8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgamma_even_moment(a: float, k: int) -> float:\n",
    "    \"\"\"E[X^k] for standard dgamma(a). Returns 0 for odd k.\"\"\"\n",
    "    if k % 2 == 1:\n",
    "        return 0.0\n",
    "    return float(math.exp(special.gammaln(a + k) - special.gammaln(a)))\n",
    "\n",
    "\n",
    "def dgamma_theory_summary(a: float) -> dict:\n",
    "    mean = 0.0\n",
    "    var = dgamma_even_moment(a, 2)\n",
    "    m4 = dgamma_even_moment(a, 4)\n",
    "    kurtosis = m4 / (var**2)\n",
    "    excess_kurtosis = kurtosis - 3.0\n",
    "\n",
    "    entropy_nats = math.log(2.0) + a + special.gammaln(a) + (1.0 - a) * special.digamma(a)\n",
    "\n",
    "    return {\n",
    "        \"mean\": mean,\n",
    "        \"variance\": var,\n",
    "        \"skewness\": 0.0,\n",
    "        \"kurtosis\": float(kurtosis),\n",
    "        \"excess_kurtosis\": float(excess_kurtosis),\n",
    "        \"entropy_nats\": float(entropy_nats),\n",
    "    }\n",
    "\n",
    "\n",
    "a_demo = 0.7\n",
    "dgamma_theory_summary(a_demo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed87b2d",
   "metadata": {},
   "source": [
    "## 5) Parameter Interpretation (shape changes)\n",
    "\n",
    "`dgamma` has a single shape parameter $a$ (plus optional `loc` and `scale`). The parameter $a$ primarily controls the **behavior near 0** and whether the distribution is **unimodal vs bimodal**.\n",
    "\n",
    "Start from the log-density for $x>0$:\n",
    "\n",
    "$$\n",
    "\\log f(x;a) = (a-1)\\log x - x - \\log(2\\Gamma(a)).\n",
    "$$\n",
    "\n",
    "Differentiate w.r.t. $x$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial x}\\log f(x;a) = \\frac{a-1}{x} - 1.\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "- If $0<a<1$, the term $x^{a-1}$ diverges at $0$ and the density has an **infinite spike at 0**.\n",
    "- If $a=1$, the density is **Laplace** and is maximized at $0$.\n",
    "- If $a>1$, setting $\\frac{a-1}{x}-1=0$ gives a mode at $x=a-1$ on the positive side, and by symmetry another at $x=-(a-1)$.\n",
    "\n",
    "The **scale** parameter in SciPy simply rescales the distribution: if $X\\sim\\texttt{dgamma}(a,0,1)$, then $\\sigma X\\sim\\texttt{dgamma}(a,0,\\sigma)$ and\n",
    "$$\\mathrm{Var}(\\sigma X)=\\sigma^2 a(a+1).$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1e8f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pdf_family(a_values: list[float], x_max: float = 8.0) -> go.Figure:\n",
    "    xs = np.linspace(-x_max, x_max, 1200)\n",
    "    fig = go.Figure()\n",
    "    for a in a_values:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=xs,\n",
    "                y=dgamma_pdf_standard(xs, a),\n",
    "                mode=\"lines\",\n",
    "                name=f\"a={a}\",\n",
    "            )\n",
    "        )\n",
    "    fig.update_layout(\n",
    "        title=\"dgamma PDF for different shape parameters a\",\n",
    "        xaxis_title=\"x\",\n",
    "        yaxis_title=\"f(x)\",\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "plot_pdf_family([0.4, 1.0, 2.0, 5.0], x_max=10.0).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e09ad37",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### 6.1 Expectation\n",
    "\n",
    "Because $f(x;a)$ is **even** and $x$ is **odd**, the integrand $x f(x;a)$ is odd. Therefore:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty} x f(x;a)\\,dx = 0.\n",
    "$$\n",
    "\n",
    "This symmetry argument is often the quickest way to compute the mean.\n",
    "\n",
    "### 6.2 Variance\n",
    "\n",
    "Since $\\mathbb{E}[X]=0$, we have $\\mathrm{Var}(X)=\\mathbb{E}[X^2]$.\n",
    "\n",
    "Using symmetry:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^2]\n",
    "=\\int_{-\\infty}^{\\infty} x^2 f(x;a)\\,dx\n",
    "=2\\int_{0}^{\\infty} x^2\\,\\frac{1}{2\\Gamma(a)}x^{a-1}e^{-x}\\,dx\n",
    "=\\frac{1}{\\Gamma(a)}\\int_0^{\\infty} x^{a+1}e^{-x}\\,dx.\n",
    "$$\n",
    "\n",
    "But\n",
    "\n",
    "$$\n",
    "\\int_0^{\\infty} x^{a+1}e^{-x}\\,dx = \\Gamma(a+2),\n",
    "$$\n",
    "\n",
    "so\n",
    "\n",
    "$$\n",
    "\\mathrm{Var}(X)=\\frac{\\Gamma(a+2)}{\\Gamma(a)}=a(a+1).\n",
    "$$\n",
    "\n",
    "### 6.3 Likelihood (shape parameter)\n",
    "\n",
    "For i.i.d. samples $x_1,\\dots,x_n$ from the **standard** `dgamma(a)` (loc=0, scale=1), the log-likelihood is\n",
    "\n",
    "$$\n",
    "\\ell(a)\n",
    "=\\sum_{i=1}^n \\log f(x_i;a)\n",
    "=(a-1)\\sum_i \\log|x_i| - \\sum_i |x_i| - n\\log 2 - n\\log\\Gamma(a).\n",
    "$$\n",
    "\n",
    "Differentiate w.r.t. $a$:\n",
    "\n",
    "$$\n",
    "\\ell'(a) = \\sum_{i=1}^n \\log|x_i| - n\\,\\psi(a),\n",
    "$$\n",
    "\n",
    "where $\\psi(a) = \\frac{d}{da}\\log\\Gamma(a)$ is the digamma function.\n",
    "\n",
    "Setting the score to zero gives an MLE condition:\n",
    "\n",
    "$$\n",
    "\\psi(\\hat a) = \\frac{1}{n}\\sum_{i=1}^n \\log|x_i|.\n",
    "$$\n",
    "\n",
    "There is no closed form for $\\hat a$, but we can solve it with Newton’s method using the trigamma function $\\psi_1(a)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5230bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_a_mle_standard(x: np.ndarray, *, a0: float | None = None, max_iter: int = 100, tol: float = 1e-12) -> float:\n",
    "    \"\"\"MLE for shape a in standard dgamma(a) assuming loc=0, scale=1.\n",
    "\n",
    "    Uses the score equation: digamma(a) = mean(log |x|).\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    ax = np.abs(x)\n",
    "    if np.any(ax == 0):\n",
    "        raise ValueError(\"Found exact zeros; log|x| is -inf. Add jitter or model rounding explicitly.\")\n",
    "\n",
    "    target = float(np.mean(np.log(ax)))\n",
    "\n",
    "    # For large a: digamma(a) ~ log(a - 1/2). So a ≈ exp(target) + 1/2.\n",
    "    a = float(a0 if a0 is not None else max(1e-6, math.exp(target) + 0.5))\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        f = float(special.digamma(a) - target)\n",
    "        fp = float(special.polygamma(1, a))  # trigamma\n",
    "        step = f / fp\n",
    "        a_new = a - step\n",
    "        if a_new <= 0:\n",
    "            a_new = a / 2.0\n",
    "        if abs(a_new - a) < tol * max(1.0, abs(a)):\n",
    "            return float(a_new)\n",
    "        a = a_new\n",
    "\n",
    "    return float(a)\n",
    "\n",
    "\n",
    "# Quick sanity check: generate data from SciPy and estimate a\n",
    "a_true = 2.5\n",
    "x_synth = dgamma.rvs(a_true, size=50_000, random_state=rng)\n",
    "a_hat = fit_a_mle_standard(x_synth)\n",
    "a_true, a_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2062784",
   "metadata": {},
   "source": [
    "## 7) Sampling & Simulation (NumPy-only)\n",
    "\n",
    "We want a sampler that uses **only NumPy**.\n",
    "\n",
    "Recall the generative story:\n",
    "\n",
    "- Sample $Y \\sim \\mathrm{Gamma}(a,1)$.\n",
    "- Sample $S \\in \\{\\pm 1\\}$ uniformly.\n",
    "- Return $X = S\\,Y$.\n",
    "\n",
    "So the core problem is sampling from a Gamma distribution.\n",
    "\n",
    "### Marsaglia–Tsang (2000) for Gamma(a,1)\n",
    "\n",
    "For $a \\ge 1$, Marsaglia–Tsang provides an efficient rejection sampler:\n",
    "\n",
    "1) Set $d = a - 1/3$ and $c = 1/\\sqrt{9d}$.\n",
    "2) Repeat:\n",
    "   - draw $Z \\sim \\mathcal{N}(0,1)$ and set $V = (1 + cZ)^3$.\n",
    "   - draw $U \\sim \\mathrm{Uniform}(0,1)$.\n",
    "   - accept if $V>0$ and $\\log U < \\tfrac12 Z^2 + d - dV + d\\log V$.\n",
    "3) Return $dV$.\n",
    "\n",
    "For $0<a<1$, use the standard boost trick:\n",
    "\n",
    "$$\n",
    "Y \\sim \\mathrm{Gamma}(a,1)\n",
    "\\quad\\Longleftarrow\\quad\n",
    "Y = Y'\\,U^{1/a},\\; Y'\\sim\\mathrm{Gamma}(a+1,1),\\; U\\sim\\mathrm{Uniform}(0,1).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c3413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_rvs_mt(shape: float, size: int, *, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Sample Gamma(shape, scale=1) using NumPy only (Marsaglia–Tsang).\n",
    "\n",
    "    References\n",
    "    - Marsaglia, G., & Tsang, W. W. (2000). A Simple Method for Generating Gamma Variables.\n",
    "    \"\"\"\n",
    "    if not (shape > 0):\n",
    "        raise ValueError(\"shape must be > 0\")\n",
    "    if size < 0:\n",
    "        raise ValueError(\"size must be >= 0\")\n",
    "\n",
    "    if size == 0:\n",
    "        return np.array([], dtype=float)\n",
    "\n",
    "    if shape < 1.0:\n",
    "        # Boost: Gamma(a) = Gamma(a+1) * U^{1/a}\n",
    "        y = gamma_rvs_mt(shape + 1.0, size, rng=rng)\n",
    "        u = rng.random(size)\n",
    "        return y * (u ** (1.0 / shape))\n",
    "\n",
    "    d = shape - 1.0 / 3.0\n",
    "    c = 1.0 / math.sqrt(9.0 * d)\n",
    "\n",
    "    out = np.empty(size, dtype=float)\n",
    "    filled = 0\n",
    "    while filled < size:\n",
    "        m = size - filled\n",
    "        z = rng.standard_normal(m)\n",
    "        v = (1.0 + c * z) ** 3\n",
    "        u = rng.random(m)\n",
    "\n",
    "        accept = (v > 0) & (np.log(u) < 0.5 * z * z + d - d * v + d * np.log(v))\n",
    "        n_acc = int(np.sum(accept))\n",
    "        if n_acc:\n",
    "            out[filled : filled + n_acc] = d * v[accept]\n",
    "            filled += n_acc\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def dgamma_rvs_numpy(a: float, size: int, *, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Sample standard dgamma(a) using NumPy only.\"\"\"\n",
    "    y = gamma_rvs_mt(a, size, rng=rng)\n",
    "    s = np.where(rng.random(size) < 0.5, -1.0, 1.0)\n",
    "    return s * y\n",
    "\n",
    "\n",
    "# Monte Carlo check: sample moments vs theory\n",
    "a_mc = 2.0\n",
    "x_mc = dgamma_rvs_numpy(a_mc, 200_000, rng=rng)\n",
    "print(\"sample mean:\", float(np.mean(x_mc)))\n",
    "print(\"sample var :\", float(np.var(x_mc)))\n",
    "print(\"theory var :\", dgamma_theory_summary(a_mc)[\"variance\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a8d62f",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We’ll visualize:\n",
    "- The **PDF** for different $a$\n",
    "- The **CDF**\n",
    "- A **Monte Carlo histogram** vs the theoretical PDF\n",
    "- An **empirical CDF** vs the theoretical CDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d9083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cdf_family(a_values: list[float], x_max: float = 8.0) -> go.Figure:\n",
    "    xs = np.linspace(-x_max, x_max, 1200)\n",
    "    fig = go.Figure()\n",
    "    for a in a_values:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=xs,\n",
    "                y=dgamma_cdf_standard(xs, a),\n",
    "                mode=\"lines\",\n",
    "                name=f\"a={a}\",\n",
    "            )\n",
    "        )\n",
    "    fig.update_layout(\n",
    "        title=\"dgamma CDF for different shape parameters a\",\n",
    "        xaxis_title=\"x\",\n",
    "        yaxis_title=\"F(x)\",\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "plot_cdf_family([0.4, 1.0, 2.0, 5.0], x_max=10.0).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b60c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_vis = 0.7\n",
    "n_vis = 80_000\n",
    "x_vis = dgamma_rvs_numpy(a_vis, n_vis, rng=rng)\n",
    "\n",
    "x_max = np.quantile(np.abs(x_vis), 0.995)\n",
    "xs = np.linspace(-x_max, x_max, 900)\n",
    "\n",
    "fig = px.histogram(\n",
    "    x=x_vis,\n",
    "    nbins=120,\n",
    "    histnorm=\"probability density\",\n",
    "    title=f\"Monte Carlo histogram vs theoretical PDF (a={a_vis})\",\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=xs, y=dgamma_pdf_standard(xs, a_vis), mode=\"lines\", name=\"theory pdf\"))\n",
    "fig.update_layout(xaxis_title=\"x\", yaxis_title=\"density\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed51be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_cdf(samples: np.ndarray):\n",
    "    xs = np.sort(samples)\n",
    "    ys = np.arange(1, xs.size + 1) / xs.size\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "x_ecdf, y_ecdf = empirical_cdf(x_vis)\n",
    "grid = np.linspace(-x_max, x_max, 800)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x_ecdf[::50], y=y_ecdf[::50], mode=\"markers\", name=\"empirical CDF\"))\n",
    "fig.add_trace(go.Scatter(x=grid, y=dgamma_cdf_standard(grid, a_vis), mode=\"lines\", name=\"theory CDF\"))\n",
    "fig.update_layout(title=f\"Empirical CDF vs theoretical CDF (a={a_vis})\", xaxis_title=\"x\", yaxis_title=\"F(x)\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7332f7",
   "metadata": {},
   "source": [
    "## 9) SciPy Integration (`scipy.stats.dgamma`)\n",
    "\n",
    "SciPy provides a full `rv_continuous` implementation:\n",
    "\n",
    "- `dgamma.pdf(x, a, loc=0, scale=1)`\n",
    "- `dgamma.cdf(x, a, loc=0, scale=1)`\n",
    "- `dgamma.rvs(a, loc=0, scale=1, size=..., random_state=...)`\n",
    "- `dgamma.fit(data)` (maximum likelihood for `a`, `loc`, `scale`)\n",
    "\n",
    "Below we show how to use these and compare to our NumPy-only sampler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f0fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_true = 2.0\n",
    "loc_true = -0.5\n",
    "scale_true = 1.8\n",
    "\n",
    "x_scipy = dgamma.rvs(a_true, loc=loc_true, scale=scale_true, size=60_000, random_state=rng)\n",
    "\n",
    "# Fit all parameters\n",
    "a_fit, loc_fit, scale_fit = dgamma.fit(x_scipy)\n",
    "print(\"true (a, loc, scale):\", (a_true, loc_true, scale_true))\n",
    "print(\"fit  (a, loc, scale):\", (float(a_fit), float(loc_fit), float(scale_fit)))\n",
    "\n",
    "# If you know loc/scale, you can fix them and estimate only a\n",
    "a_fit_fixed, loc_fixed, scale_fixed = dgamma.fit(x_scipy, floc=loc_true, fscale=scale_true)\n",
    "print(\"fit with fixed loc/scale:\", (float(a_fit_fixed), float(loc_fixed), float(scale_fixed)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cce8b69",
   "metadata": {},
   "source": [
    "## 10) Statistical Use Cases\n",
    "\n",
    "### 10.1 Hypothesis testing / goodness-of-fit\n",
    "\n",
    "If you have a proposed model (e.g. `dgamma` vs Laplace vs Normal), common workflows include:\n",
    "\n",
    "- **Goodness-of-fit** tests such as Kolmogorov–Smirnov (KS) when parameters are known.\n",
    "- **Model comparison** via likelihood / AIC / BIC when parameters are estimated.\n",
    "\n",
    "Caution: if you estimate parameters from the same data you test with, the KS p-values are not calibrated (this is the same issue as the Lilliefors correction for Normality tests). AIC/BIC comparisons are often a better quick diagnostic.\n",
    "\n",
    "### 10.2 Bayesian modeling\n",
    "\n",
    "As a prior for a coefficient $\\beta$ (centered at 0), `dgamma` includes Laplace as $a=1$.\n",
    "The log-density (standard form) is\n",
    "\n",
    "$$\n",
    "\\log p(\\beta)\n",
    "=(a-1)\\log|\\beta| - |\\beta| - \\log(2\\Gamma(a)).\n",
    "$$\n",
    "\n",
    "So the negative log-prior is\n",
    "\n",
    "$$\n",
    "-\\log p(\\beta) = |\\beta| - (a-1)\\log|\\beta| + \\text{const}.\n",
    "$$\n",
    "\n",
    "- At $a=1$, this reduces to an **L1 penalty** ($|\\beta|$).\n",
    "- For $a<1$, the prior becomes more **spiky at 0** (stronger shrinkage/sparsity).\n",
    "- For $a>1$, the density is 0 at 0, which can act like a *repulsive* prior around 0.\n",
    "\n",
    "### 10.3 Generative modeling\n",
    "\n",
    "Because sampling is easy (Gamma magnitude + random sign), `dgamma` can be used as a plug-in noise source for simulations where you want symmetric, exponential-tailed noise but more control over the central shape than Laplace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa88bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.1: AIC comparison on synthetic data\n",
    "n = 20_000\n",
    "a_true = 1.3\n",
    "x = dgamma.rvs(a_true, size=n, random_state=rng)\n",
    "\n",
    "# Fit candidate models\n",
    "a_dg, loc_dg, scale_dg = dgamma.fit(x)\n",
    "loc_lap, scale_lap = laplace.fit(x)\n",
    "mu_n, sd_n = norm.fit(x)\n",
    "\n",
    "ll_dg = float(np.sum(dgamma.logpdf(x, a_dg, loc=loc_dg, scale=scale_dg)))\n",
    "ll_lap = float(np.sum(laplace.logpdf(x, loc=loc_lap, scale=scale_lap)))\n",
    "ll_n = float(np.sum(norm.logpdf(x, loc=mu_n, scale=sd_n)))\n",
    "\n",
    "# Parameter counts: dgamma has (a, loc, scale)=3; Laplace has (loc, scale)=2; Normal has (mu, sigma)=2\n",
    "aic_dg = 2 * 3 - 2 * ll_dg\n",
    "aic_lap = 2 * 2 - 2 * ll_lap\n",
    "aic_n = 2 * 2 - 2 * ll_n\n",
    "\n",
    "print(\"AIC (lower is better)\")\n",
    "print(\"  dgamma:\", aic_dg)\n",
    "print(\"  laplace:\", aic_lap)\n",
    "print(\"  normal:\", aic_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9da0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.1: KS test with known parameters (calibrated because we don't fit)\n",
    "a_known = 1.3\n",
    "x = dgamma.rvs(a_known, size=5_000, random_state=rng)\n",
    "ks_dg = kstest(x, lambda t: dgamma.cdf(t, a_known))\n",
    "ks_lap = kstest(x, laplace.cdf)  # Laplace(0,1)\n",
    "ks_n = kstest(x, norm.cdf)       # Normal(0,1)\n",
    "print(\"KS dgamma(known a):\", ks_dg)\n",
    "print(\"KS Laplace(0,1):  \", ks_lap)\n",
    "print(\"KS Normal(0,1):   \", ks_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.2: Simple 1D MAP estimate under a dgamma prior\n",
    "# Likelihood: y | theta ~ Normal(theta, sigma^2)\n",
    "# Prior: theta ~ dgamma(a)\n",
    "\n",
    "def neg_log_posterior(theta: float, y: float, sigma: float, a: float) -> float:\n",
    "    ll = 0.5 * ((y - theta) / sigma) ** 2 + math.log(sigma * math.sqrt(2.0 * math.pi))\n",
    "    lp = -float(dgamma_logpdf_standard(theta, a))\n",
    "    return ll + lp\n",
    "\n",
    "\n",
    "y = 0.7\n",
    "sigma = 0.4\n",
    "a_values = [0.6, 1.0, 2.5]\n",
    "\n",
    "thetas = np.linspace(-2.5, 2.5, 1200)\n",
    "fig = go.Figure()\n",
    "for a in a_values:\n",
    "    vals = np.array([neg_log_posterior(t, y=y, sigma=sigma, a=a) for t in thetas])\n",
    "    fig.add_trace(go.Scatter(x=thetas, y=vals - vals.min(), mode=\"lines\", name=f\"a={a}\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"1D MAP objective (shifted): Normal likelihood + dgamma prior\",\n",
    "    xaxis_title=\"theta\",\n",
    "    yaxis_title=\"negative log-posterior (shifted)\",\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "for a in a_values:\n",
    "    res = minimize_scalar(neg_log_posterior, bounds=(-3, 3), method=\"bounded\", args=(y, sigma, a))\n",
    "    print(f\"a={a}: MAP theta={res.x:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d671fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.3: Generative modeling example: symmetric noise with tunable central shape\n",
    "\n",
    "n = 12_000\n",
    "a_gen = 0.5\n",
    "noise = dgamma_rvs_numpy(a_gen, n, rng=rng)\n",
    "\n",
    "x_max = np.quantile(np.abs(noise), 0.995)\n",
    "xs = np.linspace(-x_max, x_max, 700)\n",
    "\n",
    "fig = px.histogram(\n",
    "    x=noise,\n",
    "    nbins=120,\n",
    "    histnorm=\"probability density\",\n",
    "    title=f\"Noise samples from dgamma(a={a_gen}) (NumPy-only sampler)\",\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=xs, y=dgamma_pdf_standard(xs, a_gen), mode=\"lines\", name=\"theory pdf\"))\n",
    "fig.update_layout(xaxis_title=\"noise\", yaxis_title=\"density\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f940a",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Invalid parameters**: the shape must satisfy $a>0$; SciPy will error (or return `nan`) otherwise.\n",
    "- **Behavior at 0**:\n",
    "  - for $a<1$, the PDF diverges at 0 (infinite density). That’s fine mathematically, but it can surprise you numerically.\n",
    "  - for $a=1$, the PDF is finite at 0 (Laplace).\n",
    "  - for $a>1$, the PDF is 0 at 0.\n",
    "- **Use `logpdf` for stability**: for large $|x|$, `pdf` underflows quickly; `logpdf` is typically stable.\n",
    "- **MGF domain**: $M_X(t)$ exists only for $|t|<1$ (tails are $e^{-|x|}$).\n",
    "- **Fitting caveats**:\n",
    "  - If your data contain exact zeros (rounding/quantization), $\\log|x|$ becomes $-\\infty$ and the simple MLE derivation breaks.\n",
    "  - When fitting `loc` and `scale` as well, likelihood surfaces can be relatively flat; use diagnostics and reasonable constraints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f51f46",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `dgamma` is a **continuous**, symmetric distribution on $\\mathbb{R}$ with PDF $\\propto |x|^{a-1}e^{-|x|}$.\n",
    "- It can be generated as **sign × Gamma magnitude**: $X=S\\,Y$ with $Y\\sim\\mathrm{Gamma}(a,1)$.\n",
    "- Special case: $a=1$ gives the **Laplace** distribution.\n",
    "- Mean is 0 and variance is $a(a+1)$ (scale it by `scale^2` under SciPy’s parameterization).\n",
    "- Sampling is straightforward once you can sample Gamma; Marsaglia–Tsang gives an efficient NumPy-only implementation.\n",
    "- In practice, prefer `scipy.stats.dgamma` for production work (`pdf`, `cdf`, `rvs`, `fit`) and use `logpdf` for numerical stability.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
