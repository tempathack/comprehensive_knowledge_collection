{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0652b17",
   "metadata": {},
   "source": [
    "# ARGUS distribution (`argus`)\n",
    "\n",
    "**Goal:** build intuition, derive key formulas, and implement simulation/visualization for the continuous **ARGUS** distribution as implemented in `scipy.stats.argus`.\n",
    "\n",
    "The ARGUS distribution is most famous in **particle physics** as a parametric model for *background* shapes near a hard **kinematic endpoint**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516e6b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import scipy\n",
    "from scipy import special\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.stats import argus, chi2, norm\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"scipy:\", scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3f57d8",
   "metadata": {},
   "source": [
    "## 1) Title & classification\n",
    "\n",
    "- **Name:** `argus` (ARGUS distribution)\n",
    "- **Type:** **continuous**\n",
    "- **Support (standardized):** \\(x \\in (0, 1)\\)\n",
    "  - The density is 0 at the endpoints, so people often write \\([0,1]\\) informally.\n",
    "- **Parameter space:** shape parameter \\(\\chi > 0\\)\n",
    "  - SciPy also supports `loc` and `scale`, shifting/scaling the support to \\((\\text{loc},\\, \\text{loc}+\\text{scale})\\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35559789",
   "metadata": {},
   "source": [
    "## 2) Intuition & motivation\n",
    "\n",
    "### What it models\n",
    "A typical use case is a *background* distribution for a quantity with a **hard upper endpoint** (e.g., an invariant mass that cannot exceed a known limit).\n",
    "\n",
    "- The factor \\(\\sqrt{1-x^2}\\) creates a **phase-space-like suppression** as \\(x \\to 1\\).\n",
    "- The exponential factor \\(\\exp\\{-\\tfrac{\\chi^2}{2}(1-x^2)\\}\\) controls how strongly mass piles up near the endpoint.\n",
    "\n",
    "### Real-world use cases\n",
    "- **High energy physics:** background modeling near kinematic limits (the classic “ARGUS function”).\n",
    "- **Endpoint distributions:** any normalized measurement bounded above, where the density falls to 0 at the maximum.\n",
    "\n",
    "### Relations to other distributions\n",
    "A very useful transformation connects ARGUS to a **truncated Gamma** distribution:\n",
    "\n",
    "\\[\n",
    "Y \\;:=\\; \\frac{\\chi^2}{2}(1-X^2) \\in (0, \\chi^2/2).\n",
    "\\]\n",
    "\n",
    "Then \\(Y\\) has a density proportional to \\(\\sqrt{y} e^{-y}\\), i.e. a \\(\\text{Gamma}(3/2,\\,1)\\) **conditioned on** \\([0,\\chi^2/2]\\).\n",
    "\n",
    "Limiting behavior:\n",
    "- As \\(\\chi \\downarrow 0\\): the exponential term \\(\\to 1\\), and the density approaches \\(f(x) \\propto x\\sqrt{1-x^2}\\).\n",
    "- As \\(\\chi \\to \\infty\\): the distribution concentrates near \\(x \\approx 1\\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab638a",
   "metadata": {},
   "source": [
    "## 3) Formal definition\n",
    "\n",
    "### PDF\n",
    "For \\(0<x<1\\) and \\(\\chi>0\\), the standardized ARGUS density is\n",
    "\n",
    "\\[\n",
    " f(x;\\chi) = \\frac{\\chi^3}{\\sqrt{2\\pi}\\,\\Psi(\\chi)}\\, x\\,\\sqrt{1-x^2}\\,\\exp\\left\\{-\\frac{\\chi^2}{2}(1-x^2)\\right\\},\n",
    "\\]\n",
    "\n",
    "where\n",
    "\n",
    "\\[\n",
    "\\Psi(\\chi) = \\Phi(\\chi) - \\chi\\,\\phi(\\chi) - \\tfrac{1}{2},\n",
    "\\]\n",
    "\n",
    "and \\(\\Phi\\) and \\(\\phi\\) are the CDF and PDF of \\(\\mathcal N(0,1)\\).\n",
    "\n",
    "A numerically stable equivalent form is\n",
    "\n",
    "\\[\n",
    "\\Psi(\\chi) = \\tfrac{1}{2}\\,P\\left(\\tfrac{3}{2}, \\tfrac{\\chi^2}{2}\\right),\n",
    "\\]\n",
    "\n",
    "where \\(P(a,x)=\\gamma(a,x)/\\Gamma(a)\\) is the regularized lower incomplete gamma function.\n",
    "\n",
    "### CDF\n",
    "SciPy’s implementation uses a particularly clean survival function:\n",
    "\n",
    "\\[\n",
    "\\bar F(x;\\chi) = 1 - F(x;\\chi) = \\frac{\\Psi\\big(\\chi\\sqrt{1-x^2}\\big)}{\\Psi(\\chi)},\n",
    "\\]\n",
    "\n",
    "so\n",
    "\n",
    "\\[\n",
    "F(x;\\chi) = 1 - \\frac{\\Psi\\big(\\chi\\sqrt{1-x^2}\\big)}{\\Psi(\\chi)}.\n",
    "\\]\n",
    "\n",
    "### Location/scale\n",
    "If \\(Z\\sim\\text{ARGUS}(\\chi)\\) on \\((0,1)\\), then\n",
    "\\(X=\\text{loc}+\\text{scale}\\cdot Z\\) has support \\((\\text{loc},\\, \\text{loc}+\\text{scale})\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43288e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def argus_Psi(chi: np.ndarray | float) -> np.ndarray:\n",
    "    \"\"\"Psi(chi) used by the ARGUS distribution.\n",
    "\n",
    "    We use the regularized incomplete gamma form for numerical stability:\n",
    "        Psi(chi) = 0.5 * P(3/2, chi^2/2).\n",
    "    \"\"\"\n",
    "    chi = np.asarray(chi, dtype=float)\n",
    "    return 0.5 * special.gammainc(1.5, chi**2 / 2)\n",
    "\n",
    "\n",
    "def argus_pdf(x: np.ndarray | float, chi: float) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    chi = float(chi)\n",
    "    if chi <= 0:\n",
    "        return np.full_like(x, np.nan, dtype=float)\n",
    "\n",
    "    Psi = argus_Psi(chi)\n",
    "    norm_const = chi**3 / (np.sqrt(2 * np.pi) * Psi)\n",
    "\n",
    "    y = 1.0 - x * x\n",
    "    base = norm_const * x * np.sqrt(np.clip(y, 0.0, None)) * np.exp(-0.5 * chi**2 * y)\n",
    "    return np.where((x > 0) & (x < 1), base, 0.0)\n",
    "\n",
    "\n",
    "def argus_cdf(x: np.ndarray | float, chi: float) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    chi = float(chi)\n",
    "    if chi <= 0:\n",
    "        return np.full_like(x, np.nan, dtype=float)\n",
    "\n",
    "    Psi_chi = argus_Psi(chi)\n",
    "    t = chi * np.sqrt(np.clip(1.0 - x * x, 0.0, None))\n",
    "    sf = argus_Psi(t) / Psi_chi\n",
    "\n",
    "    cdf = 1.0 - sf\n",
    "    cdf = np.where(x <= 0, 0.0, cdf)\n",
    "    cdf = np.where(x >= 1, 1.0, cdf)\n",
    "    return cdf\n",
    "\n",
    "\n",
    "# Quick consistency check vs SciPy\n",
    "xgrid = np.linspace(0, 1, 400)\n",
    "chi_test = 2.5\n",
    "\n",
    "max_pdf_err = np.max(np.abs(argus_pdf(xgrid, chi_test) - argus.pdf(xgrid, chi_test)))\n",
    "max_cdf_err = np.max(np.abs(argus_cdf(xgrid, chi_test) - argus.cdf(xgrid, chi_test)))\n",
    "\n",
    "print(\"max |pdf - scipy|:\", max_pdf_err)\n",
    "print(\"max |cdf - scipy|:\", max_cdf_err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06713e3",
   "metadata": {},
   "source": [
    "## 4) Moments & properties\n",
    "\n",
    "### Mean and variance\n",
    "SciPy uses (and we can derive) the following closed forms.\n",
    "\n",
    "Let \\(I_1\\) be the modified Bessel function of the first kind. Define \\(z=\\chi^2/4\\).\n",
    "\n",
    "\\[\n",
    "\\mathbb E[X] = \\sqrt{\\frac{\\pi}{8}}\\,\\frac{\\chi\\,e^{-z} I_1(z)}{\\Psi(\\chi)}.\n",
    "\\]\n",
    "\n",
    "For the second moment:\n",
    "\\[\n",
    "\\mathbb E[X^2] = 1 - \\frac{3}{\\chi^2} + \\frac{\\chi\\,\\phi(\\chi)}{\\Psi(\\chi)}.\n",
    "\\]\n",
    "\n",
    "Then \\(\\operatorname{Var}(X)=\\mathbb E[X^2]-\\mathbb E[X]^2\\).\n",
    "\n",
    "### Skewness and kurtosis\n",
    "Skewness and (excess) kurtosis are defined via central moments:\n",
    "\\[\n",
    "\\gamma_1 = \\frac{\\mu_3}{\\sigma^3},\\qquad \\gamma_2 = \\frac{\\mu_4}{\\sigma^4} - 3.\n",
    "\\]\n",
    "\n",
    "For ARGUS, these don’t simplify nicely to a short expression; they’re typically computed numerically.\n",
    "\n",
    "### MGF / characteristic function\n",
    "Because \\(X\\in(0,1)\\) is bounded, both exist for all real arguments:\n",
    "\\[\n",
    "M_X(t)=\\mathbb E[e^{tX}],\\qquad \\varphi_X(\\omega)=\\mathbb E[e^{i\\omega X}].\n",
    "\\]\n",
    "\n",
    "There is no widely used simple closed form; numerical quadrature (or a moment series) is standard.\n",
    "\n",
    "### Entropy\n",
    "The differential entropy is\n",
    "\\[\n",
    "H(X) = -\\int_0^1 f(x;\\chi)\\,\\log f(x;\\chi)\\,dx.\n",
    "\\]\n",
    "\n",
    "SciPy provides `argus.entropy(chi)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ab8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def argus_mean(chi: np.ndarray | float) -> np.ndarray:\n",
    "    chi = np.asarray(chi, dtype=float)\n",
    "    Psi = argus_Psi(chi)\n",
    "    z = chi**2 / 4\n",
    "    return np.sqrt(np.pi / 8) * chi * special.ive(1, z) / Psi\n",
    "\n",
    "\n",
    "def argus_E_x2(chi: np.ndarray | float) -> np.ndarray:\n",
    "    \"\"\"E[X^2] with a small-chi branch for numerical stability (mirrors SciPy).\"\"\"\n",
    "    chi = np.asarray(chi, dtype=float)\n",
    "    out = np.empty_like(chi)\n",
    "\n",
    "    mask = chi > 0.1\n",
    "    if np.any(mask):\n",
    "        c = chi[mask]\n",
    "        out[mask] = 1 - 3 / c**2 + c * norm.pdf(c) / argus_Psi(c)\n",
    "\n",
    "    if np.any(~mask):\n",
    "        c = chi[~mask]\n",
    "        # series approximation for small chi (from SciPy's implementation)\n",
    "        coef = [-358 / 65690625, 0, -94 / 1010625, 0, 2 / 2625, 0, 6 / 175, 0, 0.4]\n",
    "        out[~mask] = np.polyval(coef, c)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def argus_var(chi: np.ndarray | float) -> np.ndarray:\n",
    "    m = argus_mean(chi)\n",
    "    return argus_E_x2(chi) - m**2\n",
    "\n",
    "\n",
    "chis = np.array([0.2, 0.5, 1.0, 2.5, 6.0])\n",
    "\n",
    "m_formula = argus_mean(chis)\n",
    "v_formula = argus_var(chis)\n",
    "\n",
    "m_scipy, v_scipy, s_scipy, k_scipy = argus.stats(chis, moments=\"mvsk\")\n",
    "\n",
    "print(\"chi    mean(formula)   mean(scipy)   var(formula)    var(scipy)   skew     kurt(excess)\")\n",
    "for chi, mf, ms, vf, vs, ss, ks in zip(chis, m_formula, m_scipy, v_formula, v_scipy, s_scipy, k_scipy):\n",
    "    print(f\"{chi:4.1f}  {mf:12.6f}  {ms:11.6f}  {vf:12.6f}  {vs:11.6f}  {ss:7.4f}  {ks:11.4f}\")\n",
    "\n",
    "\n",
    "# MGF/CF: demonstrate numerical quadrature vs Monte Carlo\n",
    "chi0 = 2.5\n",
    "x_mc = argus.rvs(chi0, size=150_000, random_state=rng)\n",
    "\n",
    "ts = np.array([-3.0, 0.0, 3.0])\n",
    "ws = np.array([0.0, 10.0, 20.0])\n",
    "\n",
    "print(\"\\nMGF M(t)=E[e^{tX}] at a few t:\")\n",
    "for t in ts:\n",
    "    mc = np.mean(np.exp(t * x_mc))\n",
    "    quad = argus.expect(lambda x, t=t: np.exp(t * x), args=(chi0,))\n",
    "    print(f\"t={t:>5.1f}  MC={mc:.6f}  quad={quad:.6f}\")\n",
    "\n",
    "print(\"\\nCharacteristic function φ(ω)=E[e^{iωX}] at a few ω:\")\n",
    "for w in ws:\n",
    "    mc = np.mean(np.exp(1j * w * x_mc))\n",
    "    quad = argus.expect(lambda x, w=w: np.exp(1j * w * x), args=(chi0,))\n",
    "    print(f\"w={w:>5.1f}  MC={mc:.6f}  quad={quad:.6f}\")\n",
    "\n",
    "print(\"\\nEntropy at chi=2.5:\", argus.entropy(chi0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed391d3",
   "metadata": {},
   "source": [
    "## 5) Parameter interpretation (shape changes)\n",
    "\n",
    "The single shape parameter \\(\\chi\\) controls how quickly the density falls away from the endpoint.\n",
    "\n",
    "- **Small \\(\\chi\\)**: the exponential term is weak, and the shape is dominated by \\(x\\sqrt{1-x^2}\\).\n",
    "- **Large \\(\\chi\\)**: the exponential term strongly favors \\(x\\) near 1, creating a sharp peak close to the endpoint.\n",
    "\n",
    "A convenient closed-form for the **mode** (maximum of the pdf) comes from differentiating \\(\\log f(x)\\):\n",
    "\n",
    "\\[\n",
    "\\text{mode}(X)^2 = \\frac{\\chi^2 - 2 + \\sqrt{\\chi^4 + 4}}{2\\chi^2}.\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af66c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def argus_mode(chi: float) -> float:\n",
    "    chi = float(chi)\n",
    "    if chi <= 0:\n",
    "        return np.nan\n",
    "    u = (chi**2 - 2 + np.sqrt(chi**4 + 4)) / (2 * chi**2)\n",
    "    return float(np.sqrt(u))\n",
    "\n",
    "\n",
    "for chi in [0.2, 1.0, 2.5, 6.0]:\n",
    "    print(f\"chi={chi:>4}: mode≈{argus_mode(chi):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f3dc96",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### 6.1 Derivation of the mean (why Bessel functions appear)\n",
    "Start from\n",
    "\\(\n",
    "\\mathbb E[X] = \\int_0^1 x\\,f(x;\\chi)\\,dx\n",
    "\\)\n",
    "\n",
    "so the integral of interest is\n",
    "\n",
    "\\[\n",
    "I = \\int_0^1 x^2\\sqrt{1-x^2}\\,\\exp\\left\\{-\\frac{\\chi^2}{2}(1-x^2)\\right\\}\\,dx.\n",
    "\\]\n",
    "\n",
    "Use the substitution \\(x=\\cos\\theta\\) with \\(\\theta\\in[0,\\pi/2]\\). Then \\(1-x^2=\\sin^2\\theta\\), \\(dx=-\\sin\\theta\\,d\\theta\\), and\n",
    "\n",
    "\\[\n",
    "I = \\int_0^{\\pi/2} \\cos^2\\theta\\,\\sin^2\\theta\\,\\exp\\left\\{-\\frac{\\chi^2}{2}\\sin^2\\theta\\right\\}d\\theta.\n",
    "\\]\n",
    "\n",
    "Rewrite \\(\\sin^2\\theta = \\tfrac{1-\\cos 2\\theta}{2}\\) and set \\(\\varphi=2\\theta\\), which yields an integral of the form\n",
    "\\(\\int_0^{\\pi} e^{z\\cos\\varphi}\\cos(n\\varphi)d\\varphi\\), whose value is \\(\\pi I_n(z)\\).\n",
    "\n",
    "After simplification you arrive at\n",
    "\n",
    "\\[\n",
    "I = \\frac{\\pi}{2\\chi^2} e^{-\\chi^2/4} I_1(\\chi^2/4).\n",
    "\\]\n",
    "\n",
    "Multiplying by the normalization constant \\(\\chi^3/(\\sqrt{2\\pi}\\Psi(\\chi))\\) gives\n",
    "\n",
    "\\[\n",
    "\\mathbb E[X] = \\sqrt{\\frac{\\pi}{8}}\\,\\frac{\\chi\\,e^{-\\chi^2/4}I_1(\\chi^2/4)}{\\Psi(\\chi)}.\n",
    "\\]\n",
    "\n",
    "### 6.2 Derivation of \\(\\mathbb E[X^2]\\) via the truncated-Gamma representation\n",
    "Let \\(Y=\\tfrac{\\chi^2}{2}(1-X^2)\\). Then \\(Y\\) is Gamma\\((3/2,1)\\) conditioned on \\([0,\\chi^2/2]\\).\n",
    "\n",
    "Since \\(X^2=1-2Y/\\chi^2\\):\n",
    "\n",
    "\\[\n",
    "\\mathbb E[X^2] = 1 - \\frac{2}{\\chi^2}\\,\\mathbb E[Y\\mid Y\\le \\chi^2/2].\n",
    "\\]\n",
    "\n",
    "For a Gamma\\((\\alpha,1)\\) truncated at \\(b\\),\n",
    "\\(\\mathbb E[Y\\mid Y\\le b] = \\gamma(\\alpha+1,b)/\\gamma(\\alpha,b)\\).\n",
    "\n",
    "Using the incomplete-gamma recurrence simplifies the ratio and leads to\n",
    "\n",
    "\\[\n",
    "\\mathbb E[X^2] = 1 - \\frac{3}{\\chi^2} + \\frac{\\chi\\,\\phi(\\chi)}{\\Psi(\\chi)}.\n",
    "\\]\n",
    "\n",
    "### 6.3 Likelihood for i.i.d. data\n",
    "For data \\(x_1,\\dots,x_n\\in(0,1)\\), the log-likelihood (standardized) is\n",
    "\n",
    "\\[\n",
    "\\ell(\\chi) = n\\left(3\\log\\chi - \\log\\Psi(\\chi) - \\tfrac{1}{2}\\log(2\\pi)\\right)\n",
    "+ \\sum_{i=1}^n\\left(\\log x_i + \\tfrac{1}{2}\\log(1-x_i^2) - \\tfrac{\\chi^2}{2}(1-x_i^2)\\right).\n",
    "\\]\n",
    "\n",
    "A handy derivative identity is\n",
    "\\(\\Psi'(\\chi)=\\chi^2\\phi(\\chi)\\), so you can optimize \\(\\ell(\\chi)\\) with gradient-based methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e8f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def argus_loglik(chi: float, x: np.ndarray) -> float:\n",
    "    \"\"\"Log-likelihood for standardized ARGUS(chi) given x in (0,1).\"\"\"\n",
    "    chi = float(chi)\n",
    "    if chi <= 0:\n",
    "        return -np.inf\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if np.any((x <= 0) | (x >= 1)):\n",
    "        return -np.inf\n",
    "\n",
    "    Psi = argus_Psi(chi)\n",
    "\n",
    "    y = 1.0 - x * x\n",
    "    ll = (\n",
    "        x.size * (3 * np.log(chi) - 0.5 * np.log(2 * np.pi) - np.log(Psi))\n",
    "        + np.sum(np.log(x) + 0.5 * np.log1p(-x * x) - 0.5 * chi**2 * y)\n",
    "    )\n",
    "    return float(ll)\n",
    "\n",
    "\n",
    "def argus_loglik_grad(chi: float, x: np.ndarray) -> float:\n",
    "    \"\"\"Gradient of the log-likelihood.\n",
    "\n",
    "    Uses Psi'(chi) = chi^2 * phi(chi).\n",
    "    \"\"\"\n",
    "    chi = float(chi)\n",
    "    if chi <= 0:\n",
    "        return np.nan\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if np.any((x <= 0) | (x >= 1)):\n",
    "        return np.nan\n",
    "\n",
    "    n = x.size\n",
    "    Psi = argus_Psi(chi)\n",
    "    Psi_prime = chi**2 * norm.pdf(chi)\n",
    "\n",
    "    y = 1.0 - x * x\n",
    "    return float(n * (3 / chi - Psi_prime / Psi) - chi * np.sum(y))\n",
    "\n",
    "\n",
    "# Simulate data and compute the MLE\n",
    "chi_true = 2.5\n",
    "x = argus.rvs(chi_true, size=800, random_state=rng)\n",
    "\n",
    "obj = lambda c: -argus_loglik(c, x)\n",
    "res = minimize_scalar(obj, bounds=(1e-6, 30.0), method=\"bounded\")\n",
    "chi_hat = float(res.x)\n",
    "\n",
    "print(\"chi_true:\", chi_true)\n",
    "print(\"chi_hat (MLE):\", chi_hat)\n",
    "print(\"grad at chi_hat:\", argus_loglik_grad(chi_hat, x))\n",
    "\n",
    "# Likelihood ratio test: H0: chi = chi0 vs H1: chi free\n",
    "chi0 = 1.0\n",
    "lr_stat = 2 * (argus_loglik(chi_hat, x) - argus_loglik(chi0, x))\n",
    "p_value = chi2.sf(lr_stat, df=1)\n",
    "\n",
    "print(\"\\nLRT statistic:\", lr_stat)\n",
    "print(\"approx p-value (chi-square df=1):\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544a3381",
   "metadata": {},
   "source": [
    "## 7) Sampling & simulation (NumPy-only)\n",
    "\n",
    "Below is a **NumPy-only** sampler for standardized ARGUS(\\(\\chi\\)). It mirrors SciPy’s piecewise strategy:\n",
    "\n",
    "- **Small \\(\\chi\\)**: rejection sampling using the \\(\\chi\\to 0\\) base density \\(g(x)=3x\\sqrt{1-x^2}\\).\n",
    "- **Moderate \\(\\chi\\)**: rejection sampling with a proposal density \\(g(x)\\propto x\\exp\\{-\\tfrac{\\chi^2}{2}(1-x^2)\\}\\).\n",
    "- **Large \\(\\chi\\)**: use the **truncated Gamma** representation of \\(Y=\\tfrac{\\chi^2}{2}(1-X^2)\\).\n",
    "\n",
    "This is not the only way to sample ARGUS, but it’s easy to implement and performs well across a wide parameter range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def argus_rvs_numpy(chi: float, size=1, rng: np.random.Generator | None = None) -> np.ndarray:\n",
    "    \"\"\"Sample from standardized ARGUS(chi) using only NumPy.\"\"\"\n",
    "    chi = float(chi)\n",
    "    if chi <= 0:\n",
    "        raise ValueError(\"chi must be > 0\")\n",
    "\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    size1d = tuple(np.atleast_1d(size))\n",
    "    n = int(np.prod(size1d))\n",
    "\n",
    "    out = np.empty(n, dtype=float)\n",
    "    simulated = 0\n",
    "\n",
    "    chi2 = chi * chi\n",
    "\n",
    "    if chi <= 0.5:\n",
    "        # Case 1: propose from g(x) = 3*x*sqrt(1-x^2), accept with exp(-chi^2(1-x^2)/2)\n",
    "        d = -chi2 / 2\n",
    "        while simulated < n:\n",
    "            k = n - simulated\n",
    "            u = rng.uniform(size=k)\n",
    "            v = rng.uniform(size=k)\n",
    "            z = v ** (2 / 3)  # z = 1 - x^2 under the proposal\n",
    "            accept = np.log(u) <= d * z\n",
    "            num_accept = int(np.sum(accept))\n",
    "            if num_accept:\n",
    "                out[simulated : simulated + num_accept] = np.sqrt(1 - z[accept])\n",
    "                simulated += num_accept\n",
    "\n",
    "    elif chi <= 1.8:\n",
    "        # Case 2: propose from g(x) ∝ x*exp(-chi^2(1-x^2)/2) and accept with sqrt(1-x^2)\n",
    "        echi = np.exp(-chi2 / 2)\n",
    "        while simulated < n:\n",
    "            k = n - simulated\n",
    "            u = rng.uniform(size=k)\n",
    "            v = rng.uniform(size=k)\n",
    "\n",
    "            # z <= 0, and x = sqrt(1 + z)\n",
    "            z = 2 * np.log(echi * (1 - v) + v) / chi2\n",
    "            accept = (u * u + z) <= 0\n",
    "            num_accept = int(np.sum(accept))\n",
    "            if num_accept:\n",
    "                out[simulated : simulated + num_accept] = np.sqrt(1 + z[accept])\n",
    "                simulated += num_accept\n",
    "\n",
    "    else:\n",
    "        # Case 3: conditional Gamma(3/2, 1) for Y in [0, chi^2/2]\n",
    "        y = np.empty(n, dtype=float)\n",
    "        while simulated < n:\n",
    "            k = n - simulated\n",
    "            g = rng.standard_gamma(shape=1.5, size=k)  # Gamma(k=3/2, theta=1)\n",
    "            accept = g <= chi2 / 2\n",
    "            num_accept = int(np.sum(accept))\n",
    "            if num_accept:\n",
    "                y[simulated : simulated + num_accept] = g[accept]\n",
    "                simulated += num_accept\n",
    "        out = np.sqrt(1 - 2 * y / chi2)\n",
    "\n",
    "    return out.reshape(size1d)\n",
    "\n",
    "\n",
    "# Sanity check: NumPy sampler vs SciPy moments\n",
    "chi_check = 2.5\n",
    "s = argus_rvs_numpy(chi_check, size=200_000, rng=rng)\n",
    "\n",
    "print(\"sample mean:\", s.mean())\n",
    "print(\"theory mean:\", argus.mean(chi_check))\n",
    "\n",
    "print(\"sample var:\", s.var())\n",
    "print(\"theory var:\", argus.var(chi_check))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0c63c",
   "metadata": {},
   "source": [
    "## 8) Visualization (PDF, CDF, Monte Carlo)\n",
    "\n",
    "We’ll visualize how \\(\\chi\\) changes the shape and verify the sampler by overlaying a Monte Carlo histogram on the theoretical PDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9373b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 800)\n",
    "chis_plot = [0.2, 0.7, 2.5, 6.0]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"PDF\", \"CDF\"),\n",
    ")\n",
    "\n",
    "for chi in chis_plot:\n",
    "    fig.add_trace(go.Scatter(x=x, y=argus_pdf(x, chi), name=f\"chi={chi}\", mode=\"lines\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=x, y=argus_cdf(x, chi), name=f\"chi={chi}\", mode=\"lines\", showlegend=False), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"x (standardized)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"x (standardized)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"density\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"CDF\", row=1, col=2)\n",
    "fig.update_layout(title=\"ARGUS distribution for different chi\", width=950)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Monte Carlo overlay\n",
    "chi_mc = 2.5\n",
    "n_mc = 40_000\n",
    "samples = argus_rvs_numpy(chi_mc, size=n_mc, rng=rng)\n",
    "\n",
    "hist = np.histogram(samples, bins=70, range=(0, 1), density=True)\n",
    "bins = hist[1]\n",
    "centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "fig2 = go.Figure()\n",
    "fig2.add_trace(go.Bar(x=centers, y=hist[0], name=\"MC histogram\", opacity=0.4))\n",
    "fig2.add_trace(go.Scatter(x=x, y=argus_pdf(x, chi_mc), name=\"theoretical pdf\", mode=\"lines\"))\n",
    "fig2.update_layout(\n",
    "    title=f\"Monte Carlo check (chi={chi_mc})\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"density\",\n",
    "    bargap=0.02,\n",
    ")\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c3482",
   "metadata": {},
   "source": [
    "## 9) SciPy integration (`scipy.stats.argus`)\n",
    "\n",
    "SciPy exposes ARGUS as a standard `rv_continuous` distribution:\n",
    "\n",
    "- `argus.pdf(x, chi)` / `argus.logpdf(x, chi)`\n",
    "- `argus.cdf(x, chi)` / `argus.sf(x, chi)`\n",
    "- `argus.rvs(chi, size=..., random_state=...)`\n",
    "- `argus.fit(data, ...)`\n",
    "\n",
    "Because the support is bounded, it’s common to **pre-normalize** data to \\((0,1)\\) and fit only \\(\\chi\\) by fixing `loc=0, scale=1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ef0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi = 2.5\n",
    "x = np.linspace(0, 1, 6)\n",
    "print(\"x:\", x)\n",
    "print(\"pdf:\", argus.pdf(x, chi))\n",
    "print(\"cdf:\", argus.cdf(x, chi))\n",
    "\n",
    "# Random variates\n",
    "r = argus.rvs(chi, size=5, random_state=rng)\n",
    "print(\"\\nrvs:\", r)\n",
    "\n",
    "# Fit chi (fix loc/scale)\n",
    "chi_true = 2.5\n",
    "x_data = argus.rvs(chi_true, size=2000, random_state=rng)\n",
    "\n",
    "chi_hat, loc_hat, scale_hat = argus.fit(x_data, floc=0.0, fscale=1.0)\n",
    "print(\"\\ntrue chi:\", chi_true)\n",
    "print(\"fit chi :\", chi_hat)\n",
    "print(\"(loc, scale fixed to)\", loc_hat, scale_hat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dfeebc",
   "metadata": {},
   "source": [
    "## 10) Statistical use cases\n",
    "\n",
    "### 10.1 Hypothesis testing\n",
    "A common workflow is to compare a fixed-shape ARGUS background (e.g. \\(\\chi=\\chi_0\\)) against a fitted \\(\\chi\\) using a **likelihood ratio test**.\n",
    "\n",
    "Caveat: the usual \\(\\chi^2\\) calibration is asymptotic and can be inaccurate for small samples.\n",
    "\n",
    "### 10.2 Bayesian modeling\n",
    "Treat \\(\\chi\\) as an unknown parameter with a prior (e.g. log-normal). Because it’s 1D, a **grid posterior** is often sufficient.\n",
    "\n",
    "### 10.3 Generative modeling\n",
    "ARGUS is frequently used as a *background component* inside a mixture model:\n",
    "\n",
    "\\[\n",
    " p(x)=\\pi\\,p_{\\text{signal}}(x) + (1-\\pi)\\,p_{\\text{bkg}}(x),\\qquad p_{\\text{bkg}}(x)=\\text{ARGUS}(\\chi).\n",
    "\\]\n",
    "\n",
    "Below is a lightweight demo of all three.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc0c954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10.1 Likelihood ratio test demo ---\n",
    "chi_true = 2.5\n",
    "x = argus.rvs(chi_true, size=600, random_state=rng)\n",
    "\n",
    "res = minimize_scalar(lambda c: -argus_loglik(c, x), bounds=(1e-6, 30.0), method=\"bounded\")\n",
    "chi_hat = float(res.x)\n",
    "\n",
    "chi0 = 1.0\n",
    "lr_stat = 2 * (argus_loglik(chi_hat, x) - argus_loglik(chi0, x))\n",
    "print(\"chi_hat:\", chi_hat)\n",
    "print(\"LRT stat:\", lr_stat)\n",
    "print(\"approx p-value:\", chi2.sf(lr_stat, df=1))\n",
    "\n",
    "\n",
    "# --- 10.2 Bayesian grid posterior for chi ---\n",
    "# Prior: log chi ~ Normal(mu=0, sigma=1)  (=> chi is log-normal)\n",
    "chis = np.linspace(0.05, 10.0, 400)\n",
    "log_prior = norm.logpdf(np.log(chis), loc=0.0, scale=1.0) - np.log(chis)  # Jacobian for chi -> log chi\n",
    "log_like = np.array([argus_loglik(c, x) for c in chis])\n",
    "\n",
    "log_post_unnorm = log_like + log_prior\n",
    "log_post_unnorm -= np.max(log_post_unnorm)\n",
    "post = np.exp(log_post_unnorm)\n",
    "post /= np.trapz(post, chis)\n",
    "\n",
    "post_cdf = np.cumsum(post)\n",
    "post_cdf /= post_cdf[-1]\n",
    "\n",
    "def quantile(q):\n",
    "    return float(np.interp(q, post_cdf, chis))\n",
    "\n",
    "ci_low, ci_high = quantile(0.05), quantile(0.95)\n",
    "post_mean = float(np.trapz(chis * post, chis))\n",
    "\n",
    "print(\"\\nPosterior mean:\", post_mean)\n",
    "print(\"90% credible interval:\", (ci_low, ci_high))\n",
    "\n",
    "fig = go.Figure(go.Scatter(x=chis, y=post, mode=\"lines\", name=\"posterior\"))\n",
    "fig.add_vline(x=chi_true, line_dash=\"dash\", line_color=\"black\", annotation_text=\"true\")\n",
    "fig.add_vrect(x0=ci_low, x1=ci_high, fillcolor=\"lightblue\", opacity=0.3, line_width=0)\n",
    "fig.update_layout(title=\"Posterior over chi (grid)\", xaxis_title=\"chi\", yaxis_title=\"density\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# --- 10.3 Simple generative mixture (signal + ARGUS background) ---\n",
    "# Background: ARGUS\n",
    "chi_bkg = 6.0\n",
    "n = 50_000\n",
    "\n",
    "# Signal: a narrow truncated normal near the endpoint\n",
    "mu_sig, sigma_sig = 0.97, 0.02\n",
    "pi_sig = 0.08\n",
    "\n",
    "n_sig = int(round(pi_sig * n))\n",
    "n_bkg = n - n_sig\n",
    "\n",
    "x_bkg = argus_rvs_numpy(chi_bkg, size=n_bkg, rng=rng)\n",
    "\n",
    "# Truncated normal via rejection (fine for a demo)\n",
    "x_sig = []\n",
    "while len(x_sig) < n_sig:\n",
    "    z = rng.normal(loc=mu_sig, scale=sigma_sig, size=n_sig)\n",
    "    z = z[(z > 0) & (z < 1)]\n",
    "    x_sig.extend(z.tolist())\n",
    "x_sig = np.array(x_sig[:n_sig])\n",
    "\n",
    "x_mix = np.concatenate([x_bkg, x_sig])\n",
    "\n",
    "fig = px.histogram(\n",
    "    x_mix,\n",
    "    nbins=120,\n",
    "    histnorm=\"probability density\",\n",
    "    title=\"Mixture example: ARGUS background + truncated-normal signal\",\n",
    "    labels={\"value\": \"x\"},\n",
    ")\n",
    "xx = np.linspace(0, 1, 800)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=xx,\n",
    "        y=(1 - pi_sig) * argus_pdf(xx, chi_bkg),\n",
    "        name=\"(1-π) * ARGUS pdf\",\n",
    "        mode=\"lines\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(showlegend=True)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70082be2",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Parameter constraints:** \\(\\chi\\le 0\\) is invalid.\n",
    "- **Boundary values:** the theoretical support is \\((0,1)\\). Real data may contain exact 0/1 due to rounding; for likelihood work you may need to clip slightly, e.g. `x = np.clip(x, 1e-12, 1-1e-12)`.\n",
    "- **Numerical stability near 1:** use `log1p(-x*x)` rather than `log(1-x**2)`.\n",
    "- **Sampling efficiency:** the simple truncated-Gamma method is great for large \\(\\chi\\) but can reject a lot when \\(\\chi\\) is small; the piecewise sampler avoids that.\n",
    "- **Fitting (`fit`) surprises:** by default, SciPy also fits `loc` and `scale`. If your data are already standardized, fix them with `floc=0, fscale=1`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4ffb02",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `argus` is a **continuous** distribution on \\((0,1)\\) with shape parameter \\(\\chi>0\\).\n",
    "- Its PDF combines a phase-space term \\(x\\sqrt{1-x^2}\\) and an exponential tilt controlled by \\(\\chi\\).\n",
    "- The CDF is especially clean in terms of \\(\\Psi(\\chi)\\): \\(F(x)=1-\\Psi(\\chi\\sqrt{1-x^2})/\\Psi(\\chi)\\).\n",
    "- Mean and second moment have closed forms (Bessel/incomplete-gamma), while skewness/kurtosis are usually computed numerically.\n",
    "- Sampling can be implemented with rejection methods and a truncated-Gamma transformation; SciPy provides a fast and robust implementation in `scipy.stats.argus`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
