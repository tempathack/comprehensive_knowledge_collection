{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e07f737f",
   "metadata": {},
   "source": [
    "# Pareto distribution (`pareto`) — heavy-tailed power laws\n",
    "\n",
    "The **Pareto (Type I)** distribution is a *continuous* distribution on $(x_m, \\infty)$ with a **power-law tail**.\n",
    "It is the canonical model behind the **Pareto principle** (“80/20 rule”) and appears whenever a small number of observations dominate totals.\n",
    "\n",
    "## What you’ll learn\n",
    "- how the **PDF/CDF** encode a power-law tail and a simple quantile function\n",
    "- which **moments exist** (and why some are infinite)\n",
    "- mean/variance/skewness/kurtosis, entropy, and what happens to the MGF\n",
    "- a clean **NumPy-only sampler** (inverse transform) and Monte Carlo validation\n",
    "- maximum likelihood estimation (MLE) and how it relates to exponentials on the log scale\n",
    "- practical usage via `scipy.stats.pareto` (`pdf`, `cdf`, `rvs`, `fit`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bfb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.integrate import quad\n",
    "\n",
    "# Plotly rendering (CKC convention)\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "# Reproducibility\n",
    "rng = np.random.default_rng(7)\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"scipy:\", scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e929a285",
   "metadata": {},
   "source": [
    "## 1) Title & Classification\n",
    "\n",
    "- **Name**: `pareto` (Pareto Type I; SciPy: `scipy.stats.pareto`)\n",
    "- **Type**: **Continuous**\n",
    "- **Support**: $x \\in [x_m, \\infty)$\n",
    "- **Parameter space**:\n",
    "  - shape (tail index) $\\alpha > 0$\n",
    "  - scale / minimum $x_m > 0$\n",
    "\n",
    "We write:\n",
    "\n",
    "$$X \\sim \\mathrm{Pareto}(\\alpha, x_m).$$\n",
    "\n",
    "**SciPy parameterization (mapping)**\n",
    "\n",
    "SciPy’s `stats.pareto(b, loc=0, scale=1)` uses a shape parameter `b` and then applies an affine transformation.\n",
    "With `loc=0` and `scale=x_m`, SciPy’s `b` corresponds to our $\\alpha$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d0e244",
   "metadata": {},
   "source": [
    "## 2) Intuition & Motivation\n",
    "\n",
    "### 2.1 What it models\n",
    "The Pareto distribution models **positive quantities with a hard lower bound** and a **heavy right tail**.\n",
    "\n",
    "A key feature is its *scale-free* tail:\n",
    "\n",
    "$$\\Pr(X > x) = \\left(\\frac{x_m}{x}\\right)^{\\alpha},\\qquad x\\ge x_m.$$\n",
    "\n",
    "On a log–log plot, this tail is a straight line with slope $-\\alpha$.\n",
    "\n",
    "### 2.2 Typical real-world use cases\n",
    "- **Wealth / income** above a minimum threshold (upper tail behavior)\n",
    "- **Insurance claims** and large losses (catastrophic tail)\n",
    "- **City sizes** and firm sizes (upper tails)\n",
    "- **File sizes / network traffic** (bursty, heavy-tailed phenomena)\n",
    "- **Waiting times** in systems with rare extreme delays\n",
    "\n",
    "### 2.3 Relations to other distributions\n",
    "- **Power law / “scale-free”**: Pareto Type I is the canonical continuous power-law model.\n",
    "- **Log transform to exponential**: if $X\\sim\\mathrm{Pareto}(\\alpha,x_m)$ then\n",
    "  $$\\log\\left(\\frac{X}{x_m}\\right) \\sim \\mathrm{Exp}(\\text{rate}=\\alpha).$$\n",
    "  This is extremely useful for inference.\n",
    "- **Lomax (Pareto II)**: if $X\\sim\\mathrm{Pareto}(\\alpha,x_m)$ then $X-x_m$ follows a Lomax distribution.\n",
    "- **Generalized Pareto (GPD)**: Pareto is a special/heavy-tailed case closely related to extreme-value modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59847d43",
   "metadata": {},
   "source": [
    "## 3) Formal Definition\n",
    "\n",
    "Let $\\alpha>0$ and $x_m>0$. The **PDF** is\n",
    "\n",
    "$$\n",
    "f(x\\mid\\alpha,x_m)\n",
    "= \\alpha\\,x_m^{\\alpha}\\,x^{-(\\alpha+1)}\\,\\mathbf{1}\\{x\\ge x_m\\}.\n",
    "$$\n",
    "\n",
    "The **CDF** is\n",
    "\n",
    "$$\n",
    "F(x\\mid\\alpha,x_m)=\n",
    "\\begin{cases}\n",
    "0, & x < x_m,\\\\\n",
    "1 - \\left(\\frac{x_m}{x}\\right)^{\\alpha}, & x\\ge x_m.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The **survival function** (tail probability) is\n",
    "\n",
    "$$\\bar F(x) = 1-F(x) = \\left(\\frac{x_m}{x}\\right)^{\\alpha},\\qquad x\\ge x_m.$$\n",
    "\n",
    "The **quantile function** (inverse CDF) for $0<u<1$ is\n",
    "\n",
    "$$Q(u) = x_m (1-u)^{-1/\\alpha}.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dea97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_pdf(x: np.ndarray, alpha: float, xm: float) -> np.ndarray:\n",
    "    '''Pareto(Type I) PDF. Returns 0 for x < xm.'''\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    alpha = float(alpha)\n",
    "    xm = float(xm)\n",
    "\n",
    "    if alpha <= 0 or xm <= 0:\n",
    "        raise ValueError(\"Pareto parameters must satisfy alpha>0 and xm>0\")\n",
    "\n",
    "    out = np.zeros_like(x, dtype=float)\n",
    "    mask = x >= xm\n",
    "    # Use log space for stability\n",
    "    log_pdf = np.log(alpha) + alpha * np.log(xm) - (alpha + 1) * np.log(x[mask])\n",
    "    out[mask] = np.exp(log_pdf)\n",
    "    return out\n",
    "\n",
    "\n",
    "def pareto_sf(x: np.ndarray, alpha: float, xm: float) -> np.ndarray:\n",
    "    '''Survival function P(X>x).'''\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    alpha = float(alpha)\n",
    "    xm = float(xm)\n",
    "\n",
    "    if alpha <= 0 or xm <= 0:\n",
    "        raise ValueError(\"Pareto parameters must satisfy alpha>0 and xm>0\")\n",
    "\n",
    "    out = np.ones_like(x, dtype=float)\n",
    "    mask = x >= xm\n",
    "    z = alpha * (np.log(xm) - np.log(x[mask]))  # <= 0\n",
    "    out[mask] = np.exp(z)\n",
    "    out[~mask] = 1.0\n",
    "    return out\n",
    "\n",
    "\n",
    "def pareto_cdf(x: np.ndarray, alpha: float, xm: float) -> np.ndarray:\n",
    "    '''Pareto(Type I) CDF.'''\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    alpha = float(alpha)\n",
    "    xm = float(xm)\n",
    "\n",
    "    if alpha <= 0 or xm <= 0:\n",
    "        raise ValueError(\"Pareto parameters must satisfy alpha>0 and xm>0\")\n",
    "\n",
    "    out = np.zeros_like(x, dtype=float)\n",
    "    mask = x >= xm\n",
    "    z = alpha * (np.log(xm) - np.log(x[mask]))  # <= 0\n",
    "    out[mask] = -np.expm1(z)  # 1 - exp(z), stable when z ~ 0\n",
    "    return out\n",
    "\n",
    "\n",
    "def pareto_ppf(u: np.ndarray, alpha: float, xm: float) -> np.ndarray:\n",
    "    '''Quantile function (inverse CDF) for 0<u<1.'''\n",
    "    u = np.asarray(u, dtype=float)\n",
    "    alpha = float(alpha)\n",
    "    xm = float(xm)\n",
    "\n",
    "    if alpha <= 0 or xm <= 0:\n",
    "        raise ValueError(\"Pareto parameters must satisfy alpha>0 and xm>0\")\n",
    "    if np.any((u <= 0) | (u >= 1)):\n",
    "        raise ValueError(\"u must lie strictly in (0,1)\")\n",
    "\n",
    "    # Q(u) = xm * (1-u)^(-1/alpha)\n",
    "    return xm * np.exp(-np.log1p(-u) / alpha)\n",
    "\n",
    "\n",
    "def pareto_rvs(alpha: float, xm: float, size: int | tuple[int, ...], rng: np.random.Generator) -> np.ndarray:\n",
    "    '''NumPy-only Pareto sampler via inverse transform.'''\n",
    "    u = rng.random(size)\n",
    "    # u in [0,1); use 1-u in (0,1] so u==0 maps safely to xm.\n",
    "    return xm * np.exp(-np.log1p(-u) / float(alpha))\n",
    "\n",
    "\n",
    "# Quick sanity check: PDF integrates to 1\n",
    "alpha0, xm0 = 2.5, 1.0\n",
    "area, err = quad(lambda t: alpha0 * xm0**alpha0 / (t ** (alpha0 + 1)), xm0, np.inf)\n",
    "area, err\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd50a435",
   "metadata": {},
   "source": [
    "## 4) Moments & Properties\n",
    "\n",
    "### 4.1 Raw moments (and when they exist)\n",
    "For $k<\\alpha$ the $k$-th raw moment exists and is\n",
    "\n",
    "$$\\mathbb{E}[X^k] = \\frac{\\alpha\\,x_m^k}{\\alpha-k},\\qquad (k<\\alpha).$$\n",
    "\n",
    "If $k\\ge \\alpha$, the integral diverges and $\\mathbb{E}[X^k]=\\infty$.\n",
    "\n",
    "### 4.2 Mean, variance, skewness, kurtosis\n",
    "For $X\\sim\\mathrm{Pareto}(\\alpha,x_m)$:\n",
    "\n",
    "- **Mean** (exists for $\\alpha>1$)\n",
    "  $$\\mathbb{E}[X] = \\frac{\\alpha\\,x_m}{\\alpha-1}.$$\n",
    "\n",
    "- **Variance** (exists for $\\alpha>2$)\n",
    "  $$\\mathrm{Var}(X) = \\frac{\\alpha\\,x_m^2}{(\\alpha-1)^2(\\alpha-2)}.$$\n",
    "\n",
    "- **Skewness** (exists for $\\alpha>3$)\n",
    "  $$\\gamma_1 = \\frac{2(\\alpha+1)}{\\alpha-3}\\sqrt{\\frac{\\alpha-2}{\\alpha}}.$$\n",
    "\n",
    "- **Excess kurtosis** (exists for $\\alpha>4$)\n",
    "  $$\\gamma_2 = \\frac{6(\\alpha^3+\\alpha^2-6\\alpha-2)}{\\alpha(\\alpha-3)(\\alpha-4)}.$$\n",
    "\n",
    "Additional useful facts:\n",
    "\n",
    "- **Mode**: $x_m$\n",
    "- **Median**: $x_m\\,2^{1/\\alpha}$\n",
    "\n",
    "### 4.3 MGF / characteristic function\n",
    "- The MGF $M(t)=\\mathbb{E}[e^{tX}]$ **diverges for all $t>0$** (the tail is polynomial).\n",
    "- For $t<0$, the Laplace transform exists and can be expressed using the **upper incomplete gamma function** $\\Gamma(s,z)$:\n",
    "\n",
    "  $$M(t) = \\alpha(-t x_m)^{\\alpha}\\,\\Gamma(-\\alpha, -t x_m),\\qquad t<0.$$\n",
    "\n",
    "- The characteristic function exists for all real $t$ and admits a similar expression:\n",
    "\n",
    "  $$\\varphi(t) = \\alpha(-i t x_m)^{\\alpha}\\,\\Gamma(-\\alpha, -i t x_m).$$\n",
    "\n",
    "In practice, these are often evaluated numerically.\n",
    "\n",
    "### 4.4 Entropy\n",
    "The differential entropy is\n",
    "\n",
    "$$H(X) = \\log\\left(\\frac{x_m}{\\alpha}\\right) + 1 + \\frac{1}{\\alpha}.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ebb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_moments(alpha: float, xm: float) -> dict:\n",
    "    a = float(alpha)\n",
    "    xm = float(xm)\n",
    "    if a <= 0 or xm <= 0:\n",
    "        raise ValueError(\"Pareto parameters must satisfy alpha>0 and xm>0\")\n",
    "\n",
    "    mean = np.inf if a <= 1 else a * xm / (a - 1)\n",
    "    var = np.inf if a <= 2 else a * xm**2 / ((a - 1) ** 2 * (a - 2))\n",
    "    skew = np.nan if a <= 3 else (2 * (a + 1) / (a - 3)) * np.sqrt((a - 2) / a)\n",
    "    excess_kurt = (\n",
    "        np.nan\n",
    "        if a <= 4\n",
    "        else 6 * (a**3 + a**2 - 6 * a - 2) / (a * (a - 3) * (a - 4))\n",
    "    )\n",
    "\n",
    "    entropy = np.log(xm / a) + 1 + 1 / a\n",
    "    median = xm * 2 ** (1 / a)\n",
    "    mode = xm\n",
    "\n",
    "    return {\n",
    "        \"mean\": mean,\n",
    "        \"var\": var,\n",
    "        \"skew\": skew,\n",
    "        \"excess_kurtosis\": excess_kurt,\n",
    "        \"entropy\": entropy,\n",
    "        \"median\": median,\n",
    "        \"mode\": mode,\n",
    "    }\n",
    "\n",
    "\n",
    "alpha0, xm0 = 2.5, 1.0\n",
    "theo = pareto_moments(alpha0, xm0)\n",
    "\n",
    "dist = stats.pareto(b=alpha0, loc=0, scale=xm0)\n",
    "m, v, s, k = dist.stats(moments=\"mvsk\")\n",
    "\n",
    "theo, {\n",
    "    \"scipy_mean\": float(m),\n",
    "    \"scipy_var\": float(v),\n",
    "    \"scipy_skew\": float(s),\n",
    "    \"scipy_excess_kurt\": float(k),\n",
    "    \"scipy_entropy\": float(dist.entropy()),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c4b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moment existence in action: running averages can be unstable when moments are infinite.\n",
    "def running_mean(x: np.ndarray) -> np.ndarray:\n",
    "    return np.cumsum(x) / np.arange(1, len(x) + 1)\n",
    "\n",
    "\n",
    "xm_demo = 1.0\n",
    "alphas_demo = [0.8, 1.5, 3.0]\n",
    "n_demo = 30_000\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for a in alphas_demo:\n",
    "    x = pareto_rvs(alpha=a, xm=xm_demo, size=n_demo, rng=rng)\n",
    "    rm = running_mean(x)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=np.arange(1, n_demo + 1),\n",
    "            y=rm,\n",
    "            mode=\"lines\",\n",
    "            name=f\"alpha={a}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Running sample mean for different tail indices (same xm=1)\",\n",
    "    xaxis_title=\"n\",\n",
    "    yaxis_title=\"running mean\",\n",
    "    yaxis_type=\"log\",\n",
    "    width=950,\n",
    "    height=450,\n",
    ")\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c09e94e",
   "metadata": {},
   "source": [
    "## 5) Parameter Interpretation\n",
    "\n",
    "### 5.1 Shape $\\alpha$ (tail index)\n",
    "The survival function is\n",
    "\n",
    "$$\\Pr(X>x) = \\left(\\frac{x_m}{x}\\right)^{\\alpha}.$$\n",
    "\n",
    "So $\\alpha$ directly controls the **tail heaviness**:\n",
    "\n",
    "- smaller $\\alpha$  → heavier tail → extreme values are more common\n",
    "- larger $\\alpha$   → lighter tail → extremes decay faster\n",
    "\n",
    "Moment existence is controlled by $\\alpha$:\n",
    "\n",
    "- mean exists iff $\\alpha>1$\n",
    "- variance exists iff $\\alpha>2$\n",
    "- skewness exists iff $\\alpha>3$\n",
    "- excess kurtosis exists iff $\\alpha>4$\n",
    "\n",
    "### 5.2 Scale/minimum $x_m$\n",
    "The parameter $x_m$ is a **hard lower bound**. Increasing $x_m$ scales the distribution to the right.\n",
    "\n",
    "If $X\\sim\\mathrm{Pareto}(\\alpha, x_m)$ then $X/x_m\\sim\\mathrm{Pareto}(\\alpha, 1)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec793af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape changes: PDF curves for different alpha\n",
    "xm = 1.0\n",
    "x = np.geomspace(xm, 80 * xm, 600)\n",
    "\n",
    "alphas = [0.8, 1.2, 2.0, 5.0]\n",
    "\n",
    "fig = go.Figure()\n",
    "for a in alphas:\n",
    "    fig.add_trace(go.Scatter(x=x, y=pareto_pdf(x, a, xm), mode=\"lines\", name=f\"alpha={a}\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Pareto PDF for different alpha (xm=1)\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"density\",\n",
    "    xaxis_type=\"log\",\n",
    "    yaxis_type=\"log\",\n",
    "    width=950,\n",
    "    height=450,\n",
    ")\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f321ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tail straight line on log-log scale: survival function\n",
    "xm = 1.0\n",
    "x = np.geomspace(xm, 500 * xm, 600)\n",
    "\n",
    "alphas = [1.2, 2.0, 4.0]\n",
    "\n",
    "fig = go.Figure()\n",
    "for a in alphas:\n",
    "    fig.add_trace(go.Scatter(x=x, y=pareto_sf(x, a, xm), mode=\"lines\", name=f\"alpha={a}\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Pareto survival function P(X>x): log-log straight lines\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"P(X>x)\",\n",
    "    xaxis_type=\"log\",\n",
    "    yaxis_type=\"log\",\n",
    "    width=950,\n",
    "    height=450,\n",
    ")\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ddf137",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### 6.1 Expectation (general $k$-th moment)\n",
    "For $k\\in\\mathbb{R}$:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^k]\n",
    "= \\int_{x_m}^{\\infty} x^k\\,\\alpha x_m^{\\alpha}x^{-(\\alpha+1)}\\,dx\n",
    "= \\alpha x_m^{\\alpha}\\int_{x_m}^{\\infty} x^{k-\\alpha-1}\\,dx.\n",
    "$$\n",
    "\n",
    "The integral converges iff $k-\\alpha-1 < -1$, i.e. **iff $k<\\alpha$**.\n",
    "When it converges:\n",
    "\n",
    "$$\n",
    "\\alpha x_m^{\\alpha}\\int_{x_m}^{\\infty} x^{k-\\alpha-1}\\,dx\n",
    "= \\alpha x_m^{\\alpha}\\left[\\frac{x^{k-\\alpha}}{k-\\alpha}\\right]_{x_m}^{\\infty}\n",
    "= \\frac{\\alpha x_m^k}{\\alpha-k}.\n",
    "$$\n",
    "\n",
    "Plugging in $k=1$ gives the mean (requires $\\alpha>1$).\n",
    "\n",
    "### 6.2 Variance\n",
    "For $\\alpha>2$ we have\n",
    "\n",
    "$$\\mathrm{Var}(X) = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2.$$\n",
    "\n",
    "Using $\\mathbb{E}[X^2] = \\frac{\\alpha x_m^2}{\\alpha-2}$ and $\\mathbb{E}[X]=\\frac{\\alpha x_m}{\\alpha-1}$ yields\n",
    "\n",
    "$$\\mathrm{Var}(X) = \\frac{\\alpha x_m^2}{(\\alpha-1)^2(\\alpha-2)}.$$\n",
    "\n",
    "### 6.3 Likelihood and MLE\n",
    "For i.i.d. data $x_1,\\dots,x_n$ with $x_i\\ge x_m$:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\alpha,x_m) = \\prod_{i=1}^n \\alpha x_m^{\\alpha} x_i^{-(\\alpha+1)}.\n",
    "$$\n",
    "\n",
    "The log-likelihood is\n",
    "\n",
    "$$\n",
    "\\ell(\\alpha,x_m)= n\\log\\alpha + n\\alpha\\log x_m - (\\alpha+1)\\sum_{i=1}^n \\log x_i,\n",
    "$$\n",
    "\n",
    "with the constraint $x_m\\le \\min_i x_i$.\n",
    "\n",
    "**If $x_m$ is known**, differentiate w.r.t. $\\alpha$ and set to zero:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell}{\\partial \\alpha} = \\frac{n}{\\alpha} + n\\log x_m - \\sum_{i=1}^n \\log x_i = 0\n",
    "\\quad\\Rightarrow\\quad\n",
    "\\hat{\\alpha} = \\frac{n}{\\sum_{i=1}^n \\log(x_i/x_m)}.\n",
    "$$\n",
    "\n",
    "**If $x_m$ is unknown**, the likelihood increases with $x_m$ (for fixed $\\alpha$) subject to $x_m\\le \\min_i x_i$, so\n",
    "\n",
    "$$\\hat{x}_m = \\min_i x_i,$$\n",
    "\n",
    "and then plug into the formula for $\\hat{\\alpha}$.\n",
    "\n",
    "**Log-scale trick**\n",
    "\n",
    "Define $Y_i = \\log(x_i/x_m)$. Under the Pareto model, $Y_i\\sim\\mathrm{Exp}(\\text{rate}=\\alpha)$.\n",
    "Inference for $\\alpha$ can be done using exponential-family tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d078c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_mle_alpha(x: np.ndarray, xm: float) -> float:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    xm = float(xm)\n",
    "    if xm <= 0:\n",
    "        raise ValueError(\"xm must be > 0\")\n",
    "    if np.any(x < xm):\n",
    "        raise ValueError(\"All observations must satisfy x >= xm\")\n",
    "    s = np.sum(np.log(x / xm))\n",
    "    if s <= 0:\n",
    "        raise ValueError(\"Sum log(x/xm) must be positive\")\n",
    "    return len(x) / s\n",
    "\n",
    "\n",
    "def pareto_mle(x: np.ndarray) -> tuple[float, float]:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    xm_hat = float(np.min(x))\n",
    "    alpha_hat = pareto_mle_alpha(x, xm_hat)\n",
    "    return alpha_hat, xm_hat\n",
    "\n",
    "\n",
    "# Demonstrate MLE on synthetic data\n",
    "alpha_true, xm_true = 2.5, 1.0\n",
    "n = 4000\n",
    "x = pareto_rvs(alpha=alpha_true, xm=xm_true, size=n, rng=rng)\n",
    "\n",
    "alpha_hat, xm_hat = pareto_mle(x)\n",
    "scipy_b_hat, scipy_loc_hat, scipy_scale_hat = stats.pareto.fit(x, floc=0)\n",
    "\n",
    "{\n",
    "    \"true\": (alpha_true, xm_true),\n",
    "    \"mle\": (alpha_hat, xm_hat),\n",
    "    \"scipy_fit_floc0\": (float(scipy_b_hat), float(scipy_scale_hat)),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba10b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood shape in alpha (xm fixed at its MLE)\n",
    "def pareto_loglik_alpha(alpha: float, x: np.ndarray, xm: float) -> float:\n",
    "    a = float(alpha)\n",
    "    if a <= 0:\n",
    "        return -np.inf\n",
    "    if np.any(x < xm):\n",
    "        return -np.inf\n",
    "    n = len(x)\n",
    "    return n * np.log(a) + n * a * np.log(xm) - (a + 1) * np.sum(np.log(x))\n",
    "\n",
    "\n",
    "grid = np.linspace(0.2, 8.0, 400)\n",
    "ll = np.array([pareto_loglik_alpha(a, x, xm_hat) for a in grid])\n",
    "\n",
    "fig = px.line(x=grid, y=ll, title=\"Log-likelihood as a function of alpha (xm fixed)\")\n",
    "fig.add_vline(alpha_hat, line_dash=\"dash\", line_color=\"black\")\n",
    "fig.update_layout(xaxis_title=\"alpha\", yaxis_title=\"log-likelihood\", width=950, height=420)\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d1c33b",
   "metadata": {},
   "source": [
    "## 7) Sampling & Simulation\n",
    "\n",
    "### 7.1 Inverse transform sampling (NumPy-only)\n",
    "From the CDF $F(x)=1-(x_m/x)^{\\alpha}$ for $x\\ge x_m$:\n",
    "\n",
    "$$U = F(X) = 1 - \\left(\\frac{x_m}{X}\\right)^{\\alpha}$$\n",
    "\n",
    "Solve for $X$:\n",
    "\n",
    "$$X = x_m(1-U)^{-1/\\alpha},\\qquad U\\sim\\mathrm{Unif}(0,1).$$\n",
    "\n",
    "**Algorithm**\n",
    "1. Draw $U\\sim\\mathrm{Unif}(0,1)$.\n",
    "2. Return $X = x_m(1-U)^{-1/\\alpha}$.\n",
    "\n",
    "### 7.2 Exponential connection (also NumPy-only)\n",
    "Since $\\log(X/x_m)\\sim\\mathrm{Exp}(\\text{rate}=\\alpha)$, you can also sample via\n",
    "\n",
    "$$X = x_m\\exp(E/\\alpha),\\qquad E\\sim\\mathrm{Exp}(1).$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f980f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_rvs_via_exponential(alpha: float, xm: float, size: int | tuple[int, ...], rng: np.random.Generator) -> np.ndarray:\n",
    "    e = rng.exponential(scale=1.0, size=size)\n",
    "    return float(xm) * np.exp(e / float(alpha))\n",
    "\n",
    "\n",
    "# Validate that both samplers agree (Monte Carlo)\n",
    "alpha0, xm0 = 2.0, 1.0\n",
    "n = 100_000\n",
    "\n",
    "x1 = pareto_rvs(alpha0, xm0, size=n, rng=rng)\n",
    "x2 = pareto_rvs_via_exponential(alpha0, xm0, size=n, rng=rng)\n",
    "\n",
    "# Compare a few quantiles\n",
    "qs = [0.5, 0.9, 0.99]\n",
    "q1 = np.quantile(x1, qs)\n",
    "q2 = np.quantile(x2, qs)\n",
    "qt = pareto_ppf(np.array(qs), alpha0, xm0)\n",
    "\n",
    "qs, q1, q2, qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446bed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The log-scale exponential relationship\n",
    "alpha0, xm0 = 3.0, 1.0\n",
    "x = pareto_rvs(alpha0, xm0, size=50_000, rng=rng)\n",
    "y = np.log(x / xm0)\n",
    "\n",
    "grid = np.linspace(0, np.quantile(y, 0.995), 500)\n",
    "exp_pdf = alpha0 * np.exp(-alpha0 * grid)  # Exp(rate=alpha0)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=y, nbinsx=80, histnorm=\"probability density\", name=\"log(X/xm)\", opacity=0.6))\n",
    "fig.add_trace(go.Scatter(x=grid, y=exp_pdf, mode=\"lines\", name=\"Exp(rate=alpha)\", line=dict(width=3)))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"If X ~ Pareto(alpha,xm), then log(X/xm) ~ Exponential(rate=alpha)\",\n",
    "    xaxis_title=\"y = log(X/xm)\",\n",
    "    yaxis_title=\"density\",\n",
    "    width=950,\n",
    "    height=420,\n",
    ")\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f8dcaa",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We’ll visualize:\n",
    "- **PDF** (log–log to emphasize tail)\n",
    "- **CDF**\n",
    "- **Monte Carlo samples** vs theory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, xm = 2.5, 1.0\n",
    "x = np.geomspace(xm, 200 * xm, 700)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=pareto_pdf(x, alpha, xm), mode=\"lines\", name=\"PDF\"))\n",
    "fig.update_layout(\n",
    "    title=f\"Pareto PDF (alpha={alpha}, xm={xm})\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"density\",\n",
    "    xaxis_type=\"log\",\n",
    "    yaxis_type=\"log\",\n",
    "    width=950,\n",
    "    height=420,\n",
    ")\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be32beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=pareto_cdf(x, alpha, xm), mode=\"lines\", name=\"CDF\"))\n",
    "fig.update_layout(\n",
    "    title=f\"Pareto CDF (alpha={alpha}, xm={xm})\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"F(x)\",\n",
    "    xaxis_type=\"log\",\n",
    "    width=950,\n",
    "    height=420,\n",
    ")\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf4b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo: histogram + theoretical PDF overlay\n",
    "n = 80_000\n",
    "xs = pareto_rvs(alpha, xm, size=n, rng=rng)\n",
    "\n",
    "x_max = np.quantile(xs, 0.995)\n",
    "x_grid = np.geomspace(xm, x_max, 600)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=xs,\n",
    "        nbinsx=120,\n",
    "        histnorm=\"probability density\",\n",
    "        name=\"samples\",\n",
    "        opacity=0.6,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=x_grid, y=pareto_pdf(x_grid, alpha, xm), mode=\"lines\", name=\"theory\", line=dict(width=3)))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Samples vs theory (alpha={alpha}, xm={xm})\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"density\",\n",
    "    xaxis_type=\"log\",\n",
    "    yaxis_type=\"log\",\n",
    "    width=950,\n",
    "    height=450,\n",
    ")\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346382c8",
   "metadata": {},
   "source": [
    "## 9) SciPy Integration\n",
    "\n",
    "SciPy’s Pareto is used as:\n",
    "\n",
    "```python\n",
    "dist = scipy.stats.pareto(b=alpha, loc=0, scale=xm)\n",
    "```\n",
    "\n",
    "With `loc=0`, this matches the textbook Pareto(Type I) on $[x_m,\\infty)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15335af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, xm = 2.5, 1.0\n",
    "dist = stats.pareto(b=alpha, loc=0, scale=xm)\n",
    "\n",
    "x = np.geomspace(xm, 50 * xm, 300)\n",
    "\n",
    "# pdf / cdf\n",
    "pdf_vals = dist.pdf(x)\n",
    "cdf_vals = dist.cdf(x)\n",
    "\n",
    "# sampling\n",
    "xs = dist.rvs(size=5, random_state=rng)\n",
    "\n",
    "pdf_vals[:3], cdf_vals[:3], xs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f64a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting\n",
    "alpha_true, xm_true = 2.0, 1.5\n",
    "x = stats.pareto(b=alpha_true, loc=0, scale=xm_true).rvs(size=5000, random_state=rng)\n",
    "\n",
    "# If you allow loc to float, it may absorb part of the minimum; usually fix loc=0.\n",
    "b_hat, loc_hat, scale_hat = stats.pareto.fit(x)  # free loc and scale\n",
    "b_hat0, loc_hat0, scale_hat0 = stats.pareto.fit(x, floc=0)  # force loc=0\n",
    "\n",
    "# Compare to MLE (xm_hat=min(x))\n",
    "alpha_mle, xm_mle = pareto_mle(x)\n",
    "\n",
    "{\n",
    "    \"true\": (alpha_true, xm_true),\n",
    "    \"fit_free_loc\": (float(b_hat), float(loc_hat), float(scale_hat)),\n",
    "    \"fit_floc0\": (float(b_hat0), float(loc_hat0), float(scale_hat0)),\n",
    "    \"mle\": (alpha_mle, xm_mle),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb7c215",
   "metadata": {},
   "source": [
    "## 10) Statistical Use Cases\n",
    "\n",
    "### 10.1 Hypothesis testing / confidence intervals (tail index)\n",
    "With known $x_m$, define $Y_i = \\log(x_i/x_m)$. Under the Pareto model, $Y_i\\sim\\mathrm{Exp}(\\text{rate}=\\alpha)$.\n",
    "\n",
    "Let $S = \\sum_i Y_i$. Then $S\\sim\\mathrm{Gamma}(\\text{shape}=n,\\text{rate}=\\alpha)$, and\n",
    "\n",
    "$$2\\alpha S \\sim \\chi^2_{2n}.$$\n",
    "\n",
    "This gives an **exact confidence interval** for $\\alpha$ by inverting chi-square quantiles.\n",
    "\n",
    "### 10.2 Bayesian modeling\n",
    "Again with $Y_i=\\log(x_i/x_m)$, the likelihood is exponential with rate $\\alpha$.\n",
    "\n",
    "A conjugate prior is **Gamma**:\n",
    "\n",
    "$$\\alpha \\sim \\mathrm{Gamma}(a_0, b_0)\\quad\\text{(shape–rate)}.$$\n",
    "\n",
    "Posterior is\n",
    "\n",
    "$$\\alpha\\mid\\text{data} \\sim \\mathrm{Gamma}(a_0+n,\\; b_0 + \\sum_i Y_i).$$\n",
    "\n",
    "### 10.3 Generative modeling (Pareto principle)\n",
    "For $\\alpha>1$, the Pareto distribution implies a Lorenz curve\n",
    "\n",
    "$$L(p) = 1 - (1-p)^{(\\alpha-1)/\\alpha}.$$\n",
    "\n",
    "The share of total mass held by the **top** fraction $q$ is\n",
    "\n",
    "$$\\text{top-share}(q) = q^{(\\alpha-1)/\\alpha}.$$\n",
    "\n",
    "This connects $\\alpha$ directly to “80/20”-style statements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9517450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "\n",
    "# Hypothesis test + exact CI for alpha (assuming xm known)\n",
    "alpha_true, xm = 2.2, 1.0\n",
    "n = 800\n",
    "\n",
    "x = stats.pareto(b=alpha_true, loc=0, scale=xm).rvs(size=n, random_state=rng)\n",
    "y = np.log(x / xm)\n",
    "S = float(np.sum(y))\n",
    "\n",
    "alpha_hat = n / S\n",
    "\n",
    "# 95% exact CI via chi-square inversion\n",
    "delta = 0.05\n",
    "q_low = chi2.ppf(delta / 2, df=2 * n)\n",
    "q_high = chi2.ppf(1 - delta / 2, df=2 * n)\n",
    "alpha_low = q_low / (2 * S)\n",
    "alpha_high = q_high / (2 * S)\n",
    "\n",
    "# Two-sided p-value for H0: alpha = alpha0\n",
    "alpha0 = 2.0\n",
    "T = 2 * alpha0 * S\n",
    "p_two_sided = 2 * min(chi2.cdf(T, df=2 * n), 1 - chi2.cdf(T, df=2 * n))\n",
    "\n",
    "{\n",
    "    \"alpha_hat\": alpha_hat,\n",
    "    \"ci_95\": (alpha_low, alpha_high),\n",
    "    \"test_H0_alpha=2.0_p\": p_two_sided,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91b74d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian update for alpha with a Gamma prior (shape-rate)\n",
    "a0, b0 = 2.0, 1.0  # weak-ish prior\n",
    "\n",
    "a_post = a0 + n\n",
    "b_post = b0 + S\n",
    "\n",
    "prior = stats.gamma(a=a0, scale=1 / b0)\n",
    "post = stats.gamma(a=a_post, scale=1 / b_post)\n",
    "\n",
    "grid = np.linspace(0.2, np.quantile(post.rvs(size=50_000, random_state=rng), 0.995), 600)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=grid, y=prior.pdf(grid), mode=\"lines\", name=f\"Prior Gamma({a0:.0f},{b0:.0f})\"))\n",
    "fig.add_trace(go.Scatter(x=grid, y=post.pdf(grid), mode=\"lines\", name=f\"Posterior Gamma({a_post:.0f},{b_post:.1f})\", line=dict(width=3)))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Posterior over alpha (Pareto tail index)\",\n",
    "    xaxis_title=\"alpha\",\n",
    "    yaxis_title=\"density\",\n",
    "    width=950,\n",
    "    height=420,\n",
    ")\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86546b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative modeling: calibrate alpha to match a target top-share (e.g. 80/20)\n",
    "target_q = 0.2\n",
    "target_share = 0.8\n",
    "\n",
    "# Solve target_share = q^((alpha-1)/alpha)\n",
    "# Let r = (alpha-1)/alpha = 1 - 1/alpha.\n",
    "r = np.log(target_share) / np.log(target_q)\n",
    "alpha_8020 = 1 / (1 - r)\n",
    "\n",
    "alpha_8020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eaa705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate and compare empirical top-share and Lorenz curve\n",
    "alpha, xm = float(alpha_8020), 1.0\n",
    "n = 200_000\n",
    "w = pareto_rvs(alpha, xm, size=n, rng=rng)\n",
    "\n",
    "# Empirical top-q share\n",
    "q = 0.2\n",
    "cutoff = np.quantile(w, 1 - q)\n",
    "top_share_emp = w[w >= cutoff].sum() / w.sum()\n",
    "\n",
    "# Theoretical top share\n",
    "top_share_theory = q ** ((alpha - 1) / alpha)\n",
    "\n",
    "top_share_emp, top_share_theory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c501b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lorenz curve: empirical vs theoretical\n",
    "w_sorted = np.sort(w)\n",
    "cum = np.cumsum(w_sorted)\n",
    "cum = np.insert(cum, 0, 0.0)\n",
    "cum = cum / cum[-1]\n",
    "\n",
    "p = np.linspace(0, 1, len(cum))\n",
    "lorenz_theory = 1 - (1 - p) ** ((alpha - 1) / alpha)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=p, y=cum, mode=\"lines\", name=\"empirical\"))\n",
    "fig.add_trace(go.Scatter(x=p, y=lorenz_theory, mode=\"lines\", name=\"theoretical\", line=dict(dash=\"dash\")))\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode=\"lines\", name=\"equality\", line=dict(color=\"black\", dash=\"dot\")))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Lorenz curve for Pareto(alpha={alpha:.3f})\",\n",
    "    xaxis_title=\"population share p\",\n",
    "    yaxis_title=\"wealth share L(p)\",\n",
    "    width=950,\n",
    "    height=450,\n",
    ")\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14775260",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Invalid parameters**: $\\alpha\\le 0$ or $x_m\\le 0$ is not a valid Pareto distribution.\n",
    "- **Infinite moments are not a corner case**:\n",
    "  - if $\\alpha\\le 1$, the mean is infinite\n",
    "  - if $1<\\alpha\\le 2$, the mean exists but the variance is infinite\n",
    "  Many “moment-based” summaries (sample mean/variance) can be unstable.\n",
    "- **Threshold choice ($x_m$) in real data**: Pareto is usually a *tail model*. Choosing the cutoff is a modeling decision;\n",
    "  fitting a Pareto to the entire distribution can be misleading.\n",
    "- **Fitting with `loc` free in SciPy**: letting `loc` float can absorb part of the minimum and change the interpretation.\n",
    "  If you want the textbook model, use `floc=0`.\n",
    "- **Numerical overflow in simulation/plots**: for small $\\alpha$, extremely large samples occur.\n",
    "  Use log-scales and consider clipping for visualization (never for inference).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972058ef",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `pareto` is a continuous distribution on $[x_m,\\infty)$ with **power-law tail** $\\Pr(X>x)=(x_m/x)^{\\alpha}$.\n",
    "- The tail index $\\alpha$ controls both **extremes** and **moment existence** (mean requires $\\alpha>1$, variance requires $\\alpha>2$, ...).\n",
    "- Sampling is simple via **inverse CDF**: $X=x_m(1-U)^{-1/\\alpha}$.\n",
    "- With known $x_m$, inference for $\\alpha$ becomes inference for an **exponential rate** on $\\log(X/x_m)$.\n",
    "- SciPy provides a solid reference implementation: `scipy.stats.pareto`.\n",
    "\n",
    "**References**\n",
    "- SciPy documentation: `scipy.stats.pareto`\n",
    "- Embrechts, Klüppelberg, Mikosch (1997). *Modelling Extremal Events*.\n",
    "- Newman (2005). *Power laws, Pareto distributions and Zipf's law*.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
