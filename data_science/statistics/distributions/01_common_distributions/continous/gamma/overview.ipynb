{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gamma distribution\n",
    "\n",
    "The Gamma distribution is a flexible **continuous** distribution on positive real numbers. It’s a natural model for **waiting times**, **lifetimes**, and other **positive, right-skewed** quantities.\n",
    "\n",
    "---\n",
    "\n",
    "## 1) Title & classification\n",
    "\n",
    "| Item | Value |\n",
    "|---|---|\n",
    "| Name | Gamma (`gamma`) |\n",
    "| Type | Continuous |\n",
    "| Support | $x \\in (0,\\infty)$ |\n",
    "| Parameters (common) | shape $\\alpha>0$, scale $\\theta>0$ |\n",
    "| Alternative | shape $\\alpha>0$, rate $\\beta = 1/\\theta > 0$ |\n",
    "\n",
    "### What you’ll be able to do after this notebook\n",
    "\n",
    "- recognize when a Gamma model makes sense (and when it doesn’t)\n",
    "- write the PDF/CDF and compute key moments\n",
    "- interpret how $(\\alpha, \\theta)$ change the shape\n",
    "- derive the mean/variance and the log-likelihood\n",
    "- sample from a Gamma **using NumPy only** (Marsaglia–Tsang)\n",
    "- use `scipy.stats.gamma` for inference and simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.special import gammainc, gammaln, psi\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Intuition & motivation\n",
    "\n",
    "### What it models\n",
    "\n",
    "A classic story:\n",
    "\n",
    "- Events arrive according to a Poisson process with rate $\\lambda$.\n",
    "- The waiting time between events is exponential.\n",
    "- The **waiting time until the $k$-th event** is **Gamma**.\n",
    "\n",
    "Even when that exact Poisson-process story isn’t literally true, Gamma is often a good model for **positive** quantities with **right skew**.\n",
    "\n",
    "### Typical real-world use cases\n",
    "\n",
    "- **Reliability / survival**: time-to-failure for components under certain assumptions\n",
    "- **Queueing / service times**: durations that are sums of smaller random delays\n",
    "- **Insurance / finance**: positive claim sizes, severities, waiting times\n",
    "- **Hydrology / weather**: rainfall amounts over fixed intervals\n",
    "- **Bayesian stats**: priors for **rates** (Poisson/exponential) and **precisions**\n",
    "\n",
    "### Relations to other distributions\n",
    "\n",
    "- **Exponential**: $\\text{Gamma}(\\alpha=1,\\theta)$\n",
    "- **Erlang** (integer shape): $\\alpha=k\\in\\{1,2,\\dots\\}$; sum of $k$ exponentials\n",
    "- **Chi-square**: if $X\\sim\\chi^2_\\nu$, then $X \\sim \\text{Gamma}(\\alpha=\\nu/2,\\theta=2)$\n",
    "- **Additivity**: if $X_i\\sim\\text{Gamma}(\\alpha_i,\\theta)$ i.i.d. with *shared scale* $\\theta$, then $\\sum_i X_i\\sim\\text{Gamma}(\\sum_i\\alpha_i,\\theta)$\n",
    "- **Normal approximation**: for large $\\alpha$, Gamma becomes close to normal (by CLT-like behavior)\n",
    "\n",
    "A practical note: different fields use **scale** $\\theta$ or **rate** $\\beta=1/\\theta$. Always check which one a library/API expects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Formal definition\n",
    "\n",
    "We use the **shape–scale** parameterization: $\\alpha>0$ (shape), $\\theta>0$ (scale).\n",
    "\n",
    "### Gamma function\n",
    "\n",
    "$$\n",
    "\\Gamma(\\alpha) = \\int_0^{\\infty} u^{\\alpha-1} e^{-u}\\,du\n",
    "$$\n",
    "\n",
    "### PDF\n",
    "\n",
    "For $x>0$:\n",
    "$$\n",
    "f(x\\mid\\alpha,\\theta)\n",
    "= \\frac{1}{\\Gamma(\\alpha)\\,\\theta^{\\alpha}}\\,x^{\\alpha-1} e^{-x/\\theta}\n",
    "\\quad (x>0)\n",
    "$$\n",
    "\n",
    "and $f(x)=0$ for $x\\le 0$.\n",
    "\n",
    "### CDF\n",
    "\n",
    "The CDF can be written using the **lower incomplete gamma function**. A convenient standard form uses the **regularized** lower incomplete gamma:\n",
    "$$\n",
    "F(x\\mid\\alpha,\\theta) = P\\left(\\alpha, \\frac{x}{\\theta}\\right)\n",
    "= \\frac{\\gamma\\left(\\alpha, x/\\theta\\right)}{\\Gamma(\\alpha)}\n",
    "$$\n",
    "where $\\gamma(\\alpha, z)=\\int_0^z u^{\\alpha-1}e^{-u}\\,du$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_logpdf(x, alpha, theta):\n",
    "    \"\"\"Log-PDF of Gamma(alpha, theta) with support (0, inf).\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    alpha = float(alpha)\n",
    "    theta = float(theta)\n",
    "    if alpha <= 0 or theta <= 0:\n",
    "        raise ValueError(\"alpha and theta must be > 0\")\n",
    "\n",
    "    logpdf = np.full_like(x, -np.inf, dtype=float)\n",
    "    mask = x > 0\n",
    "    logpdf[mask] = (\n",
    "        (alpha - 1) * np.log(x[mask]) - x[mask] / theta - gammaln(alpha) - alpha * np.log(theta)\n",
    "    )\n",
    "    return logpdf\n",
    "\n",
    "\n",
    "def gamma_pdf(x, alpha, theta):\n",
    "    return np.exp(gamma_logpdf(x, alpha, theta))\n",
    "\n",
    "\n",
    "def gamma_cdf(x, alpha, theta):\n",
    "    \"\"\"CDF via the regularized lower incomplete gamma P(alpha, x/theta).\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    alpha = float(alpha)\n",
    "    theta = float(theta)\n",
    "    if alpha <= 0 or theta <= 0:\n",
    "        raise ValueError(\"alpha and theta must be > 0\")\n",
    "\n",
    "    cdf = np.zeros_like(x, dtype=float)\n",
    "    mask = x > 0\n",
    "    cdf[mask] = gammainc(alpha, x[mask] / theta)\n",
    "    return cdf\n",
    "\n",
    "\n",
    "def gamma_entropy(alpha, theta):\n",
    "    \"\"\"Differential entropy of Gamma(alpha, theta).\"\"\"\n",
    "    alpha = float(alpha)\n",
    "    theta = float(theta)\n",
    "    if alpha <= 0 or theta <= 0:\n",
    "        raise ValueError(\"alpha and theta must be > 0\")\n",
    "\n",
    "    return alpha + np.log(theta) + gammaln(alpha) + (1 - alpha) * psi(alpha)\n",
    "\n",
    "\n",
    "def gamma_mgf(t, alpha, theta):\n",
    "    \"\"\"MGF M_X(t) for t < 1/theta; diverges for t >= 1/theta.\"\"\"\n",
    "    t = np.asarray(t, dtype=float)\n",
    "    alpha = float(alpha)\n",
    "    theta = float(theta)\n",
    "    if alpha <= 0 or theta <= 0:\n",
    "        raise ValueError(\"alpha and theta must be > 0\")\n",
    "\n",
    "    out = np.full_like(t, np.inf, dtype=float)\n",
    "    mask = t < 1 / theta\n",
    "    out[mask] = (1 - theta * t[mask]) ** (-alpha)\n",
    "    return out\n",
    "\n",
    "\n",
    "def gamma_cf(t, alpha, theta):\n",
    "    \"\"\"Characteristic function phi_X(t).\"\"\"\n",
    "    t = np.asarray(t, dtype=float)\n",
    "    alpha = float(alpha)\n",
    "    theta = float(theta)\n",
    "    if alpha <= 0 or theta <= 0:\n",
    "        raise ValueError(\"alpha and theta must be > 0\")\n",
    "\n",
    "    return (1 - 1j * theta * t) ** (-alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Moments & properties\n",
    "\n",
    "For $X\\sim\\text{Gamma}(\\alpha,\\theta)$ (shape–scale):\n",
    "\n",
    "| Quantity | Value |\n",
    "|---|---|\n",
    "| Mean | $\\mathbb{E}[X]=\\alpha\\theta$ |\n",
    "| Variance | $\\mathrm{Var}(X)=\\alpha\\theta^2$ |\n",
    "| Skewness | $\\gamma_1 = \\frac{2}{\\sqrt{\\alpha}}$ |\n",
    "| Excess kurtosis | $\\gamma_2 = \\frac{6}{\\alpha}$ (so kurtosis $=3+6/\\alpha$) |\n",
    "| Mode | $(\\alpha-1)\\theta$ for $\\alpha\\ge 1$ (otherwise at 0+) |\n",
    "| MGF | $M_X(t)=(1-\\theta t)^{-\\alpha}$ for $t<1/\\theta$ |\n",
    "| CF | $\\varphi_X(t)=(1-i\\theta t)^{-\\alpha}$ |\n",
    "| Entropy | $H = \\alpha + \\log\\theta + \\log\\Gamma(\\alpha) + (1-\\alpha)\\psi(\\alpha)$ |\n",
    "\n",
    "Key closure properties:\n",
    "\n",
    "- **Scaling**: if $X\\sim\\text{Gamma}(\\alpha,\\theta)$ and $c>0$, then $cX\\sim\\text{Gamma}(\\alpha,c\\theta)$.\n",
    "- **Additivity (shared scale)**: if $X_i\\sim\\text{Gamma}(\\alpha_i,\\theta)$ independent, then $\\sum_i X_i\\sim\\text{Gamma}(\\sum_i\\alpha_i,\\theta)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, theta = 2.5, 1.3\n",
    "\n",
    "mean_theory = alpha * theta\n",
    "var_theory = alpha * theta**2\n",
    "skew_theory = 2 / np.sqrt(alpha)\n",
    "excess_kurt_theory = 6 / alpha\n",
    "entropy_theory = gamma_entropy(alpha, theta)\n",
    "\n",
    "mean_theory, var_theory, skew_theory, excess_kurt_theory, entropy_theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Parameter interpretation\n",
    "\n",
    "### Shape $\\alpha$\n",
    "\n",
    "- Controls **how concentrated** the mass is and how quickly the density rises from 0.\n",
    "- If $\\alpha=1$, the Gamma becomes **exponential** (memoryless).\n",
    "- If $0<\\alpha<1$, the density has a **singularity at 0** (it blows up as $x\\to 0^+$) and the distribution is highly right-skewed.\n",
    "- As $\\alpha$ increases, the distribution becomes more symmetric and eventually looks close to normal.\n",
    "\n",
    "### Scale $\\theta$ (or rate $\\beta=1/\\theta$)\n",
    "\n",
    "- **Scale** stretches/compresses the distribution horizontally.\n",
    "- Mean and standard deviation scale linearly with $\\theta$:\n",
    "  - $\\mathbb{E}[X]=\\alpha\\theta$\n",
    "  - $\\mathrm{SD}(X)=\\sqrt{\\alpha}\\,\\theta$\n",
    "\n",
    "A good mental model: $\\alpha$ affects the *shape*, $\\theta$ affects the *units / scale*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF: changing shape alpha (keep theta fixed)\n",
    "theta_fixed = 1.0\n",
    "alphas = [0.5, 1.0, 2.0, 5.0]\n",
    "\n",
    "x = np.linspace(1e-6, 12, 600)\n",
    "fig = go.Figure()\n",
    "for a in alphas:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=gamma_pdf(x, a, theta_fixed),\n",
    "            mode=\"lines\",\n",
    "            name=f\"α={a:g}, θ={theta_fixed:g}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Gamma PDF: effect of the shape α (scale θ=1)\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"pdf\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF: changing scale theta (keep alpha fixed)\n",
    "alpha_fixed = 2.0\n",
    "thetas = [0.5, 1.0, 2.0]\n",
    "\n",
    "x = np.linspace(1e-6, 20, 700)\n",
    "fig = go.Figure()\n",
    "for th in thetas:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=gamma_pdf(x, alpha_fixed, th),\n",
    "            mode=\"lines\",\n",
    "            name=f\"α={alpha_fixed:g}, θ={th:g}\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_vline(\n",
    "        x=alpha_fixed * th,\n",
    "        line_dash=\"dot\",\n",
    "        annotation_text=f\"mean={alpha_fixed * th:.2f}\",\n",
    "        annotation_position=\"top\",\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Gamma PDF: effect of the scale θ (shape α=2)\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"pdf\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### Expectation\n",
    "\n",
    "Start from the definition (for $X\\sim\\text{Gamma}(\\alpha,\\theta)$):\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X]\n",
    "= \\int_0^\\infty x\\, f(x\\mid\\alpha,\\theta)\\,dx\n",
    "= \\frac{1}{\\Gamma(\\alpha)\\theta^\\alpha} \\int_0^\\infty x^{\\alpha} e^{-x/\\theta}\\,dx\n",
    "$$\n",
    "\n",
    "Substitute $u=x/\\theta$ (so $x=\\theta u$, $dx=\\theta du$):\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X]\n",
    "= \\frac{1}{\\Gamma(\\alpha)\\theta^\\alpha} \\int_0^\\infty (\\theta u)^{\\alpha} e^{-u}\\, \\theta du\n",
    "= \\frac{\\theta}{\\Gamma(\\alpha)} \\int_0^\\infty u^{\\alpha} e^{-u}\\,du\n",
    "= \\frac{\\theta\\,\\Gamma(\\alpha+1)}{\\Gamma(\\alpha)}\n",
    "= \\theta\\alpha.\n",
    "$$\n",
    "\n",
    "So $\\mathbb{E}[X]=\\alpha\\theta$.\n",
    "\n",
    "### Variance\n",
    "\n",
    "Similarly,\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^2]\n",
    "= \\frac{1}{\\Gamma(\\alpha)\\theta^\\alpha}\\int_0^\\infty x^{\\alpha+1} e^{-x/\\theta}\\,dx\n",
    "= \\theta^2\\frac{\\Gamma(\\alpha+2)}{\\Gamma(\\alpha)}\n",
    "= \\theta^2\\alpha(\\alpha+1).\n",
    "$$\n",
    "\n",
    "Then:\n",
    "$$\n",
    "\\mathrm{Var}(X)=\\mathbb{E}[X^2] - \\mathbb{E}[X]^2\n",
    "= \\theta^2\\alpha(\\alpha+1) - (\\alpha\\theta)^2\n",
    "= \\alpha\\theta^2.\n",
    "$$\n",
    "\n",
    "### Likelihood (i.i.d. sample)\n",
    "\n",
    "Let $x_1,\\dots,x_n$ be i.i.d. from $\\text{Gamma}(\\alpha,\\theta)$ with $x_i>0$.\n",
    "\n",
    "The log-likelihood is:\n",
    "$$\n",
    "\\ell(\\alpha,\\theta)\n",
    "= \\sum_{i=1}^n \\log f(x_i\\mid\\alpha,\\theta)\n",
    "= (\\alpha-1)\\sum_i \\log x_i - \\frac{1}{\\theta}\\sum_i x_i - n\\big(\\log\\Gamma(\\alpha) + \\alpha\\log\\theta\\big).\n",
    "$$\n",
    "\n",
    "**MLE for $\\theta$ given $\\alpha$** comes from setting $\\partial\\ell/\\partial\\theta = 0$:\n",
    "$$\n",
    "\\hat{\\theta}(\\alpha) = \\frac{\\bar{x}}{\\alpha}.\n",
    "$$\n",
    "\n",
    "Solving for $\\hat{\\alpha}$ jointly requires a numerical root find; one common equation is:\n",
    "$$\n",
    "\\log\\hat{\\alpha} - \\psi(\\hat{\\alpha}) = \\log\\bar{x} - \\overline{\\log x}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_loglik(x, alpha, theta):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    alpha = float(alpha)\n",
    "    theta = float(theta)\n",
    "    if alpha <= 0 or theta <= 0:\n",
    "        return -np.inf\n",
    "    if np.any(x <= 0):\n",
    "        return -np.inf\n",
    "\n",
    "    n = x.size\n",
    "    return (\n",
    "        (alpha - 1) * np.sum(np.log(x))\n",
    "        - np.sum(x) / theta\n",
    "        - n * (gammaln(alpha) + alpha * np.log(theta))\n",
    "    )\n",
    "\n",
    "\n",
    "# Quick sanity check: theta-hat given alpha\n",
    "alpha_true, theta_true = 3.0, 1.5\n",
    "x = stats.gamma(a=alpha_true, scale=theta_true).rvs(size=2000, random_state=rng)\n",
    "\n",
    "theta_hat_if_alpha_known = x.mean() / alpha_true\n",
    "theta_hat_if_alpha_known, theta_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Sampling & simulation (NumPy-only)\n",
    "\n",
    "### Two ideas\n",
    "\n",
    "1) **Integer shape** ($\\alpha=k\\in\\mathbb{N}$, Erlang):\n",
    "\n",
    "$$\n",
    "X = \\sum_{j=1}^k E_j,\\quad E_j\\sim\\text{Exponential}(\\text{scale}=\\theta).\n",
    "$$\n",
    "\n",
    "2) **General shape** ($\\alpha>0$): use the **Marsaglia–Tsang** rejection sampler (fast and widely used).\n",
    "\n",
    "### Marsaglia–Tsang (2000) sketch\n",
    "\n",
    "For $\\alpha\\ge 1$:\n",
    "\n",
    "- Set $d = \\alpha - 1/3$, $c = 1/\\sqrt{9d}$.\n",
    "- Repeat:\n",
    "  - draw $Z\\sim\\mathcal{N}(0,1)$ and set $V=(1+cZ)^3$.\n",
    "  - draw $U\\sim\\text{Uniform}(0,1)$.\n",
    "  - accept $X=dV$ if a (cheap) squeeze test passes, otherwise accept using the log test.\n",
    "\n",
    "For $0<\\alpha<1$ we use a reduction:\n",
    "\n",
    "- If $Y\\sim\\text{Gamma}(\\alpha+1,\\theta)$ and $U\\sim\\text{Uniform}(0,1)$ independent,\n",
    "  then $X = Y\\,U^{1/\\alpha} \\sim \\text{Gamma}(\\alpha,\\theta)$.\n",
    "\n",
    "Below is a reference implementation using **NumPy only** (no `scipy.stats.gamma.rvs`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gamma_rvs_mt_shape_ge_1(alpha, n, rng):\n",
    "    \"\"\"Marsaglia–Tsang sampler for Gamma(alpha, 1) with alpha >= 1.\"\"\"\n",
    "    d = alpha - 1.0 / 3.0\n",
    "    c = 1.0 / np.sqrt(9.0 * d)\n",
    "\n",
    "    out = np.empty(n, dtype=float)\n",
    "    filled = 0\n",
    "    while filled < n:\n",
    "        m = n - filled\n",
    "\n",
    "        z = rng.normal(size=m)\n",
    "        v = (1.0 + c * z) ** 3\n",
    "\n",
    "        valid = v > 0\n",
    "        if not np.any(valid):\n",
    "            continue\n",
    "\n",
    "        z = z[valid]\n",
    "        v = v[valid]\n",
    "        u = rng.random(size=v.size)\n",
    "\n",
    "        # Squeeze step + main acceptance test\n",
    "        accept = (u < 1.0 - 0.0331 * (z**4)) | (\n",
    "            np.log(u) < 0.5 * z**2 + d * (1.0 - v + np.log(v))\n",
    "        )\n",
    "\n",
    "        accepted = d * v[accept]\n",
    "        k = accepted.size\n",
    "        out[filled : filled + k] = accepted\n",
    "        filled += k\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def gamma_rvs_numpy(alpha, theta=1.0, size=1, rng=None):\n",
    "    \"\"\"Sample from Gamma(alpha, theta) using NumPy only.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float\n",
    "        Shape parameter (> 0).\n",
    "    theta : float\n",
    "        Scale parameter (> 0).\n",
    "    size : int or tuple\n",
    "        Output shape.\n",
    "    rng : np.random.Generator\n",
    "        Random number generator.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    alpha = float(alpha)\n",
    "    theta = float(theta)\n",
    "    if alpha <= 0 or theta <= 0:\n",
    "        raise ValueError(\"alpha and theta must be > 0\")\n",
    "\n",
    "    size_tuple = (size,) if isinstance(size, int) else tuple(size)\n",
    "    n = int(np.prod(size_tuple))\n",
    "\n",
    "    if alpha >= 1:\n",
    "        x = _gamma_rvs_mt_shape_ge_1(alpha, n, rng)\n",
    "    else:\n",
    "        # Boost shape to alpha+1 >= 1, then apply the U^(1/alpha) correction\n",
    "        y = _gamma_rvs_mt_shape_ge_1(alpha + 1.0, n, rng)\n",
    "        u = rng.random(size=n)\n",
    "        x = y * (u ** (1.0 / alpha))\n",
    "\n",
    "    return (x * theta).reshape(size_tuple)\n",
    "\n",
    "\n",
    "# Smoke test: mean/variance roughly match theory\n",
    "alpha_test, theta_test = 2.5, 1.3\n",
    "s = gamma_rvs_numpy(alpha_test, theta_test, size=50_000, rng=rng)\n",
    "s.mean(), (alpha_test * theta_test), s.var(), (alpha_test * theta_test**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We’ll visualize:\n",
    "\n",
    "- the **PDF** and how it compares to a Monte Carlo histogram\n",
    "- the **CDF** and how it compares to an empirical CDF\n",
    "\n",
    "We’ll use the NumPy-only sampler from above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(samples):\n",
    "    x = np.sort(np.asarray(samples))\n",
    "    y = np.arange(1, x.size + 1) / x.size\n",
    "    return x, y\n",
    "\n",
    "\n",
    "alpha_viz, theta_viz = 2.5, 1.3\n",
    "n_viz = 80_000\n",
    "\n",
    "samples = gamma_rvs_numpy(alpha_viz, theta_viz, size=n_viz, rng=rng)\n",
    "x_max = float(np.quantile(samples, 0.995))\n",
    "x_grid = np.linspace(1e-6, x_max, 600)\n",
    "\n",
    "# PDF + histogram\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=samples,\n",
    "        nbinsx=70,\n",
    "        histnorm=\"probability density\",\n",
    "        name=\"Monte Carlo samples\",\n",
    "        opacity=0.55,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_grid,\n",
    "        y=gamma_pdf(x_grid, alpha_viz, theta_viz),\n",
    "        mode=\"lines\",\n",
    "        name=\"Theoretical PDF\",\n",
    "        line=dict(width=3),\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=f\"Gamma(α={alpha_viz:g}, θ={theta_viz:g}): histogram vs PDF\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"density\",\n",
    "    bargap=0.02,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# CDF + empirical CDF\n",
    "xs, ys = ecdf(samples)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_grid,\n",
    "        y=gamma_cdf(x_grid, alpha_viz, theta_viz),\n",
    "        mode=\"lines\",\n",
    "        name=\"Theoretical CDF\",\n",
    "        line=dict(width=3),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=xs[::100],\n",
    "        y=ys[::100],\n",
    "        mode=\"markers\",\n",
    "        name=\"Empirical CDF (subsampled)\",\n",
    "        marker=dict(size=5),\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=f\"Gamma(α={alpha_viz:g}, θ={theta_viz:g}): empirical CDF vs CDF\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"CDF\",\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Monte Carlo moment check\n",
    "sample_mean = samples.mean()\n",
    "sample_var = samples.var()\n",
    "theory_mean = alpha_viz * theta_viz\n",
    "theory_var = alpha_viz * theta_viz**2\n",
    "\n",
    "sample_mean, theory_mean, sample_var, theory_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) SciPy integration (`scipy.stats.gamma`)\n",
    "\n",
    "SciPy’s Gamma distribution is `scipy.stats.gamma`.\n",
    "\n",
    "- Shape is passed as `a`.\n",
    "- Scale is passed as `scale`.\n",
    "- There is also a `loc` parameter (a shift). For the standard Gamma distribution, use `loc=0`.\n",
    "\n",
    "So the mapping is:\n",
    "\n",
    "$$\n",
    "X \\sim \\text{Gamma}(\\alpha, \\theta)\n",
    "\\quad\\Longleftrightarrow\\quad\n",
    "\\texttt{stats.gamma(a=alpha, loc=0, scale=theta)}.\n",
    "$$\n",
    "\n",
    "If you’re using a **rate** $\\beta$ instead: `scale = 1 / beta`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_true, theta_true = 3.0, 1.5\n",
    "\n",
    "dist = stats.gamma(a=alpha_true, loc=0, scale=theta_true)\n",
    "\n",
    "x = np.linspace(0, 15, 500)\n",
    "pdf = dist.pdf(x)\n",
    "cdf = dist.cdf(x)\n",
    "\n",
    "samples_scipy = dist.rvs(size=5000, random_state=rng)\n",
    "\n",
    "# MLE fit (note: constrain loc=0 to match the usual Gamma support)\n",
    "a_hat, loc_hat, scale_hat = stats.gamma.fit(samples_scipy, floc=0)\n",
    "a_hat, loc_hat, scale_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Statistical use cases\n",
    "\n",
    "### A) Hypothesis testing\n",
    "\n",
    "- **Goodness-of-fit**: do Gamma parameters explain the data?\n",
    "- **Model comparison**: e.g. exponential vs general Gamma (is $\\alpha=1$ plausible?)\n",
    "\n",
    "### B) Bayesian modeling\n",
    "\n",
    "Gamma is a standard conjugate prior for **rates**:\n",
    "\n",
    "- Poisson likelihood (counts) with unknown rate\n",
    "- Exponential likelihood (waiting times) with unknown rate\n",
    "\n",
    "### C) Generative modeling / hierarchical models\n",
    "\n",
    "Gamma is often used as a **latent positive variable** (rates, precisions, intensities). A classic example is a **Poisson–Gamma mixture**, which creates **overdispersed** count data (marginally negative binomial).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Hypothesis testing example: Exponential (alpha=1) vs Gamma (alpha free)\n",
    "\n",
    "# Generate data from a Gamma alternative\n",
    "alpha_data, theta_data = 2.0, 2.0\n",
    "data = stats.gamma(a=alpha_data, scale=theta_data).rvs(size=2500, random_state=rng)\n",
    "\n",
    "# Fit the unrestricted Gamma\n",
    "a_hat, loc_hat, scale_hat = stats.gamma.fit(data, floc=0)\n",
    "\n",
    "# Null model: alpha = 1 (exponential). MLE for theta is just the sample mean.\n",
    "theta0_hat = data.mean()\n",
    "\n",
    "ll_null = gamma_loglik(data, alpha=1.0, theta=theta0_hat)\n",
    "ll_alt = gamma_loglik(data, alpha=a_hat, theta=scale_hat)\n",
    "\n",
    "lr_stat = 2 * (ll_alt - ll_null)\n",
    "p_value_lrt = stats.chi2.sf(lr_stat, df=1)\n",
    "\n",
    "# Goodness-of-fit (KS) for the fitted Gamma\n",
    "D_ks, p_value_ks = stats.kstest(data, \"gamma\", args=(a_hat, 0, scale_hat))\n",
    "\n",
    "lr_stat, p_value_lrt, D_ks, p_value_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) Bayesian modeling: Gamma prior for a Poisson rate\n",
    "# Use rate parameterization for the prior/posterior: Gamma(α, β) with mean α/β.\n",
    "\n",
    "alpha0, beta0 = 2.0, 1.0\n",
    "lambda_true = 3.0\n",
    "n = 25\n",
    "\n",
    "y = rng.poisson(lam=lambda_true, size=n)\n",
    "\n",
    "alpha_post = alpha0 + y.sum()\n",
    "beta_post = beta0 + n\n",
    "\n",
    "# Convert rate β to scale θ=1/β for our Gamma(alpha, theta) helper functions\n",
    "lam_grid = np.linspace(1e-6, max(10, 3 * lambda_true), 600)\n",
    "prior_pdf = gamma_pdf(lam_grid, alpha0, theta=1 / beta0)\n",
    "post_pdf = gamma_pdf(lam_grid, alpha_post, theta=1 / beta_post)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=lam_grid,\n",
    "        y=prior_pdf,\n",
    "        mode=\"lines\",\n",
    "        name=f\"prior Γ(α={alpha0:g}, β={beta0:g})\",\n",
    "        line=dict(width=3),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=lam_grid,\n",
    "        y=post_pdf,\n",
    "        mode=\"lines\",\n",
    "        name=f\"posterior Γ(α={alpha_post:g}, β={beta_post:g})\",\n",
    "        line=dict(width=3),\n",
    "    )\n",
    ")\n",
    "fig.add_vline(x=lambda_true, line_dash=\"dash\", line_color=\"black\", annotation_text=\"true λ\")\n",
    "fig.update_layout(\n",
    "    title=\"Gamma–Poisson conjugacy: prior → posterior on λ\",\n",
    "    xaxis_title=\"λ\",\n",
    "    yaxis_title=\"density\",\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "y.sum(), y.mean(), (alpha_post / beta_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C) Generative modeling: Poisson–Gamma mixture (overdispersed counts)\n",
    "\n",
    "alpha_latent, theta_latent = 5.0, 0.6  # latent lambda ~ Gamma(alpha, theta)\n",
    "n_obs = 20_000\n",
    "\n",
    "lambdas = gamma_rvs_numpy(alpha_latent, theta_latent, size=n_obs, rng=rng)\n",
    "counts_mixture = rng.poisson(lam=lambdas)\n",
    "\n",
    "mean_counts = counts_mixture.mean()\n",
    "counts_poisson = rng.poisson(lam=mean_counts, size=n_obs)\n",
    "\n",
    "max_k = int(np.quantile(counts_mixture, 0.995))\n",
    "bin_spec = dict(start=-0.5, end=max_k + 0.5, size=1)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=counts_mixture,\n",
    "        xbins=bin_spec,\n",
    "        histnorm=\"probability\",\n",
    "        name=\"Poisson–Gamma mixture\",\n",
    "        opacity=0.6,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=counts_poisson,\n",
    "        xbins=bin_spec,\n",
    "        histnorm=\"probability\",\n",
    "        name=\"Poisson (same mean)\",\n",
    "        opacity=0.6,\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Overdispersion from a Poisson–Gamma mixture\",\n",
    "    xaxis_title=\"count\",\n",
    "    yaxis_title=\"probability\",\n",
    "    barmode=\"overlay\",\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "counts_mixture.mean(), counts_mixture.var(), counts_poisson.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "1) **Parameterization confusion**\n",
    "\n",
    "- Some sources use **rate** $\\beta$ (larger $\\beta$ means smaller values), others use **scale** $\\theta=1/\\beta$.\n",
    "- `scipy.stats.gamma` uses `scale` (not rate).\n",
    "\n",
    "2) **`loc` in SciPy**\n",
    "\n",
    "- `scipy.stats` distributions often include a shift `loc` by default.\n",
    "- For the standard Gamma with support $(0,\\infty)$, you typically want `loc=0`.\n",
    "\n",
    "3) **Behavior near zero**\n",
    "\n",
    "- If $0<\\alpha<1$, the PDF diverges as $x\\to 0^+$. Plots should avoid including exactly $x=0$.\n",
    "\n",
    "4) **Numerical stability**\n",
    "\n",
    "- Computing the PDF directly can underflow/overflow for extreme parameters.\n",
    "- Prefer `logpdf` (and `gammaln`) when doing inference or optimization.\n",
    "\n",
    "5) **Invalid parameters / data**\n",
    "\n",
    "- Gamma requires $\\alpha>0$, $\\theta>0$, and data $x_i>0$.\n",
    "- If your data include zeros or negatives, consider a shifted model (`loc`), a hurdle model, or a different distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- Gamma is a **continuous** distribution on $(0,\\infty)$ with parameters shape $\\alpha$ and scale $\\theta$.\n",
    "- It naturally models **waiting times** and **sums of exponentials**, and it’s a workhorse for positive skewed data.\n",
    "- Key formulas: $\\mathbb{E}[X]=\\alpha\\theta$, $\\mathrm{Var}(X)=\\alpha\\theta^2$, $M_X(t)=(1-\\theta t)^{-\\alpha}$.\n",
    "- Sampling can be done efficiently with **Marsaglia–Tsang**; SciPy provides `stats.gamma` for `pdf`, `cdf`, `rvs`, and `fit`.\n",
    "- Always watch for parameterization (scale vs rate), `loc`, and numerical stability near $x=0$ / extreme parameters.\n",
    "\n",
    "### References\n",
    "\n",
    "- Marsaglia, G. and Tsang, W. W. (2000). *A Simple Method for Generating Gamma Variables*.\n",
    "- SciPy documentation: `scipy.stats.gamma`\n",
    "- Any standard mathematical statistics text (Gamma function, incomplete gamma, conjugacy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
