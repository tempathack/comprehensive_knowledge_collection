{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3df8426b",
   "metadata": {},
   "source": [
    "# Log-Laplace Distribution — a log-symmetric, heavy-tailed model on $(0,\\infty)$\n",
    "\n",
    "The **log-Laplace distribution** (SciPy: `scipy.stats.loglaplace`) is a positive distribution whose logarithm is **Laplace** (double-exponential).\n",
    "\n",
    "It’s a useful choice when you want a distribution on **positive magnitudes** with:\n",
    "- symmetry on a **multiplicative** (log) scale,\n",
    "- **power-law tails** (heavier than lognormal), and\n",
    "- a simple **inverse-CDF sampler**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c374b4d4",
   "metadata": {},
   "source": [
    "## What you’ll learn\n",
    "\n",
    "- How to define the log-Laplace PDF/CDF and connect it to the Laplace distribution via a change of variables.\n",
    "- Which moments exist (and why some don’t), including closed forms for mean/variance/skewness/kurtosis when they do.\n",
    "- A NumPy-only inverse-CDF sampler and how to validate it.\n",
    "- Simple inference for the shape parameter: MLE, exact confidence intervals, and a conjugate Bayesian update.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b842fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")  # CKC convention\n",
    "\n",
    "np.set_printoptions(precision=5, suppress=True)\n",
    "rng = np.random.default_rng(7)\n",
    "\n",
    "print(\"Python\", platform.python_version())\n",
    "print(\"NumPy\", np.__version__)\n",
    "print(\"SciPy\", scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49acd94",
   "metadata": {},
   "source": [
    "## 1) Title & Classification\n",
    "\n",
    "- **Name**: Log-Laplace distribution (`loglaplace`)\n",
    "- **Type**: **Continuous**\n",
    "- **Support (standard)**: $x \\in (0,\\infty)$\n",
    "- **Parameter space (standard)**: shape parameter $c>0$\n",
    "\n",
    "SciPy uses an additional location/scale transform:\n",
    "\n",
    "$$X = \\text{loc} + \\text{scale}\\,Y, \\quad Y \\sim \\mathrm{LogLaplace}(c),$$\n",
    "\n",
    "where `scale > 0` and the support becomes $x > \\text{loc}$.\n",
    "\n",
    "We write (standard form):\n",
    "\n",
    "$$X \\sim \\mathrm{LogLaplace}(c).$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fedae0",
   "metadata": {},
   "source": [
    "## 2) Intuition & Motivation\n",
    "\n",
    "### 2.1 What it models\n",
    "\n",
    "A log-Laplace random variable can be written as\n",
    "\n",
    "$$X = \\exp(Z), \\quad Z \\sim \\mathrm{Laplace}(0, 1/c).$$\n",
    "\n",
    "So **additive Laplace noise in log-space** becomes **multiplicative, heavy-tailed noise** on the original scale.\n",
    "\n",
    "A key symmetry is:\n",
    "\n",
    "$$\\log X \\text{ is symmetric about } 0 \\quad\\Longleftrightarrow\\quad X \\text{ is symmetric about } 1 \\text{ on the multiplicative scale.}$$\n",
    "\n",
    "In fact, $X$ and $1/X$ have the same distribution.\n",
    "\n",
    "### 2.2 Typical real-world use cases\n",
    "\n",
    "- **Positive data with occasional extreme values**: file sizes, response times, claim sizes.\n",
    "- **Multiplicative error models**: $Y = \\theta \\cdot X$ where $\\log X$ has Laplace-like “spiky + outlier-prone” behavior.\n",
    "- **Robust alternatives in log-space**: if $\\log Y$ is better modeled by Laplace than Normal (heavier tails), then $Y$ may be log-Laplace rather than lognormal.\n",
    "\n",
    "### 2.3 Relations to other distributions\n",
    "\n",
    "- **Laplace**: $\\log X \\sim \\mathrm{Laplace}(0, 1/c)$.\n",
    "- **Lognormal**: $\\log X$ Normal vs Laplace (log-Laplace has sharper peak and heavier tails).\n",
    "- **Pareto-like tails**: for $x\\to\\infty$, $f(x)\\propto x^{-(c+1)}$.\n",
    "- **Invariance**: $X \\stackrel{d}{=} 1/X$ (log-symmetry).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd574098",
   "metadata": {},
   "source": [
    "## 3) Formal Definition\n",
    "\n",
    "### 3.1 PDF\n",
    "\n",
    "The standard log-Laplace density can be written in a compact way:\n",
    "\n",
    "$$f(x; c) = \\frac{c}{2x}\\,\\exp\\bigl(-c\\,|\\log x|\\bigr), \\quad x>0,\\; c>0.$$\n",
    "\n",
    "Equivalently, as a piecewise power law (useful for intuition):\n",
    "\n",
    "$$\n",
    "f(x;c) =\n",
    "\\begin{cases}\n",
    "\\frac{c}{2}\\,x^{c-1}, & 0 < x < 1,\\\\[4pt]\n",
    "\\frac{c}{2}\\,x^{-c-1}, & x \\ge 1.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### 3.2 CDF\n",
    "\n",
    "$$\n",
    "F(x;c) =\n",
    "\\begin{cases}\n",
    "0, & x \\le 0,\\\\[4pt]\n",
    "\\frac{1}{2}x^{c}, & 0 < x < 1,\\\\[4pt]\n",
    "1 - \\frac{1}{2}x^{-c}, & x \\ge 1.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### 3.3 Quantile function (inverse CDF)\n",
    "\n",
    "This is especially convenient for sampling:\n",
    "\n",
    "$$\n",
    "F^{-1}(p;c)=\n",
    "\\begin{cases}\n",
    "(2p)^{1/c}, & 0<p<\\tfrac12,\\\\[4pt]\n",
    "\\left(\\frac{1}{2(1-p)}\\right)^{1/c}, & \\tfrac12\\le p<1.\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15568aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_c(c: float) -> float:\n",
    "    c = float(c)\n",
    "    if c <= 0:\n",
    "        raise ValueError(\"c must be > 0\")\n",
    "    return c\n",
    "\n",
    "\n",
    "def loglaplace_pdf_std(x: np.ndarray, c: float) -> np.ndarray:\n",
    "    \"\"\"Standard log-Laplace PDF on (0, inf) with shape c>0.\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    c = _validate_c(c)\n",
    "\n",
    "    out = np.zeros_like(x, dtype=float)\n",
    "    mask = x > 0\n",
    "    xm = x[mask]\n",
    "\n",
    "    # Stable expression: f(x)= (c/(2x))*exp(-c*|log x|)\n",
    "    out[mask] = 0.5 * c / xm * np.exp(-c * np.abs(np.log(xm)))\n",
    "    return out\n",
    "\n",
    "\n",
    "def loglaplace_logpdf_std(x: np.ndarray, c: float) -> np.ndarray:\n",
    "    \"\"\"Standard log-Laplace log-PDF.\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    c = _validate_c(c)\n",
    "\n",
    "    out = np.full_like(x, -np.inf, dtype=float)\n",
    "    mask = x > 0\n",
    "    xm = x[mask]\n",
    "\n",
    "    out[mask] = np.log(c) - np.log(2.0) - np.log(xm) - c * np.abs(np.log(xm))\n",
    "    return out\n",
    "\n",
    "\n",
    "def loglaplace_cdf_std(x: np.ndarray, c: float) -> np.ndarray:\n",
    "    \"\"\"Standard log-Laplace CDF.\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    c = _validate_c(c)\n",
    "\n",
    "    out = np.zeros_like(x, dtype=float)\n",
    "    mask = x > 0\n",
    "    xm = x[mask]\n",
    "\n",
    "    out[mask] = np.where(\n",
    "        xm < 1.0,\n",
    "        0.5 * np.power(xm, c),\n",
    "        1.0 - 0.5 * np.power(xm, -c),\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def loglaplace_ppf_std(p: np.ndarray, c: float) -> np.ndarray:\n",
    "    \"\"\"Standard log-Laplace inverse CDF.\"\"\"\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    c = _validate_c(c)\n",
    "    if np.any((p <= 0) | (p >= 1)):\n",
    "        raise ValueError(\"p must be in (0, 1)\")\n",
    "\n",
    "    return np.where(\n",
    "        p < 0.5,\n",
    "        np.power(2.0 * p, 1.0 / c),\n",
    "        np.power(1.0 / (2.0 * (1.0 - p)), 1.0 / c),\n",
    "    )\n",
    "\n",
    "\n",
    "def loglaplace_rvs_numpy(\n",
    "    c: float, size: int | tuple[int, ...], rng: np.random.Generator\n",
    ") -> np.ndarray:\n",
    "    \"\"\"NumPy-only sampling via inverse CDF (standard form).\"\"\"\n",
    "    c = _validate_c(c)\n",
    "\n",
    "    u = rng.random(size)\n",
    "    # Keep u in (0,1) to avoid returning exactly 0 or inf from floating endpoints.\n",
    "    u = np.clip(u, np.finfo(float).tiny, 1.0 - np.finfo(float).eps)\n",
    "\n",
    "    return np.where(\n",
    "        u < 0.5,\n",
    "        np.power(2.0 * u, 1.0 / c),\n",
    "        np.power(1.0 / (2.0 * (1.0 - u)), 1.0 / c),\n",
    "    )\n",
    "\n",
    "\n",
    "def loglaplace_pdf(x: np.ndarray, c: float, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Location/scale version: X = loc + scale*Y, Y ~ LogLaplace(c).\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    c = _validate_c(c)\n",
    "    scale = float(scale)\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    z = (x - loc) / scale\n",
    "    return loglaplace_pdf_std(z, c) / scale\n",
    "\n",
    "\n",
    "def loglaplace_logpdf(\n",
    "    x: np.ndarray, c: float, loc: float = 0.0, scale: float = 1.0\n",
    ") -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    c = _validate_c(c)\n",
    "    scale = float(scale)\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    z = (x - loc) / scale\n",
    "    return loglaplace_logpdf_std(z, c) - np.log(scale)\n",
    "\n",
    "\n",
    "def loglaplace_cdf(x: np.ndarray, c: float, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    c = _validate_c(c)\n",
    "    scale = float(scale)\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    z = (x - loc) / scale\n",
    "    return loglaplace_cdf_std(z, c)\n",
    "\n",
    "\n",
    "def loglaplace_ppf(p: np.ndarray, c: float, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    c = _validate_c(c)\n",
    "    scale = float(scale)\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    return loc + scale * loglaplace_ppf_std(p, c)\n",
    "\n",
    "\n",
    "# Quick cross-check against SciPy (standard form: loc=0, scale=1)\n",
    "x_test = np.array([1e-3, 0.2, 0.9, 1.0, 2.0, 10.0])\n",
    "c_test = 2.5\n",
    "dist = stats.loglaplace(c_test)\n",
    "\n",
    "print(\"max |pdf - scipy|:\", np.max(np.abs(loglaplace_pdf_std(x_test, c_test) - dist.pdf(x_test))))\n",
    "print(\"max |cdf - scipy|:\", np.max(np.abs(loglaplace_cdf_std(x_test, c_test) - dist.cdf(x_test))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a86262a",
   "metadata": {},
   "source": [
    "## 4) Moments & Properties\n",
    "\n",
    "A convenient fact is that the log-Laplace has **power-law tails**, so not all moments exist.\n",
    "\n",
    "### 4.1 Raw moments\n",
    "\n",
    "For real $k$ with $-c < k < c$,\n",
    "\n",
    "$$\\mathbb{E}[X^k] = \\frac{c^2}{c^2 - k^2}.$$\n",
    "\n",
    "In particular:\n",
    "\n",
    "- Mean exists iff $c>1$:\n",
    "  $$\\mathbb{E}[X] = \\frac{c^2}{c^2 - 1}.$$\n",
    "- Second moment exists iff $c>2$:\n",
    "  $$\\mathbb{E}[X^2] = \\frac{c^2}{c^2 - 4}.$$\n",
    "\n",
    "### 4.2 Variance\n",
    "\n",
    "For $c>2$:\n",
    "\n",
    "$$\\mathrm{Var}(X) = \\frac{c^2(2c^2+1)}{(c^2-4)(c^2-1)^2}.$$\n",
    "\n",
    "### 4.3 Skewness and kurtosis\n",
    "\n",
    "These require higher moments:\n",
    "\n",
    "- Skewness exists for $c>3$:\n",
    "\n",
    "$$\n",
    "\\gamma_1\n",
    "= \\frac{2(15c^4+7c^2+2)\\,\\sqrt{c^2-4}}{c\\,(c^2-9)\\,(2c^2+1)^{3/2}}.\n",
    "$$\n",
    "\n",
    "- Excess kurtosis exists for $c>4$:\n",
    "\n",
    "$$\n",
    "\\gamma_2\n",
    "= \\frac{6\\bigl(2c^{10}+138c^8-615c^6-449c^4-132c^2-24\\bigr)}{c^2\\,(c^2-16)\\,(c^2-9)\\,(2c^2+1)^2}.\n",
    "$$\n",
    "\n",
    "### 4.4 MGF / characteristic function\n",
    "\n",
    "Because the right tail behaves like $x^{-(c+1)}$, the moment generating function\n",
    "\n",
    "$$M_X(t)=\\mathbb{E}[e^{tX}]$$\n",
    "\n",
    "**diverges for any $t>0$** (too much mass in the far right tail for an exponential weight).\n",
    "\n",
    "For $t<0$, the Laplace transform exists and can be written using incomplete gamma functions:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[e^{tX}] = \\frac{c}{2}\\Bigl[(-t)^{-c}\\,\\gamma(c,-t) + (-t)^{c}\\,\\Gamma(-c,-t)\\Bigr], \\quad t<0.\n",
    "$$\n",
    "\n",
    "The characteristic function $\\varphi_X(\\omega)=\\mathbb{E}[e^{i\\omega X}]$ exists for all real $\\omega$ (bounded integrand), and admits an analogous representation with complex arguments.\n",
    "\n",
    "### 4.5 Entropy\n",
    "\n",
    "Using $\\log X \\sim \\mathrm{Laplace}(0,1/c)$ and the entropy change-of-variables rule,\n",
    "\n",
    "$$h(X) = 1 + \\log\\Bigl(\\frac{2}{c}\\Bigr).$$\n",
    "\n",
    "(Here $h$ is **differential entropy**.)\n",
    "\n",
    "### 4.6 Other handy properties\n",
    "\n",
    "- **Median**: $\\mathrm{median}(X)=1$.\n",
    "- **Log-moments**: $\\mathbb{E}[\\log X]=0$ and $\\mathrm{Var}(\\log X)=2/c^2$.\n",
    "- **Reciprocal invariance**: $X \\stackrel{d}{=} 1/X$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd524d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglaplace_raw_moment(k: float, c: float) -> float:\n",
    "    \"\"\"Return E[X^k] for the standard log-Laplace, when it exists (|k|<c).\"\"\"\n",
    "    c = _validate_c(c)\n",
    "    k = float(k)\n",
    "    if not (-c < k < c):\n",
    "        return np.inf\n",
    "    return (c * c) / (c * c - k * k)\n",
    "\n",
    "\n",
    "def loglaplace_mean(c: float) -> float:\n",
    "    c = _validate_c(c)\n",
    "    return loglaplace_raw_moment(1.0, c) if c > 1 else np.nan\n",
    "\n",
    "\n",
    "def loglaplace_variance(c: float) -> float:\n",
    "    c = _validate_c(c)\n",
    "    if c <= 2:\n",
    "        return np.nan\n",
    "    c2 = c * c\n",
    "    return c2 * (2 * c2 + 1) / ((c2 - 4) * (c2 - 1) ** 2)\n",
    "\n",
    "\n",
    "def loglaplace_skewness(c: float) -> float:\n",
    "    c = _validate_c(c)\n",
    "    if c <= 3:\n",
    "        return np.nan\n",
    "    c2 = c * c\n",
    "    num = 2 * (15 * c2 * c2 + 7 * c2 + 2) * np.sqrt(c2 - 4)\n",
    "    den = c * (c2 - 9) * (2 * c2 + 1) ** 1.5\n",
    "    return num / den\n",
    "\n",
    "\n",
    "def loglaplace_excess_kurtosis(c: float) -> float:\n",
    "    c = _validate_c(c)\n",
    "    if c <= 4:\n",
    "        return np.nan\n",
    "    c2 = c * c\n",
    "    num = 6 * (\n",
    "        2 * c**10 + 138 * c**8 - 615 * c**6 - 449 * c**4 - 132 * c2 - 24\n",
    "    )\n",
    "    den = c2 * (c2 - 16) * (c2 - 9) * (2 * c2 + 1) ** 2\n",
    "    return num / den\n",
    "\n",
    "\n",
    "def loglaplace_entropy(c: float) -> float:\n",
    "    c = _validate_c(c)\n",
    "    return 1.0 + np.log(2.0 / c)\n",
    "\n",
    "\n",
    "for c in [0.8, 1.5, 2.5, 5.0]:\n",
    "    print(\n",
    "        f\"c={c:>4}: mean={loglaplace_mean(c)}, var={loglaplace_variance(c)}, \"\n",
    "        f\"skew={loglaplace_skewness(c)}, excess_kurt={loglaplace_excess_kurtosis(c)}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d761d601",
   "metadata": {},
   "source": [
    "## 5) Parameter Interpretation\n",
    "\n",
    "The shape parameter $c$ is best understood via the log transform:\n",
    "\n",
    "$$\\log X \\sim \\mathrm{Laplace}(0, 1/c).$$\n",
    "\n",
    "- Larger $c$ means **smaller** Laplace scale $1/c$ in log-space, so $X$ concentrates more tightly around $1$.\n",
    "- Smaller $c$ means **heavier tails** on the original scale (more extreme small and large values).\n",
    "\n",
    "A quick rule of thumb from the tail:\n",
    "\n",
    "$$\\mathbb{P}(X > x) \\approx \\tfrac12\\,x^{-c}\\quad (x\\ge 1).$$\n",
    "\n",
    "So $c$ acts like a **Pareto tail index** on the right tail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a264ac95",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### 6.1 Expectation (and when it exists)\n",
    "\n",
    "Using the piecewise PDF and splitting at 1:\n",
    "\n",
    "$$\\mathbb{E}[X^k] = \\int_0^\\infty x^k f(x;c)\\,dx\n",
    "= \\frac{c}{2}\\int_0^1 x^{k+c-1}\\,dx + \\frac{c}{2}\\int_1^\\infty x^{k-c-1}\\,dx.$$\n",
    "\n",
    "The first integral is finite when $k>-c$; the second is finite when $k<c$. Evaluating gives:\n",
    "\n",
    "$$\\mathbb{E}[X^k] = \\frac{c}{2}\\Bigl(\\frac{1}{k+c} + \\frac{1}{c-k}\\Bigr)=\\frac{c^2}{c^2-k^2}, \\quad -c<k<c.$$\n",
    "\n",
    "Setting $k=1$ shows the mean exists iff $c>1$.\n",
    "\n",
    "### 6.2 Variance\n",
    "\n",
    "For $c>2$ we have $\\mathbb{E}[X]$ and $\\mathbb{E}[X^2]$, so\n",
    "\n",
    "$$\\mathrm{Var}(X)=\\mathbb{E}[X^2]-\\mathbb{E}[X]^2$$\n",
    "\n",
    "which simplifies to\n",
    "\n",
    "$$\\mathrm{Var}(X)=\\frac{c^2(2c^2+1)}{(c^2-4)(c^2-1)^2}.$$\n",
    "\n",
    "### 6.3 Likelihood (iid sample) and MLE\n",
    "\n",
    "For data $x_1,\\dots,x_n$ with $x_i>0$ in the **standard** model (only $c$ unknown),\n",
    "\n",
    "$$f(x_i;c)=\\frac{c}{2x_i}\\exp\\bigl(-c|\\log x_i|\\bigr).$$\n",
    "\n",
    "The log-likelihood is\n",
    "\n",
    "$$\\ell(c)= n\\log c - n\\log 2 - \\sum_{i=1}^n \\log x_i - c\\sum_{i=1}^n |\\log x_i|.$$\n",
    "\n",
    "Differentiating and setting to zero:\n",
    "\n",
    "$$\\ell'(c)=\\frac{n}{c}-\\sum_{i=1}^n |\\log x_i|=0\\quad\\Rightarrow\\quad \\hat c=\\frac{n}{\\sum_i |\\log x_i|}.$$\n",
    "\n",
    "**Interpretation:** since $\\log X$ is Laplace, $|\\log X|$ is Exponential(rate $c$), so inference on $c$ reduces to inference on an exponential rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3722a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglaplace_loglik_c(x: np.ndarray, c: float) -> float:\n",
    "    \"\"\"Log-likelihood for the standard model (c only).\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    c = _validate_c(c)\n",
    "    if np.any(x <= 0):\n",
    "        return -np.inf\n",
    "\n",
    "    n = x.size\n",
    "    s = np.sum(np.abs(np.log(x)))\n",
    "    return n * np.log(c) - n * np.log(2.0) - np.sum(np.log(x)) - c * s\n",
    "\n",
    "\n",
    "def loglaplace_mle_c(x: np.ndarray) -> float:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if np.any(x <= 0):\n",
    "        raise ValueError(\"all observations must be > 0\")\n",
    "    s = np.sum(np.abs(np.log(x)))\n",
    "    if s <= 0:\n",
    "        raise ValueError(\"degenerate sample: sum |log x| must be > 0\")\n",
    "    return x.size / s\n",
    "\n",
    "\n",
    "# Quick check: simulate and verify the MLE is close to truth\n",
    "c0 = 2.5\n",
    "x = loglaplace_rvs_numpy(c0, size=10_000, rng=rng)\n",
    "print(\"c0     =\", c0)\n",
    "print(\"c_hat  =\", loglaplace_mle_c(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfbe7cc",
   "metadata": {},
   "source": [
    "## 7) Sampling & Simulation\n",
    "\n",
    "### 7.1 Inverse CDF method (NumPy-only)\n",
    "\n",
    "Draw $U\\sim\\mathrm{Unif}(0,1)$ and transform using the quantile function:\n",
    "\n",
    "$$\n",
    "X=\n",
    "\\begin{cases}\n",
    "(2U)^{1/c}, & U<\\tfrac12,\\\\\n",
    "\\left(\\frac{1}{2(1-U)}\\right)^{1/c}, & U\\ge\\tfrac12.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This is exactly what `loglaplace_rvs_numpy` implements.\n",
    "\n",
    "### 7.2 Alternative viewpoint (log transform)\n",
    "\n",
    "Sample $Z\\sim\\mathrm{Laplace}(0,1/c)$ and set $X=\\exp(Z)$. This is conceptually helpful, but the inverse-CDF above is simpler to implement without relying on a Laplace RNG.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb70913",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We’ll visualize:\n",
    "- the PDF and CDF for different $c$,\n",
    "- Monte Carlo samples (including a log-scale view).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc8324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grids that resolve both sides around x=1\n",
    "x_left = np.logspace(-3, 0, 400, endpoint=False)\n",
    "x_right = np.logspace(0, 3, 400)\n",
    "xgrid = np.unique(np.concatenate([x_left, x_right]))\n",
    "\n",
    "c_values = [0.8, 1.5, 3.0, 7.0]\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"PDF\", \"CDF\"))\n",
    "\n",
    "for c in c_values:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=xgrid, y=loglaplace_pdf_std(xgrid, c), mode=\"lines\", name=f\"c={c}\"),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=xgrid,\n",
    "            y=loglaplace_cdf_std(xgrid, c),\n",
    "            mode=\"lines\",\n",
    "            name=f\"c={c}\",\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(title=\"x\", type=\"log\", row=1, col=1)\n",
    "fig.update_xaxes(title=\"x\", type=\"log\", row=1, col=2)\n",
    "fig.update_yaxes(title=\"density\", row=1, col=1)\n",
    "fig.update_yaxes(title=\"F(x)\", row=1, col=2)\n",
    "fig.update_layout(width=980, height=380, legend_title_text=\"shape c\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e31132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo: samples on x-scale and log-scale\n",
    "c_mc = 2.5\n",
    "n_mc = 50_000\n",
    "x_samp = loglaplace_rvs_numpy(c_mc, size=n_mc, rng=rng)\n",
    "z_samp = np.log(x_samp)\n",
    "\n",
    "zgrid = np.linspace(np.quantile(z_samp, 0.001), np.quantile(z_samp, 0.999), 500)\n",
    "laplace_pdf = 0.5 * c_mc * np.exp(-c_mc * np.abs(zgrid))  # Laplace(0, 1/c_mc)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Samples on original scale (log x-axis)\", \"log(samples) vs Laplace(0,1/c)\"),\n",
    ")\n",
    "\n",
    "# Original-scale samples (histogram) with theoretical PDF overlay\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=x_samp, nbinsx=120, histnorm=\"probability density\", name=\"samples\", opacity=0.6),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=xgrid, y=loglaplace_pdf_std(xgrid, c_mc), mode=\"lines\", name=\"theory\"),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# Log-scale samples should look Laplace\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=z_samp, nbinsx=120, histnorm=\"probability density\", name=\"log samples\", opacity=0.6),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=zgrid, y=laplace_pdf, mode=\"lines\", name=\"Laplace pdf\"),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title=\"x\", type=\"log\", row=1, col=1)\n",
    "fig.update_xaxes(title=\"z = log x\", row=1, col=2)\n",
    "fig.update_yaxes(title=\"density\", row=1, col=1)\n",
    "fig.update_yaxes(title=\"density\", row=1, col=2)\n",
    "fig.update_layout(width=980, height=380)\n",
    "fig.show()\n",
    "\n",
    "# Monte Carlo check of mean/variance when they exist (c>2)\n",
    "print(\"theory mean:\", loglaplace_mean(c_mc))\n",
    "print(\"MC mean    :\", x_samp.mean())\n",
    "print(\"theory var :\", loglaplace_variance(c_mc))\n",
    "print(\"MC var     :\", x_samp.var())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8032d9",
   "metadata": {},
   "source": [
    "## 9) SciPy Integration (`scipy.stats.loglaplace`)\n",
    "\n",
    "SciPy provides a ready-to-use distribution object:\n",
    "\n",
    "- `pdf`, `logpdf`, `cdf`, `ppf`\n",
    "- `rvs` for sampling\n",
    "- `fit` for MLE of parameters\n",
    "\n",
    "We’ll use `fit` in two ways:\n",
    "\n",
    "1) **Shape-only** fit with `loc=0, scale=1` fixed (matches the “standard” model).\n",
    "2) Full `c, loc, scale` fit (often less stable; interpret carefully).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282e890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loglaplace\n",
    "\n",
    "c0 = 2.0\n",
    "x = loglaplace.rvs(c0, size=5, random_state=rng)\n",
    "print(\"SciPy rvs:\", x)\n",
    "\n",
    "# Evaluate\n",
    "print(\"pdf:\", loglaplace.pdf(x, c0))\n",
    "print(\"cdf:\", loglaplace.cdf(x, c0))\n",
    "\n",
    "# Fit: generate data from the standard model\n",
    "data = loglaplace_rvs_numpy(c0, size=5_000, rng=rng)\n",
    "\n",
    "# Closed-form MLE for the standard model\n",
    "c_hat_closed = loglaplace_mle_c(data)\n",
    "\n",
    "# SciPy fit with loc/scale fixed to match the standard model\n",
    "c_hat_scipy, loc_hat, scale_hat = stats.loglaplace.fit(data, floc=0.0, fscale=1.0)\n",
    "\n",
    "print(\"c0          =\", c0)\n",
    "print(\"c_hat closed=\", c_hat_closed)\n",
    "print(\"c_hat SciPy =\", c_hat_scipy)\n",
    "print(\"(loc,scale) =\", (loc_hat, scale_hat))\n",
    "\n",
    "# Full fit (c, loc, scale) — can be sensitive for heavy tails\n",
    "c_fit, loc_fit, scale_fit = stats.loglaplace.fit(data)\n",
    "print(\"full fit (c,loc,scale)=\", (c_fit, loc_fit, scale_fit))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8c3c6d",
   "metadata": {},
   "source": [
    "## 10) Statistical Use Cases\n",
    "\n",
    "### 10.1 Hypothesis testing\n",
    "\n",
    "In the standard model, inference on $c$ is especially simple.\n",
    "\n",
    "Since $|\\log X|\\sim \\mathrm{Exp}(\\text{rate}=c)$, the statistic\n",
    "\n",
    "$$S = \\sum_{i=1}^n |\\log x_i|$$\n",
    "\n",
    "satisfies\n",
    "\n",
    "$$2cS \\sim \\chi^2_{2n}.$$\n",
    "\n",
    "This gives **exact** confidence intervals and tests for $c$.\n",
    "\n",
    "### 10.2 Bayesian modeling\n",
    "\n",
    "The standard-model likelihood for $c$ is proportional to\n",
    "\n",
    "$$c^n\\,\\exp\\bigl(-cS\\bigr),$$\n",
    "\n",
    "so a Gamma prior on $c$ is conjugate:\n",
    "\n",
    "$$c\\sim\\mathrm{Gamma}(a,b) \\;\\Rightarrow\\; c\\mid x \\sim \\mathrm{Gamma}(a+n,\\; b+S).$$\n",
    "\n",
    "(Here $b$ is a **rate** parameter.)\n",
    "\n",
    "### 10.3 Generative modeling\n",
    "\n",
    "If you want **multiplicative** heavy-tailed noise, you can model\n",
    "\n",
    "$$Y = \\theta \\cdot X, \\quad X\\sim\\mathrm{LogLaplace}(c),$$\n",
    "\n",
    "which is equivalent to adding Laplace noise in log-space:\n",
    "\n",
    "$$\\log Y = \\log \\theta + Z, \\quad Z\\sim\\mathrm{Laplace}(0,1/c).$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "# Exact CI and an exact two-sided test for c in the standard model\n",
    "c0 = 2.0\n",
    "n = 300\n",
    "x = loglaplace_rvs_numpy(c0, size=n, rng=rng)\n",
    "S = np.sum(np.abs(np.log(x)))\n",
    "\n",
    "alpha = 0.05\n",
    "ci = (\n",
    "    chi2.ppf(alpha / 2, df=2 * n) / (2 * S),\n",
    "    chi2.ppf(1 - alpha / 2, df=2 * n) / (2 * S),\n",
    ")\n",
    "\n",
    "c_hat = loglaplace_mle_c(x)\n",
    "test_stat = 2 * c0 * S  # under H0, this is chi2_{2n}\n",
    "p_left = chi2.cdf(test_stat, df=2 * n)\n",
    "p_two_sided = 2 * min(p_left, 1 - p_left)\n",
    "\n",
    "print(\"c0   =\", c0)\n",
    "print(\"c_hat=\", c_hat)\n",
    "print(\"95% exact CI for c:\", ci)\n",
    "print(\"two-sided exact p-value for H0: c=c0:\", p_two_sided)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f598501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjugate Bayesian update for c (standard model)\n",
    "# Prior: c ~ Gamma(a0, rate=b0)\n",
    "a0, b0 = 2.0, 1.0\n",
    "\n",
    "c0 = 2.0\n",
    "n = 200\n",
    "x = loglaplace_rvs_numpy(c0, size=n, rng=rng)\n",
    "S = np.sum(np.abs(np.log(x)))\n",
    "\n",
    "a_post = a0 + n\n",
    "b_post = b0 + S\n",
    "\n",
    "posterior_mean = a_post / b_post\n",
    "posterior_ci = (\n",
    "    stats.gamma.ppf(0.025, a=a_post, scale=1 / b_post),\n",
    "    stats.gamma.ppf(0.975, a=a_post, scale=1 / b_post),\n",
    ")\n",
    "\n",
    "print(\"prior (a,b)=\", (a0, b0))\n",
    "print(\"posterior (a,b)=\", (a_post, b_post))\n",
    "print(\"posterior mean=\", posterior_mean)\n",
    "print(\"posterior 95% CI=\", posterior_ci)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b31b12",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Invalid parameters**: $c\\le 0$ (and `scale <= 0` in SciPy) is invalid.\n",
    "- **Nonexistent moments**: mean requires $c>1$, variance requires $c>2$, etc. For smaller $c$, Monte Carlo estimates like the sample mean can look “unstable” because the target quantity is infinite.\n",
    "- **Extreme samples**: the inverse CDF produces very large values when $U$ is extremely close to 1. In floating point code, clip uniforms away from 0/1.\n",
    "- **Numerical evaluation**: prefer `logpdf` for likelihoods to avoid underflow, especially when $x$ is tiny/huge or $c$ is large.\n",
    "- **Fitting with `loc/scale`**: unconstrained `fit` may be sensitive for heavy-tailed data; consider fixing `loc`/`scale` when you have a clear standardization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886472d4",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- Log-Laplace models **positive, heavy-tailed** data and is **Laplace in log-space**.\n",
    "- The PDF is piecewise power-law and the right tail behaves like a **Pareto** tail with index $c$.\n",
    "- Raw moments satisfy $\\mathbb{E}[X^k]=\\frac{c^2}{c^2-k^2}$ for $|k|<c$, so some moments may not exist.\n",
    "- Sampling is easy with an **inverse CDF** (NumPy-only).\n",
    "- In the standard model, $|\\log X|$ is exponential, giving a closed-form **MLE**, **exact** chi-square inference, and a conjugate **Gamma** posterior for $c$.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
