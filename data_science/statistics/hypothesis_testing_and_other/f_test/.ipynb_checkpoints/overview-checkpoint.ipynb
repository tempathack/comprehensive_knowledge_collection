{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# F-test (Variance Ratio Test)\n",
        "\n",
        "The two-sample F-test for variances answers a simple question:\n",
        "\n",
        "> Do these two groups have the same variability?\n",
        "\n",
        "It is also the distribution behind the **F-statistic** you see in ANOVA and linear regression, but in this notebook we focus on the most direct version: **testing whether two population variances are equal**.\n",
        "\n",
        "---\n",
        "\n",
        "## Learning goals\n",
        "- Understand what the F-test is testing (and what it is *not* testing)\n",
        "- Build intuition for where the F distribution comes from (chi-square → ratio)\n",
        "- Implement the test **with NumPy only** (Monte Carlo p-values + critical values)\n",
        "- Learn how to interpret p-values, rejection regions, and a variance-ratio confidence interval\n",
        "- See common pitfalls (especially non-normality / outliers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "\n",
        "pio.templates.default = 'plotly_white'\n",
        "pio.renderers.default = 'notebook'\n",
        "np.set_printoptions(precision=4, suppress=True)\n",
        "\n",
        "rng = np.random.default_rng(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How sample size affects the F distribution\n",
        "\n",
        "The degrees of freedom (df₁ = n₁−1, df₂ = n₂−1) control how much the variance estimates fluctuate.\n",
        "\n",
        "- Small samples (small df) → wide, heavy-tailed distribution\n",
        "- Large samples (large df) → concentrated near 1 (variance estimates stabilize)\n",
        "\n",
        "Here are a few F pdf curves to make that shape change visible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pairs = [(5, 5), (10, 10), (30, 30), (5, 30)]\n",
        "x_grid = np.linspace(1e-4, 5.0, 900)\n",
        "\n",
        "fig = go.Figure()\n",
        "for d1, d2 in df_pairs:\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=x_grid,\n",
        "            y=f_pdf(x_grid, d1, d2),\n",
        "            mode='lines',\n",
        "            name=f'df1={d1}, df2={d2}',\n",
        "        )\n",
        "    )\n",
        "\n",
        "fig.add_vline(x=1.0, line_dash='dash', line_color='black')\n",
        "fig.update_layout(\n",
        "    title='How degrees of freedom shape the F distribution',\n",
        "    xaxis_title='F',\n",
        "    yaxis_title='density',\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) What problem does the F-test solve?\n",
        "\n",
        "Sometimes the mean is not the main issue. You might care more about **spread**:\n",
        "\n",
        "- Does a new manufacturing process reduce variability?\n",
        "- Is sensor A noisier than sensor B?\n",
        "- Are two groups equally consistent, even if their averages match?\n",
        "\n",
        "A variance F-test is a hypothesis test about **population variances** (σ²), based on **sample variances** (s²).\n",
        "\n",
        "Let's start with a picture: two groups with the same center, but different spread.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_a, n_b = 40, 60\n",
        "a = rng.normal(loc=0.0, scale=1.0, size=n_a)\n",
        "b = rng.normal(loc=0.0, scale=1.8, size=n_b)\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Violin(y=a, name='Group A', box_visible=True, meanline_visible=True))\n",
        "fig.add_trace(go.Violin(y=b, name='Group B', box_visible=True, meanline_visible=True))\n",
        "fig.update_layout(\n",
        "    title='Same center, different spread',\n",
        "    yaxis_title='value',\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) The hypothesis, assumptions, and what the result means\n",
        "\n",
        "### Hypotheses\n",
        "\n",
        "For two independent samples (group 1 and group 2):\n",
        "\n",
        "- **H₀**: σ₁² = σ₂² (equal population variances)\n",
        "- **H₁** (two-sided): σ₁² ≠ σ₂²\n",
        "- **H₁** (one-sided): σ₁² > σ₂² or σ₁² < σ₂²\n",
        "\n",
        "### Assumptions (important)\n",
        "\n",
        "The classic F-test for variances is derived under:\n",
        "\n",
        "- **Independence** within and across the two samples\n",
        "- **Normality**: each group is (approximately) normally distributed\n",
        "\n",
        "This test is **very sensitive** to outliers and non-normal/heavy-tailed data. If normality is doubtful, consider more robust alternatives such as **Levene**, **Brown–Forsythe**, or **Fligner–Killeen**.\n",
        "\n",
        "### What does rejecting H₀ mean?\n",
        "\n",
        "Rejecting H₀ means: *the observed difference in sample variances is unlikely if the true variances were equal* (given the assumptions).\n",
        "\n",
        "Failing to reject H₀ does **not** prove variances are equal; it usually means *the data are not strong enough to detect a difference*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Where does the F distribution come from?\n",
        "\n",
        "For a Normal sample of size *n*, the sample variance is:\n",
        "\n",
        "$$\n",
        "s^2 = \\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar{x})^2\n",
        "$$\n",
        "\n",
        "A key result (for Normal data) is:\n",
        "\n",
        "$$\n",
        "\\frac{(n-1)s^2}{\\sigma^2} \\sim \\chi^2_{n-1}\n",
        "$$\n",
        "\n",
        "So if you take two independent samples (sizes n₁, n₂), then under **H₀: σ₁² = σ₂²**, the ratio of sample variances\n",
        "\n",
        "$$\n",
        "F = \\frac{s_1^2}{s_2^2}\n",
        "$$\n",
        "\n",
        "follows an **F distribution** with degrees of freedom:\n",
        "\n",
        "- df₁ = n₁ - 1 (numerator)\n",
        "- df₂ = n₂ - 1 (denominator)\n",
        "\n",
        "Let's verify these building blocks with simulation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f_rvs(df1: int, df2: int, size: int, rng: np.random.Generator) -> np.ndarray:\n",
        "    \"\"\"Sample from an F(df1, df2) distribution using the chi-square ratio definition.\"\"\"\n",
        "    num = rng.chisquare(df1, size=size) / df1\n",
        "    den = rng.chisquare(df2, size=size) / df2\n",
        "    return num / den\n",
        "\n",
        "\n",
        "def f_pdf(x: np.ndarray, df1: int, df2: int) -> np.ndarray:\n",
        "    \"\"\"Analytic F(df1, df2) pdf using only stdlib + NumPy (no SciPy).\"\"\"\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    a = df1 / 2.0\n",
        "    b = df2 / 2.0\n",
        "\n",
        "    log_beta = math.lgamma(a) + math.lgamma(b) - math.lgamma(a + b)\n",
        "    log_coeff = a * math.log(df1 / df2) - log_beta\n",
        "\n",
        "    with np.errstate(divide='ignore'):\n",
        "        log_pdf = (\n",
        "            log_coeff\n",
        "            + (a - 1.0) * np.log(x)\n",
        "            - (a + b) * np.log1p((df1 / df2) * x)\n",
        "        )\n",
        "\n",
        "    pdf = np.exp(log_pdf)\n",
        "    return np.where(x > 0, pdf, 0.0)\n",
        "\n",
        "\n",
        "# 1) Scaled sample variance ~ chi-square (Normal data)\n",
        "n = 12\n",
        "sigma = 2.0\n",
        "n_sim = 50_000\n",
        "\n",
        "samples = rng.normal(loc=0.0, scale=sigma, size=(n_sim, n))\n",
        "s2 = samples.var(axis=1, ddof=1)\n",
        "scaled_s2 = (n - 1) * s2 / (sigma**2)\n",
        "\n",
        "chi = rng.chisquare(df=n - 1, size=n_sim)\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(\n",
        "    go.Histogram(\n",
        "        x=scaled_s2,\n",
        "        nbinsx=90,\n",
        "        histnorm='probability density',\n",
        "        name='(n-1)s^2/σ^2 from samples',\n",
        "        opacity=0.6,\n",
        "    )\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Histogram(\n",
        "        x=chi,\n",
        "        nbinsx=90,\n",
        "        histnorm='probability density',\n",
        "        name='Chi-square(df=n-1)',\n",
        "        opacity=0.6,\n",
        "    )\n",
        ")\n",
        "fig.update_layout(\n",
        "    title='Scaled sample variance follows a chi-square distribution (Normal data)',\n",
        "    barmode='overlay',\n",
        "    xaxis_title='value',\n",
        "    yaxis_title='density',\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "\n",
        "# 2) Ratio of (chi-square/df) terms ~ F\n",
        "n1, n2 = 10, 25\n",
        "df1, df2 = n1 - 1, n2 - 1\n",
        "\n",
        "f_sim = f_rvs(df1, df2, size=n_sim, rng=rng)\n",
        "x_max = np.quantile(f_sim, 0.995)\n",
        "x_grid = np.linspace(1e-4, x_max, 700)\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(\n",
        "    go.Histogram(\n",
        "        x=f_sim,\n",
        "        nbinsx=120,\n",
        "        histnorm='probability density',\n",
        "        name='Simulated F',\n",
        "        opacity=0.6,\n",
        "    )\n",
        ")\n",
        "fig.add_trace(go.Scatter(x=x_grid, y=f_pdf(x_grid, df1, df2), mode='lines', name='Analytic pdf'))\n",
        "fig.update_layout(\n",
        "    title=f'F distribution from a chi-square ratio (df1={df1}, df2={df2})',\n",
        "    barmode='overlay',\n",
        "    xaxis_title='F value',\n",
        "    yaxis_title='density',\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) The variance F-test: statistic, p-value, and critical region\n",
        "\n",
        "Given samples `x` and `y`:\n",
        "\n",
        "- Compute unbiased sample variances: s₁², s₂² (using `ddof=1`)\n",
        "- Test statistic:\n",
        "\n",
        "$$\n",
        "F_{obs} = \\frac{s_1^2}{s_2^2}\n",
        "$$\n",
        "\n",
        "- Degrees of freedom: df₁ = n₁ - 1, df₂ = n₂ - 1\n",
        "\n",
        "### Interpreting F_obs\n",
        "\n",
        "- If **F_obs ≈ 1**, the sample variances are similar.\n",
        "- If **F_obs is large**, group 1 looks more variable than group 2.\n",
        "- If **F_obs is small** (≪ 1), group 1 looks less variable.\n",
        "\n",
        "### Two-sided decision rule (α = 0.05)\n",
        "\n",
        "Reject H₀ if F_obs lands in either tail:\n",
        "\n",
        "$$\n",
        "F_{obs} < F_{\\alpha/2}(df_1, df_2) \\quad \\text{or} \\quad F_{obs} > F_{1-\\alpha/2}(df_1, df_2)\n",
        "$$\n",
        "\n",
        "In practice, the p-value is:\n",
        "\n",
        "$$\n",
        "p = 2 \\cdot \\min(\\Pr(F \\le F_{obs}),\\, \\Pr(F \\ge F_{obs}))\n",
        "$$\n",
        "\n",
        "We'll compute these probabilities with a **Monte Carlo approximation** (NumPy only).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f_test_variances(\n",
        "    x: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    *,\n",
        "    alternative: str = 'two-sided',\n",
        "    alpha: float = 0.05,\n",
        "    n_sim: int = 300_000,\n",
        "    seed: int = 0,\n",
        ") -> dict:\n",
        "    \"\"\"Two-sample F-test for equal variances using a Monte Carlo reference distribution.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x, y:\n",
        "        1D samples.\n",
        "    alternative:\n",
        "        'two-sided', 'greater' (σ₁² > σ₂²), or 'less' (σ₁² < σ₂²).\n",
        "    alpha:\n",
        "        Significance level.\n",
        "    n_sim:\n",
        "        Number of Monte Carlo draws from F(df1, df2).\n",
        "    seed:\n",
        "        RNG seed (for reproducibility).\n",
        "    \"\"\"\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    y = np.asarray(y, dtype=float)\n",
        "    if x.ndim != 1 or y.ndim != 1:\n",
        "        raise ValueError('x and y must be 1D arrays.')\n",
        "    if len(x) < 2 or len(y) < 2:\n",
        "        raise ValueError('Need at least 2 observations per group.')\n",
        "    if not (0.0 < alpha < 1.0):\n",
        "        raise ValueError('alpha must be in (0, 1).')\n",
        "\n",
        "    n1, n2 = len(x), len(y)\n",
        "    df1, df2 = n1 - 1, n2 - 1\n",
        "\n",
        "    s1_sq = x.var(ddof=1)\n",
        "    s2_sq = y.var(ddof=1)\n",
        "    f_obs = s1_sq / s2_sq\n",
        "\n",
        "    rng_local = np.random.default_rng(seed)\n",
        "    f_sim = f_rvs(df1, df2, size=n_sim, rng=rng_local)\n",
        "\n",
        "    p_right = np.mean(f_sim >= f_obs)\n",
        "    p_left = np.mean(f_sim <= f_obs)\n",
        "\n",
        "    alternative_norm = alternative.strip().lower()\n",
        "\n",
        "    if alternative_norm in {'two-sided', 'two_sided', 'two sided'}:\n",
        "        alternative_canonical = 'two-sided'\n",
        "        p_value = 2.0 * min(p_left, p_right)\n",
        "        p_value = float(min(p_value, 1.0))\n",
        "\n",
        "        q_low, q_high = np.quantile(f_sim, [alpha / 2.0, 1.0 - alpha / 2.0])\n",
        "        critical_values = (float(q_low), float(q_high))\n",
        "        reject = bool((f_obs < q_low) or (f_obs > q_high))\n",
        "\n",
        "        # CI for variance ratio σ₁² / σ₂² (Monte Carlo quantiles)\n",
        "        ci_low = float(f_obs / q_high)\n",
        "        ci_high = float(f_obs / q_low)\n",
        "        ci = (ci_low, ci_high)\n",
        "    elif alternative_norm in {'greater', 'right', 'larger'}:\n",
        "        alternative_canonical = 'greater'\n",
        "        p_value = float(p_right)\n",
        "        q_high = float(np.quantile(f_sim, 1.0 - alpha))\n",
        "        critical_values = (q_high,)\n",
        "        reject = bool(f_obs > q_high)\n",
        "        ci = None\n",
        "    elif alternative_norm in {'less', 'left', 'smaller'}:\n",
        "        alternative_canonical = 'less'\n",
        "        p_value = float(p_left)\n",
        "        q_low = float(np.quantile(f_sim, alpha))\n",
        "        critical_values = (q_low,)\n",
        "        reject = bool(f_obs < q_low)\n",
        "        ci = None\n",
        "    else:\n",
        "        raise ValueError(\"alternative must be one of: 'two-sided', 'greater', 'less'.\")\n",
        "\n",
        "    # Monte Carlo standard error for the estimated p-value (rough sense of noise)\n",
        "    mc_se = float(np.sqrt(p_value * (1.0 - p_value) / n_sim))\n",
        "\n",
        "    return {\n",
        "        'n1': n1,\n",
        "        'n2': n2,\n",
        "        'df1': df1,\n",
        "        'df2': df2,\n",
        "        's1_sq': float(s1_sq),\n",
        "        's2_sq': float(s2_sq),\n",
        "        'f_obs': float(f_obs),\n",
        "        'alternative': alternative_canonical,\n",
        "        'alpha': float(alpha),\n",
        "        'p_value': float(p_value),\n",
        "        'mc_se': mc_se,\n",
        "        'critical_values': critical_values,\n",
        "        'reject_h0': reject,\n",
        "        'ci_var_ratio': ci,\n",
        "        'n_sim': int(n_sim),\n",
        "        'seed': int(seed),\n",
        "    }\n",
        "\n",
        "\n",
        "def plot_f_test(result: dict, *, x_max_quantile: float = 0.997) -> go.Figure:\n",
        "    df1 = int(result['df1'])\n",
        "    df2 = int(result['df2'])\n",
        "    f_obs = float(result['f_obs'])\n",
        "    alpha = float(result['alpha'])\n",
        "    alternative = result['alternative']\n",
        "\n",
        "    rng_plot = np.random.default_rng(123)\n",
        "    f_sim_plot = f_rvs(df1, df2, size=200_000, rng=rng_plot)\n",
        "    x_max = float(np.quantile(f_sim_plot, x_max_quantile))\n",
        "    x_max = max(x_max, f_obs) * 1.1\n",
        "\n",
        "    x_grid = np.linspace(1e-4, x_max, 900)\n",
        "    pdf = f_pdf(x_grid, df1, df2)\n",
        "\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=x_grid, y=pdf, mode='lines', name=f'F pdf (df1={df1}, df2={df2})'))\n",
        "\n",
        "    # Shade rejection region(s)\n",
        "    if alternative == 'two-sided':\n",
        "        q_low, q_high = result['critical_values']\n",
        "\n",
        "        left = x_grid <= q_low\n",
        "        right = x_grid >= q_high\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=x_grid[left],\n",
        "                y=pdf[left],\n",
        "                mode='lines',\n",
        "                fill='tozeroy',\n",
        "                name=f'Reject (α/2={alpha/2:.3f})',\n",
        "                line=dict(color='rgba(239, 85, 59, 1.0)'),\n",
        "                fillcolor='rgba(239, 85, 59, 0.25)',\n",
        "            )\n",
        "        )\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=x_grid[right],\n",
        "                y=pdf[right],\n",
        "                mode='lines',\n",
        "                fill='tozeroy',\n",
        "                name=f'Reject (α/2={alpha/2:.3f})',\n",
        "                line=dict(color='rgba(239, 85, 59, 1.0)'),\n",
        "                fillcolor='rgba(239, 85, 59, 0.25)',\n",
        "                showlegend=False,\n",
        "            )\n",
        "        )\n",
        "        fig.add_vline(x=q_low, line_dash='dot', line_color='rgba(239, 85, 59, 0.9)')\n",
        "        fig.add_vline(x=q_high, line_dash='dot', line_color='rgba(239, 85, 59, 0.9)')\n",
        "    elif alternative == 'greater':\n",
        "        (q_high,) = result['critical_values']\n",
        "        right = x_grid >= q_high\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=x_grid[right],\n",
        "                y=pdf[right],\n",
        "                mode='lines',\n",
        "                fill='tozeroy',\n",
        "                name=f'Reject (α={alpha:.3f})',\n",
        "                line=dict(color='rgba(239, 85, 59, 1.0)'),\n",
        "                fillcolor='rgba(239, 85, 59, 0.25)',\n",
        "            )\n",
        "        )\n",
        "        fig.add_vline(x=q_high, line_dash='dot', line_color='rgba(239, 85, 59, 0.9)')\n",
        "    elif alternative == 'less':\n",
        "        (q_low,) = result['critical_values']\n",
        "        left = x_grid <= q_low\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=x_grid[left],\n",
        "                y=pdf[left],\n",
        "                mode='lines',\n",
        "                fill='tozeroy',\n",
        "                name=f'Reject (α={alpha:.3f})',\n",
        "                line=dict(color='rgba(239, 85, 59, 1.0)'),\n",
        "                fillcolor='rgba(239, 85, 59, 0.25)',\n",
        "            )\n",
        "        )\n",
        "        fig.add_vline(x=q_low, line_dash='dot', line_color='rgba(239, 85, 59, 0.9)')\n",
        "    else:\n",
        "        raise ValueError('Unknown alternative in result dict.')\n",
        "\n",
        "    fig.add_vline(x=f_obs, line_dash='dash', line_color='black')\n",
        "    fig.add_annotation(\n",
        "        x=f_obs,\n",
        "        y=float(np.interp(f_obs, x_grid, pdf)),\n",
        "        text=f\"F_obs={f_obs:.3f}<br>p≈{result['p_value']:.4f}\",\n",
        "        showarrow=True,\n",
        "        arrowhead=2,\n",
        "        ax=40,\n",
        "        ay=-40,\n",
        "        bgcolor='rgba(255,255,255,0.9)',\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='F-test: reference distribution and rejection region',\n",
        "        xaxis_title='F',\n",
        "        yaxis_title='density',\n",
        "        legend_title='Region',\n",
        "    )\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Worked example: equal variances (H₀ true)\n",
        "\n",
        "We will sample two Normal groups with the **same** standard deviation (σ₁ = σ₂). In this situation, we expect the test to reject only about α of the time.\n",
        "\n",
        "For a single run, the p-value can land anywhere from 0 to 1 (randomness!), but on average it should not look systematically small.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n1, n2 = 18, 22\n",
        "x = rng.normal(loc=0.0, scale=1.2, size=n1)\n",
        "y = rng.normal(loc=0.0, scale=1.2, size=n2)\n",
        "\n",
        "res_equal = f_test_variances(x, y, alternative='two-sided', alpha=0.05, n_sim=400_000, seed=1)\n",
        "res_equal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_f_test(res_equal).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Worked example: different variances (H₁ true)\n",
        "\n",
        "Now we generate two groups where the second group is noisier (larger σ). This should push **F_obs** away from 1 and often produce a small p-value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n1, n2 = 18, 22\n",
        "x = rng.normal(loc=0.0, scale=1.0, size=n1)\n",
        "y = rng.normal(loc=0.0, scale=2.0, size=n2)\n",
        "\n",
        "res_diff = f_test_variances(x, y, alternative='two-sided', alpha=0.05, n_sim=400_000, seed=2)\n",
        "res_diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_f_test(res_diff).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Interpreting the output (what it *exactly* means)\n",
        "\n",
        "From the result dictionary:\n",
        "\n",
        "- `f_obs = s1_sq / s2_sq` is the **observed variance ratio**.\n",
        "- `p_value` is the probability (under H₀) of seeing an F statistic at least as extreme as the observed one.\n",
        "- `reject_h0` tells you whether the observed statistic lands in the rejection region for your chosen α.\n",
        "- `ci_var_ratio` is a (Monte Carlo) **confidence interval for σ₁² / σ₂²**.\n",
        "\n",
        "### A practical reading\n",
        "\n",
        "- If `p_value < α`: the data are inconsistent with equal variances (under the Normality assumption).\n",
        "- If `p_value ≥ α`: you do not have enough evidence to claim the variances differ.\n",
        "\n",
        "A helpful companion to the p-value is the confidence interval:\n",
        "\n",
        "- If the CI for σ₁² / σ₂² includes **1**, equal variances are plausible.\n",
        "- If the CI is entirely above **1**, variance 1 is likely larger.\n",
        "- If the CI is entirely below **1**, variance 1 is likely smaller.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Pitfall demo: heavy tails can break the test\n",
        "\n",
        "Even when the true variances are equal, non-normal data can cause the F-test to reject too often.\n",
        "\n",
        "Below we compare the **empirical false positive rate** (Type I error) under:\n",
        "\n",
        "- Normal data (assumptions match)\n",
        "- Heavy-tailed data (Student-t with df=3, scaled to variance 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "alpha = 0.05\n",
        "n1, n2 = 20, 20\n",
        "df1, df2 = n1 - 1, n2 - 1\n",
        "\n",
        "# Critical region under the F(df1, df2) model (computed once)\n",
        "rng_crit = np.random.default_rng(0)\n",
        "f_crit_sim = f_rvs(df1, df2, size=600_000, rng=rng_crit)\n",
        "q_low, q_high = np.quantile(f_crit_sim, [alpha / 2.0, 1.0 - alpha / 2.0])\n",
        "\n",
        "n_rep = 8_000\n",
        "\n",
        "# Case A: Normal (variance 1)\n",
        "x_norm = rng.normal(0.0, 1.0, size=(n_rep, n1))\n",
        "y_norm = rng.normal(0.0, 1.0, size=(n_rep, n2))\n",
        "f_norm = x_norm.var(axis=1, ddof=1) / y_norm.var(axis=1, ddof=1)\n",
        "reject_norm = np.mean((f_norm < q_low) | (f_norm > q_high))\n",
        "\n",
        "# Case B: Heavy-tailed t(df=3), scaled to variance 1\n",
        "# Var(t_df) = df/(df-2) for df>2 -> 3/(1)=3, so divide by sqrt(3) to get variance ~1\n",
        "x_t = rng.standard_t(df=3, size=(n_rep, n1)) / np.sqrt(3.0)\n",
        "y_t = rng.standard_t(df=3, size=(n_rep, n2)) / np.sqrt(3.0)\n",
        "f_t = x_t.var(axis=1, ddof=1) / y_t.var(axis=1, ddof=1)\n",
        "reject_t = np.mean((f_t < q_low) | (f_t > q_high))\n",
        "\n",
        "fig = px.bar(\n",
        "    x=['Normal', 'Student-t df=3 (heavy-tailed)'],\n",
        "    y=[reject_norm, reject_t],\n",
        "    title='Type I error inflation when Normality is violated',\n",
        "    labels={'x': 'data generating distribution (true variances equal)', 'y': f'fraction rejected (α={alpha})'},\n",
        ")\n",
        "fig.add_hline(y=alpha, line_dash='dash', line_color='black')\n",
        "fig.update_layout(yaxis_range=[0, max(alpha * 2.5, reject_t * 1.15)])\n",
        "fig.show()\n",
        "\n",
        "reject_norm, reject_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Takeaway\n",
        "\n",
        "If your data are plausibly non-normal or contain outliers, the classic F-test can be misleading.\n",
        "\n",
        "In that case, look at robust variance tests (Levene / Brown–Forsythe / Fligner–Killeen) and always pair any test with **plots** (box/violin, histograms, QQ-plots).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Connection to ANOVA / regression (why F shows up everywhere)\n",
        "\n",
        "In ANOVA and linear regression, an F-statistic typically compares **two variance estimates**:\n",
        "\n",
        "- a variance explained by a model/effect (signal)\n",
        "- a residual variance not explained (noise)\n",
        "\n",
        "That ratio also follows an F distribution under suitable assumptions. So even though this notebook focuses on the variance-ratio test, the same distribution is doing a lot of work across classical statistics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n",
        "\n",
        "1) Swap the groups (`x` and `y`) in the worked examples. What happens to `f_obs`? What happens to a two-sided p-value?\n",
        "\n",
        "2) Increase sample sizes and observe how the F distribution tightens around 1 under H₀.\n",
        "\n",
        "3) Create data with a few extreme outliers and see how quickly the test starts rejecting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n",
        "\n",
        "- F distribution (definition as ratio of chi-square variables)\n",
        "- Variance ratio confidence interval derived from F quantiles\n",
        "- Robust alternatives: Levene, Brown–Forsythe, Fligner–Killeen\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
