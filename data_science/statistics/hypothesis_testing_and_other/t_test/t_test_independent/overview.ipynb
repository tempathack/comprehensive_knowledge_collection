{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3402da3b",
   "metadata": {},
   "source": [
    "# Independent two-sample t-test (`t_test_independent`)\n",
    "\n",
    "The **independent (unpaired) two-sample t-test** asks:\n",
    "\n",
    "> “Do these two independent groups plausibly come from populations with the same mean?”\n",
    "\n",
    "It is used when you have:\n",
    "- a **continuous** outcome (interval/ratio scale)\n",
    "- **two independent groups** (different people/items; not paired / repeated measurements)\n",
    "- interest in a **difference in means**\n",
    "\n",
    "This notebook covers:\n",
    "- **Student’s t-test** (assumes equal variances)\n",
    "- **Welch’s t-test** (does *not* assume equal variances; often the safer default)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44045a4d",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "By the end you should be able to:\n",
    "\n",
    "- choose the right t-test variant (Student vs Welch)\n",
    "- write down $H_0$ / $H_1$ and pick one- vs two-sided alternatives\n",
    "- compute the t-statistic and degrees of freedom from scratch (NumPy)\n",
    "- understand what the **p-value** is (and what it is not)\n",
    "- interpret results using both **p-values** and **confidence intervals**\n",
    "- build intuition with simulations and Plotly visuals\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "361305b2",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "import platform\n",
    "from dataclasses import dataclass\n",
    "from typing import Literal\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "print(\"Python\", platform.python_version())\n",
    "print(\"NumPy\", np.__version__)\n",
    "\n",
    "# SciPy is optional: we only use it for cross-checks in a later section.\n",
    "try:\n",
    "    import scipy\n",
    "    from scipy.stats import t as scipy_t\n",
    "    from scipy.stats import ttest_ind\n",
    "\n",
    "    HAS_SCIPY = True\n",
    "    print(\"SciPy\", scipy.__version__)\n",
    "except Exception as e:\n",
    "    HAS_SCIPY = False\n",
    "    print(\"SciPy not available:\", repr(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742fb72b",
   "metadata": {},
   "source": [
    "## Prerequisites (quick)\n",
    "\n",
    "Math / stats:\n",
    "- sample mean and (unbiased) sample variance\n",
    "- the idea of a **standard error** (estimate of sampling uncertainty)\n",
    "- basic probability: \"area under a curve\"\n",
    "\n",
    "Tools:\n",
    "- NumPy\n",
    "- Plotly (for visuals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfaadca",
   "metadata": {},
   "source": [
    "## 1) When to use the independent t-test\n",
    "\n",
    "Use it when:\n",
    "- you compare the **means** of a numeric variable between **two independent groups**\n",
    "- you can treat observations as **independent** within and across groups\n",
    "- the outcome is **approximately normal** within each group (or sample sizes are large enough for the CLT to help)\n",
    "\n",
    "Do **not** use it when:\n",
    "- the same subject/item is measured twice → use a **paired t-test**\n",
    "- you have >2 groups → use **ANOVA** (or multiple-comparisons-corrected pairwise tests)\n",
    "- you care about medians / heavy-tailed distributions / strong outliers → consider **Mann–Whitney U**, a **permutation test**, or robust methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d006d39c",
   "metadata": {},
   "source": [
    "## 2) Hypotheses and alternatives\n",
    "\n",
    "Let $\\mu_1$ and $\\mu_2$ be the **population means** for group 1 and group 2.\n",
    "\n",
    "Most common (two-sided):\n",
    "\n",
    "$$\n",
    "H_0: \\mu_1 - \\mu_2 = 0\n",
    "\\qquad\text{vs}\\qquad\n",
    "H_1: \\mu_1 - \\mu_2 \n",
    "e 0\n",
    "$$\n",
    "\n",
    "One-sided alternatives are also possible:\n",
    "\n",
    "- **greater**: $H_1: \\mu_1 - \\mu_2 > 0$\n",
    "- **less**: $H_1: \\mu_1 - \\mu_2 < 0$\n",
    "\n",
    "Pick the alternative **before** looking at the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c3af5d",
   "metadata": {},
   "source": [
    "## 3) The test statistic (Student vs Welch)\n",
    "\n",
    "We observe samples:\n",
    "\n",
    "- group 1: $x_1,\\dots,x_{n_1}$\n",
    "- group 2: $y_1,\\dots,y_{n_2}$\n",
    "\n",
    "Compute sample means:\n",
    "\n",
    "$$\n",
    "\bar{x} = \f",
    "rac{1}{n_1}\\sum_{i=1}^{n_1} x_i,\n",
    "\\qquad\n",
    "\bar{y} = \f",
    "rac{1}{n_2}\\sum_{j=1}^{n_2} y_j\n",
    "$$\n",
    "\n",
    "and unbiased sample variances:\n",
    "\n",
    "$$\n",
    "s_x^2 = \f",
    "rac{1}{n_1-1}\\sum_{i=1}^{n_1}(x_i-\bar{x})^2,\n",
    "\\qquad\n",
    "s_y^2 = \f",
    "rac{1}{n_2-1}\\sum_{j=1}^{n_2}(y_j-\bar{y})^2\n",
    "$$\n",
    "\n",
    "The **difference in sample means** is:\n",
    "\n",
    "$$\n",
    "\\Delta = \bar{x} - \bar{y}.\n",
    "$$\n",
    "\n",
    "The t-test turns this into a **signal-to-noise ratio**:\n",
    "\n",
    "$$\n",
    "t = \f",
    "rac{\\Delta}{\\mathrm{SE}(\\Delta)},\n",
    "$$\n",
    "\n",
    "where $\\mathrm{SE}(\\Delta)$ is the **standard error** of the difference.\n",
    "\n",
    "### Student’s t-test (equal variances)\n",
    "\n",
    "Assumes $\\sigma_x^2 = \\sigma_y^2$.\n",
    "\n",
    "Pooled variance:\n",
    "\n",
    "$$\n",
    "s_p^2 = \f",
    "rac{(n_1-1)s_x^2 + (n_2-1)s_y^2}{n_1+n_2-2}\n",
    "$$\n",
    "\n",
    "Standard error:\n",
    "\n",
    "$$\n",
    "\\mathrm{SE}(\\Delta) = \\sqrt{s_p^2\\left(\f",
    "rac{1}{n_1}+\f",
    "rac{1}{n_2}\r",
    "ight)}\n",
    "$$\n",
    "\n",
    "Degrees of freedom:\n",
    "\n",
    "$$\n",
    "\n",
    "u = n_1 + n_2 - 2\n",
    "$$\n",
    "\n",
    "### Welch’s t-test (unequal variances)\n",
    "\n",
    "Does not assume equal variances.\n",
    "\n",
    "Standard error:\n",
    "\n",
    "$$\n",
    "\\mathrm{SE}(\\Delta) = \\sqrt{\f",
    "rac{s_x^2}{n_1}+\f",
    "rac{s_y^2}{n_2}}\n",
    "$$\n",
    "\n",
    "Approximate degrees of freedom (Welch–Satterthwaite):\n",
    "\n",
    "$$\n",
    "\n",
    "u \u0007pprox\n",
    "\f",
    "rac{\\left(\f",
    "rac{s_x^2}{n_1}+\f",
    "rac{s_y^2}{n_2}\r",
    "ight)^2}{\n",
    "\f",
    "rac{(s_x^2/n_1)^2}{n_1-1} + \f",
    "rac{(s_y^2/n_2)^2}{n_2-1}\n",
    "}\n",
    "$$\n",
    "\n",
    "### From $t$ to a p-value\n",
    "\n",
    "Under $H_0$ (and assumptions), the statistic follows a **Student t distribution**:\n",
    "\n",
    "$$\n",
    "t \\sim t_{\n",
    "u}.\n",
    "$$\n",
    "\n",
    "The **p-value** is a tail probability under that reference distribution (two-sided example):\n",
    "\n",
    "$$\n",
    "p = P(|T| \\ge |t_{\text{obs}}| \\mid H_0).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30610736",
   "metadata": {},
   "source": [
    "## 4) What the p-value means (precisely)\n",
    "\n",
    "A p-value is:\n",
    "\n",
    "- **A probability computed under the null model**.\n",
    "- The probability of getting a result **at least as extreme as observed**, **if** $H_0$ were true.\n",
    "\n",
    "A p-value is **not**:\n",
    "\n",
    "- the probability that $H_0$ is true\n",
    "- the probability that the result happened \"by chance\" (without defining a model)\n",
    "- a measure of practical importance (effect size matters!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a847e7",
   "metadata": {},
   "source": [
    "## 5) NumPy-only implementation\n",
    "\n",
    "We'll implement:\n",
    "\n",
    "1. summary stats ($\bar{x}$, $s^2$)\n",
    "2. the t-statistic + degrees of freedom (Student or Welch)\n",
    "3. the Student-t PDF\n",
    "4. a **numerical CDF** via integration (needed for p-values and critical values)\n",
    "\n",
    "Note: numerical integration is for learning; for production-grade accuracy/performance, prefer `scipy.stats`.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "212d1944",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "Alternative = Literal[\"two-sided\", \"less\", \"greater\"]\n",
    "\n",
    "\n",
    "def _as_1d_float(x, name: str) -> np.ndarray:\n",
    "    arr = np.asarray(x, dtype=float).reshape(-1)\n",
    "    if arr.size < 2:\n",
    "        raise ValueError(f\"{name} must have at least 2 observations\")\n",
    "    if np.any(~np.isfinite(arr)):\n",
    "        raise ValueError(f\"{name} contains non-finite values\")\n",
    "    return arr\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TDistLookup:\n",
    "    df: float\n",
    "    t_max: float\n",
    "    xs: np.ndarray\n",
    "    cdf_pos: np.ndarray\n",
    "\n",
    "\n",
    "def t_pdf(x: np.ndarray | float, df: float) -> np.ndarray:\n",
    "    '''Student-t PDF (NumPy-only).'''\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    df = float(df)\n",
    "    if not np.isfinite(df) or df <= 0:\n",
    "        raise ValueError(\"df must be finite and > 0\")\n",
    "\n",
    "    # pdf(x) = Gamma((df+1)/2) / (sqrt(df*pi) * Gamma(df/2)) * (1 + x^2/df)^(-(df+1)/2)\n",
    "    log_c = (\n",
    "        math.lgamma((df + 1.0) / 2.0)\n",
    "        - 0.5 * (math.log(df) + math.log(math.pi))\n",
    "        - math.lgamma(df / 2.0)\n",
    "    )\n",
    "    c = math.exp(log_c)\n",
    "    return c * (1.0 + (x * x) / df) ** (-(df + 1.0) / 2.0)\n",
    "\n",
    "\n",
    "def make_t_lookup(df: float, *, t_max: float = 12.0, n: int = 60_000) -> TDistLookup:\n",
    "    '''Approximate the t CDF on [0, t_max] via cumulative trapezoid integration.'''\n",
    "    df = float(df)\n",
    "    t_max = float(t_max)\n",
    "    n = int(n)\n",
    "\n",
    "    if not np.isfinite(df) or df <= 0:\n",
    "        raise ValueError(\"df must be finite and > 0\")\n",
    "    if not np.isfinite(t_max) or t_max <= 0:\n",
    "        raise ValueError(\"t_max must be finite and > 0\")\n",
    "    if n < 1000:\n",
    "        raise ValueError(\"n must be >= 1000 for a reasonable CDF approximation\")\n",
    "\n",
    "    xs = np.linspace(0.0, t_max, n + 1)\n",
    "    pdf = t_pdf(xs, df)\n",
    "    dx = float(xs[1] - xs[0])\n",
    "\n",
    "    # Integral from 0..xs[i] (for i>=1)\n",
    "    area = np.cumsum((pdf[:-1] + pdf[1:]) * 0.5 * dx)\n",
    "\n",
    "    cdf_pos = np.empty_like(xs)\n",
    "    cdf_pos[0] = 0.5\n",
    "    cdf_pos[1:] = 0.5 + area\n",
    "    cdf_pos = np.clip(cdf_pos, 0.0, 1.0)\n",
    "\n",
    "    return TDistLookup(df=df, t_max=t_max, xs=xs, cdf_pos=cdf_pos)\n",
    "\n",
    "\n",
    "def t_cdf(t: np.ndarray | float, lookup: TDistLookup) -> np.ndarray:\n",
    "    '''Student-t CDF via interpolation from a precomputed lookup table.'''\n",
    "    t = np.asarray(t, dtype=float)\n",
    "    t_abs = np.abs(t)\n",
    "\n",
    "    cdf_abs = np.interp(t_abs, lookup.xs, lookup.cdf_pos, left=0.5, right=1.0)\n",
    "    return np.where(t >= 0, cdf_abs, 1.0 - cdf_abs)\n",
    "\n",
    "\n",
    "def t_ppf(p: np.ndarray | float, lookup: TDistLookup) -> np.ndarray:\n",
    "    '''Inverse CDF (quantile) via interpolation.'''\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    if np.any((p <= 0.0) | (p >= 1.0)):\n",
    "        raise ValueError(\"p must be in (0, 1)\")\n",
    "\n",
    "    sign = np.where(p >= 0.5, 1.0, -1.0)\n",
    "    p_abs = np.where(p >= 0.5, p, 1.0 - p)\n",
    "\n",
    "    t_abs = np.interp(p_abs, lookup.cdf_pos, lookup.xs)\n",
    "    return sign * t_abs\n",
    "\n",
    "\n",
    "def t_p_value(t_obs: float, lookup: TDistLookup, *, alternative: Alternative) -> float:\n",
    "    '''p-value for a t-statistic under t(df).'''\n",
    "    cdf = float(t_cdf(t_obs, lookup))\n",
    "    if alternative == \"two-sided\":\n",
    "        p = 2.0 * min(cdf, 1.0 - cdf)\n",
    "    elif alternative == \"greater\":\n",
    "        p = 1.0 - cdf\n",
    "    elif alternative == \"less\":\n",
    "        p = cdf\n",
    "    else:\n",
    "        raise ValueError(\"alternative must be one of: 'two-sided', 'less', 'greater'\")\n",
    "\n",
    "    return float(np.clip(p, 0.0, 1.0))\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class IndependentTTestResult:\n",
    "    t: float\n",
    "    df: float\n",
    "    p_value: float\n",
    "    alternative: Alternative\n",
    "    equal_var: bool\n",
    "\n",
    "    n1: int\n",
    "    n2: int\n",
    "    mean1: float\n",
    "    mean2: float\n",
    "    var1: float\n",
    "    var2: float\n",
    "\n",
    "    diff: float\n",
    "    se: float\n",
    "    ci: tuple[float, float]\n",
    "    alpha: float\n",
    "\n",
    "    cohens_d: float\n",
    "    cohens_d_method: str\n",
    "\n",
    "\n",
    "def t_test_independent_numpy(\n",
    "    x,\n",
    "    y,\n",
    "    *,\n",
    "    equal_var: bool = False,\n",
    "    alternative: Alternative = \"two-sided\",\n",
    "    alpha: float = 0.05,\n",
    "    t_max: float = 12.0,\n",
    "    lookup_n: int = 60_000,\n",
    ") -> IndependentTTestResult:\n",
    "    '''Independent two-sample t-test (Student or Welch), using NumPy-only p-values.'''\n",
    "    x = _as_1d_float(x, \"x\")\n",
    "    y = _as_1d_float(y, \"y\")\n",
    "\n",
    "    n1, n2 = int(x.size), int(y.size)\n",
    "    mean1, mean2 = float(x.mean()), float(y.mean())\n",
    "    var1, var2 = float(x.var(ddof=1)), float(y.var(ddof=1))\n",
    "    diff = mean1 - mean2\n",
    "\n",
    "    if equal_var:\n",
    "        df = float(n1 + n2 - 2)\n",
    "        sp2 = ((n1 - 1) * var1 + (n2 - 1) * var2) / df\n",
    "        se = math.sqrt(sp2 * (1.0 / n1 + 1.0 / n2))\n",
    "        cohens_d = diff / math.sqrt(sp2)\n",
    "        cohens_d_method = \"pooled SD\"\n",
    "    else:\n",
    "        se = math.sqrt(var1 / n1 + var2 / n2)\n",
    "        df = float(\n",
    "            (var1 / n1 + var2 / n2) ** 2\n",
    "            / ((var1 / n1) ** 2 / (n1 - 1) + (var2 / n2) ** 2 / (n2 - 1))\n",
    "        )\n",
    "        # A common fallback is to standardize by the average SD (not perfect, but useful for scale).\n",
    "        cohens_d = diff / math.sqrt(0.5 * (var1 + var2))\n",
    "        cohens_d_method = \"average SD\"\n",
    "\n",
    "    if se == 0.0:\n",
    "        raise ValueError(\"Standard error is zero; check data (all values identical?)\")\n",
    "\n",
    "    t_stat = diff / se\n",
    "\n",
    "    if not (0.0 < alpha < 1.0):\n",
    "        raise ValueError(\"alpha must be in (0, 1)\")\n",
    "\n",
    "    lookup = make_t_lookup(df, t_max=t_max, n=lookup_n)\n",
    "    p_value = t_p_value(t_stat, lookup, alternative=alternative)\n",
    "\n",
    "    t_crit = float(t_ppf(1.0 - alpha / 2.0, lookup))  # always two-sided CI\n",
    "    ci = (diff - t_crit * se, diff + t_crit * se)\n",
    "\n",
    "    return IndependentTTestResult(\n",
    "        t=float(t_stat),\n",
    "        df=float(df),\n",
    "        p_value=float(p_value),\n",
    "        alternative=alternative,\n",
    "        equal_var=bool(equal_var),\n",
    "        n1=n1,\n",
    "        n2=n2,\n",
    "        mean1=mean1,\n",
    "        mean2=mean2,\n",
    "        var1=var1,\n",
    "        var2=var2,\n",
    "        diff=float(diff),\n",
    "        se=float(se),\n",
    "        ci=(float(ci[0]), float(ci[1])),\n",
    "        alpha=float(alpha),\n",
    "        cohens_d=float(cohens_d),\n",
    "        cohens_d_method=cohens_d_method,\n",
    "    )\n",
    "\n",
    "\n",
    "def format_result(r: IndependentTTestResult) -> str:\n",
    "    ci_level = int(round((1.0 - r.alpha) * 100))\n",
    "\n",
    "    return \"\\n\".join(\n",
    "        [\n",
    "            f\"t = {r.t:.4f} | df = {r.df:.2f} | p = {r.p_value:.6g} ({r.alternative}, equal_var={r.equal_var})\",\n",
    "            f\"mean1 = {r.mean1:.4f} (n={r.n1}), mean2 = {r.mean2:.4f} (n={r.n2})\",\n",
    "            f\"diff = mean1 - mean2 = {r.diff:.4f}, SE(diff) = {r.se:.4f}\",\n",
    "            f\"{ci_level}% CI for diff: [{r.ci[0]:.4f}, {r.ci[1]:.4f}]\",\n",
    "            f\"Cohen's d ({r.cohens_d_method}): {r.cohens_d:.4f}\",\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e9cf3d",
   "metadata": {},
   "source": [
    "## 6) Worked example (synthetic data)\n",
    "\n",
    "We create two independent groups with a small mean difference.\n",
    "\n",
    "Tip: In real analyses, build these arrays from your dataset after filtering into two groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "dad5151e",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "n1, n2 = 25, 28\n",
    "\n",
    "group1 = rng.normal(loc=0.0, scale=1.0, size=n1)\n",
    "group2 = rng.normal(loc=0.5, scale=1.0, size=n2)\n",
    "\n",
    "print(\"group1: mean=\", float(group1.mean()), \"sd=\", float(group1.std(ddof=1)))\n",
    "print(\"group2: mean=\", float(group2.mean()), \"sd=\", float(group2.std(ddof=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cef391f3",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize the raw distributions\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=group1,\n",
    "        name=\"group1\",\n",
    "        histnorm=\"probability density\",\n",
    "        opacity=0.6,\n",
    "        marker_color=\"#1f77b4\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=group2,\n",
    "        name=\"group2\",\n",
    "        histnorm=\"probability density\",\n",
    "        opacity=0.6,\n",
    "        marker_color=\"#d62728\",\n",
    "    )\n",
    ")\n",
    "\n",
    "m1 = float(group1.mean())\n",
    "m2 = float(group2.mean())\n",
    "fig.add_shape(type=\"line\", x0=m1, x1=m1, y0=0, y1=1, yref=\"paper\", line=dict(color=\"#1f77b4\", dash=\"dash\"))\n",
    "fig.add_shape(type=\"line\", x0=m2, x1=m2, y0=0, y1=1, yref=\"paper\", line=dict(color=\"#d62728\", dash=\"dash\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Independent groups: histogram (density) with sample means\",\n",
    "    barmode=\"overlay\",\n",
    "    xaxis_title=\"Value\",\n",
    "    yaxis_title=\"Density\",\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig2 = go.Figure()\n",
    "fig2.add_trace(go.Violin(y=group1, name=\"group1\", box_visible=True, meanline_visible=True, line_color=\"#1f77b4\"))\n",
    "fig2.add_trace(go.Violin(y=group2, name=\"group2\", box_visible=True, meanline_visible=True, line_color=\"#d62728\"))\n",
    "fig2.update_layout(title=\"Violin + box plot\", yaxis_title=\"Value\")\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "81e3cc9c",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run the test (Student vs Welch)\n",
    "\n",
    "res_student = t_test_independent_numpy(group1, group2, equal_var=True)\n",
    "res_welch = t_test_independent_numpy(group1, group2, equal_var=False)\n",
    "\n",
    "print(\"Student (equal variances):\")\n",
    "print(format_result(res_student))\n",
    "print(\"\\nWelch (unequal variances):\")\n",
    "print(format_result(res_welch))\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "5e409f9f",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_two_sided_p_value_region(\n",
    "    t_obs: float,\n",
    "    df: float,\n",
    "    p_value: float,\n",
    "    *,\n",
    "    x_max: float = 6.0,\n",
    "    n: int = 2000,\n",
    ") -> go.Figure:\n",
    "    xs = np.linspace(-x_max, x_max, n)\n",
    "    ys = t_pdf(xs, df)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=xs, y=ys, mode=\"lines\", name=f\"t(df={df:.2f})\"))\n",
    "\n",
    "    t_abs = abs(float(t_obs))\n",
    "\n",
    "    xr = np.linspace(t_abs, x_max, 800)\n",
    "    yr = t_pdf(xr, df)\n",
    "\n",
    "    # Right tail polygon\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=np.r_[xr, xr[::-1]],\n",
    "            y=np.r_[yr, np.zeros_like(yr)],\n",
    "            fill=\"toself\",\n",
    "            fillcolor=\"rgba(214, 39, 40, 0.25)\",\n",
    "            line=dict(color=\"rgba(214, 39, 40, 0.45)\"),\n",
    "            hoverinfo=\"skip\",\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Left tail polygon (mirror)\n",
    "    xl = -xr[::-1]  # from -x_max .. -t_abs\n",
    "    yl = yr[::-1]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=np.r_[xl, xl[::-1]],\n",
    "            y=np.r_[yl, np.zeros_like(yl)],\n",
    "            fill=\"toself\",\n",
    "            fillcolor=\"rgba(214, 39, 40, 0.25)\",\n",
    "            line=dict(color=\"rgba(214, 39, 40, 0.45)\"),\n",
    "            hoverinfo=\"skip\",\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    y_top = float(np.max(ys))\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=t_obs,\n",
    "        x1=t_obs,\n",
    "        y0=0.0,\n",
    "        y1=y_top,\n",
    "        line=dict(color=\"black\", dash=\"dash\"),\n",
    "    )\n",
    "\n",
    "    fig.add_annotation(\n",
    "        x=t_obs,\n",
    "        y=y_top * 0.9,\n",
    "        text=f\"t = {t_obs:.3f}<br>p = {p_value:.3g}\",\n",
    "        showarrow=True,\n",
    "        arrowhead=2,\n",
    "        ax=40,\n",
    "        ay=-40,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Two-sided p-value = shaded tail area under t(df)\",\n",
    "        xaxis_title=\"t\",\n",
    "        yaxis_title=\"Density\",\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "plot_two_sided_p_value_region(res_welch.t, res_welch.df, res_welch.p_value, x_max=6.0).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd49f27",
   "metadata": {},
   "source": [
    "## 7) How to interpret the output\n",
    "\n",
    "A practical checklist:\n",
    "\n",
    "1. **Direction**: the sign of `t` matches the sign of `mean1 - mean2`.\n",
    "2. **Statistical significance**: compare `p` to your threshold $\u0007lpha$ (commonly 0.05).\n",
    "3. **Confidence interval**: a $(1-\u0007lpha)$ CI for $(\\mu_1-\\mu_2)$ that *excludes* 0 corresponds to rejecting $H_0$ at level $\u0007lpha$.\n",
    "4. **Practical importance**: consider effect size (e.g. Cohen’s d) and whether the CI is meaningfully far from 0.\n",
    "5. **Assumptions**: independence (design), distribution shape/outliers, variance structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "61edba1e",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "for name, r in [(\"Student\", res_student), (\"Welch\", res_welch)]:\n",
    "    includes_zero = r.ci[0] <= 0.0 <= r.ci[1]\n",
    "    print(f\"{name}: CI includes 0? {includes_zero}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba847976",
   "metadata": {},
   "source": [
    "## 8) Assumptions, diagnostics, and pitfalls\n",
    "\n",
    "### Independence (most important)\n",
    "The t-test assumes each observation is independent. This is usually a **study design** question (random sampling / random assignment).\n",
    "\n",
    "### Approximate normality (within each group)\n",
    "- The t-test is fairly robust for moderate/large sample sizes.\n",
    "- With **strong skew / heavy tails / outliers**, the mean can behave badly.\n",
    "\n",
    "### Equal variances (only for Student’s t-test)\n",
    "If you are not comfortable assuming equal variances, use **Welch’s t-test**.\n",
    "\n",
    "### Outliers\n",
    "Because the test compares **means**, a single extreme value can move the mean and change the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "98998944",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Outlier sensitivity demo: add a single extreme value to group2\n",
    "\n",
    "outlier_value = 6.0\n",
    "group2_outlier = np.concatenate([group2, [outlier_value]])\n",
    "\n",
    "res_welch_outlier = t_test_independent_numpy(group1, group2_outlier, equal_var=False)\n",
    "\n",
    "print(\"Welch (baseline):\")\n",
    "print(format_result(res_welch))\n",
    "print(\"\\nWelch (group2 with one added outlier):\")\n",
    "print(format_result(res_welch_outlier))\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Original data\", \"After adding an outlier to group2\"))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=group1,\n",
    "        name=\"group1\",\n",
    "        histnorm=\"probability density\",\n",
    "        opacity=0.6,\n",
    "        marker_color=\"#1f77b4\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=group2,\n",
    "        name=\"group2\",\n",
    "        histnorm=\"probability density\",\n",
    "        opacity=0.6,\n",
    "        marker_color=\"#d62728\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=group1,\n",
    "        name=\"group1\",\n",
    "        histnorm=\"probability density\",\n",
    "        opacity=0.6,\n",
    "        marker_color=\"#1f77b4\",\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=group2_outlier,\n",
    "        name=\"group2 (+ outlier)\",\n",
    "        histnorm=\"probability density\",\n",
    "        opacity=0.6,\n",
    "        marker_color=\"#d62728\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Outliers can change means (and therefore the t-test)\",\n",
    "    barmode=\"overlay\",\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Value\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Value\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Density\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Density\", row=1, col=2)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4c8e1f",
   "metadata": {},
   "source": [
    "## 9) Simulation intuition: Type I error and power\n",
    "\n",
    "A good mental model:\n",
    "\n",
    "- **Type I error (false positive rate)**: if $H_0$ is true, how often do we reject at level $\u0007lpha$?\n",
    "- **Power**: if there is a real mean difference, how often do we reject?\n",
    "\n",
    "Below we simulate many experiments and visualize:\n",
    "- the distribution of t-statistics under $H_0$\n",
    "- the distribution of p-values under $H_0$ (should be roughly Uniform(0,1))\n",
    "- a simple power curve as the true mean difference grows\n",
    "\n",
    "For speed we use Student’s t-test here (equal variances, fixed df).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c783ad26",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def student_t_stats_matrix(X: np.ndarray, Y: np.ndarray) -> np.ndarray:\n",
    "    '''Vectorized Student t-statistics for many simulated experiments.\n",
    "\n",
    "    X: shape (n_sims, n1)\n",
    "    Y: shape (n_sims, n2)\n",
    "    '''\n",
    "    n1 = X.shape[1]\n",
    "    n2 = Y.shape[1]\n",
    "\n",
    "    m1 = X.mean(axis=1)\n",
    "    m2 = Y.mean(axis=1)\n",
    "\n",
    "    v1 = X.var(axis=1, ddof=1)\n",
    "    v2 = Y.var(axis=1, ddof=1)\n",
    "\n",
    "    df = n1 + n2 - 2\n",
    "    sp2 = ((n1 - 1) * v1 + (n2 - 1) * v2) / df\n",
    "    se = np.sqrt(sp2 * (1.0 / n1 + 1.0 / n2))\n",
    "\n",
    "    return (m1 - m2) / se\n",
    "\n",
    "\n",
    "alpha = 0.05\n",
    "n_sims = 8000\n",
    "n1 = n2 = 20\n",
    "\n",
    "# Under H0: same mean, same variance\n",
    "X0 = rng.normal(0.0, 1.0, size=(n_sims, n1))\n",
    "Y0 = rng.normal(0.0, 1.0, size=(n_sims, n2))\n",
    "\n",
    "df0 = n1 + n2 - 2\n",
    "lookup0 = make_t_lookup(df0, t_max=12.0, n=80_000)\n",
    "\n",
    "t_stats0 = student_t_stats_matrix(X0, Y0)\n",
    "cdf0 = t_cdf(t_stats0, lookup0)\n",
    "p_vals0 = 2.0 * np.minimum(cdf0, 1.0 - cdf0)\n",
    "\n",
    "print(\"Empirical Type I error at alpha=0.05:\", float(np.mean(p_vals0 < alpha)))\n",
    "\n",
    "# Plot p-values under H0 (should be ~Uniform(0,1))\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=p_vals0, nbinsx=40, histnorm=\"probability density\", name=\"p-values\"))\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[1, 1], mode=\"lines\", name=\"Uniform(0,1) density=1\"))\n",
    "fig.update_layout(\n",
    "    title=\"p-values under H0 (should be roughly uniform)\",\n",
    "    xaxis_title=\"p-value\",\n",
    "    yaxis_title=\"Density\",\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Plot t-statistics under H0 with theoretical t pdf\n",
    "x_line = np.linspace(-6, 6, 1400)\n",
    "pdf_line = t_pdf(x_line, df0)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=t_stats0, nbinsx=60, histnorm=\"probability density\", name=\"simulated t\"))\n",
    "fig.add_trace(go.Scatter(x=x_line, y=pdf_line, mode=\"lines\", name=f\"t pdf (df={df0})\"))\n",
    "fig.update_layout(\n",
    "    title=\"t-statistics under H0 (simulation vs theoretical t density)\",\n",
    "    xaxis_title=\"t\",\n",
    "    yaxis_title=\"Density\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "809ece40",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# A simple power curve: how power increases as the true mean difference grows\n",
    "\n",
    "deltas = np.linspace(0.0, 1.2, 9)  # true |mu1 - mu2| when sigma=1\n",
    "powers = []\n",
    "\n",
    "for delta in deltas:\n",
    "    X = rng.normal(0.0, 1.0, size=(n_sims, n1))\n",
    "    Y = rng.normal(delta, 1.0, size=(n_sims, n2))\n",
    "\n",
    "    t_stats = student_t_stats_matrix(X, Y)\n",
    "    cdf = t_cdf(t_stats, lookup0)\n",
    "    p_vals = 2.0 * np.minimum(cdf, 1.0 - cdf)\n",
    "    powers.append(float(np.mean(p_vals < alpha)))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=deltas, y=powers, mode=\"lines+markers\"))\n",
    "fig.update_layout(\n",
    "    title=\"Power vs true mean difference (n1=n2=20, sigma=1, alpha=0.05)\",\n",
    "    xaxis_title=\"True |mu1 - mu2|\",\n",
    "    yaxis_title=\"Power (P(reject H0))\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c77616",
   "metadata": {},
   "source": [
    "## 10) Practical usage (SciPy cross-check)\n",
    "\n",
    "In real work, you typically use `scipy.stats.ttest_ind`:\n",
    "\n",
    "- `equal_var=True` → Student’s t-test\n",
    "- `equal_var=False` → Welch’s t-test\n",
    "\n",
    "Below we compare SciPy’s result to our NumPy-only implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ff031aa4",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "if HAS_SCIPY:\n",
    "    r_student = ttest_ind(group1, group2, equal_var=True)\n",
    "    r_welch = ttest_ind(group1, group2, equal_var=False)\n",
    "\n",
    "    print(\"SciPy Student:\")\n",
    "    print(\"  t=\", float(r_student.statistic), \"p=\", float(r_student.pvalue))\n",
    "    print(\"Our Student:\")\n",
    "    print(\"  t=\", res_student.t, \"p=\", res_student.p_value)\n",
    "\n",
    "    print(\"\\nSciPy Welch:\")\n",
    "    print(\"  t=\", float(r_welch.statistic), \"p=\", float(r_welch.pvalue))\n",
    "    print(\"Our Welch:\")\n",
    "    print(\"  t=\", res_welch.t, \"p=\", res_welch.p_value)\n",
    "else:\n",
    "    print(\"SciPy not installed; skipping cross-check.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0caf8fc",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Change the sample sizes (`n1`, `n2`) and see how the standard error and power change.\n",
    "2. Try a clearly non-normal distribution (e.g. exponential) and compare the t-test to a permutation test.\n",
    "3. Simulate unequal variances and compare Student vs Welch rejection rates.\n",
    "4. Compute and visualize a bootstrap CI for $(\\mu_1-\\mu_2)$ and compare it to the t-based CI.\n",
    "\n",
    "## References\n",
    "\n",
    "- Student (1908), *The probable error of a mean*\n",
    "- Welch (1947), *The generalization of “Student's” problem when several different population variances are involved*\n",
    "- SciPy docs: `scipy.stats.ttest_ind`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
