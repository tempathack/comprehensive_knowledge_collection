{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Odds Ratio: Interpretation + Hypothesis Test (2×2 tables)\n",
    "\n",
    "The **odds ratio (OR)** is a measure of association between two binary variables (e.g., *treatment* vs *control* and *event* vs *no event*).\n",
    "\n",
    "This notebook focuses on:\n",
    "- what odds and odds ratios mean (and what they do **not** mean)\n",
    "- how to test the null hypothesis **OR = 1** (\"no association\")\n",
    "- a low-level NumPy implementation (no stats libraries)\n",
    "- an exact alternative (Fisher's exact test) for small samples\n"
   ],
   "id": "628c07b1"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"Plotly:\", plotly.__version__)\n"
   ],
   "id": "2f68cb69"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Odds vs probability\n",
    "\n",
    "A **probability** $p$ lives in $[0,1]$.\n",
    "\n",
    "The corresponding **odds** are:\n",
    "\n",
    "$$\text{odds}(p) = \frac{p}{1-p}$$\n",
    "\n",
    "Interpretation:\n",
    "- odds = 1 means \"event\" and \"no event\" are equally likely ($p=0.5$)\n",
    "- odds = 3 means the event is 3× as likely as the non-event\n",
    "\n",
    "The **odds ratio** compares odds between two groups:\n",
    "\n",
    "$$\text{OR} = \frac{\text{odds}_1}{\text{odds}_0}$$\n",
    "\n",
    "Important: an OR multiplies **odds**, not probabilities. The same OR can imply very different probability changes depending on the baseline probability.\n"
   ],
   "id": "e3e3a144"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize probability -> odds and probability -> log-odds (logit)\n",
    "\n",
    "p = np.linspace(0.001, 0.999, 800)\n",
    "odds = p / (1.0 - p)\n",
    "log_odds = np.log(odds)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Odds = p/(1-p)\", \"Log-odds = log(p/(1-p))\"),\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(x=p, y=odds, mode=\"lines\", name=\"odds\"), row=1, col=1)\n",
    "fig.update_yaxes(type=\"log\", title_text=\"odds (log scale)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"probability p\", row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=p, y=log_odds, mode=\"lines\", name=\"log-odds\"), row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"log-odds\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"probability p\", row=1, col=2)\n",
    "\n",
    "# Helpful reference line: p=0.5 -> odds=1 -> log-odds=0\n",
    "for col in [1, 2]:\n",
    "    fig.add_vline(x=0.5, line_dash=\"dash\", line_color=\"gray\", row=1, col=col)\n",
    "\n",
    "fig.update_layout(title=\"Odds are an unbounded re-parameterization of probability\", showlegend=False, height=420)\n",
    "fig.show()\n"
   ],
   "id": "c97118db"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Odds ratio from a 2×2 table\n",
    "\n",
    "For two binary variables (e.g., **Exposure** and **Outcome**), summarize counts in a 2×2 table:\n",
    "\n",
    "|               | Outcome = 1 | Outcome = 0 |\n",
    "|---            |---:         |---:         |\n",
    "| Exposure = 1  | $a$         | $b$         |\n",
    "| Exposure = 0  | $c$         | $d$         |\n",
    "\n",
    "Group odds:\n",
    "\n",
    "$$\text{odds}_1 = \frac{a}{b},\\qquad \text{odds}_0 = \frac{c}{d}$$\n",
    "\n",
    "Odds ratio:\n",
    "\n",
    "$$\text{OR} = \frac{a/b}{c/d} = \frac{ad}{bc}$$\n",
    "\n",
    "- OR = 1: equal odds (no association)\n",
    "- OR > 1: higher odds of outcome in the exposed group\n",
    "- OR < 1: lower odds of outcome in the exposed group\n",
    "\n",
    "If any of $a,b,c,d$ are 0, the raw OR can be 0 or $\\infty$. A common small-sample fix is the **Haldane–Anscombe correction**: add 0.5 to every cell before computing OR and standard errors.\n"
   ],
   "id": "3367147e"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Example 2×2 table\n",
    "# Rows: [exposed, unexposed]\n",
    "# Cols: [event, no event]\n",
    "\n",
    "table = np.array([[30, 70],\n",
    "                  [15, 85]], dtype=float)\n",
    "\n",
    "a, b = table[0]\n",
    "c, d = table[1]\n",
    "\n",
    "p1 = a / (a + b)\n",
    "p0 = c / (c + d)\n",
    "\n",
    "odds1 = a / b\n",
    "odds0 = c / d\n",
    "OR = odds1 / odds0\n",
    "\n",
    "print(f\"P(event | exposed)   = {p1:.3f}\")\n",
    "print(f\"P(event | unexposed) = {p0:.3f}\")\n",
    "print(f\"odds(exposed)        = {odds1:.3f}\")\n",
    "print(f\"odds(unexposed)      = {odds0:.3f}\")\n",
    "print(f\"odds ratio (OR)      = {OR:.3f}\")\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=go.Heatmap(\n",
    "        z=table,\n",
    "        x=[\"Event\", \"No event\"],\n",
    "        y=[\"Exposed\", \"Unexposed\"],\n",
    "        colorscale=\"Blues\",\n",
    "        text=table.astype(int),\n",
    "        texttemplate=\"%{text}\",\n",
    "        hovertemplate=\"%{y} / %{x}<br>count=%{z}<extra></extra>\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(title=\"Observed 2×2 counts\", height=360)\n",
    "fig.show()\n"
   ],
   "id": "47dbf309"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) What hypothesis is being tested?\n",
    "\n",
    "In a 2×2 table, the most common null hypothesis is:\n",
    "\n",
    "$$H_0: \text{OR} = 1$$\n",
    "\n",
    "This is equivalent to **independence** between exposure and outcome (no association).\n",
    "\n",
    "A typical workflow:\n",
    "1) summarize your data as a 2×2 table\n",
    "2) compute an estimate of OR (effect size)\n",
    "3) compute a p-value and/or confidence interval for OR\n",
    "\n",
    "Two common ways to test $H_0$:\n",
    "- **Large-sample Wald test** using $\\log(\\widehat{\text{OR}})$ (fast, approximate)\n",
    "- **Fisher's exact test** (exact under fixed margins; better for small counts)\n"
   ],
   "id": "c2397a8d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large-sample Wald test on the log-odds-ratio\n",
    "\n",
    "We test on the log scale because OR is positive and skewed, while $\\log(\text{OR})$ is often close to normal.\n",
    "\n",
    "Estimate:\n",
    "\n",
    "$$\\widehat{\\log(\text{OR})} = \\log\\left(\frac{ad}{bc}\right)$$\n",
    "\n",
    "Approximate standard error:\n",
    "\n",
    "$$\\mathrm{SE}\big(\\widehat{\\log(\text{OR})}\big) = \\sqrt{\frac{1}{a}+\frac{1}{b}+\frac{1}{c}+\frac{1}{d}}$$\n",
    "\n",
    "Test statistic (approximately standard normal under $H_0$):\n",
    "\n",
    "$$z = \frac{\\widehat{\\log(\text{OR})}}{\\mathrm{SE}}$$\n",
    "\n",
    "Two-sided p-value:\n",
    "\n",
    "$$p = 2\\,\big(1-\\Phi(|z|)\big)$$\n",
    "\n",
    "A $(1-\u0007lpha)$ confidence interval for OR:\n",
    "\n",
    "$$\\exp\\left(\\widehat{\\log(\text{OR})} \\pm z_{1-\u0007lpha/2}\\,\\mathrm{SE}\right)$$\n",
    "\n",
    "Notes:\n",
    "- This approximation is usually OK when all cells are reasonably large (rule of thumb: \\~5+).\n",
    "- If any cell is very small (or 0), prefer Fisher's exact test and/or use a continuity correction.\n"
   ],
   "id": "f42b7af6"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --- Normal CDF/PPF approximations (NumPy-only) ---\n",
    "\n",
    "SQRT_2PI = np.sqrt(2.0 * np.pi)\n",
    "\n",
    "\n",
    "def normal_pdf(x: np.ndarray) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    return np.exp(-0.5 * x * x) / SQRT_2PI\n",
    "\n",
    "\n",
    "def normal_cdf(x: np.ndarray) -> np.ndarray:\n",
    "    # Approximate Φ(x) using a classic 5th-order rational approximation.\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    # Abramowitz & Stegun style approximation\n",
    "    p = 0.2316419\n",
    "    b1 = 0.319381530\n",
    "    b2 = -0.356563782\n",
    "    b3 = 1.781477937\n",
    "    b4 = -1.821255978\n",
    "    b5 = 1.330274429\n",
    "\n",
    "    ax = np.abs(x)\n",
    "    t = 1.0 / (1.0 + p * ax)\n",
    "    poly = (((((b5 * t + b4) * t + b3) * t + b2) * t + b1) * t)\n",
    "\n",
    "    cdf_pos = 1.0 - normal_pdf(ax) * poly\n",
    "    return np.where(x >= 0.0, cdf_pos, 1.0 - cdf_pos)\n",
    "\n",
    "\n",
    "def normal_ppf(p: np.ndarray) -> np.ndarray:\n",
    "    # Approximate Φ^{-1}(p) (Acklam's approximation).\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    if np.any((p <= 0.0) | (p >= 1.0)):\n",
    "        raise ValueError(\"p must be in (0, 1)\")\n",
    "\n",
    "    # Coefficients in rational approximations\n",
    "    a = np.array([\n",
    "        -3.969683028665376e01,\n",
    "        2.209460984245205e02,\n",
    "        -2.759285104469687e02,\n",
    "        1.383577518672690e02,\n",
    "        -3.066479806614716e01,\n",
    "        2.506628277459239e00,\n",
    "    ])\n",
    "    b = np.array([\n",
    "        -5.447609879822406e01,\n",
    "        1.615858368580409e02,\n",
    "        -1.556989798598866e02,\n",
    "        6.680131188771972e01,\n",
    "        -1.328068155288572e01,\n",
    "    ])\n",
    "    c = np.array([\n",
    "        -7.784894002430293e-03,\n",
    "        -3.223964580411365e-01,\n",
    "        -2.400758277161838e00,\n",
    "        -2.549732539343734e00,\n",
    "        4.374664141464968e00,\n",
    "        2.938163982698783e00,\n",
    "    ])\n",
    "    d = np.array([\n",
    "        7.784695709041462e-03,\n",
    "        3.224671290700398e-01,\n",
    "        2.445134137142996e00,\n",
    "        3.754408661907416e00,\n",
    "    ])\n",
    "\n",
    "    plow = 0.02425\n",
    "    phigh = 1.0 - plow\n",
    "\n",
    "    x = np.empty_like(p)\n",
    "\n",
    "    # Lower region\n",
    "    m = p < plow\n",
    "    q = np.sqrt(-2.0 * np.log(p[m]))\n",
    "    x[m] = -(\n",
    "        (((((c[0] * q + c[1]) * q + c[2]) * q + c[3]) * q + c[4]) * q + c[5])\n",
    "        / ((((d[0] * q + d[1]) * q + d[2]) * q + d[3]) * q + 1.0)\n",
    "    )\n",
    "\n",
    "    # Upper region\n",
    "    m = p > phigh\n",
    "    q = np.sqrt(-2.0 * np.log(1.0 - p[m]))\n",
    "    x[m] = (\n",
    "        (((((c[0] * q + c[1]) * q + c[2]) * q + c[3]) * q + c[4]) * q + c[5])\n",
    "        / ((((d[0] * q + d[1]) * q + d[2]) * q + d[3]) * q + 1.0)\n",
    "    )\n",
    "\n",
    "    # Central region\n",
    "    m = (~(p < plow)) & (~(p > phigh))\n",
    "    q = p[m] - 0.5\n",
    "    r = q * q\n",
    "    x[m] = (\n",
    "        (((((a[0] * r + a[1]) * r + a[2]) * r + a[3]) * r + a[4]) * r + a[5]) * q\n",
    "        / (((((b[0] * r + b[1]) * r + b[2]) * r + b[3]) * r + b[4]) * r + 1.0)\n",
    "    )\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def odds_ratio_wald_test(\n",
    "    table_2x2: np.ndarray,\n",
    "    correction: float = 0.0,\n",
    "    alternative: str = \"two-sided\",\n",
    "    confidence_level: float = 0.95,\n",
    "):\n",
    "    # Wald test and CI for OR in a 2×2 table.\n",
    "    table_2x2 = np.asarray(table_2x2, dtype=float)\n",
    "    if table_2x2.shape != (2, 2):\n",
    "        raise ValueError(\"table_2x2 must have shape (2, 2)\")\n",
    "\n",
    "    a, b = table_2x2[0] + correction\n",
    "    c, d = table_2x2[1] + correction\n",
    "\n",
    "    log_or = np.log(a) + np.log(d) - np.log(b) - np.log(c)\n",
    "    se = np.sqrt(1.0 / a + 1.0 / b + 1.0 / c + 1.0 / d)\n",
    "\n",
    "    z = log_or / se\n",
    "\n",
    "    if alternative == \"two-sided\":\n",
    "        p_value = 2.0 * (1.0 - normal_cdf(np.abs(z)))\n",
    "    elif alternative == \"greater\":\n",
    "        p_value = 1.0 - normal_cdf(z)\n",
    "    elif alternative == \"less\":\n",
    "        p_value = normal_cdf(z)\n",
    "    else:\n",
    "        raise ValueError(\"alternative must be: 'two-sided', 'greater', or 'less'\")\n",
    "\n",
    "    alpha = 1.0 - confidence_level\n",
    "    zcrit = normal_ppf(1.0 - alpha / 2.0)\n",
    "    ci_log = (log_or - zcrit * se, log_or + zcrit * se)\n",
    "    ci_or = (float(np.exp(ci_log[0])), float(np.exp(ci_log[1])))\n",
    "\n",
    "    return {\n",
    "        'odds_ratio': float(np.exp(log_or)),\n",
    "        'log_odds_ratio': float(log_or),\n",
    "        'se_log_odds_ratio': float(se),\n",
    "        'z': float(z),\n",
    "        'p_value': float(p_value),\n",
    "        'confidence_level': float(confidence_level),\n",
    "        'ci_or': ci_or,\n",
    "    }\n",
    "\n",
    "\n",
    "res = odds_ratio_wald_test(table, correction=0.0)\n",
    "res_cc = odds_ratio_wald_test(table, correction=0.5)\n",
    "\n",
    "print(\"Wald test (no correction)\")\n",
    "print(res)\n",
    "print(\"\n",
    "Wald test (Haldane–Anscombe correction = 0.5)\")\n",
    "print(res_cc)\n"
   ],
   "id": "72e16945"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize the z statistic on a standard normal curve\n",
    "\n",
    "z = res[\"z\"]\n",
    "zabs = abs(z)\n",
    "\n",
    "x = np.linspace(-4.0, 4.0, 1200)\n",
    "y = normal_pdf(x)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y, mode=\"lines\", name=\"N(0,1) pdf\"))\n",
    "\n",
    "# Shade the two tails beyond ±|z|\n",
    "left = x <= -zabs\n",
    "right = x >= zabs\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x[left],\n",
    "    y=y[left],\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"rgba(214,39,40,0.0)\"),\n",
    "    fill=\"tozeroy\",\n",
    "    fillcolor=\"rgba(214,39,40,0.25)\",\n",
    "    showlegend=False,\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x[right],\n",
    "    y=y[right],\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"rgba(214,39,40,0.0)\"),\n",
    "    fill=\"tozeroy\",\n",
    "    fillcolor=\"rgba(214,39,40,0.25)\",\n",
    "    showlegend=False,\n",
    "))\n",
    "\n",
    "fig.add_vline(x=-zabs, line_dash=\"dash\", line_color=\"firebrick\")\n",
    "fig.add_vline(x= zabs, line_dash=\"dash\", line_color=\"firebrick\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Wald test: z = {z:.3f}, two-sided p = {res['p_value']:.4f}\",\n",
    "    xaxis_title=\"z\",\n",
    "    yaxis_title=\"density\",\n",
    "    height=420,\n",
    ")\n",
    "fig.show()\n"
   ],
   "id": "a731d639"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quick simulation check (why z ≈ N(0,1) under H0)\n",
    "\n",
    "Under $H_0$ (no association), if sample sizes are large enough, the Wald statistic behaves like a standard normal.\n",
    "\n",
    "We'll simulate many 2×2 tables **under independence** and look at the distribution of the resulting z-statistics.\n"
   ],
   "id": "d5a7cedf"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def simulate_tables_under_h0(\n",
    "    n_exposed: int,\n",
    "    n_unexposed: int,\n",
    "    p_event: float,\n",
    "    n_sims: int = 30_000,\n",
    "):\n",
    "    # Simulate 2×2 tables where event is independent of exposure.\n",
    "    a = rng.binomial(n_exposed, p_event, size=n_sims)\n",
    "    c = rng.binomial(n_unexposed, p_event, size=n_sims)\n",
    "\n",
    "    b = n_exposed - a\n",
    "    d = n_unexposed - c\n",
    "\n",
    "    tables = np.stack([np.stack([a, b], axis=1), np.stack([c, d], axis=1)], axis=1)\n",
    "    return tables\n",
    "\n",
    "\n",
    "def wald_z_for_tables(tables: np.ndarray, correction: float = 0.5) -> np.ndarray:\n",
    "    tables = np.asarray(tables, dtype=float)\n",
    "    a = tables[:, 0, 0] + correction\n",
    "    b = tables[:, 0, 1] + correction\n",
    "    c = tables[:, 1, 0] + correction\n",
    "    d = tables[:, 1, 1] + correction\n",
    "\n",
    "    log_or = np.log(a) + np.log(d) - np.log(b) - np.log(c)\n",
    "    se = np.sqrt(1.0 / a + 1.0 / b + 1.0 / c + 1.0 / d)\n",
    "    return log_or / se\n",
    "\n",
    "\n",
    "tables_h0 = simulate_tables_under_h0(n_exposed=200, n_unexposed=200, p_event=0.2, n_sims=30_000)\n",
    "zs = wald_z_for_tables(tables_h0, correction=0.5)\n",
    "\n",
    "fig = px.histogram(zs, nbins=80, histnorm=\"probability density\", opacity=0.7)\n",
    "\n",
    "x = np.linspace(-4, 4, 600)\n",
    "fig.add_trace(go.Scatter(x=x, y=normal_pdf(x), mode=\"lines\", name=\"N(0,1) pdf\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Simulated z-statistics under H0 (independence)\",\n",
    "    xaxis_title=\"z\",\n",
    "    yaxis_title=\"density\",\n",
    "    height=420,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"mean(z):\", float(np.mean(zs)))\n",
    "print(\"std(z): \", float(np.std(zs)))\n"
   ],
   "id": "abb390c0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Exact alternative: Fisher's exact test\n",
    "\n",
    "When counts are small (or a cell is 0), the Wald test can be inaccurate.\n",
    "\n",
    "**Fisher's exact test** computes an exact p-value for independence in a 2×2 table *conditional on the row and column totals*.\n",
    "\n",
    "Under $H_0$ and fixed margins, the top-left cell $a$ follows a **hypergeometric** distribution. The p-value is computed by summing probabilities of tables at least as \"surprising\" as the observed one.\n",
    "\n",
    "We'll implement a standard two-sided Fisher p-value by summing probabilities of all tables with probability ≤ the observed table's probability.\n"
   ],
   "id": "0ace2d36"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "LGAMMA = np.vectorize(math.lgamma, otypes=[float])\n",
    "\n",
    "\n",
    "def log_choose(n: int, k: np.ndarray) -> np.ndarray:\n",
    "    k = np.asarray(k, dtype=float)\n",
    "\n",
    "    # log(n!) = lgamma(n+1) is stable for large n\n",
    "    return LGAMMA(n + 1.0) - LGAMMA(k + 1.0) - LGAMMA(n - k + 1.0)\n",
    "\n",
    "\n",
    "def fisher_exact(table_2x2: np.ndarray, alternative: str = \"two-sided\"):\n",
    "    table_2x2 = np.asarray(table_2x2, dtype=int)\n",
    "    if table_2x2.shape != (2, 2):\n",
    "        raise ValueError(\"table_2x2 must have shape (2, 2)\")\n",
    "\n",
    "    a_obs, b_obs = table_2x2[0]\n",
    "    c_obs, d_obs = table_2x2[1]\n",
    "\n",
    "    r1 = a_obs + b_obs\n",
    "    r2 = c_obs + d_obs\n",
    "    c1 = a_obs + c_obs\n",
    "    c2 = b_obs + d_obs\n",
    "    n = r1 + r2\n",
    "\n",
    "    a_min = max(0, c1 - r2)\n",
    "    a_max = min(r1, c1)\n",
    "\n",
    "    a_vals = np.arange(a_min, a_max + 1)\n",
    "\n",
    "    # Hypergeometric probabilities with fixed margins\n",
    "    log_p = log_choose(c1, a_vals) + log_choose(c2, r1 - a_vals) - log_choose(n, r1)\n",
    "\n",
    "    # Stabilize before exponentiating\n",
    "    log_p -= np.max(log_p)\n",
    "    p = np.exp(log_p)\n",
    "    p /= np.sum(p)\n",
    "\n",
    "    # Observed probability\n",
    "    p_obs = float(p[a_vals == a_obs][0])\n",
    "\n",
    "    if alternative == \"two-sided\":\n",
    "        p_value = float(np.sum(p[p <= p_obs + 1e-15]))\n",
    "    elif alternative == \"less\":\n",
    "        p_value = float(np.sum(p[a_vals <= a_obs]))\n",
    "    elif alternative == \"greater\":\n",
    "        p_value = float(np.sum(p[a_vals >= a_obs]))\n",
    "    else:\n",
    "        raise ValueError(\"alternative must be: 'two-sided', 'greater', or 'less'\")\n",
    "\n",
    "    return {\n",
    "        'a_support': a_vals,\n",
    "        'pmf': p,\n",
    "        'p_value': p_value,\n",
    "        'p_observed_table': p_obs,\n",
    "    }\n",
    "\n",
    "\n",
    "fisher = fisher_exact(table, alternative=\"two-sided\")\n",
    "print(\"Fisher two-sided p-value:\", fisher[\"p_value\"])\n",
    "\n",
    "# Visualize the exact null distribution of 'a' given the margins\n",
    "colors = np.where(fisher[\"pmf\"] <= fisher[\"p_observed_table\"] + 1e-15, \"crimson\", \"steelblue\")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=fisher[\"a_support\"],\n",
    "    y=fisher[\"pmf\"],\n",
    "    marker_color=colors,\n",
    "))\n",
    "fig.add_vline(x=int(table[0, 0]), line_dash=\"dash\", line_color=\"black\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Fisher's exact test (two-sided p = {fisher['p_value']:.4f})\",\n",
    "    xaxis_title=\"a (top-left cell count)\",\n",
    "    yaxis_title=\"P(A=a | margins)\",\n",
    "    height=420,\n",
    ")\n",
    "fig.show()\n"
   ],
   "id": "bc6f7d3f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Interpreting OR in terms of probabilities (why OR can mislead)\n",
    "\n",
    "Because OR multiplies **odds**, the same OR can correspond to different probability changes.\n",
    "\n",
    "If baseline probability is $p_0$ and the odds ratio is OR, then:\n",
    "\n",
    "- baseline odds: $\text{odds}_0 = \frac{p_0}{1-p_0}$\n",
    "- new odds: $\text{odds}_1 = \text{OR}\\cdot\text{odds}_0$\n",
    "- implied new probability:\n",
    "\n",
    "$$p_1 = \frac{\text{OR}\\,p_0}{1 - p_0 + \text{OR}\\,p_0}$$\n",
    "\n",
    "We'll plot $p_1$ vs $p_0$ for a few OR values, and also the **risk ratio** $p_1/p_0$.\n"
   ],
   "id": "66ec23ea"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def p1_from_p0_and_or(p0: np.ndarray, odds_ratio: float) -> np.ndarray:\n",
    "    p0 = np.asarray(p0, dtype=float)\n",
    "    return (odds_ratio * p0) / (1.0 - p0 + odds_ratio * p0)\n",
    "\n",
    "\n",
    "p0 = np.linspace(0.001, 0.999, 500)\n",
    "ors = [0.5, 1.0, 2.0, 5.0]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Implied p1 for a fixed OR\", \"Risk ratio p1/p0 for a fixed OR\"),\n",
    ")\n",
    "\n",
    "for OR in ors:\n",
    "    p1 = p1_from_p0_and_or(p0, OR)\n",
    "    rr = p1 / p0\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=p0, y=p1, mode=\"lines\", name=f\"OR={OR}\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=p0, y=rr, mode=\"lines\", name=f\"OR={OR}\", showlegend=False), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"baseline probability p0\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"implied probability p1\", row=1, col=1)\n",
    "\n",
    "fig.update_xaxes(title_text=\"baseline probability p0\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"risk ratio = p1/p0\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(title=\"Same OR, different probability changes\", height=460)\n",
    "fig.show()\n"
   ],
   "id": "25b9e3f5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) How to interpret the test result\n",
    "\n",
    "What a p-value answers (in this context):\n",
    "\n",
    "> If there were truly **no association** between exposure and outcome (OR = 1), how unusual would it be to see a table at least this extreme (by the chosen test)?\n",
    "\n",
    "- Small p-value (e.g., < 0.05): evidence against OR = 1 (an association is plausible)\n",
    "- Large p-value: the data are consistent with OR = 1 (but this is **not** proof of no effect)\n",
    "\n",
    "What the confidence interval answers:\n",
    "\n",
    "> A range of OR values compatible with the data (given the test's assumptions).\n",
    "\n",
    "If the CI **excludes 1**, it aligns with rejecting OR=1 at the corresponding level.\n",
    "\n",
    "Always report the effect size (OR) and uncertainty (CI), not just the p-value.\n"
   ],
   "id": "3a754862"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Practical notes + pitfalls\n",
    "\n",
    "- **OR is symmetric**: swapping rows or columns in the 2×2 table inverts the OR (interpret carefully).\n",
    "- **Case-control studies** often estimate OR because sampling is conditional on the outcome.\n",
    "- **OR ≠ risk ratio** unless the event is rare; for common outcomes OR can look “bigger” than the risk ratio.\n",
    "- **Small counts / zeros**: prefer Fisher's exact test (or use continuity corrections / exact logistic regression).\n",
    "- **Association ≠ causation**: confounding can produce OR ≠ 1 even without a causal effect.\n"
   ],
   "id": "5731dc27"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Exercises\n",
    "\n",
    "1) Create a 2×2 table with a zero cell and compare OR and Wald p-values with correction=0 and correction=0.5.\n",
    "2) For a fixed OR=2, read off the implied $p_1$ when $p_0 \\in \\{0.01, 0.1, 0.5\\}$. Why do the probability changes differ so much?\n",
    "3) Implement a function that takes raw individual-level data (two boolean arrays) and returns the 2×2 table, OR, and test results.\n"
   ],
   "id": "07d4f1c6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Agresti, *An Introduction to Categorical Data Analysis*\n",
    "- Fisher's exact test and the hypergeometric distribution (standard categorical data texts)\n",
    "- Relationship to logistic regression: for a binary predictor, the logistic regression coefficient equals $\\log(\text{OR})$.\n"
   ],
   "id": "d2bda644"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
