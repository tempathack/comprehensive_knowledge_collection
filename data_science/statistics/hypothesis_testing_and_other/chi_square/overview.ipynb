{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi-square Tests (Goodness-of-Fit & Independence)\n",
    "\n",
    "Chi-square (χ²) tests are **hypothesis tests for categorical data**. They compare **observed counts** to **expected counts** under a null hypothesis.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "- Know when to use χ² tests (and when not to)\n",
    "- Understand where the χ² statistic comes from: \"squared standardized residuals\"\n",
    "- Implement χ² tests from scratch with NumPy\n",
    "- Visualize the χ² distribution, p-values, and which cells/categories drive the result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Basic probability and hypotheses (H0/H1, p-values, α)\n",
    "- Categorical variables, contingency tables\n",
    "- Comfort with NumPy arrays\n",
    "\n",
    "## When to use\n",
    "\n",
    "Use χ² tests when your data are **counts** in categories (or can be binned into categories).\n",
    "\n",
    "Common variants:\n",
    "\n",
    "1) **Goodness-of-fit**: do observed category counts match a claimed distribution?\n",
    "2) **Independence / homogeneity**: are two categorical variables associated?\n",
    "\n",
    "## When NOT to use\n",
    "\n",
    "- Continuous data (use t-tests/ANOVA, nonparametric tests, etc.)\n",
    "- Very small expected counts (consider combining categories or using exact tests, e.g. Fisher for 2×2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The hypotheses\n",
    "\n",
    "### 1) Goodness-of-fit (one categorical variable)\n",
    "\n",
    "- H0: category probabilities are p1,...,pk (given by theory/business claim)\n",
    "- H1: at least one probability differs\n",
    "\n",
    "### 2) Independence (two categorical variables)\n",
    "\n",
    "- H0: X and Y are independent (no association)\n",
    "- H1: X and Y are associated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The χ² statistic (Pearson's X²): \"sum of squared standardized residuals\"\n",
    "\n",
    "For each category/cell:\n",
    "\n",
    "- Observed count: **O**\n",
    "- Expected count under H0: **E**\n",
    "\n",
    "The standardized residual is roughly:\n",
    "\n",
    "r = (O − E) / √E\n",
    "\n",
    "Pearson's chi-square statistic is:\n",
    "\n",
    "X² = Σ (O − E)² / E = Σ r²\n",
    "\n",
    "So **X² gets large** when observed counts differ from expected counts by more than \"random fluctuation\" would suggest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.templates.default = 'plotly_white'\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "print('python:', sys.version.split()[0])\n",
    "print('numpy:', np.__version__)\n",
    "print('plotly:', plotly.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why \"chi-square\"?\n",
    "\n",
    "If Z1,...,Zk are independent standard normals, then:\n",
    "\n",
    "Z1² + ... + Zk² ~ χ²(k)\n",
    "\n",
    "That connection is why the χ² distribution appears when we add up many squared (approximately normal) residual-like terms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Numeric building blocks: log Γ, regularized incomplete gamma, χ² pdf/cdf/sf ---\n",
    "# We implement the χ² p-value using the identity:\n",
    "#   If X ~ χ²(df), then P(X >= x) = Q(df/2, x/2)\n",
    "# where Q is the regularized upper incomplete gamma.\n",
    "\n",
    "_LANCZOS_COEFFS = np.array(\n",
    "    [\n",
    "        0.99999999999980993,\n",
    "        676.5203681218851,\n",
    "        -1259.1392167224028,\n",
    "        771.3234287776531,\n",
    "        -176.6150291621406,\n",
    "        12.507343278686905,\n",
    "        -0.13857109526572012,\n",
    "        9.984369578019572e-6,\n",
    "        1.5056327351493116e-7,\n",
    "    ],\n",
    "    dtype=float,\n",
    ")\n",
    "_LANCZOS_G = 7\n",
    "\n",
    "\n",
    "def log_gamma(z: float) -> float:\n",
    "    '''log(Γ(z)) using a Lanczos approximation (real z).'''\n",
    "    if z <= 0 and float(z).is_integer():\n",
    "        return float('inf')  # pole\n",
    "    if z < 0.5:\n",
    "        # Reflection formula: Γ(z)Γ(1-z) = π / sin(πz)\n",
    "        return math.log(math.pi) - math.log(abs(math.sin(math.pi * z))) - log_gamma(1 - z)\n",
    "\n",
    "    z_minus_1 = z - 1.0\n",
    "    x = float(_LANCZOS_COEFFS[0])\n",
    "    for i in range(1, len(_LANCZOS_COEFFS)):\n",
    "        x += float(_LANCZOS_COEFFS[i]) / (z_minus_1 + i)\n",
    "    t = z_minus_1 + _LANCZOS_G + 0.5\n",
    "    return 0.5 * math.log(2 * math.pi) + (z_minus_1 + 0.5) * math.log(t) - t + math.log(x)\n",
    "\n",
    "\n",
    "def _gamma_p_series(a: float, x: float, eps: float = 1e-14, max_iter: int = 10_000) -> float:\n",
    "    '''Lower regularized gamma P(a,x) via series (stable for x < a+1).'''\n",
    "    if x == 0:\n",
    "        return 0.0\n",
    "    ap = a\n",
    "    term = 1.0 / a\n",
    "    summation = term\n",
    "    for _ in range(max_iter):\n",
    "        ap += 1.0\n",
    "        term *= x / ap\n",
    "        summation += term\n",
    "        if abs(term) < abs(summation) * eps:\n",
    "            break\n",
    "    return summation * math.exp(-x + a * math.log(x) - log_gamma(a))\n",
    "\n",
    "\n",
    "def _gamma_q_contfrac(a: float, x: float, eps: float = 1e-14, max_iter: int = 10_000) -> float:\n",
    "    '''Upper regularized gamma Q(a,x) via continued fraction (stable for x >= a+1).'''\n",
    "    fpmin = 1e-300\n",
    "    b = x + 1.0 - a\n",
    "    c = 1.0 / fpmin\n",
    "    d = 1.0 / max(b, fpmin)\n",
    "    h = d\n",
    "\n",
    "    for i in range(1, max_iter + 1):\n",
    "        an = -i * (i - a)\n",
    "        b += 2.0\n",
    "\n",
    "        d = an * d + b\n",
    "        if abs(d) < fpmin:\n",
    "            d = fpmin\n",
    "\n",
    "        c = b + an / c\n",
    "        if abs(c) < fpmin:\n",
    "            c = fpmin\n",
    "\n",
    "        d = 1.0 / d\n",
    "        delta = d * c\n",
    "        h *= delta\n",
    "\n",
    "        if abs(delta - 1.0) < eps:\n",
    "            break\n",
    "\n",
    "    return math.exp(-x + a * math.log(x) - log_gamma(a)) * h\n",
    "\n",
    "\n",
    "def gamma_p(a: float, x: float) -> float:\n",
    "    '''Lower regularized incomplete gamma P(a,x).'''\n",
    "    if x < 0 or a <= 0:\n",
    "        raise ValueError('gamma_p requires a>0 and x>=0')\n",
    "    if x == 0:\n",
    "        return 0.0\n",
    "\n",
    "    if x < a + 1.0:\n",
    "        p = _gamma_p_series(a, x)\n",
    "    else:\n",
    "        # P = 1 - Q\n",
    "        p = 1.0 - _gamma_q_contfrac(a, x)\n",
    "\n",
    "    return float(min(1.0, max(0.0, p)))\n",
    "\n",
    "\n",
    "def gamma_q(a: float, x: float) -> float:\n",
    "    '''Upper regularized incomplete gamma Q(a,x) = 1 - P(a,x).'''\n",
    "    if x < 0 or a <= 0:\n",
    "        raise ValueError('gamma_q requires a>0 and x>=0')\n",
    "    if x == 0:\n",
    "        return 1.0\n",
    "\n",
    "    if x < a + 1.0:\n",
    "        q = 1.0 - _gamma_p_series(a, x)\n",
    "    else:\n",
    "        q = _gamma_q_contfrac(a, x)\n",
    "\n",
    "    return float(min(1.0, max(0.0, q)))\n",
    "\n",
    "\n",
    "def chi2_pdf(x, df: int):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    x = np.maximum(x, 0.0)\n",
    "    k = float(df)\n",
    "    a = 0.5 * k\n",
    "    # log f(x) = -a log(2) - log Γ(a) + (a-1)log(x) - x/2\n",
    "    log_coeff = -a * math.log(2.0) - log_gamma(a)\n",
    "    with np.errstate(divide='ignore'):\n",
    "        log_pdf = log_coeff + (a - 1.0) * np.log(x) - 0.5 * x\n",
    "    pdf = np.exp(log_pdf)\n",
    "    return pdf\n",
    "\n",
    "\n",
    "def chi2_cdf(x: float, df: int) -> float:\n",
    "    return gamma_p(0.5 * df, 0.5 * x)\n",
    "\n",
    "\n",
    "def chi2_sf(x: float, df: int) -> float:\n",
    "    return gamma_q(0.5 * df, 0.5 * x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = 6\n",
    "n_sims = 60_000\n",
    "\n",
    "chi2_sim = np.sum(rng.standard_normal((n_sims, df_demo)) ** 2, axis=1)\n",
    "\n",
    "x_grid = np.linspace(0.001, np.percentile(chi2_sim, 99.5), 400)\n",
    "pdf_grid = chi2_pdf(x_grid, df_demo)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=chi2_sim,\n",
    "        nbinsx=60,\n",
    "        histnorm='probability density',\n",
    "        name='simulation (sum of squares)',\n",
    "        opacity=0.65,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=x_grid, y=pdf_grid, mode='lines', name=f'χ² pdf (df={df_demo})'))\n",
    "fig.update_layout(\n",
    "    title='A χ² distribution as a sum of squared standard normals',\n",
    "    xaxis_title='x',\n",
    "    yaxis_title='density',\n",
    "    bargap=0.02,\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-values: how extreme is X²?\n",
    "\n",
    "For a computed statistic **x_obs** and degrees of freedom **df**:\n",
    "\n",
    "p-value = P(Χ²(df) ≥ x_obs)\n",
    "\n",
    "Small p-values mean: *\"this much discrepancy (or more) would be rare if H0 were true\"*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = 5\n",
    "x_obs = 11.1\n",
    "p_val = chi2_sf(x_obs, df)\n",
    "\n",
    "x = np.linspace(0.001, max(30, x_obs * 1.4), 600)\n",
    "pdf = chi2_pdf(x, df)\n",
    "\n",
    "tail_mask = x >= x_obs\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=pdf, mode='lines', name=f'χ² pdf (df={df})'))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.concatenate([x[tail_mask], x[tail_mask][::-1]]),\n",
    "        y=np.concatenate([pdf[tail_mask], np.zeros_like(pdf[tail_mask])]),\n",
    "        fill='toself',\n",
    "        fillcolor='rgba(214,39,40,0.25)',\n",
    "        line=dict(color='rgba(0,0,0,0)'),\n",
    "        name=f'p-value area = {p_val:.4f}',\n",
    "    )\n",
    ")\n",
    "fig.add_vline(x=x_obs, line_dash='dash', line_color='firebrick')\n",
    "fig.update_layout(title='Right-tail p-value for a χ² test', xaxis_title='χ² value', yaxis_title='density')\n",
    "fig.show()\n",
    "\n",
    "print(f'x_obs={x_obs:.3f}, df={df}, p-value={p_val:.6f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From scratch: χ² test helpers (NumPy only)\n",
    "\n",
    "We'll implement:\n",
    "\n",
    "- χ² statistic\n",
    "- goodness-of-fit test\n",
    "- independence test (contingency table)\n",
    "- diagnostics: contributions, standardized residuals, Cramér's V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_statistic(observed, expected) -> float:\n",
    "    observed = np.asarray(observed, dtype=float)\n",
    "    expected = np.asarray(expected, dtype=float)\n",
    "    if observed.shape != expected.shape:\n",
    "        raise ValueError('observed and expected must have the same shape')\n",
    "    if np.any(expected <= 0):\n",
    "        raise ValueError('expected counts must be positive')\n",
    "    return float(np.sum((observed - expected) ** 2 / expected))\n",
    "\n",
    "\n",
    "def chi_square_contributions(observed, expected):\n",
    "    observed = np.asarray(observed, dtype=float)\n",
    "    expected = np.asarray(expected, dtype=float)\n",
    "    return (observed - expected) ** 2 / expected\n",
    "\n",
    "\n",
    "def standardized_residuals(observed, expected):\n",
    "    observed = np.asarray(observed, dtype=float)\n",
    "    expected = np.asarray(expected, dtype=float)\n",
    "    return (observed - expected) / np.sqrt(expected)\n",
    "\n",
    "\n",
    "def chi_square_gof(observed, expected_probs=None, expected_counts=None, ddof: int = 0):\n",
    "    '''Goodness-of-fit test for 1D category counts.\n",
    "\n",
    "    ddof: how many parameters were estimated from the data to form expected_probs.\n",
    "          (df = k - 1 - ddof)\n",
    "    '''\n",
    "    observed = np.asarray(observed, dtype=float)\n",
    "    if observed.ndim != 1:\n",
    "        raise ValueError('observed must be 1D category counts')\n",
    "    n = float(observed.sum())\n",
    "    if n <= 0:\n",
    "        raise ValueError('total count must be positive')\n",
    "\n",
    "    if expected_counts is None:\n",
    "        if expected_probs is None:\n",
    "            raise ValueError('provide expected_probs or expected_counts')\n",
    "        expected_probs = np.asarray(expected_probs, dtype=float)\n",
    "        if expected_probs.shape != observed.shape:\n",
    "            raise ValueError('expected_probs must match observed')\n",
    "        if np.any(expected_probs < 0):\n",
    "            raise ValueError('expected_probs must be non-negative')\n",
    "        if not np.isclose(expected_probs.sum(), 1.0):\n",
    "            raise ValueError('expected_probs must sum to 1')\n",
    "        expected_counts = n * expected_probs\n",
    "    else:\n",
    "        expected_counts = np.asarray(expected_counts, dtype=float)\n",
    "        if expected_counts.shape != observed.shape:\n",
    "            raise ValueError('expected_counts must match observed')\n",
    "\n",
    "    stat = chi_square_statistic(observed, expected_counts)\n",
    "    df = int(observed.size - 1 - ddof)\n",
    "    if df <= 0:\n",
    "        raise ValueError('degrees of freedom must be positive; check ddof')\n",
    "    p_value = chi2_sf(stat, df)\n",
    "    return dict(statistic=stat, df=df, p_value=p_value, expected=expected_counts)\n",
    "\n",
    "\n",
    "def expected_counts_independence(table):\n",
    "    observed = np.asarray(table, dtype=float)\n",
    "    if observed.ndim != 2:\n",
    "        raise ValueError('table must be 2D (rows x columns)')\n",
    "    n = float(observed.sum())\n",
    "    if n <= 0:\n",
    "        raise ValueError('table must have positive total count')\n",
    "    row_sums = observed.sum(axis=1, keepdims=True)\n",
    "    col_sums = observed.sum(axis=0, keepdims=True)\n",
    "    return row_sums @ col_sums / n\n",
    "\n",
    "\n",
    "def chi_square_independence(table):\n",
    "    observed = np.asarray(table, dtype=float)\n",
    "    expected = expected_counts_independence(observed)\n",
    "    stat = chi_square_statistic(observed, expected)\n",
    "    r, c = observed.shape\n",
    "    df = int((r - 1) * (c - 1))\n",
    "    p_value = chi2_sf(stat, df)\n",
    "    return dict(statistic=stat, df=df, p_value=p_value, expected=expected)\n",
    "\n",
    "\n",
    "def cramers_v(chi2_stat: float, n: float, r: int, c: int) -> float:\n",
    "    denom = n * min(r - 1, c - 1)\n",
    "    if denom <= 0:\n",
    "        return float('nan')\n",
    "    return math.sqrt(chi2_stat / denom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example A: Goodness-of-fit (is a die fair?)\n",
    "\n",
    "Suppose we roll a 6-sided die **n** times.\n",
    "\n",
    "- H0: p(face=i) = 1/6 for i=1..6 (fair die)\n",
    "- H1: the probabilities are not all 1/6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = np.arange(1, 7)\n",
    "observed = np.array([15, 23, 16, 19, 24, 23])\n",
    "\n",
    "expected_probs = np.ones_like(observed) / observed.size\n",
    "gof = chi_square_gof(observed, expected_probs=expected_probs)\n",
    "gof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = gof['expected']\n",
    "contrib = chi_square_contributions(observed, expected)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=faces, y=observed, name='observed'))\n",
    "fig.add_trace(go.Bar(x=faces, y=expected, name='expected (H0)'))\n",
    "fig.update_layout(\n",
    "    barmode='group',\n",
    "    title='Die rolls: observed vs expected counts',\n",
    "    xaxis_title='face',\n",
    "    yaxis_title='count',\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure(go.Bar(x=faces, y=contrib))\n",
    "fig.update_layout(\n",
    "    title='Per-category contribution to χ² statistic',\n",
    "    xaxis_title='face',\n",
    "    yaxis_title='(O−E)²/E',\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print('χ² statistic:', gof['statistic'])\n",
    "print('df:', gof['df'])\n",
    "print('p-value (χ² approx):', gof['p_value'])\n",
    "print('sum of contributions:', float(contrib.sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the goodness-of-fit result\n",
    "\n",
    "- If the p-value is small (≤ α), the data are **inconsistent** with the claimed probabilities.\n",
    "- If the p-value is not small, you *do not prove* H0; you only say the data are **compatible** with H0.\n",
    "\n",
    "Also remember:\n",
    "\n",
    "- χ² tests become very sensitive with large n.\n",
    "- A single p-value won't tell you *which* categories are driving the mismatch (use residuals/contributions).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo view of the null distribution (GOF)\n",
    "n_sims = 50_000\n",
    "n = int(observed.sum())\n",
    "\n",
    "sim_counts = rng.multinomial(n, expected_probs, size=n_sims)\n",
    "expected_counts = n * expected_probs\n",
    "sim_stats = np.sum((sim_counts - expected_counts) ** 2 / expected_counts, axis=1)\n",
    "\n",
    "p_mc = (np.sum(sim_stats >= gof['statistic']) + 1) / (n_sims + 1)\n",
    "\n",
    "x_grid = np.linspace(0.001, np.percentile(sim_stats, 99.7), 400)\n",
    "pdf_grid = chi2_pdf(x_grid, gof['df'])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=sim_stats,\n",
    "        nbinsx=70,\n",
    "        histnorm='probability density',\n",
    "        name='Monte Carlo (H0)',\n",
    "        opacity=0.65,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=x_grid, y=pdf_grid, mode='lines', name='χ² approximation'))\n",
    "fig.add_vline(x=gof['statistic'], line_dash='dash', line_color='firebrick')\n",
    "fig.update_layout(\n",
    "    title='Null distribution of χ² statistic (GOF): simulation vs χ² approximation',\n",
    "    xaxis_title='χ² statistic',\n",
    "    yaxis_title='density',\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print('Analytic p-value (χ² approx):', gof['p_value'])\n",
    "print('Monte Carlo p-value:', p_mc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which categories drive the discrepancy?\n",
    "\n",
    "The overall p-value is one number. To see *where* the discrepancy lives, look at:\n",
    "\n",
    "- standardized residuals r = (O−E)/√E\n",
    "- contributions (O−E)²/E\n",
    "\n",
    "Large |r| means that category differs from expectation more than random fluctuation would suggest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = standardized_residuals(observed, expected)\n",
    "\n",
    "fig = go.Figure(go.Bar(x=faces, y=resid))\n",
    "fig.update_layout(\n",
    "    title='Standardized residuals per face',\n",
    "    xaxis_title='face',\n",
    "    yaxis_title='(O−E)/√E',\n",
    ")\n",
    "fig.add_hline(y=2, line_dash='dot', line_color='gray')\n",
    "fig.add_hline(y=-2, line_dash='dot', line_color='gray')\n",
    "fig.show()\n",
    "\n",
    "resid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example B: Test of independence (contingency table)\n",
    "\n",
    "We observe counts for two categorical variables.\n",
    "\n",
    "- H0: the variables are independent (joint probability = product of marginals)\n",
    "- Expected cell count under H0:\n",
    "\n",
    "Eᵢⱼ = (row_totalᵢ × col_totalⱼ) / n\n",
    "\n",
    "- χ² statistic sums (Oᵢⱼ − Eᵢⱼ)² / Eᵢⱼ over all cells\n",
    "- df = (r−1)(c−1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_labels = np.array(['New', 'Returning'])\n",
    "col_labels = np.array(['Chat', 'Email', 'Phone'])\n",
    "\n",
    "table = np.array(\n",
    "    [\n",
    "        [50, 30, 20],\n",
    "        [30, 45, 25],\n",
    "    ]\n",
    ")\n",
    "\n",
    "ind = chi_square_independence(table)\n",
    "expected_ind = ind['expected']\n",
    "resid_ind = standardized_residuals(table, expected_ind)\n",
    "contrib_ind = chi_square_contributions(table, expected_ind)\n",
    "\n",
    "n = float(table.sum())\n",
    "v = cramers_v(ind['statistic'], n, *table.shape)\n",
    "\n",
    "print('χ² statistic:', ind['statistic'])\n",
    "print('df:', ind['df'])\n",
    "print('p-value (χ² approx):', ind['p_value'])\n",
    "print(\"Cramér's V:\", v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotated_heatmap(z, x_labels, y_labels, title, fmt='{:.1f}', colorscale='Blues', zmid=None):\n",
    "    z = np.asarray(z)\n",
    "    text = [[fmt.format(v) for v in row] for row in z]\n",
    "    heatmap_kwargs = dict(\n",
    "        z=z,\n",
    "        x=list(x_labels),\n",
    "        y=list(y_labels),\n",
    "        text=text,\n",
    "        texttemplate='%{text}',\n",
    "        colorscale=colorscale,\n",
    "        colorbar=dict(title='value'),\n",
    "    )\n",
    "    if zmid is not None:\n",
    "        heatmap_kwargs['zmid'] = zmid\n",
    "    fig = go.Figure(go.Heatmap(**heatmap_kwargs))\n",
    "    fig.update_layout(title=title, xaxis_title='column category', yaxis_title='row category')\n",
    "    return fig\n",
    "\n",
    "\n",
    "annotated_heatmap(table, col_labels, row_labels, title='Observed counts', fmt='{:.0f}').show()\n",
    "annotated_heatmap(expected_ind, col_labels, row_labels, title='Expected counts under independence (H0)').show()\n",
    "annotated_heatmap(resid_ind, col_labels, row_labels, title='Standardized residuals (direction + strength)', fmt='{:.2f}', colorscale='RdBu', zmid=0).show()\n",
    "annotated_heatmap(contrib_ind, col_labels, row_labels, title='Contributions to χ² (where the test is \"spent\")', fmt='{:.3f}', colorscale='Reds').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the independence test\n",
    "\n",
    "- If p-value ≤ α: evidence that variables are associated (not independent).\n",
    "- This does **not** prove causality — only association.\n",
    "- Standardized residuals tell direction (positive = more than expected, negative = less).\n",
    "- Report an effect size like **Cramér's V** (especially when n is large).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo view of the null distribution (independence)\n",
    "# We simulate tables under an independence model using plug-in (estimated marginals).\n",
    "n_sims = 50_000\n",
    "n_int = int(n)\n",
    "\n",
    "row_probs = table.sum(axis=1) / n\n",
    "col_probs = table.sum(axis=0) / n\n",
    "cell_probs = np.outer(row_probs, col_probs).ravel()\n",
    "\n",
    "sim_flat = rng.multinomial(n_int, cell_probs, size=n_sims)\n",
    "sim_tables = sim_flat.reshape(n_sims, table.shape[0], table.shape[1])\n",
    "\n",
    "# Compute the χ² statistic the same way as the test does: expected from margins of each simulated table.\n",
    "row_sums = sim_tables.sum(axis=2, keepdims=True)\n",
    "col_sums = sim_tables.sum(axis=1, keepdims=True)\n",
    "expected_sim = row_sums * col_sums / n\n",
    "sim_stats = np.sum((sim_tables - expected_sim) ** 2 / expected_sim, axis=(1, 2))\n",
    "\n",
    "p_mc = (np.sum(sim_stats >= ind['statistic']) + 1) / (n_sims + 1)\n",
    "\n",
    "x_grid = np.linspace(0.001, np.percentile(sim_stats, 99.7), 400)\n",
    "pdf_grid = chi2_pdf(x_grid, ind['df'])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=sim_stats,\n",
    "        nbinsx=70,\n",
    "        histnorm='probability density',\n",
    "        name='Monte Carlo (H0)',\n",
    "        opacity=0.65,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=x_grid, y=pdf_grid, mode='lines', name='χ² approximation'))\n",
    "fig.add_vline(x=ind['statistic'], line_dash='dash', line_color='firebrick')\n",
    "fig.update_layout(\n",
    "    title='Null distribution (independence): simulation vs χ² approximation',\n",
    "    xaxis_title='χ² statistic',\n",
    "    yaxis_title='density',\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print('Analytic p-value (χ² approx):', ind['p_value'])\n",
    "print('Monte Carlo p-value:', p_mc)\n",
    "print(\"Cramér's V:\", v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions and pitfalls\n",
    "\n",
    "1) **Independent observations**: counts come from independent draws (no repeated-measures unless modeled)\n",
    "2) **Adequate expected counts**: a common rule is all Eᵢⱼ ≥ 5 (or at least 80% ≥ 5 and none < 1)\n",
    "3) Categories are mutually exclusive and collectively exhaustive\n",
    "4) Large n makes the χ² approximation better — but also makes tiny differences \"significant\"\n",
    "\n",
    "Diagnostics / good practice:\n",
    "\n",
    "- Inspect expected counts; merge sparse categories if needed\n",
    "- Look at contributions and residuals, not only the p-value\n",
    "- Report an effect size (Cramér's V) and context\n",
    "- Beware multiple testing if you run many χ² tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical usage (SciPy, optional)\n",
    "\n",
    "SciPy provides:\n",
    "\n",
    "- `scipy.stats.chisquare` for goodness-of-fit\n",
    "- `scipy.stats.chi2_contingency` for independence (with optional Yates correction for 2×2)\n",
    "\n",
    "The NumPy implementation above is for learning; SciPy is recommended for production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from scipy.stats import chi2_contingency, chisquare\n",
    "\n",
    "    print('SciPy available:', True)\n",
    "\n",
    "    print('\\nGOF via scipy.stats.chisquare:')\n",
    "    print(chisquare(f_obs=observed, f_exp=gof['expected']))\n",
    "\n",
    "    print('\\nIndependence via scipy.stats.chi2_contingency:')\n",
    "    chi2_stat, p, dof, exp = chi2_contingency(table, correction=False)\n",
    "    print({'statistic': chi2_stat, 'p_value': p, 'df': dof})\n",
    "except Exception as e:\n",
    "    print('SciPy not available (or import failed):', repr(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1) Goodness-of-fit: simulate an unfair die and see how sample size affects p-value.\n",
    "2) Independence: create a contingency table where the association is weak but n is huge; compare p-value vs Cramér's V.\n",
    "3) Check the expected-count rule: what happens when some expected counts are < 5?\n",
    "4) Implement Yates' correction for a 2×2 table and compare.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Pearson's chi-square test (core statistic X² = Σ (O−E)²/E)\n",
    "- Any intro stats text: expected counts, df formulas, and assumptions\n",
    "- SciPy docs: `scipy.stats.chisquare`, `scipy.stats.chi2_contingency`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}