{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d652a452",
   "metadata": {},
   "source": [
    "# Large Language Models (LLM) Overview\n",
    "\n",
    "This notebook provides a comprehensive overview of Large Language Models, covering fundamental concepts, architectures, and training methodologies.\n",
    "\n",
    "## Table of Contents\n",
    "1. [LLM Fundamentals](#1-llm-fundamentals)\n",
    "2. [Transformer Architecture](#2-transformer-architecture)\n",
    "3. [Attention Mechanism](#3-attention-mechanism)\n",
    "4. [Tokenization](#4-tokenization)\n",
    "5. [Key Models](#5-key-models)\n",
    "6. [Training Stages](#6-training-stages)\n",
    "7. [Scaling Laws](#7-scaling-laws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa9c082",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. LLM Fundamentals\n",
    "\n",
    "### What is a Large Language Model?\n",
    "\n",
    "A **Large Language Model (LLM)** is a neural network trained on massive amounts of text data to understand and generate human-like text. These models learn statistical patterns in language and can perform various tasks:\n",
    "\n",
    "- **Text generation**: Writing essays, code, stories\n",
    "- **Question answering**: Providing informative responses\n",
    "- **Summarization**: Condensing long documents\n",
    "- **Translation**: Converting between languages\n",
    "- **Reasoning**: Solving logical and mathematical problems\n",
    "\n",
    "### Core Concept: Next Token Prediction\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                  Next Token Prediction                       │\n",
    "├─────────────────────────────────────────────────────────────┤\n",
    "│                                                              │\n",
    "│  Input:  \"The cat sat on the\"                               │\n",
    "│                    │                                         │\n",
    "│                    ▼                                         │\n",
    "│            ┌─────────────┐                                   │\n",
    "│            │    LLM      │                                   │\n",
    "│            └─────────────┘                                   │\n",
    "│                    │                                         │\n",
    "│                    ▼                                         │\n",
    "│  Probability Distribution:                                   │\n",
    "│    \"mat\"   → 0.45                                           │\n",
    "│    \"floor\" → 0.25                                           │\n",
    "│    \"bed\"   → 0.15                                           │\n",
    "│    \"roof\"  → 0.08                                           │\n",
    "│    ...     → 0.07                                           │\n",
    "│                                                              │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "LLMs are trained using **autoregressive language modeling**: predicting the next token given all previous tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f71ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified illustration of next-token prediction concept\n",
    "import numpy as np\n",
    "\n",
    "def softmax(logits):\n",
    "    \"\"\"Convert logits to probabilities\"\"\"\n",
    "    exp_logits = np.exp(logits - np.max(logits))\n",
    "    return exp_logits / exp_logits.sum()\n",
    "\n",
    "# Simulated vocabulary and logits from an LLM\n",
    "vocabulary = [\"mat\", \"floor\", \"bed\", \"roof\", \"table\", \"chair\"]\n",
    "logits = np.array([2.5, 1.8, 1.2, 0.5, 0.3, 0.1])  # Raw model outputs\n",
    "\n",
    "probabilities = softmax(logits)\n",
    "\n",
    "print(\"Input: 'The cat sat on the ___'\\n\")\n",
    "print(\"Token Probabilities:\")\n",
    "for token, prob in sorted(zip(vocabulary, probabilities), key=lambda x: -x[1]):\n",
    "    bar = \"█\" * int(prob * 40)\n",
    "    print(f\"  {token:8} {prob:.3f} {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a4fd24",
   "metadata": {},
   "source": [
    "### Key Characteristics of LLMs\n",
    "\n",
    "| Characteristic | Description |\n",
    "|---------------|-------------|\n",
    "| **Scale** | Billions to trillions of parameters |\n",
    "| **Training Data** | Terabytes of text from internet, books, code |\n",
    "| **Architecture** | Transformer-based (usually decoder-only) |\n",
    "| **Emergent Abilities** | Capabilities that appear at larger scales |\n",
    "| **In-context Learning** | Learning from examples in the prompt |\n",
    "| **Zero-shot Capability** | Performing tasks without task-specific training |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22eeddd",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Transformer Architecture\n",
    "\n",
    "The **Transformer** architecture, introduced in \"Attention Is All You Need\" (Vaswani et al., 2017), is the foundation of modern LLMs.\n",
    "\n",
    "### High-Level Architecture\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                    Transformer Architecture                         │\n",
    "├────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│  ┌──────────────────────┐     ┌──────────────────────┐             │\n",
    "│  │      ENCODER         │     │      DECODER         │             │\n",
    "│  │  (e.g., BERT)        │     │  (e.g., GPT)         │             │\n",
    "│  ├──────────────────────┤     ├──────────────────────┤             │\n",
    "│  │                      │     │                      │             │\n",
    "│  │  ┌────────────────┐  │     │  ┌────────────────┐  │             │\n",
    "│  │  │ Self-Attention │  │     │  │Masked Self-Attn│  │             │\n",
    "│  │  └───────┬────────┘  │     │  └───────┬────────┘  │             │\n",
    "│  │          │           │     │          │           │             │\n",
    "│  │  ┌───────▼────────┐  │     │  ┌───────▼────────┐  │             │\n",
    "│  │  │   Add & Norm   │  │     │  │   Add & Norm   │  │             │\n",
    "│  │  └───────┬────────┘  │     │  └───────┬────────┘  │             │\n",
    "│  │          │           │     │          │           │             │\n",
    "│  │  ┌───────▼────────┐  │     │  ┌───────▼────────┐  │             │\n",
    "│  │  │  Feed Forward  │  │     │  │  Feed Forward  │  │             │\n",
    "│  │  └───────┬────────┘  │     │  └───────┬────────┘  │             │\n",
    "│  │          │           │     │          │           │             │\n",
    "│  │  ┌───────▼────────┐  │     │  ┌───────▼────────┐  │             │\n",
    "│  │  │   Add & Norm   │  │     │  │   Add & Norm   │  │             │\n",
    "│  │  └────────────────┘  │     │  └────────────────┘  │             │\n",
    "│  │                      │     │                      │             │\n",
    "│  │     × N layers       │     │     × N layers       │             │\n",
    "│  └──────────────────────┘     └──────────────────────┘             │\n",
    "│                                                                     │\n",
    "│  Encoder: Bidirectional        Decoder: Autoregressive             │\n",
    "│  (sees all tokens)             (sees only past tokens)             │\n",
    "│                                                                     │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Types of Transformer Models\n",
    "\n",
    "| Type | Examples | Use Case |\n",
    "|------|----------|----------|\n",
    "| **Encoder-only** | BERT, RoBERTa | Classification, NER, embeddings |\n",
    "| **Decoder-only** | GPT, Claude, LLaMA | Text generation, chatbots |\n",
    "| **Encoder-Decoder** | T5, BART | Translation, summarization |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9600cfa3",
   "metadata": {},
   "source": [
    "### Decoder Block Details (GPT-style)\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                    Single Decoder Block                          │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                  │\n",
    "│                      Input (x)                                   │\n",
    "│                         │                                        │\n",
    "│                         ▼                                        │\n",
    "│                  ┌──────────────┐                                │\n",
    "│                  │  Layer Norm  │                                │\n",
    "│                  └──────┬───────┘                                │\n",
    "│                         │                                        │\n",
    "│                         ▼                                        │\n",
    "│              ┌──────────────────────┐                            │\n",
    "│              │  Multi-Head Causal   │                            │\n",
    "│              │  Self-Attention      │                            │\n",
    "│              └──────────┬───────────┘                            │\n",
    "│                         │                                        │\n",
    "│         x ─────────────(+)◄──────────  (Residual Connection)     │\n",
    "│                         │                                        │\n",
    "│                         ▼                                        │\n",
    "│                  ┌──────────────┐                                │\n",
    "│                  │  Layer Norm  │                                │\n",
    "│                  └──────┬───────┘                                │\n",
    "│                         │                                        │\n",
    "│                         ▼                                        │\n",
    "│              ┌──────────────────────┐                            │\n",
    "│              │   Feed-Forward Net   │                            │\n",
    "│              │   (MLP: up → down)   │                            │\n",
    "│              └──────────┬───────────┘                            │\n",
    "│                         │                                        │\n",
    "│         x ─────────────(+)◄──────────  (Residual Connection)     │\n",
    "│                         │                                        │\n",
    "│                         ▼                                        │\n",
    "│                    Output (y)                                    │\n",
    "│                                                                  │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e4614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"A single transformer decoder block (GPT-style, pre-norm)\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model: int, n_heads: int, d_ff: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.attn = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        # Pre-norm architecture (used in GPT-2, LLaMA)\n",
    "        # Self-attention with residual\n",
    "        normed = self.ln1(x)\n",
    "        attn_out, _ = self.attn(normed, normed, normed, attn_mask=mask, is_causal=True)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        \n",
    "        # FFN with residual\n",
    "        normed = self.ln2(x)\n",
    "        x = x + self.ffn(normed)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "d_model = 512   # Embedding dimension\n",
    "n_heads = 8     # Number of attention heads\n",
    "d_ff = 2048     # FFN hidden dimension (typically 4x d_model)\n",
    "\n",
    "block = TransformerBlock(d_model, n_heads, d_ff)\n",
    "x = torch.randn(2, 10, d_model)  # (batch, seq_len, d_model)\n",
    "output = block(x)\n",
    "\n",
    "print(f\"Input shape:  {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"\\nBlock parameters: {sum(p.numel() for p in block.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ed1cf1",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Attention Mechanism\n",
    "\n",
    "The **attention mechanism** is the core innovation of transformers. It allows each token to \"attend\" to all other tokens and gather relevant information.\n",
    "\n",
    "### Scaled Dot-Product Attention\n",
    "\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
    "\n",
    "Where:\n",
    "- **Q (Query)**: What am I looking for?\n",
    "- **K (Key)**: What do I contain?\n",
    "- **V (Value)**: What information should I pass?\n",
    "- **$d_k$**: Dimension of keys (for scaling)\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    Scaled Dot-Product Attention                      │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                      │\n",
    "│     Q          K          V                                          │\n",
    "│     │          │          │                                          │\n",
    "│     │          │          │                                          │\n",
    "│     └────┬─────┘          │                                          │\n",
    "│          │                │                                          │\n",
    "│          ▼                │                                          │\n",
    "│    ┌──────────┐           │                                          │\n",
    "│    │  MatMul  │  (Q @ K.T)│                                          │\n",
    "│    └────┬─────┘           │                                          │\n",
    "│         │                 │                                          │\n",
    "│         ▼                 │                                          │\n",
    "│    ┌──────────┐           │                                          │\n",
    "│    │  Scale   │  (÷ √dk) │                                          │\n",
    "│    └────┬─────┘           │                                          │\n",
    "│         │                 │                                          │\n",
    "│         ▼                 │                                          │\n",
    "│    ┌──────────┐           │                                          │\n",
    "│    │   Mask   │ (optional)│                                          │\n",
    "│    └────┬─────┘           │                                          │\n",
    "│         │                 │                                          │\n",
    "│         ▼                 │                                          │\n",
    "│    ┌──────────┐           │                                          │\n",
    "│    │ Softmax  │           │                                          │\n",
    "│    └────┬─────┘           │                                          │\n",
    "│         │                 │                                          │\n",
    "│         └────────┬────────┘                                          │\n",
    "│                  │                                                   │\n",
    "│                  ▼                                                   │\n",
    "│            ┌──────────┐                                              │\n",
    "│            │  MatMul  │  (attn_weights @ V)                          │\n",
    "│            └────┬─────┘                                              │\n",
    "│                 │                                                    │\n",
    "│                 ▼                                                    │\n",
    "│              Output                                                  │\n",
    "│                                                                      │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e923525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    \"\"\"\n",
    "    Compute scaled dot-product attention.\n",
    "    \n",
    "    Args:\n",
    "        Q: Query tensor (batch, seq_len, d_k)\n",
    "        K: Key tensor (batch, seq_len, d_k)\n",
    "        V: Value tensor (batch, seq_len, d_v)\n",
    "        mask: Optional attention mask\n",
    "    \n",
    "    Returns:\n",
    "        output: Weighted sum of values\n",
    "        attention_weights: Attention probabilities\n",
    "    \"\"\"\n",
    "    d_k = Q.size(-1)\n",
    "    \n",
    "    # Compute attention scores\n",
    "    scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    \n",
    "    # Apply mask (for causal/decoder attention)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "    \n",
    "    # Softmax to get attention weights\n",
    "    attention_weights = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    # Weighted sum of values\n",
    "    output = torch.matmul(attention_weights, V)\n",
    "    \n",
    "    return output, attention_weights\n",
    "\n",
    "# Example: Simple attention computation\n",
    "batch_size, seq_len, d_k = 1, 4, 8\n",
    "Q = torch.randn(batch_size, seq_len, d_k)\n",
    "K = torch.randn(batch_size, seq_len, d_k)\n",
    "V = torch.randn(batch_size, seq_len, d_k)\n",
    "\n",
    "# Create causal mask (lower triangular)\n",
    "causal_mask = torch.tril(torch.ones(seq_len, seq_len))\n",
    "\n",
    "output, attn_weights = scaled_dot_product_attention(Q, K, V, causal_mask)\n",
    "\n",
    "print(\"Causal Attention Mask:\")\n",
    "print(causal_mask.numpy())\n",
    "print(\"\\nAttention Weights (after masking):\")\n",
    "print(attn_weights.squeeze().detach().numpy().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ca1c53",
   "metadata": {},
   "source": [
    "### Multi-Head Attention\n",
    "\n",
    "Instead of performing single attention, we use **multiple attention heads** in parallel, allowing the model to attend to information from different representation subspaces.\n",
    "\n",
    "```\n",
    "┌──────────────────────────────────────────────────────────────────────┐\n",
    "│                       Multi-Head Attention                            │\n",
    "├──────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                       │\n",
    "│              Input (d_model = 512)                                    │\n",
    "│                      │                                                │\n",
    "│    ┌─────────────────┼─────────────────┐                              │\n",
    "│    │                 │                 │                              │\n",
    "│    ▼                 ▼                 ▼                              │\n",
    "│  ┌────┐           ┌────┐           ┌────┐                             │\n",
    "│  │ Wq │           │ Wk │           │ Wv │   Linear projections        │\n",
    "│  └─┬──┘           └─┬──┘           └─┬──┘                             │\n",
    "│    │                │                │                                │\n",
    "│    ▼                ▼                ▼                                │\n",
    "│  ┌───────────────────────────────────────┐                            │\n",
    "│  │     Split into h=8 heads              │                            │\n",
    "│  │     (d_k = d_model/h = 64 per head)   │                            │\n",
    "│  └───────────────────────────────────────┘                            │\n",
    "│    │                                                                  │\n",
    "│    ├──► Head 1: Attention(Q₁, K₁, V₁)                                │\n",
    "│    ├──► Head 2: Attention(Q₂, K₂, V₂)                                │\n",
    "│    ├──► Head 3: Attention(Q₃, K₃, V₃)                                │\n",
    "│    │     ...                                                          │\n",
    "│    └──► Head 8: Attention(Q₈, K₈, V₈)                                │\n",
    "│                      │                                                │\n",
    "│                      ▼                                                │\n",
    "│            ┌─────────────────┐                                        │\n",
    "│            │   Concatenate   │                                        │\n",
    "│            └────────┬────────┘                                        │\n",
    "│                     │                                                 │\n",
    "│                     ▼                                                 │\n",
    "│               ┌──────────┐                                            │\n",
    "│               │    Wo    │  Output projection                         │\n",
    "│               └────┬─────┘                                            │\n",
    "│                    │                                                  │\n",
    "│                    ▼                                                  │\n",
    "│              Output (d_model)                                         │\n",
    "│                                                                       │\n",
    "└──────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Why Multi-Head?**\n",
    "- Each head can learn different types of relationships\n",
    "- Head 1 might focus on syntactic relationships\n",
    "- Head 2 might capture semantic similarity\n",
    "- Head 3 might track positional patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e300023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multi-Head Attention implementation from scratch\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model: int, n_heads: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "        \n",
    "        # Linear projections for Q, K, V\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # Project and reshape: (batch, seq, d_model) -> (batch, n_heads, seq, d_k)\n",
    "        Q = self.W_q(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # Compute attention\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        \n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        context = torch.matmul(attn_weights, V)\n",
    "        \n",
    "        # Concatenate heads and project\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
    "        output = self.W_o(context)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Demonstrate\n",
    "mha = MultiHeadAttention(d_model=256, n_heads=8)\n",
    "x = torch.randn(2, 16, 256)  # (batch, seq_len, d_model)\n",
    "output = mha(x)\n",
    "\n",
    "print(f\"Multi-Head Attention\")\n",
    "print(f\"  d_model: 256, n_heads: 8, d_k: 32\")\n",
    "print(f\"  Input shape:  {x.shape}\")\n",
    "print(f\"  Output shape: {output.shape}\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in mha.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f1a27a",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Tokenization\n",
    "\n",
    "**Tokenization** is the process of converting raw text into a sequence of discrete tokens that the model can process.\n",
    "\n",
    "### Tokenization Methods\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                     Tokenization Methods                             │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                      │\n",
    "│  Input: \"The transformer architecture is amazing!\"                  │\n",
    "│                                                                      │\n",
    "│  ┌─────────────────────────────────────────────────────────────┐    │\n",
    "│  │ Word-level:                                                  │    │\n",
    "│  │ [\"The\", \"transformer\", \"architecture\", \"is\", \"amazing\", \"!\"] │    │\n",
    "│  │ ⚠️ Large vocabulary, OOV problems                            │    │\n",
    "│  └─────────────────────────────────────────────────────────────┘    │\n",
    "│                                                                      │\n",
    "│  ┌─────────────────────────────────────────────────────────────┐    │\n",
    "│  │ Character-level:                                             │    │\n",
    "│  │ [\"T\",\"h\",\"e\",\" \",\"t\",\"r\",\"a\",\"n\",\"s\",\"f\",\"o\",\"r\",\"m\",...]   │    │\n",
    "│  │ ⚠️ Very long sequences, hard to learn semantics              │    │\n",
    "│  └─────────────────────────────────────────────────────────────┘    │\n",
    "│                                                                      │\n",
    "│  ┌─────────────────────────────────────────────────────────────┐    │\n",
    "│  │ Subword (BPE/WordPiece/Unigram):                    ✓ Best   │    │\n",
    "│  │ [\"The\", \" transform\", \"er\", \" architecture\", \" is\", ...]   │    │\n",
    "│  │ ✓ Balanced vocabulary, handles rare words                    │    │\n",
    "│  └─────────────────────────────────────────────────────────────┘    │\n",
    "│                                                                      │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Popular Tokenizers\n",
    "\n",
    "| Tokenizer | Used By | Vocab Size | Key Features |\n",
    "|-----------|---------|------------|---------------|\n",
    "| **BPE** | GPT-2, GPT-3 | 50,257 | Byte-level, no UNK tokens |\n",
    "| **SentencePiece** | LLaMA, T5 | ~32,000 | Language-agnostic |\n",
    "| **WordPiece** | BERT | 30,522 | Subword with ## prefix |\n",
    "| **tiktoken** | GPT-4, Claude | ~100,000 | Fast, efficient |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acb2579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate tokenization with tiktoken (OpenAI's tokenizer)\n",
    "try:\n",
    "    import tiktoken\n",
    "    \n",
    "    # GPT-4 uses cl100k_base encoding\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    \n",
    "    text = \"The transformer architecture revolutionized natural language processing!\"\n",
    "    \n",
    "    # Encode\n",
    "    tokens = enc.encode(text)\n",
    "    \n",
    "    print(f\"Original text: '{text}'\")\n",
    "    print(f\"\\nNumber of tokens: {len(tokens)}\")\n",
    "    print(f\"Token IDs: {tokens}\")\n",
    "    print(f\"\\nToken breakdown:\")\n",
    "    for token_id in tokens:\n",
    "        token_text = enc.decode([token_id])\n",
    "        print(f\"  {token_id:6d} → '{token_text}'\")\n",
    "    \n",
    "    # Decode back\n",
    "    decoded = enc.decode(tokens)\n",
    "    print(f\"\\nDecoded text: '{decoded}'\")\n",
    "    print(f\"Round-trip successful: {text == decoded}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"tiktoken not installed. Install with: pip install tiktoken\")\n",
    "    print(\"\\nSimulated tokenization example:\")\n",
    "    print(\"  'Hello world' → [15496, 995]\")\n",
    "    print(\"  'Transformer'  → [49688, Former]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb488af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple BPE implementation for educational purposes\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "\n",
    "def get_vocab(text: str) -> dict:\n",
    "    \"\"\"Initialize vocabulary with character-level tokens\"\"\"\n",
    "    words = text.lower().split()\n",
    "    vocab = Counter()\n",
    "    for word in words:\n",
    "        # Add end-of-word marker\n",
    "        word_tokens = tuple(list(word) + ['</w>'])\n",
    "        vocab[word_tokens] += 1\n",
    "    return vocab\n",
    "\n",
    "def get_pairs(vocab: dict) -> Counter:\n",
    "    \"\"\"Get frequency of adjacent pairs\"\"\"\n",
    "    pairs = Counter()\n",
    "    for word, freq in vocab.items():\n",
    "        for i in range(len(word) - 1):\n",
    "            pairs[(word[i], word[i+1])] += freq\n",
    "    return pairs\n",
    "\n",
    "def merge_vocab(pair: tuple, vocab: dict) -> dict:\n",
    "    \"\"\"Merge most frequent pair in vocabulary\"\"\"\n",
    "    new_vocab = {}\n",
    "    bigram = pair\n",
    "    replacement = ''.join(pair)\n",
    "    \n",
    "    for word, freq in vocab.items():\n",
    "        new_word = []\n",
    "        i = 0\n",
    "        while i < len(word):\n",
    "            if i < len(word) - 1 and (word[i], word[i+1]) == bigram:\n",
    "                new_word.append(replacement)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_word.append(word[i])\n",
    "                i += 1\n",
    "        new_vocab[tuple(new_word)] = freq\n",
    "    \n",
    "    return new_vocab\n",
    "\n",
    "# Demonstrate BPE on sample text\n",
    "text = \"the cat sat on the mat the cat is fat\"\n",
    "vocab = get_vocab(text)\n",
    "\n",
    "print(\"BPE (Byte Pair Encoding) Demo\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nInitial text: '{text}'\")\n",
    "print(f\"\\nInitial vocabulary (character-level):\")\n",
    "for word, freq in sorted(vocab.items(), key=lambda x: -x[1])[:5]:\n",
    "    print(f\"  {' '.join(word):20} freq={freq}\")\n",
    "\n",
    "# Perform a few BPE merges\n",
    "num_merges = 5\n",
    "print(f\"\\nPerforming {num_merges} BPE merges:\")\n",
    "for i in range(num_merges):\n",
    "    pairs = get_pairs(vocab)\n",
    "    if not pairs:\n",
    "        break\n",
    "    best_pair = pairs.most_common(1)[0][0]\n",
    "    vocab = merge_vocab(best_pair, vocab)\n",
    "    print(f\"  Merge {i+1}: '{best_pair[0]}' + '{best_pair[1]}' → '{best_pair[0]+best_pair[1]}'\")\n",
    "\n",
    "print(f\"\\nFinal vocabulary after merges:\")\n",
    "for word, freq in sorted(vocab.items(), key=lambda x: -x[1])[:5]:\n",
    "    print(f\"  {' '.join(word):20} freq={freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c30d565",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Key Models\n",
    "\n",
    "### Evolution of LLMs\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────────────┐\n",
    "│                        LLM Evolution Timeline                               │\n",
    "├────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                             │\n",
    "│  2017    2018      2019       2020        2022        2023       2024       │\n",
    "│    │       │         │          │           │           │          │        │\n",
    "│    ▼       ▼         ▼          ▼           ▼           ▼          ▼        │\n",
    "│  Trans-  BERT     GPT-2      GPT-3      ChatGPT     GPT-4     Claude 3    │\n",
    "│  former  110M     1.5B       175B       (RLHF)      ~1.7T?    LLaMA 3      │\n",
    "│                                                     Claude 2              │\n",
    "│    │       │         │          │           │           │          │        │\n",
    "│    └───────┴─────────┴──────────┴───────────┴───────────┴──────────┘        │\n",
    "│                                                                             │\n",
    "│  Key Milestones:                                                            │\n",
    "│  • 2017: Attention Is All You Need (Transformer)                            │\n",
    "│  • 2018: BERT - Bidirectional pretraining                                   │\n",
    "│  • 2019: GPT-2 - \"Too dangerous to release\"                                 │\n",
    "│  • 2020: GPT-3 - In-context learning, few-shot                              │\n",
    "│  • 2022: ChatGPT - RLHF, conversational AI goes mainstream                  │\n",
    "│  • 2023: GPT-4/Claude 2 - Multimodal, improved reasoning                    │\n",
    "│  • 2024: Claude 3/LLaMA 3 - Open weights, competition intensifies           │\n",
    "│                                                                             │\n",
    "└────────────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ef389",
   "metadata": {},
   "source": [
    "### GPT Family (OpenAI)\n",
    "\n",
    "**GPT (Generative Pre-trained Transformer)** models are decoder-only transformers trained for autoregressive language modeling.\n",
    "\n",
    "| Model | Parameters | Context | Key Features |\n",
    "|-------|------------|---------|---------------|\n",
    "| GPT-2 | 1.5B | 1,024 | Open weights, trained on WebText |\n",
    "| GPT-3 | 175B | 2,048 | Few-shot learning, API-only |\n",
    "| GPT-3.5 | ~20B? | 4,096 | RLHF, ChatGPT |\n",
    "| GPT-4 | ~1.7T? (MoE) | 8K-128K | Multimodal, improved reasoning |\n",
    "| GPT-4o | Unknown | 128K | Fast, multimodal native |\n",
    "\n",
    "### Claude Family (Anthropic)\n",
    "\n",
    "**Claude** models are developed by Anthropic with a focus on safety, helpfulness, and honesty.\n",
    "\n",
    "| Model | Context | Key Features |\n",
    "|-------|---------|---------------|\n",
    "| Claude 1 | 9K | Constitutional AI |\n",
    "| Claude 2 | 100K | Longer context, improved coding |\n",
    "| Claude 3 Haiku | 200K | Fast, efficient |\n",
    "| Claude 3 Sonnet | 200K | Balanced speed/capability |\n",
    "| Claude 3 Opus | 200K | Most capable |\n",
    "| Claude 3.5 Sonnet | 200K | Improved reasoning, artifacts |\n",
    "\n",
    "**Key Innovations:**\n",
    "- **Constitutional AI (CAI)**: Self-improvement through principles\n",
    "- **RLHF with human feedback**: Alignment with human values\n",
    "- **Harmlessness training**: Reducing harmful outputs\n",
    "\n",
    "### LLaMA Family (Meta)\n",
    "\n",
    "**LLaMA (Large Language Model Meta AI)** provides open-weight models for research.\n",
    "\n",
    "| Model | Parameters | Context | Key Features |\n",
    "|-------|------------|---------|---------------|\n",
    "| LLaMA 1 | 7B-65B | 2K | Open weights for research |\n",
    "| LLaMA 2 | 7B-70B | 4K | Commercial license, chat-tuned |\n",
    "| LLaMA 3 | 8B-70B | 8K | Improved training, tokenizer |\n",
    "| LLaMA 3.1 | 8B-405B | 128K | Largest open model |\n",
    "\n",
    "**Key Innovations:**\n",
    "- **RMSNorm**: Faster layer normalization\n",
    "- **SwiGLU activation**: Better than GELU\n",
    "- **Rotary Position Embeddings (RoPE)**: Efficient position encoding\n",
    "- **Grouped Query Attention (GQA)**: Efficient inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model size comparison visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "models = {\n",
    "    'GPT-2': 1.5,\n",
    "    'GPT-3': 175,\n",
    "    'LLaMA-7B': 7,\n",
    "    'LLaMA-70B': 70,\n",
    "    'LLaMA-405B': 405,\n",
    "    'GPT-4 (est.)': 1700,  # Estimated MoE total\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "names = list(models.keys())\n",
    "sizes = list(models.values())\n",
    "colors = ['#1f77b4', '#1f77b4', '#2ca02c', '#2ca02c', '#2ca02c', '#ff7f0e']\n",
    "\n",
    "bars = ax.barh(names, sizes, color=colors)\n",
    "ax.set_xlabel('Parameters (Billions)', fontsize=12)\n",
    "ax.set_title('LLM Parameter Comparison', fontsize=14)\n",
    "ax.set_xscale('log')\n",
    "\n",
    "# Add value labels\n",
    "for bar, size in zip(bars, sizes):\n",
    "    ax.text(size * 1.1, bar.get_y() + bar.get_height()/2, \n",
    "            f'{size:.0f}B', va='center', fontsize=10)\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#1f77b4', label='OpenAI GPT'),\n",
    "    Patch(facecolor='#2ca02c', label='Meta LLaMA'),\n",
    "    Patch(facecolor='#ff7f0e', label='GPT-4 (MoE est.)'),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8356aa",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Training Stages\n",
    "\n",
    "Modern LLMs go through multiple training stages:\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────────────┐\n",
    "│                        LLM Training Pipeline                                │\n",
    "├────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                             │\n",
    "│  ┌─────────────────────────────────────────────────────────────────────┐   │\n",
    "│  │  Stage 1: PRETRAINING                                                │   │\n",
    "│  │  ─────────────────────                                               │   │\n",
    "│  │  • Objective: Next token prediction                                  │   │\n",
    "│  │  • Data: Trillions of tokens (web, books, code)                      │   │\n",
    "│  │  • Compute: 1000s of GPUs for weeks/months                           │   │\n",
    "│  │  • Result: Base model with general knowledge                         │   │\n",
    "│  └─────────────────────────────────────────────────────────────────────┘   │\n",
    "│                                    │                                        │\n",
    "│                                    ▼                                        │\n",
    "│  ┌─────────────────────────────────────────────────────────────────────┐   │\n",
    "│  │  Stage 2: SUPERVISED FINE-TUNING (SFT)                               │   │\n",
    "│  │  ─────────────────────────────────────                               │   │\n",
    "│  │  • Objective: Learn instruction following                            │   │\n",
    "│  │  • Data: (instruction, response) pairs                               │   │\n",
    "│  │  • Compute: 10s-100s of GPUs for hours/days                          │   │\n",
    "│  │  • Result: Instruction-tuned model                                   │   │\n",
    "│  └─────────────────────────────────────────────────────────────────────┘   │\n",
    "│                                    │                                        │\n",
    "│                                    ▼                                        │\n",
    "│  ┌─────────────────────────────────────────────────────────────────────┐   │\n",
    "│  │  Stage 3: RLHF (Reinforcement Learning from Human Feedback)          │   │\n",
    "│  │  ──────────────────────────────────────────────────────              │   │\n",
    "│  │  • Train reward model on human preferences                           │   │\n",
    "│  │  • Optimize policy (LLM) using PPO/DPO                               │   │\n",
    "│  │  • Result: Aligned, helpful, harmless model                          │   │\n",
    "│  └─────────────────────────────────────────────────────────────────────┘   │\n",
    "│                                                                             │\n",
    "└────────────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977182a6",
   "metadata": {},
   "source": [
    "### Stage 1: Pretraining\n",
    "\n",
    "The foundational training stage where the model learns language patterns.\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                      Pretraining                                 │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                  │\n",
    "│   Training Data                        Objective                 │\n",
    "│   ─────────────                        ─────────                 │\n",
    "│   • Common Crawl (web)                                           │\n",
    "│   • Books (Books3, etc.)        \"The cat sat on the [?]\"        │\n",
    "│   • Wikipedia                            │                       │\n",
    "│   • Code (GitHub)                        ▼                       │\n",
    "│   • Scientific papers            Predict: \"mat\"                  │\n",
    "│                                                                  │\n",
    "│   Loss Function:                                                 │\n",
    "│   ─────────────                                                  │\n",
    "│   L = -∑ log P(token_t | token_1, ..., token_{t-1})             │\n",
    "│       (Cross-entropy loss)                                       │\n",
    "│                                                                  │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified pretraining loss calculation\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_lm_loss(logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute language modeling loss (cross-entropy).\n",
    "    \n",
    "    Args:\n",
    "        logits: Model predictions (batch, seq_len, vocab_size)\n",
    "        targets: Ground truth token IDs (batch, seq_len)\n",
    "    \"\"\"\n",
    "    # Flatten for cross-entropy\n",
    "    batch_size, seq_len, vocab_size = logits.shape\n",
    "    logits_flat = logits.view(-1, vocab_size)\n",
    "    targets_flat = targets.view(-1)\n",
    "    \n",
    "    # Cross-entropy loss\n",
    "    loss = F.cross_entropy(logits_flat, targets_flat, reduction='mean')\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Simulate a forward pass\n",
    "batch_size = 4\n",
    "seq_len = 128\n",
    "vocab_size = 50257  # GPT-2 vocabulary size\n",
    "\n",
    "# Random logits (in practice, from the model)\n",
    "logits = torch.randn(batch_size, seq_len, vocab_size)\n",
    "# Random targets (in practice, the next tokens)\n",
    "targets = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "\n",
    "loss = compute_lm_loss(logits, targets)\n",
    "perplexity = torch.exp(loss)\n",
    "\n",
    "print(f\"Pretraining Metrics (simulated):\")\n",
    "print(f\"  Cross-entropy loss: {loss.item():.4f}\")\n",
    "print(f\"  Perplexity: {perplexity.item():.2f}\")\n",
    "print(f\"\\n  Note: Lower perplexity = better language modeling\")\n",
    "print(f\"  Typical pretrained LLM perplexity: 5-20 on held-out data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2ee18f",
   "metadata": {},
   "source": [
    "### Stage 2: Supervised Fine-Tuning (SFT)\n",
    "\n",
    "Teaching the model to follow instructions.\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│               Supervised Fine-Tuning (SFT)                       │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                  │\n",
    "│  Training Data Format:                                           │\n",
    "│  ─────────────────────                                           │\n",
    "│                                                                  │\n",
    "│  ┌─────────────────────────────────────────────────────┐        │\n",
    "│  │ <s>[INST] Explain quantum computing [/INST]         │        │\n",
    "│  │ Quantum computing harnesses quantum mechanical      │        │\n",
    "│  │ phenomena like superposition and entanglement...    │        │\n",
    "│  │ </s>                                                 │        │\n",
    "│  └─────────────────────────────────────────────────────┘        │\n",
    "│                                                                  │\n",
    "│  Key Aspects:                                                    │\n",
    "│  • Only compute loss on response tokens (not instruction)       │\n",
    "│  • Data: 10K-1M high-quality examples                           │\n",
    "│  • Sources: Human-written, distilled from larger models         │\n",
    "│                                                                  │\n",
    "│  Popular SFT Datasets:                                           │\n",
    "│  • FLAN Collection                                               │\n",
    "│  • Alpaca (Stanford)                                             │\n",
    "│  • ShareGPT                                                      │\n",
    "│  • OpenAssistant                                                 │\n",
    "│                                                                  │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6b3004",
   "metadata": {},
   "source": [
    "### Stage 3: RLHF (Reinforcement Learning from Human Feedback)\n",
    "\n",
    "Aligning the model with human preferences.\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────────────┐\n",
    "│                              RLHF Pipeline                                  │\n",
    "├────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                             │\n",
    "│  Step 1: Collect Human Preferences                                          │\n",
    "│  ─────────────────────────────────                                          │\n",
    "│                                                                             │\n",
    "│    Prompt: \"Explain photosynthesis\"                                        │\n",
    "│                                                                             │\n",
    "│    Response A                      Response B                               │\n",
    "│    ┌──────────────────┐           ┌──────────────────┐                     │\n",
    "│    │ Photosynthesis   │           │ Plants eat sun   │                     │\n",
    "│    │ converts light   │     👍    │ and make food.   │     👎              │\n",
    "│    │ energy into...   │   BETTER  │                  │    WORSE            │\n",
    "│    └──────────────────┘           └──────────────────┘                     │\n",
    "│                                                                             │\n",
    "│  Step 2: Train Reward Model                                                 │\n",
    "│  ──────────────────────────                                                 │\n",
    "│                                                                             │\n",
    "│    ┌─────────────────────────────────────────────────────┐                 │\n",
    "│    │  Reward Model (RM)                                  │                 │\n",
    "│    │  r = RM(prompt, response)                           │                 │\n",
    "│    │  Loss: -log(σ(r_chosen - r_rejected))               │                 │\n",
    "│    └─────────────────────────────────────────────────────┘                 │\n",
    "│                                                                             │\n",
    "│  Step 3: Optimize Policy with PPO                                           │\n",
    "│  ────────────────────────────────                                           │\n",
    "│                                                                             │\n",
    "│    ┌────────────┐   generate   ┌────────────┐   score   ┌────────────┐    │\n",
    "│    │   Policy   │───────────►  │  Response  │─────────► │   Reward   │    │\n",
    "│    │   (LLM)    │              │            │           │   Model    │    │\n",
    "│    └─────▲──────┘              └────────────┘           └─────┬──────┘    │\n",
    "│          │                                                    │           │\n",
    "│          └────────────────── PPO Update ◄─────────────────────┘           │\n",
    "│                                                                             │\n",
    "│    Loss = -E[r(x,y)] + β·KL(π_θ || π_ref)                                  │\n",
    "│           ↑               ↑                                                │\n",
    "│        Maximize       KL penalty to stay close                             │\n",
    "│        reward         to original model                                    │\n",
    "│                                                                             │\n",
    "└────────────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward model training objective (Bradley-Terry model)\n",
    "def reward_model_loss(r_chosen: torch.Tensor, r_rejected: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute reward model loss using Bradley-Terry model.\n",
    "    \n",
    "    The loss encourages the reward model to assign higher scores\n",
    "    to preferred responses.\n",
    "    \n",
    "    Args:\n",
    "        r_chosen: Reward for chosen/preferred response\n",
    "        r_rejected: Reward for rejected response\n",
    "    \"\"\"\n",
    "    # Sigmoid on difference: P(chosen > rejected) = σ(r_chosen - r_rejected)\n",
    "    return -torch.log(torch.sigmoid(r_chosen - r_rejected)).mean()\n",
    "\n",
    "# Simulate reward model outputs\n",
    "batch_size = 16\n",
    "r_chosen = torch.randn(batch_size) + 1.0    # Higher rewards\n",
    "r_rejected = torch.randn(batch_size) - 0.5  # Lower rewards\n",
    "\n",
    "loss = reward_model_loss(r_chosen, r_rejected)\n",
    "\n",
    "print(\"Reward Model Training\")\n",
    "print(\"=\"*50)\n",
    "print(f\"  Mean reward (chosen):   {r_chosen.mean():.3f}\")\n",
    "print(f\"  Mean reward (rejected): {r_rejected.mean():.3f}\")\n",
    "print(f\"  Loss: {loss.item():.4f}\")\n",
    "print(f\"\\n  Note: Loss decreases as the model learns to\")\n",
    "print(f\"        distinguish preferred from rejected responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c41babe",
   "metadata": {},
   "source": [
    "### Alternative: Direct Preference Optimization (DPO)\n",
    "\n",
    "DPO simplifies RLHF by eliminating the need for a separate reward model.\n",
    "\n",
    "$$\\mathcal{L}_{DPO}(\\pi_\\theta; \\pi_{ref}) = -\\mathbb{E}\\left[\\log \\sigma\\left(\\beta \\log \\frac{\\pi_\\theta(y_w|x)}{\\pi_{ref}(y_w|x)} - \\beta \\log \\frac{\\pi_\\theta(y_l|x)}{\\pi_{ref}(y_l|x)}\\right)\\right]$$\n",
    "\n",
    "Where:\n",
    "- $y_w$: Preferred (winning) response\n",
    "- $y_l$: Rejected (losing) response\n",
    "- $\\beta$: Temperature parameter\n",
    "- $\\pi_{ref}$: Reference policy (SFT model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b098378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpo_loss(\n",
    "    policy_chosen_logps: torch.Tensor,\n",
    "    policy_rejected_logps: torch.Tensor,\n",
    "    reference_chosen_logps: torch.Tensor,\n",
    "    reference_rejected_logps: torch.Tensor,\n",
    "    beta: float = 0.1\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute DPO loss.\n",
    "    \n",
    "    Args:\n",
    "        policy_chosen_logps: Log probs of chosen response under policy\n",
    "        policy_rejected_logps: Log probs of rejected response under policy\n",
    "        reference_chosen_logps: Log probs of chosen response under reference\n",
    "        reference_rejected_logps: Log probs of rejected response under reference\n",
    "        beta: Temperature parameter\n",
    "    \"\"\"\n",
    "    # Compute log ratios\n",
    "    chosen_logratios = policy_chosen_logps - reference_chosen_logps\n",
    "    rejected_logratios = policy_rejected_logps - reference_rejected_logps\n",
    "    \n",
    "    # DPO loss\n",
    "    logits = beta * (chosen_logratios - rejected_logratios)\n",
    "    loss = -F.logsigmoid(logits).mean()\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Simulate log probabilities\n",
    "batch_size = 16\n",
    "policy_chosen = torch.randn(batch_size) - 2.0\n",
    "policy_rejected = torch.randn(batch_size) - 3.0\n",
    "ref_chosen = torch.randn(batch_size) - 2.5\n",
    "ref_rejected = torch.randn(batch_size) - 2.5\n",
    "\n",
    "loss = dpo_loss(policy_chosen, policy_rejected, ref_chosen, ref_rejected)\n",
    "\n",
    "print(\"Direct Preference Optimization (DPO)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"  Loss: {loss.item():.4f}\")\n",
    "print(f\"\\n  Advantages of DPO over RLHF:\")\n",
    "print(f\"  • No separate reward model needed\")\n",
    "print(f\"  • More stable training (no RL)\")\n",
    "print(f\"  • Simpler implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181d4640",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Scaling Laws\n",
    "\n",
    "**Scaling laws** describe how model performance improves with increased compute, data, and parameters.\n",
    "\n",
    "### Kaplan Scaling Laws (OpenAI, 2020)\n",
    "\n",
    "Performance scales as a power law with:\n",
    "\n",
    "$$L(N) \\propto N^{-0.076}$$\n",
    "$$L(D) \\propto D^{-0.095}$$\n",
    "$$L(C) \\propto C^{-0.050}$$\n",
    "\n",
    "Where:\n",
    "- $L$: Cross-entropy loss\n",
    "- $N$: Number of parameters\n",
    "- $D$: Dataset size (tokens)\n",
    "- $C$: Compute budget (FLOPs)\n",
    "\n",
    "### Chinchilla Scaling Laws (DeepMind, 2022)\n",
    "\n",
    "Key finding: **Models are typically undertrained!**\n",
    "\n",
    "Optimal ratio: **20 tokens per parameter**\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────────────┐\n",
    "│                    Chinchilla Optimal Scaling                               │\n",
    "├────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                             │\n",
    "│  For a given compute budget C:                                              │\n",
    "│                                                                             │\n",
    "│  ┌─────────────────────────────────────────────────────────────────────┐   │\n",
    "│  │                                                                      │   │\n",
    "│  │    N_opt ∝ C^0.5      (Optimal parameters)                          │   │\n",
    "│  │    D_opt ∝ C^0.5      (Optimal tokens)                              │   │\n",
    "│  │                                                                      │   │\n",
    "│  │    N_opt ≈ D_opt / 20                                               │   │\n",
    "│  │                                                                      │   │\n",
    "│  └─────────────────────────────────────────────────────────────────────┘   │\n",
    "│                                                                             │\n",
    "│  Comparison:                                                                │\n",
    "│  ───────────                                                                │\n",
    "│                                                                             │\n",
    "│  Model        Parameters   Tokens        Tokens/Param   Status             │\n",
    "│  ─────        ──────────   ──────        ────────────   ──────             │\n",
    "│  GPT-3        175B         300B          1.7            Undertrained       │\n",
    "│  Chinchilla   70B          1.4T          20             Optimal            │\n",
    "│  LLaMA        65B          1.4T          21.5           Optimal            │\n",
    "│  LLaMA 2      70B          2T            28.6           Well-trained       │\n",
    "│                                                                             │\n",
    "│  Both Chinchilla (70B) and GPT-3 (175B) achieve similar performance!       │\n",
    "│                                                                             │\n",
    "└────────────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0bcb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Visualize scaling laws\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Loss vs Parameters\n",
    "ax1 = axes[0]\n",
    "params = np.logspace(6, 12, 100)  # 1M to 1T parameters\n",
    "loss_kaplan = 10 * (params / 1e6) ** (-0.076)  # Kaplan scaling\n",
    "\n",
    "ax1.loglog(params, loss_kaplan, 'b-', linewidth=2)\n",
    "ax1.set_xlabel('Parameters', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Loss vs Model Size (Power Law)', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Mark some models\n",
    "models_params = {\n",
    "    'GPT-2': 1.5e9,\n",
    "    'GPT-3': 175e9,\n",
    "    'LLaMA-70B': 70e9,\n",
    "}\n",
    "for name, p in models_params.items():\n",
    "    loss = 10 * (p / 1e6) ** (-0.076)\n",
    "    ax1.plot(p, loss, 'ro', markersize=8)\n",
    "    ax1.annotate(name, (p, loss), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "# Right: Chinchilla optimal scaling\n",
    "ax2 = axes[1]\n",
    "compute = np.logspace(19, 25, 100)  # FLOPs\n",
    "params_optimal = (compute / 6) ** 0.5  # Simplified Chinchilla\n",
    "tokens_optimal = params_optimal * 20\n",
    "\n",
    "ax2.loglog(compute, params_optimal, 'b-', linewidth=2, label='Optimal Parameters')\n",
    "ax2.loglog(compute, tokens_optimal, 'g--', linewidth=2, label='Optimal Tokens')\n",
    "ax2.set_xlabel('Compute (FLOPs)', fontsize=12)\n",
    "ax2.set_ylabel('Scale', fontsize=12)\n",
    "ax2.set_title('Chinchilla Optimal Scaling', fontsize=14)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nChinchilla Recommendations for Given Compute:\")\n",
    "print(\"─\" * 60)\n",
    "for flops, name in [(1e21, '10^21 FLOPs'), (1e23, '10^23 FLOPs'), (1e25, '10^25 FLOPs')]:\n",
    "    opt_params = (flops / 6) ** 0.5\n",
    "    opt_tokens = opt_params * 20\n",
    "    print(f\"{name}: {opt_params/1e9:.1f}B params, {opt_tokens/1e12:.1f}T tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eb70a7",
   "metadata": {},
   "source": [
    "### Emergent Abilities\n",
    "\n",
    "Certain capabilities **emerge** only at sufficient scale:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                     Emergent Abilities                               │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                      │\n",
    "│  Performance                                                         │\n",
    "│       │                                          ●─────────●        │\n",
    "│       │                                      ●                       │\n",
    "│       │                                   ●                          │\n",
    "│       │                               ●                              │\n",
    "│       │  ●────●────●────●────●────●  ← Sharp transition              │\n",
    "│       │                                                              │\n",
    "│       └──────────────────────────────────────────────► Model Size   │\n",
    "│                              ↑                                       │\n",
    "│                        Threshold scale                               │\n",
    "│                                                                      │\n",
    "│  Examples of emergent abilities:                                     │\n",
    "│  • Chain-of-thought reasoning                                        │\n",
    "│  • Multi-step arithmetic                                             │\n",
    "│  • Word unscrambling                                                 │\n",
    "│  • Code execution prediction                                         │\n",
    "│  • Theory of mind tasks                                              │\n",
    "│                                                                      │\n",
    "│  Debate: Are these truly \"emergent\" or measurement artifacts?       │\n",
    "│                                                                      │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d719ca",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **LLMs are next-token predictors** trained on massive text corpora\n",
    "2. **Transformer architecture** with attention is the foundation\n",
    "3. **Multi-head attention** allows parallel learning of different patterns\n",
    "4. **Subword tokenization** (BPE) balances vocabulary and sequence length\n",
    "5. **Three training stages**: Pretraining → SFT → RLHF/DPO\n",
    "6. **Scaling laws** guide efficient compute allocation\n",
    "7. **Emergent abilities** appear at larger scales\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - Original Transformer paper\n",
    "- [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) - GPT-3 paper\n",
    "- [Training Compute-Optimal LLMs](https://arxiv.org/abs/2203.15556) - Chinchilla paper\n",
    "- [LLaMA: Open Foundation Models](https://arxiv.org/abs/2302.13971) - LLaMA paper\n",
    "- [Constitutional AI](https://arxiv.org/abs/2212.08073) - Anthropic's approach\n",
    "- [Direct Preference Optimization](https://arxiv.org/abs/2305.18290) - DPO paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cef52e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reference: Key hyperparameters for popular LLMs\n",
    "llm_configs = {\n",
    "    \"GPT-2\": {\n",
    "        \"params\": \"1.5B\",\n",
    "        \"layers\": 48,\n",
    "        \"d_model\": 1600,\n",
    "        \"heads\": 25,\n",
    "        \"context\": 1024,\n",
    "        \"vocab\": 50257,\n",
    "    },\n",
    "    \"GPT-3 (175B)\": {\n",
    "        \"params\": \"175B\",\n",
    "        \"layers\": 96,\n",
    "        \"d_model\": 12288,\n",
    "        \"heads\": 96,\n",
    "        \"context\": 2048,\n",
    "        \"vocab\": 50257,\n",
    "    },\n",
    "    \"LLaMA-7B\": {\n",
    "        \"params\": \"7B\",\n",
    "        \"layers\": 32,\n",
    "        \"d_model\": 4096,\n",
    "        \"heads\": 32,\n",
    "        \"context\": 2048,\n",
    "        \"vocab\": 32000,\n",
    "    },\n",
    "    \"LLaMA-70B\": {\n",
    "        \"params\": \"70B\",\n",
    "        \"layers\": 80,\n",
    "        \"d_model\": 8192,\n",
    "        \"heads\": 64,\n",
    "        \"context\": 4096,\n",
    "        \"vocab\": 32000,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"LLM Architecture Comparison\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Model':<18} {'Params':<10} {'Layers':<8} {'d_model':<10} {'Heads':<8} {'Context':<10} {'Vocab'}\")\n",
    "print(\"-\" * 80)\n",
    "for model, config in llm_configs.items():\n",
    "    print(f\"{model:<18} {config['params']:<10} {config['layers']:<8} {config['d_model']:<10} {config['heads']:<8} {config['context']:<10} {config['vocab']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
