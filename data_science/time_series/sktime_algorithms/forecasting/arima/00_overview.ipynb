{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA (AutoRegressive Integrated Moving Average)\n",
    "\n",
    "ARIMA models explain a time series using **autoregression**, **differencing**, and **moving average** components. This notebook covers the mathematical theory, low-level NumPy implementations, and practical usage with sktime.\n",
    "\n",
    "## ARIMA(p, d, q) Parameters\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| **p** | Number of autoregressive (AR) lags |\n",
    "| **d** | Number of differences to achieve stationarity |\n",
    "| **q** | Number of moving-average (MA) lags |\n",
    "\n",
    "---\n",
    "\n",
    "## Mathematical Foundation\n",
    "\n",
    "### 1. Autoregressive Process AR(p)\n",
    "\n",
    "An AR(p) process models the current value as a linear combination of its past values:\n",
    "\n",
    "$$y_t = c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\cdots + \\phi_p y_{t-p} + \\epsilon_t$$\n",
    "\n",
    "Or in summation notation:\n",
    "\n",
    "$$y_t = c + \\sum_{i=1}^{p} \\phi_i y_{t-i} + \\epsilon_t$$\n",
    "\n",
    "where:\n",
    "- $c$ is a constant (intercept)\n",
    "- $\\phi_i$ are the AR coefficients\n",
    "- $\\epsilon_t \\sim WN(0, \\sigma^2)$ is white noise\n",
    "\n",
    "**Characteristic Polynomial (Stationarity Condition):**\n",
    "\n",
    "$$\\Phi(z) = 1 - \\phi_1 z - \\phi_2 z^2 - \\cdots - \\phi_p z^p$$\n",
    "\n",
    "The process is **stationary** if all roots of $\\Phi(z) = 0$ lie outside the unit circle ($|z| > 1$).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Moving Average Process MA(q)\n",
    "\n",
    "An MA(q) process models the current value as a linear combination of current and past error terms:\n",
    "\n",
    "$$y_t = c + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + \\cdots + \\theta_q \\epsilon_{t-q}$$\n",
    "\n",
    "Or in summation notation:\n",
    "\n",
    "$$y_t = c + \\epsilon_t + \\sum_{j=1}^{q} \\theta_j \\epsilon_{t-j}$$\n",
    "\n",
    "where:\n",
    "- $\\theta_j$ are the MA coefficients\n",
    "- $\\epsilon_t \\sim WN(0, \\sigma^2)$\n",
    "\n",
    "**Characteristic Polynomial (Invertibility Condition):**\n",
    "\n",
    "$$\\Theta(z) = 1 + \\theta_1 z + \\theta_2 z^2 + \\cdots + \\theta_q z^q$$\n",
    "\n",
    "The process is **invertible** if all roots of $\\Theta(z) = 0$ lie outside the unit circle.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. ARMA(p, q) Process\n",
    "\n",
    "Combining AR and MA components:\n",
    "\n",
    "$$y_t = c + \\sum_{i=1}^{p} \\phi_i y_{t-i} + \\epsilon_t + \\sum_{j=1}^{q} \\theta_j \\epsilon_{t-j}$$\n",
    "\n",
    "Using the **backshift operator** $B$ where $B^k y_t = y_{t-k}$:\n",
    "\n",
    "$$\\Phi(B) y_t = c + \\Theta(B) \\epsilon_t$$\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Differencing for ARIMA\n",
    "\n",
    "Non-stationary series can often be made stationary through differencing:\n",
    "\n",
    "**First Difference:**\n",
    "$$\\nabla y_t = y_t - y_{t-1} = (1 - B) y_t$$\n",
    "\n",
    "**d-th Order Difference:**\n",
    "$$\\nabla^d y_t = (1 - B)^d y_t$$\n",
    "\n",
    "For $d = 2$:\n",
    "$$\\nabla^2 y_t = \\nabla(\\nabla y_t) = y_t - 2y_{t-1} + y_{t-2}$$\n",
    "\n",
    "The **ARIMA(p, d, q)** model applies ARMA(p, q) to the differenced series:\n",
    "\n",
    "$$\\Phi(B)(1 - B)^d y_t = c + \\Theta(B) \\epsilon_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2541c93",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Low-Level NumPy Implementation\n",
    "\n",
    "Let's build ARIMA from scratch to understand each component deeply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sktime.datasets import load_airline\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load data\n",
    "y = load_airline()\n",
    "y.name = \"Passengers\"\n",
    "\n",
    "# Convert to numpy for our implementations\n",
    "y_values = y.values.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed9cdb8",
   "metadata": {},
   "source": [
    "### Differencing Functions\n",
    "\n",
    "The differencing operator transforms a non-stationary series into a stationary one. We implement both forward differencing and its inverse for reconstructing forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf1f8a2",
   "metadata": {},
   "source": [
    "### AR Model Fitting via Ordinary Least Squares\n",
    "\n",
    "For an AR(p) model, we can estimate coefficients using **least squares regression**:\n",
    "\n",
    "$$y_t = \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\cdots + \\phi_p y_{t-p} + \\epsilon_t$$\n",
    "\n",
    "In matrix form: $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\phi} + \\boldsymbol{\\epsilon}$\n",
    "\n",
    "The OLS solution is:\n",
    "\n",
    "$$\\hat{\\boldsymbol{\\phi}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$\n",
    "\n",
    "where $\\mathbf{X}$ is the design matrix of lagged values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439ad74b",
   "metadata": {},
   "source": [
    "### Stationarity Check via Characteristic Polynomial\n",
    "\n",
    "An AR(p) process is stationary if all roots of the characteristic polynomial lie **outside** the unit circle.\n",
    "\n",
    "$$\\Phi(z) = 1 - \\phi_1 z - \\phi_2 z^2 - \\cdots - \\phi_p z^p = 0$$\n",
    "\n",
    "We check this condition for our fitted model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c3832c",
   "metadata": {},
   "source": [
    "### AR Prediction (Multi-Step Forecasting)\n",
    "\n",
    "For multi-step forecasting, we recursively apply the AR model:\n",
    "\n",
    "$$\\hat{y}_{t+h} = c + \\phi_1 \\hat{y}_{t+h-1} + \\phi_2 \\hat{y}_{t+h-2} + \\cdots + \\phi_p \\hat{y}_{t+h-p}$$\n",
    "\n",
    "Note: For $h > 1$, we use previously forecasted values $\\hat{y}$ when actual values aren't available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c25f7f7",
   "metadata": {},
   "source": [
    "### Complete ARIMA Forecast Function\n",
    "\n",
    "Putting it all together: difference → fit AR → forecast → inverse difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c4e6d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Visualizations with Plotly\n",
    "\n",
    "### ACF and PACF for Order Selection\n",
    "\n",
    "**ACF (Autocorrelation Function)** shows correlation of series with its lagged values.  \n",
    "**PACF (Partial Autocorrelation Function)** shows direct correlation after removing intermediate effects.\n",
    "\n",
    "| Pattern | Suggests |\n",
    "|---------|----------|\n",
    "| ACF tails off, PACF cuts off at lag p | AR(p) |\n",
    "| ACF cuts off at lag q, PACF tails off | MA(q) |\n",
    "| Both tail off | ARMA(p, q) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e83178",
   "metadata": {},
   "source": [
    "### Fitted Values vs Actual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992584cc",
   "metadata": {},
   "source": [
    "### Residual Diagnostics (Plotly)\n",
    "\n",
    "A well-specified ARIMA model should produce residuals that are:\n",
    "1. **Uncorrelated** (white noise) - check via ACF of residuals\n",
    "2. **Normally distributed** - check via histogram/Q-Q plot\n",
    "3. **Homoscedastic** - check via residual plot over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b35bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals\n",
    "residuals = y_values[fitted_start_idx:fitted_start_idx + len(fitted_original)] - fitted_original\n",
    "standardized_resid = (residuals - np.mean(residuals)) / np.std(residuals)\n",
    "\n",
    "# Compute ACF of residuals\n",
    "resid_acf = compute_acf(residuals, max_lag=20)\n",
    "\n",
    "# Create diagnostic plots\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=(\n",
    "        \"Residuals Over Time\",\n",
    "        \"Histogram of Residuals\",\n",
    "        \"ACF of Residuals\",\n",
    "        \"Q-Q Plot\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 1. Residuals over time\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(len(residuals)),\n",
    "        y=residuals,\n",
    "        mode=\"lines+markers\",\n",
    "        marker=dict(size=4),\n",
    "        line=dict(color=\"steelblue\"),\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"red\", row=1, col=1)\n",
    "\n",
    "# 2. Histogram\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=residuals,\n",
    "        nbinsx=25,\n",
    "        marker_color=\"steelblue\",\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. ACF of residuals\n",
    "conf_bound = 1.96 / np.sqrt(len(residuals))\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=np.arange(len(resid_acf)),\n",
    "        y=resid_acf,\n",
    "        marker_color=\"darkorange\",\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "fig.add_hline(y=conf_bound, line_dash=\"dash\", line_color=\"red\", row=2, col=1)\n",
    "fig.add_hline(y=-conf_bound, line_dash=\"dash\", line_color=\"red\", row=2, col=1)\n",
    "\n",
    "# 4. Q-Q plot (approximate)\n",
    "sorted_resid = np.sort(standardized_resid)\n",
    "n = len(sorted_resid)\n",
    "theoretical_quantiles = np.array([np.percentile(np.random.randn(10000), 100 * (i + 0.5) / n) \n",
    "                                  for i in range(n)])\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=theoretical_quantiles,\n",
    "        y=sorted_resid,\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=\"steelblue\", size=5),\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "# Add reference line\n",
    "qq_min, qq_max = theoretical_quantiles.min(), theoretical_quantiles.max()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[qq_min, qq_max],\n",
    "        y=[qq_min, qq_max],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"red\", dash=\"dash\"),\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"ARIMA(2,1,0) Residual Diagnostics\",\n",
    "    height=600,\n",
    "    showlegend=False\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Time\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Residual\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Residual Value\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Lag\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"ACF\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Theoretical Quantiles\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"Sample Quantiles\", row=2, col=2)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Ljung-Box test statistic (simplified)\n",
    "def ljung_box_stat(residuals: np.ndarray, max_lag: int) -> float:\n",
    "    \"\"\"Compute Ljung-Box Q statistic for autocorrelation test.\"\"\"\n",
    "    n = len(residuals)\n",
    "    acf = compute_acf(residuals, max_lag)\n",
    "    Q = n * (n + 2) * np.sum([acf[k]**2 / (n - k) for k in range(1, max_lag + 1)])\n",
    "    return Q\n",
    "\n",
    "Q_stat = ljung_box_stat(residuals, 10)\n",
    "print(f\"\\nLjung-Box Q statistic (lag 10): {Q_stat:.2f}\")\n",
    "print(\"Large Q values suggest residual autocorrelation (model misspecification)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca75ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute fitted values on original scale using our NumPy implementation\n",
    "y_diff = difference(y_values, d=1)\n",
    "phi, c, _ = fit_ar_ols(y_diff, p=2)\n",
    "fitted_diff = ar_fitted_values(y_diff, phi, c)\n",
    "\n",
    "# Convert fitted values back to original scale\n",
    "# For d=1: y_t = y_{t-1} + diff_t\n",
    "# Fitted values start at index p=2 in differenced series\n",
    "# Which corresponds to index p+d=3 in original series\n",
    "fitted_original = y_values[2:-1] + fitted_diff  # Add previous actual to get fitted\n",
    "\n",
    "# Create time index (use original index if available)\n",
    "time_index = np.arange(len(y_values))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Actual series\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=time_index,\n",
    "    y=y_values,\n",
    "    name=\"Actual\",\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"steelblue\", width=2)\n",
    "))\n",
    "\n",
    "# Fitted values (starts from index 3 due to d=1 and p=2)\n",
    "fitted_start_idx = 3\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=time_index[fitted_start_idx:fitted_start_idx + len(fitted_original)],\n",
    "    y=fitted_original,\n",
    "    name=\"Fitted (NumPy)\",\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"crimson\", width=2, dash=\"dash\")\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"ARIMA(2,1,0) Fitted Values vs Actual - NumPy Implementation\",\n",
    "    xaxis_title=\"Time Index\",\n",
    "    yaxis_title=\"Passengers\",\n",
    "    legend=dict(x=0.02, y=0.98),\n",
    "    height=450\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Calculate in-sample metrics\n",
    "mse = np.mean((y_values[fitted_start_idx:fitted_start_idx + len(fitted_original)] - fitted_original) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = np.mean(np.abs(y_values[fitted_start_idx:fitted_start_idx + len(fitted_original)] - fitted_original))\n",
    "print(f\"In-sample metrics (NumPy implementation):\")\n",
    "print(f\"  RMSE: {rmse:.2f}\")\n",
    "print(f\"  MAE:  {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1279ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acf(y: np.ndarray, max_lag: int) -> np.ndarray:\n",
    "    \"\"\"Compute autocorrelation function up to max_lag.\"\"\"\n",
    "    n = len(y)\n",
    "    y_centered = y - np.mean(y)\n",
    "    var = np.var(y)\n",
    "    \n",
    "    acf_values = np.zeros(max_lag + 1)\n",
    "    for k in range(max_lag + 1):\n",
    "        if k == 0:\n",
    "            acf_values[k] = 1.0\n",
    "        else:\n",
    "            acf_values[k] = np.sum(y_centered[k:] * y_centered[:-k]) / (n * var)\n",
    "    return acf_values\n",
    "\n",
    "\n",
    "def compute_pacf(y: np.ndarray, max_lag: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute partial autocorrelation using Durbin-Levinson recursion.\n",
    "    PACF(k) is the correlation between y_t and y_{t-k} after removing \n",
    "    the effect of intermediate lags.\n",
    "    \"\"\"\n",
    "    acf = compute_acf(y, max_lag)\n",
    "    pacf_values = np.zeros(max_lag + 1)\n",
    "    pacf_values[0] = 1.0\n",
    "    \n",
    "    if max_lag == 0:\n",
    "        return pacf_values\n",
    "    \n",
    "    # Durbin-Levinson algorithm\n",
    "    phi = np.zeros((max_lag + 1, max_lag + 1))\n",
    "    phi[1, 1] = acf[1]\n",
    "    pacf_values[1] = acf[1]\n",
    "    \n",
    "    for k in range(2, max_lag + 1):\n",
    "        # Compute phi[k,k]\n",
    "        num = acf[k] - np.sum(phi[k-1, 1:k] * acf[k-1:0:-1])\n",
    "        den = 1 - np.sum(phi[k-1, 1:k] * acf[1:k])\n",
    "        \n",
    "        if abs(den) < 1e-10:\n",
    "            phi[k, k] = 0\n",
    "        else:\n",
    "            phi[k, k] = num / den\n",
    "        \n",
    "        # Update other coefficients\n",
    "        for j in range(1, k):\n",
    "            phi[k, j] = phi[k-1, j] - phi[k, k] * phi[k-1, k-j]\n",
    "        \n",
    "        pacf_values[k] = phi[k, k]\n",
    "    \n",
    "    return pacf_values\n",
    "\n",
    "\n",
    "# Compute ACF/PACF for the differenced series\n",
    "y_diff = difference(y_values, d=1)\n",
    "max_lag = 24\n",
    "acf_vals = compute_acf(y_diff, max_lag)\n",
    "pacf_vals = compute_pacf(y_diff, max_lag)\n",
    "\n",
    "# Confidence bounds (approximate 95% CI)\n",
    "n = len(y_diff)\n",
    "conf_bound = 1.96 / np.sqrt(n)\n",
    "\n",
    "# Create ACF/PACF plots with Plotly\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"ACF (Autocorrelation)\", \"PACF (Partial Autocorrelation)\"))\n",
    "\n",
    "lags = np.arange(max_lag + 1)\n",
    "\n",
    "# ACF plot\n",
    "fig.add_trace(\n",
    "    go.Bar(x=lags, y=acf_vals, name=\"ACF\", marker_color=\"steelblue\", showlegend=False),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_hline(y=conf_bound, line_dash=\"dash\", line_color=\"red\", row=1, col=1)\n",
    "fig.add_hline(y=-conf_bound, line_dash=\"dash\", line_color=\"red\", row=1, col=1)\n",
    "fig.add_hline(y=0, line_color=\"black\", row=1, col=1)\n",
    "\n",
    "# PACF plot\n",
    "fig.add_trace(\n",
    "    go.Bar(x=lags, y=pacf_vals, name=\"PACF\", marker_color=\"darkorange\", showlegend=False),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.add_hline(y=conf_bound, line_dash=\"dash\", line_color=\"red\", row=1, col=2)\n",
    "fig.add_hline(y=-conf_bound, line_dash=\"dash\", line_color=\"red\", row=1, col=2)\n",
    "fig.add_hline(y=0, line_color=\"black\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"ACF and PACF of Differenced Airline Series\",\n",
    "    height=400,\n",
    "    showlegend=False\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Lag\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Lag\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Correlation\", row=1, col=1)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(\"- Significant spikes at lags 12, 24 suggest seasonal pattern (monthly data)\")\n",
    "print(\"- PACF cuts off suggesting AR component\")\n",
    "print(\"- Red dashed lines = 95% confidence bounds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af34ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_forecast(y: np.ndarray, p: int, d: int, q: int, h: int) -> dict:\n",
    "    \"\"\"\n",
    "    Full ARIMA(p, d, q) forecasting pipeline.\n",
    "    \n",
    "    Note: This simplified implementation only handles the AR component (q=0).\n",
    "    For full MA estimation, iterative methods like MLE are typically used.\n",
    "    \n",
    "    Pipeline:\n",
    "    1. Apply d-order differencing\n",
    "    2. Fit AR(p) model via OLS\n",
    "    3. Generate h-step forecasts on differenced series\n",
    "    4. Inverse difference to get forecasts on original scale\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.ndarray\n",
    "        Original time series\n",
    "    p : int\n",
    "        AR order\n",
    "    d : int\n",
    "        Differencing order\n",
    "    q : int\n",
    "        MA order (not implemented, must be 0)\n",
    "    h : int\n",
    "        Forecast horizon\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys:\n",
    "        'forecast': h-step ahead forecasts in original scale\n",
    "        'forecast_diff': forecasts on differenced scale\n",
    "        'phi': AR coefficients\n",
    "        'c': intercept\n",
    "        'sigma2': noise variance\n",
    "        'roots': characteristic polynomial roots\n",
    "        'is_stationary': stationarity indicator\n",
    "    \"\"\"\n",
    "    if q != 0:\n",
    "        print(\"Warning: MA component not implemented. Using AR(p) only.\")\n",
    "    \n",
    "    # Step 1: Difference the series\n",
    "    y_diff = difference(y, d) if d > 0 else y.copy()\n",
    "    \n",
    "    # Step 2: Fit AR(p) model\n",
    "    phi, c, sigma2 = fit_ar_ols(y_diff, p)\n",
    "    \n",
    "    # Step 3: Check stationarity\n",
    "    roots, is_stationary = check_stationarity(phi)\n",
    "    \n",
    "    # Step 4: Forecast on differenced scale\n",
    "    forecast_diff = ar_predict(y_diff, phi, c, h)\n",
    "    \n",
    "    # Step 5: Inverse difference to original scale\n",
    "    if d > 0:\n",
    "        forecast = inverse_difference(forecast_diff, y, d)\n",
    "    else:\n",
    "        forecast = forecast_diff\n",
    "    \n",
    "    return {\n",
    "        'forecast': forecast,\n",
    "        'forecast_diff': forecast_diff,\n",
    "        'phi': phi,\n",
    "        'c': c,\n",
    "        'sigma2': sigma2,\n",
    "        'roots': roots,\n",
    "        'is_stationary': is_stationary\n",
    "    }\n",
    "\n",
    "\n",
    "# Apply our ARIMA implementation\n",
    "result = arima_forecast(y_values, p=2, d=1, q=0, h=24)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"ARIMA(2, 1, 0) Results - NumPy Implementation\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nModel Parameters:\")\n",
    "print(f\"  c (intercept):  {result['c']:.4f}\")\n",
    "print(f\"  φ₁:             {result['phi'][0]:.4f}\")\n",
    "print(f\"  φ₂:             {result['phi'][1]:.4f}\")\n",
    "print(f\"  σ²:             {result['sigma2']:.4f}\")\n",
    "print(f\"\\nStationarity: {'✓ Yes' if result['is_stationary'] else '✗ No'}\")\n",
    "print(f\"\\nForecasts (first 6 of {len(result['forecast'])}):\")\n",
    "for i, f in enumerate(result['forecast'][:6]):\n",
    "    print(f\"  t+{i+1}: {f:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c602a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ar_predict(y: np.ndarray, phi: np.ndarray, c: float, h: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate h-step ahead forecasts using AR model.\n",
    "    \n",
    "    Recursive forecasting:\n",
    "    ŷ_{t+h} = c + φ₁ŷ_{t+h-1} + φ₂ŷ_{t+h-2} + ... + φₚŷ_{t+h-p}\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.ndarray\n",
    "        Historical time series (at least p observations)\n",
    "    phi : np.ndarray\n",
    "        AR coefficients [φ₁, φ₂, ..., φₚ]\n",
    "    c : float\n",
    "        Intercept term\n",
    "    h : int\n",
    "        Forecast horizon\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    forecast : np.ndarray\n",
    "        h-step ahead forecasts\n",
    "    \"\"\"\n",
    "    p = len(phi)\n",
    "    \n",
    "    # Initialize with last p observations\n",
    "    history = list(y[-p:])\n",
    "    forecasts = []\n",
    "    \n",
    "    for _ in range(h):\n",
    "        # y_hat = c + φ₁*y_{t-1} + φ₂*y_{t-2} + ...\n",
    "        y_hat = c + np.dot(phi, history[-p:][::-1])\n",
    "        forecasts.append(y_hat)\n",
    "        history.append(y_hat)\n",
    "    \n",
    "    return np.array(forecasts)\n",
    "\n",
    "\n",
    "def ar_fitted_values(y: np.ndarray, phi: np.ndarray, c: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute in-sample fitted values for AR model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.ndarray\n",
    "        Time series data\n",
    "    phi : np.ndarray\n",
    "        AR coefficients\n",
    "    c : float\n",
    "        Intercept\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    fitted : np.ndarray\n",
    "        Fitted values (length = len(y) - p)\n",
    "    \"\"\"\n",
    "    p = len(phi)\n",
    "    n = len(y)\n",
    "    fitted = np.zeros(n - p)\n",
    "    \n",
    "    for t in range(p, n):\n",
    "        # Get lagged values [y_{t-1}, y_{t-2}, ..., y_{t-p}]\n",
    "        lagged = y[t-p:t][::-1]\n",
    "        fitted[t - p] = c + np.dot(phi, lagged)\n",
    "    \n",
    "    return fitted\n",
    "\n",
    "\n",
    "# Generate forecasts on differenced series\n",
    "h = 24  # Forecast horizon\n",
    "forecast_diff = ar_predict(y_diff, phi, c, h)\n",
    "print(f\"AR(2) forecasts on differenced series (next {h} periods):\")\n",
    "print(f\"  First 5: {forecast_diff[:5].round(2)}\")\n",
    "\n",
    "# Compute fitted values\n",
    "fitted_diff = ar_fitted_values(y_diff, phi, c)\n",
    "print(f\"\\nIn-sample fitted values: {len(fitted_diff)} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be70c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stationarity(phi: np.ndarray) -> tuple[np.ndarray, bool]:\n",
    "    \"\"\"\n",
    "    Check if AR process is stationary by examining characteristic polynomial roots.\n",
    "    \n",
    "    Characteristic polynomial: Φ(z) = 1 - φ₁z - φ₂z² - ... - φₚzᵖ\n",
    "    Process is stationary if all roots have |z| > 1\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    phi : np.ndarray\n",
    "        AR coefficients [φ₁, φ₂, ..., φₚ]\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    roots : np.ndarray\n",
    "        Roots of the characteristic polynomial\n",
    "    is_stationary : bool\n",
    "        True if all roots lie outside unit circle\n",
    "    \"\"\"\n",
    "    # Polynomial coefficients: [1, -φ₁, -φ₂, ..., -φₚ]\n",
    "    # np.roots expects highest degree first, so we reverse\n",
    "    poly_coeffs = np.concatenate([[1], -phi])[::-1]\n",
    "    roots = np.roots(poly_coeffs)\n",
    "    \n",
    "    is_stationary = np.all(np.abs(roots) > 1)\n",
    "    \n",
    "    return roots, is_stationary\n",
    "\n",
    "\n",
    "# Check stationarity of our fitted AR(2) model\n",
    "roots, is_stationary = check_stationarity(phi)\n",
    "\n",
    "print(\"Characteristic Polynomial Analysis:\")\n",
    "print(f\"  Φ(z) = 1 - ({phi[0]:.4f})z - ({phi[1]:.4f})z²\")\n",
    "print(f\"\\nRoots of Φ(z) = 0:\")\n",
    "for i, root in enumerate(roots):\n",
    "    print(f\"  z_{i+1} = {root:.4f}, |z_{i+1}| = {np.abs(root):.4f}\")\n",
    "print(f\"\\nStationarity: {'✓ STATIONARY' if is_stationary else '✗ NON-STATIONARY'}\")\n",
    "print(\"  (All roots must have |z| > 1 for stationarity)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ef6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ar_ols(y: np.ndarray, p: int) -> tuple[np.ndarray, float, float]:\n",
    "    \"\"\"\n",
    "    Fit an AR(p) model using Ordinary Least Squares.\n",
    "    \n",
    "    Model: y_t = c + φ₁y_{t-1} + φ₂y_{t-2} + ... + φₚy_{t-p} + ε_t\n",
    "    \n",
    "    OLS solution: φ̂ = (X'X)⁻¹X'y\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.ndarray\n",
    "        Time series data\n",
    "    p : int\n",
    "        AR order (number of lags)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    phi : np.ndarray\n",
    "        AR coefficients [φ₁, φ₂, ..., φₚ]\n",
    "    c : float\n",
    "        Intercept term\n",
    "    sigma2 : float\n",
    "        Estimated noise variance\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    \n",
    "    # Build design matrix X with lagged values\n",
    "    # Each row: [1, y_{t-1}, y_{t-2}, ..., y_{t-p}]\n",
    "    X = np.zeros((n - p, p + 1))\n",
    "    X[:, 0] = 1  # Intercept column\n",
    "    \n",
    "    for i in range(p):\n",
    "        X[:, i + 1] = y[p - 1 - i:n - 1 - i]\n",
    "    \n",
    "    # Target vector: [y_p, y_{p+1}, ..., y_{n-1}]\n",
    "    y_target = y[p:]\n",
    "    \n",
    "    # OLS solution: β̂ = (X'X)⁻¹X'y\n",
    "    XtX = X.T @ X\n",
    "    Xty = X.T @ y_target\n",
    "    beta = np.linalg.solve(XtX, Xty)  # More stable than inv(X'X) @ X'y\n",
    "    \n",
    "    c = beta[0]        # Intercept\n",
    "    phi = beta[1:]     # AR coefficients\n",
    "    \n",
    "    # Estimate residual variance\n",
    "    y_fitted = X @ beta\n",
    "    residuals = y_target - y_fitted\n",
    "    sigma2 = np.var(residuals, ddof=p + 1)  # Adjust for estimated parameters\n",
    "    \n",
    "    return phi, c, sigma2\n",
    "\n",
    "\n",
    "# Fit AR(2) model on differenced airline data\n",
    "y_diff = difference(y_values, d=1)\n",
    "phi, c, sigma2 = fit_ar_ols(y_diff, p=2)\n",
    "\n",
    "print(\"AR(2) Model on Differenced Series:\")\n",
    "print(f\"  Intercept (c):    {c:.4f}\")\n",
    "print(f\"  AR coefficients:  φ₁ = {phi[0]:.4f}, φ₂ = {phi[1]:.4f}\")\n",
    "print(f\"  Noise variance:   σ² = {sigma2:.4f}\")\n",
    "print(f\"\\nModel equation:\")\n",
    "print(f\"  ∇y_t = {c:.3f} + {phi[0]:.3f}·∇y_{{t-1}} + {phi[1]:.3f}·∇y_{{t-2}} + ε_t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20616282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(y: np.ndarray, d: int = 1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply d-th order differencing to a time series.\n",
    "    \n",
    "    Mathematical definition:\n",
    "    ∇¹y_t = y_t - y_{t-1}\n",
    "    ∇ᵈy_t = (1 - B)^d y_t\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.ndarray\n",
    "        Original time series\n",
    "    d : int\n",
    "        Order of differencing\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Differenced series (length = len(y) - d)\n",
    "    \"\"\"\n",
    "    y_diff = y.copy()\n",
    "    for _ in range(d):\n",
    "        y_diff = np.diff(y_diff)\n",
    "    return y_diff\n",
    "\n",
    "\n",
    "def inverse_difference(y_diff: np.ndarray, y_orig: np.ndarray, d: int = 1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reverse differencing to reconstruct the original scale.\n",
    "    \n",
    "    For d=1: y_t = y_{t-1} + ∇y_t\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_diff : np.ndarray\n",
    "        Differenced forecast values\n",
    "    y_orig : np.ndarray\n",
    "        Original series (need last d values as anchors)\n",
    "    d : int\n",
    "        Order of differencing used\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Reconstructed series in original scale\n",
    "    \"\"\"\n",
    "    y_reconstructed = y_diff.copy()\n",
    "    \n",
    "    for i in range(d):\n",
    "        # Use the last value from the original series at each differencing level\n",
    "        anchor = y_orig[-(d - i)]\n",
    "        y_reconstructed = np.cumsum(np.concatenate([[anchor], y_reconstructed]))[1:]\n",
    "        # Actually we need to add from the anchor\n",
    "        y_reconstructed = anchor + np.cumsum(y_diff if i == 0 else y_reconstructed)\n",
    "        \n",
    "    # Simpler approach for d=1 case (most common):\n",
    "    if d == 1:\n",
    "        anchor = y_orig[-1]\n",
    "        return anchor + np.cumsum(y_diff)\n",
    "    \n",
    "    return y_reconstructed\n",
    "\n",
    "\n",
    "# Demonstrate differencing\n",
    "print(\"Original series (first 10):\", y_values[:10])\n",
    "y_diff1 = difference(y_values, d=1)\n",
    "print(\"First difference (first 10):\", y_diff1[:10])\n",
    "y_diff2 = difference(y_values, d=2)\n",
    "print(\"Second difference (first 10):\", y_diff2[:10])\n",
    "\n",
    "# Verify inverse differencing\n",
    "y_forecast_diff = np.array([5, 10, 15])  # Example differenced forecast\n",
    "y_reconstructed = inverse_difference(y_forecast_diff, y_values, d=1)\n",
    "print(f\"\\nInverse differencing demo:\")\n",
    "print(f\"Last original value: {y_values[-1]}\")\n",
    "print(f\"Differenced forecast: {y_forecast_diff}\")\n",
    "print(f\"Reconstructed: {y_reconstructed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Practical Application with sktime\n",
    "\n",
    "Now that we understand the theory and NumPy implementation, let's use the production-ready sktime library.\n",
    "\n",
    "### Make the series more stationary (log + difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = np.log(y)\n",
    "y_diff = y_log.diff().dropna()\n",
    "\n",
    "fig = px.line(y_diff, title=\"Log-differenced series\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACF/PACF to guide p and q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "plot_acf(y_diff, ax=axes[0], lags=36)\n",
    "plot_pacf(y_diff, ax=axes[1], lags=36, method=\"ywm\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model with sktime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_selection import temporal_train_test_split, ForecastingHorizon\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_error\n",
    "from sktime.forecasting.arima import ARIMA\n",
    "model = ARIMA(order=(1,1,1))\n",
    "\n",
    "\n",
    "y_train, y_test = temporal_train_test_split(y, test_size=24)\n",
    "fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
    "\n",
    "model.fit(y_train)\n",
    "pred = model.predict(fh)\n",
    "\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=y_train.index.to_timestamp(), y=y_train, name=\"Train\"))\n",
    "fig.add_trace(go.Scatter(x=y_test.index.to_timestamp(), y=y_test, name=\"Test\"))\n",
    "fig.add_trace(go.Scatter(x=pred.index.to_timestamp(), y=pred, name=\"Forecast\"))\n",
    "fig.update_layout(title=\"ARIMA forecast vs actual\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics\n",
    "\n",
    "Check residuals for autocorrelation and non‑normality. A well‑specified ARIMA model leaves **white noise** residuals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = y_test - pred\n",
    "fig = px.histogram(resid, nbins=30, title=\"Residual distribution\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efcf26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate forecasts using our NumPy implementation on the same train/test split\n",
    "y_train_np = y_values[:len(y_train)]\n",
    "y_test_np = y_values[len(y_train):]\n",
    "\n",
    "# Our ARIMA(2,1,0) forecast\n",
    "numpy_result = arima_forecast(y_train_np, p=2, d=1, q=0, h=len(y_test))\n",
    "numpy_forecast = numpy_result['forecast']\n",
    "\n",
    "# Compare with sktime forecast\n",
    "fig = go.Figure()\n",
    "\n",
    "# Training data\n",
    "train_dates = y_train.index.to_timestamp() if hasattr(y_train.index, 'to_timestamp') else np.arange(len(y_train))\n",
    "test_dates = y_test.index.to_timestamp() if hasattr(y_test.index, 'to_timestamp') else np.arange(len(y_train), len(y_train) + len(y_test))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=train_dates,\n",
    "    y=y_train.values,\n",
    "    name=\"Training Data\",\n",
    "    line=dict(color=\"steelblue\", width=2)\n",
    "))\n",
    "\n",
    "# Actual test data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_dates,\n",
    "    y=y_test.values,\n",
    "    name=\"Actual (Test)\",\n",
    "    line=dict(color=\"gray\", width=2)\n",
    "))\n",
    "\n",
    "# sktime forecast\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_dates,\n",
    "    y=pred.values,\n",
    "    name=\"sktime ARIMA(1,1,1)\",\n",
    "    line=dict(color=\"crimson\", width=2, dash=\"dash\")\n",
    "))\n",
    "\n",
    "# NumPy forecast\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_dates,\n",
    "    y=numpy_forecast,\n",
    "    name=\"NumPy ARIMA(2,1,0)\",\n",
    "    line=dict(color=\"green\", width=2, dash=\"dot\")\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Forecast Comparison: NumPy Implementation vs sktime\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Passengers\",\n",
    "    legend=dict(x=0.02, y=0.98),\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Compare MAE\n",
    "numpy_mae = np.mean(np.abs(y_test_np - numpy_forecast))\n",
    "sktime_mae = mean_absolute_error(y_test, pred)\n",
    "\n",
    "print(\"Forecast Comparison:\")\n",
    "print(f\"  sktime ARIMA(1,1,1) MAE:  {sktime_mae:.2f}\")\n",
    "print(f\"  NumPy ARIMA(2,1,0) MAE:   {numpy_mae:.2f}\")\n",
    "print(\"\\nNote: sktime uses MLE fitting and includes MA component,\")\n",
    "print(\"      while our NumPy version uses OLS with AR only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede9e902",
   "metadata": {},
   "source": [
    "### NumPy vs sktime Comparison\n",
    "\n",
    "Let's compare our from-scratch implementation with sktime's optimized ARIMA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary & When to Use ARIMA\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "| Component | Formula | Purpose |\n",
    "|-----------|---------|---------|\n",
    "| **AR(p)** | $y_t = c + \\sum_{i=1}^p \\phi_i y_{t-i} + \\epsilon_t$ | Capture autocorrelation |\n",
    "| **I(d)** | $\\nabla^d y_t = (1-B)^d y_t$ | Achieve stationarity |\n",
    "| **MA(q)** | $y_t = c + \\epsilon_t + \\sum_{j=1}^q \\theta_j \\epsilon_{t-j}$ | Model shock persistence |\n",
    "\n",
    "### When to Use ARIMA\n",
    "\n",
    "✅ **Good for:**\n",
    "- Univariate time series forecasting\n",
    "- Series with trend (use differencing)\n",
    "- Moderately seasonal series (consider SARIMA)\n",
    "- When interpretability is important\n",
    "\n",
    "⚠️ **Limitations:**\n",
    "- Requires stationarity (must difference)\n",
    "- Linear relationships only\n",
    "- Univariate (no external regressors without ARIMAX)\n",
    "- Manual order selection can be tricky\n",
    "\n",
    "### Order Selection Tips\n",
    "\n",
    "1. **Visual inspection**: Plot ACF/PACF of differenced series\n",
    "2. **Automated**: Use `auto_arima` or information criteria (AIC, BIC)\n",
    "3. **Validation**: Always check residual diagnostics\n",
    "4. **Parsimony**: Prefer simpler models when performance is similar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}