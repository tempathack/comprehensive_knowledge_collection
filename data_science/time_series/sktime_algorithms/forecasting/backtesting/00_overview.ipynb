{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Backtesting & Evaluation\n\nForecasting models should be evaluated **across time**, not on a single split.\nBacktesting simulates rolling-origin forecasts to estimate real-world performance.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Windowing strategies\n\n- **Expanding window**: train grows over time.\n- **Sliding window**: train size fixed, window moves.\n\nLet $w$ be window length, $s$ step size, and $h$ forecast horizon.\nTraining windows cover $[t-w+1, t]$, with forecasts at $t+1,\\dots,t+h$.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np",
    "import plotly.graph_objects as go",
    "",
    "np.random.seed(33)",
    "",
    "# Synthetic series",
    "n = 100",
    "t = np.arange(n)",
    "y = 5 + 0.03 * t + np.sin(2 * np.pi * t / 20) + np.random.normal(0, 0.4, n)",
    "",
    "w = 40",
    "h = 8",
    "step = 10",
    "origins = list(range(w - 1, n - h, step))",
    "",
    "fig = go.Figure()",
    "fig.add_trace(go.Scatter(x=t, y=y, mode=\"lines\", name=\"Series\", line=dict(color=\"#2a3f5f\")))",
    "",
    "for i, origin in enumerate(origins):",
    "    train_start = origin - w + 1",
    "    train_end = origin",
    "    test_start = origin + 1",
    "    test_end = origin + h",
    "",
    "    fig.add_vrect(",
    "        x0=train_start,",
    "        x1=train_end,",
    "        fillcolor=\"rgba(99,110,250,0.15)\",",
    "        line_width=0,",
    "    )",
    "    fig.add_vrect(",
    "        x0=test_start,",
    "        x1=test_end,",
    "        fillcolor=\"rgba(239,85,59,0.15)\",",
    "        line_width=0,",
    "    )",
    "",
    "fig.update_layout(",
    "    title=\"Backtesting windows (blue=train, orange=test)\",",
    "    height=420,",
    ")",
    "fig",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Metrics (quick intuition)\n\nCommon time-series metrics include:\n- **MAE**: average absolute error\n- **sMAPE**: symmetric percentage error\n- **MASE**: scaled by a seasonal naive benchmark\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\n\n# Naive 1-step forecast for illustration\nerrors = []\ny_true_all = []\ny_pred_all = []\n\nfor origin in origins:\n    y_train = y[:origin + 1]\n    y_test = y[origin + 1: origin + 1 + h]\n    y_pred = np.repeat(y_train[-1], h)\n    errors.append(y_test - y_pred)\n    y_true_all.append(y_test)\n    y_pred_all.append(y_pred)\n\nerrors = np.concatenate(errors)\ny_true_all = np.concatenate(y_true_all)\ny_pred_all = np.concatenate(y_pred_all)\n\nmae = np.mean(np.abs(errors))\nsmape = np.mean(2 * np.abs(y_pred_all - y_true_all) / (np.abs(y_true_all) + np.abs(y_pred_all)))\n\n# MASE with seasonal period 12 (fallback if short)\nseasonal_period = 12\nif len(y) > seasonal_period:\n    naive_diff = np.abs(y[seasonal_period:] - y[:-seasonal_period]).mean()\n    mase = mae / naive_diff\nelse:\n    mase = np.nan\n\npd.DataFrame({\"MAE\": [mae], \"sMAPE\": [smape], \"MASE\": [mase]})\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## sktime mapping (practical pointers)\n\nKey utilities in sktime for evaluation and backtesting include:\n- `temporal_train_test_split`\n- `SlidingWindowSplitter` / `ExpandingWindowSplitter`\n- `ForecastingGridSearchCV` for tuning with time-aware validation\n\nUse these to keep evaluation aligned with temporal order.\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}