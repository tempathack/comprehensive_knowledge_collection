{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Time Series Classification\n",
    "\n",
    "Ensembles combine **diverse base classifiers** (distance, interval, dictionary, shapelet,\n",
    "deep learning, etc.) and aggregate their predictions. The goal is to reduce variance,\n",
    "stabilize performance across datasets, and benefit from complementary inductive biases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core idea (weighted voting)\n",
    "Let base classifiers produce class probabilities $p_k(y \\mid x)$.\n",
    "A weighted ensemble computes:\n",
    "\\[s(y \\mid x) = \\sum_{k=1}^K w_k \\, p_k(y \\mid x), \\quad w_k \\ge 0, \\sum_k w_k = 1\\]\n",
    "Then predict $\\hat{y} = \\arg\\max_y s(y \\mid x)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "classes = [\"A\", \"B\", \"C\"]\n",
    "base = pd.DataFrame(\n",
    "    {\n",
    "        \"Distance\": [0.60, 0.30, 0.10],\n",
    "        \"Interval\": [0.20, 0.55, 0.25],\n",
    "        \"Dictionary\": [0.35, 0.25, 0.40],\n",
    "        \"Shapelet\": [0.25, 0.50, 0.25],\n",
    "    },\n",
    "    index=classes,\n",
    ")\n",
    "weights = np.array([0.35, 0.25, 0.20, 0.20])\n",
    "ensemble = (base.values @ weights).round(3)\n",
    "base[\"Ensemble\"] = ensemble\n",
    "\n",
    "fig = px.bar(\n",
    "    base.reset_index().melt(id_vars=\"index\"),\n",
    "    x=\"index\",\n",
    "    y=\"value\",\n",
    "    color=\"variable\",\n",
    "    barmode=\"group\",\n",
    "    title=\"Base probabilities vs ensemble vote\",\n",
    ")\n",
    "fig.update_layout(xaxis_title=\"Class\", yaxis_title=\"Probability\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why ensembles help\n",
    "If base learners are accurate **and** make *different mistakes*, the average prediction\n",
    "is more stable. A simple variance model for an average of $K$ estimators with pairwise\n",
    "correlation $\\rho$ is:\n",
    "\\[\\mathrm{Var}(\\bar{f}) = \\frac{1}{K}\\sigma^2 + \\frac{K-1}{K}\\rho\\sigma^2\\]\n",
    "Lower correlation means stronger variance reduction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "K = 10\n",
    "rho = np.linspace(0, 1, 51)\n",
    "sigma2 = 1.0\n",
    "var_avg = (1 / K) * sigma2 + ((K - 1) / K) * rho * sigma2\n",
    "\n",
    "fig = px.line(x=rho, y=var_avg, title=\"Ensemble variance vs correlation\")\n",
    "fig.update_layout(xaxis_title=\"Correlation between base learners (rho)\", yaxis_title=\"Var(average prediction)\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sktime inventory for ensemble classifiers\n",
    "sktime exposes ensembles via the registry. The exact list depends on your installed version\n",
    "and optional dependencies. Use the filter below to surface ensemble-style estimators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    from sktime.registry import all_estimators\n",
    "\n",
    "    ests = all_estimators(estimator_types=\"classifier\", as_dataframe=True)\n",
    "    mask = (\n",
    "        ests[\"name\"].str.contains(\"Ensemble|HIVE|Proximity|COTE\", case=False, na=False)\n",
    "        | ests[\"module\"].str.contains(\"ensemble|hive|cote|proximity\", case=False, na=False)\n",
    "    )\n",
    "    print(ests.loc[mask, [\"name\", \"module\"]].sort_values(\"name\").to_string(index=False))\n",
    "except Exception as exc:\n",
    "    print(\"sktime is not installed or registry lookup failed:\", exc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to use\n",
    "- Datasets are heterogeneous and no single model family wins everywhere.\n",
    "- You need robust accuracy and are willing to trade extra compute for stability.\n",
    "- You can afford a validation loop to tune ensemble weights or meta-learners.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5651a10f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Low-Level NumPy Implementation\n",
    "\n",
    "Below we implement core ensemble techniques from scratch using NumPy.\n",
    "This helps understand the mechanics behind **bagging**, **weighted voting**, and **stacking**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1b5531",
   "metadata": {},
   "source": [
    "### 1. Bagging (Bootstrap Aggregating)\n",
    "\n",
    "Bagging creates diversity by training each base classifier on a **bootstrap sample**\n",
    "(sampling with replacement). The final prediction is obtained by **majority voting**.\n",
    "\n",
    "For a dataset with $n$ samples, each bootstrap sample draws $n$ examples with replacement.\n",
    "On average, about $1 - (1 - 1/n)^n \\approx 63.2\\%$ of unique samples appear in each bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12debfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def bootstrap_sample(X: np.ndarray, y: np.ndarray, random_state: int = None) -> tuple:\n",
    "    \"\"\"\n",
    "    Generate a bootstrap sample (sampling with replacement).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray of shape (n_samples, n_features)\n",
    "    y : np.ndarray of shape (n_samples,)\n",
    "    random_state : int, optional\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_boot, y_boot : bootstrap samples\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    n_samples = X.shape[0]\n",
    "    indices = rng.integers(0, n_samples, size=n_samples)\n",
    "    return X[indices], y[indices]\n",
    "\n",
    "\n",
    "def train_base_classifiers(X: np.ndarray, y: np.ndarray, n_estimators: int = 10,\n",
    "                            random_state: int = 42) -> list:\n",
    "    \"\"\"\n",
    "    Train multiple base classifiers on bootstrap samples.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray of shape (n_samples, n_features)\n",
    "    y : np.ndarray of shape (n_samples,)\n",
    "    n_estimators : int, number of base classifiers\n",
    "    random_state : int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    classifiers : list of fitted classifiers\n",
    "    \"\"\"\n",
    "    classifiers = []\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    \n",
    "    for i in range(n_estimators):\n",
    "        X_boot, y_boot = bootstrap_sample(X, y, random_state=rng.integers(0, 10000))\n",
    "        clf = DecisionTreeClassifier(max_depth=5, random_state=rng.integers(0, 10000))\n",
    "        clf.fit(X_boot, y_boot)\n",
    "        classifiers.append(clf)\n",
    "    \n",
    "    return classifiers\n",
    "\n",
    "\n",
    "def bagging_predict(classifiers: list, X_test: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Aggregate predictions using majority voting.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    classifiers : list of fitted classifiers\n",
    "    X_test : np.ndarray of shape (n_samples, n_features)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    predictions : np.ndarray of shape (n_samples,)\n",
    "    \"\"\"\n",
    "    # Collect predictions from all classifiers: shape (n_estimators, n_samples)\n",
    "    all_preds = np.array([clf.predict(X_test) for clf in classifiers])\n",
    "    \n",
    "    # Majority vote for each sample\n",
    "    predictions = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        sample_preds = all_preds[:, i]\n",
    "        unique, counts = np.unique(sample_preds, return_counts=True)\n",
    "        predictions.append(unique[np.argmax(counts)])\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "# Demo: Bagging on synthetic data\n",
    "X, y = make_classification(n_samples=500, n_features=20, n_informative=10,\n",
    "                           n_classes=3, n_clusters_per_class=1, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "classifiers = train_base_classifiers(X_train, y_train, n_estimators=15)\n",
    "y_pred = bagging_predict(classifiers, X_test)\n",
    "\n",
    "print(f\"Bagging Ensemble Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(f\"Single Tree Accuracy:      {accuracy_score(y_test, classifiers[0].predict(X_test)):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1267df8",
   "metadata": {},
   "source": [
    "### 2. Weighted Voting\n",
    "\n",
    "Instead of equal votes, we can assign **weights** to each classifier based on their\n",
    "validation performance. The ensemble prediction becomes:\n",
    "\n",
    "$$\\hat{y} = \\arg\\max_c \\sum_{k=1}^K w_k \\cdot \\mathbb{1}[\\hat{y}_k = c]$$\n",
    "\n",
    "where $w_k \\ge 0$ and $\\sum_k w_k = 1$. Optimal weights can be found by minimizing\n",
    "cross-entropy or maximizing accuracy on a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c5bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def weighted_vote(predictions: np.ndarray, weights: np.ndarray, n_classes: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute weighted voting across multiple classifier predictions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : np.ndarray of shape (n_estimators, n_samples)\n",
    "        Predictions from each classifier\n",
    "    weights : np.ndarray of shape (n_estimators,)\n",
    "        Weight for each classifier (must sum to 1)\n",
    "    n_classes : int\n",
    "        Number of classes\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    final_preds : np.ndarray of shape (n_samples,)\n",
    "    \"\"\"\n",
    "    n_estimators, n_samples = predictions.shape\n",
    "    final_preds = np.zeros(n_samples, dtype=int)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Accumulate weighted votes for each class\n",
    "        class_scores = np.zeros(n_classes)\n",
    "        for k in range(n_estimators):\n",
    "            class_scores[predictions[k, i]] += weights[k]\n",
    "        final_preds[i] = np.argmax(class_scores)\n",
    "    \n",
    "    return final_preds\n",
    "\n",
    "\n",
    "def optimize_weights(predictions: np.ndarray, y_true: np.ndarray, n_classes: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Find optimal weights by maximizing accuracy on validation data.\n",
    "    Uses constrained optimization with softmax parameterization.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : np.ndarray of shape (n_estimators, n_samples)\n",
    "    y_true : np.ndarray of shape (n_samples,)\n",
    "    n_classes : int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    optimal_weights : np.ndarray of shape (n_estimators,)\n",
    "    \"\"\"\n",
    "    n_estimators = predictions.shape[0]\n",
    "    \n",
    "    def neg_accuracy(log_weights):\n",
    "        # Softmax to ensure weights sum to 1\n",
    "        weights = np.exp(log_weights) / np.sum(np.exp(log_weights))\n",
    "        preds = weighted_vote(predictions, weights, n_classes)\n",
    "        return -accuracy_score(y_true, preds)\n",
    "    \n",
    "    # Initial equal weights\n",
    "    x0 = np.zeros(n_estimators)\n",
    "    result = minimize(neg_accuracy, x0, method='Nelder-Mead')\n",
    "    \n",
    "    optimal_log_weights = result.x\n",
    "    optimal_weights = np.exp(optimal_log_weights) / np.sum(np.exp(optimal_log_weights))\n",
    "    \n",
    "    return optimal_weights\n",
    "\n",
    "\n",
    "# Demo: Weighted Voting\n",
    "# Get predictions from all classifiers on validation set\n",
    "all_predictions = np.array([clf.predict(X_test) for clf in classifiers])\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "# Optimize weights\n",
    "optimal_weights = optimize_weights(all_predictions, y_test, n_classes)\n",
    "\n",
    "# Compare equal vs optimal weights\n",
    "equal_weights = np.ones(len(classifiers)) / len(classifiers)\n",
    "equal_preds = weighted_vote(all_predictions, equal_weights, n_classes)\n",
    "optimal_preds = weighted_vote(all_predictions, optimal_weights, n_classes)\n",
    "\n",
    "print(f\"Equal Weights Accuracy:   {accuracy_score(y_test, equal_preds):.3f}\")\n",
    "print(f\"Optimal Weights Accuracy: {accuracy_score(y_test, optimal_preds):.3f}\")\n",
    "print(f\"\\nOptimal weights: {np.round(optimal_weights, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ee6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize weight distribution\n",
    "import plotly.express as px\n",
    "\n",
    "weight_df = pd.DataFrame({\n",
    "    'Classifier': [f'Tree_{i+1}' for i in range(len(classifiers))],\n",
    "    'Optimal Weight': optimal_weights,\n",
    "    'Equal Weight': equal_weights\n",
    "}).melt(id_vars='Classifier', var_name='Weight Type', value_name='Weight')\n",
    "\n",
    "fig = px.bar(weight_df, x='Classifier', y='Weight', color='Weight Type',\n",
    "             barmode='group', title='Classifier Weight Distribution')\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b6f37",
   "metadata": {},
   "source": [
    "### 3. Stacking Meta-Learner\n",
    "\n",
    "Stacking uses a **meta-learner** (level-1 model) to combine base classifier outputs.\n",
    "Instead of simple voting, we train a model to learn optimal combination weights.\n",
    "\n",
    "The process:\n",
    "1. Generate **meta-features**: predictions (or probabilities) from base classifiers\n",
    "2. Train a meta-learner (e.g., logistic regression) on these meta-features\n",
    "3. At inference, pass base predictions through the meta-learner\n",
    "\n",
    "$$\\hat{y}_{stack} = f_{meta}\\big([\\hat{p}_1(x), \\hat{p}_2(x), \\ldots, \\hat{p}_K(x)]\\big)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "def generate_meta_features(classifiers: list, X: np.ndarray, \n",
    "                           use_probabilities: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate meta-features from base classifier predictions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    classifiers : list of fitted classifiers\n",
    "    X : np.ndarray of shape (n_samples, n_features)\n",
    "    use_probabilities : bool\n",
    "        If True, use predicted probabilities; otherwise use class predictions\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    meta_features : np.ndarray of shape (n_samples, n_meta_features)\n",
    "    \"\"\"\n",
    "    if use_probabilities:\n",
    "        # Stack probability predictions: shape (n_samples, n_estimators * n_classes)\n",
    "        proba_list = [clf.predict_proba(X) for clf in classifiers]\n",
    "        meta_features = np.hstack(proba_list)\n",
    "    else:\n",
    "        # Stack class predictions: shape (n_samples, n_estimators)\n",
    "        pred_list = [clf.predict(X).reshape(-1, 1) for clf in classifiers]\n",
    "        meta_features = np.hstack(pred_list)\n",
    "    \n",
    "    return meta_features\n",
    "\n",
    "\n",
    "def train_meta_learner(meta_features: np.ndarray, y: np.ndarray) -> LogisticRegression:\n",
    "    \"\"\"\n",
    "    Train a logistic regression meta-learner on meta-features.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    meta_features : np.ndarray of shape (n_samples, n_meta_features)\n",
    "    y : np.ndarray of shape (n_samples,)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    meta_learner : fitted LogisticRegression\n",
    "    \"\"\"\n",
    "    meta_learner = LogisticRegression(max_iter=1000, multi_class='multinomial', random_state=42)\n",
    "    meta_learner.fit(meta_features, y)\n",
    "    return meta_learner\n",
    "\n",
    "\n",
    "def stacking_predict(base_classifiers: list, meta_learner, X: np.ndarray,\n",
    "                     use_probabilities: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Make predictions using stacking ensemble.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    base_classifiers : list of fitted classifiers\n",
    "    meta_learner : fitted meta-learner model\n",
    "    X : np.ndarray of shape (n_samples, n_features)\n",
    "    use_probabilities : bool\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    predictions : np.ndarray of shape (n_samples,)\n",
    "    \"\"\"\n",
    "    meta_features = generate_meta_features(base_classifiers, X, use_probabilities)\n",
    "    return meta_learner.predict(meta_features)\n",
    "\n",
    "\n",
    "# Demo: Stacking with proper train/validation split for meta-features\n",
    "# To avoid leakage, we use cross-validated predictions for training meta-learner\n",
    "\n",
    "# Re-split data: train for base classifiers, validation for meta-learner\n",
    "X_base, X_meta, y_base, y_meta = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train base classifiers on X_base\n",
    "base_classifiers = train_base_classifiers(X_base, y_base, n_estimators=10)\n",
    "\n",
    "# Generate meta-features using X_meta (held-out validation data)\n",
    "meta_features_train = generate_meta_features(base_classifiers, X_meta, use_probabilities=True)\n",
    "\n",
    "# Train meta-learner on held-out predictions\n",
    "meta_learner = train_meta_learner(meta_features_train, y_meta)\n",
    "\n",
    "# Predict on test set\n",
    "stacking_preds = stacking_predict(base_classifiers, meta_learner, X_test, use_probabilities=True)\n",
    "\n",
    "print(f\"Stacking Ensemble Accuracy: {accuracy_score(y_test, stacking_preds):.3f}\")\n",
    "print(f\"Bagging (majority vote):    {accuracy_score(y_test, bagging_predict(base_classifiers, X_test)):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd49e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize meta-learner coefficients (importance of each base classifier's predictions)\n",
    "coef_matrix = meta_learner.coef_  # shape: (n_classes, n_meta_features)\n",
    "n_classes_viz = coef_matrix.shape[0]\n",
    "n_classifiers = len(base_classifiers)\n",
    "\n",
    "# Average absolute coefficient per base classifier (across all classes and their probability outputs)\n",
    "avg_importance = np.abs(coef_matrix).reshape(n_classes_viz, n_classifiers, n_classes_viz).mean(axis=(0, 2))\n",
    "\n",
    "fig = px.bar(\n",
    "    x=[f'Base_{i+1}' for i in range(n_classifiers)],\n",
    "    y=avg_importance,\n",
    "    title='Meta-Learner: Average Importance per Base Classifier',\n",
    "    labels={'x': 'Base Classifier', 'y': 'Average |Coefficient|'}\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9568e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all methods\n",
    "methods = ['Single Tree', 'Bagging (Majority)', 'Weighted Voting', 'Stacking']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, base_classifiers[0].predict(X_test)),\n",
    "    accuracy_score(y_test, bagging_predict(base_classifiers, X_test)),\n",
    "    accuracy_score(y_test, optimal_preds),\n",
    "    accuracy_score(y_test, stacking_preds)\n",
    "]\n",
    "\n",
    "fig = px.bar(\n",
    "    x=methods, y=accuracies,\n",
    "    title='Ensemble Methods Comparison',\n",
    "    labels={'x': 'Method', 'y': 'Accuracy'},\n",
    "    color=accuracies,\n",
    "    color_continuous_scale='Viridis'\n",
    ")\n",
    "fig.update_layout(showlegend=False)\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}