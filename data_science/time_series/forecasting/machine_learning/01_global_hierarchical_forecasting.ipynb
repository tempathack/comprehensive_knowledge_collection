{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global and Hierarchical Forecasting\n",
        "\n",
        "Global models learn shared patterns across many related series, while hierarchical forecasting\n",
        "enforces coherence across aggregation levels (store -> region -> total). This notebook builds\n",
        "a fully reproducible example with Plotly visuals and numpy-based baselines.\n",
        "\n",
        "## What you will learn\n",
        "- The difference between local and global forecasting models.\n",
        "- How hierarchical aggregation and reconciliation work.\n",
        "- How to evaluate bottom-up vs top-down forecasts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem setup\n",
        "\n",
        "Suppose we have series $y_{i,t}$ for series $i$ and time $t$.\n",
        "\n",
        "- **Local model**: fit a separate model per series.\n",
        "  $$\\hat{y}_{i,t+h} = f_i(y_{i,1:t}, x_{i,1:t}).$$\n",
        "- **Global model**: fit a shared model across all series, allowing shared patterns to transfer.\n",
        "  $$\\hat{y}_{i,t+h} = f(y_{i,1:t}, x_{i,1:t}; \\theta).$$\n",
        "- **Hierarchical forecasting**: predictions must be **coherent** across aggregation levels.\n",
        "  For example, store-level forecasts must sum to regional and total forecasts.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "rng = np.random.default_rng(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulate hierarchical retail data\n",
        "\n",
        "We create two regions with multiple stores. Each store shares a global trend and seasonal\n",
        "pattern, plus region and store-level effects.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "regions = {\n",
        "    \"North\": [\"N-1\", \"N-2\"],\n",
        "    \"South\": [\"S-1\", \"S-2\", \"S-3\"],\n",
        "}\n",
        "\n",
        "periods = 72\n",
        "period_index = pd.period_range(\"2018-01\", periods=periods, freq=\"M\")\n",
        "t = np.arange(periods)\n",
        "\n",
        "global_trend = 0.15 * t\n",
        "global_season = 3.0 * np.sin(2 * np.pi * t / 12)\n",
        "\n",
        "records = []\n",
        "for region, stores in regions.items():\n",
        "    region_bias = rng.normal(2.0, 0.4)\n",
        "    for store in stores:\n",
        "        store_bias = rng.normal(0.0, 0.8)\n",
        "        noise = rng.normal(0, 0.8, size=periods)\n",
        "        y = 20 + region_bias + store_bias + global_trend + global_season + noise\n",
        "        for idx, period in enumerate(period_index):\n",
        "            records.append({\n",
        "                \"region\": region,\n",
        "                \"store\": store,\n",
        "                \"period\": period,\n",
        "                \"t\": idx,\n",
        "                \"y\": y[idx],\n",
        "            })\n",
        "\n",
        "df = pd.DataFrame.from_records(records)\n",
        "df[\"series_id\"] = df[\"region\"] + \"/\" + df[\"store\"]\n",
        "df[\"timestamp\"] = df[\"period\"].dt.to_timestamp()\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "tree_df = df.groupby([\"region\", \"store\"], as_index=False)[\"y\"].mean()\n",
        "fig = px.sunburst(tree_df, path=[\"region\", \"store\"], values=\"y\",\n",
        "                 title=\"Hierarchy (average series level)\")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "for series_id in sorted(df[\"series_id\"].unique()):\n",
        "    s = df[df[\"series_id\"] == series_id]\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=s[\"timestamp\"],\n",
        "        y=s[\"y\"],\n",
        "        mode=\"lines\",\n",
        "        name=series_id\n",
        "    ))\n",
        "fig.update_layout(title=\"Store-level series\", xaxis_title=\"time\", yaxis_title=\"y\", height=420)\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Local vs global baselines\n",
        "\n",
        "We fit simple linear + seasonal models. Local models fit each series independently;\n",
        "global models share the same slope and seasonality across all series while allowing\n",
        "series-specific intercepts.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def make_features(t_values, include_intercept=True):\n",
        "    t_values = np.asarray(t_values)\n",
        "    sin_term = np.sin(2 * np.pi * t_values / 12)\n",
        "    cos_term = np.cos(2 * np.pi * t_values / 12)\n",
        "    cols = []\n",
        "    if include_intercept:\n",
        "        cols.append(np.ones_like(t_values))\n",
        "    cols.extend([t_values, sin_term, cos_term])\n",
        "    return np.column_stack(cols)\n",
        "\n",
        "def fit_linear(X, y):\n",
        "    beta, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
        "    return beta\n",
        "\n",
        "def mae(y_true, y_pred):\n",
        "    return float(np.mean(np.abs(y_true - y_pred)))\n",
        "\n",
        "horizon = 12\n",
        "t_train = t[:-horizon]\n",
        "t_test = t[-horizon:]\n",
        "\n",
        "series_ids = sorted(df[\"series_id\"].unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Local models\n",
        "local_preds = {}\n",
        "local_mae = {}\n",
        "\n",
        "for series_id in series_ids:\n",
        "    s = df[df[\"series_id\"] == series_id].sort_values(\"t\")\n",
        "    y = s[\"y\"].values\n",
        "    y_train, y_test = y[:-horizon], y[-horizon:]\n",
        "\n",
        "    X_train = make_features(t_train, include_intercept=True)\n",
        "    X_test = make_features(t_test, include_intercept=True)\n",
        "    beta = fit_linear(X_train, y_train)\n",
        "    y_pred = X_test @ beta\n",
        "\n",
        "    local_preds[series_id] = y_pred\n",
        "    local_mae[series_id] = mae(y_test, y_pred)\n",
        "\n",
        "local_mae\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Global model with shared slope/seasonality and series-specific intercepts\n",
        "n_series = len(series_ids)\n",
        "X_blocks = []\n",
        "y_blocks = []\n",
        "\n",
        "for idx, series_id in enumerate(series_ids):\n",
        "    s = df[df[\"series_id\"] == series_id].sort_values(\"t\")\n",
        "    y = s[\"y\"].values\n",
        "    y_train = y[:-horizon]\n",
        "    X_shared = make_features(t_train, include_intercept=False)\n",
        "\n",
        "    intercept_cols = np.zeros((len(t_train), n_series))\n",
        "    intercept_cols[:, idx] = 1.0\n",
        "    X = np.hstack([intercept_cols, X_shared])\n",
        "\n",
        "    X_blocks.append(X)\n",
        "    y_blocks.append(y_train)\n",
        "\n",
        "X_train_all = np.vstack(X_blocks)\n",
        "y_train_all = np.concatenate(y_blocks)\n",
        "\n",
        "beta_global = fit_linear(X_train_all, y_train_all)\n",
        "beta_intercepts = beta_global[:n_series]\n",
        "beta_shared = beta_global[n_series:]\n",
        "\n",
        "global_preds = {}\n",
        "global_mae = {}\n",
        "\n",
        "for idx, series_id in enumerate(series_ids):\n",
        "    s = df[df[\"series_id\"] == series_id].sort_values(\"t\")\n",
        "    y = s[\"y\"].values\n",
        "    y_test = y[-horizon:]\n",
        "\n",
        "    X_test_shared = make_features(t_test, include_intercept=False)\n",
        "    y_pred = beta_intercepts[idx] + X_test_shared @ beta_shared\n",
        "\n",
        "    global_preds[series_id] = y_pred\n",
        "    global_mae[series_id] = mae(y_test, y_pred)\n",
        "\n",
        "global_mae\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "score_df = pd.DataFrame({\n",
        "    \"series_id\": series_ids,\n",
        "    \"local_mae\": [local_mae[sid] for sid in series_ids],\n",
        "    \"global_mae\": [global_mae[sid] for sid in series_ids],\n",
        "})\n",
        "score_df\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "score_long = score_df.melt(id_vars=\"series_id\", var_name=\"model\", value_name=\"mae\")\n",
        "fig = px.bar(score_long, x=\"series_id\", y=\"mae\", color=\"model\",\n",
        "             barmode=\"group\", title=\"Local vs global MAE (lower is better)\")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "example_id = series_ids[0]\n",
        "s = df[df[\"series_id\"] == example_id].sort_values(\"t\")\n",
        "y = s[\"y\"].values\n",
        "y_train, y_test = y[:-horizon], y[-horizon:]\n",
        "\n",
        "train_idx = s[\"timestamp\"].iloc[:-horizon]\n",
        "test_idx = s[\"timestamp\"].iloc[-horizon:]\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=train_idx, y=y_train, mode=\"lines\", name=\"Train\"))\n",
        "fig.add_trace(go.Scatter(x=test_idx, y=y_test, mode=\"lines\", name=\"Test\", line=dict(color=\"black\")))\n",
        "fig.add_trace(go.Scatter(x=test_idx, y=local_preds[example_id], mode=\"lines\", name=\"Local pred\"))\n",
        "fig.add_trace(go.Scatter(x=test_idx, y=global_preds[example_id], mode=\"lines\", name=\"Global pred\"))\n",
        "fig.update_layout(title=f\"Example series: {example_id}\", xaxis_title=\"time\", yaxis_title=\"y\")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hierarchical reconciliation\n",
        "\n",
        "We compare two simple strategies:\n",
        "\n",
        "- **Bottom-up**: forecast each store and sum to region/total.\n",
        "- **Top-down**: forecast the total, then allocate to stores using historical proportions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Build forecast DataFrame (store-level) using the global model\n",
        "pred_rows = []\n",
        "for series_id in series_ids:\n",
        "    s = df[df[\"series_id\"] == series_id].sort_values(\"t\")\n",
        "    test_periods = s[\"period\"].iloc[-horizon:]\n",
        "    region, store = series_id.split(\"/\")\n",
        "    for period, pred in zip(test_periods, global_preds[series_id]):\n",
        "        pred_rows.append({\n",
        "            \"region\": region,\n",
        "            \"store\": store,\n",
        "            \"period\": period,\n",
        "            \"timestamp\": period.to_timestamp(),\n",
        "            \"y_pred\": pred,\n",
        "        })\n",
        "\n",
        "pred_df = pd.DataFrame(pred_rows)\n",
        "\n",
        "# Actuals for test horizon\n",
        "actual_df = df[df[\"t\"] >= t_test[0]].copy()\n",
        "actual_df = actual_df[[\"region\", \"store\", \"period\", \"timestamp\", \"y\"]]\n",
        "\n",
        "# Bottom-up aggregation\n",
        "bu_region = pred_df.groupby([\"region\", \"period\"], as_index=False)[\"y_pred\"].sum().sort_values(\"period\")\n",
        "bu_total = pred_df.groupby([\"period\"], as_index=False)[\"y_pred\"].sum().sort_values(\"period\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Top-down: forecast total series, then allocate by historical share\n",
        "total_series = df.groupby(\"period\", as_index=False)[\"y\"].sum().sort_values(\"period\")\n",
        "total_train = total_series.iloc[:-horizon]\n",
        "total_test = total_series.iloc[-horizon:]\n",
        "\n",
        "beta_total = fit_linear(make_features(t_train, include_intercept=True), total_train[\"y\"].values)\n",
        "total_pred = make_features(t_test, include_intercept=True) @ beta_total\n",
        "\n",
        "train_df = df[df[\"t\"] < t_test[0]]\n",
        "shares = train_df.groupby(\"series_id\")[\"y\"].sum() / train_df[\"y\"].sum()\n",
        "\n",
        "td_rows = []\n",
        "for series_id in series_ids:\n",
        "    region, store = series_id.split(\"/\")\n",
        "    share = shares.loc[series_id]\n",
        "    for period, pred in zip(total_test[\"period\"], total_pred):\n",
        "        td_rows.append({\n",
        "            \"region\": region,\n",
        "            \"store\": store,\n",
        "            \"period\": period,\n",
        "            \"timestamp\": period.to_timestamp(),\n",
        "            \"y_pred\": pred * share,\n",
        "        })\n",
        "\n",
        "td_df = pd.DataFrame(td_rows)\n",
        "td_region = td_df.groupby([\"region\", \"period\"], as_index=False)[\"y_pred\"].sum().sort_values(\"period\")\n",
        "td_total = td_df.groupby([\"period\"], as_index=False)[\"y_pred\"].sum().sort_values(\"period\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Compare total-level accuracy\n",
        "actual_total = total_test[\"y\"].values\n",
        "bu_total_mae = mae(actual_total, bu_total[\"y_pred\"].values)\n",
        "td_total_mae = mae(actual_total, td_total[\"y_pred\"].values)\n",
        "\n",
        "bu_total_mae, td_total_mae\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=total_test[\"period\"].dt.to_timestamp(), y=actual_total,\n",
        "                         mode=\"lines\", name=\"Actual total\", line=dict(color=\"black\")))\n",
        "fig.add_trace(go.Scatter(x=bu_total[\"period\"].dt.to_timestamp(), y=bu_total[\"y_pred\"],\n",
        "                         mode=\"lines\", name=\"Bottom-up\"))\n",
        "fig.add_trace(go.Scatter(x=td_total[\"period\"].dt.to_timestamp(), y=td_total[\"y_pred\"],\n",
        "                         mode=\"lines\", name=\"Top-down\"))\n",
        "fig.update_layout(title=\"Total forecast: bottom-up vs top-down\", xaxis_title=\"time\", yaxis_title=\"y\")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## sktime mapping (high level)\n",
        "\n",
        "- sktime supports hierarchical **mtypes** via pandas MultiIndex containers.\n",
        "- Forecasting estimators can be evaluated on hierarchical data if they declare the right tags.\n",
        "- Reconciliation strategies (bottom-up, top-down, middle-out) can be implemented as\n",
        "  preprocessing or post-processing steps in a pipeline.\n",
        "\n",
        "See the datatypes and registry notebooks in\n",
        "`data_science/time_series/sktime_algorithms/` for a version-specific catalog.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n",
        "- Swap the global model for a lag-based regression (add $y_{t-1}$ and $y_{t-12}$).\n",
        "- Compare bottom-up vs top-down at the **region** level, not just total.\n",
        "- Try different allocation rules (last-year share vs average share).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Further reading\n",
        "- Hyndman et al., *Forecasting: Principles and Practice* (hierarchical forecasting).\n",
        "- Global forecasting surveys and benchmark papers on pooled learning across series.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}