{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Time Series Clustering â€” Overview\n\n## Why this matters\n- Group sequences by **shape**, **phase**, or **dynamics** to discover regimes.\n- Build cohorts for monitoring, forecasting, or anomaly detection.\n- Create prototypes (medoids/centroids) that summarize behavior.\n\n## Key decisions\n1. **Representation**: raw series, aligned series, or engineered features.\n2. **Similarity**: Euclidean, correlation, DTW, shape-based distances.\n3. **Algorithm**: partitional (k-means/k-medoids), hierarchical, density.\n4. **Validation**: silhouette, stability, and domain interpretation.\n\n## Notation\nA univariate series is $x = (x_1, \\dots, x_T)$. We often standardize per-series using\n\n$$z_t = \\frac{x_t - \\mu_x}{\\sigma_x}.$$\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\nimport plotly.express as px\n\ncolors = [\"#1B9E77\", \"#D95F02\", \"#7570B3\"]\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A simple clustering pipeline\nThis pipeline frames the common choices you make in most projects.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "steps = [\"Ingest\", \"Preprocess\", \"Representation\", \"Similarity\", \"Clustering\", \"Validate\"]",
    "",
    "fig = go.Figure()",
    "for i, step in enumerate(steps):",
    "    fig.add_shape(",
    "        type=\"rect\",",
    "        x0=i - 0.45,",
    "        x1=i + 0.45,",
    "        y0=-0.25,",
    "        y1=0.25,",
    "        line=dict(color=\"#2C7FB8\", width=2),",
    "        fillcolor=\"#D0ECF4\",",
    "    )",
    "    fig.add_annotation(x=i, y=0, text=step, showarrow=False, font=dict(size=12))",
    "    if i < len(steps) - 1:",
    "        fig.add_annotation(",
    "            x=i + 0.45,",
    "            y=0,",
    "            ax=i + 0.55,",
    "            ay=0,",
    "            showarrow=True,",
    "            arrowhead=3,",
    "            arrowsize=1,",
    "        )",
    "",
    "fig.update_xaxes(visible=False)",
    "fig.update_yaxes(visible=False)",
    "fig.update_layout(",
    "    title=\"Time series clustering pipeline\",",
    "    height=240,",
    "    margin=dict(l=10, r=10, t=40, b=10),",
    ")",
    "fig",
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Synthetic dataset\nWe will create three families of series to make the effects of representation clear.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rng = np.random.default_rng(7)",
    "",
    "n_series = 90",
    "length = 120",
    "t = np.linspace(0, 2 * np.pi, length)",
    "",
    "series = []",
    "labels_true = []",
    "",
    "for _ in range(n_series // 3):",
    "    phase = rng.normal(0, 0.2)",
    "    series.append(np.sin(t + phase) + 0.1 * rng.normal(size=length))",
    "    labels_true.append(\"sine\")",
    "",
    "for _ in range(n_series // 3):",
    "    phase = rng.normal(1.0, 0.2)",
    "    series.append(np.sin(t + phase) + 0.1 * rng.normal(size=length))",
    "    labels_true.append(\"phase_shifted\")",
    "",
    "for _ in range(n_series // 3):",
    "    trend = np.linspace(-0.6, 0.8, length)",
    "    series.append(trend + 0.6 * np.sin(2 * t) + 0.1 * rng.normal(size=length))",
    "    labels_true.append(\"trend_seasonal\")",
    "",
    "series = np.array(series)",
    "labels_true = np.array(labels_true)",
    "",
    "sample_ids = rng.choice(len(series), size=12, replace=False)",
    "",
    "df_plot = (",
    "    pd.DataFrame(series[sample_ids])",
    "    .assign(series_id=[f\"s{i}\" for i in sample_ids])",
    "    .assign(true_label=labels_true[sample_ids])",
    "    .melt(id_vars=[\"series_id\", \"true_label\"], var_name=\"time\", value_name=\"value\")",
    ")",
    "",
    "fig = px.line(",
    "    df_plot,",
    "    x=\"time\",",
    "    y=\"value\",",
    "    color=\"series_id\",",
    "    facet_col=\"true_label\",",
    "    facet_col_spacing=0.05,",
    "    title=\"Sample series by generating process\",",
    ")",
    "fig.update_layout(showlegend=False)",
    "fig",
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Representation choices\n\n### 1) Raw series\n- Requires equal length and aligned time indexes.\n- Sensitive to **phase shifts** and **time warping**.\n\n### 2) Feature-based vectors\n- Works with standard clustering algorithms.\n- Useful for scale, trend, seasonality, or volatility patterns.\n- Examples: mean, slope, dominant frequency, autocorrelation.\n\n### 3) Learned or shape-based embeddings\n- ROCKET, shapelets, autoencoders, wavelets.\n- Often cluster in latent space.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Feature-based clustering (baseline)\nWe first map each series to a feature vector and cluster with $k$-means.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.cluster import KMeans",
    "from sklearn.decomposition import PCA",
    "from sklearn.preprocessing import StandardScaler",
    "",
    "",
    "def extract_features(x):",
    "    idx = np.arange(len(x))",
    "    slope = np.polyfit(idx, x, 1)[0]",
    "    mean = x.mean()",
    "    std = x.std()",
    "    autocorr = np.corrcoef(x[:-1], x[1:])[0, 1]",
    "    fft = np.fft.rfft(x - mean)",
    "    dominant_freq = np.argmax(np.abs(fft[1:])) + 1",
    "    amplitude = x.max() - x.min()",
    "    return [mean, std, slope, autocorr, dominant_freq, amplitude]",
    "",
    "",
    "X = np.array([extract_features(s) for s in series])",
    "",
    "scaler = StandardScaler()",
    "X_scaled = scaler.fit_transform(X)",
    "",
    "kmeans = KMeans(n_clusters=3, n_init=20, random_state=7)",
    "labels_km = kmeans.fit_predict(X_scaled)",
    "",
    "pca = PCA(n_components=2, random_state=7)",
    "X_2d = pca.fit_transform(X_scaled)",
    "",
    "df_feat = pd.DataFrame(X_2d, columns=[\"PC1\", \"PC2\"])",
    "df_feat[\"cluster\"] = labels_km.astype(str)",
    "df_feat[\"true_label\"] = labels_true",
    "",
    "fig = px.scatter(",
    "    df_feat,",
    "    x=\"PC1\",",
    "    y=\"PC2\",",
    "    color=\"cluster\",",
    "    symbol=\"true_label\",",
    "    title=\"Feature-based clustering (PCA view)\",",
    ")",
    "fig",
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cluster_means = []",
    "for k in range(3):",
    "    cluster_series = series[labels_km == k]",
    "    cluster_means.append(cluster_series.mean(axis=0))",
    "",
    "fig = go.Figure()",
    "for k, mean_series in enumerate(cluster_means):",
    "    fig.add_trace(",
    "        go.Scatter(",
    "            x=np.arange(length),",
    "            y=mean_series,",
    "            mode=\"lines\",",
    "            line=dict(color=colors[k], width=3),",
    "            name=f\"Cluster {k} mean\",",
    "        )",
    "    )",
    "",
    "fig.update_layout(title=\"Average series per feature-based cluster\")",
    "fig",
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Distance-based clustering with DTW\nDynamic Time Warping aligns series by allowing flexible time shifts. The classic recurrence is\n\n$$D_{i,j} = (x_i - y_j)^2 + \\min\\{D_{i-1,j}, D_{i,j-1}, D_{i-1,j-1}\\},$$\n\nand the DTW distance is $\\sqrt{D_{T,T'}}$.\n\nThis helps when two series share the same **shape** but are phase-shifted.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.cluster import AgglomerativeClustering",
    "",
    "",
    "def dtw_distance(x, y):",
    "    n, m = len(x), len(y)",
    "    D = np.full((n + 1, m + 1), np.inf)",
    "    D[0, 0] = 0.0",
    "    for i in range(1, n + 1):",
    "        for j in range(1, m + 1):",
    "            cost = (x[i - 1] - y[j - 1]) ** 2",
    "            D[i, j] = cost + min(D[i - 1, j], D[i, j - 1], D[i - 1, j - 1])",
    "    return np.sqrt(D[n, m])",
    "",
    "",
    "def pairwise_dtw(X):",
    "    n = len(X)",
    "    dist = np.zeros((n, n))",
    "    for i in range(n):",
    "        for j in range(i + 1, n):",
    "            d = dtw_distance(X[i], X[j])",
    "            dist[i, j] = d",
    "            dist[j, i] = d",
    "    return dist",
    "",
    "",
    "subset = 36",
    "series_small = series[:subset]",
    "labels_small = labels_true[:subset]",
    "",
    "D = pairwise_dtw(series_small)",
    "",
    "try:",
    "    model = AgglomerativeClustering(",
    "        n_clusters=3, metric=\"precomputed\", linkage=\"average\"",
    "    )",
    "except TypeError:",
    "    model = AgglomerativeClustering(",
    "        n_clusters=3, affinity=\"precomputed\", linkage=\"average\"",
    "    )",
    "",
    "labels_dtw = model.fit_predict(D)",
    "",
    "medoids = []",
    "for k in range(3):",
    "    idx = np.where(labels_dtw == k)[0]",
    "    if len(idx) == 0:",
    "        medoids.append(None)",
    "        continue",
    "    sub = D[np.ix_(idx, idx)]",
    "    medoid = idx[np.argmin(sub.sum(axis=1))]",
    "    medoids.append(medoid)",
    "",
    "fig = go.Figure()",
    "for k, medoid_idx in enumerate(medoids):",
    "    idx = np.where(labels_dtw == k)[0]",
    "    for j in idx:",
    "        fig.add_trace(",
    "            go.Scatter(",
    "                x=np.arange(length),",
    "                y=series_small[j],",
    "                mode=\"lines\",",
    "                line=dict(color=colors[k], width=1),",
    "                opacity=0.25,",
    "                showlegend=False,",
    "            )",
    "        )",
    "    if medoid_idx is not None:",
    "        fig.add_trace(",
    "            go.Scatter(",
    "                x=np.arange(length),",
    "                y=series_small[medoid_idx],",
    "                mode=\"lines\",",
    "                line=dict(color=colors[k], width=3),",
    "                name=f\"DTW cluster {k} medoid\",",
    "            )",
    "        )",
    "",
    "fig.update_layout(title=\"DTW-based clusters with medoids\")",
    "fig",
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Quick sanity check: Euclidean vs DTW\nA phase-shifted pair may look far apart in Euclidean space but close under DTW.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "x = series[0]\ny = series[n_series // 3]  # shifted sine\n\neuclid = np.linalg.norm(x - y)\ndtw = dtw_distance(x, y)\n\npd.DataFrame(\n    {\n        \"metric\": [\"Euclidean\", \"DTW\"],\n        \"distance\": [euclid, dtw],\n    }\n)\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Validation and selection\n- **Silhouette** scores work well for feature-based clustering.\n- For DTW or custom distances, use **stability** (resampling) and **domain coherence**.\n- Choose $k$ with elbow/Gap statistics or by inspecting medoids.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from sklearn.metrics import silhouette_score\n\nsilhouette = silhouette_score(X_scaled, labels_km)\nfloat(silhouette)\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Practical tips\n- Always normalize or standardize per-series when shape matters more than scale.\n- Consider **seasonal differencing** before clustering if trend dominates.\n- For multivariate series, concatenate features per channel or use multivariate DTW.\n- Use **medoids** instead of means when using non-Euclidean distances.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Exercises\n1. Replace DTW with **correlation distance** and compare cluster assignments.\n2. Add a new feature (e.g., spectral entropy) and observe changes in PCA space.\n3. Try **k-medoids** on the DTW distance matrix and compare medoids.\n\n## Further reading\n- tslearn documentation for DTW and k-medoids.\n- aeon/sktime for time-series transformations and pipelines.\n- Shapelets and ROCKET for fast, discriminative representations.\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}