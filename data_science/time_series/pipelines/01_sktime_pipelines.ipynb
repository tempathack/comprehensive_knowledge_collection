{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sktime Pipelines for Forecasting\n",
    "\n",
    "Pipelines let you chain preprocessing, modeling, and evaluation into a single object that can be tuned\n",
    "and backtested without leakage. This notebook shows common sktime patterns: transformed-target\n",
    "pipelines, reduction to regression, and systematic backtesting with Plotly visuals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline anatomy\n",
    "\n",
    "- **Transformers**: per-series transforms like Box-Cox, detrending, or deseasonalizing.\n",
    "- **Forecasters**: classical models (Theta, ARIMA), ML reduction, or deep models.\n",
    "- **Evaluation**: temporal splits and backtesting with expanding or sliding windows.\n",
    "\n",
    "In sktime, `TransformedTargetForecaster` is the most direct way to chain transforms on the target\n",
    "series before applying a forecaster. For feature-based ML, `make_reduction` turns a regressor into a\n",
    "forecaster with a sliding window.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical view\n",
    "\n",
    "Let transformations $T_1,\\dots,T_k$ act on the target series $y_t$. A pipeline applies them in order,\n",
    "then fits a forecaster $F$ to the transformed series:\n",
    "\n",
    "$$z_t = T_k(\\dots T_1(y_t))$$\n",
    "$$\\hat{z}_{t+h} = F(z_{1:t})$$\n",
    "$$\\hat{y}_{t+h} = T_1^{-1}(\\dots T_k^{-1}(\\hat{z}_{t+h}))$$\n",
    "\n",
    "Fitting the transformations **inside** the pipeline is what prevents leakage during backtesting.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "steps = [\"Raw series\", \"Box-Cox\", \"Deseasonalize\", \"Forecaster\", \"Forecasts\"]\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, label in enumerate(steps):\n",
    "    x0 = i * 1.25\n",
    "    x1 = x0 + 1.0\n",
    "    fig.add_shape(\n",
    "        type=\"rect\",\n",
    "        x0=x0,\n",
    "        x1=x1,\n",
    "        y0=0,\n",
    "        y1=0.6,\n",
    "        line=dict(color=\"#1f77b4\", width=2),\n",
    "        fillcolor=\"rgba(31, 119, 180, 0.15)\",\n",
    "    )\n",
    "    fig.add_annotation(x=(x0 + x1) / 2, y=0.3, text=label, showarrow=False)\n",
    "    if i < len(steps) - 1:\n",
    "        fig.add_annotation(x=x1 + 0.1, y=0.3, text=\"->\", showarrow=False, font=dict(size=18))\n",
    "\n",
    "fig.update_xaxes(visible=False)\n",
    "fig.update_yaxes(visible=False)\n",
    "fig.update_layout(\n",
    "    title=\"Forecasting pipeline sketch\",\n",
    "    height=220,\n",
    "    margin=dict(l=20, r=20, t=50, b=20),\n",
    ")\n",
    "fig"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic monthly series\n",
    "\n",
    "We will create a small seasonal series with trend and noise. This keeps the example reproducible and\n",
    "clear for plotting.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "n_periods = 120\n",
    "index = pd.period_range(\"2015-01\", periods=n_periods, freq=\"M\")\n",
    "trend = 0.2 * np.arange(n_periods)\n",
    "seasonal = 4 * np.sin(2 * np.pi * np.arange(n_periods) / 12)\n",
    "noise = np.random.normal(0, 1.0, n_periods)\n",
    "\n",
    "series = pd.Series(20 + trend + seasonal + noise, index=index, name=\"y\")\n",
    "series.head()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "idx = series.index.to_timestamp()\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=idx, y=series, mode=\"lines\", name=\"y\", line=dict(color=\"#1f77b4\")))\n",
    "fig.update_layout(title=\"Synthetic monthly series\", xaxis_title=\"time\", yaxis_title=\"value\", height=420)\n",
    "fig"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split and forecasting horizon\n",
    "\n",
    "A forecasting horizon $H = \\{h_1,\\dots,h_k\\}$ defines which steps ahead we predict.\n",
    "We will use an absolute horizon based on the test index for clarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sktime.forecasting.model_selection import temporal_train_test_split, ForecastingHorizon\n",
    "\n",
    "y_train, y_test = temporal_train_test_split(series, test_size=24)\n",
    "fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
    "\n",
    "len(y_train), len(y_test)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Transformed-target pipeline\n",
    "\n",
    "We chain a Box-Cox transform and deseasonalizer before forecasting with the Theta method. The entire\n",
    "sequence is a single estimator, so backtesting treats it as one unit.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sktime.transformations.series.boxcox import BoxCoxTransformer\n",
    "from sktime.transformations.series.detrend import Deseasonalizer\n",
    "from sktime.forecasting.theta import ThetaForecaster\n",
    "from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "pipe = TransformedTargetForecaster(\n",
    "    steps=[\n",
    "        (\"boxcox\", BoxCoxTransformer()),\n",
    "        (\"deseasonalize\", Deseasonalizer(sp=12, model=\"multiplicative\")),\n",
    "        (\"forecaster\", ThetaForecaster(sp=12)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(y_train)\n",
    "y_pred = pipe.predict(fh)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"MAPE: {mape * 100:.2f}%\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_idx = y_train.index.to_timestamp()\n",
    "test_idx = y_test.index.to_timestamp()\n",
    "pred_idx = y_pred.index.to_timestamp()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=train_idx, y=y_train, mode=\"lines\", name=\"Train\", line=dict(color=\"#1f77b4\")))\n",
    "fig.add_trace(go.Scatter(x=test_idx, y=y_test, mode=\"lines\", name=\"Test\", line=dict(color=\"#ff7f0e\")))\n",
    "fig.add_trace(go.Scatter(x=pred_idx, y=y_pred, mode=\"lines\", name=\"Forecast\", line=dict(color=\"#2ca02c\")))\n",
    "fig.update_layout(title=\"Pipeline forecast vs actual\", xaxis_title=\"time\", yaxis_title=\"value\", height=420)\n",
    "fig"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting with expanding windows\n",
    "\n",
    "Backtesting evaluates a pipeline over multiple cutoffs. The expanding window strategy starts with a\n",
    "minimum training size and grows the training window at each split.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sktime.forecasting.model_selection import ExpandingWindowSplitter\n",
    "from sktime.forecasting.model_evaluation import evaluate\n",
    "\n",
    "cv = ExpandingWindowSplitter(initial_window=60, step_length=12, fh=[1, 2, 3, 6, 12])\n",
    "results = evaluate(\n",
    "    pipe,\n",
    "    series,\n",
    "    cv=cv,\n",
    "    strategy=\"refit\",\n",
    "    scoring=mean_absolute_error,\n",
    ")\n",
    "\n",
    "results.head()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "metric_col = [col for col in results.columns if col.startswith(\"test_\")][0]\n",
    "cutoff = results[\"cutoff\"].astype(str)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=cutoff,\n",
    "        y=results[metric_col],\n",
    "        marker_color=\"#ff7f0e\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=f\"Backtesting {metric_col.replace('test_', '')} by cutoff\",\n",
    "    xaxis_title=\"cutoff\",\n",
    "    yaxis_title=metric_col,\n",
    "    height=380,\n",
    ")\n",
    "fig"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Reduction to regression\n",
    "\n",
    "For ML pipelines, `make_reduction` wraps a standard regressor to forecast using lagged windows. This\n",
    "is a simple path to tree-based or linear models without manual feature engineering.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sktime.forecasting.compose import make_reduction\n",
    "\n",
    "reduction_forecaster = make_reduction(\n",
    "    RandomForestRegressor(n_estimators=200, random_state=7),\n",
    "    strategy=\"recursive\",\n",
    "    window_length=24,\n",
    ")\n",
    "\n",
    "reduction_forecaster.fit(y_train)\n",
    "y_pred_ml = reduction_forecaster.predict(fh)\n",
    "mae_ml = mean_absolute_error(y_test, y_pred_ml)\n",
    "\n",
    "print(f\"Reduction forecaster MAE: {mae_ml:.3f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=test_idx, y=y_test, mode=\"lines\", name=\"Test\", line=dict(color=\"#ff7f0e\")))\n",
    "fig.add_trace(go.Scatter(x=pred_idx, y=y_pred, mode=\"lines\", name=\"Theta pipeline\", line=dict(color=\"#2ca02c\")))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_pred_ml.index.to_timestamp(),\n",
    "        y=y_pred_ml,\n",
    "        mode=\"lines\",\n",
    "        name=\"Reduction (RF)\",\n",
    "        line=dict(color=\"#9467bd\", dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "fig.update_layout(title=\"Comparing pipeline vs reduction forecasts\", xaxis_title=\"time\", yaxis_title=\"value\", height=420)\n",
    "fig"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical checklist\n",
    "\n",
    "- Choose transforms that match the data (variance stabilization, seasonality, trend).\n",
    "- Fit transforms **inside** the pipeline so backtesting avoids leakage.\n",
    "- Use expanding windows for stable processes; sliding windows for non-stationary regimes.\n",
    "- Track multiple metrics (MAE, MAPE, MASE) to see sensitivity to scale and outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "- sktime user guide and forecasting tutorials (pipelines, reduction, backtesting)\n",
    "- scikit-learn pipeline patterns for transformers + estimators\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}