{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning â€” Overview\n",
    "\n",
    "## Purpose\n",
    "- Learn hierarchical representations with neural networks.\n",
    "- Scale modeling capacity with data and compute.\n",
    "- Reduce manual feature engineering for complex signals.\n",
    "\n",
    "## Key questions this section answers\n",
    "- Which architecture fits the data (CNN, RNN, Transformer)?\n",
    "- How do we optimize and regularize large models?\n",
    "- How do we monitor training and avoid overfitting?\n",
    "\n",
    "## Topics\n",
    "- MLPs, CNNs, RNNs/LSTMs/GRUs, Transformers\n",
    "- Embeddings and representation learning\n",
    "- Optimization (SGD, Adam) and learning-rate schedules\n",
    "- Regularization (dropout, weight decay, augmentation)\n",
    "- Loss functions, metrics, and debugging\n",
    "- Deployment and inference efficiency\n",
    "\n",
    "## References\n",
    "- PyTorch, TensorFlow, Keras; Goodfellow et al., \"Deep Learning\"\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "x = np.linspace(-5, 5, 400)\n",
    "sigmoid = 1 / (1 + np.exp(-x))\n",
    "tanh = np.tanh(x)\n",
    "relu = np.maximum(0, x)\n",
    "gelu = 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x**3)))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=sigmoid, name=\"sigmoid\"))\n",
    "fig.add_trace(go.Scatter(x=x, y=tanh, name=\"tanh\"))\n",
    "fig.add_trace(go.Scatter(x=x, y=relu, name=\"ReLU\"))\n",
    "fig.add_trace(go.Scatter(x=x, y=gelu, name=\"GELU\"))\n",
    "fig.update_layout(\n",
    "    title=\"Common activation functions\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"activation(x)\",\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaway\n",
    "Depth adds expressive power, but training stability and data scale become critical.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}