{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd15fae7",
   "metadata": {},
   "source": [
    "# Residual Networks (ResNets) for Image Data (from scratch NumPy + PyTorch)\n",
    "\n",
    "ResNets (Residual Networks) are a CNN architecture built around one core idea:\n",
    "\n",
    "- learn **residual updates** and add them back with a **skip connection**:  \\(y = x + F(x)\\)\n",
    "\n",
    "Why this matters:\n",
    "\n",
    "- deeper networks become much easier to optimize (better gradient flow)\n",
    "- blocks can fall back to the identity map when extra depth isn't needed\n",
    "\n",
    "This notebook includes a quick CNN recap. For a more CNN-first introduction, see:\n",
    "\n",
    "- `../cnn/00_overview.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "By the end you should be able to:\n",
    "\n",
    "- explain the ResNet block and why skip connections help\n",
    "- implement and train a tiny ResNet-like model in **pure NumPy** (manual backprop)\n",
    "- implement the same idea in **PyTorch** and visualize training and predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e973d",
   "metadata": {},
   "source": [
    "## Notebook roadmap\n",
    "\n",
    "1. Data: load a small image dataset (no downloads)\n",
    "2. Intuition: convolution, filters, and parameter counts\n",
    "3. ResNet intuition: why skip connections help\n",
    "4. From scratch (NumPy): Conv2D + ReLU + residual block + training loop\n",
    "5. Visual diagnostics (NumPy): filters, feature maps, confusion matrix\n",
    "6. Practical (PyTorch): same model idea with autograd\n",
    "7. Pitfalls + exercises\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514a91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    TORCH_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    TORCH_AVAILABLE = False\n",
    "    _TORCH_IMPORT_ERROR = e\n",
    "\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a18acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run configuration ---\n",
    "FAST_RUN = True  # set False for better accuracy / more epochs\n",
    "\n",
    "EPOCHS_NUMPY = 10 if FAST_RUN else 40\n",
    "EPOCHS_TORCH = 10 if FAST_RUN else 30\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LR_NUMPY = 0.05\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "LR_TORCH = 1e-3\n",
    "\n",
    "RUN_GRAD_CHECK = False  # optional (slow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8377330f",
   "metadata": {},
   "source": [
    "## 1) Data: a tiny image dataset (8×8 handwritten digits)\n",
    "\n",
    "To keep this notebook **offline-friendly**, we use `sklearn.datasets.load_digits()`:\n",
    "\n",
    "- 1 channel (grayscale)\n",
    "- 8×8 images\n",
    "- 10 classes (0–9)\n",
    "\n",
    "Even though this is much smaller than ImageNet, it's perfect for understanding the mechanics of CNNs/ResNets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a7ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.images.astype(np.float32)  # (N, 8, 8)\n",
    "y = digits.target.astype(np.int64)\n",
    "\n",
    "# Normalize pixels roughly into [0, 1]\n",
    "X = X / 16.0\n",
    "\n",
    "# Add channel dimension: (N, C=1, H, W)\n",
    "X = X[:, None, :, :]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "print('X_train', X_train.shape, 'X_test', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87263aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a grid of sample images\n",
    "\n",
    "idx = rng.choice(len(X_train), size=36, replace=False)\n",
    "imgs = X_train[idx, 0]  # (36, 8, 8)\n",
    "labels = y_train[idx]\n",
    "\n",
    "fig = px.imshow(\n",
    "    imgs,\n",
    "    facet_col=0,\n",
    "    facet_col_wrap=9,\n",
    "    color_continuous_scale='gray',\n",
    "    title='Sample training images (8×8)',\n",
    ")\n",
    "\n",
    "# Remove axis ticks for small multiples\n",
    "for a in fig.layout.annotations:\n",
    "    a.text = ''\n",
    "fig.update_xaxes(showticklabels=False).update_yaxes(showticklabels=False)\n",
    "fig.update_layout(coloraxis_showscale=False, margin=dict(l=10, r=10, t=60, b=10))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d38cd28",
   "metadata": {},
   "source": [
    "## 2) Convolution intuition (filters as pattern detectors)\n",
    "\n",
    "In deep learning, \"convolution\" is usually implemented as **cross-correlation** (we *don’t* flip the kernel):\n",
    "\n",
    "\\[\n",
    "y[n, c_{out}, i, j] = b[c_{out}] + \\sum_{c_{in}} \\sum_{u=0}^{kH-1} \\sum_{v=0}^{kW-1}\n",
    "  x[n, c_{in}, i+u, j+v]\\, W[c_{out}, c_{in}, u, v]\n",
    "\\]\n",
    "\n",
    "Why this is powerful:\n",
    "\n",
    "- **Local receptive fields**: each output looks at a small patch.\n",
    "- **Weight sharing**: the *same* kernel weights are reused at every location → far fewer parameters.\n",
    "\n",
    "Key knobs:\n",
    "\n",
    "- **Kernel size** (e.g. 3×3): how much local context a filter sees at once\n",
    "- **Padding**: whether we keep spatial size (\"same\") or shrink (\"valid\")\n",
    "- **Stride**: step size when sliding the kernel\n",
    "- **Channels**: multiple input and output feature maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6abf331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter count: dense vs conv\n",
    "#\n",
    "# Suppose we map an 8×8 image (64 pixels) to 8 feature maps (still 8×8).\n",
    "# - A dense layer would connect every input pixel to every output pixel.\n",
    "# - A conv layer uses a small kernel shared across space.\n",
    "\n",
    "def n_params_dense(fan_in: int, fan_out: int) -> int:\n",
    "    return fan_in * fan_out + fan_out\n",
    "\n",
    "\n",
    "def n_params_conv2d(c_in: int, c_out: int, k: int) -> int:\n",
    "    return c_out * (c_in * k * k) + c_out\n",
    "\n",
    "\n",
    "dense = n_params_dense(64, 64 * 8)\n",
    "conv = n_params_conv2d(c_in=1, c_out=8, k=3)\n",
    "\n",
    "_df = pd.DataFrame(\n",
    "    [\n",
    "        {'layer': 'Dense (64 → 512)', 'params': dense},\n",
    "        {'layer': 'Conv2D (1→8, 3×3)', 'params': conv},\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig = px.bar(\n",
    "    _df,\n",
    "    x='layer',\n",
    "    y='params',\n",
    "    text='params',\n",
    "    title='Parameter count: dense vs convolution (weight sharing)',\n",
    ")\n",
    "fig.update_traces(textposition='outside')\n",
    "fig.update_layout(yaxis_title='number of parameters')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d245b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c180355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_single_channel_naive(img: np.ndarray, kernel: np.ndarray, padding: int = 0, stride: int = 1) -> np.ndarray:\n",
    "    img = np.asarray(img, dtype=np.float32)\n",
    "    kernel = np.asarray(kernel, dtype=np.float32)\n",
    "\n",
    "    H, W = img.shape\n",
    "    kH, kW = kernel.shape\n",
    "\n",
    "    if padding > 0:\n",
    "        img_p = np.pad(img, ((padding, padding), (padding, padding)), mode='constant')\n",
    "    else:\n",
    "        img_p = img\n",
    "\n",
    "    Hp, Wp = img_p.shape\n",
    "    out_h = (Hp - kH) // stride + 1\n",
    "    out_w = (Wp - kW) // stride + 1\n",
    "\n",
    "    out = np.zeros((out_h, out_w), dtype=np.float32)\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            patch = img_p[i*stride:i*stride+kH, j*stride:j*stride+kW]\n",
    "            out[i, j] = float(np.sum(patch * kernel))\n",
    "    return out\n",
    "\n",
    "\n",
    "# Pick one image\n",
    "img = X_train[0, 0]\n",
    "\n",
    "# Two classic \"edge\" kernels\n",
    "kx = np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=np.float32)\n",
    "ky = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=np.float32)\n",
    "\n",
    "fx = conv2d_single_channel_naive(img, kx, padding=1)\n",
    "fy = conv2d_single_channel_naive(img, ky, padding=1)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=3, subplot_titles=['Input', 'Horizontal edges', 'Vertical edges'])\n",
    "\n",
    "fig.add_trace(go.Heatmap(z=img, colorscale='gray', showscale=False), row=1, col=1)\n",
    "fig.add_trace(go.Heatmap(z=fx, colorscale='RdBu', zmid=0, showscale=False), row=1, col=2)\n",
    "fig.add_trace(go.Heatmap(z=fy, colorscale='RdBu', zmid=0, showscale=False), row=1, col=3)\n",
    "\n",
    "fig.update_layout(title='A toy convolution demo (naive implementation)', height=320, margin=dict(l=10, r=10, t=60, b=10))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e1f0c4",
   "metadata": {},
   "source": [
    "## 3) ResNet intuition: why skip connections help\n",
    "\n",
    "A common surprise with deep networks is the **degradation problem**:\n",
    "\n",
    "- as you add more layers, the **training** error can get *worse* (even if overfitting isn’t the issue).\n",
    "\n",
    "A residual block changes the learning target. Instead of learning a full mapping \\(H(x)\\), it learns a *residual* \\(F(x)\\):\n",
    "\n",
    "\\[\n",
    "y = x + F(x;\theta)\n",
    "\\]\n",
    "\n",
    "Why this helps:\n",
    "\n",
    "- **Easy identity**: if the extra layers aren’t useful, set \\(F(x)=0\\) and the block behaves like the identity.\n",
    "- **Better gradient flow**: the skip path gives a direct route for gradients.\n",
    "\n",
    "A quick gradient sketch (informal):\n",
    "\n",
    "\\[\n",
    "\f",
    "rac{\\partial \\mathcal{L}}{\\partial x} = \f",
    "rac{\\partial \\mathcal{L}}{\\partial y}\\,\\Big(I + \f",
    "rac{\\partial F}{\\partial x}\\Big)\n",
    "\\]\n",
    "\n",
    "The identity term \\(I\\) means gradients don’t have to pass *only* through \\(F\\), which makes optimization easier in practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3b9cc9",
   "metadata": {},
   "source": [
    "## 4) From scratch in NumPy: a tiny residual CNN\n",
    "\n",
    "In this section we implement a small CNN/ResNet-like model **without autograd**:\n",
    "\n",
    "- `Conv2D` forward + backward (via `im2col` / `col2im`)\n",
    "- `ReLU`, `MaxPool2D`, `Flatten`, `Linear`\n",
    "- a `ResidualBlock`: \\(y = \\mathrm{ReLU}(x + F(x))\\)\n",
    "- softmax cross-entropy loss\n",
    "- SGD with momentum\n",
    "\n",
    "This is not meant to be the fastest implementation — it's meant to be readable and faithful to the math.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446d7a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "def _pad2d(x: np.ndarray, pad: int) -> np.ndarray:\n",
    "    if pad <= 0:\n",
    "        return x\n",
    "    return np.pad(x, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant')\n",
    "\n",
    "\n",
    "def im2col(x: np.ndarray, kH: int, kW: int, stride: int, pad: int) -> tuple[np.ndarray, tuple[int,int,int,int]]:\n",
    "    \"\"\"\n",
    "    x: (N, C, H, W)\n",
    "    Returns:\n",
    "      cols: (N*out_h*out_w, C*kH*kW)\n",
    "      out_shape: (out_h, out_w, H_padded, W_padded) for col2im\n",
    "    \"\"\"\n",
    "    N, C, H, W = x.shape\n",
    "    x_p = _pad2d(x, pad)\n",
    "    _, _, Hp, Wp = x_p.shape\n",
    "\n",
    "    out_h = (Hp - kH) // stride + 1\n",
    "    out_w = (Wp - kW) // stride + 1\n",
    "\n",
    "    cols = np.empty((N, C, kH, kW, out_h, out_w), dtype=x.dtype)\n",
    "\n",
    "    for i in range(kH):\n",
    "        i_end = i + stride * out_h\n",
    "        for j in range(kW):\n",
    "            j_end = j + stride * out_w\n",
    "            cols[:, :, i, j, :, :] = x_p[:, :, i:i_end:stride, j:j_end:stride]\n",
    "\n",
    "    cols = cols.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, C * kH * kW)\n",
    "    return cols, (out_h, out_w, Hp, Wp)\n",
    "\n",
    "\n",
    "def col2im(cols: np.ndarray, x_shape: tuple[int,int,int,int], kH: int, kW: int, stride: int, pad: int, out_shape: tuple[int,int,int,int]) -> np.ndarray:\n",
    "    N, C, H, W = x_shape\n",
    "    out_h, out_w, Hp, Wp = out_shape\n",
    "\n",
    "    cols_reshaped = cols.reshape(N, out_h, out_w, C, kH, kW).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    x_p = np.zeros((N, C, Hp, Wp), dtype=cols.dtype)\n",
    "\n",
    "    for i in range(kH):\n",
    "        i_end = i + stride * out_h\n",
    "        for j in range(kW):\n",
    "            j_end = j + stride * out_w\n",
    "            x_p[:, :, i:i_end:stride, j:j_end:stride] += cols_reshaped[:, :, i, j, :, :]\n",
    "\n",
    "    if pad <= 0:\n",
    "        return x_p\n",
    "    return x_p[:, :, pad:-pad, pad:-pad]\n",
    "\n",
    "\n",
    "class Conv2D:\n",
    "    def __init__(self, c_in: int, c_out: int, k: int, stride: int = 1, pad: int = 0, rng: np.random.Generator | None = None):\n",
    "        self.c_in = c_in\n",
    "        self.c_out = c_out\n",
    "        self.k = k\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "\n",
    "        rng = rng or np.random.default_rng(0)\n",
    "        scale = np.sqrt(2.0 / (c_in * k * k))  # He init for ReLU\n",
    "        self.W = (rng.standard_normal((c_out, c_in, k, k)).astype(np.float32) * scale)\n",
    "        self.b = np.zeros((c_out,), dtype=np.float32)\n",
    "\n",
    "        self.dW = np.zeros_like(self.W)\n",
    "        self.db = np.zeros_like(self.b)\n",
    "\n",
    "        self._cache = None\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        # x: (N, C_in, H, W)\n",
    "        cols, out_shape = im2col(x, self.k, self.k, self.stride, self.pad)\n",
    "        W_col = self.W.reshape(self.c_out, -1)\n",
    "        out = cols @ W_col.T + self.b[None, :]\n",
    "\n",
    "        N, _, H, W = x.shape\n",
    "        out_h, out_w, _, _ = out_shape\n",
    "        out = out.reshape(N, out_h, out_w, self.c_out).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self._cache = (x, cols, out_shape)\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout: np.ndarray) -> np.ndarray:\n",
    "        x, cols, out_shape = self._cache\n",
    "        N, C_in, H, W = x.shape\n",
    "\n",
    "        # dout: (N, C_out, out_h, out_w)\n",
    "        dout_col = dout.transpose(0, 2, 3, 1).reshape(-1, self.c_out)\n",
    "\n",
    "        self.db[...] = dout_col.sum(axis=0)\n",
    "\n",
    "        W_col = self.W.reshape(self.c_out, -1)\n",
    "        self.dW[...] = (dout_col.T @ cols).reshape(self.W.shape)\n",
    "\n",
    "        dcols = dout_col @ W_col\n",
    "        dx = col2im(dcols, x.shape, self.k, self.k, self.stride, self.pad, out_shape)\n",
    "        return dx\n",
    "\n",
    "    def step(self, lr: float, vW: np.ndarray, vb: np.ndarray, weight_decay: float) -> tuple[np.ndarray, np.ndarray]:\n",
    "        # SGD + momentum with weight decay\n",
    "        vW = MOMENTUM * vW - lr * (self.dW + weight_decay * self.W)\n",
    "        vb = MOMENTUM * vb - lr * self.db\n",
    "        self.W += vW\n",
    "        self.b += vb\n",
    "        return vW, vb\n",
    "\n",
    "\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self._mask = None\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        self._mask = x > 0\n",
    "        return x * self._mask\n",
    "\n",
    "    def backward(self, dout: np.ndarray) -> np.ndarray:\n",
    "        return dout * self._mask\n",
    "\n",
    "\n",
    "class MaxPool2D:\n",
    "    def __init__(self, pool: int = 2, stride: int = 2):\n",
    "        self.pool = pool\n",
    "        self.stride = stride\n",
    "        self._cache = None\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        N, C, H, W = x.shape\n",
    "        p, s = self.pool, self.stride\n",
    "        assert H % p == 0 and W % p == 0, 'For simplicity we assume H and W divisible by pool size.'\n",
    "\n",
    "        out_h, out_w = H // p, W // p\n",
    "        x_reshaped = x.reshape(N, C, out_h, p, out_w, p)\n",
    "        out = x_reshaped.max(axis=(3, 5))\n",
    "\n",
    "        self._cache = (x, x_reshaped, out)\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout: np.ndarray) -> np.ndarray:\n",
    "        x, x_reshaped, out = self._cache\n",
    "        N, C, out_h, p, out_w, _ = x_reshaped.shape\n",
    "\n",
    "        mask = x_reshaped == out[:, :, :, None, :, None]\n",
    "        denom = mask.sum(axis=(3, 5), keepdims=True)\n",
    "        denom = np.where(denom == 0, 1, denom)\n",
    "\n",
    "        dx_reshaped = mask * (dout[:, :, :, None, :, None] / denom)\n",
    "        dx = dx_reshaped.reshape(x.shape)\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Flatten:\n",
    "    def __init__(self):\n",
    "        self._shape = None\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        self._shape = x.shape\n",
    "        return x.reshape(x.shape[0], -1)\n",
    "\n",
    "    def backward(self, dout: np.ndarray) -> np.ndarray:\n",
    "        return dout.reshape(self._shape)\n",
    "\n",
    "\n",
    "class Linear:\n",
    "    def __init__(self, fan_in: int, fan_out: int, rng: np.random.Generator | None = None):\n",
    "        rng = rng or np.random.default_rng(0)\n",
    "        scale = np.sqrt(2.0 / fan_in)\n",
    "        self.W = (rng.standard_normal((fan_in, fan_out)).astype(np.float32) * scale)\n",
    "        self.b = np.zeros((fan_out,), dtype=np.float32)\n",
    "\n",
    "        self.dW = np.zeros_like(self.W)\n",
    "        self.db = np.zeros_like(self.b)\n",
    "\n",
    "        self._cache = None\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        self._cache = x\n",
    "        return x @ self.W + self.b\n",
    "\n",
    "    def backward(self, dout: np.ndarray) -> np.ndarray:\n",
    "        x = self._cache\n",
    "        self.dW[...] = x.T @ dout\n",
    "        self.db[...] = dout.sum(axis=0)\n",
    "        return dout @ self.W.T\n",
    "\n",
    "    def step(self, lr: float, vW: np.ndarray, vb: np.ndarray, weight_decay: float) -> tuple[np.ndarray, np.ndarray]:\n",
    "        vW = MOMENTUM * vW - lr * (self.dW + weight_decay * self.W)\n",
    "        vb = MOMENTUM * vb - lr * self.db\n",
    "        self.W += vW\n",
    "        self.b += vb\n",
    "        return vW, vb\n",
    "\n",
    "\n",
    "class ResidualBlock:\n",
    "    def __init__(self, channels: int, k: int = 3, pad: int = 1, rng: np.random.Generator | None = None):\n",
    "        rng = rng or np.random.default_rng(0)\n",
    "        self.conv1 = Conv2D(channels, channels, k=k, stride=1, pad=pad, rng=rng)\n",
    "        self.relu1 = ReLU()\n",
    "        self.conv2 = Conv2D(channels, channels, k=k, stride=1, pad=pad, rng=rng)\n",
    "        self.relu2 = ReLU()\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        out = self.conv1.forward(x)\n",
    "        out = self.relu1.forward(out)\n",
    "        out = self.conv2.forward(out)\n",
    "        out = out + x  # skip connection\n",
    "        out = self.relu2.forward(out)\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout: np.ndarray) -> np.ndarray:\n",
    "        dout = self.relu2.backward(dout)\n",
    "        dskip = dout  # gradient through identity path\n",
    "\n",
    "        dout = self.conv2.backward(dout)\n",
    "        dout = self.relu1.backward(dout)\n",
    "        dout = self.conv1.backward(dout)\n",
    "\n",
    "        dx = dout + dskip\n",
    "        return dx\n",
    "\n",
    "\n",
    "def softmax_cross_entropy(logits: np.ndarray, y: np.ndarray) -> tuple[float, np.ndarray]:\n",
    "    # logits: (N, K), y: (N,)\n",
    "    logits = logits.astype(np.float32)\n",
    "    logits = logits - logits.max(axis=1, keepdims=True)\n",
    "    exp = np.exp(logits)\n",
    "    probs = exp / exp.sum(axis=1, keepdims=True)\n",
    "\n",
    "    N = logits.shape[0]\n",
    "    loss = -np.log(probs[np.arange(N), y] + 1e-12).mean()\n",
    "\n",
    "    dlogits = probs\n",
    "    dlogits[np.arange(N), y] -= 1\n",
    "    dlogits /= N\n",
    "    return float(loss), dlogits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ef1516",
   "metadata": {},
   "source": [
    "### Optional: quick gradient check (small and slow)\n",
    "\n",
    "If you're writing low-level backprop code, a simple finite-difference gradient check helps catch mistakes.\n",
    "\n",
    "We keep this off by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b09a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_check_conv2d():\n",
    "    rng_local = np.random.default_rng(0)\n",
    "    x = rng_local.standard_normal((2, 1, 6, 6)).astype(np.float32)\n",
    "    conv = Conv2D(1, 2, k=3, stride=1, pad=1, rng=rng_local)\n",
    "\n",
    "    # Forward\n",
    "    out = conv.forward(x)\n",
    "    dout = rng_local.standard_normal(out.shape).astype(np.float32)\n",
    "    dx = conv.backward(dout)\n",
    "\n",
    "    # Numerical check for a few random weight entries\n",
    "    eps = 1e-3\n",
    "    for _ in range(10):\n",
    "        oc = int(rng_local.integers(0, conv.W.shape[0]))\n",
    "        ic = int(rng_local.integers(0, conv.W.shape[1]))\n",
    "        i = int(rng_local.integers(0, conv.W.shape[2]))\n",
    "        j = int(rng_local.integers(0, conv.W.shape[3]))\n",
    "\n",
    "        old = conv.W[oc, ic, i, j]\n",
    "\n",
    "        conv.W[oc, ic, i, j] = old + eps\n",
    "        out_p = conv.forward(x)\n",
    "        loss_p = float((out_p * dout).sum())\n",
    "\n",
    "        conv.W[oc, ic, i, j] = old - eps\n",
    "        out_m = conv.forward(x)\n",
    "        loss_m = float((out_m * dout).sum())\n",
    "\n",
    "        conv.W[oc, ic, i, j] = old\n",
    "\n",
    "        num = (loss_p - loss_m) / (2 * eps)\n",
    "        ana = float(conv.dW[oc, ic, i, j])\n",
    "        rel_err = abs(num - ana) / (abs(num) + abs(ana) + 1e-12)\n",
    "        print(f'W[{oc},{ic},{i},{j}]  num={num:.5f}  ana={ana:.5f}  rel_err={rel_err:.3e}')\n",
    "\n",
    "\n",
    "if RUN_GRAD_CHECK:\n",
    "    grad_check_conv2d()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c049fba1",
   "metadata": {},
   "source": [
    "### Train the NumPy model\n",
    "\n",
    "Model (tiny ResNet-ish CNN):\n",
    "\n",
    "- Conv(1→8, 3×3, pad=1) + ReLU\n",
    "- ResidualBlock(8 channels)\n",
    "- MaxPool(2×2)\n",
    "- Flatten\n",
    "- Linear(8·4·4 → 10)\n",
    "\n",
    "We track loss and accuracy each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d0d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "rng_model = np.random.default_rng(SEED)\n",
    "\n",
    "conv1 = Conv2D(1, 8, k=3, stride=1, pad=1, rng=rng_model)\n",
    "relu1 = ReLU()\n",
    "res1 = ResidualBlock(8, k=3, pad=1, rng=rng_model)\n",
    "pool = MaxPool2D(pool=2, stride=2)\n",
    "flat = Flatten()\n",
    "fc = Linear(8 * 4 * 4, 10, rng=rng_model)\n",
    "\n",
    "# Momentum buffers\n",
    "v_conv1_W = np.zeros_like(conv1.W)\n",
    "v_conv1_b = np.zeros_like(conv1.b)\n",
    "\n",
    "v_res1_c1_W = np.zeros_like(res1.conv1.W)\n",
    "v_res1_c1_b = np.zeros_like(res1.conv1.b)\n",
    "v_res1_c2_W = np.zeros_like(res1.conv2.W)\n",
    "v_res1_c2_b = np.zeros_like(res1.conv2.b)\n",
    "\n",
    "v_fc_W = np.zeros_like(fc.W)\n",
    "v_fc_b = np.zeros_like(fc.b)\n",
    "\n",
    "\n",
    "def forward_numpy(xb: np.ndarray) -> np.ndarray:\n",
    "    out = conv1.forward(xb)\n",
    "    out = relu1.forward(out)\n",
    "    out = res1.forward(out)\n",
    "    out = pool.forward(out)\n",
    "    out = flat.forward(out)\n",
    "    out = fc.forward(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def backward_numpy(dlogits: np.ndarray) -> None:\n",
    "    dout = fc.backward(dlogits)\n",
    "    dout = flat.backward(dout)\n",
    "    dout = pool.backward(dout)\n",
    "    dout = res1.backward(dout)\n",
    "    dout = relu1.backward(dout)\n",
    "    _ = conv1.backward(dout)\n",
    "\n",
    "\n",
    "def step_numpy(lr: float) -> None:\n",
    "    global v_conv1_W, v_conv1_b\n",
    "    global v_res1_c1_W, v_res1_c1_b, v_res1_c2_W, v_res1_c2_b\n",
    "    global v_fc_W, v_fc_b\n",
    "\n",
    "    v_conv1_W, v_conv1_b = conv1.step(lr, v_conv1_W, v_conv1_b, WEIGHT_DECAY)\n",
    "\n",
    "    v_res1_c1_W, v_res1_c1_b = res1.conv1.step(lr, v_res1_c1_W, v_res1_c1_b, WEIGHT_DECAY)\n",
    "    v_res1_c2_W, v_res1_c2_b = res1.conv2.step(lr, v_res1_c2_W, v_res1_c2_b, WEIGHT_DECAY)\n",
    "\n",
    "    v_fc_W, v_fc_b = fc.step(lr, v_fc_W, v_fc_b, WEIGHT_DECAY)\n",
    "\n",
    "\n",
    "def predict_numpy(x: np.ndarray) -> np.ndarray:\n",
    "    logits = forward_numpy(x)\n",
    "    return logits.argmax(axis=1)\n",
    "\n",
    "\n",
    "def iterate_minibatches(X_: np.ndarray, y_: np.ndarray, batch_size: int, rng_: np.random.Generator):\n",
    "    idx = rng_.permutation(len(X_))\n",
    "    for start in range(0, len(X_), batch_size):\n",
    "        sl = idx[start:start + batch_size]\n",
    "        yield X_[sl], y_[sl]\n",
    "\n",
    "\n",
    "history_numpy = []\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(1, EPOCHS_NUMPY + 1):\n",
    "    # Train\n",
    "    losses = []\n",
    "    for xb, yb in iterate_minibatches(X_train, y_train, BATCH_SIZE, rng):\n",
    "        logits = forward_numpy(xb)\n",
    "        loss, dlogits = softmax_cross_entropy(logits, yb)\n",
    "        losses.append(loss)\n",
    "\n",
    "        backward_numpy(dlogits)\n",
    "        step_numpy(LR_NUMPY)\n",
    "\n",
    "    # Eval\n",
    "    yhat_train = predict_numpy(X_train)\n",
    "    yhat_test = predict_numpy(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, yhat_train)\n",
    "    test_acc = accuracy_score(y_test, yhat_test)\n",
    "\n",
    "    history_numpy.append({\n",
    "        'epoch': epoch,\n",
    "        'loss': float(np.mean(losses)),\n",
    "        'train_acc': float(train_acc),\n",
    "        'test_acc': float(test_acc),\n",
    "    })\n",
    "\n",
    "    print(f\"[NumPy] epoch {epoch:02d}/{EPOCHS_NUMPY}  loss={history_numpy[-1]['loss']:.4f}  train_acc={train_acc:.3f}  test_acc={test_acc:.3f}\")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"NumPy training time: {elapsed:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63260f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = pd.DataFrame(history_numpy)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=dfn['epoch'], y=dfn['loss'], mode='lines+markers', name='loss'))\n",
    "fig.update_layout(title='NumPy training loss', xaxis_title='epoch', yaxis_title='cross-entropy')\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=dfn['epoch'], y=dfn['train_acc'], mode='lines+markers', name='train'))\n",
    "fig.add_trace(go.Scatter(x=dfn['epoch'], y=dfn['test_acc'], mode='lines+markers', name='test'))\n",
    "fig.update_layout(title='NumPy accuracy', xaxis_title='epoch', yaxis_title='accuracy', yaxis=dict(range=[0,1]))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70bdc69",
   "metadata": {},
   "source": [
    "## 5) Visual diagnostics (NumPy)\n",
    "\n",
    "A few quick sanity checks that often help with CNNs:\n",
    "\n",
    "- learned **filters** in the first conv layer\n",
    "- **feature maps** (activations) for a single image\n",
    "- confusion matrix and misclassifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1185ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First-layer filters: (8, 1, 3, 3)\n",
    "W1 = conv1.W[:, 0]  # (8, 3, 3)\n",
    "\n",
    "fig = px.imshow(\n",
    "    W1,\n",
    "    facet_col=0,\n",
    "    facet_col_wrap=4,\n",
    "    color_continuous_scale='RdBu',\n",
    "    zmin=float(W1.min()),\n",
    "    zmax=float(W1.max()),\n",
    "    title='NumPy: learned Conv1 filters (3×3)',\n",
    ")\n",
    "for a in fig.layout.annotations:\n",
    "    a.text = ''\n",
    "fig.update_layout(coloraxis_showscale=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature maps after the first conv+relu (before residual block)\n",
    "\n",
    "x0 = X_test[0:1]\n",
    "\n",
    "out1 = relu1.forward(conv1.forward(x0))  # (1, 8, 8, 8)\n",
    "\n",
    "fig = px.imshow(\n",
    "    out1[0],\n",
    "    facet_col=0,\n",
    "    facet_col_wrap=4,\n",
    "    color_continuous_scale='Viridis',\n",
    "    title='NumPy: feature maps after Conv1 + ReLU (one test image)',\n",
    ")\n",
    "for a in fig.layout.annotations:\n",
    "    a.text = ''\n",
    "fig.update_layout(coloraxis_showscale=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa8707",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = predict_numpy(X_test)\n",
    "cm = confusion_matrix(y_test, yhat, labels=list(range(10)))\n",
    "\n",
    "fig = px.imshow(\n",
    "    cm,\n",
    "    text_auto=True,\n",
    "    color_continuous_scale='Blues',\n",
    "    title='NumPy: confusion matrix (test set)',\n",
    "    labels=dict(x='pred', y='true', color='count'),\n",
    ")\n",
    "fig.update_xaxes(tickmode='array', tickvals=list(range(10)))\n",
    "fig.update_yaxes(tickmode='array', tickvals=list(range(10)))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a327fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick look at some NumPy misclassifications\n",
    "\n",
    "yhat = predict_numpy(X_test)\n",
    "mis = np.where(yhat != y_test)[0]\n",
    "\n",
    "n_show = min(36, len(mis))\n",
    "mis = mis[:n_show]\n",
    "\n",
    "imgs = X_test[mis, 0]\n",
    "texts = [f\"true={int(y_test[i])}, pred={int(yhat[i])}\" for i in mis]\n",
    "\n",
    "fig = px.imshow(\n",
    "    imgs,\n",
    "    facet_col=0,\n",
    "    facet_col_wrap=9,\n",
    "    color_continuous_scale='gray',\n",
    "    title=f'NumPy: misclassified test images (first {n_show})',\n",
    ")\n",
    "\n",
    "for a, t in zip(fig.layout.annotations, texts):\n",
    "    a.text = t\n",
    "\n",
    "fig.update_xaxes(showticklabels=False).update_yaxes(showticklabels=False)\n",
    "fig.update_layout(coloraxis_showscale=False, margin=dict(l=10, r=10, t=60, b=10))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe8837a",
   "metadata": {},
   "source": [
    "## 6) Practical implementation in PyTorch\n",
    "\n",
    "Now we implement the same *idea* in PyTorch:\n",
    "\n",
    "- define a small residual CNN using `nn.Module`\n",
    "- train with Adam\n",
    "- visualize curves and a few predictions\n",
    "\n",
    "Compared to NumPy, PyTorch gives you:\n",
    "\n",
    "- automatic differentiation (autograd)\n",
    "- optimized kernels\n",
    "- higher-level building blocks (Conv2d, BatchNorm, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20773d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TORCH_AVAILABLE:\n",
    "    raise RuntimeError(f\"PyTorch not available: {_TORCH_IMPORT_ERROR}\")\n",
    "\n",
    "# Device (suppress noisy CUDA init warnings in restricted environments)\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore', message='CUDA initialization:.*')\n",
    "    cuda_ok = bool(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device('cuda' if cuda_ok else 'cpu')\n",
    "print('device:', device)\n",
    "\n",
    "# Tensors\n",
    "Xtr = torch.from_numpy(X_train).to(device)\n",
    "ytr = torch.from_numpy(y_train).to(device)\n",
    "Xte = torch.from_numpy(X_test).to(device)\n",
    "yte = torch.from_numpy(y_test).to(device)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(Xtr, ytr), batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_eval_loader = DataLoader(TensorDataset(Xtr, ytr), batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(Xte, yte), batch_size=256, shuffle=False)\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ch: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(ch, ch, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(ch)\n",
    "        self.conv2 = nn.Conv2d(ch, ch, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = F.relu(out + x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class TinyResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.block1 = ResBlock(16)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.head = nn.Linear(16 * 4 * 4, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.flatten(1)\n",
    "        return self.head(x)\n",
    "\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "model = TinyResNet().to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR_TORCH, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "\n",
    "def eval_loader(loader):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    yhats = []\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            logits = model(xb)\n",
    "            loss = F.cross_entropy(logits, yb)\n",
    "            losses.append(loss.item())\n",
    "            ys.append(yb.detach().cpu().numpy())\n",
    "            yhats.append(logits.argmax(dim=1).detach().cpu().numpy())\n",
    "    y_all = np.concatenate(ys)\n",
    "    yhat_all = np.concatenate(yhats)\n",
    "    return float(np.mean(losses)), float(accuracy_score(y_all, yhat_all))\n",
    "\n",
    "\n",
    "history_torch = []\n",
    "start = time.time()\n",
    "for epoch in range(1, EPOCHS_TORCH + 1):\n",
    "    model.train()\n",
    "    batch_losses = []\n",
    "    for xb, yb in train_loader:\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        logits = model(xb)\n",
    "        loss = F.cross_entropy(logits, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "    train_loss, train_acc = eval_loader(train_eval_loader)\n",
    "    test_loss, test_acc = eval_loader(test_loader)\n",
    "\n",
    "    history_torch.append({\n",
    "        'epoch': epoch,\n",
    "        'loss': float(np.mean(batch_losses)),\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'train_loss_eval': train_loss,\n",
    "        'test_loss_eval': test_loss,\n",
    "    })\n",
    "    print(f\"[Torch] epoch {epoch:02d}/{EPOCHS_TORCH}  loss={history_torch[-1]['loss']:.4f}  train_acc={train_acc:.3f}  test_acc={test_acc:.3f}\")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Torch training time: {elapsed:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.DataFrame(history_torch)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=dft['epoch'], y=dft['loss'], mode='lines+markers', name='train_loss(batch)'))\n",
    "fig.add_trace(go.Scatter(x=dft['epoch'], y=dft['test_loss_eval'], mode='lines+markers', name='test_loss'))\n",
    "fig.update_layout(title='Torch loss', xaxis_title='epoch', yaxis_title='cross-entropy')\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=dft['epoch'], y=dft['train_acc'], mode='lines+markers', name='train'))\n",
    "fig.add_trace(go.Scatter(x=dft['epoch'], y=dft['test_acc'], mode='lines+markers', name='test'))\n",
    "fig.update_layout(title='Torch accuracy', xaxis_title='epoch', yaxis_title='accuracy', yaxis=dict(range=[0,1]))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f3e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(Xte)\n",
    "    yhat = logits.argmax(dim=1).detach().cpu().numpy()\n",
    "\n",
    "cm = confusion_matrix(y_test, yhat, labels=list(range(10)))\n",
    "\n",
    "fig = px.imshow(\n",
    "    cm,\n",
    "    text_auto=True,\n",
    "    color_continuous_scale='Blues',\n",
    "    title='Torch: confusion matrix (test set)',\n",
    "    labels=dict(x='pred', y='true', color='count'),\n",
    ")\n",
    "fig.update_xaxes(tickmode='array', tickvals=list(range(10)))\n",
    "fig.update_yaxes(tickmode='array', tickvals=list(range(10)))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d6d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick look at some Torch misclassifications\n",
    "\n",
    "# yhat is produced in the confusion-matrix cell above\n",
    "mis = np.where(yhat != y_test)[0]\n",
    "\n",
    "n_show = min(36, len(mis))\n",
    "mis = mis[:n_show]\n",
    "\n",
    "imgs = X_test[mis, 0]\n",
    "texts = [f\"true={int(y_test[i])}, pred={int(yhat[i])}\" for i in mis]\n",
    "\n",
    "fig = px.imshow(\n",
    "    imgs,\n",
    "    facet_col=0,\n",
    "    facet_col_wrap=9,\n",
    "    color_continuous_scale='gray',\n",
    "    title=f'Torch: misclassified test images (first {n_show})',\n",
    ")\n",
    "\n",
    "for a, t in zip(fig.layout.annotations, texts):\n",
    "    a.text = t\n",
    "\n",
    "fig.update_xaxes(showticklabels=False).update_yaxes(showticklabels=False)\n",
    "fig.update_layout(coloraxis_showscale=False, margin=dict(l=10, r=10, t=60, b=10))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6630453",
   "metadata": {},
   "source": [
    "## 7) NumPy vs PyTorch (what to take away)\n",
    "\n",
    "- **NumPy from scratch** forces you to understand tensor shapes, gradients, and the mechanics of convolution.\n",
    "- **PyTorch** lets you scale up: larger models, bigger datasets, GPUs, and a huge ecosystem.\n",
    "\n",
    "On real vision tasks you almost always prototype/iterate in PyTorch (or similar), but knowing what happens under the hood makes you better at debugging and designing models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee52cfa3",
   "metadata": {},
   "source": [
    "## Pitfalls + diagnostics\n",
    "\n",
    "- If training is unstable: lower the learning rate, check initialization, and verify your loss/gradients.\n",
    "- If accuracy saturates early: try more channels, add another residual block, or train longer.\n",
    "- If NumPy training is very slow: reduce epochs, reduce channels, or use fewer samples.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Add a second residual block and compare curves.\n",
    "2. Replace MaxPool with a strided convolution.\n",
    "3. Add dropout in the PyTorch head.\n",
    "4. (Advanced) Implement BatchNorm in NumPy.\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "- He et al., 2015: *Deep Residual Learning for Image Recognition*\n",
    "- CS231n notes on CNNs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
