{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d7ddc8",
   "metadata": {},
   "source": [
    "# Risk Management\n",
    "\n",
    "## Overview\n",
    "Risk management is the process of identifying, measuring, and mitigating financial risks. It aims to protect portfolios from adverse market movements while optimizing risk-adjusted returns.\n",
    "\n",
    "## Types of Financial Risk\n",
    "\n",
    "| Risk Type | Description | Example |\n",
    "|-----------|-------------|----------|\n",
    "| **Market Risk** | Price movements in equities, rates, FX, commodities | Stock market crash |\n",
    "| **Credit Risk** | Counterparty default or downgrade | Bond issuer bankruptcy |\n",
    "| **Liquidity Risk** | Inability to trade without price impact | Illiquid bond during crisis |\n",
    "| **Operational Risk** | System failures, fraud, human error | Trading system outage |\n",
    "| **Model Risk** | Incorrect model assumptions | VaR underestimation |\n",
    "\n",
    "## Value at Risk (VaR)\n",
    "\n",
    "VaR answers: *\"What is the maximum loss over a given period with a specified confidence level?\"*\n",
    "\n",
    "$$\\text{VaR}_{\\alpha} = -\\inf\\{x : P(L \\leq x) \\geq 1 - \\alpha\\}$$\n",
    "\n",
    "**Example:** A 1-day 99% VaR of $1M means there's a 1% chance of losing more than $1M in one day.\n",
    "\n",
    "### VaR Methods\n",
    "\n",
    "1. **Parametric (Variance-Covariance)**\n",
    "   $$\\text{VaR} = \\mu + z_\\alpha \\cdot \\sigma$$\n",
    "   - Assumes normal distribution\n",
    "   - Fast computation\n",
    "\n",
    "2. **Historical Simulation**\n",
    "   - Uses actual historical returns\n",
    "   - No distributional assumptions\n",
    "\n",
    "3. **Monte Carlo Simulation**\n",
    "   - Generates random scenarios\n",
    "   - Most flexible, computationally intensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bfff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate portfolio returns\n",
    "returns = np.random.normal(0.0005, 0.02, 1000)  # Daily returns\n",
    "\n",
    "# Calculate VaR at different confidence levels\n",
    "confidence_levels = [0.90, 0.95, 0.99]\n",
    "vars = {conf: np.percentile(returns, (1-conf)*100) for conf in confidence_levels}\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Histogram of returns\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=returns, nbinsx=50, name='Returns Distribution',\n",
    "    marker_color='rgba(52, 152, 219, 0.7)'\n",
    "))\n",
    "\n",
    "# VaR lines\n",
    "colors = ['#2ecc71', '#f39c12', '#e74c3c']\n",
    "for (conf, var), color in zip(vars.items(), colors):\n",
    "    fig.add_vline(x=var, line_dash='dash', line_color=color,\n",
    "                  annotation_text=f'{int(conf*100)}% VaR: {var*100:.2f}%')\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Portfolio Return Distribution with VaR',\n",
    "    xaxis_title='Daily Return', yaxis_title='Frequency',\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"VaR Summary (Portfolio Value = $10M):\")\n",
    "for conf, var in vars.items():\n",
    "    print(f\"  {int(conf*100)}% VaR: ${abs(var)*10_000_000:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3f9960",
   "metadata": {},
   "source": [
    "## Conditional VaR (Expected Shortfall)\n",
    "\n",
    "CVaR (or Expected Shortfall) measures the **expected loss given that the loss exceeds VaR**:\n",
    "\n",
    "$$\\text{CVaR}_\\alpha = E[L | L > \\text{VaR}_\\alpha]$$\n",
    "\n",
    "**Advantages over VaR:**\n",
    "- Considers tail severity, not just probability\n",
    "- Coherent risk measure (satisfies subadditivity)\n",
    "- Better captures extreme event risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2da683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VaR vs CVaR comparison\n",
    "def calculate_var_cvar(returns, confidence=0.95):\n",
    "    var = np.percentile(returns, (1-confidence)*100)\n",
    "    cvar = returns[returns <= var].mean()\n",
    "    return var, cvar\n",
    "\n",
    "# Normal vs Fat-tailed distribution\n",
    "normal_returns = np.random.normal(0, 0.02, 10000)\n",
    "fat_tail_returns = np.random.standard_t(df=3, size=10000) * 0.015  # t-distribution\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\n",
    "    'Normal Distribution', 'Fat-Tailed Distribution (t-dist, df=3)'\n",
    "))\n",
    "\n",
    "for idx, (returns_data, name) in enumerate([(normal_returns, 'Normal'), (fat_tail_returns, 'Fat-tailed')]):\n",
    "    var, cvar = calculate_var_cvar(returns_data, 0.95)\n",
    "    \n",
    "    fig.add_trace(go.Histogram(\n",
    "        x=returns_data, nbinsx=100, name=name,\n",
    "        marker_color='rgba(52, 152, 219, 0.6)'\n",
    "    ), row=1, col=idx+1)\n",
    "    \n",
    "    fig.add_vline(x=var, line_dash='dash', line_color='#f39c12', row=1, col=idx+1)\n",
    "    fig.add_vline(x=cvar, line_dash='solid', line_color='#e74c3c', row=1, col=idx+1)\n",
    "\n",
    "fig.update_layout(title='VaR (orange) vs CVaR (red) Comparison', template='plotly_white', showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "print(\"95% Confidence Metrics:\")\n",
    "print(f\"  Normal:     VaR={calculate_var_cvar(normal_returns)[0]*100:.2f}%, CVaR={calculate_var_cvar(normal_returns)[1]*100:.2f}%\")\n",
    "print(f\"  Fat-tailed: VaR={calculate_var_cvar(fat_tail_returns)[0]*100:.2f}%, CVaR={calculate_var_cvar(fat_tail_returns)[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fc571c",
   "metadata": {},
   "source": [
    "## Volatility Models\n",
    "\n",
    "### Historical Volatility\n",
    "$$\\sigma = \\sqrt{\\frac{252}{n-1} \\sum_{i=1}^{n} (r_i - \\bar{r})^2}$$\n",
    "\n",
    "### EWMA (Exponentially Weighted Moving Average)\n",
    "$$\\sigma_t^2 = \\lambda \\sigma_{t-1}^2 + (1-\\lambda) r_{t-1}^2$$\n",
    "\n",
    "RiskMetrics uses $\\lambda = 0.94$ for daily data.\n",
    "\n",
    "### GARCH(1,1)\n",
    "$$\\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2$$\n",
    "\n",
    "Captures volatility clustering (high volatility tends to follow high volatility)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc40cf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EWMA volatility estimation\n",
    "returns = np.random.normal(0, 0.02, 500)\n",
    "# Add volatility clustering\n",
    "for i in range(100, 150):\n",
    "    returns[i] *= 2  # High volatility period\n",
    "\n",
    "lambda_param = 0.94\n",
    "ewma_var = np.zeros(len(returns))\n",
    "ewma_var[0] = returns[0]**2\n",
    "\n",
    "for i in range(1, len(returns)):\n",
    "    ewma_var[i] = lambda_param * ewma_var[i-1] + (1 - lambda_param) * returns[i-1]**2\n",
    "\n",
    "ewma_vol = np.sqrt(ewma_var) * np.sqrt(252)  # Annualized\n",
    "\n",
    "# Rolling window volatility for comparison\n",
    "window = 20\n",
    "rolling_vol = np.array([np.std(returns[max(0,i-window):i]) * np.sqrt(252) if i > 0 else 0 for i in range(len(returns))])\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1, subplot_titles=('Returns', 'Volatility Estimates'))\n",
    "\n",
    "fig.add_trace(go.Scatter(y=returns, mode='lines', name='Returns', line=dict(color='#3498db')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(y=ewma_vol, mode='lines', name='EWMA Vol', line=dict(color='#e74c3c')), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(y=rolling_vol, mode='lines', name='Rolling Vol', line=dict(color='#2ecc71', dash='dash')), row=2, col=1)\n",
    "\n",
    "fig.update_layout(title='EWMA vs Rolling Volatility', template='plotly_white')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108ee508",
   "metadata": {},
   "source": [
    "## Stress Testing and Scenario Analysis\n",
    "\n",
    "### Historical Scenarios\n",
    "- 1987 Black Monday (-22.6%)\n",
    "- 2008 Financial Crisis\n",
    "- 2020 COVID Crash\n",
    "\n",
    "### Hypothetical Scenarios\n",
    "- Interest rate shock (+/- 200 bps)\n",
    "- Currency devaluation\n",
    "- Commodity price spike\n",
    "\n",
    "## Risk-Adjusted Performance Metrics\n",
    "\n",
    "| Metric | Formula | Interpretation |\n",
    "|--------|---------|----------------|\n",
    "| **Sharpe Ratio** | $\\frac{R_p - R_f}{\\sigma_p}$ | Return per unit of total risk |\n",
    "| **Sortino Ratio** | $\\frac{R_p - R_f}{\\sigma_{downside}}$ | Return per unit of downside risk |\n",
    "| **Information Ratio** | $\\frac{R_p - R_b}{\\sigma_{tracking}}$ | Active return per tracking error |\n",
    "| **Max Drawdown** | $\\max_t \\left(\\frac{\\text{Peak}_t - \\text{Trough}_t}{\\text{Peak}_t}\\right)$ | Largest peak-to-trough decline |\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **VaR has limitations** — Doesn't capture tail severity; use CVaR for coherent measure\n",
    "2. **Fat tails matter** — Financial returns are not normally distributed\n",
    "3. **Volatility clusters** — Use EWMA/GARCH for dynamic volatility estimation\n",
    "4. **Diversification reduces risk** — But correlations increase during crises\n",
    "5. **Stress test regularly** — Historical scenarios reveal portfolio vulnerabilities"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}