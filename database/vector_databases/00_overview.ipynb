{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e52ba0",
   "metadata": {},
   "source": [
    "# Vector Databases: Comprehensive Overview\n",
    "\n",
    "## Table of Contents\n",
    "1. [What Are Vector Databases?](#what-are-vector-databases)\n",
    "2. [Why Vector Databases Matter for AI](#why-they-matter)\n",
    "3. [Embeddings Basics](#embeddings-basics)\n",
    "4. [Similarity Metrics](#similarity-metrics)\n",
    "5. [Vector Database Solutions Comparison](#comparison)\n",
    "6. [Use Cases](#use-cases)\n",
    "7. [Code Examples](#code-examples)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebbd466",
   "metadata": {},
   "source": [
    "## 1. What Are Vector Databases? <a id='what-are-vector-databases'></a>\n",
    "\n",
    "A **vector database** is a specialized database designed to store, index, and query high-dimensional vectors (embeddings). Unlike traditional databases that excel at exact matches and range queries, vector databases are optimized for **similarity search** â€” finding the most similar items to a given query vector.\n",
    "\n",
    "### Traditional Database vs Vector Database\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    TRADITIONAL DATABASE                                      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  Query: SELECT * FROM products WHERE name = 'laptop'                        â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚\n",
    "â”‚  â”‚  Query   â”‚â”€â”€â”€â”€â–¶â”‚  B-Tree/Hash â”‚â”€â”€â”€â”€â–¶â”‚ Exact Match  â”‚                     â”‚\n",
    "â”‚  â”‚  'laptop'â”‚     â”‚    Index     â”‚     â”‚   Results    â”‚                     â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  Result: Rows where name exactly equals 'laptop'                            â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                      VECTOR DATABASE                                         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  Query: Find similar items to this image/text                               â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚  Input   â”‚â”€â”€â”€â”€â–¶â”‚  Embedding   â”‚â”€â”€â”€â”€â–¶â”‚  ANN Index   â”‚â”€â”€â”€â”€â–¶â”‚  Similar   â”‚  â”‚\n",
    "â”‚  â”‚  Data    â”‚     â”‚    Model     â”‚     â”‚ (HNSW/IVF)   â”‚     â”‚  Results   â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â”‚       â”‚                  â”‚                    â”‚                    â”‚         â”‚\n",
    "â”‚   \"laptop\"        [0.23, -0.45,         Similarity          Top-K nearest   â”‚\n",
    "â”‚                    0.67, ...]            Search              neighbors       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Key Characteristics\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **High-Dimensional Storage** | Store vectors with hundreds to thousands of dimensions |\n",
    "| **Approximate Nearest Neighbor (ANN)** | Trade small accuracy loss for massive speed gains |\n",
    "| **Metadata Filtering** | Combine vector similarity with attribute-based filtering |\n",
    "| **Real-time Updates** | Support for CRUD operations on vector data |\n",
    "| **Scalability** | Handle billions of vectors with distributed architectures |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43051996",
   "metadata": {},
   "source": [
    "## 2. Why Vector Databases Matter for AI <a id='why-they-matter'></a>\n",
    "\n",
    "### The AI/ML Revolution and Embeddings\n",
    "\n",
    "Modern AI systems represent data as **dense vectors** (embeddings) that capture semantic meaning:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     THE EMBEDDING PIPELINE                                   â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚   Raw Data                    Embedding Model               Vector Space    â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚   â”‚  Text   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚             â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ [0.2, -0.5,  â”‚  â”‚\n",
    "â”‚   â”‚ \"Hello\" â”‚                â”‚   BERT /    â”‚              â”‚  0.8, 0.1,   â”‚  â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚  OpenAI /   â”‚              â”‚  ...768 dim] â”‚  â”‚\n",
    "â”‚                              â”‚  Sentence   â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚ Transformersâ”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚   â”‚  Image  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚             â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ [0.9, 0.3,   â”‚  â”‚\n",
    "â”‚   â”‚   ğŸ–¼ï¸    â”‚                â”‚   CLIP /    â”‚              â”‚  -0.2, 0.7,  â”‚  â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚   ResNet    â”‚              â”‚  ...512 dim] â”‚  â”‚\n",
    "â”‚                              â”‚             â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚             â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚   â”‚  Audio  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Whisper /  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ [0.1, 0.8,   â”‚  â”‚\n",
    "â”‚   â”‚   ğŸµ    â”‚                â”‚   wav2vec   â”‚              â”‚  0.4, -0.6,  â”‚  â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  ...256 dim] â”‚  â”‚\n",
    "â”‚                                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚   Similar meaning â”€â”€â–¶ Similar vectors â”€â”€â–¶ Close in vector space             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Critical Role in Modern AI Applications\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                  RAG (Retrieval-Augmented Generation)                        â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚   User   â”‚â”€â”€â”€â–¶â”‚   Embed      â”‚â”€â”€â”€â–¶â”‚    Vector     â”‚â”€â”€â”€â–¶â”‚   Retrieve   â”‚  â”‚\n",
    "â”‚  â”‚  Query   â”‚    â”‚   Query      â”‚    â”‚    Search     â”‚    â”‚   Context    â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â”‚                                                                   â”‚          â”‚\n",
    "â”‚                                                                   â–¼          â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚ Response â”‚â—€â”€â”€â”€â”‚     LLM      â”‚â—€â”€â”€â”€â”‚   Augmented   â”‚â—€â”€â”€â”€â”‚   Relevant   â”‚  â”‚\n",
    "â”‚  â”‚          â”‚    â”‚   (GPT-4)    â”‚    â”‚    Prompt     â”‚    â”‚    Docs      â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  Why Vector DB?                                                              â”‚\n",
    "â”‚  â€¢ Fast retrieval from millions/billions of documents                        â”‚\n",
    "â”‚  â€¢ Semantic search (meaning, not just keywords)                              â”‚\n",
    "â”‚  â€¢ Reduces hallucinations by grounding LLM in facts                          â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Why Traditional Databases Fall Short\n",
    "\n",
    "| Challenge | Traditional DB | Vector DB |\n",
    "|-----------|---------------|----------|\n",
    "| **Similarity Search** | Full table scan O(n) | ANN indexing O(log n) |\n",
    "| **High Dimensions** | Curse of dimensionality | Optimized algorithms (HNSW, IVF) |\n",
    "| **Scale** | Performance degrades | Designed for billions of vectors |\n",
    "| **Semantic Understanding** | Keyword matching only | Meaning-based matching |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f1c46a",
   "metadata": {},
   "source": [
    "## 3. Embeddings Basics <a id='embeddings-basics'></a>\n",
    "\n",
    "### What Are Embeddings?\n",
    "\n",
    "**Embeddings** are dense numerical representations of data in a continuous vector space. They transform complex, unstructured data into fixed-size arrays of numbers that capture semantic relationships.\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    EMBEDDING SPACE VISUALIZATION                             â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚                              â–² Dimension 2                                   â”‚\n",
    "â”‚                              â”‚                                               â”‚\n",
    "â”‚                              â”‚    ğŸ• dog                                     â”‚\n",
    "â”‚                              â”‚         ğŸ± cat      (animals cluster)         â”‚\n",
    "â”‚                              â”‚    ğŸ¦ bird                                    â”‚\n",
    "â”‚                              â”‚                                               â”‚\n",
    "â”‚                              â”‚                                               â”‚\n",
    "â”‚         ğŸš— car               â”‚                                               â”‚\n",
    "â”‚    ğŸšŒ bus    ğŸï¸ motorcycle   â”‚                                               â”‚\n",
    "â”‚       (vehicles cluster)     â”‚                                               â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Dimension 1    â”‚\n",
    "â”‚                              â”‚                                               â”‚\n",
    "â”‚                              â”‚         ğŸ apple                              â”‚\n",
    "â”‚                              â”‚    ğŸŠ orange  ğŸŒ banana                       â”‚\n",
    "â”‚                              â”‚         (fruits cluster)                      â”‚\n",
    "â”‚                              â”‚                                               â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚   Key Insight: Similar items are CLOSE in vector space                       â”‚\n",
    "â”‚                Dissimilar items are FAR apart                                â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Properties of Good Embeddings\n",
    "\n",
    "1. **Semantic Similarity**: Similar meanings â†’ similar vectors\n",
    "2. **Compositionality**: Vector arithmetic captures relationships\n",
    "   - `king - man + woman â‰ˆ queen`\n",
    "3. **Generalization**: Works on unseen data\n",
    "4. **Density**: Every dimension carries meaningful information\n",
    "\n",
    "### Common Embedding Models\n",
    "\n",
    "| Model | Type | Dimensions | Use Case |\n",
    "|-------|------|------------|----------|\n",
    "| **OpenAI text-embedding-3-large** | Text | 3072 | General-purpose text |\n",
    "| **OpenAI text-embedding-3-small** | Text | 1536 | Cost-effective text |\n",
    "| **Sentence-BERT** | Text | 384-768 | Sentence similarity |\n",
    "| **CLIP** | Multi-modal | 512-768 | Text + Images |\n",
    "| **BGE** | Text | 768-1024 | Multilingual, retrieval |\n",
    "| **Cohere Embed v3** | Text | 1024 | Enterprise search |\n",
    "| **Jina Embeddings** | Text | 768 | Long context support |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f9773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Creating embeddings with different models\n",
    "import numpy as np\n",
    "\n",
    "# Simulated embeddings (in practice, use actual models)\n",
    "# pip install sentence-transformers openai\n",
    "\n",
    "# Method 1: Using Sentence Transformers (local, free)\n",
    "def get_embeddings_sentence_transformers(texts):\n",
    "    \"\"\"\n",
    "    Generate embeddings using Sentence Transformers.\n",
    "    \n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')  # 384 dimensions\n",
    "    embeddings = model.encode(texts)\n",
    "    return embeddings\n",
    "    \"\"\"\n",
    "    # Simulated output\n",
    "    return np.random.randn(len(texts), 384)\n",
    "\n",
    "\n",
    "# Method 2: Using OpenAI API (cloud, paid)\n",
    "def get_embeddings_openai(texts):\n",
    "    \"\"\"\n",
    "    Generate embeddings using OpenAI API.\n",
    "    \n",
    "    from openai import OpenAI\n",
    "    client = OpenAI()\n",
    "    \n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        input=texts\n",
    "    )\n",
    "    return [item.embedding for item in response.data]\n",
    "    \"\"\"\n",
    "    # Simulated output\n",
    "    return np.random.randn(len(texts), 1536)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "sample_texts = [\n",
    "    \"Machine learning is a subset of artificial intelligence\",\n",
    "    \"Deep learning uses neural networks with many layers\",\n",
    "    \"The weather is sunny today\"\n",
    "]\n",
    "\n",
    "embeddings = get_embeddings_sentence_transformers(sample_texts)\n",
    "print(f\"Generated {len(embeddings)} embeddings\")\n",
    "print(f\"Each embedding has {embeddings[0].shape[0]} dimensions\")\n",
    "print(f\"Sample embedding (first 10 values): {embeddings[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e5e3ad",
   "metadata": {},
   "source": [
    "## 4. Similarity Metrics <a id='similarity-metrics'></a>\n",
    "\n",
    "Vector databases use various distance/similarity metrics to measure how \"close\" two vectors are. The choice of metric significantly impacts search results.\n",
    "\n",
    "### The Big Three Metrics\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                        SIMILARITY METRICS OVERVIEW                           â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  COSINE SIMILARITY                                                           â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                          â”‚\n",
    "â”‚  Measures: Angle between vectors (direction)                                 â”‚\n",
    "â”‚  Range: -1 to 1 (1 = identical direction)                                    â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚         â–²                    Formula:                                        â”‚\n",
    "â”‚        /â”‚                                A Â· B                               â”‚\n",
    "â”‚       / â”‚  Î¸                cos(Î¸) = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚\n",
    "â”‚      /  â”‚                            â•‘Aâ•‘ Ã— â•‘Bâ•‘                               â”‚\n",
    "â”‚     â”€â”€â”€â”€â”¼â”€â”€â”€â”€â–¶                                                               â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  Best for: Text embeddings, normalized vectors                               â”‚\n",
    "â”‚  Ignores: Vector magnitude (length)                                          â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  EUCLIDEAN DISTANCE (L2)                                                     â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                     â”‚\n",
    "â”‚  Measures: Straight-line distance                                            â”‚\n",
    "â”‚  Range: 0 to âˆ (0 = identical)                                               â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚         â–²                    Formula:                                        â”‚\n",
    "â”‚         â”‚  â—B                                    _______________             â”‚\n",
    "â”‚         â”‚ /                  d(A,B) = âˆš Î£(Aáµ¢ - Báµ¢)Â²                          â”‚\n",
    "â”‚         â”‚/  d                                                                â”‚\n",
    "â”‚       Aâ—â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶                                                           â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  Best for: Image embeddings, clustering, when magnitude matters              â”‚\n",
    "â”‚  Considers: Both direction AND magnitude                                     â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  DOT PRODUCT (Inner Product)                                                 â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚\n",
    "â”‚  Measures: Combined similarity of direction and magnitude                    â”‚\n",
    "â”‚  Range: -âˆ to âˆ (higher = more similar)                                      â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚         â–²                    Formula:                                        â”‚\n",
    "â”‚        â•±â”‚                                                                    â”‚\n",
    "â”‚       â•± â”‚                    A Â· B = Î£(Aáµ¢ Ã— Báµ¢)                              â”‚\n",
    "â”‚      â•±  â”‚                                                                    â”‚\n",
    "â”‚     â”€â”€â”€â”€â”¼â”€â”€â”€â”€â–¶                                                               â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  Best for: Recommendation systems, when importance (magnitude) matters       â”‚\n",
    "â”‚  Note: Equivalent to cosine similarity when vectors are normalized           â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### When to Use Which Metric\n",
    "\n",
    "| Metric | Use When | Example Use Cases |\n",
    "|--------|----------|-------------------|\n",
    "| **Cosine** | Direction matters more than magnitude | Semantic text search, document similarity |\n",
    "| **Euclidean** | Actual distance matters | Image similarity, anomaly detection |\n",
    "| **Dot Product** | Both direction and magnitude matter | Recommendation systems, Maximum Inner Product Search |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77032a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between two vectors.\n",
    "    Range: -1 to 1 (1 = identical direction)\n",
    "    \"\"\"\n",
    "    return np.dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "\n",
    "def euclidean_distance(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute Euclidean (L2) distance between two vectors.\n",
    "    Range: 0 to infinity (0 = identical)\n",
    "    \"\"\"\n",
    "    return norm(a - b)\n",
    "\n",
    "\n",
    "def dot_product(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute dot product between two vectors.\n",
    "    Higher value = more similar (for normalized vectors)\n",
    "    \"\"\"\n",
    "    return np.dot(a, b)\n",
    "\n",
    "\n",
    "# Example: Comparing similarity metrics\n",
    "# Normalized vectors (unit length)\n",
    "vec_a = np.array([1.0, 0.0, 0.0])\n",
    "vec_b = np.array([0.707, 0.707, 0.0])  # 45 degrees from vec_a\n",
    "vec_c = np.array([0.0, 1.0, 0.0])      # 90 degrees from vec_a\n",
    "\n",
    "print(\"Comparing vector A with B (45Â° apart) and C (90Â° apart)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nCosine Similarity:\")\n",
    "print(f\"  A vs B: {cosine_similarity(vec_a, vec_b):.4f}\")\n",
    "print(f\"  A vs C: {cosine_similarity(vec_a, vec_c):.4f}\")\n",
    "\n",
    "print(f\"\\nEuclidean Distance:\")\n",
    "print(f\"  A vs B: {euclidean_distance(vec_a, vec_b):.4f}\")\n",
    "print(f\"  A vs C: {euclidean_distance(vec_a, vec_c):.4f}\")\n",
    "\n",
    "print(f\"\\nDot Product:\")\n",
    "print(f\"  A vs B: {dot_product(vec_a, vec_b):.4f}\")\n",
    "print(f\"  A vs C: {dot_product(vec_a, vec_c):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fce205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-world example: Text similarity comparison\n",
    "import numpy as np\n",
    "\n",
    "# Simulated embeddings for demonstration\n",
    "# In practice, these would come from an embedding model\n",
    "np.random.seed(42)\n",
    "\n",
    "texts = {\n",
    "    \"machine_learning\": \"Machine learning is a subset of AI\",\n",
    "    \"deep_learning\": \"Deep learning uses neural networks\",\n",
    "    \"cooking\": \"How to bake a chocolate cake\"\n",
    "}\n",
    "\n",
    "# Simulating embeddings where ML and DL are similar, cooking is different\n",
    "base_ml = np.random.randn(384)\n",
    "embeddings = {\n",
    "    \"machine_learning\": base_ml,\n",
    "    \"deep_learning\": base_ml + np.random.randn(384) * 0.3,  # Similar to ML\n",
    "    \"cooking\": np.random.randn(384)  # Completely different\n",
    "}\n",
    "\n",
    "# Normalize for fair comparison\n",
    "for key in embeddings:\n",
    "    embeddings[key] = embeddings[key] / norm(embeddings[key])\n",
    "\n",
    "print(\"Text Similarity Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query = embeddings[\"machine_learning\"]\n",
    "print(f\"\\nQuery: '{texts['machine_learning']}'\")\n",
    "print(\"\\nSimilarity to other texts:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for key, emb in embeddings.items():\n",
    "    if key != \"machine_learning\":\n",
    "        cos_sim = cosine_similarity(query, emb)\n",
    "        euc_dist = euclidean_distance(query, emb)\n",
    "        print(f\"\\n  '{texts[key]}'\")\n",
    "        print(f\"    Cosine Similarity: {cos_sim:.4f}\")\n",
    "        print(f\"    Euclidean Distance: {euc_dist:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a8fad",
   "metadata": {},
   "source": [
    "## 5. Vector Database Solutions Comparison <a id='comparison'></a>\n",
    "\n",
    "### Overview of Major Solutions\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    VECTOR DATABASE LANDSCAPE                                 â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚   MANAGED CLOUD      â”‚   â”‚    OPEN SOURCE       â”‚   â”‚  LIBRARY/       â”‚  â”‚\n",
    "â”‚  â”‚   SERVICES           â”‚   â”‚    (Self-Hosted)     â”‚   â”‚  EXTENSION      â”‚  â”‚\n",
    "â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚\n",
    "â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚\n",
    "â”‚  â”‚  â”‚  Pinecone   â”‚     â”‚   â”‚  â”‚   Milvus    â”‚     â”‚   â”‚  â”‚   FAISS   â”‚  â”‚  â”‚\n",
    "â”‚  â”‚  â”‚  Serverless â”‚     â”‚   â”‚  â”‚   Qdrant    â”‚     â”‚   â”‚  â”‚  pgvector â”‚  â”‚  â”‚\n",
    "â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚  â”‚   Weaviate  â”‚     â”‚   â”‚  â”‚  ChromaDB â”‚  â”‚  â”‚\n",
    "â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚  â”‚   Chroma    â”‚     â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚\n",
    "â”‚  â”‚  â”‚   Weaviate  â”‚     â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚                 â”‚  â”‚\n",
    "â”‚  â”‚  â”‚    Cloud    â”‚     â”‚   â”‚                      â”‚   â”‚  Embed in       â”‚  â”‚\n",
    "â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚  Full control,       â”‚   â”‚  existing       â”‚  â”‚\n",
    "â”‚  â”‚                      â”‚   â”‚  self-managed        â”‚   â”‚  systems        â”‚  â”‚\n",
    "â”‚  â”‚  Zero ops,           â”‚   â”‚                      â”‚   â”‚                 â”‚  â”‚\n",
    "â”‚  â”‚  pay-per-use         â”‚   â”‚                      â”‚   â”‚                 â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea2c55",
   "metadata": {},
   "source": [
    "### Detailed Comparison Table\n",
    "\n",
    "| Feature | Pinecone | Weaviate | Milvus | Qdrant | Chroma | FAISS | pgvector |\n",
    "|---------|----------|----------|--------|--------|--------|-------|----------|\n",
    "| **Type** | Managed Cloud | OSS + Cloud | Open Source | OSS + Cloud | Open Source | Library | PostgreSQL Extension |\n",
    "| **Language** | - | Go | C++/Go | Rust | Python | C++ | C |\n",
    "| **Deployment** | Cloud only | Self-hosted/Cloud | Self-hosted/Cloud | Self-hosted/Cloud | Embedded/Server | Embedded | PostgreSQL |\n",
    "| **Max Vectors** | 1B+ | 100M+ | 1B+ | 100M+ | Millions | 1B+ | Millions |\n",
    "| **Index Types** | Proprietary | HNSW | IVF, HNSW, DiskANN | HNSW | HNSW | IVF, HNSW, PQ | IVFFlat, HNSW |\n",
    "| **Metadata Filter** | âœ… | âœ… | âœ… | âœ… | âœ… | âŒ | âœ… (SQL) |\n",
    "| **Hybrid Search** | âœ… | âœ… | âœ… | âœ… | âœ… | âŒ | âœ… |\n",
    "| **Multi-tenancy** | âœ… | âœ… | âœ… | âœ… | âœ… | âŒ | âœ… |\n",
    "| **Pricing** | Pay-per-use | Free OSS / Cloud tiers | Free | Free OSS / Cloud | Free | Free | Free |\n",
    "| **Best For** | Production, scale | GraphQL-native, AI apps | Enterprise, massive scale | High performance | Prototyping, Python | Research, benchmarks | Existing PostgreSQL |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc121a",
   "metadata": {},
   "source": [
    "### Solution Deep Dives\n",
    "\n",
    "#### Pinecone\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  PINECONE                                                                    â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  âœ… Strengths                          âŒ Weaknesses                         â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚\n",
    "â”‚  â€¢ Fully managed, zero ops             â€¢ Cloud-only (no self-hosting)        â”‚\n",
    "â”‚  â€¢ Serverless option available         â€¢ Can be expensive at scale           â”‚\n",
    "â”‚  â€¢ Excellent documentation             â€¢ Vendor lock-in                      â”‚\n",
    "â”‚  â€¢ Fast setup (minutes)                â€¢ Limited customization               â”‚\n",
    "â”‚  â€¢ Built-in metadata filtering                                               â”‚\n",
    "â”‚  â€¢ Automatic scaling                                                         â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  ğŸ¯ Best For: Teams wanting production-ready with minimal infrastructure     â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "#### Weaviate\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  WEAVIATE                                                                    â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  âœ… Strengths                          âŒ Weaknesses                         â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚\n",
    "â”‚  â€¢ Native GraphQL API                  â€¢ Higher resource requirements        â”‚\n",
    "â”‚  â€¢ Built-in vectorization modules      â€¢ Steeper learning curve              â”‚\n",
    "â”‚  â€¢ Multi-modal support                 â€¢ Complex configuration               â”‚\n",
    "â”‚  â€¢ Flexible deployment options                                               â”‚\n",
    "â”‚  â€¢ Strong hybrid search                                                      â”‚\n",
    "â”‚  â€¢ Active community                                                          â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  ğŸ¯ Best For: AI-native apps needing flexible data modeling                  â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "#### Milvus\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  MILVUS                                                                      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  âœ… Strengths                          âŒ Weaknesses                         â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚\n",
    "â”‚  â€¢ Massive scale (billion+ vectors)    â€¢ Complex deployment                  â”‚\n",
    "â”‚  â€¢ Multiple index algorithms           â€¢ Resource intensive                  â”‚\n",
    "â”‚  â€¢ GPU acceleration support            â€¢ Steeper operational overhead        â”‚\n",
    "â”‚  â€¢ Enterprise-grade features                                                 â”‚\n",
    "â”‚  â€¢ LF AI & Data Foundation project                                           â”‚\n",
    "â”‚  â€¢ Strong community                                                          â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  ğŸ¯ Best For: Enterprise deployments needing massive scale                   â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "#### Qdrant\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  QDRANT                                                                      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  âœ… Strengths                          âŒ Weaknesses                         â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚\n",
    "â”‚  â€¢ Written in Rust (fast & safe)       â€¢ Smaller ecosystem                   â”‚\n",
    "â”‚  â€¢ Excellent performance               â€¢ Newer project                       â”‚\n",
    "â”‚  â€¢ Easy to deploy (single binary)      â€¢ Less enterprise features            â”‚\n",
    "â”‚  â€¢ Rich filtering capabilities                                               â”‚\n",
    "â”‚  â€¢ Great developer experience                                                â”‚\n",
    "â”‚  â€¢ Low resource footprint                                                    â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  ğŸ¯ Best For: Performance-critical apps with complex filtering               â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "#### Chroma\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  CHROMA                                                                      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  âœ… Strengths                          âŒ Weaknesses                         â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚\n",
    "â”‚  â€¢ Python-native API                   â€¢ Limited scale                       â”‚\n",
    "â”‚  â€¢ Simple embedded mode                â€¢ Fewer features                      â”‚\n",
    "â”‚  â€¢ Built-in embedding functions        â€¢ Not for production at scale         â”‚\n",
    "â”‚  â€¢ LangChain integration                                                     â”‚\n",
    "â”‚  â€¢ Great for prototyping                                                     â”‚\n",
    "â”‚  â€¢ Zero configuration                                                        â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  ğŸ¯ Best For: Prototyping, small projects, Python developers                 â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "#### FAISS\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  FAISS (Facebook AI Similarity Search)                                       â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  âœ… Strengths                          âŒ Weaknesses                         â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚\n",
    "â”‚  â€¢ Extremely fast                      â€¢ Library, not database               â”‚\n",
    "â”‚  â€¢ GPU support                         â€¢ No built-in persistence             â”‚\n",
    "â”‚  â€¢ Many index options                  â€¢ No metadata filtering               â”‚\n",
    "â”‚  â€¢ Battle-tested at Meta               â€¢ No distributed mode                 â”‚\n",
    "â”‚  â€¢ Great for research                  â€¢ Manual memory management            â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  ğŸ¯ Best For: Research, benchmarking, building custom solutions              â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "#### pgvector\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  PGVECTOR                                                                    â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  âœ… Strengths                          âŒ Weaknesses                         â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚\n",
    "â”‚  â€¢ Uses existing PostgreSQL            â€¢ Limited to PostgreSQL               â”‚\n",
    "â”‚  â€¢ Full SQL support                    â€¢ Less optimized than specialized DBs â”‚\n",
    "â”‚  â€¢ ACID transactions                   â€¢ Scale limitations                   â”‚\n",
    "â”‚  â€¢ No new infrastructure               â€¢ Fewer index options                 â”‚\n",
    "â”‚  â€¢ Familiar tooling                                                          â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  ğŸ¯ Best For: Teams with existing PostgreSQL wanting to add vector search    â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b24d6ed",
   "metadata": {},
   "source": [
    "### Decision Framework\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    CHOOSING A VECTOR DATABASE                                â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚                           Start Here                                         â”‚\n",
    "â”‚                               â”‚                                              â”‚\n",
    "â”‚                               â–¼                                              â”‚\n",
    "â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚\n",
    "â”‚                    â”‚ Just prototyping or  â”‚                                  â”‚\n",
    "â”‚                    â”‚ learning?            â”‚                                  â”‚\n",
    "â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚\n",
    "â”‚                      Yes â”‚          â”‚ No                                     â”‚\n",
    "â”‚                          â–¼          â–¼                                        â”‚\n",
    "â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚\n",
    "â”‚                    â”‚  Chroma  â”‚  â”‚ Already using        â”‚                    â”‚\n",
    "â”‚                    â”‚  or FAISSâ”‚  â”‚ PostgreSQL?          â”‚                    â”‚\n",
    "â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚\n",
    "â”‚                                    Yes â”‚          â”‚ No                       â”‚\n",
    "â”‚                                        â–¼          â–¼                          â”‚\n",
    "â”‚                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚\n",
    "â”‚                               â”‚ pgvector â”‚  â”‚ Need managed/zero    â”‚         â”‚\n",
    "â”‚                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ ops?                 â”‚         â”‚\n",
    "â”‚                                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚\n",
    "â”‚                                               Yes â”‚          â”‚ No            â”‚\n",
    "â”‚                                                   â–¼          â–¼               â”‚\n",
    "â”‚                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\n",
    "â”‚                                          â”‚ Pinecone â”‚  â”‚ Need billion+  â”‚    â”‚\n",
    "â”‚                                          â”‚ or Cloud â”‚  â”‚ vectors?       â”‚    â”‚\n",
    "â”‚                                          â”‚ Weaviate â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n",
    "â”‚                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    Yes â”‚      â”‚ No     â”‚\n",
    "â”‚                                                              â–¼      â–¼        â”‚\n",
    "â”‚                                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\n",
    "â”‚                                                      â”‚ Milvus â”‚ â”‚ Qdrant â”‚   â”‚\n",
    "â”‚                                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚Weaviateâ”‚   â”‚\n",
    "â”‚                                                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47222a5a",
   "metadata": {},
   "source": [
    "## 6. Use Cases <a id='use-cases'></a>\n",
    "\n",
    "### Primary Use Cases for Vector Databases\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    VECTOR DATABASE USE CASES                                 â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  1ï¸âƒ£  SEMANTIC SEARCH                                                        â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                       â”‚\n",
    "â”‚  â€¢ Search by meaning, not keywords                                           â”‚\n",
    "â”‚  â€¢ Query: \"affordable housing\" â†’ matches \"cheap apartments\"                 â”‚\n",
    "â”‚  â€¢ Multi-language search                                                     â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  2ï¸âƒ£  RAG (Retrieval-Augmented Generation)                                   â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â”‚\n",
    "â”‚  â€¢ Ground LLMs with company knowledge                                        â”‚\n",
    "â”‚  â€¢ Reduce hallucinations                                                     â”‚\n",
    "â”‚  â€¢ Build chatbots over private data                                          â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  3ï¸âƒ£  RECOMMENDATION SYSTEMS                                                 â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚\n",
    "â”‚  â€¢ \"Users who liked X also liked...\"                                         â”‚\n",
    "â”‚  â€¢ Content-based recommendations                                             â”‚\n",
    "â”‚  â€¢ Similar product discovery                                                 â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  4ï¸âƒ£  IMAGE SEARCH                                                           â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                               â”‚\n",
    "â”‚  â€¢ Reverse image search                                                      â”‚\n",
    "â”‚  â€¢ Visual similarity (fashion, products)                                     â”‚\n",
    "â”‚  â€¢ Image deduplication                                                       â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  5ï¸âƒ£  ANOMALY DETECTION                                                      â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                        â”‚\n",
    "â”‚  â€¢ Find outliers in high-dimensional data                                    â”‚\n",
    "â”‚  â€¢ Fraud detection                                                           â”‚\n",
    "â”‚  â€¢ Security threat identification                                            â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚  6ï¸âƒ£  DEDUPLICATION                                                          â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                             â”‚\n",
    "â”‚  â€¢ Find near-duplicate documents                                             â”‚\n",
    "â”‚  â€¢ Data cleaning                                                             â”‚\n",
    "â”‚  â€¢ Content moderation                                                        â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Industry Applications\n",
    "\n",
    "| Industry | Use Case | Example |\n",
    "|----------|----------|----------|\n",
    "| **E-commerce** | Visual search | \"Find similar products to this image\" |\n",
    "| **Healthcare** | Medical imaging | Find similar X-rays/scans for diagnosis |\n",
    "| **Legal** | Document discovery | Find relevant case law semantically |\n",
    "| **Finance** | Fraud detection | Identify unusual transaction patterns |\n",
    "| **Media** | Content recommendation | Personalized news/video feeds |\n",
    "| **HR** | Resume matching | Match candidates to job descriptions |\n",
    "| **Support** | Ticket routing | Route to relevant knowledge articles |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c914a492",
   "metadata": {},
   "source": [
    "## 7. Code Examples <a id='code-examples'></a>\n",
    "\n",
    "### Example 1: Chroma (Simple Local Setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f64828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma - Simple local vector database\n",
    "# pip install chromadb\n",
    "\n",
    "# import chromadb\n",
    "\n",
    "# Create client and collection\n",
    "# client = chromadb.Client()\n",
    "# collection = client.create_collection(\n",
    "#     name=\"documents\",\n",
    "#     metadata={\"hnsw:space\": \"cosine\"}  # Use cosine similarity\n",
    "# )\n",
    "\n",
    "# Add documents (Chroma auto-generates embeddings with default model)\n",
    "# collection.add(\n",
    "#     documents=[\n",
    "#         \"Machine learning is a subset of artificial intelligence\",\n",
    "#         \"Deep learning uses neural networks with many layers\",\n",
    "#         \"Natural language processing deals with text and speech\",\n",
    "#         \"Computer vision focuses on image and video analysis\"\n",
    "#     ],\n",
    "#     metadatas=[\n",
    "#         {\"category\": \"ml\", \"difficulty\": \"beginner\"},\n",
    "#         {\"category\": \"dl\", \"difficulty\": \"intermediate\"},\n",
    "#         {\"category\": \"nlp\", \"difficulty\": \"intermediate\"},\n",
    "#         {\"category\": \"cv\", \"difficulty\": \"advanced\"}\n",
    "#     ],\n",
    "#     ids=[\"doc1\", \"doc2\", \"doc3\", \"doc4\"]\n",
    "# )\n",
    "\n",
    "# Query\n",
    "# results = collection.query(\n",
    "#     query_texts=[\"neural networks and AI\"],\n",
    "#     n_results=2,\n",
    "#     where={\"difficulty\": {\"$ne\": \"advanced\"}}  # Exclude advanced\n",
    "# )\n",
    "# print(results)\n",
    "\n",
    "print(\"Chroma example - install chromadb to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e87c69",
   "metadata": {},
   "source": [
    "### Example 2: Pinecone (Managed Cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fbab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinecone - Managed vector database\n",
    "# pip install pinecone-client\n",
    "\n",
    "# from pinecone import Pinecone, ServerlessSpec\n",
    "# import numpy as np\n",
    "\n",
    "# Initialize\n",
    "# pc = Pinecone(api_key=\"YOUR_API_KEY\")\n",
    "\n",
    "# Create index\n",
    "# pc.create_index(\n",
    "#     name=\"quickstart\",\n",
    "#     dimension=1536,  # OpenAI embedding dimension\n",
    "#     metric=\"cosine\",\n",
    "#     spec=ServerlessSpec(\n",
    "#         cloud=\"aws\",\n",
    "#         region=\"us-east-1\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# Get index\n",
    "# index = pc.Index(\"quickstart\")\n",
    "\n",
    "# Upsert vectors\n",
    "# vectors = [\n",
    "#     {\n",
    "#         \"id\": \"vec1\",\n",
    "#         \"values\": np.random.rand(1536).tolist(),\n",
    "#         \"metadata\": {\"genre\": \"action\", \"year\": 2020}\n",
    "#     },\n",
    "#     {\n",
    "#         \"id\": \"vec2\",\n",
    "#         \"values\": np.random.rand(1536).tolist(),\n",
    "#         \"metadata\": {\"genre\": \"comedy\", \"year\": 2021}\n",
    "#     }\n",
    "# ]\n",
    "# index.upsert(vectors=vectors)\n",
    "\n",
    "# Query with metadata filter\n",
    "# results = index.query(\n",
    "#     vector=np.random.rand(1536).tolist(),\n",
    "#     top_k=5,\n",
    "#     filter={\"genre\": {\"$eq\": \"action\"}},\n",
    "#     include_metadata=True\n",
    "# )\n",
    "\n",
    "print(\"Pinecone example - requires API key to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982ffffd",
   "metadata": {},
   "source": [
    "### Example 3: Qdrant (High-Performance Open Source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qdrant - High-performance vector database\n",
    "# pip install qdrant-client\n",
    "\n",
    "# from qdrant_client import QdrantClient\n",
    "# from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "\n",
    "# Initialize client (local mode for testing)\n",
    "# client = QdrantClient(\":memory:\")  # In-memory for testing\n",
    "# For server: client = QdrantClient(\"localhost\", port=6333)\n",
    "\n",
    "# Create collection\n",
    "# client.create_collection(\n",
    "#     collection_name=\"my_collection\",\n",
    "#     vectors_config=VectorParams(\n",
    "#         size=384,\n",
    "#         distance=Distance.COSINE\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# Insert points\n",
    "# client.upsert(\n",
    "#     collection_name=\"my_collection\",\n",
    "#     points=[\n",
    "#         PointStruct(\n",
    "#             id=1,\n",
    "#             vector=np.random.rand(384).tolist(),\n",
    "#             payload={\"city\": \"London\", \"population\": 9000000}\n",
    "#         ),\n",
    "#         PointStruct(\n",
    "#             id=2,\n",
    "#             vector=np.random.rand(384).tolist(),\n",
    "#             payload={\"city\": \"Paris\", \"population\": 2100000}\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# Search with filtering\n",
    "# from qdrant_client.models import Filter, FieldCondition, Range\n",
    "# \n",
    "# results = client.search(\n",
    "#     collection_name=\"my_collection\",\n",
    "#     query_vector=np.random.rand(384).tolist(),\n",
    "#     limit=5,\n",
    "#     query_filter=Filter(\n",
    "#         must=[\n",
    "#             FieldCondition(\n",
    "#                 key=\"population\",\n",
    "#                 range=Range(gte=1000000)\n",
    "#             )\n",
    "#         ]\n",
    "#     )\n",
    "# )\n",
    "\n",
    "print(\"Qdrant example - install qdrant-client to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e93847b",
   "metadata": {},
   "source": [
    "### Example 4: FAISS (Facebook AI Similarity Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc5964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS - High-performance similarity search library\n",
    "# pip install faiss-cpu  # or faiss-gpu for GPU support\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Simulated FAISS example\n",
    "# import faiss\n",
    "\n",
    "# Parameters\n",
    "d = 128  # Vector dimension\n",
    "nb = 10000  # Number of database vectors\n",
    "nq = 5  # Number of query vectors\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(42)\n",
    "xb = np.random.random((nb, d)).astype('float32')  # Database vectors\n",
    "xq = np.random.random((nq, d)).astype('float32')  # Query vectors\n",
    "\n",
    "# Normalize for cosine similarity\n",
    "# faiss.normalize_L2(xb)\n",
    "# faiss.normalize_L2(xq)\n",
    "\n",
    "# Create index (Flat = exact search, good for small datasets)\n",
    "# index = faiss.IndexFlatL2(d)  # L2 distance\n",
    "# index = faiss.IndexFlatIP(d)  # Inner product (cosine if normalized)\n",
    "\n",
    "# Add vectors to index\n",
    "# index.add(xb)\n",
    "# print(f\"Index contains {index.ntotal} vectors\")\n",
    "\n",
    "# Search\n",
    "# k = 4  # Number of nearest neighbors\n",
    "# distances, indices = index.search(xq, k)\n",
    "# print(f\"Nearest neighbors for first query: {indices[0]}\")\n",
    "# print(f\"Distances: {distances[0]}\")\n",
    "\n",
    "# For large datasets, use IVF (Inverted File) index\n",
    "# nlist = 100  # Number of clusters\n",
    "# quantizer = faiss.IndexFlatL2(d)\n",
    "# index_ivf = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
    "# index_ivf.train(xb)  # Train on sample data\n",
    "# index_ivf.add(xb)\n",
    "# index_ivf.nprobe = 10  # Number of clusters to search\n",
    "\n",
    "print(f\"FAISS example setup:\")\n",
    "print(f\"  Database vectors: {nb:,}\")\n",
    "print(f\"  Vector dimension: {d}\")\n",
    "print(f\"  Query vectors: {nq}\")\n",
    "print(\"\\nInstall faiss-cpu to run full example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44163ea",
   "metadata": {},
   "source": [
    "### Example 5: pgvector (PostgreSQL Extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3366d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pgvector - Vector search in PostgreSQL\n",
    "# Requires PostgreSQL with pgvector extension installed\n",
    "\n",
    "# SQL Setup:\n",
    "sql_setup = \"\"\"\n",
    "-- Enable the extension\n",
    "CREATE EXTENSION IF NOT EXISTS vector;\n",
    "\n",
    "-- Create table with vector column\n",
    "CREATE TABLE documents (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    content TEXT,\n",
    "    embedding vector(1536),  -- OpenAI embedding dimension\n",
    "    metadata JSONB\n",
    ");\n",
    "\n",
    "-- Create an index for faster searches\n",
    "CREATE INDEX ON documents USING ivfflat (embedding vector_cosine_ops)\n",
    "WITH (lists = 100);  -- Number of clusters\n",
    "\n",
    "-- Or use HNSW for better recall\n",
    "CREATE INDEX ON documents USING hnsw (embedding vector_cosine_ops)\n",
    "WITH (m = 16, ef_construction = 64);\n",
    "\"\"\"\n",
    "\n",
    "# Insert example\n",
    "sql_insert = \"\"\"\n",
    "INSERT INTO documents (content, embedding, metadata)\n",
    "VALUES (\n",
    "    'Machine learning is a subset of AI',\n",
    "    '[0.1, 0.2, 0.3, ...]',  -- Your embedding here\n",
    "    '{\"category\": \"tech\", \"author\": \"john\"}'\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Query example (find 5 most similar)\n",
    "sql_query = \"\"\"\n",
    "SELECT id, content, \n",
    "       1 - (embedding <=> '[0.1, 0.2, ...]') AS similarity\n",
    "FROM documents\n",
    "WHERE metadata->>'category' = 'tech'\n",
    "ORDER BY embedding <=> '[0.1, 0.2, ...]'  -- <=> is cosine distance\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "# Python usage with psycopg2\n",
    "python_example = \"\"\"\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "\n",
    "# Connect\n",
    "conn = psycopg2.connect(\"postgresql://user:pass@localhost/db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Insert\n",
    "embedding = np.random.rand(1536).tolist()\n",
    "cur.execute(\n",
    "    \"INSERT INTO documents (content, embedding) VALUES (%s, %s)\",\n",
    "    (\"Sample text\", embedding)\n",
    ")\n",
    "\n",
    "# Search\n",
    "query_embedding = np.random.rand(1536).tolist()\n",
    "cur.execute(\n",
    "    \"SELECT id, content FROM documents ORDER BY embedding <=> %s LIMIT 5\",\n",
    "    (query_embedding,)\n",
    ")\n",
    "results = cur.fetchall()\n",
    "\"\"\"\n",
    "\n",
    "print(\"pgvector SQL Setup:\")\n",
    "print(sql_setup)\n",
    "print(\"\\nQuery Example:\")\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3eaa0e",
   "metadata": {},
   "source": [
    "### Example 6: Complete RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ce55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete RAG Pipeline Example (Conceptual)\n",
    "# This demonstrates the full flow from documents to answers\n",
    "\n",
    "class SimpleRAGPipeline:\n",
    "    \"\"\"\n",
    "    A simple Retrieval-Augmented Generation pipeline.\n",
    "    In production, use actual embedding models and vector databases.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.documents = []\n",
    "        self.embeddings = []\n",
    "    \n",
    "    def add_documents(self, docs: list[str]):\n",
    "        \"\"\"Add documents to the knowledge base.\"\"\"\n",
    "        self.documents.extend(docs)\n",
    "        # In production: self.embeddings = embedding_model.encode(docs)\n",
    "        self.embeddings = [np.random.randn(384) for _ in docs]\n",
    "        print(f\"Added {len(docs)} documents\")\n",
    "    \n",
    "    def retrieve(self, query: str, top_k: int = 3) -> list[str]:\n",
    "        \"\"\"Retrieve relevant documents for a query.\"\"\"\n",
    "        # In production: query_embedding = embedding_model.encode([query])[0]\n",
    "        query_embedding = np.random.randn(384)\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities = []\n",
    "        for i, emb in enumerate(self.embeddings):\n",
    "            sim = np.dot(query_embedding, emb) / (np.linalg.norm(query_embedding) * np.linalg.norm(emb))\n",
    "            similarities.append((sim, i))\n",
    "        \n",
    "        # Sort by similarity and get top_k\n",
    "        similarities.sort(reverse=True)\n",
    "        top_indices = [idx for _, idx in similarities[:top_k]]\n",
    "        \n",
    "        return [self.documents[i] for i in top_indices]\n",
    "    \n",
    "    def generate_answer(self, query: str, context: list[str]) -> str:\n",
    "        \"\"\"Generate answer using LLM with retrieved context.\"\"\"\n",
    "        # In production: Use OpenAI, Anthropic, etc.\n",
    "        prompt = f\"\"\"\n",
    "        Context:\n",
    "        {chr(10).join(f'- {doc}' for doc in context)}\n",
    "        \n",
    "        Question: {query}\n",
    "        \n",
    "        Answer based on the context above:\n",
    "        \"\"\"\n",
    "        # Simulated LLM response\n",
    "        return f\"[LLM would generate answer here based on context]\"\n",
    "    \n",
    "    def query(self, question: str) -> dict:\n",
    "        \"\"\"Full RAG pipeline: retrieve and generate.\"\"\"\n",
    "        # Step 1: Retrieve relevant documents\n",
    "        relevant_docs = self.retrieve(question)\n",
    "        \n",
    "        # Step 2: Generate answer with context\n",
    "        answer = self.generate_answer(question, relevant_docs)\n",
    "        \n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"retrieved_docs\": relevant_docs,\n",
    "            \"answer\": answer\n",
    "        }\n",
    "\n",
    "\n",
    "# Usage example\n",
    "rag = SimpleRAGPipeline()\n",
    "\n",
    "# Add knowledge base\n",
    "knowledge = [\n",
    "    \"Vector databases store high-dimensional vectors for similarity search.\",\n",
    "    \"HNSW (Hierarchical Navigable Small World) is a popular indexing algorithm.\",\n",
    "    \"Cosine similarity measures the angle between two vectors.\",\n",
    "    \"RAG combines retrieval with generation for better AI responses.\",\n",
    "    \"Embeddings capture semantic meaning in numerical form.\"\n",
    "]\n",
    "\n",
    "rag.add_documents(knowledge)\n",
    "\n",
    "# Query the system\n",
    "result = rag.query(\"How do vector databases work?\")\n",
    "print(f\"\\nQuestion: {result['question']}\")\n",
    "print(f\"\\nRetrieved {len(result['retrieved_docs'])} relevant documents\")\n",
    "print(f\"\\nAnswer: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045f89c0",
   "metadata": {},
   "source": [
    "## 8. Summary and Best Practices\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Vector databases are essential for modern AI** - They enable semantic search, RAG, and recommendation systems at scale.\n",
    "\n",
    "2. **Choose the right similarity metric** - Cosine for text, Euclidean for images, Dot Product when magnitude matters.\n",
    "\n",
    "3. **Solution selection depends on your needs**:\n",
    "   - Prototyping â†’ Chroma or FAISS\n",
    "   - Existing PostgreSQL â†’ pgvector\n",
    "   - Managed service â†’ Pinecone\n",
    "   - Self-hosted scale â†’ Milvus or Qdrant\n",
    "\n",
    "4. **Embeddings quality matters more than the database** - Invest in good embedding models.\n",
    "\n",
    "5. **Hybrid search is powerful** - Combine vector search with metadata filtering.\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "| Practice | Why |\n",
    "|----------|-----|\n",
    "| **Normalize embeddings** | Consistent similarity scores, required for cosine |\n",
    "| **Chunk documents appropriately** | 256-512 tokens often optimal for RAG |\n",
    "| **Use metadata filtering** | Reduce search space, improve relevance |\n",
    "| **Benchmark before choosing** | Performance varies by use case |\n",
    "| **Monitor recall vs latency** | Trade-offs in ANN algorithms |\n",
    "| **Keep embeddings versioned** | Model updates affect vector compatibility |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973792aa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "- [Pinecone Documentation](https://docs.pinecone.io/)\n",
    "- [Weaviate Documentation](https://weaviate.io/developers/weaviate)\n",
    "- [Milvus Documentation](https://milvus.io/docs)\n",
    "- [Qdrant Documentation](https://qdrant.tech/documentation/)\n",
    "- [Chroma Documentation](https://docs.trychroma.com/)\n",
    "- [FAISS Wiki](https://github.com/facebookresearch/faiss/wiki)\n",
    "- [pgvector GitHub](https://github.com/pgvector/pgvector)\n",
    "- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)\n",
    "- [Sentence Transformers](https://www.sbert.net/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
