{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "771d8052",
   "metadata": {},
   "source": [
    "# Vector Database Implementation: ChromaDB & FAISS\n",
    "\n",
    "This notebook provides hands-on implementation of vector databases using **ChromaDB** and **FAISS**. We'll cover installation, creating collections, generating embeddings, inserting vectors, similarity search, filtering, and persistence.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction to Vector Databases](#introduction)\n",
    "2. [ANN Algorithms Overview](#ann-algorithms)\n",
    "3. [ChromaDB Implementation](#chromadb)\n",
    "4. [FAISS Implementation](#faiss)\n",
    "5. [Comparison & Best Practices](#comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bb6201",
   "metadata": {},
   "source": [
    "## 1. Introduction to Vector Databases <a id=\"introduction\"></a>\n",
    "\n",
    "Vector databases are specialized databases designed to store, index, and query high-dimensional vectors (embeddings). They are essential for:\n",
    "\n",
    "- **Semantic search**: Finding similar documents based on meaning\n",
    "- **Recommendation systems**: Finding similar items/users\n",
    "- **RAG (Retrieval Augmented Generation)**: Providing context to LLMs\n",
    "- **Image/Audio similarity**: Finding similar media files\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Embedding** | A dense vector representation of data (text, image, etc.) |\n",
    "| **Dimension** | The number of elements in an embedding vector (e.g., 384, 768, 1536) |\n",
    "| **Distance Metric** | How similarity is measured (cosine, L2/Euclidean, inner product) |\n",
    "| **ANN (Approximate Nearest Neighbor)** | Algorithms that trade some accuracy for speed |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55391774",
   "metadata": {},
   "source": [
    "## 2. ANN Algorithms Overview <a id=\"ann-algorithms\"></a>\n",
    "\n",
    "Exact nearest neighbor search has O(n) complexity, which is impractical for large datasets. ANN algorithms provide near-optimal results with much better performance.\n",
    "\n",
    "### 2.1 HNSW (Hierarchical Navigable Small World)\n",
    "\n",
    "HNSW builds a multi-layer graph structure where:\n",
    "- **Upper layers**: Sparse connections for fast long-range navigation\n",
    "- **Lower layers**: Dense connections for precise local search\n",
    "\n",
    "```\n",
    "Layer 2:  [A]---------------[D]\n",
    "           |                 |\n",
    "Layer 1:  [A]----[B]----[C]-[D]----[E]\n",
    "           |      |      |   |      |\n",
    "Layer 0:  [A]-[B]-[B]-[C]-[C]-[D]-[E]-[F]-[G]\n",
    "```\n",
    "\n",
    "**Key Parameters:**\n",
    "- `M`: Number of connections per node (higher = more accurate, more memory)\n",
    "- `ef_construction`: Size of dynamic candidate list during construction\n",
    "- `ef_search`: Size of dynamic candidate list during search\n",
    "\n",
    "**Characteristics:**\n",
    "- ✅ Excellent query performance (O(log n))\n",
    "- ✅ High recall (accuracy)\n",
    "- ❌ Higher memory usage\n",
    "- ❌ Slower index construction\n",
    "\n",
    "### 2.2 IVF (Inverted File Index)\n",
    "\n",
    "IVF partitions the vector space into clusters (Voronoi cells) using k-means:\n",
    "\n",
    "```\n",
    "          Centroid 1          Centroid 2          Centroid 3\n",
    "              *                   *                   *\n",
    "           /  |  \\             /  |  \\             /  |  \\\n",
    "          v1  v2  v3          v4  v5  v6          v7  v8  v9\n",
    "```\n",
    "\n",
    "**Key Parameters:**\n",
    "- `nlist`: Number of clusters/cells\n",
    "- `nprobe`: Number of clusters to search (higher = more accurate, slower)\n",
    "\n",
    "**Characteristics:**\n",
    "- ✅ Lower memory footprint\n",
    "- ✅ Fast index construction\n",
    "- ✅ Can be combined with Product Quantization (IVF-PQ)\n",
    "- ❌ Lower recall than HNSW at same speed\n",
    "\n",
    "### 2.3 Algorithm Comparison\n",
    "\n",
    "| Algorithm | Build Time | Query Time | Memory | Recall | Best For |\n",
    "|-----------|------------|------------|--------|--------|----------|\n",
    "| HNSW | Slow | Fast | High | High | Real-time search, high accuracy |\n",
    "| IVF | Fast | Medium | Low | Medium | Large datasets, memory constrained |\n",
    "| IVF-PQ | Fast | Fast | Very Low | Lower | Billion-scale datasets |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90309509",
   "metadata": {},
   "source": [
    "## 3. ChromaDB Implementation <a id=\"chromadb\"></a>\n",
    "\n",
    "ChromaDB is an open-source embedding database designed for AI applications. It's simple to use and supports persistence out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0734bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation\n",
    "# !pip install chromadb sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6038af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# Create an in-memory client\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Or create a persistent client (data survives restarts)\n",
    "# client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "print(f\"ChromaDB version: {chromadb.__version__}\")\n",
    "print(f\"Client type: {type(client).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa70a50d",
   "metadata": {},
   "source": [
    "### 3.1 Creating Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a collection with default embedding function\n",
    "# ChromaDB uses all-MiniLM-L6-v2 by default (384 dimensions)\n",
    "collection = client.create_collection(\n",
    "    name=\"documents\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"}  # Distance metric: cosine, l2, or ip\n",
    ")\n",
    "\n",
    "print(f\"Collection created: {collection.name}\")\n",
    "print(f\"Collection metadata: {collection.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8281d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a custom embedding function\n",
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-MiniLM-L6-v2\"  # 384 dimensions, fast and efficient\n",
    ")\n",
    "\n",
    "# Create collection with custom embedding function\n",
    "custom_collection = client.get_or_create_collection(\n",
    "    name=\"custom_embeddings\",\n",
    "    embedding_function=sentence_transformer_ef,\n",
    "    metadata={\n",
    "        \"hnsw:space\": \"cosine\",\n",
    "        \"hnsw:M\": 16,  # Number of connections per node\n",
    "        \"hnsw:construction_ef\": 100  # Construction-time search width\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Custom collection: {custom_collection.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65321152",
   "metadata": {},
   "source": [
    "### 3.2 Inserting Documents with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1170d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents about programming languages\n",
    "documents = [\n",
    "    \"Python is a high-level programming language known for its simplicity and readability.\",\n",
    "    \"JavaScript is the language of the web, used for frontend and backend development.\",\n",
    "    \"Rust provides memory safety without garbage collection, ideal for systems programming.\",\n",
    "    \"Go is designed for simplicity and efficiency, great for cloud and network services.\",\n",
    "    \"TypeScript adds static typing to JavaScript, improving code quality and maintainability.\",\n",
    "    \"Java is a robust, platform-independent language widely used in enterprise applications.\",\n",
    "    \"C++ offers high performance and is used in game development and system software.\",\n",
    "    \"Kotlin is a modern language for Android development, fully interoperable with Java.\"\n",
    "]\n",
    "\n",
    "# Metadata for filtering\n",
    "metadatas = [\n",
    "    {\"type\": \"interpreted\", \"paradigm\": \"multi\", \"year\": 1991},\n",
    "    {\"type\": \"interpreted\", \"paradigm\": \"multi\", \"year\": 1995},\n",
    "    {\"type\": \"compiled\", \"paradigm\": \"multi\", \"year\": 2010},\n",
    "    {\"type\": \"compiled\", \"paradigm\": \"procedural\", \"year\": 2009},\n",
    "    {\"type\": \"transpiled\", \"paradigm\": \"multi\", \"year\": 2012},\n",
    "    {\"type\": \"compiled\", \"paradigm\": \"oop\", \"year\": 1995},\n",
    "    {\"type\": \"compiled\", \"paradigm\": \"multi\", \"year\": 1983},\n",
    "    {\"type\": \"compiled\", \"paradigm\": \"multi\", \"year\": 2011}\n",
    "]\n",
    "\n",
    "# Unique IDs for each document\n",
    "ids = [f\"doc_{i}\" for i in range(len(documents))]\n",
    "\n",
    "# Add documents to collection (embeddings generated automatically)\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids\n",
    ")\n",
    "\n",
    "print(f\"Added {collection.count()} documents to the collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76b4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding documents with pre-computed embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Additional documents\n",
    "new_docs = [\n",
    "    \"SQL is essential for database querying and data manipulation.\",\n",
    "    \"HTML and CSS are the building blocks of web pages.\"\n",
    "]\n",
    "\n",
    "# Generate embeddings manually\n",
    "embeddings = model.encode(new_docs).tolist()\n",
    "\n",
    "# Add with pre-computed embeddings\n",
    "collection.add(\n",
    "    embeddings=embeddings,\n",
    "    documents=new_docs,\n",
    "    metadatas=[\n",
    "        {\"type\": \"query\", \"paradigm\": \"declarative\", \"year\": 1974},\n",
    "        {\"type\": \"markup\", \"paradigm\": \"declarative\", \"year\": 1993}\n",
    "    ],\n",
    "    ids=[\"doc_8\", \"doc_9\"]\n",
    ")\n",
    "\n",
    "print(f\"Total documents: {collection.count()}\")\n",
    "print(f\"Embedding dimension: {len(embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550f2b8c",
   "metadata": {},
   "source": [
    "### 3.3 Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b23414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic similarity search\n",
    "results = collection.query(\n",
    "    query_texts=[\"What programming language is good for web development?\"],\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "print(\"Query: What programming language is good for web development?\\n\")\n",
    "print(\"Top 3 Results:\")\n",
    "for i, (doc, distance, metadata) in enumerate(zip(\n",
    "    results['documents'][0], \n",
    "    results['distances'][0],\n",
    "    results['metadatas'][0]\n",
    ")):\n",
    "    print(f\"{i+1}. [Distance: {distance:.4f}] {doc}\")\n",
    "    print(f\"   Metadata: {metadata}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26924c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with pre-computed query embedding\n",
    "query_text = \"systems programming with memory safety\"\n",
    "query_embedding = model.encode([query_text]).tolist()\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding,\n",
    "    n_results=3,\n",
    "    include=[\"documents\", \"distances\", \"metadatas\", \"embeddings\"]\n",
    ")\n",
    "\n",
    "print(f\"Query: {query_text}\\n\")\n",
    "for i, (doc, dist) in enumerate(zip(results['documents'][0], results['distances'][0])):\n",
    "    print(f\"{i+1}. [Distance: {dist:.4f}] {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdac00c",
   "metadata": {},
   "source": [
    "### 3.4 Filtering with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df67d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by single condition\n",
    "results = collection.query(\n",
    "    query_texts=[\"modern programming language\"],\n",
    "    n_results=5,\n",
    "    where={\"type\": \"compiled\"}  # Only compiled languages\n",
    ")\n",
    "\n",
    "print(\"Compiled languages matching 'modern programming language':\")\n",
    "for doc, meta in zip(results['documents'][0], results['metadatas'][0]):\n",
    "    print(f\"  - {doc[:60]}... ({meta})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38faef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex filtering with operators\n",
    "results = collection.query(\n",
    "    query_texts=[\"popular programming language\"],\n",
    "    n_results=5,\n",
    "    where={\n",
    "        \"$and\": [\n",
    "            {\"year\": {\"$gte\": 2000}},  # Year >= 2000\n",
    "            {\"paradigm\": {\"$ne\": \"declarative\"}}  # Not declarative\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Modern languages (year >= 2000, not declarative):\")\n",
    "for doc, meta in zip(results['documents'][0], results['metadatas'][0]):\n",
    "    print(f\"  - {meta['year']}: {doc[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bf8b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by document content\n",
    "results = collection.query(\n",
    "    query_texts=[\"programming\"],\n",
    "    n_results=5,\n",
    "    where_document={\"$contains\": \"web\"}  # Document must contain \"web\"\n",
    ")\n",
    "\n",
    "print(\"Documents containing 'web':\")\n",
    "for doc in results['documents'][0]:\n",
    "    print(f\"  - {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceee6d5",
   "metadata": {},
   "source": [
    "### 3.5 Updating and Deleting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0439c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update a document\n",
    "collection.update(\n",
    "    ids=[\"doc_0\"],\n",
    "    documents=[\"Python is a versatile, high-level language popular in AI, web development, and data science.\"],\n",
    "    metadatas=[{\"type\": \"interpreted\", \"paradigm\": \"multi\", \"year\": 1991, \"updated\": True}]\n",
    ")\n",
    "\n",
    "# Verify update\n",
    "result = collection.get(ids=[\"doc_0\"])\n",
    "print(\"Updated document:\")\n",
    "print(f\"  Text: {result['documents'][0]}\")\n",
    "print(f\"  Metadata: {result['metadatas'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac3ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete documents\n",
    "print(f\"Documents before delete: {collection.count()}\")\n",
    "\n",
    "# Delete by ID\n",
    "collection.delete(ids=[\"doc_9\"])\n",
    "\n",
    "# Delete by filter\n",
    "collection.delete(where={\"type\": \"markup\"})\n",
    "\n",
    "print(f\"Documents after delete: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facdeed1",
   "metadata": {},
   "source": [
    "### 3.6 Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa278a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Clean up any existing database\n",
    "persist_path = \"./chroma_persistent_db\"\n",
    "if os.path.exists(persist_path):\n",
    "    shutil.rmtree(persist_path)\n",
    "\n",
    "# Create persistent client\n",
    "persistent_client = chromadb.PersistentClient(path=persist_path)\n",
    "\n",
    "# Create and populate a collection\n",
    "persistent_collection = persistent_client.create_collection(\"persistent_docs\")\n",
    "persistent_collection.add(\n",
    "    documents=[\"This data will persist across sessions\"],\n",
    "    ids=[\"persistent_1\"]\n",
    ")\n",
    "\n",
    "print(f\"Data saved to: {persist_path}\")\n",
    "print(f\"Directory contents: {os.listdir(persist_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc62ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate restarting - create new client with same path\n",
    "del persistent_client  # Close the client\n",
    "\n",
    "# Reconnect to persisted data\n",
    "restored_client = chromadb.PersistentClient(path=persist_path)\n",
    "restored_collection = restored_client.get_collection(\"persistent_docs\")\n",
    "\n",
    "# Verify data persisted\n",
    "result = restored_collection.get(ids=[\"persistent_1\"])\n",
    "print(f\"Restored document: {result['documents'][0]}\")\n",
    "\n",
    "# Cleanup\n",
    "shutil.rmtree(persist_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a4019b",
   "metadata": {},
   "source": [
    "## 4. FAISS Implementation <a id=\"faiss\"></a>\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) is a library for efficient similarity search and clustering of dense vectors. It's highly optimized and supports GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870e2e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation\n",
    "# !pip install faiss-cpu  # CPU version\n",
    "# !pip install faiss-gpu  # GPU version (requires CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a6883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(f\"FAISS version: {faiss.__version__}\")\n",
    "print(f\"Number of available threads: {faiss.omp_get_max_threads()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e84882e",
   "metadata": {},
   "source": [
    "### 4.1 Creating Indices\n",
    "\n",
    "FAISS offers multiple index types for different use cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6974aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "documents = [\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"Deep learning uses neural networks with many layers.\",\n",
    "    \"Natural language processing enables computers to understand text.\",\n",
    "    \"Computer vision allows machines to interpret visual data.\",\n",
    "    \"Reinforcement learning trains agents through rewards and penalties.\",\n",
    "    \"Transfer learning reuses models trained on different tasks.\",\n",
    "    \"Generative AI creates new content like text and images.\",\n",
    "    \"Supervised learning uses labeled data for training.\"\n",
    "]\n",
    "\n",
    "# Generate embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(documents)\n",
    "\n",
    "# Convert to float32 (FAISS requirement)\n",
    "embeddings = np.array(embeddings).astype('float32')\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Dimension: {embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2abef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flat Index (exact search, brute force)\n",
    "dimension = embeddings.shape[1]\n",
    "\n",
    "# L2 (Euclidean) distance\n",
    "index_flat_l2 = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Inner Product (for cosine similarity, normalize vectors first)\n",
    "index_flat_ip = faiss.IndexFlatIP(dimension)\n",
    "\n",
    "print(f\"Index type: {type(index_flat_l2).__name__}\")\n",
    "print(f\"Is trained: {index_flat_l2.is_trained}\")\n",
    "print(f\"Total vectors: {index_flat_l2.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541b0138",
   "metadata": {},
   "source": [
    "### 4.2 Inserting Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77040ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add vectors to the index\n",
    "index_flat_l2.add(embeddings)\n",
    "\n",
    "print(f\"Vectors added: {index_flat_l2.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bbb8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cosine similarity, normalize embeddings and use Inner Product\n",
    "normalized_embeddings = embeddings.copy()\n",
    "faiss.normalize_L2(normalized_embeddings)  # In-place normalization\n",
    "\n",
    "index_flat_ip.add(normalized_embeddings)\n",
    "print(f\"Normalized vectors added: {index_flat_ip.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3543ab8",
   "metadata": {},
   "source": [
    "### 4.3 Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3101396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic search with L2 distance\n",
    "query = \"How do neural networks learn?\"\n",
    "query_embedding = model.encode([query]).astype('float32')\n",
    "\n",
    "k = 3  # Number of nearest neighbors\n",
    "distances, indices = index_flat_l2.search(query_embedding, k)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Top 3 results (L2 distance):\")\n",
    "for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):\n",
    "    print(f\"{i+1}. [Index: {idx}, Distance: {dist:.4f}] {documents[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc1cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity search (using normalized vectors)\n",
    "query_normalized = query_embedding.copy()\n",
    "faiss.normalize_L2(query_normalized)\n",
    "\n",
    "similarities, indices = index_flat_ip.search(query_normalized, k)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Top 3 results (Cosine similarity):\")\n",
    "for i, (idx, sim) in enumerate(zip(indices[0], similarities[0])):\n",
    "    print(f\"{i+1}. [Index: {idx}, Similarity: {sim:.4f}] {documents[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082c2465",
   "metadata": {},
   "source": [
    "### 4.4 ANN Indices (HNSW and IVF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c18eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HNSW Index\n",
    "M = 16  # Number of connections per layer\n",
    "index_hnsw = faiss.IndexHNSWFlat(dimension, M)\n",
    "\n",
    "# Set construction parameters\n",
    "index_hnsw.hnsw.efConstruction = 40  # Higher = more accurate, slower build\n",
    "index_hnsw.hnsw.efSearch = 16  # Higher = more accurate, slower search\n",
    "\n",
    "# Add vectors\n",
    "index_hnsw.add(embeddings)\n",
    "\n",
    "# Search\n",
    "distances, indices = index_hnsw.search(query_embedding, k)\n",
    "\n",
    "print(\"HNSW Index Results:\")\n",
    "for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):\n",
    "    print(f\"{i+1}. [Distance: {dist:.4f}] {documents[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995cf1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IVF Index (requires training)\n",
    "nlist = 4  # Number of clusters (typically sqrt(n) to n/10)\n",
    "\n",
    "# Create quantizer (for coarse search)\n",
    "quantizer = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Create IVF index\n",
    "index_ivf = faiss.IndexIVFFlat(quantizer, dimension, nlist)\n",
    "\n",
    "# Train on data (learn cluster centroids)\n",
    "print(f\"Before training - is_trained: {index_ivf.is_trained}\")\n",
    "index_ivf.train(embeddings)\n",
    "print(f\"After training - is_trained: {index_ivf.is_trained}\")\n",
    "\n",
    "# Add vectors\n",
    "index_ivf.add(embeddings)\n",
    "\n",
    "# Set search parameter\n",
    "index_ivf.nprobe = 2  # Number of clusters to search\n",
    "\n",
    "# Search\n",
    "distances, indices = index_ivf.search(query_embedding, k)\n",
    "\n",
    "print(\"\\nIVF Index Results:\")\n",
    "for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):\n",
    "    print(f\"{i+1}. [Distance: {dist:.4f}] {documents[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b228ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IVF with Product Quantization (for memory efficiency)\n",
    "m = 8  # Number of sub-vectors (dimension must be divisible by m)\n",
    "nbits = 8  # Bits per sub-vector (typically 8)\n",
    "\n",
    "# Adjust dimension to be divisible by m\n",
    "# For 384-dim embeddings, m=8 works (384/8 = 48)\n",
    "\n",
    "index_ivfpq = faiss.IndexIVFPQ(quantizer, dimension, nlist, m, nbits)\n",
    "\n",
    "# Train\n",
    "index_ivfpq.train(embeddings)\n",
    "index_ivfpq.add(embeddings)\n",
    "index_ivfpq.nprobe = 2\n",
    "\n",
    "# Search\n",
    "distances, indices = index_ivfpq.search(query_embedding, k)\n",
    "\n",
    "print(\"IVF-PQ Index Results:\")\n",
    "for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):\n",
    "    print(f\"{i+1}. [Distance: {dist:.4f}] {documents[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a62626",
   "metadata": {},
   "source": [
    "### 4.5 Index Factory (Convenient Index Creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d7e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS Index Factory - create complex indices with a simple string\n",
    "# Format: \"preprocessing,coarse_quantizer,fine_quantizer\"\n",
    "\n",
    "# Examples:\n",
    "index_strings = {\n",
    "    \"Flat\": \"Flat\",  # Exact search\n",
    "    \"IVF100,Flat\": \"IVF100,Flat\",  # IVF with 100 cells\n",
    "    \"IVF100,PQ8\": \"IVF100,PQ8\",  # IVF + Product Quantization\n",
    "    \"HNSW32\": \"HNSW32\",  # HNSW with M=32\n",
    "    \"HNSW32,Flat\": \"HNSW32,Flat\",  # HNSW for coarse + Flat for fine\n",
    "}\n",
    "\n",
    "# Create using factory\n",
    "index = faiss.index_factory(dimension, \"IVF4,Flat\")\n",
    "index.train(embeddings)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(f\"Index created: {index}\")\n",
    "print(f\"Total vectors: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b428c36",
   "metadata": {},
   "source": [
    "### 4.6 ID Mapping (Storing Custom IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8773f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS returns indices 0 to n-1 by default\n",
    "# Use IndexIDMap to store custom IDs\n",
    "\n",
    "# Create base index\n",
    "base_index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Wrap with ID mapping\n",
    "index_with_ids = faiss.IndexIDMap(base_index)\n",
    "\n",
    "# Custom IDs (e.g., database primary keys)\n",
    "custom_ids = np.array([1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008], dtype=np.int64)\n",
    "\n",
    "# Add with custom IDs\n",
    "index_with_ids.add_with_ids(embeddings, custom_ids)\n",
    "\n",
    "# Search returns custom IDs\n",
    "distances, indices = index_with_ids.search(query_embedding, k)\n",
    "\n",
    "print(\"Results with custom IDs:\")\n",
    "for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):\n",
    "    doc_index = list(custom_ids).index(idx)  # Map back to document\n",
    "    print(f\"{i+1}. [ID: {idx}, Distance: {dist:.4f}] {documents[doc_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76486aa4",
   "metadata": {},
   "source": [
    "### 4.7 Persistence (Saving and Loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35414ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Save index to disk\n",
    "index_path = \"./faiss_index.bin\"\n",
    "faiss.write_index(index_flat_l2, index_path)\n",
    "\n",
    "print(f\"Index saved to: {index_path}\")\n",
    "print(f\"File size: {os.path.getsize(index_path) / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd64be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load index from disk\n",
    "loaded_index = faiss.read_index(index_path)\n",
    "\n",
    "print(f\"Loaded index: {type(loaded_index).__name__}\")\n",
    "print(f\"Total vectors: {loaded_index.ntotal}\")\n",
    "\n",
    "# Verify search works\n",
    "distances, indices = loaded_index.search(query_embedding, k)\n",
    "print(f\"\\nSearch result indices: {indices[0]}\")\n",
    "\n",
    "# Cleanup\n",
    "os.remove(index_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b238ce",
   "metadata": {},
   "source": [
    "### 4.8 Filtering in FAISS\n",
    "\n",
    "FAISS doesn't have built-in metadata filtering like ChromaDB. Here are common approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 1: Pre-filtering with IDSelector\n",
    "# Create metadata store\n",
    "metadata = {\n",
    "    0: {\"category\": \"ml\", \"year\": 2020},\n",
    "    1: {\"category\": \"dl\", \"year\": 2021},\n",
    "    2: {\"category\": \"nlp\", \"year\": 2019},\n",
    "    3: {\"category\": \"cv\", \"year\": 2022},\n",
    "    4: {\"category\": \"rl\", \"year\": 2020},\n",
    "    5: {\"category\": \"ml\", \"year\": 2018},\n",
    "    6: {\"category\": \"genai\", \"year\": 2023},\n",
    "    7: {\"category\": \"ml\", \"year\": 2015}\n",
    "}\n",
    "\n",
    "# Filter IDs based on metadata\n",
    "def get_filtered_ids(metadata, filter_fn):\n",
    "    \"\"\"Return IDs that match the filter function.\"\"\"\n",
    "    return np.array([k for k, v in metadata.items() if filter_fn(v)], dtype=np.int64)\n",
    "\n",
    "# Get IDs for documents after 2019\n",
    "valid_ids = get_filtered_ids(metadata, lambda x: x['year'] >= 2020)\n",
    "print(f\"IDs with year >= 2020: {valid_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d926e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 2: Post-filtering (over-fetch and filter)\n",
    "def search_with_filter(index, query_vec, k, metadata, filter_fn, fetch_k=None):\n",
    "    \"\"\"\n",
    "    Search with post-filtering.\n",
    "    \n",
    "    Args:\n",
    "        index: FAISS index\n",
    "        query_vec: Query embedding\n",
    "        k: Number of results to return\n",
    "        metadata: Metadata dictionary\n",
    "        filter_fn: Function to filter metadata\n",
    "        fetch_k: Number of candidates to fetch (default: k * 4)\n",
    "    \"\"\"\n",
    "    if fetch_k is None:\n",
    "        fetch_k = min(k * 4, index.ntotal)\n",
    "    \n",
    "    # Fetch more candidates than needed\n",
    "    distances, indices = index.search(query_vec, fetch_k)\n",
    "    \n",
    "    # Filter results\n",
    "    results = []\n",
    "    for idx, dist in zip(indices[0], distances[0]):\n",
    "        if idx in metadata and filter_fn(metadata[idx]):\n",
    "            results.append((idx, dist))\n",
    "            if len(results) == k:\n",
    "                break\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Search for ML category only\n",
    "results = search_with_filter(\n",
    "    index_flat_l2, \n",
    "    query_embedding, \n",
    "    k=2, \n",
    "    metadata=metadata,\n",
    "    filter_fn=lambda x: x['category'] == 'ml'\n",
    ")\n",
    "\n",
    "print(\"Filtered results (category='ml'):\")\n",
    "for idx, dist in results:\n",
    "    print(f\"  [ID: {idx}, Distance: {dist:.4f}] {documents[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a35a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 3: Separate indices per category (for large-scale filtering)\n",
    "def create_category_indices(embeddings, metadata):\n",
    "    \"\"\"Create separate FAISS index for each category.\"\"\"\n",
    "    category_indices = {}\n",
    "    category_id_maps = {}\n",
    "    \n",
    "    # Group by category\n",
    "    for idx, meta in metadata.items():\n",
    "        cat = meta['category']\n",
    "        if cat not in category_indices:\n",
    "            category_indices[cat] = []\n",
    "            category_id_maps[cat] = []\n",
    "        category_indices[cat].append(embeddings[idx])\n",
    "        category_id_maps[cat].append(idx)\n",
    "    \n",
    "    # Create indices\n",
    "    faiss_indices = {}\n",
    "    for cat, vectors in category_indices.items():\n",
    "        vectors = np.array(vectors).astype('float32')\n",
    "        index = faiss.IndexFlatL2(dimension)\n",
    "        index.add(vectors)\n",
    "        faiss_indices[cat] = {\n",
    "            'index': index,\n",
    "            'id_map': category_id_maps[cat]\n",
    "        }\n",
    "    \n",
    "    return faiss_indices\n",
    "\n",
    "# Create category-specific indices\n",
    "cat_indices = create_category_indices(embeddings, metadata)\n",
    "print(f\"Categories: {list(cat_indices.keys())}\")\n",
    "\n",
    "# Search only in 'ml' category\n",
    "ml_index = cat_indices['ml']['index']\n",
    "ml_id_map = cat_indices['ml']['id_map']\n",
    "\n",
    "distances, indices = ml_index.search(query_embedding, k=2)\n",
    "\n",
    "print(\"\\nSearch in 'ml' category:\")\n",
    "for idx, dist in zip(indices[0], distances[0]):\n",
    "    original_id = ml_id_map[idx]\n",
    "    print(f\"  [Original ID: {original_id}] {documents[original_id]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bb47a9",
   "metadata": {},
   "source": [
    "## 5. Comparison & Best Practices <a id=\"comparison\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dafebe2",
   "metadata": {},
   "source": [
    "### Feature Comparison\n",
    "\n",
    "| Feature | ChromaDB | FAISS |\n",
    "|---------|----------|-------|\n",
    "| **Ease of Use** | ⭐⭐⭐⭐⭐ Simple API | ⭐⭐⭐ Lower-level |\n",
    "| **Built-in Embeddings** | ✅ Yes | ❌ No |\n",
    "| **Metadata Filtering** | ✅ Native | ❌ Manual |\n",
    "| **Persistence** | ✅ Built-in | ✅ Manual save/load |\n",
    "| **GPU Support** | ❌ No | ✅ Yes |\n",
    "| **Scalability** | Medium (millions) | High (billions) |\n",
    "| **Memory Efficiency** | Medium | High (with PQ) |\n",
    "| **Index Types** | HNSW only | Many options |\n",
    "| **Best For** | RAG, prototyping | Production, large-scale |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a06e5a",
   "metadata": {},
   "source": [
    "### Best Practices\n",
    "\n",
    "#### Embedding Generation\n",
    "1. **Normalize embeddings** for cosine similarity\n",
    "2. **Batch processing** for efficiency\n",
    "3. **Use appropriate models** for your domain (e.g., `bge-large` for retrieval)\n",
    "\n",
    "#### Index Selection\n",
    "1. **< 10K vectors**: Use Flat index (exact search)\n",
    "2. **10K - 1M vectors**: Use HNSW or IVF\n",
    "3. **> 1M vectors**: Use IVF-PQ or HNSW with careful tuning\n",
    "\n",
    "#### Performance Tuning\n",
    "```python\n",
    "# HNSW tuning\n",
    "index_hnsw.hnsw.efSearch = 64  # Increase for better recall\n",
    "\n",
    "# IVF tuning\n",
    "index_ivf.nprobe = 10  # Increase for better recall (default: 1)\n",
    "```\n",
    "\n",
    "#### Memory Management\n",
    "1. Use **float16** if precision allows\n",
    "2. Use **Product Quantization** for large datasets\n",
    "3. **Shard indices** across machines for very large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ff82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison example\n",
    "import time\n",
    "\n",
    "def benchmark_search(index, query, n_queries=100, k=10):\n",
    "    \"\"\"Benchmark search performance.\"\"\"\n",
    "    start = time.time()\n",
    "    for _ in range(n_queries):\n",
    "        index.search(query, k)\n",
    "    elapsed = time.time() - start\n",
    "    return elapsed / n_queries * 1000  # ms per query\n",
    "\n",
    "# Create different index types\n",
    "indices = {\n",
    "    'Flat (Exact)': faiss.IndexFlatL2(dimension),\n",
    "    'HNSW (M=16)': faiss.IndexHNSWFlat(dimension, 16),\n",
    "    'IVF (nlist=4)': faiss.index_factory(dimension, \"IVF4,Flat\")\n",
    "}\n",
    "\n",
    "# Train and add vectors\n",
    "for name, index in indices.items():\n",
    "    if hasattr(index, 'train') and not index.is_trained:\n",
    "        index.train(embeddings)\n",
    "    index.add(embeddings)\n",
    "\n",
    "# Benchmark\n",
    "print(\"Search Performance (ms per query):\")\n",
    "print(\"-\" * 40)\n",
    "for name, index in indices.items():\n",
    "    ms = benchmark_search(index, query_embedding, n_queries=100)\n",
    "    print(f\"{name:20s}: {ms:.4f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a55030",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "**Choose ChromaDB when:**\n",
    "- Building RAG applications quickly\n",
    "- Need built-in embedding generation\n",
    "- Require metadata filtering\n",
    "- Dataset is < 1M vectors\n",
    "\n",
    "**Choose FAISS when:**\n",
    "- Need maximum performance\n",
    "- Working with very large datasets (billions)\n",
    "- Need GPU acceleration\n",
    "- Want fine-grained control over indexing\n",
    "\n",
    "**Hybrid Approach:**\n",
    "Many production systems use FAISS as the underlying index with a wrapper that provides ChromaDB-like features (metadata, persistence, etc.)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
