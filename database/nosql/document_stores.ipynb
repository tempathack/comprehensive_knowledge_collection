{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2736283c",
   "metadata": {},
   "source": [
    "# Document Stores: MongoDB & CouchDB Patterns\n",
    "\n",
    "Document stores are a category of NoSQL databases that store data as semi-structured documents (JSON, BSON, XML). They offer **schema flexibility**, **horizontal scalability**, and **developer-friendly data models**.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Document** | Self-contained data unit (JSON-like), analogous to a row in RDBMS |\n",
    "| **Collection** | Group of documents, analogous to a table |\n",
    "| **Database** | Container for collections |\n",
    "| **BSON** | Binary JSON - MongoDB's storage format with extended types |\n",
    "| **Schema Flexibility** | Documents in the same collection can have different fields |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cc3211",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. The Document Model\n",
    "\n",
    "### What is a Document?\n",
    "\n",
    "A document is a **self-describing, hierarchical data structure** that maps closely to objects in programming languages.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"_id\": \"ObjectId('507f1f77bcf86cd799439011')\",\n",
    "  \"name\": \"John Doe\",\n",
    "  \"email\": \"john@example.com\",\n",
    "  \"orders\": [\n",
    "    { \"product\": \"Laptop\", \"price\": 1200 },\n",
    "    { \"product\": \"Mouse\", \"price\": 25 }\n",
    "  ],\n",
    "  \"address\": {\n",
    "    \"city\": \"New York\",\n",
    "    \"zip\": \"10001\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### BSON (Binary JSON)\n",
    "\n",
    "MongoDB uses **BSON** internally, which extends JSON with:\n",
    "- **Additional data types**: `ObjectId`, `Date`, `Binary`, `Decimal128`, `Int32`, `Int64`\n",
    "- **Efficient encoding**: Faster parsing and traversal\n",
    "- **Field ordering**: Preserves insertion order\n",
    "\n",
    "### Schema Flexibility\n",
    "\n",
    "Unlike RDBMS, document stores allow:\n",
    "- **Polymorphic documents** - different structures in the same collection\n",
    "- **Evolution without migrations** - add/remove fields anytime\n",
    "- **Optional validation** - enforce schema when needed (JSON Schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c790a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Any\n",
    "from uuid import uuid4\n",
    "from copy import deepcopy\n",
    "\n",
    "# Simulated ObjectId generator\n",
    "def generate_object_id() -> str:\n",
    "    return str(uuid4())[:24]\n",
    "\n",
    "# Example documents with schema flexibility\n",
    "documents = [\n",
    "    {\n",
    "        \"_id\": generate_object_id(),\n",
    "        \"type\": \"user\",\n",
    "        \"name\": \"Alice Johnson\",\n",
    "        \"email\": \"alice@example.com\",\n",
    "        \"created_at\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"_id\": generate_object_id(),\n",
    "        \"type\": \"user\",\n",
    "        \"name\": \"Bob Smith\",\n",
    "        \"email\": \"bob@example.com\",\n",
    "        \"phone\": \"+1-555-0123\",  # Additional field - schema flexibility!\n",
    "        \"preferences\": {\"theme\": \"dark\", \"notifications\": True},\n",
    "        \"created_at\": datetime.now().isoformat()\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Schema Flexibility Demo:\")\n",
    "for doc in documents:\n",
    "    print(f\"  Document fields: {list(doc.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0477211",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Simulated Document Store\n",
    "\n",
    "Let's build a simple in-memory document store to understand core operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e61d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentStore:\n",
    "    \"\"\"Simulated document store mimicking MongoDB operations.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.collections: dict[str, list[dict]] = {}\n",
    "    \n",
    "    def get_collection(self, name: str) -> list:\n",
    "        \"\"\"Get or create a collection.\"\"\"\n",
    "        if name not in self.collections:\n",
    "            self.collections[name] = []\n",
    "        return self.collections[name]\n",
    "    \n",
    "    # --- CRUD Operations ---\n",
    "    \n",
    "    def insert_one(self, collection: str, document: dict) -> str:\n",
    "        \"\"\"Insert a single document.\"\"\"\n",
    "        doc = deepcopy(document)\n",
    "        if \"_id\" not in doc:\n",
    "            doc[\"_id\"] = generate_object_id()\n",
    "        self.get_collection(collection).append(doc)\n",
    "        return doc[\"_id\"]\n",
    "    \n",
    "    def insert_many(self, collection: str, documents: list[dict]) -> list[str]:\n",
    "        \"\"\"Insert multiple documents.\"\"\"\n",
    "        return [self.insert_one(collection, doc) for doc in documents]\n",
    "    \n",
    "    def find(self, collection: str, query: dict = None) -> list[dict]:\n",
    "        \"\"\"Find documents matching query.\"\"\"\n",
    "        query = query or {}\n",
    "        results = []\n",
    "        for doc in self.get_collection(collection):\n",
    "            if self._matches(doc, query):\n",
    "                results.append(deepcopy(doc))\n",
    "        return results\n",
    "    \n",
    "    def find_one(self, collection: str, query: dict) -> dict | None:\n",
    "        \"\"\"Find a single document.\"\"\"\n",
    "        results = self.find(collection, query)\n",
    "        return results[0] if results else None\n",
    "    \n",
    "    def update_one(self, collection: str, query: dict, update: dict) -> int:\n",
    "        \"\"\"Update first matching document. Returns count of modified docs.\"\"\"\n",
    "        for doc in self.get_collection(collection):\n",
    "            if self._matches(doc, query):\n",
    "                self._apply_update(doc, update)\n",
    "                return 1\n",
    "        return 0\n",
    "    \n",
    "    def delete_one(self, collection: str, query: dict) -> int:\n",
    "        \"\"\"Delete first matching document.\"\"\"\n",
    "        coll = self.get_collection(collection)\n",
    "        for i, doc in enumerate(coll):\n",
    "            if self._matches(doc, query):\n",
    "                coll.pop(i)\n",
    "                return 1\n",
    "        return 0\n",
    "    \n",
    "    # --- Helper Methods ---\n",
    "    \n",
    "    def _matches(self, doc: dict, query: dict) -> bool:\n",
    "        \"\"\"Check if document matches query (simplified).\"\"\"\n",
    "        for key, value in query.items():\n",
    "            # Handle nested keys with dot notation\n",
    "            keys = key.split(\".\")\n",
    "            current = doc\n",
    "            for k in keys:\n",
    "                if isinstance(current, dict) and k in current:\n",
    "                    current = current[k]\n",
    "                else:\n",
    "                    return False\n",
    "            if current != value:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def _apply_update(self, doc: dict, update: dict) -> None:\n",
    "        \"\"\"Apply update operators (simplified).\"\"\"\n",
    "        if \"$set\" in update:\n",
    "            for key, value in update[\"$set\"].items():\n",
    "                doc[key] = value\n",
    "        if \"$unset\" in update:\n",
    "            for key in update[\"$unset\"]:\n",
    "                doc.pop(key, None)\n",
    "        if \"$inc\" in update:\n",
    "            for key, value in update[\"$inc\"].items():\n",
    "                doc[key] = doc.get(key, 0) + value\n",
    "        if \"$push\" in update:\n",
    "            for key, value in update[\"$push\"].items():\n",
    "                if key not in doc:\n",
    "                    doc[key] = []\n",
    "                doc[key].append(value)\n",
    "\n",
    "# Initialize store\n",
    "db = DocumentStore()\n",
    "print(\"DocumentStore initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2121f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo CRUD operations\n",
    "\n",
    "# Insert documents\n",
    "users = [\n",
    "    {\"name\": \"Alice\", \"age\": 30, \"department\": \"Engineering\", \"skills\": [\"Python\", \"MongoDB\"]},\n",
    "    {\"name\": \"Bob\", \"age\": 25, \"department\": \"Engineering\", \"skills\": [\"JavaScript\", \"React\"]},\n",
    "    {\"name\": \"Charlie\", \"age\": 35, \"department\": \"Sales\", \"skills\": [\"CRM\", \"Analytics\"]},\n",
    "    {\"name\": \"Diana\", \"age\": 28, \"department\": \"Engineering\", \"skills\": [\"Python\", \"Docker\"]},\n",
    "]\n",
    "\n",
    "ids = db.insert_many(\"users\", users)\n",
    "print(f\"Inserted {len(ids)} documents\")\n",
    "\n",
    "# Find operations\n",
    "print(\"\\n--- Find all Engineering users ---\")\n",
    "engineers = db.find(\"users\", {\"department\": \"Engineering\"})\n",
    "for eng in engineers:\n",
    "    print(f\"  {eng['name']}: {eng['skills']}\")\n",
    "\n",
    "# Update operations\n",
    "print(\"\\n--- Update Alice's age ---\")\n",
    "db.update_one(\"users\", {\"name\": \"Alice\"}, {\"$inc\": {\"age\": 1}})\n",
    "alice = db.find_one(\"users\", {\"name\": \"Alice\"})\n",
    "print(f\"  Alice's new age: {alice['age']}\")\n",
    "\n",
    "# Add new skill using $push\n",
    "print(\"\\n--- Add skill to Bob ---\")\n",
    "db.update_one(\"users\", {\"name\": \"Bob\"}, {\"$push\": {\"skills\": \"Node.js\"}})\n",
    "bob = db.find_one(\"users\", {\"name\": \"Bob\"})\n",
    "print(f\"  Bob's skills: {bob['skills']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d0670",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Embedding vs Referencing Patterns\n",
    "\n",
    "A critical design decision in document databases is choosing between **embedding** related data or **referencing** it.\n",
    "\n",
    "### Embedding (Denormalization)\n",
    "\n",
    "Store related data **within** the same document.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"_id\": \"order_001\",\n",
    "  \"customer\": {\n",
    "    \"name\": \"John Doe\",\n",
    "    \"email\": \"john@example.com\"\n",
    "  },\n",
    "  \"items\": [\n",
    "    { \"product\": \"Laptop\", \"price\": 1200, \"qty\": 1 }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "- Single query retrieves all data\n",
    "- Atomic updates within document\n",
    "- Better read performance\n",
    "\n",
    "**Cons:**\n",
    "- Document size limits (16MB in MongoDB)\n",
    "- Data duplication\n",
    "- Harder to update shared data\n",
    "\n",
    "---\n",
    "\n",
    "### Referencing (Normalization)\n",
    "\n",
    "Store related data in **separate documents** with references.\n",
    "\n",
    "```json\n",
    "// Order document\n",
    "{\n",
    "  \"_id\": \"order_001\",\n",
    "  \"customer_id\": \"user_001\",\n",
    "  \"item_ids\": [\"item_001\", \"item_002\"]\n",
    "}\n",
    "\n",
    "// User document\n",
    "{\n",
    "  \"_id\": \"user_001\",\n",
    "  \"name\": \"John Doe\",\n",
    "  \"email\": \"john@example.com\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "- No data duplication\n",
    "- Smaller documents\n",
    "- Flexible relationships\n",
    "\n",
    "**Cons:**\n",
    "- Multiple queries required\n",
    "- No join support (application-level joins)\n",
    "- Less atomic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f946d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 1: Embedded Documents\n",
    "print(\"=\" * 50)\n",
    "print(\"EMBEDDED PATTERN\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Order with embedded customer and items\n",
    "embedded_order = {\n",
    "    \"_id\": \"order_001\",\n",
    "    \"order_date\": \"2026-02-01\",\n",
    "    \"status\": \"shipped\",\n",
    "    \"customer\": {\n",
    "        \"name\": \"John Doe\",\n",
    "        \"email\": \"john@example.com\",\n",
    "        \"shipping_address\": {\n",
    "            \"street\": \"123 Main St\",\n",
    "            \"city\": \"New York\",\n",
    "            \"zip\": \"10001\"\n",
    "        }\n",
    "    },\n",
    "    \"items\": [\n",
    "        {\"product\": \"Laptop\", \"sku\": \"LAP-001\", \"price\": 1200, \"qty\": 1},\n",
    "        {\"product\": \"Mouse\", \"sku\": \"MOU-003\", \"price\": 25, \"qty\": 2}\n",
    "    ],\n",
    "    \"total\": 1250\n",
    "}\n",
    "\n",
    "db.insert_one(\"orders_embedded\", embedded_order)\n",
    "\n",
    "# Single query gets everything!\n",
    "order = db.find_one(\"orders_embedded\", {\"_id\": \"order_001\"})\n",
    "print(f\"\\nOrder for: {order['customer']['name']}\")\n",
    "print(f\"Ship to: {order['customer']['shipping_address']['city']}\")\n",
    "print(f\"Items: {len(order['items'])}\")\n",
    "print(f\"Total: ${order['total']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df5e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 2: Referenced Documents\n",
    "print(\"=\" * 50)\n",
    "print(\"REFERENCED PATTERN\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Separate collections with references\n",
    "customer = {\n",
    "    \"_id\": \"user_001\",\n",
    "    \"name\": \"Jane Smith\",\n",
    "    \"email\": \"jane@example.com\",\n",
    "    \"addresses\": [\n",
    "        {\"type\": \"home\", \"city\": \"Boston\", \"zip\": \"02101\"},\n",
    "        {\"type\": \"work\", \"city\": \"Cambridge\", \"zip\": \"02139\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "products = [\n",
    "    {\"_id\": \"prod_001\", \"name\": \"Keyboard\", \"price\": 150, \"stock\": 50},\n",
    "    {\"_id\": \"prod_002\", \"name\": \"Monitor\", \"price\": 400, \"stock\": 20}\n",
    "]\n",
    "\n",
    "referenced_order = {\n",
    "    \"_id\": \"order_002\",\n",
    "    \"customer_id\": \"user_001\",  # Reference\n",
    "    \"items\": [\n",
    "        {\"product_id\": \"prod_001\", \"qty\": 2},  # References\n",
    "        {\"product_id\": \"prod_002\", \"qty\": 1}\n",
    "    ],\n",
    "    \"shipping_address_type\": \"work\"\n",
    "}\n",
    "\n",
    "db.insert_one(\"customers\", customer)\n",
    "db.insert_many(\"products\", products)\n",
    "db.insert_one(\"orders_referenced\", referenced_order)\n",
    "\n",
    "# Application-level join (multiple queries)\n",
    "def get_order_with_details(order_id: str) -> dict:\n",
    "    \"\"\"Simulate $lookup by joining data at application level.\"\"\"\n",
    "    order = db.find_one(\"orders_referenced\", {\"_id\": order_id})\n",
    "    if not order:\n",
    "        return None\n",
    "    \n",
    "    # Fetch customer\n",
    "    customer = db.find_one(\"customers\", {\"_id\": order[\"customer_id\"]})\n",
    "    \n",
    "    # Fetch products and calculate total\n",
    "    total = 0\n",
    "    enriched_items = []\n",
    "    for item in order[\"items\"]:\n",
    "        product = db.find_one(\"products\", {\"_id\": item[\"product_id\"]})\n",
    "        line_total = product[\"price\"] * item[\"qty\"]\n",
    "        enriched_items.append({\n",
    "            \"product\": product[\"name\"],\n",
    "            \"price\": product[\"price\"],\n",
    "            \"qty\": item[\"qty\"],\n",
    "            \"subtotal\": line_total\n",
    "        })\n",
    "        total += line_total\n",
    "    \n",
    "    return {\n",
    "        \"order_id\": order[\"_id\"],\n",
    "        \"customer_name\": customer[\"name\"],\n",
    "        \"items\": enriched_items,\n",
    "        \"total\": total\n",
    "    }\n",
    "\n",
    "result = get_order_with_details(\"order_002\")\n",
    "print(f\"\\nOrder: {result['order_id']}\")\n",
    "print(f\"Customer: {result['customer_name']}\")\n",
    "for item in result['items']:\n",
    "    print(f\"  - {item['product']} x{item['qty']} = ${item['subtotal']}\")\n",
    "print(f\"Total: ${result['total']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cb4ca6",
   "metadata": {},
   "source": [
    "### Decision Matrix: When to Embed vs Reference\n",
    "\n",
    "| Factor | Embed | Reference |\n",
    "|--------|-------|----------|\n",
    "| **Relationship** | 1:1, 1:few | 1:many, many:many |\n",
    "| **Read pattern** | Data accessed together | Data accessed separately |\n",
    "| **Update pattern** | Child data rarely changes | Child data changes frequently |\n",
    "| **Data size** | Child data is small | Child data is large or unbounded |\n",
    "| **Atomicity** | Need atomic operations | Can tolerate eventual consistency |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9bf5da",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Aggregation Pipeline Concepts\n",
    "\n",
    "The aggregation pipeline is a powerful framework for data transformation and analysis. Data flows through **stages**, each transforming the documents.\n",
    "\n",
    "### Common Pipeline Stages\n",
    "\n",
    "| Stage | Purpose |\n",
    "|-------|--------|\n",
    "| `$match` | Filter documents (like WHERE) |\n",
    "| `$group` | Group by field and aggregate (like GROUP BY) |\n",
    "| `$project` | Reshape documents (like SELECT) |\n",
    "| `$sort` | Order documents |\n",
    "| `$limit` / `$skip` | Pagination |\n",
    "| `$unwind` | Deconstruct arrays |\n",
    "| `$lookup` | Left outer join |\n",
    "| `$addFields` | Add computed fields |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc740f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AggregationPipeline:\n",
    "    \"\"\"Simulated MongoDB-style aggregation pipeline.\"\"\"\n",
    "    \n",
    "    def __init__(self, documents: list[dict]):\n",
    "        self.documents = deepcopy(documents)\n",
    "    \n",
    "    def match(self, criteria: dict) -> 'AggregationPipeline':\n",
    "        \"\"\"$match - Filter documents.\"\"\"\n",
    "        self.documents = [\n",
    "            doc for doc in self.documents\n",
    "            if all(doc.get(k) == v for k, v in criteria.items())\n",
    "        ]\n",
    "        return self\n",
    "    \n",
    "    def project(self, fields: dict) -> 'AggregationPipeline':\n",
    "        \"\"\"$project - Select/reshape fields.\"\"\"\n",
    "        result = []\n",
    "        for doc in self.documents:\n",
    "            new_doc = {}\n",
    "            for field, include in fields.items():\n",
    "                if include and field in doc:\n",
    "                    new_doc[field] = doc[field]\n",
    "            result.append(new_doc)\n",
    "        self.documents = result\n",
    "        return self\n",
    "    \n",
    "    def group(self, _id: str, **accumulators) -> 'AggregationPipeline':\n",
    "        \"\"\"$group - Group and aggregate.\"\"\"\n",
    "        groups = {}\n",
    "        for doc in self.documents:\n",
    "            key = doc.get(_id) if _id else None\n",
    "            if key not in groups:\n",
    "                groups[key] = {\"_id\": key, \"_docs\": []}\n",
    "            groups[key][\"_docs\"].append(doc)\n",
    "        \n",
    "        result = []\n",
    "        for key, group in groups.items():\n",
    "            doc = {\"_id\": key}\n",
    "            for acc_name, (op, field) in accumulators.items():\n",
    "                values = [d.get(field, 0) for d in group[\"_docs\"]]\n",
    "                if op == \"$sum\":\n",
    "                    doc[acc_name] = sum(values)\n",
    "                elif op == \"$avg\":\n",
    "                    doc[acc_name] = sum(values) / len(values) if values else 0\n",
    "                elif op == \"$count\":\n",
    "                    doc[acc_name] = len(group[\"_docs\"])\n",
    "                elif op == \"$max\":\n",
    "                    doc[acc_name] = max(values) if values else None\n",
    "                elif op == \"$min\":\n",
    "                    doc[acc_name] = min(values) if values else None\n",
    "            result.append(doc)\n",
    "        self.documents = result\n",
    "        return self\n",
    "    \n",
    "    def sort(self, field: str, ascending: bool = True) -> 'AggregationPipeline':\n",
    "        \"\"\"$sort - Order documents.\"\"\"\n",
    "        self.documents.sort(key=lambda x: x.get(field, 0), reverse=not ascending)\n",
    "        return self\n",
    "    \n",
    "    def limit(self, n: int) -> 'AggregationPipeline':\n",
    "        \"\"\"$limit - Return first n documents.\"\"\"\n",
    "        self.documents = self.documents[:n]\n",
    "        return self\n",
    "    \n",
    "    def unwind(self, array_field: str) -> 'AggregationPipeline':\n",
    "        \"\"\"$unwind - Deconstruct array field.\"\"\"\n",
    "        result = []\n",
    "        for doc in self.documents:\n",
    "            arr = doc.get(array_field, [])\n",
    "            if isinstance(arr, list):\n",
    "                for item in arr:\n",
    "                    new_doc = deepcopy(doc)\n",
    "                    new_doc[array_field] = item\n",
    "                    result.append(new_doc)\n",
    "            else:\n",
    "                result.append(doc)\n",
    "        self.documents = result\n",
    "        return self\n",
    "    \n",
    "    def result(self) -> list[dict]:\n",
    "        \"\"\"Return aggregation result.\"\"\"\n",
    "        return self.documents\n",
    "\n",
    "print(\"AggregationPipeline class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample sales data for aggregation\n",
    "sales = [\n",
    "    {\"product\": \"Laptop\", \"category\": \"Electronics\", \"price\": 1200, \"qty\": 2, \"region\": \"North\"},\n",
    "    {\"product\": \"Mouse\", \"category\": \"Electronics\", \"price\": 25, \"qty\": 10, \"region\": \"South\"},\n",
    "    {\"product\": \"Desk\", \"category\": \"Furniture\", \"price\": 350, \"qty\": 3, \"region\": \"North\"},\n",
    "    {\"product\": \"Chair\", \"category\": \"Furniture\", \"price\": 200, \"qty\": 5, \"region\": \"East\"},\n",
    "    {\"product\": \"Keyboard\", \"category\": \"Electronics\", \"price\": 150, \"qty\": 8, \"region\": \"North\"},\n",
    "    {\"product\": \"Monitor\", \"category\": \"Electronics\", \"price\": 400, \"qty\": 4, \"region\": \"South\"},\n",
    "    {\"product\": \"Bookshelf\", \"category\": \"Furniture\", \"price\": 180, \"qty\": 2, \"region\": \"East\"},\n",
    "]\n",
    "\n",
    "# Add computed revenue field\n",
    "for sale in sales:\n",
    "    sale[\"revenue\"] = sale[\"price\"] * sale[\"qty\"]\n",
    "\n",
    "print(\"Sales Data:\")\n",
    "for s in sales:\n",
    "    print(f\"  {s['product']:12} | {s['category']:12} | ${s['revenue']:>6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7edb8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation Example 1: Total revenue by category\n",
    "print(\"=\" * 50)\n",
    "print(\"Revenue by Category (sorted descending)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "result = (\n",
    "    AggregationPipeline(sales)\n",
    "    .group(\n",
    "        \"category\",\n",
    "        total_revenue=(\"$sum\", \"revenue\"),\n",
    "        count=(\"$count\", \"_id\")\n",
    "    )\n",
    "    .sort(\"total_revenue\", ascending=False)\n",
    "    .result()\n",
    ")\n",
    "\n",
    "for doc in result:\n",
    "    print(f\"  {doc['_id']:15} Revenue: ${doc['total_revenue']:>6}  Items: {doc['count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652dd49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation Example 2: Electronics products with revenue > $1000\n",
    "print(\"=\" * 50)\n",
    "print(\"Electronics with Revenue > $1000\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "result = (\n",
    "    AggregationPipeline(sales)\n",
    "    .match({\"category\": \"Electronics\"})\n",
    "    .project({\"product\": True, \"revenue\": True})\n",
    "    .result()\n",
    ")\n",
    "\n",
    "# Filter for revenue > 1000 (simulating $match after $project)\n",
    "high_revenue = [r for r in result if r[\"revenue\"] > 1000]\n",
    "\n",
    "for doc in high_revenue:\n",
    "    print(f\"  {doc['product']:15} ${doc['revenue']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af98af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation Example 3: Unwind array and count skills\n",
    "print(\"=\" * 50)\n",
    "print(\"$unwind Example: Count skill occurrences\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "employees = [\n",
    "    {\"name\": \"Alice\", \"skills\": [\"Python\", \"MongoDB\", \"Docker\"]},\n",
    "    {\"name\": \"Bob\", \"skills\": [\"JavaScript\", \"MongoDB\", \"React\"]},\n",
    "    {\"name\": \"Charlie\", \"skills\": [\"Python\", \"PostgreSQL\", \"Docker\"]},\n",
    "]\n",
    "\n",
    "result = (\n",
    "    AggregationPipeline(employees)\n",
    "    .unwind(\"skills\")\n",
    "    .group(\n",
    "        \"skills\",\n",
    "        count=(\"$count\", \"_id\")\n",
    "    )\n",
    "    .sort(\"count\", ascending=False)\n",
    "    .result()\n",
    ")\n",
    "\n",
    "print(\"\\nSkill Frequency:\")\n",
    "for doc in result:\n",
    "    bar = \"‚ñà\" * doc[\"count\"]\n",
    "    print(f\"  {doc['_id']:12} {bar} ({doc['count']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c702ca73",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. MongoDB vs CouchDB Comparison\n",
    "\n",
    "| Feature | MongoDB | CouchDB |\n",
    "|---------|---------|--------|\n",
    "| **Query Language** | MQL (MongoDB Query Language) | Mango queries, MapReduce |\n",
    "| **Replication** | Replica Sets | Multi-Master |\n",
    "| **Conflict Resolution** | Last-write-wins | MVCC, revision history |\n",
    "| **Protocol** | Binary (wire protocol) | HTTP/REST |\n",
    "| **Offline Support** | Limited | Built-in (PouchDB sync) |\n",
    "| **Indexing** | B-tree, Text, Geospatial | B-tree views |\n",
    "| **Transactions** | Multi-document ACID (4.0+) | Document-level only |\n",
    "| **Use Case** | General purpose, real-time | Offline-first, sync-heavy |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9926805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CouchDB-style revision tracking simulation\n",
    "class CouchDBDocument:\n",
    "    \"\"\"Simulates CouchDB's MVCC (Multi-Version Concurrency Control).\"\"\"\n",
    "    \n",
    "    def __init__(self, doc_id: str, data: dict):\n",
    "        self._id = doc_id\n",
    "        self._rev = self._generate_rev(1)\n",
    "        self._data = deepcopy(data)\n",
    "        self._history = [{\n",
    "            \"_rev\": self._rev,\n",
    "            \"data\": deepcopy(data)\n",
    "        }]\n",
    "    \n",
    "    def _generate_rev(self, num: int) -> str:\n",
    "        \"\"\"Generate CouchDB-style revision ID.\"\"\"\n",
    "        import hashlib\n",
    "        hash_part = hashlib.md5(str(datetime.now()).encode()).hexdigest()[:8]\n",
    "        return f\"{num}-{hash_part}\"\n",
    "    \n",
    "    def update(self, rev: str, new_data: dict) -> str:\n",
    "        \"\"\"Update document (requires current revision).\"\"\"\n",
    "        if rev != self._rev:\n",
    "            raise Exception(f\"Conflict! Expected rev {self._rev}, got {rev}\")\n",
    "        \n",
    "        rev_num = int(self._rev.split(\"-\")[0]) + 1\n",
    "        self._rev = self._generate_rev(rev_num)\n",
    "        self._data = deepcopy(new_data)\n",
    "        self._history.append({\n",
    "            \"_rev\": self._rev,\n",
    "            \"data\": deepcopy(new_data)\n",
    "        })\n",
    "        return self._rev\n",
    "    \n",
    "    def get(self) -> dict:\n",
    "        \"\"\"Get current document state.\"\"\"\n",
    "        return {\n",
    "            \"_id\": self._id,\n",
    "            \"_rev\": self._rev,\n",
    "            **self._data\n",
    "        }\n",
    "    \n",
    "    def get_revision_history(self) -> list:\n",
    "        \"\"\"Get all revisions.\"\"\"\n",
    "        return self._history\n",
    "\n",
    "# Demo CouchDB-style updates\n",
    "print(\"CouchDB MVCC Demo\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "doc = CouchDBDocument(\"user_001\", {\"name\": \"Alice\", \"status\": \"active\"})\n",
    "print(f\"\\nInitial: {doc.get()}\")\n",
    "\n",
    "# Update with correct revision\n",
    "current_rev = doc.get()[\"_rev\"]\n",
    "new_rev = doc.update(current_rev, {\"name\": \"Alice\", \"status\": \"premium\"})\n",
    "print(f\"After update: {doc.get()}\")\n",
    "\n",
    "# Try update with stale revision (conflict!)\n",
    "try:\n",
    "    doc.update(current_rev, {\"name\": \"Alice\", \"status\": \"inactive\"})  # Using old rev\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è  {e}\")\n",
    "\n",
    "print(f\"\\nRevision History ({len(doc.get_revision_history())} versions):\")\n",
    "for rev in doc.get_revision_history():\n",
    "    print(f\"  {rev['_rev']}: {rev['data']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52e95ac",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Best Practices & Patterns\n",
    "\n",
    "### Schema Design Patterns\n",
    "\n",
    "| Pattern | Description | Use Case |\n",
    "|---------|-------------|----------|\n",
    "| **Attribute** | Store dynamic attributes as array of key-value pairs | Product variants, custom fields |\n",
    "| **Bucket** | Group time-series data into fixed-size buckets | IoT, logs, metrics |\n",
    "| **Computed** | Pre-compute and store derived values | Analytics, dashboards |\n",
    "| **Extended Reference** | Embed frequently-accessed fields from referenced docs | Reduce lookups |\n",
    "| **Outlier** | Handle documents that exceed normal size | Social media (viral posts) |\n",
    "| **Polymorphic** | Store different entity types in same collection | Content management |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce998475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern: Attribute Pattern\n",
    "print(\"Attribute Pattern Example\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Instead of fixed schema with many optional fields:\n",
    "# {\"color\": \"red\", \"size\": \"L\", \"material\": \"cotton\", \"weight\": null, ...}\n",
    "\n",
    "# Use attribute pattern:\n",
    "product_with_attributes = {\n",
    "    \"_id\": \"prod_123\",\n",
    "    \"name\": \"T-Shirt\",\n",
    "    \"price\": 29.99,\n",
    "    \"attributes\": [\n",
    "        {\"k\": \"color\", \"v\": \"red\"},\n",
    "        {\"k\": \"size\", \"v\": \"L\"},\n",
    "        {\"k\": \"material\", \"v\": \"cotton\"},\n",
    "        {\"k\": \"brand\", \"v\": \"Acme\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Easy to query: db.products.find({\"attributes.k\": \"color\", \"attributes.v\": \"red\"})\n",
    "# Easy to add new attributes without schema changes\n",
    "\n",
    "print(json.dumps(product_with_attributes, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57416c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern: Bucket Pattern (for time-series data)\n",
    "print(\"\\nBucket Pattern Example\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Instead of one document per reading:\n",
    "# {\"sensor_id\": \"s1\", \"timestamp\": \"...\", \"value\": 23.5}\n",
    "\n",
    "# Bucket by hour:\n",
    "sensor_bucket = {\n",
    "    \"_id\": \"sensor_001_2026020115\",  # sensor_id + YYYYMMDDHH\n",
    "    \"sensor_id\": \"sensor_001\",\n",
    "    \"bucket_start\": \"2026-02-01T15:00:00Z\",\n",
    "    \"bucket_end\": \"2026-02-01T15:59:59Z\",\n",
    "    \"count\": 4,\n",
    "    \"sum\": 94.2,  # Pre-computed for fast aggregation\n",
    "    \"min\": 22.5,\n",
    "    \"max\": 24.1,\n",
    "    \"readings\": [\n",
    "        {\"t\": \"2026-02-01T15:00:00Z\", \"v\": 23.5},\n",
    "        {\"t\": \"2026-02-01T15:15:00Z\", \"v\": 24.1},\n",
    "        {\"t\": \"2026-02-01T15:30:00Z\", \"v\": 22.5},\n",
    "        {\"t\": \"2026-02-01T15:45:00Z\", \"v\": 24.1},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Benefits:\n",
    "# - Fewer documents (1 per hour vs 60 per hour)\n",
    "# - Pre-computed aggregates\n",
    "# - Efficient time-range queries\n",
    "\n",
    "print(json.dumps(sensor_bucket, indent=2))\n",
    "print(f\"\\nAverage reading: {sensor_bucket['sum'] / sensor_bucket['count']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794cb7ce",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Key Takeaways\n",
    "\n",
    "### Document Model Fundamentals\n",
    "- Documents are **self-contained, hierarchical data structures** (JSON/BSON)\n",
    "- **Schema flexibility** allows evolution without migrations\n",
    "- BSON extends JSON with types like `ObjectId`, `Date`, `Decimal128`\n",
    "\n",
    "### Embedding vs Referencing\n",
    "- **Embed** when: data is accessed together, 1:1 or 1:few relationships, child data is small\n",
    "- **Reference** when: data is accessed independently, many:many relationships, child data changes frequently\n",
    "- Trade-off: **Read performance (embed)** vs **Write flexibility (reference)**\n",
    "\n",
    "### Aggregation Pipeline\n",
    "- Chain of **stages** that transform documents: `$match` ‚Üí `$group` ‚Üí `$project` ‚Üí `$sort`\n",
    "- **$unwind** expands arrays for per-element analysis\n",
    "- **$lookup** enables joins (use sparingly for performance)\n",
    "\n",
    "### MongoDB vs CouchDB\n",
    "- **MongoDB**: General-purpose, strong consistency, rich queries\n",
    "- **CouchDB**: Offline-first, MVCC conflict resolution, HTTP/REST API\n",
    "\n",
    "### Design Patterns\n",
    "- **Attribute Pattern**: Dynamic key-value pairs for flexible schemas\n",
    "- **Bucket Pattern**: Group time-series data for efficiency\n",
    "- **Extended Reference**: Denormalize frequently-accessed fields\n",
    "\n",
    "### When to Choose Document Stores\n",
    "‚úÖ Rapid development with evolving schemas  \n",
    "‚úÖ Hierarchical data that maps to application objects  \n",
    "‚úÖ Read-heavy workloads with embedded data  \n",
    "‚ùå Complex multi-table transactions  \n",
    "‚ùå Highly normalized relational data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
