{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da2e277b",
   "metadata": {},
   "source": [
    "# Replication & Sharding — Overview\n",
    "\n",
    "## Purpose\n",
    "Understand the fundamental strategies for scaling databases horizontally: **replication** for high availability and read performance, and **sharding** for distributing data across multiple nodes to handle massive datasets.\n",
    "\n",
    "## Key Questions\n",
    "1. When should you replicate data vs. shard it?\n",
    "2. What are the consistency trade-offs in replication?\n",
    "3. How do you choose a good sharding key?\n",
    "4. What happens when a shard becomes a hotspot?\n",
    "5. How do replication and sharding work together in production systems?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60a3e72",
   "metadata": {},
   "source": [
    "---\n",
    "## Why We Need Replication\n",
    "\n",
    "**Replication** copies data across multiple database nodes. Each copy is called a **replica**.\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "| Benefit | Description |\n",
    "|---------|-------------|\n",
    "| **High Availability** | If one node fails, others continue serving requests |\n",
    "| **Read Scaling** | Distribute read queries across replicas to reduce load on primary |\n",
    "| **Durability** | Data survives hardware failures when stored on multiple machines |\n",
    "| **Geographic Distribution** | Place replicas closer to users for lower latency |\n",
    "\n",
    "### Replication Topologies\n",
    "\n",
    "1. **Leader-Follower (Primary-Replica)**\n",
    "   - One leader handles writes; followers replicate and serve reads\n",
    "   - Simple but leader is a single point of failure for writes\n",
    "\n",
    "2. **Leader-Leader (Multi-Primary)**\n",
    "   - Multiple nodes accept writes\n",
    "   - Requires conflict resolution\n",
    "\n",
    "3. **Leaderless**\n",
    "   - Any node can accept reads/writes (e.g., Cassandra, DynamoDB)\n",
    "   - Uses quorum-based consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b0e9d2",
   "metadata": {},
   "source": [
    "---\n",
    "## Why We Need Sharding\n",
    "\n",
    "**Sharding** (horizontal partitioning) splits data across multiple database instances. Each instance holds a subset of the data.\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "| Benefit | Description |\n",
    "|---------|-------------|\n",
    "| **Horizontal Scaling** | Add more shards to handle increased load |\n",
    "| **Data Size** | No single machine needs to hold the entire dataset |\n",
    "| **Write Scaling** | Distribute writes across multiple nodes |\n",
    "| **Query Performance** | Smaller indexes per shard = faster lookups |\n",
    "\n",
    "### Sharding Strategies\n",
    "\n",
    "1. **Range-Based Sharding**\n",
    "   - Partition by value ranges (e.g., A-M on shard 1, N-Z on shard 2)\n",
    "   - Good for range queries, but can cause hotspots\n",
    "\n",
    "2. **Hash-Based Sharding**\n",
    "   - Hash the shard key to determine placement\n",
    "   - Even distribution, but range queries require scatter-gather\n",
    "\n",
    "3. **Directory-Based Sharding**\n",
    "   - Lookup table maps keys to shards\n",
    "   - Flexible but adds lookup overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c62fa",
   "metadata": {},
   "source": [
    "---\n",
    "## Replication vs. Sharding: Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0652159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create comparison visualization\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Replication: Same Data, Multiple Copies', \n",
    "                    'Sharding: Data Split Across Nodes'),\n",
    "    horizontal_spacing=0.15\n",
    ")\n",
    "\n",
    "# Colors for data segments\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
    "\n",
    "# Replication visualization (left) - 3 replicas with same data\n",
    "replica_positions = [0.5, 2, 3.5]\n",
    "replica_labels = ['Primary', 'Replica 1', 'Replica 2']\n",
    "\n",
    "for i, (x, label) in enumerate(zip(replica_positions, replica_labels)):\n",
    "    # Each replica has ALL data (stacked bars)\n",
    "    for j, color in enumerate(colors):\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=[label],\n",
    "                y=[25],\n",
    "                name=f'Data Segment {j+1}' if i == 0 else None,\n",
    "                marker_color=color,\n",
    "                showlegend=(i == 0),\n",
    "                legendgroup=f'seg{j}',\n",
    "                hovertemplate=f'{label}<br>Data Segment {j+1}<extra></extra>'\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "# Sharding visualization (right) - data split across shards\n",
    "shard_labels = ['Shard 1', 'Shard 2', 'Shard 3', 'Shard 4']\n",
    "shard_data = [\n",
    "    [100, 0, 0, 0],   # Shard 1 has segment 1\n",
    "    [0, 100, 0, 0],   # Shard 2 has segment 2\n",
    "    [0, 0, 100, 0],   # Shard 3 has segment 3\n",
    "    [0, 0, 0, 100],   # Shard 4 has segment 4\n",
    "]\n",
    "\n",
    "for j, color in enumerate(colors):\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=shard_labels,\n",
    "            y=[shard_data[i][j] for i in range(4)],\n",
    "            marker_color=color,\n",
    "            showlegend=False,\n",
    "            hovertemplate='%{x}<br>Data Segment ' + str(j+1) + '<extra></extra>'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text='<b>Replication vs Sharding Concepts</b>',\n",
    "        x=0.5,\n",
    "        font=dict(size=18)\n",
    "    ),\n",
    "    barmode='stack',\n",
    "    height=450,\n",
    "    legend=dict(\n",
    "        orientation='h',\n",
    "        yanchor='bottom',\n",
    "        y=-0.2,\n",
    "        xanchor='center',\n",
    "        x=0.5\n",
    "    ),\n",
    "    annotations=[\n",
    "        dict(\n",
    "            text='↑ All nodes have complete copy of data',\n",
    "            x=0.18, y=-0.08, xref='paper', yref='paper',\n",
    "            showarrow=False, font=dict(size=11, color='#555')\n",
    "        ),\n",
    "        dict(\n",
    "            text='↑ Each node has unique subset of data',\n",
    "            x=0.82, y=-0.08, xref='paper', yref='paper',\n",
    "            showarrow=False, font=dict(size=11, color='#555')\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title_text='Data Volume', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Data Volume', row=1, col=2)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a4abbc",
   "metadata": {},
   "source": [
    "---\n",
    "## When to Use Each Strategy\n",
    "\n",
    "| Scenario | Replication | Sharding |\n",
    "|----------|:-----------:|:--------:|\n",
    "| Read-heavy workload | ✅ | ➖ |\n",
    "| Write-heavy workload | ➖ | ✅ |\n",
    "| High availability requirement | ✅ | ➖ |\n",
    "| Data exceeds single node capacity | ➖ | ✅ |\n",
    "| Low-latency global access | ✅ | ➖ |\n",
    "| Need to scale writes linearly | ➖ | ✅ |\n",
    "\n",
    "### Combined Approach (Production Reality)\n",
    "\n",
    "Most production systems use **both**:\n",
    "- **Shard** data across multiple partitions\n",
    "- **Replicate** each shard for availability\n",
    "\n",
    "Example: A 12-node cluster might have 4 shards × 3 replicas each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a25549",
   "metadata": {},
   "source": [
    "---\n",
    "## ✅ Takeaways\n",
    "\n",
    "1. **Replication** creates copies of data for **availability**, **read scaling**, and **durability**\n",
    "\n",
    "2. **Sharding** partitions data for **horizontal scaling** and handling **large datasets**\n",
    "\n",
    "3. **Replication doesn't scale writes** — all replicas must process the same writes\n",
    "\n",
    "4. **Sharding adds complexity** — cross-shard queries, rebalancing, and hotspot management\n",
    "\n",
    "5. **Production systems combine both** — shard for scale, replicate each shard for resilience\n",
    "\n",
    "6. **Choose your shard key carefully** — it determines data distribution and query efficiency"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}