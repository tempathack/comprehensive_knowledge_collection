{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "342ab6f3",
   "metadata": {},
   "source": [
    "# Sharding Patterns: Range, Hash, and Directory\n",
    "\n",
    "**Sharding** (also known as horizontal partitioning) is a database scaling strategy that distributes data across multiple servers or nodes. Each shard holds a subset of the total data, enabling:\n",
    "\n",
    "- **Horizontal scalability** â€“ Add more nodes to handle increased load\n",
    "- **Improved performance** â€“ Queries target specific shards\n",
    "- **Fault isolation** â€“ Failure in one shard doesn't affect others\n",
    "\n",
    "This notebook explores three fundamental sharding strategies:\n",
    "\n",
    "| Strategy | Description | Best For |\n",
    "|----------|-------------|----------|\n",
    "| **Range Sharding** | Data partitioned by value ranges | Time-series, sequential data |\n",
    "| **Hash Sharding** | Data distributed using hash function | Even distribution, random access |\n",
    "| **Directory Sharding** | Lookup table maps keys to shards | Complex routing rules, multi-tenant |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a00595",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Range Sharding\n",
    "\n",
    "Range sharding partitions data based on ranges of a **shard key** value. Each shard is responsible for a contiguous range.\n",
    "\n",
    "### Characteristics\n",
    "- âœ… **Range queries are efficient** â€“ Data for a range resides on one or few shards\n",
    "- âœ… **Easy to understand** â€“ Clear boundaries between shards\n",
    "- âŒ **Hot spots** â€“ Uneven data distribution if ranges are poorly chosen\n",
    "- âŒ **Sequential inserts** â€“ New data may overwhelm a single shard\n",
    "\n",
    "### Example Use Cases\n",
    "- Time-series data (partition by date/month)\n",
    "- Geographic data (partition by region)\n",
    "- Alphabetical data (partition by first letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3727d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass, field\n",
    "import hashlib\n",
    "import bisect\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RangeShard:\n",
    "    \"\"\"A shard that handles a specific range of keys.\"\"\"\n",
    "    name: str\n",
    "    min_key: int  # Inclusive\n",
    "    max_key: int  # Exclusive\n",
    "    data: Dict[int, Any] = field(default_factory=dict)\n",
    "    \n",
    "    def contains(self, key: int) -> bool:\n",
    "        return self.min_key <= key < self.max_key\n",
    "    \n",
    "    def insert(self, key: int, value: Any) -> None:\n",
    "        if not self.contains(key):\n",
    "            raise ValueError(f\"Key {key} outside range [{self.min_key}, {self.max_key})\")\n",
    "        self.data[key] = value\n",
    "    \n",
    "    def get(self, key: int) -> Optional[Any]:\n",
    "        return self.data.get(key)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class RangeShardedDB:\n",
    "    \"\"\"Database with range-based sharding.\"\"\"\n",
    "    \n",
    "    def __init__(self, shard_ranges: List[Tuple[str, int, int]]):\n",
    "        \"\"\"\n",
    "        Initialize with shard definitions.\n",
    "        \n",
    "        Args:\n",
    "            shard_ranges: List of (shard_name, min_key, max_key) tuples\n",
    "        \"\"\"\n",
    "        self.shards = [\n",
    "            RangeShard(name=name, min_key=min_k, max_key=max_k)\n",
    "            for name, min_k, max_k in shard_ranges\n",
    "        ]\n",
    "        # Sort by min_key for efficient lookup\n",
    "        self.shards.sort(key=lambda s: s.min_key)\n",
    "        self._boundaries = [s.min_key for s in self.shards]\n",
    "    \n",
    "    def _get_shard(self, key: int) -> RangeShard:\n",
    "        \"\"\"Find the shard responsible for a given key.\"\"\"\n",
    "        idx = bisect.bisect_right(self._boundaries, key) - 1\n",
    "        if idx < 0 or idx >= len(self.shards):\n",
    "            raise ValueError(f\"No shard found for key {key}\")\n",
    "        shard = self.shards[idx]\n",
    "        if not shard.contains(key):\n",
    "            raise ValueError(f\"No shard found for key {key}\")\n",
    "        return shard\n",
    "    \n",
    "    def insert(self, key: int, value: Any) -> str:\n",
    "        \"\"\"Insert a key-value pair, returns shard name.\"\"\"\n",
    "        shard = self._get_shard(key)\n",
    "        shard.insert(key, value)\n",
    "        return shard.name\n",
    "    \n",
    "    def get(self, key: int) -> Tuple[Optional[Any], str]:\n",
    "        \"\"\"Get a value by key, returns (value, shard_name).\"\"\"\n",
    "        shard = self._get_shard(key)\n",
    "        return shard.get(key), shard.name\n",
    "    \n",
    "    def range_query(self, start: int, end: int) -> List[Tuple[int, Any, str]]:\n",
    "        \"\"\"Query a range of keys, returns list of (key, value, shard_name).\"\"\"\n",
    "        results = []\n",
    "        for shard in self.shards:\n",
    "            # Check if shard range overlaps with query range\n",
    "            if shard.max_key <= start or shard.min_key >= end:\n",
    "                continue\n",
    "            for key, value in shard.data.items():\n",
    "                if start <= key < end:\n",
    "                    results.append((key, value, shard.name))\n",
    "        return sorted(results, key=lambda x: x[0])\n",
    "    \n",
    "    def get_distribution(self) -> Dict[str, int]:\n",
    "        \"\"\"Get the number of records in each shard.\"\"\"\n",
    "        return {shard.name: len(shard) for shard in self.shards}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ad2ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Range sharding by user ID\n",
    "range_db = RangeShardedDB([\n",
    "    (\"shard_A\", 0, 1000),      # Users 0-999\n",
    "    (\"shard_B\", 1000, 2000),   # Users 1000-1999\n",
    "    (\"shard_C\", 2000, 3000),   # Users 2000-2999\n",
    "])\n",
    "\n",
    "# Insert sample data\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "users = [\n",
    "    (random.randint(0, 2999), f\"user_{i}@example.com\")\n",
    "    for i in range(50)\n",
    "]\n",
    "\n",
    "for user_id, email in users:\n",
    "    shard = range_db.insert(user_id, {\"email\": email, \"id\": user_id})\n",
    "    \n",
    "# Check distribution\n",
    "print(\"ğŸ“Š Data Distribution:\")\n",
    "for shard_name, count in range_db.get_distribution().items():\n",
    "    print(f\"  {shard_name}: {count} records\")\n",
    "\n",
    "# Perform a range query\n",
    "print(\"\\nğŸ” Range Query (keys 500-1500):\")\n",
    "results = range_db.range_query(500, 1500)\n",
    "for key, value, shard in results[:5]:  # Show first 5\n",
    "    print(f\"  Key {key} -> {shard}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a485e427",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Hash Sharding\n",
    "\n",
    "Hash sharding uses a **hash function** to determine which shard holds a piece of data. The hash of the shard key is computed, then mapped to a shard (typically using modulo).\n",
    "\n",
    "### Characteristics\n",
    "- âœ… **Even distribution** â€“ Hash functions spread data uniformly\n",
    "- âœ… **No hot spots** â€“ Sequential keys are distributed across shards\n",
    "- âŒ **Range queries inefficient** â€“ Must query all shards\n",
    "- âŒ **Resharding is expensive** â€“ Adding shards requires data migration\n",
    "\n",
    "### Hash Function Formula\n",
    "$$\\text{shard\\_index} = \\text{hash}(\\text{key}) \\mod N$$\n",
    "\n",
    "Where $N$ is the number of shards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ad2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HashShard:\n",
    "    \"\"\"A shard in a hash-partitioned database.\"\"\"\n",
    "    name: str\n",
    "    index: int\n",
    "    data: Dict[str, Any] = field(default_factory=dict)\n",
    "    \n",
    "    def insert(self, key: str, value: Any) -> None:\n",
    "        self.data[key] = value\n",
    "    \n",
    "    def get(self, key: str) -> Optional[Any]:\n",
    "        return self.data.get(key)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class HashShardedDB:\n",
    "    \"\"\"Database with hash-based sharding.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_shards: int):\n",
    "        self.num_shards = num_shards\n",
    "        self.shards = [\n",
    "            HashShard(name=f\"shard_{i}\", index=i)\n",
    "            for i in range(num_shards)\n",
    "        ]\n",
    "    \n",
    "    def _hash_key(self, key: str) -> int:\n",
    "        \"\"\"Compute hash of a key.\"\"\"\n",
    "        # Using MD5 for consistent hashing (not for security)\n",
    "        hash_bytes = hashlib.md5(str(key).encode()).digest()\n",
    "        return int.from_bytes(hash_bytes[:4], 'big')\n",
    "    \n",
    "    def _get_shard_index(self, key: str) -> int:\n",
    "        \"\"\"Determine which shard holds a key.\"\"\"\n",
    "        return self._hash_key(key) % self.num_shards\n",
    "    \n",
    "    def _get_shard(self, key: str) -> HashShard:\n",
    "        \"\"\"Get the shard for a key.\"\"\"\n",
    "        return self.shards[self._get_shard_index(key)]\n",
    "    \n",
    "    def insert(self, key: str, value: Any) -> str:\n",
    "        \"\"\"Insert a key-value pair.\"\"\"\n",
    "        shard = self._get_shard(key)\n",
    "        shard.insert(key, value)\n",
    "        return shard.name\n",
    "    \n",
    "    def get(self, key: str) -> Tuple[Optional[Any], str]:\n",
    "        \"\"\"Get a value by key.\"\"\"\n",
    "        shard = self._get_shard(key)\n",
    "        return shard.get(key), shard.name\n",
    "    \n",
    "    def get_distribution(self) -> Dict[str, int]:\n",
    "        \"\"\"Get the number of records in each shard.\"\"\"\n",
    "        return {shard.name: len(shard) for shard in self.shards}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66517695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Hash sharding with 4 shards\n",
    "hash_db = HashShardedDB(num_shards=4)\n",
    "\n",
    "# Insert sequential user IDs (would cause hot spots in range sharding)\n",
    "for i in range(100):\n",
    "    user_id = f\"user_{i:05d}\"\n",
    "    hash_db.insert(user_id, {\"name\": f\"User {i}\", \"id\": user_id})\n",
    "\n",
    "# Check distribution - should be relatively even\n",
    "print(\"ğŸ“Š Hash Sharding Distribution (100 sequential keys):\")\n",
    "distribution = hash_db.get_distribution()\n",
    "for shard_name, count in distribution.items():\n",
    "    bar = \"â–ˆ\" * count\n",
    "    print(f\"  {shard_name}: {count:3d} {bar}\")\n",
    "\n",
    "# Demonstrate consistent routing\n",
    "print(\"\\nğŸ”— Key Routing Examples:\")\n",
    "for key in [\"user_00042\", \"user_00099\", \"user_00001\"]:\n",
    "    value, shard = hash_db.get(key)\n",
    "    print(f\"  {key} -> {shard}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cd4e32",
   "metadata": {},
   "source": [
    "### âš ï¸ The Resharding Problem\n",
    "\n",
    "When adding or removing shards with simple modulo hashing, **most keys get remapped**:\n",
    "\n",
    "```\n",
    "Before (3 shards): hash(key) % 3 = 2\n",
    "After  (4 shards): hash(key) % 4 = 1  â† Different shard!\n",
    "```\n",
    "\n",
    "This requires massive data migration. **Consistent hashing** solves this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d41009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the resharding problem\n",
    "def simulate_resharding(keys: List[str], old_shards: int, new_shards: int) -> float:\n",
    "    \"\"\"Calculate percentage of keys that change shards.\"\"\"\n",
    "    def hash_key(key: str) -> int:\n",
    "        return int.from_bytes(hashlib.md5(key.encode()).digest()[:4], 'big')\n",
    "    \n",
    "    moved = 0\n",
    "    for key in keys:\n",
    "        h = hash_key(key)\n",
    "        old_shard = h % old_shards\n",
    "        new_shard = h % new_shards\n",
    "        if old_shard != new_shard:\n",
    "            moved += 1\n",
    "    \n",
    "    return (moved / len(keys)) * 100\n",
    "\n",
    "# Test with 10,000 keys\n",
    "test_keys = [f\"key_{i}\" for i in range(10000)]\n",
    "\n",
    "print(\"ğŸ“¦ Data Migration with Simple Modulo Hashing:\")\n",
    "print(\"â”€\" * 45)\n",
    "for old, new in [(3, 4), (4, 5), (5, 6), (10, 11)]:\n",
    "    pct = simulate_resharding(test_keys, old, new)\n",
    "    print(f\"  {old} â†’ {new} shards: {pct:.1f}% keys need to move\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a9c903",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Consistent Hashing\n",
    "\n",
    "Consistent hashing minimizes key redistribution when nodes are added or removed. Instead of modulo, it uses a **hash ring**.\n",
    "\n",
    "### How It Works\n",
    "1. Both **nodes** and **keys** are hashed to positions on a virtual ring (0 to 2Â³Â² - 1)\n",
    "2. A key is assigned to the **first node clockwise** from its position\n",
    "3. When a node is added/removed, only keys between it and its neighbor move\n",
    "\n",
    "### Virtual Nodes (Vnodes)\n",
    "To improve distribution, each physical node is represented by multiple **virtual nodes** on the ring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b55ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsistentHashRing:\n",
    "    \"\"\"Consistent hashing implementation with virtual nodes.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_virtual_nodes: int = 150):\n",
    "        self.num_virtual_nodes = num_virtual_nodes\n",
    "        self.ring: Dict[int, str] = {}  # hash -> node_name\n",
    "        self.sorted_hashes: List[int] = []\n",
    "        self.nodes: set = set()\n",
    "    \n",
    "    def _hash(self, key: str) -> int:\n",
    "        \"\"\"Hash a key to a position on the ring.\"\"\"\n",
    "        return int(hashlib.md5(key.encode()).hexdigest(), 16)\n",
    "    \n",
    "    def add_node(self, node: str) -> None:\n",
    "        \"\"\"Add a node with virtual nodes to the ring.\"\"\"\n",
    "        self.nodes.add(node)\n",
    "        for i in range(self.num_virtual_nodes):\n",
    "            virtual_key = f\"{node}:vnode{i}\"\n",
    "            h = self._hash(virtual_key)\n",
    "            self.ring[h] = node\n",
    "            bisect.insort(self.sorted_hashes, h)\n",
    "    \n",
    "    def remove_node(self, node: str) -> None:\n",
    "        \"\"\"Remove a node from the ring.\"\"\"\n",
    "        self.nodes.discard(node)\n",
    "        for i in range(self.num_virtual_nodes):\n",
    "            virtual_key = f\"{node}:vnode{i}\"\n",
    "            h = self._hash(virtual_key)\n",
    "            if h in self.ring:\n",
    "                del self.ring[h]\n",
    "                self.sorted_hashes.remove(h)\n",
    "    \n",
    "    def get_node(self, key: str) -> Optional[str]:\n",
    "        \"\"\"Get the node responsible for a key.\"\"\"\n",
    "        if not self.ring:\n",
    "            return None\n",
    "        \n",
    "        h = self._hash(key)\n",
    "        # Find the first node clockwise from the key's position\n",
    "        idx = bisect.bisect(self.sorted_hashes, h)\n",
    "        if idx >= len(self.sorted_hashes):\n",
    "            idx = 0  # Wrap around\n",
    "        \n",
    "        return self.ring[self.sorted_hashes[idx]]\n",
    "    \n",
    "    def get_key_distribution(self, keys: List[str]) -> Dict[str, int]:\n",
    "        \"\"\"Get the distribution of keys across nodes.\"\"\"\n",
    "        distribution = {node: 0 for node in self.nodes}\n",
    "        for key in keys:\n",
    "            node = self.get_node(key)\n",
    "            if node:\n",
    "                distribution[node] += 1\n",
    "        return distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bd4c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Consistent hashing in action\n",
    "ring = ConsistentHashRing(num_virtual_nodes=150)\n",
    "\n",
    "# Add initial nodes\n",
    "for node in [\"node_A\", \"node_B\", \"node_C\"]:\n",
    "    ring.add_node(node)\n",
    "\n",
    "# Generate test keys\n",
    "test_keys = [f\"user:{i}\" for i in range(10000)]\n",
    "\n",
    "# Check initial distribution\n",
    "print(\"ğŸ“Š Initial Distribution (3 nodes):\")\n",
    "initial_dist = ring.get_key_distribution(test_keys)\n",
    "for node, count in sorted(initial_dist.items()):\n",
    "    pct = count / len(test_keys) * 100\n",
    "    bar = \"â–ˆ\" * int(pct)\n",
    "    print(f\"  {node}: {count:5d} ({pct:.1f}%) {bar}\")\n",
    "\n",
    "# Record which node each key maps to\n",
    "initial_mapping = {key: ring.get_node(key) for key in test_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be47e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new node and measure migration\n",
    "ring.add_node(\"node_D\")\n",
    "\n",
    "# Check new distribution\n",
    "print(\"ğŸ“Š Distribution After Adding node_D (4 nodes):\")\n",
    "new_dist = ring.get_key_distribution(test_keys)\n",
    "for node, count in sorted(new_dist.items()):\n",
    "    pct = count / len(test_keys) * 100\n",
    "    bar = \"â–ˆ\" * int(pct)\n",
    "    print(f\"  {node}: {count:5d} ({pct:.1f}%) {bar}\")\n",
    "\n",
    "# Calculate migration\n",
    "moved_keys = sum(\n",
    "    1 for key in test_keys \n",
    "    if ring.get_node(key) != initial_mapping[key]\n",
    ")\n",
    "migration_pct = moved_keys / len(test_keys) * 100\n",
    "\n",
    "print(f\"\\nğŸ“¦ Keys Migrated: {moved_keys:,} ({migration_pct:.1f}%)\")\n",
    "print(f\"   Optimal (1/N): {100/4:.1f}%\")\n",
    "print(f\"   vs Simple Hash: ~75%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67c69a5",
   "metadata": {},
   "source": [
    "### Visualizing the Hash Ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a9c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_hash_ring(ring: ConsistentHashRing, sample_keys: List[str] = None):\n",
    "    \"\"\"Visualize the consistent hash ring.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    # Draw the ring\n",
    "    theta = np.linspace(0, 2 * np.pi, 100)\n",
    "    ax.plot(np.cos(theta), np.sin(theta), 'k-', linewidth=2, alpha=0.3)\n",
    "    \n",
    "    # Color map for nodes\n",
    "    colors = plt.cm.Set2(np.linspace(0, 1, len(ring.nodes)))\n",
    "    node_colors = {node: colors[i] for i, node in enumerate(sorted(ring.nodes))}\n",
    "    \n",
    "    # Plot virtual nodes (sample only to avoid clutter)\n",
    "    max_ring = 2**128\n",
    "    sample_vnodes = list(ring.ring.items())[::10]  # Every 10th vnode\n",
    "    \n",
    "    for h, node in sample_vnodes:\n",
    "        angle = (h / max_ring) * 2 * np.pi\n",
    "        x, y = np.cos(angle) * 1.05, np.sin(angle) * 1.05\n",
    "        ax.scatter(x, y, c=[node_colors[node]], s=30, alpha=0.6, zorder=5)\n",
    "    \n",
    "    # Plot sample keys if provided\n",
    "    if sample_keys:\n",
    "        for key in sample_keys[:20]:  # Limit to 20 keys\n",
    "            h = ring._hash(key)\n",
    "            angle = (h / max_ring) * 2 * np.pi\n",
    "            x, y = np.cos(angle) * 0.85, np.sin(angle) * 0.85\n",
    "            \n",
    "            node = ring.get_node(key)\n",
    "            ax.scatter(x, y, c=[node_colors[node]], s=100, marker='*', \n",
    "                      edgecolors='black', linewidth=0.5, zorder=10)\n",
    "    \n",
    "    # Create legend\n",
    "    for node, color in node_colors.items():\n",
    "        ax.scatter([], [], c=[color], s=100, label=node)\n",
    "    ax.legend(loc='upper right', title='Nodes')\n",
    "    \n",
    "    ax.set_xlim(-1.3, 1.3)\n",
    "    ax.set_ylim(-1.3, 1.3)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Consistent Hash Ring\\n(dots = vnodes, stars = sample keys)', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the ring\n",
    "sample_keys = [f\"key_{i}\" for i in range(20)]\n",
    "visualize_hash_ring(ring, sample_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d20ad1",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Directory-Based Sharding\n",
    "\n",
    "Directory sharding uses a **lookup table** (directory) to map keys to shards. This provides maximum flexibility but adds a single point of lookup.\n",
    "\n",
    "### Characteristics\n",
    "- âœ… **Maximum flexibility** â€“ Any routing logic can be implemented\n",
    "- âœ… **Easy rebalancing** â€“ Just update the directory\n",
    "- âŒ **Lookup overhead** â€“ Every operation requires directory access\n",
    "- âŒ **Single point of failure** â€“ Directory must be highly available\n",
    "\n",
    "### Use Cases\n",
    "- Multi-tenant applications (tenant â†’ shard mapping)\n",
    "- Complex routing rules\n",
    "- Hybrid sharding strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f76ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DirectoryShard:\n",
    "    \"\"\"A shard in a directory-based sharded database.\"\"\"\n",
    "    name: str\n",
    "    capacity: int\n",
    "    data: Dict[str, Any] = field(default_factory=dict)\n",
    "    \n",
    "    @property\n",
    "    def usage(self) -> float:\n",
    "        return len(self.data) / self.capacity\n",
    "    \n",
    "    def is_full(self) -> bool:\n",
    "        return len(self.data) >= self.capacity\n",
    "\n",
    "\n",
    "class DirectoryShardedDB:\n",
    "    \"\"\"Database with directory-based sharding.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.shards: Dict[str, DirectoryShard] = {}\n",
    "        self.directory: Dict[str, str] = {}  # key -> shard_name mapping\n",
    "    \n",
    "    def add_shard(self, name: str, capacity: int = 1000) -> None:\n",
    "        \"\"\"Add a new shard.\"\"\"\n",
    "        self.shards[name] = DirectoryShard(name=name, capacity=capacity)\n",
    "    \n",
    "    def _find_available_shard(self) -> Optional[DirectoryShard]:\n",
    "        \"\"\"Find a shard with capacity.\"\"\"\n",
    "        for shard in self.shards.values():\n",
    "            if not shard.is_full():\n",
    "                return shard\n",
    "        return None\n",
    "    \n",
    "    def insert(self, key: str, value: Any) -> str:\n",
    "        \"\"\"Insert a key-value pair.\"\"\"\n",
    "        # Check if key already exists\n",
    "        if key in self.directory:\n",
    "            shard_name = self.directory[key]\n",
    "            self.shards[shard_name].data[key] = value\n",
    "            return shard_name\n",
    "        \n",
    "        # Find an available shard\n",
    "        shard = self._find_available_shard()\n",
    "        if not shard:\n",
    "            raise RuntimeError(\"All shards are full!\")\n",
    "        \n",
    "        # Insert and update directory\n",
    "        shard.data[key] = value\n",
    "        self.directory[key] = shard.name\n",
    "        return shard.name\n",
    "    \n",
    "    def get(self, key: str) -> Tuple[Optional[Any], Optional[str]]:\n",
    "        \"\"\"Get a value by key.\"\"\"\n",
    "        shard_name = self.directory.get(key)\n",
    "        if not shard_name:\n",
    "            return None, None\n",
    "        return self.shards[shard_name].data.get(key), shard_name\n",
    "    \n",
    "    def move_key(self, key: str, target_shard: str) -> bool:\n",
    "        \"\"\"Move a key to a different shard (rebalancing).\"\"\"\n",
    "        if key not in self.directory:\n",
    "            return False\n",
    "        if target_shard not in self.shards:\n",
    "            return False\n",
    "        if self.shards[target_shard].is_full():\n",
    "            return False\n",
    "        \n",
    "        # Move the data\n",
    "        source_shard = self.directory[key]\n",
    "        value = self.shards[source_shard].data.pop(key)\n",
    "        self.shards[target_shard].data[key] = value\n",
    "        self.directory[key] = target_shard\n",
    "        return True\n",
    "    \n",
    "    def get_shard_stats(self) -> Dict[str, Dict]:\n",
    "        \"\"\"Get statistics for all shards.\"\"\"\n",
    "        return {\n",
    "            name: {\"count\": len(shard.data), \"usage\": f\"{shard.usage:.1%}\"}\n",
    "            for name, shard in self.shards.items()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69057b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Multi-tenant SaaS application\n",
    "dir_db = DirectoryShardedDB()\n",
    "\n",
    "# Add shards with different capacities\n",
    "dir_db.add_shard(\"shard_premium\", capacity=100)   # Premium tier\n",
    "dir_db.add_shard(\"shard_standard_1\", capacity=500)\n",
    "dir_db.add_shard(\"shard_standard_2\", capacity=500)\n",
    "\n",
    "# Simulate tenant data insertion\n",
    "tenants = {\n",
    "    \"acme_corp\": \"Enterprise\",\n",
    "    \"startup_xyz\": \"Startup\",\n",
    "    \"bigco_inc\": \"Enterprise\",\n",
    "    \"small_biz\": \"SMB\",\n",
    "}\n",
    "\n",
    "for tenant, tier in tenants.items():\n",
    "    for i in range(50):\n",
    "        key = f\"{tenant}:data_{i}\"\n",
    "        shard = dir_db.insert(key, {\"tenant\": tenant, \"tier\": tier, \"id\": i})\n",
    "\n",
    "print(\"ğŸ“Š Shard Statistics:\")\n",
    "for shard, stats in dir_db.get_shard_stats().items():\n",
    "    print(f\"  {shard}: {stats['count']} records ({stats['usage']})\")\n",
    "\n",
    "# Demonstrate directory lookup\n",
    "print(\"\\nğŸ” Directory Lookups:\")\n",
    "for key in [\"acme_corp:data_0\", \"startup_xyz:data_25\"]:\n",
    "    value, shard = dir_db.get(key)\n",
    "    print(f\"  {key} -> {shard}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea26ac3",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Hot Spots and Rebalancing Challenges\n",
    "\n",
    "### Hot Spots\n",
    "\n",
    "A **hot spot** occurs when one shard receives disproportionately more traffic than others, causing:\n",
    "- Performance degradation\n",
    "- Increased latency\n",
    "- Potential resource exhaustion\n",
    "\n",
    "### Common Causes\n",
    "\n",
    "| Cause | Example | Mitigation |\n",
    "|-------|---------|------------|\n",
    "| **Poor shard key** | Using timestamp for range sharding | Use hash sharding or composite keys |\n",
    "| **Celebrity problem** | One user has millions of followers | Split hot keys across multiple shards |\n",
    "| **Time-based access** | End-of-month reports | Pre-compute aggregates |\n",
    "| **Geographic clustering** | All US users on one shard | Use consistent hashing |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05f5899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_hot_spot_scenario():\n",
    "    \"\"\"Simulate a hot spot caused by celebrity users.\"\"\"\n",
    "    \n",
    "    # User follower counts (power law distribution)\n",
    "    users = {\n",
    "        \"celebrity_A\": 10_000_000,\n",
    "        \"celebrity_B\": 5_000_000,\n",
    "        \"influencer_1\": 500_000,\n",
    "        \"influencer_2\": 250_000,\n",
    "    }\n",
    "    # Add 1000 regular users\n",
    "    for i in range(1000):\n",
    "        users[f\"user_{i}\"] = random.randint(10, 1000)\n",
    "    \n",
    "    # Hash shard by user ID\n",
    "    num_shards = 4\n",
    "    shard_load = {f\"shard_{i}\": 0 for i in range(num_shards)}\n",
    "    \n",
    "    def get_shard(user_id: str) -> str:\n",
    "        h = int(hashlib.md5(user_id.encode()).hexdigest(), 16)\n",
    "        return f\"shard_{h % num_shards}\"\n",
    "    \n",
    "    # Simulate read load (proportional to followers)\n",
    "    for user_id, followers in users.items():\n",
    "        shard = get_shard(user_id)\n",
    "        shard_load[shard] += followers\n",
    "    \n",
    "    return shard_load, users\n",
    "\n",
    "shard_load, users = simulate_hot_spot_scenario()\n",
    "total_load = sum(shard_load.values())\n",
    "\n",
    "print(\"ğŸ”¥ Hot Spot Simulation (Social Media Reads):\")\n",
    "print(\"â”€\" * 50)\n",
    "for shard, load in sorted(shard_load.items()):\n",
    "    pct = load / total_load * 100\n",
    "    bar = \"â–ˆ\" * int(pct / 2)\n",
    "    status = \"ğŸ”¥ HOT!\" if pct > 40 else \"\"\n",
    "    print(f\"  {shard}: {load:>12,} requests ({pct:5.1f}%) {bar} {status}\")\n",
    "\n",
    "# Show which celebrities are on which shard\n",
    "print(\"\\nğŸ‘¤ Celebrity Distribution:\")\n",
    "for user_id in [\"celebrity_A\", \"celebrity_B\", \"influencer_1\", \"influencer_2\"]:\n",
    "    h = int(hashlib.md5(user_id.encode()).hexdigest(), 16)\n",
    "    shard = f\"shard_{h % 4}\"\n",
    "    print(f\"  {user_id} ({users[user_id]:,} followers) -> {shard}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e2d3bf",
   "metadata": {},
   "source": [
    "### Rebalancing Strategies\n",
    "\n",
    "**Rebalancing** is the process of redistributing data across shards to maintain even load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535d701",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RebalancingSimulator:\n",
    "    \"\"\"Simulate different rebalancing strategies.\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_shards: int = 4, keys_per_shard: int = 1000):\n",
    "        self.shards = {f\"shard_{i}\": keys_per_shard for i in range(initial_shards)}\n",
    "        self.total_keys = initial_shards * keys_per_shard\n",
    "    \n",
    "    def add_shard_naive(self, new_shard: str) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Naive approach: Rehash everything.\n",
    "        Returns migration count per source shard.\n",
    "        \"\"\"\n",
    "        # With simple modulo, ~75% of keys need to move\n",
    "        old_count = len(self.shards)\n",
    "        new_count = old_count + 1\n",
    "        \n",
    "        keys_to_move = int(self.total_keys * (1 - old_count / new_count))\n",
    "        per_shard = keys_to_move // old_count\n",
    "        \n",
    "        migration = {shard: per_shard for shard in self.shards}\n",
    "        self.shards[new_shard] = keys_to_move\n",
    "        \n",
    "        return migration\n",
    "    \n",
    "    def add_shard_consistent(self, new_shard: str) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Consistent hashing: Only 1/N keys move.\n",
    "        \"\"\"\n",
    "        new_count = len(self.shards) + 1\n",
    "        keys_to_move = self.total_keys // new_count\n",
    "        \n",
    "        # Keys come evenly from existing shards\n",
    "        per_shard = keys_to_move // len(self.shards)\n",
    "        \n",
    "        migration = {shard: per_shard for shard in self.shards}\n",
    "        self.shards[new_shard] = keys_to_move\n",
    "        \n",
    "        return migration\n",
    "\n",
    "# Compare approaches\n",
    "print(\"ğŸ“¦ Rebalancing Comparison (4 â†’ 5 shards, 4000 keys):\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "sim_naive = RebalancingSimulator(4, 1000)\n",
    "naive_migration = sim_naive.add_shard_naive(\"shard_4\")\n",
    "\n",
    "sim_consistent = RebalancingSimulator(4, 1000)\n",
    "consistent_migration = sim_consistent.add_shard_consistent(\"shard_4\")\n",
    "\n",
    "print(\"\\nğŸ”„ Naive (Modulo Rehash):\")\n",
    "total_naive = sum(naive_migration.values())\n",
    "for shard, count in naive_migration.items():\n",
    "    print(f\"  {shard} â†’ shard_4: {count} keys\")\n",
    "print(f\"  Total migrated: {total_naive} ({total_naive/4000*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nâœ… Consistent Hashing:\")\n",
    "total_consistent = sum(consistent_migration.values())\n",
    "for shard, count in consistent_migration.items():\n",
    "    print(f\"  {shard} â†’ shard_4: {count} keys\")\n",
    "print(f\"  Total migrated: {total_consistent} ({total_consistent/4000*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Migration Reduction: {(1 - total_consistent/total_naive)*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee95423",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Choosing the Right Sharding Strategy\n",
    "\n",
    "| Factor | Range | Hash | Directory | Consistent Hash |\n",
    "|--------|-------|------|-----------|----------------|\n",
    "| Range queries | âœ… Excellent | âŒ Poor | ğŸ”¶ Depends | âŒ Poor |\n",
    "| Even distribution | âŒ Risk of hot spots | âœ… Good | âœ… Controllable | âœ… Good |\n",
    "| Add/remove nodes | ğŸ”¶ Manual | âŒ Expensive | âœ… Easy | âœ… Minimal migration |\n",
    "| Complexity | ğŸŸ¢ Low | ğŸŸ¢ Low | ğŸŸ¡ Medium | ğŸŸ¡ Medium |\n",
    "| Lookup overhead | ğŸŸ¢ O(log n) | ğŸŸ¢ O(1) | ğŸŸ¡ O(1) + network | ğŸŸ¢ O(log n) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d676d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision helper\n",
    "def recommend_sharding_strategy(\n",
    "    needs_range_queries: bool,\n",
    "    high_write_volume: bool,\n",
    "    frequent_scaling: bool,\n",
    "    complex_routing: bool\n",
    ") -> str:\n",
    "    \"\"\"Recommend a sharding strategy based on requirements.\"\"\"\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    if needs_range_queries and not high_write_volume:\n",
    "        recommendations.append((\"Range Sharding\", \n",
    "            \"Efficient range queries, but watch for hot spots\"))\n",
    "    \n",
    "    if high_write_volume and not needs_range_queries:\n",
    "        recommendations.append((\"Hash Sharding\", \n",
    "            \"Even write distribution, but range queries are expensive\"))\n",
    "    \n",
    "    if frequent_scaling:\n",
    "        recommendations.append((\"Consistent Hashing\", \n",
    "            \"Minimal data migration when scaling\"))\n",
    "    \n",
    "    if complex_routing:\n",
    "        recommendations.append((\"Directory Sharding\", \n",
    "            \"Maximum flexibility for routing logic\"))\n",
    "    \n",
    "    if not recommendations:\n",
    "        recommendations.append((\"Hash Sharding\", \n",
    "            \"Good default choice for most scenarios\"))\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example scenarios\n",
    "scenarios = [\n",
    "    (\"Time-series analytics\", True, False, False, False),\n",
    "    (\"High-traffic social media\", False, True, True, False),\n",
    "    (\"Multi-tenant SaaS\", False, False, False, True),\n",
    "    (\"E-commerce catalog\", False, True, True, False),\n",
    "]\n",
    "\n",
    "print(\"ğŸ§­ Sharding Strategy Recommendations:\")\n",
    "print(\"=\" * 60)\n",
    "for scenario, *args in scenarios:\n",
    "    recs = recommend_sharding_strategy(*args)\n",
    "    print(f\"\\nğŸ“‹ {scenario}:\")\n",
    "    for strategy, reason in recs:\n",
    "        print(f\"   âœ“ {strategy}: {reason}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dc7fd9",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“ Key Takeaways\n",
    "\n",
    "### Sharding Strategies Summary\n",
    "\n",
    "1. **Range Sharding**\n",
    "   - Partitions by value ranges (e.g., date, alphabetical)\n",
    "   - âœ… Great for range queries and sequential data\n",
    "   - âš ï¸ Prone to hot spots with uneven data distribution\n",
    "\n",
    "2. **Hash Sharding**\n",
    "   - Uses `hash(key) % N` for even distribution\n",
    "   - âœ… Eliminates hot spots from sequential inserts\n",
    "   - âš ï¸ Range queries require scatter-gather across all shards\n",
    "   - âš ï¸ Adding shards causes massive data migration\n",
    "\n",
    "3. **Consistent Hashing**\n",
    "   - Uses a hash ring with virtual nodes\n",
    "   - âœ… Only ~K/N keys move when adding a node\n",
    "   - âœ… Industry standard for distributed caches (Redis, Memcached)\n",
    "   - âš ï¸ More complex to implement\n",
    "\n",
    "4. **Directory Sharding**\n",
    "   - Lookup table maps keys to shards\n",
    "   - âœ… Maximum flexibility and easy rebalancing\n",
    "   - âš ï¸ Directory is a single point of failure\n",
    "   - âš ï¸ Every operation requires directory lookup\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "- **Choose shard key carefully** â€“ It determines data distribution and query patterns\n",
    "- **Plan for growth** â€“ Use consistent hashing if you expect to add nodes\n",
    "- **Monitor hot spots** â€“ Use metrics to detect uneven load\n",
    "- **Consider composite keys** â€“ Combine multiple fields for better distribution\n",
    "- **Test rebalancing** â€“ Ensure your system can handle shard additions gracefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d6c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reference cheat sheet\n",
    "cheat_sheet = \"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                    SHARDING PATTERNS CHEAT SHEET                  â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘  RANGE SHARDING                                                   â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                    â•‘\n",
    "â•‘  Formula: shard = find_range(key)                                 â•‘\n",
    "â•‘  Use for: Time-series, logs, sequential IDs                       â•‘\n",
    "â•‘  Avoid:   High-frequency inserts, celebrity data                  â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘  HASH SHARDING                                                    â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                    â•‘\n",
    "â•‘  Formula: shard = hash(key) % N                                   â•‘\n",
    "â•‘  Use for: Even distribution, random access                        â•‘\n",
    "â•‘  Avoid:   Range queries, frequent scaling                         â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘  CONSISTENT HASHING                                               â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â•‘\n",
    "â•‘  Formula: shard = first_node_clockwise(hash(key))                 â•‘\n",
    "â•‘  Use for: Caches, dynamic scaling, distributed systems            â•‘\n",
    "â•‘  Avoid:   Simple applications, when range queries needed          â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘  DIRECTORY SHARDING                                               â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â•‘\n",
    "â•‘  Formula: shard = directory[key]                                  â•‘\n",
    "â•‘  Use for: Multi-tenant, complex routing, hybrid approaches        â•‘\n",
    "â•‘  Avoid:   High-throughput with latency requirements               â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "print(cheat_sheet)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
