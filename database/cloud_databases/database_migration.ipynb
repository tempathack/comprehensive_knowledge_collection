{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03d11784",
   "metadata": {},
   "source": [
    "# Database Migration Strategies\n",
    "\n",
    "Database migration is the process of moving data from one database system to another, whether on-premises to cloud, between cloud providers, or upgrading database versions. This notebook covers essential strategies, tools, and best practices for successful database migrations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efa2a76",
   "metadata": {},
   "source": [
    "## Migration Approaches Overview\n",
    "\n",
    "There are three primary approaches to database migration, each with different levels of complexity, cost, and transformation:\n",
    "\n",
    "| Approach | Complexity | Cost | Downtime | Cloud Benefits |\n",
    "|----------|------------|------|----------|----------------|\n",
    "| Lift-and-Shift | Low | Low | Medium | Minimal |\n",
    "| Re-platform | Medium | Medium | Medium | Moderate |\n",
    "| Re-architect | High | High | High | Maximum |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93de056",
   "metadata": {},
   "source": [
    "## 1. Lift-and-Shift (Rehost)\n",
    "\n",
    "**Definition**: Moving the database to the cloud with minimal or no changes to the schema, data model, or application code.\n",
    "\n",
    "### When to Use\n",
    "- Urgent migration deadlines\n",
    "- Legacy applications with tight database coupling\n",
    "- When immediate cloud benefits (DR, scalability) are needed\n",
    "- Limited budget or resources for refactoring\n",
    "\n",
    "### Advantages\n",
    "- âœ… Fastest migration path\n",
    "- âœ… Lowest risk of introducing bugs\n",
    "- âœ… Minimal application changes required\n",
    "- âœ… Easier rollback if issues arise\n",
    "\n",
    "### Disadvantages\n",
    "- âŒ May not leverage cloud-native features\n",
    "- âŒ Technical debt remains\n",
    "- âŒ Potentially higher operational costs\n",
    "- âŒ Performance may not be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Lift-and-Shift Migration Checklist\n",
    "\n",
    "lift_shift_checklist = {\n",
    "    \"pre_migration\": [\n",
    "        \"Inventory all database objects (tables, views, stored procedures)\",\n",
    "        \"Document current performance baselines\",\n",
    "        \"Identify database dependencies and connections\",\n",
    "        \"Assess storage requirements and IOPS needs\",\n",
    "        \"Plan network connectivity (VPN, Direct Connect)\"\n",
    "    ],\n",
    "    \"migration\": [\n",
    "        \"Create target database instance with matching specs\",\n",
    "        \"Configure security groups and firewall rules\",\n",
    "        \"Perform initial data load (full backup/restore)\",\n",
    "        \"Set up ongoing replication for sync\",\n",
    "        \"Validate data integrity\"\n",
    "    ],\n",
    "    \"post_migration\": [\n",
    "        \"Update application connection strings\",\n",
    "        \"Verify application functionality\",\n",
    "        \"Monitor performance metrics\",\n",
    "        \"Decommission source database\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for phase, tasks in lift_shift_checklist.items():\n",
    "    print(f\"\\n{phase.upper().replace('_', ' ')}:\")\n",
    "    for i, task in enumerate(tasks, 1):\n",
    "        print(f\"  {i}. {task}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ca1ac1",
   "metadata": {},
   "source": [
    "## 2. Re-platform (Lift-Tinker-and-Shift)\n",
    "\n",
    "**Definition**: Moving to the cloud with some optimizations to leverage cloud capabilities without changing the core architecture.\n",
    "\n",
    "### Common Re-platforming Scenarios\n",
    "- Moving from self-managed MySQL to Amazon RDS MySQL\n",
    "- Migrating SQL Server to Azure SQL Managed Instance\n",
    "- Converting Oracle to PostgreSQL-compatible Aurora\n",
    "\n",
    "### When to Use\n",
    "- Want managed database benefits (patching, backups, HA)\n",
    "- Need to reduce operational overhead\n",
    "- Willing to make minor schema/configuration changes\n",
    "- Budget for moderate refactoring\n",
    "\n",
    "### Key Considerations\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    RE-PLATFORM CHANGES                      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  â€¢ Engine version upgrades                                  â”‚\n",
    "â”‚  â€¢ Parameter group/configuration adjustments                â”‚\n",
    "â”‚  â€¢ Authentication mechanism changes (IAM integration)       â”‚\n",
    "â”‚  â€¢ Storage type optimization (SSD, provisioned IOPS)        â”‚\n",
    "â”‚  â€¢ High availability configuration (Multi-AZ, replicas)     â”‚\n",
    "â”‚  â€¢ Backup and retention policy updates                      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a0999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Re-platform Decision Matrix\n",
    "\n",
    "replatform_scenarios = [\n",
    "    {\n",
    "        \"source\": \"MySQL 5.7 (on-prem)\",\n",
    "        \"target\": \"Amazon RDS MySQL 8.0\",\n",
    "        \"changes_needed\": [\n",
    "            \"Update deprecated SQL syntax\",\n",
    "            \"Review reserved keyword changes\",\n",
    "            \"Adjust character set defaults (utf8mb4)\",\n",
    "            \"Update authentication plugins\"\n",
    "        ],\n",
    "        \"benefits\": [\"Managed backups\", \"Multi-AZ\", \"Read replicas\", \"Auto-patching\"]\n",
    "    },\n",
    "    {\n",
    "        \"source\": \"SQL Server (on-prem)\",\n",
    "        \"target\": \"Azure SQL Managed Instance\",\n",
    "        \"changes_needed\": [\n",
    "            \"Remove unsupported features (SQL Agent jobs â†’ Elastic Jobs)\",\n",
    "            \"Update linked server configurations\",\n",
    "            \"Migrate SSIS packages to Azure Data Factory\",\n",
    "            \"Configure Azure AD authentication\"\n",
    "        ],\n",
    "        \"benefits\": [\"Near 100% compatibility\", \"Built-in HA\", \"Automated tuning\", \"Geo-replication\"]\n",
    "    },\n",
    "    {\n",
    "        \"source\": \"PostgreSQL (EC2)\",\n",
    "        \"target\": \"Cloud SQL for PostgreSQL\",\n",
    "        \"changes_needed\": [\n",
    "            \"Review extension compatibility\",\n",
    "            \"Update connection pooling (PgBouncer â†’ Cloud SQL Proxy)\",\n",
    "            \"Migrate custom configurations\",\n",
    "            \"Set up IAM database authentication\"\n",
    "        ],\n",
    "        \"benefits\": [\"Fully managed\", \"Automatic storage\", \"Point-in-time recovery\", \"HA with failover\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "for scenario in replatform_scenarios:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Migration: {scenario['source']} â†’ {scenario['target']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(\"\\nChanges Required:\")\n",
    "    for change in scenario['changes_needed']:\n",
    "        print(f\"  â€¢ {change}\")\n",
    "    print(\"\\nBenefits Gained:\")\n",
    "    for benefit in scenario['benefits']:\n",
    "        print(f\"  âœ“ {benefit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36960286",
   "metadata": {},
   "source": [
    "## 3. Re-architect (Refactor)\n",
    "\n",
    "**Definition**: Fundamentally redesigning the database to fully leverage cloud-native services and modern architectures.\n",
    "\n",
    "### When to Use\n",
    "- Building for massive scale\n",
    "- Need to break monolithic databases into microservices\n",
    "- Want to adopt serverless or event-driven architectures\n",
    "- Long-term cost optimization is priority\n",
    "\n",
    "### Re-architecture Patterns\n",
    "\n",
    "```\n",
    "MONOLITHIC DATABASE                    CLOUD-NATIVE ARCHITECTURE\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     â”‚               â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\n",
    "â”‚   Single Oracle     â”‚               â”‚  â”‚ Aurora  â”‚  â”‚DynamoDB â”‚   â”‚\n",
    "â”‚   Database          â”‚    â”€â”€â”€â”€â–º      â”‚  â”‚ (OLTP)  â”‚  â”‚ (NoSQL) â”‚   â”‚\n",
    "â”‚                     â”‚               â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\n",
    "â”‚  - Users            â”‚               â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\n",
    "â”‚  - Orders           â”‚               â”‚  â”‚Redshift â”‚  â”‚   S3    â”‚   â”‚\n",
    "â”‚  - Products         â”‚               â”‚  â”‚ (DWH)   â”‚  â”‚ (Lake)  â”‚   â”‚\n",
    "â”‚  - Analytics        â”‚               â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\n",
    "â”‚  - Logs             â”‚               â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\n",
    "â”‚                     â”‚               â”‚  â”‚ElastiC. â”‚  â”‚Timestr. â”‚   â”‚\n",
    "â”‚                     â”‚               â”‚  â”‚ (Search)â”‚  â”‚ (Logs)  â”‚   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\n",
    "                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Database-per-Service Pattern\n",
    "- Each microservice owns its data\n",
    "- Choose the right database for each use case\n",
    "- Use event sourcing for data synchronization\n",
    "- Implement saga patterns for distributed transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d29c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Re-architect Strategy Planning\n",
    "\n",
    "rearchitect_analysis = {\n",
    "    \"current_state\": {\n",
    "        \"database\": \"Oracle 12c (Single Instance)\",\n",
    "        \"size\": \"5 TB\",\n",
    "        \"tables\": 500,\n",
    "        \"daily_transactions\": \"10M\",\n",
    "        \"pain_points\": [\n",
    "            \"High licensing costs\",\n",
    "            \"Scaling limitations\",\n",
    "            \"Complex stored procedures\",\n",
    "            \"Mixed workloads (OLTP + Analytics)\"\n",
    "        ]\n",
    "    },\n",
    "    \"target_architecture\": {\n",
    "        \"transactional\": {\n",
    "            \"service\": \"Amazon Aurora PostgreSQL\",\n",
    "            \"use_case\": \"Core business transactions\",\n",
    "            \"tables\": \"~200 (normalized)\",\n",
    "            \"features\": [\"Multi-AZ\", \"Read replicas\", \"Serverless v2\"]\n",
    "        },\n",
    "        \"document_store\": {\n",
    "            \"service\": \"Amazon DocumentDB\",\n",
    "            \"use_case\": \"Product catalogs, user profiles\",\n",
    "            \"features\": [\"Flexible schema\", \"JSON queries\", \"Auto-scaling\"]\n",
    "        },\n",
    "        \"analytics\": {\n",
    "            \"service\": \"Amazon Redshift Serverless\",\n",
    "            \"use_case\": \"Business intelligence, reporting\",\n",
    "            \"features\": [\"Columnar storage\", \"ML integration\", \"Pay-per-query\"]\n",
    "        },\n",
    "        \"cache\": {\n",
    "            \"service\": \"Amazon ElastiCache (Redis)\",\n",
    "            \"use_case\": \"Session management, hot data\",\n",
    "            \"features\": [\"Sub-millisecond latency\", \"Cluster mode\"]\n",
    "        },\n",
    "        \"search\": {\n",
    "            \"service\": \"Amazon OpenSearch\",\n",
    "            \"use_case\": \"Full-text search, log analytics\",\n",
    "            \"features\": [\"Real-time indexing\", \"Dashboards\"]\n",
    "        }\n",
    "    },\n",
    "    \"migration_phases\": [\n",
    "        {\"phase\": 1, \"duration\": \"3 months\", \"scope\": \"Strangler fig pattern - new features on cloud\"},\n",
    "        {\"phase\": 2, \"duration\": \"6 months\", \"scope\": \"Migrate read workloads to purpose-built DBs\"},\n",
    "        {\"phase\": 3, \"duration\": \"6 months\", \"scope\": \"Migrate write workloads with CDC\"},\n",
    "        {\"phase\": 4, \"duration\": \"3 months\", \"scope\": \"Decommission legacy Oracle\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"CURRENT STATE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "current = rearchitect_analysis[\"current_state\"]\n",
    "print(f\"Database: {current['database']}\")\n",
    "print(f\"Size: {current['size']} | Tables: {current['tables']} | Daily Txns: {current['daily_transactions']}\")\n",
    "print(\"\\nPain Points:\")\n",
    "for pain in current['pain_points']:\n",
    "    print(f\"  âš  {pain}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TARGET ARCHITECTURE\")\n",
    "print(\"=\" * 50)\n",
    "for component, details in rearchitect_analysis[\"target_architecture\"].items():\n",
    "    print(f\"\\n{component.upper()}:\")\n",
    "    print(f\"  Service: {details['service']}\")\n",
    "    print(f\"  Use Case: {details['use_case']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"MIGRATION TIMELINE\")\n",
    "print(\"=\" * 50)\n",
    "for phase in rearchitect_analysis[\"migration_phases\"]:\n",
    "    print(f\"  Phase {phase['phase']} ({phase['duration']}): {phase['scope']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aaaf8e",
   "metadata": {},
   "source": [
    "## Cloud Database Migration Services\n",
    "\n",
    "### AWS Database Migration Service (DMS)\n",
    "\n",
    "AWS DMS enables you to migrate databases to AWS quickly and securely while keeping the source database operational during migration.\n",
    "\n",
    "#### Key Features\n",
    "- **Homogeneous migrations**: Oracle to Oracle, MySQL to MySQL\n",
    "- **Heterogeneous migrations**: Oracle to Aurora PostgreSQL, SQL Server to MySQL\n",
    "- **Continuous replication**: Keep source and target in sync\n",
    "- **Schema Conversion Tool (SCT)**: Convert database schemas and code\n",
    "\n",
    "#### Supported Sources/Targets\n",
    "| Sources | Targets |\n",
    "|---------|--------|\n",
    "| Oracle | Amazon Aurora |\n",
    "| SQL Server | Amazon RDS |\n",
    "| MySQL | Amazon Redshift |\n",
    "| PostgreSQL | Amazon S3 |\n",
    "| MongoDB | Amazon DynamoDB |\n",
    "| SAP ASE | Amazon DocumentDB |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS DMS Task Configuration Example (Conceptual)\n",
    "\n",
    "aws_dms_config = {\n",
    "    \"replication_instance\": {\n",
    "        \"class\": \"dms.r5.2xlarge\",\n",
    "        \"allocated_storage\": 100,  # GB\n",
    "        \"multi_az\": True,\n",
    "        \"vpc_security_groups\": [\"sg-migration-001\"]\n",
    "    },\n",
    "    \"source_endpoint\": {\n",
    "        \"engine\": \"oracle\",\n",
    "        \"server_name\": \"oracle-prod.company.com\",\n",
    "        \"port\": 1521,\n",
    "        \"database_name\": \"ORCL\",\n",
    "        \"ssl_mode\": \"require\",\n",
    "        \"extra_connection_attributes\": \"useLogMinerReader=Y;useBfile=Y\"\n",
    "    },\n",
    "    \"target_endpoint\": {\n",
    "        \"engine\": \"aurora-postgresql\",\n",
    "        \"server_name\": \"aurora-prod.cluster-xxx.us-east-1.rds.amazonaws.com\",\n",
    "        \"port\": 5432,\n",
    "        \"database_name\": \"production\",\n",
    "        \"ssl_mode\": \"require\"\n",
    "    },\n",
    "    \"replication_task\": {\n",
    "        \"migration_type\": \"full-load-and-cdc\",  # Full load + ongoing replication\n",
    "        \"table_mappings\": {\n",
    "            \"rules\": [\n",
    "                {\n",
    "                    \"rule-type\": \"selection\",\n",
    "                    \"rule-id\": \"1\",\n",
    "                    \"rule-name\": \"include-all-tables\",\n",
    "                    \"object-locator\": {\n",
    "                        \"schema-name\": \"APP_SCHEMA\",\n",
    "                        \"table-name\": \"%\"\n",
    "                    },\n",
    "                    \"rule-action\": \"include\"\n",
    "                },\n",
    "                {\n",
    "                    \"rule-type\": \"transformation\",\n",
    "                    \"rule-id\": \"2\",\n",
    "                    \"rule-name\": \"lowercase-schema\",\n",
    "                    \"rule-action\": \"convert-lowercase\",\n",
    "                    \"rule-target\": \"schema\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"task_settings\": {\n",
    "            \"TargetMetadata\": {\n",
    "                \"BatchApplyEnabled\": True,\n",
    "                \"FullLobMode\": False,\n",
    "                \"LobChunkSize\": 64\n",
    "            },\n",
    "            \"FullLoadSettings\": {\n",
    "                \"TargetTablePrepMode\": \"DROP_AND_CREATE\",\n",
    "                \"MaxFullLoadSubTasks\": 8,\n",
    "                \"TransactionConsistencyTimeout\": 600\n",
    "            },\n",
    "            \"Logging\": {\n",
    "                \"EnableLogging\": True,\n",
    "                \"LogComponents\": [\n",
    "                    {\"Id\": \"SOURCE_UNLOAD\", \"Severity\": \"LOGGER_SEVERITY_DEFAULT\"},\n",
    "                    {\"Id\": \"TARGET_LOAD\", \"Severity\": \"LOGGER_SEVERITY_DEFAULT\"}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"AWS DMS Configuration Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nReplication Instance: {aws_dms_config['replication_instance']['class']}\")\n",
    "print(f\"Multi-AZ: {aws_dms_config['replication_instance']['multi_az']}\")\n",
    "print(f\"\\nSource: {aws_dms_config['source_endpoint']['engine'].upper()}\")\n",
    "print(f\"  â†’ {aws_dms_config['source_endpoint']['server_name']}\")\n",
    "print(f\"\\nTarget: {aws_dms_config['target_endpoint']['engine'].upper()}\")\n",
    "print(f\"  â†’ {aws_dms_config['target_endpoint']['server_name']}\")\n",
    "print(f\"\\nMigration Type: {aws_dms_config['replication_task']['migration_type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b08bae",
   "metadata": {},
   "source": [
    "### Azure Database Migration Service\n",
    "\n",
    "Azure DMS provides seamless migrations from multiple database sources to Azure data platforms with minimal downtime.\n",
    "\n",
    "#### Migration Scenarios\n",
    "\n",
    "| Scenario | Tool | Mode |\n",
    "|----------|------|------|\n",
    "| SQL Server â†’ Azure SQL DB | DMS Online | Near-zero downtime |\n",
    "| SQL Server â†’ Azure SQL MI | DMS Online | Near-zero downtime |\n",
    "| MySQL â†’ Azure MySQL | DMS | Offline/Online |\n",
    "| PostgreSQL â†’ Azure PostgreSQL | DMS | Offline/Online |\n",
    "| MongoDB â†’ Azure Cosmos DB | DMS | Offline/Online |\n",
    "\n",
    "#### Key Components\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    AZURE DMS ARCHITECTURE                      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚  Source  â”‚â”€â”€â”€â–ºâ”‚  Azure DMS      â”‚â”€â”€â”€â–ºâ”‚  Target Azure    â”‚  â”‚\n",
    "â”‚  â”‚ Database â”‚    â”‚  (Hybrid Worker)â”‚    â”‚  Database        â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â”‚       â”‚                  â”‚                       â”‚            â”‚\n",
    "â”‚       â–¼                  â–¼                       â–¼            â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚Self-hostedâ”‚    â”‚ Data Migration â”‚    â”‚  Azure Monitor   â”‚  â”‚\n",
    "â”‚  â”‚Integrationâ”‚    â”‚   Assistant    â”‚    â”‚  (Metrics/Logs)  â”‚  â”‚\n",
    "â”‚  â”‚  Runtime  â”‚    â”‚    (DMA)       â”‚    â”‚                  â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â”‚                                                                â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594a0b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure DMS Migration Project Example (Conceptual)\n",
    "\n",
    "azure_dms_project = {\n",
    "    \"project_name\": \"SQLServer-to-AzureSQL-Migration\",\n",
    "    \"resource_group\": \"rg-database-migration\",\n",
    "    \"location\": \"eastus\",\n",
    "    \"service_tier\": \"Premium\",  # Required for online migrations\n",
    "    \n",
    "    \"source_connection\": {\n",
    "        \"type\": \"SQL Server\",\n",
    "        \"server\": \"sqlserver-prod.company.local\",\n",
    "        \"authentication\": \"SQL Authentication\",\n",
    "        \"encrypt_connection\": True,\n",
    "        \"trust_server_certificate\": False\n",
    "    },\n",
    "    \n",
    "    \"target_connection\": {\n",
    "        \"type\": \"Azure SQL Database\",\n",
    "        \"server\": \"sqlserver-prod.database.windows.net\",\n",
    "        \"authentication\": \"Azure AD\",\n",
    "        \"database\": \"production-db\"\n",
    "    },\n",
    "    \n",
    "    \"migration_settings\": {\n",
    "        \"mode\": \"Online\",  # Continuous sync until cutover\n",
    "        \"backup_file_share\": \"\\\\\\\\fileserver\\\\sqlbackups\",\n",
    "        \"databases\": [\n",
    "            {\n",
    "                \"name\": \"SalesDB\",\n",
    "                \"target_name\": \"SalesDB\",\n",
    "                \"tables_to_migrate\": \"All\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"InventoryDB\",\n",
    "                \"target_name\": \"InventoryDB\",\n",
    "                \"tables_to_migrate\": \"All\"\n",
    "            }\n",
    "        ],\n",
    "        \"validation_options\": {\n",
    "            \"data_integrity_validation\": True,\n",
    "            \"schema_validation\": True,\n",
    "            \"query_analysis_validation\": True\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"assessment_results\": {\n",
    "        \"compatibility_level\": \"150\",\n",
    "        \"blocking_issues\": 0,\n",
    "        \"warnings\": 3,\n",
    "        \"estimated_migration_time\": \"4 hours\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Azure DMS Migration Project\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Project: {azure_dms_project['project_name']}\")\n",
    "print(f\"Mode: {azure_dms_project['migration_settings']['mode']}\")\n",
    "print(f\"\\nSource: {azure_dms_project['source_connection']['type']}\")\n",
    "print(f\"  Server: {azure_dms_project['source_connection']['server']}\")\n",
    "print(f\"\\nTarget: {azure_dms_project['target_connection']['type']}\")\n",
    "print(f\"  Server: {azure_dms_project['target_connection']['server']}\")\n",
    "print(f\"\\nDatabases to Migrate:\")\n",
    "for db in azure_dms_project['migration_settings']['databases']:\n",
    "    print(f\"  â€¢ {db['name']} â†’ {db['target_name']}\")\n",
    "print(f\"\\nAssessment Results:\")\n",
    "print(f\"  Blocking Issues: {azure_dms_project['assessment_results']['blocking_issues']}\")\n",
    "print(f\"  Warnings: {azure_dms_project['assessment_results']['warnings']}\")\n",
    "print(f\"  Estimated Time: {azure_dms_project['assessment_results']['estimated_migration_time']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb939a63",
   "metadata": {},
   "source": [
    "### Google Cloud Database Migration Service\n",
    "\n",
    "GCP DMS provides serverless, minimal-downtime migrations to Cloud SQL and AlloyDB.\n",
    "\n",
    "#### Supported Migration Paths\n",
    "- MySQL â†’ Cloud SQL for MySQL\n",
    "- PostgreSQL â†’ Cloud SQL for PostgreSQL / AlloyDB\n",
    "- SQL Server â†’ Cloud SQL for SQL Server\n",
    "- Oracle â†’ Bare Metal Solution / PostgreSQL (via heterogeneous migration)\n",
    "\n",
    "#### Key Features\n",
    "- **Serverless**: No infrastructure to manage\n",
    "- **Continuous migration**: Real-time replication\n",
    "- **Minimal downtime**: Seconds of downtime during cutover\n",
    "- **Built-in validation**: Data validation before cutover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c1424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCP DMS Migration Job Example (Conceptual)\n",
    "\n",
    "gcp_dms_job = {\n",
    "    \"migration_job_id\": \"mysql-to-cloudsql-prod\",\n",
    "    \"display_name\": \"Production MySQL Migration\",\n",
    "    \"type\": \"CONTINUOUS\",  # CDC replication\n",
    "    \n",
    "    \"source\": {\n",
    "        \"connection_profile\": \"mysql-source-profile\",\n",
    "        \"engine\": \"MYSQL\",\n",
    "        \"version\": \"8.0\",\n",
    "        \"host\": \"mysql-prod.company.com\",\n",
    "        \"port\": 3306,\n",
    "        \"ssl_config\": {\n",
    "            \"type\": \"SERVER_ONLY\",\n",
    "            \"ca_certificate\": \"projects/my-project/locations/us-central1/certificates/mysql-ca\"\n",
    "        },\n",
    "        \"connectivity\": \"VPC_PEERING\"  # or REVERSE_SSH_TUNNEL\n",
    "    },\n",
    "    \n",
    "    \"destination\": {\n",
    "        \"connection_profile\": \"cloudsql-dest-profile\",\n",
    "        \"cloud_sql_id\": \"projects/my-project/instances/mysql-prod-cloudsql\",\n",
    "        \"instance_tier\": \"db-custom-8-32768\",\n",
    "        \"storage_size_gb\": 500,\n",
    "        \"availability_type\": \"REGIONAL\"  # High availability\n",
    "    },\n",
    "    \n",
    "    \"migration_settings\": {\n",
    "        \"dump_parallelism\": 4,\n",
    "        \"dump_path\": \"gs://migration-bucket/mysql-dump\",\n",
    "        \"filter\": {\n",
    "            \"databases\": [\"app_db\", \"analytics_db\"],\n",
    "            \"excluded_tables\": [\"app_db.temp_*\", \"app_db.logs_*\"]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"phases\": [\n",
    "        {\"phase\": \"FULL_DUMP\", \"status\": \"COMPLETED\", \"duration\": \"45 min\"},\n",
    "        {\"phase\": \"CDC\", \"status\": \"RUNNING\", \"lag\": \"2 seconds\"},\n",
    "        {\"phase\": \"PROMOTE_IN_PROGRESS\", \"status\": \"PENDING\", \"duration\": None}\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"GCP Database Migration Service Job\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Job ID: {gcp_dms_job['migration_job_id']}\")\n",
    "print(f\"Type: {gcp_dms_job['type']}\")\n",
    "print(f\"\\nSource: {gcp_dms_job['source']['engine']} {gcp_dms_job['source']['version']}\")\n",
    "print(f\"  Host: {gcp_dms_job['source']['host']}\")\n",
    "print(f\"  Connectivity: {gcp_dms_job['source']['connectivity']}\")\n",
    "print(f\"\\nDestination: Cloud SQL\")\n",
    "print(f\"  Instance: {gcp_dms_job['destination']['cloud_sql_id'].split('/')[-1]}\")\n",
    "print(f\"  Tier: {gcp_dms_job['destination']['instance_tier']}\")\n",
    "print(f\"\\nMigration Phases:\")\n",
    "for phase in gcp_dms_job['phases']:\n",
    "    status_icon = \"âœ“\" if phase['status'] == 'COMPLETED' else \"âŸ³\" if phase['status'] == 'RUNNING' else \"â—‹\"\n",
    "    duration_str = f\" ({phase['duration']})\" if phase['duration'] else \"\"\n",
    "    lag_str = f\" - Lag: {phase['lag']}\" if 'lag' in phase and phase['status'] == 'RUNNING' else \"\"\n",
    "    print(f\"  {status_icon} {phase['phase']}: {phase['status']}{duration_str}{lag_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fba767",
   "metadata": {},
   "source": [
    "## Zero-Downtime Migration Techniques\n",
    "\n",
    "Achieving zero or near-zero downtime during database migration requires careful planning and the right combination of techniques.\n",
    "\n",
    "### Core Techniques\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    ZERO-DOWNTIME MIGRATION FLOW                         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  Phase 1: Initial Load          Phase 2: CDC Sync                       â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚\n",
    "â”‚  â”‚  Source  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  Target  â”‚                            â”‚\n",
    "â”‚  â”‚    DB    â”‚   Full Snapshot   â”‚    DB    â”‚                            â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚\n",
    "â”‚       â”‚                              â–²                                  â”‚\n",
    "â”‚       â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚                                  â”‚\n",
    "â”‚       â””â”€â”€â”€â”€â–ºâ”‚  Change Data â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚\n",
    "â”‚             â”‚   Capture    â”‚  Continuous                                â”‚\n",
    "â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  Replication                               â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  Phase 3: Validation            Phase 4: Cutover                        â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚\n",
    "â”‚  â”‚ Row counts match   â”‚        â”‚ Stop writes     â”‚                      â”‚\n",
    "â”‚  â”‚ Checksums verify   â”‚   â”€â”€â–º  â”‚ Final sync      â”‚                      â”‚\n",
    "â”‚  â”‚ Sample data compareâ”‚        â”‚ Switch apps     â”‚                      â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e233a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-Downtime Migration Strategy Implementation\n",
    "\n",
    "zero_downtime_strategy = {\n",
    "    \"technique\": \"Blue-Green with CDC\",\n",
    "    \n",
    "    \"phases\": {\n",
    "        \"1_preparation\": {\n",
    "            \"duration\": \"1-2 weeks\",\n",
    "            \"tasks\": [\n",
    "                \"Set up target database infrastructure\",\n",
    "                \"Configure network connectivity (VPN/peering)\",\n",
    "                \"Create replication user with minimal privileges\",\n",
    "                \"Enable binary logging (MySQL) or logical replication (PostgreSQL)\",\n",
    "                \"Test failover procedures in staging\"\n",
    "            ]\n",
    "        },\n",
    "        \"2_initial_load\": {\n",
    "            \"duration\": \"Hours to days (size dependent)\",\n",
    "            \"tasks\": [\n",
    "                \"Take consistent snapshot of source database\",\n",
    "                \"Transfer snapshot to target (parallel load for speed)\",\n",
    "                \"Note the binlog/LSN position at snapshot time\",\n",
    "                \"Restore snapshot to target database\",\n",
    "                \"Build indexes after data load (faster than during)\"\n",
    "            ],\n",
    "            \"tips\": [\n",
    "                \"Use parallel dump/restore for large databases\",\n",
    "                \"Disable foreign key checks during load\",\n",
    "                \"Consider using native cloud import tools\"\n",
    "            ]\n",
    "        },\n",
    "        \"3_cdc_replication\": {\n",
    "            \"duration\": \"Continuous until cutover\",\n",
    "            \"tasks\": [\n",
    "                \"Start CDC from recorded binlog/LSN position\",\n",
    "                \"Monitor replication lag continuously\",\n",
    "                \"Handle schema changes carefully (DDL replication)\",\n",
    "                \"Ensure replication catches up before cutover\"\n",
    "            ],\n",
    "            \"monitoring_metrics\": [\n",
    "                \"Replication lag (seconds behind master)\",\n",
    "                \"Transactions per second replicated\",\n",
    "                \"Error rate and skipped transactions\"\n",
    "            ]\n",
    "        },\n",
    "        \"4_validation\": {\n",
    "            \"duration\": \"1-2 days\",\n",
    "            \"tasks\": [\n",
    "                \"Compare row counts for all tables\",\n",
    "                \"Verify checksum of sample data\",\n",
    "                \"Run application test suite against target\",\n",
    "                \"Validate stored procedures and functions\",\n",
    "                \"Performance benchmark critical queries\"\n",
    "            ]\n",
    "        },\n",
    "        \"5_cutover\": {\n",
    "            \"duration\": \"Seconds to minutes\",\n",
    "            \"steps\": [\n",
    "                \"1. Announce maintenance window (even if minimal)\",\n",
    "                \"2. Stop application writes to source\",\n",
    "                \"3. Wait for replication to fully catch up (lag = 0)\",\n",
    "                \"4. Verify final row counts match\",\n",
    "                \"5. Update application connection strings\",\n",
    "                \"6. Start applications pointing to new database\",\n",
    "                \"7. Monitor for errors\",\n",
    "                \"8. Keep source database read-only for rollback (24-48h)\"\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"rollback_plan\": {\n",
    "        \"trigger_conditions\": [\n",
    "            \"Data integrity issues detected\",\n",
    "            \"Performance degradation > 50%\",\n",
    "            \"Critical application errors\",\n",
    "            \"Replication lag cannot be recovered\"\n",
    "        ],\n",
    "        \"rollback_steps\": [\n",
    "            \"Stop applications\",\n",
    "            \"Revert connection strings to source\",\n",
    "            \"Restart applications\",\n",
    "            \"Sync any target changes back to source (if needed)\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ZERO-DOWNTIME MIGRATION STRATEGY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Technique: {zero_downtime_strategy['technique']}\")\n",
    "\n",
    "for phase_name, phase_details in zero_downtime_strategy['phases'].items():\n",
    "    print(f\"\\n{'â”€' * 60}\")\n",
    "    print(f\"Phase: {phase_name.replace('_', ' ').upper()}\")\n",
    "    print(f\"Duration: {phase_details['duration']}\")\n",
    "    \n",
    "    if 'tasks' in phase_details:\n",
    "        print(\"Tasks:\")\n",
    "        for task in phase_details['tasks']:\n",
    "            print(f\"  â–¡ {task}\")\n",
    "    \n",
    "    if 'steps' in phase_details:\n",
    "        print(\"Steps:\")\n",
    "        for step in phase_details['steps']:\n",
    "            print(f\"  {step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfceafeb",
   "metadata": {},
   "source": [
    "### Dual-Write Pattern\n",
    "\n",
    "An alternative approach where the application writes to both databases simultaneously during migration.\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     DUAL-WRITE PATTERN                      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                             â”‚\n",
    "â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚\n",
    "â”‚                    â”‚ Application â”‚                          â”‚\n",
    "â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                          â”‚\n",
    "â”‚                           â”‚                                 â”‚\n",
    "â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                          â”‚\n",
    "â”‚                    â”‚   Write     â”‚                          â”‚\n",
    "â”‚                    â”‚   Router    â”‚                          â”‚\n",
    "â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                          â”‚\n",
    "â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚\n",
    "â”‚                  â”‚                 â”‚                        â”‚\n",
    "â”‚           â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                 â”‚\n",
    "â”‚           â”‚   Source    â”‚   â”‚   Target    â”‚                 â”‚\n",
    "â”‚           â”‚  (Primary)  â”‚   â”‚ (Secondary) â”‚                 â”‚\n",
    "â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚\n",
    "â”‚                                                             â”‚\n",
    "â”‚  Phase 1: Source primary, Target secondary                  â”‚\n",
    "â”‚  Phase 2: Both active, source primary                       â”‚\n",
    "â”‚  Phase 3: Both active, target primary                       â”‚\n",
    "â”‚  Phase 4: Target primary only                               â”‚\n",
    "â”‚                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Caution**: Dual-write adds complexity and potential consistency issues. Use CDC-based approaches when possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee617fdc",
   "metadata": {},
   "source": [
    "## Data Validation and Cutover Strategies\n",
    "\n",
    "### Validation Framework\n",
    "\n",
    "Data validation ensures that the migrated data is complete, accurate, and consistent with the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Data Validation Framework\n",
    "\n",
    "class MigrationValidator:\n",
    "    \"\"\"Framework for validating database migrations.\"\"\"\n",
    "    \n",
    "    def __init__(self, source_db, target_db):\n",
    "        self.source = source_db\n",
    "        self.target = target_db\n",
    "        self.validation_results = []\n",
    "    \n",
    "    def validate_row_counts(self, tables):\n",
    "        \"\"\"Compare row counts between source and target.\"\"\"\n",
    "        results = []\n",
    "        for table in tables:\n",
    "            # Simulated counts for demonstration\n",
    "            source_count = 1000000  # Would query source\n",
    "            target_count = 1000000  # Would query target\n",
    "            \n",
    "            results.append({\n",
    "                'table': table,\n",
    "                'source_count': source_count,\n",
    "                'target_count': target_count,\n",
    "                'match': source_count == target_count,\n",
    "                'difference': source_count - target_count\n",
    "            })\n",
    "        return results\n",
    "    \n",
    "    def validate_checksums(self, table, key_columns, sample_size=1000):\n",
    "        \"\"\"Compare checksums of sample data.\"\"\"\n",
    "        # Query pattern for checksum comparison\n",
    "        checksum_query = f\"\"\"\n",
    "        SELECT \n",
    "            MD5(CONCAT_WS('|', {', '.join(key_columns)})) as row_hash,\n",
    "            {', '.join(key_columns)}\n",
    "        FROM {table}\n",
    "        ORDER BY RANDOM()\n",
    "        LIMIT {sample_size}\n",
    "        \"\"\"\n",
    "        return {\"query\": checksum_query, \"sample_size\": sample_size}\n",
    "    \n",
    "    def validate_constraints(self):\n",
    "        \"\"\"Verify all constraints are properly migrated.\"\"\"\n",
    "        constraint_checks = {\n",
    "            'primary_keys': \"Check all PKs exist and are enforced\",\n",
    "            'foreign_keys': \"Verify FK relationships and cascades\",\n",
    "            'unique_constraints': \"Confirm unique constraints active\",\n",
    "            'check_constraints': \"Validate check constraints migrated\",\n",
    "            'not_null': \"Ensure NOT NULL constraints preserved\"\n",
    "        }\n",
    "        return constraint_checks\n",
    "    \n",
    "    def validate_sequences(self):\n",
    "        \"\"\"Ensure sequences are synced and won't conflict.\"\"\"\n",
    "        return {\n",
    "            'check': \"Target sequence values > max source values\",\n",
    "            'buffer': \"Add 10000 buffer to sequence values\",\n",
    "            'verification': \"Test insert with auto-increment\"\n",
    "        }\n",
    "\n",
    "# Validation Checklist\n",
    "validation_checklist = {\n",
    "    \"pre_cutover_validation\": [\n",
    "        {\n",
    "            \"check\": \"Row Count Verification\",\n",
    "            \"description\": \"All tables have matching row counts\",\n",
    "            \"tolerance\": \"0% difference\",\n",
    "            \"blocking\": True\n",
    "        },\n",
    "        {\n",
    "            \"check\": \"Schema Comparison\",\n",
    "            \"description\": \"All objects (tables, views, procedures) exist\",\n",
    "            \"tolerance\": \"100% match\",\n",
    "            \"blocking\": True\n",
    "        },\n",
    "        {\n",
    "            \"check\": \"Primary Key Integrity\",\n",
    "            \"description\": \"No duplicate PKs, all PKs migrated\",\n",
    "            \"tolerance\": \"0 violations\",\n",
    "            \"blocking\": True\n",
    "        },\n",
    "        {\n",
    "            \"check\": \"Sample Data Checksum\",\n",
    "            \"description\": \"1000 random rows match source exactly\",\n",
    "            \"tolerance\": \"100% match\",\n",
    "            \"blocking\": True\n",
    "        },\n",
    "        {\n",
    "            \"check\": \"Replication Lag\",\n",
    "            \"description\": \"CDC is caught up with source\",\n",
    "            \"tolerance\": \"< 5 seconds lag\",\n",
    "            \"blocking\": True\n",
    "        },\n",
    "        {\n",
    "            \"check\": \"Critical Query Performance\",\n",
    "            \"description\": \"Top 10 queries perform within SLA\",\n",
    "            \"tolerance\": \"< 20% slower than source\",\n",
    "            \"blocking\": False\n",
    "        },\n",
    "        {\n",
    "            \"check\": \"Application Smoke Tests\",\n",
    "            \"description\": \"Core application functions work\",\n",
    "            \"tolerance\": \"All tests pass\",\n",
    "            \"blocking\": True\n",
    "        }\n",
    "    ],\n",
    "    \n",
    "    \"post_cutover_validation\": [\n",
    "        \"Monitor error rates in application logs\",\n",
    "        \"Track database connection failures\",\n",
    "        \"Verify batch job completions\",\n",
    "        \"Check replication to read replicas\",\n",
    "        \"Validate backup jobs running\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"DATA VALIDATION CHECKLIST\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nPRE-CUTOVER VALIDATION\")\n",
    "print(\"-\" * 60)\n",
    "for item in validation_checklist['pre_cutover_validation']:\n",
    "    blocking = \"ðŸš« BLOCKING\" if item['blocking'] else \"âš ï¸ WARNING\"\n",
    "    print(f\"\\n{blocking}: {item['check']}\")\n",
    "    print(f\"  Description: {item['description']}\")\n",
    "    print(f\"  Tolerance: {item['tolerance']}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"POST-CUTOVER VALIDATION\")\n",
    "print(\"-\" * 60)\n",
    "for item in validation_checklist['post_cutover_validation']:\n",
    "    print(f\"  â–¡ {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9307e3a8",
   "metadata": {},
   "source": [
    "### Cutover Strategies\n",
    "\n",
    "The cutover is the critical moment when traffic switches from source to target database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6217fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutover Strategy Comparison\n",
    "\n",
    "cutover_strategies = {\n",
    "    \"big_bang\": {\n",
    "        \"description\": \"All applications switch to new database at once\",\n",
    "        \"downtime\": \"Minutes to hours\",\n",
    "        \"risk\": \"High\",\n",
    "        \"complexity\": \"Low\",\n",
    "        \"best_for\": \"Small databases, simple applications\",\n",
    "        \"steps\": [\n",
    "            \"Schedule maintenance window\",\n",
    "            \"Stop all applications\",\n",
    "            \"Final data sync\",\n",
    "            \"Validate data\",\n",
    "            \"Update all connection strings\",\n",
    "            \"Start all applications\",\n",
    "            \"Verify functionality\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"phased_rollout\": {\n",
    "        \"description\": \"Migrate applications in groups/phases\",\n",
    "        \"downtime\": \"Per-application, minimal\",\n",
    "        \"risk\": \"Medium\",\n",
    "        \"complexity\": \"Medium\",\n",
    "        \"best_for\": \"Multiple applications, different criticality\",\n",
    "        \"steps\": [\n",
    "            \"Categorize apps by criticality\",\n",
    "            \"Migrate non-critical apps first\",\n",
    "            \"Monitor and validate each phase\",\n",
    "            \"Progressively migrate critical apps\",\n",
    "            \"Keep dual-write for rollback capability\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"canary_release\": {\n",
    "        \"description\": \"Route small percentage of traffic to new DB\",\n",
    "        \"downtime\": \"Zero\",\n",
    "        \"risk\": \"Low\",\n",
    "        \"complexity\": \"High\",\n",
    "        \"best_for\": \"High-traffic, critical systems\",\n",
    "        \"steps\": [\n",
    "            \"Set up traffic routing (load balancer/proxy)\",\n",
    "            \"Route 1% of read traffic to target\",\n",
    "            \"Monitor errors and latency\",\n",
    "            \"Gradually increase to 10%, 25%, 50%\",\n",
    "            \"Switch writes when confident\",\n",
    "            \"Complete migration to 100%\"\n",
    "        ],\n",
    "        \"rollback\": \"Instantly route traffic back to source\"\n",
    "    },\n",
    "    \n",
    "    \"blue_green\": {\n",
    "        \"description\": \"Two identical environments, instant switch\",\n",
    "        \"downtime\": \"Seconds\",\n",
    "        \"risk\": \"Low\",\n",
    "        \"complexity\": \"High\",\n",
    "        \"best_for\": \"Mission-critical systems, strict SLAs\",\n",
    "        \"steps\": [\n",
    "            \"Maintain both environments in sync\",\n",
    "            \"Validate green (target) environment\",\n",
    "            \"DNS/Load balancer switch to green\",\n",
    "            \"Monitor for issues\",\n",
    "            \"Keep blue (source) for rollback\",\n",
    "            \"Decommission blue after stability period\"\n",
    "        ],\n",
    "        \"rollback\": \"Switch DNS/LB back to blue environment\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"CUTOVER STRATEGY COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Summary table\n",
    "print(f\"\\n{'Strategy':<20} {'Downtime':<15} {'Risk':<10} {'Complexity':<12}\")\n",
    "print(\"-\" * 70)\n",
    "for name, details in cutover_strategies.items():\n",
    "    print(f\"{name.replace('_', ' ').title():<20} {details['downtime']:<15} {details['risk']:<10} {details['complexity']:<12}\")\n",
    "\n",
    "# Detailed breakdown\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "for name, details in cutover_strategies.items():\n",
    "    print(f\"\\n{name.replace('_', ' ').upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Description: {details['description']}\")\n",
    "    print(f\"Best For: {details['best_for']}\")\n",
    "    print(\"\\nSteps:\")\n",
    "    for i, step in enumerate(details['steps'], 1):\n",
    "        print(f\"  {i}. {step}\")\n",
    "    if 'rollback' in details:\n",
    "        print(f\"\\nRollback: {details['rollback']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7994684",
   "metadata": {},
   "source": [
    "### Cutover Runbook Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6997230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutover Runbook Template\n",
    "\n",
    "cutover_runbook = {\n",
    "    \"migration_name\": \"Oracle to Aurora PostgreSQL Migration\",\n",
    "    \"scheduled_date\": \"2026-02-15 02:00 UTC\",\n",
    "    \"estimated_duration\": \"45 minutes\",\n",
    "    \"max_rollback_time\": \"15 minutes\",\n",
    "    \n",
    "    \"team_contacts\": {\n",
    "        \"migration_lead\": \"DBA Team Lead - (555) 123-4567\",\n",
    "        \"application_owner\": \"App Team Lead - (555) 234-5678\",\n",
    "        \"infrastructure\": \"Infra On-Call - (555) 345-6789\",\n",
    "        \"escalation\": \"VP Engineering - (555) 456-7890\"\n",
    "    },\n",
    "    \n",
    "    \"pre_cutover_checklist\": [\n",
    "        {\"task\": \"Confirm maintenance window communicated\", \"owner\": \"PM\", \"time\": \"T-24h\"},\n",
    "        {\"task\": \"Validate all CDC replication healthy\", \"owner\": \"DBA\", \"time\": \"T-4h\"},\n",
    "        {\"task\": \"Run pre-cutover validation suite\", \"owner\": \"DBA\", \"time\": \"T-2h\"},\n",
    "        {\"task\": \"Confirm rollback procedure tested\", \"owner\": \"DBA\", \"time\": \"T-2h\"},\n",
    "        {\"task\": \"All team members available on bridge\", \"owner\": \"All\", \"time\": \"T-30m\"},\n",
    "        {\"task\": \"Monitoring dashboards ready\", \"owner\": \"SRE\", \"time\": \"T-30m\"}\n",
    "    ],\n",
    "    \n",
    "    \"cutover_steps\": [\n",
    "        {\"step\": 1, \"action\": \"Announce cutover start on bridge\", \"duration\": \"1 min\", \"rollback\": \"N/A\"},\n",
    "        {\"step\": 2, \"action\": \"Enable application maintenance mode\", \"duration\": \"2 min\", \"rollback\": \"Disable maintenance mode\"},\n",
    "        {\"step\": 3, \"action\": \"Stop application write connections\", \"duration\": \"2 min\", \"rollback\": \"Re-enable connections\"},\n",
    "        {\"step\": 4, \"action\": \"Wait for replication lag = 0\", \"duration\": \"5 min\", \"rollback\": \"N/A\"},\n",
    "        {\"step\": 5, \"action\": \"Verify final row counts match\", \"duration\": \"5 min\", \"rollback\": \"Investigate discrepancy\"},\n",
    "        {\"step\": 6, \"action\": \"Stop CDC replication\", \"duration\": \"1 min\", \"rollback\": \"Resume replication\"},\n",
    "        {\"step\": 7, \"action\": \"Update DNS/connection strings\", \"duration\": \"5 min\", \"rollback\": \"Revert DNS changes\"},\n",
    "        {\"step\": 8, \"action\": \"Disable maintenance mode\", \"duration\": \"2 min\", \"rollback\": \"Enable maintenance mode\"},\n",
    "        {\"step\": 9, \"action\": \"Verify application connectivity\", \"duration\": \"5 min\", \"rollback\": \"Check connection settings\"},\n",
    "        {\"step\": 10, \"action\": \"Run smoke tests\", \"duration\": \"10 min\", \"rollback\": \"Initiate rollback\"},\n",
    "        {\"step\": 11, \"action\": \"Monitor for 15 min stability\", \"duration\": \"15 min\", \"rollback\": \"Initiate rollback\"},\n",
    "        {\"step\": 12, \"action\": \"Announce cutover complete\", \"duration\": \"1 min\", \"rollback\": \"N/A\"}\n",
    "    ],\n",
    "    \n",
    "    \"rollback_triggers\": [\n",
    "        \"Data integrity validation fails\",\n",
    "        \"Application error rate > 5%\",\n",
    "        \"P99 latency > 2x baseline\",\n",
    "        \"Critical functionality not working\",\n",
    "        \"Team consensus to rollback\"\n",
    "    ],\n",
    "    \n",
    "    \"success_criteria\": [\n",
    "        \"All applications connected to new database\",\n",
    "        \"Error rates within normal range\",\n",
    "        \"Response times within SLA\",\n",
    "        \"All batch jobs completed successfully\",\n",
    "        \"No data integrity issues reported\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"DATABASE MIGRATION CUTOVER RUNBOOK\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nMigration: {cutover_runbook['migration_name']}\")\n",
    "print(f\"Scheduled: {cutover_runbook['scheduled_date']}\")\n",
    "print(f\"Duration: {cutover_runbook['estimated_duration']}\")\n",
    "print(f\"Max Rollback Window: {cutover_runbook['max_rollback_time']}\")\n",
    "\n",
    "print(\"\\nTEAM CONTACTS\")\n",
    "print(\"-\" * 40)\n",
    "for role, contact in cutover_runbook['team_contacts'].items():\n",
    "    print(f\"  {role.replace('_', ' ').title()}: {contact}\")\n",
    "\n",
    "print(\"\\nCUTOVER STEPS\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Step':<6} {'Action':<40} {'Duration':<10}\")\n",
    "print(\"-\" * 70)\n",
    "for step in cutover_runbook['cutover_steps']:\n",
    "    print(f\"{step['step']:<6} {step['action']:<40} {step['duration']:<10}\")\n",
    "\n",
    "print(\"\\nROLLBACK TRIGGERS\")\n",
    "print(\"-\" * 40)\n",
    "for trigger in cutover_runbook['rollback_triggers']:\n",
    "    print(f\"  ðŸš¨ {trigger}\")\n",
    "\n",
    "print(\"\\nSUCCESS CRITERIA\")\n",
    "print(\"-\" * 40)\n",
    "for criteria in cutover_runbook['success_criteria']:\n",
    "    print(f\"  âœ“ {criteria}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b5b9b5",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "### Key Principles for Successful Database Migration\n",
    "\n",
    "| Principle | Description |\n",
    "|-----------|-------------|\n",
    "| **Assess First** | Thoroughly analyze source database, dependencies, and workload patterns before choosing a strategy |\n",
    "| **Choose the Right Approach** | Match lift-and-shift, re-platform, or re-architect to your timeline, budget, and goals |\n",
    "| **Use Managed Tools** | Leverage cloud provider DMS tools (AWS, Azure, GCP) for reliable, battle-tested migrations |\n",
    "| **Prioritize Zero-Downtime** | Use CDC-based replication for minimal business disruption |\n",
    "| **Validate Extensively** | Never skip data validationâ€”row counts, checksums, and application testing |\n",
    "| **Plan Rollback** | Always have a tested rollback plan with clear triggers |\n",
    "\n",
    "### Migration Strategy Decision Tree\n",
    "\n",
    "```\n",
    "                        START\n",
    "                          â”‚\n",
    "                          â–¼\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚ Urgent deadline or    â”‚â”€â”€â”€Yesâ”€â”€â–º LIFT-AND-SHIFT\n",
    "              â”‚ minimal budget?       â”‚\n",
    "              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                          â”‚ No\n",
    "                          â–¼\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚ Need managed DB       â”‚â”€â”€â”€Yesâ”€â”€â–º RE-PLATFORM\n",
    "              â”‚ without major changes?â”‚\n",
    "              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                          â”‚ No\n",
    "                          â–¼\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚ Building for scale or â”‚â”€â”€â”€Yesâ”€â”€â–º RE-ARCHITECT\n",
    "              â”‚ cloud-native features?â”‚\n",
    "              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                          â”‚ No\n",
    "                          â–¼\n",
    "                    RE-PLATFORM\n",
    "                   (Safe default)\n",
    "```\n",
    "\n",
    "### Common Pitfalls to Avoid\n",
    "\n",
    "1. **Underestimating data volume** - Test with production-scale data\n",
    "2. **Ignoring network latency** - Set up proper connectivity early\n",
    "3. **Skipping application testing** - Run full test suites against target\n",
    "4. **No rollback plan** - Always have a tested escape route\n",
    "5. **Rushing cutover** - Wait for zero replication lag\n",
    "6. **Forgetting about sequences** - Ensure auto-increment values won't collide\n",
    "7. **Not monitoring after cutover** - Watch closely for 24-48 hours\n",
    "\n",
    "### Recommended Resources\n",
    "\n",
    "- [AWS Database Migration Service](https://docs.aws.amazon.com/dms/)\n",
    "- [Azure Database Migration Guide](https://learn.microsoft.com/en-us/azure/dms/)\n",
    "- [Google Cloud Database Migration Service](https://cloud.google.com/database-migration)\n",
    "- [Martin Fowler's Strangler Fig Pattern](https://martinfowler.com/bliki/StranglerFigApplication.html)\n",
    "- [AWS Schema Conversion Tool](https://docs.aws.amazon.com/SchemaConversionTool/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
