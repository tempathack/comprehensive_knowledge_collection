{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af0aa68",
   "metadata": {},
   "source": [
    "# Async Programming in Python for Backend Development\n",
    "\n",
    "**A comprehensive guide to asynchronous programming patterns, best practices, and real-world applications**\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Why Async Matters for Backend Development](#1-why-async-matters)\n",
    "2. [Python asyncio Fundamentals](#2-asyncio-fundamentals)\n",
    "3. [async/await Syntax and Patterns](#3-async-await-patterns)\n",
    "4. [Running Concurrent Tasks](#4-concurrent-tasks)\n",
    "5. [Async Context Managers and Iterators](#5-async-context-managers)\n",
    "6. [Error Handling in Async Code](#6-error-handling)\n",
    "7. [Common Pitfalls](#7-common-pitfalls)\n",
    "8. [Async Libraries Ecosystem](#8-async-ecosystem)\n",
    "9. [FastAPI Async Patterns](#9-fastapi-patterns)\n",
    "10. [Testing Async Code](#10-testing-async)\n",
    "11. [When NOT to Use Async](#11-when-not-to-use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e40c086",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"1-why-async-matters\"></a>\n",
    "## 1. Why Async Matters for Backend Development\n",
    "\n",
    "### Understanding I/O Bound vs CPU Bound Operations\n",
    "\n",
    "Backend applications spend most of their time waiting for external resources:\n",
    "\n",
    "| Operation Type | Examples | Characteristics | Solution |\n",
    "|---------------|----------|-----------------|----------|\n",
    "| **I/O Bound** | Database queries, HTTP requests, File I/O, Network calls | Waiting for external systems | Async programming |\n",
    "| **CPU Bound** | Image processing, Encryption, ML inference, Data parsing | Heavy computation | Multiprocessing |\n",
    "\n",
    "### The Problem with Synchronous Code\n",
    "\n",
    "```\n",
    "Synchronous Execution (1 worker, 3 requests):\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│ Request 1: [████████████████] (2s)                                          │\n",
    "│ Request 2:                   [████████████████] (2s)                        │\n",
    "│ Request 3:                                      [████████████████] (2s)     │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "Total time: 6 seconds\n",
    "\n",
    "Asynchronous Execution (1 worker, 3 requests):\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│ Request 1: [████████████████] (2s)                                          │\n",
    "│ Request 2: [████████████████] (2s)                                          │\n",
    "│ Request 3: [████████████████] (2s)                                          │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "Total time: ~2 seconds (concurrent execution)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bd5f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import asyncio\n",
    "from typing import List\n",
    "\n",
    "# Synchronous approach - sequential execution\n",
    "def fetch_data_sync(item_id: int) -> dict:\n",
    "    \"\"\"Simulates a database/API call that takes 1 second.\"\"\"\n",
    "    time.sleep(1)  # Blocking call\n",
    "    return {\"id\": item_id, \"data\": f\"Result for {item_id}\"}\n",
    "\n",
    "def process_items_sync(item_ids: List[int]) -> List[dict]:\n",
    "    \"\"\"Process items sequentially.\"\"\"\n",
    "    results = []\n",
    "    for item_id in item_ids:\n",
    "        results.append(fetch_data_sync(item_id))\n",
    "    return results\n",
    "\n",
    "# Measure synchronous execution\n",
    "start = time.perf_counter()\n",
    "sync_results = process_items_sync([1, 2, 3, 4, 5])\n",
    "sync_duration = time.perf_counter() - start\n",
    "print(f\"Synchronous: {sync_duration:.2f}s for {len(sync_results)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asynchronous approach - concurrent execution\n",
    "async def fetch_data_async(item_id: int) -> dict:\n",
    "    \"\"\"Simulates an async database/API call that takes 1 second.\"\"\"\n",
    "    await asyncio.sleep(1)  # Non-blocking call\n",
    "    return {\"id\": item_id, \"data\": f\"Result for {item_id}\"}\n",
    "\n",
    "async def process_items_async(item_ids: List[int]) -> List[dict]:\n",
    "    \"\"\"Process items concurrently.\"\"\"\n",
    "    tasks = [fetch_data_async(item_id) for item_id in item_ids]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return list(results)\n",
    "\n",
    "# Measure asynchronous execution\n",
    "start = time.perf_counter()\n",
    "async_results = await process_items_async([1, 2, 3, 4, 5])\n",
    "async_duration = time.perf_counter() - start\n",
    "print(f\"Asynchronous: {async_duration:.2f}s for {len(async_results)} items\")\n",
    "print(f\"\\nSpeedup: {sync_duration / async_duration:.1f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96695b71",
   "metadata": {},
   "source": [
    "### Real-World Backend Scenario: API Gateway\n",
    "\n",
    "Consider an API endpoint that aggregates data from multiple services:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                           API Gateway Request                               │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                             │\n",
    "│   ┌──────────────┐    ┌──────────────┐    ┌──────────────┐                 │\n",
    "│   │ User Service │    │ Order Service│    │ Product Svc  │                 │\n",
    "│   │   (50ms)     │    │   (100ms)    │    │   (75ms)     │                 │\n",
    "│   └──────────────┘    └──────────────┘    └──────────────┘                 │\n",
    "│                                                                             │\n",
    "│   Sync Total:  50 + 100 + 75 = 225ms                                       │\n",
    "│   Async Total: max(50, 100, 75) = 100ms                                    │\n",
    "│                                                                             │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85459dd3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"2-asyncio-fundamentals\"></a>\n",
    "## 2. Python asyncio Fundamentals\n",
    "\n",
    "### Core Concepts Architecture\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                            ASYNCIO ARCHITECTURE                             │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                             │\n",
    "│   ┌─────────────────────────────────────────────────────────────────────┐  │\n",
    "│   │                         EVENT LOOP                                   │  │\n",
    "│   │  (Single-threaded scheduler that manages all async operations)      │  │\n",
    "│   └─────────────────────────────────────────────────────────────────────┘  │\n",
    "│                    │                                                        │\n",
    "│         ┌──────────┴──────────┬─────────────────────┐                      │\n",
    "│         ▼                     ▼                     ▼                      │\n",
    "│   ┌───────────┐         ┌───────────┐         ┌───────────┐               │\n",
    "│   │ COROUTINE │         │   TASK    │         │  FUTURE   │               │\n",
    "│   │           │         │           │         │           │               │\n",
    "│   │ async def │         │ Wrapped   │         │ Low-level │               │\n",
    "│   │ function  │ ──────▶ │ coroutine │ ──────▶ │ awaitable │               │\n",
    "│   │           │  create │ scheduled │  result │ result    │               │\n",
    "│   └───────────┘  _task  └───────────┘  holder └───────────┘               │\n",
    "│                                                                             │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bda526",
   "metadata": {},
   "source": [
    "### 2.1 The Event Loop\n",
    "\n",
    "The event loop is the heart of asyncio - it schedules and runs async code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb66925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Getting the current event loop\n",
    "loop = asyncio.get_event_loop()\n",
    "print(f\"Event Loop: {type(loop).__name__}\")\n",
    "print(f\"Is running: {loop.is_running()}\")\n",
    "\n",
    "# In Jupyter/IPython, the event loop is already running\n",
    "# In scripts, you'd use asyncio.run() which creates and manages the loop\n",
    "\n",
    "async def demonstrate_loop():\n",
    "    \"\"\"Show event loop details from within a coroutine.\"\"\"\n",
    "    current_loop = asyncio.get_running_loop()\n",
    "    print(f\"Running loop: {current_loop}\")\n",
    "    print(f\"Loop time: {current_loop.time():.4f}\")\n",
    "    return \"Loop demonstration complete\"\n",
    "\n",
    "result = await demonstrate_loop()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4448cc",
   "metadata": {},
   "source": [
    "### 2.2 Coroutines\n",
    "\n",
    "Coroutines are the building blocks of async code - special functions that can be paused and resumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7429040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import inspect\n",
    "\n",
    "# Define a coroutine function\n",
    "async def my_coroutine(name: str, delay: float) -> str:\n",
    "    \"\"\"A simple coroutine that simulates async work.\"\"\"\n",
    "    print(f\"[{name}] Starting...\")\n",
    "    await asyncio.sleep(delay)  # Yield control back to event loop\n",
    "    print(f\"[{name}] Completed after {delay}s\")\n",
    "    return f\"{name} result\"\n",
    "\n",
    "# Calling the function returns a coroutine object (not the result!)\n",
    "coro = my_coroutine(\"test\", 0.1)\n",
    "print(f\"Type: {type(coro)}\")\n",
    "print(f\"Is coroutine: {inspect.iscoroutine(coro)}\")\n",
    "print(f\"Is coroutine function: {inspect.iscoroutinefunction(my_coroutine)}\")\n",
    "\n",
    "# To get the result, we must await it\n",
    "result = await coro\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7db9ae",
   "metadata": {},
   "source": [
    "### 2.3 Tasks\n",
    "\n",
    "Tasks wrap coroutines and schedule them for execution. They allow coroutines to run concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a638fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def worker(name: str, duration: float) -> str:\n",
    "    \"\"\"Simulates an async worker.\"\"\"\n",
    "    print(f\"Worker {name}: started\")\n",
    "    await asyncio.sleep(duration)\n",
    "    print(f\"Worker {name}: finished\")\n",
    "    return f\"Result from {name}\"\n",
    "\n",
    "async def demonstrate_tasks():\n",
    "    \"\"\"Show how tasks enable concurrent execution.\"\"\"\n",
    "    \n",
    "    # Create tasks - they start running immediately!\n",
    "    task1 = asyncio.create_task(worker(\"A\", 2), name=\"TaskA\")\n",
    "    task2 = asyncio.create_task(worker(\"B\", 1), name=\"TaskB\")\n",
    "    task3 = asyncio.create_task(worker(\"C\", 1.5), name=\"TaskC\")\n",
    "    \n",
    "    print(f\"\\nTask 1: {task1.get_name()}, done={task1.done()}\")\n",
    "    print(f\"Task 2: {task2.get_name()}, done={task2.done()}\")\n",
    "    print(f\"Task 3: {task3.get_name()}, done={task3.done()}\")\n",
    "    \n",
    "    # Wait for all tasks to complete\n",
    "    results = await asyncio.gather(task1, task2, task3)\n",
    "    \n",
    "    print(f\"\\nAll tasks completed!\")\n",
    "    print(f\"Results: {results}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "await demonstrate_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8ed3d4",
   "metadata": {},
   "source": [
    "### 2.4 Futures\n",
    "\n",
    "Futures are low-level awaitables representing an eventual result. Tasks are actually a subclass of Future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def demonstrate_futures():\n",
    "    \"\"\"Show how Futures work at a low level.\"\"\"\n",
    "    loop = asyncio.get_running_loop()\n",
    "    \n",
    "    # Create a Future manually\n",
    "    future = loop.create_future()\n",
    "    \n",
    "    print(f\"Future created: done={future.done()}\")\n",
    "    \n",
    "    # Simulate setting the result from somewhere else\n",
    "    async def set_result_later():\n",
    "        await asyncio.sleep(1)\n",
    "        future.set_result(\"Future completed!\")\n",
    "        print(\"Result was set on the future\")\n",
    "    \n",
    "    # Start the task that will set the result\n",
    "    asyncio.create_task(set_result_later())\n",
    "    \n",
    "    # Wait for the future\n",
    "    print(\"Waiting for future...\")\n",
    "    result = await future\n",
    "    print(f\"Got result: {result}\")\n",
    "    \n",
    "    # Demonstrate Task is a Future subclass\n",
    "    task = asyncio.create_task(asyncio.sleep(0.1))\n",
    "    print(f\"\\nTask is Future subclass: {isinstance(task, asyncio.Future)}\")\n",
    "\n",
    "await demonstrate_futures()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c01ea5d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"3-async-await-patterns\"></a>\n",
    "## 3. async/await Syntax and Patterns\n",
    "\n",
    "### 3.1 Basic Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import Any, Optional\n",
    "\n",
    "# Pattern 1: Simple async function\n",
    "async def fetch_user(user_id: int) -> dict:\n",
    "    \"\"\"Fetch user from database.\"\"\"\n",
    "    await asyncio.sleep(0.1)  # Simulate DB query\n",
    "    return {\"id\": user_id, \"name\": f\"User_{user_id}\"}\n",
    "\n",
    "# Pattern 2: Async function with error handling\n",
    "async def safe_fetch_user(user_id: int) -> Optional[dict]:\n",
    "    \"\"\"Fetch user with error handling.\"\"\"\n",
    "    try:\n",
    "        if user_id < 0:\n",
    "            raise ValueError(\"Invalid user ID\")\n",
    "        return await fetch_user(user_id)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching user {user_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Pattern 3: Chaining async calls\n",
    "async def fetch_user_orders(user_id: int) -> dict:\n",
    "    \"\"\"Fetch user and their orders.\"\"\"\n",
    "    user = await fetch_user(user_id)\n",
    "    \n",
    "    # Simulate fetching orders\n",
    "    await asyncio.sleep(0.1)\n",
    "    orders = [{\"order_id\": i, \"user_id\": user_id} for i in range(3)]\n",
    "    \n",
    "    return {\"user\": user, \"orders\": orders}\n",
    "\n",
    "# Test the patterns\n",
    "user = await fetch_user(1)\n",
    "print(f\"Pattern 1 - User: {user}\")\n",
    "\n",
    "safe_user = await safe_fetch_user(-1)\n",
    "print(f\"Pattern 2 - Safe fetch: {safe_user}\")\n",
    "\n",
    "user_orders = await fetch_user_orders(1)\n",
    "print(f\"Pattern 3 - User with orders: {user_orders}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e3af20",
   "metadata": {},
   "source": [
    "### 3.2 Advanced Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcece74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import Callable, TypeVar, Awaitable\n",
    "from functools import wraps\n",
    "import time\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "# Pattern 4: Async decorator for timing\n",
    "def async_timed(func: Callable[..., Awaitable[T]]) -> Callable[..., Awaitable[T]]:\n",
    "    \"\"\"Decorator to time async functions.\"\"\"\n",
    "    @wraps(func)\n",
    "    async def wrapper(*args, **kwargs) -> T:\n",
    "        start = time.perf_counter()\n",
    "        result = await func(*args, **kwargs)\n",
    "        elapsed = time.perf_counter() - start\n",
    "        print(f\"{func.__name__} took {elapsed:.4f}s\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@async_timed\n",
    "async def slow_operation() -> str:\n",
    "    \"\"\"A slow async operation.\"\"\"\n",
    "    await asyncio.sleep(0.5)\n",
    "    return \"Done!\"\n",
    "\n",
    "# Pattern 5: Retry decorator with exponential backoff\n",
    "def async_retry(\n",
    "    max_attempts: int = 3,\n",
    "    base_delay: float = 1.0,\n",
    "    exponential_base: float = 2.0\n",
    "):\n",
    "    \"\"\"Decorator for retrying failed async operations.\"\"\"\n",
    "    def decorator(func: Callable[..., Awaitable[T]]) -> Callable[..., Awaitable[T]]:\n",
    "        @wraps(func)\n",
    "        async def wrapper(*args, **kwargs) -> T:\n",
    "            last_exception = None\n",
    "            for attempt in range(max_attempts):\n",
    "                try:\n",
    "                    return await func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    last_exception = e\n",
    "                    if attempt < max_attempts - 1:\n",
    "                        delay = base_delay * (exponential_base ** attempt)\n",
    "                        print(f\"Attempt {attempt + 1} failed, retrying in {delay}s...\")\n",
    "                        await asyncio.sleep(delay)\n",
    "            raise last_exception\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "attempt_count = 0\n",
    "\n",
    "@async_retry(max_attempts=3, base_delay=0.1)\n",
    "async def flaky_operation() -> str:\n",
    "    \"\"\"Simulates an operation that fails intermittently.\"\"\"\n",
    "    global attempt_count\n",
    "    attempt_count += 1\n",
    "    if attempt_count < 3:\n",
    "        raise ConnectionError(\"Service unavailable\")\n",
    "    return \"Success after retries!\"\n",
    "\n",
    "# Test the patterns\n",
    "result = await slow_operation()\n",
    "print(f\"Timed result: {result}\")\n",
    "\n",
    "print(\"\\nTesting retry pattern:\")\n",
    "result = await flaky_operation()\n",
    "print(f\"Retry result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb9e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import TypeVar, Generic, Optional\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "# Pattern 6: Async cache\n",
    "@dataclass\n",
    "class CacheEntry(Generic[T]):\n",
    "    value: T\n",
    "    expires_at: datetime\n",
    "\n",
    "class AsyncCache(Generic[T]):\n",
    "    \"\"\"Simple async-aware cache.\"\"\"\n",
    "    \n",
    "    def __init__(self, ttl_seconds: float = 60.0):\n",
    "        self._cache: dict[str, CacheEntry[T]] = {}\n",
    "        self._ttl = timedelta(seconds=ttl_seconds)\n",
    "        self._lock = asyncio.Lock()\n",
    "    \n",
    "    async def get(self, key: str) -> Optional[T]:\n",
    "        \"\"\"Get value from cache.\"\"\"\n",
    "        async with self._lock:\n",
    "            entry = self._cache.get(key)\n",
    "            if entry and datetime.now() < entry.expires_at:\n",
    "                return entry.value\n",
    "            return None\n",
    "    \n",
    "    async def set(self, key: str, value: T) -> None:\n",
    "        \"\"\"Set value in cache.\"\"\"\n",
    "        async with self._lock:\n",
    "            self._cache[key] = CacheEntry(\n",
    "                value=value,\n",
    "                expires_at=datetime.now() + self._ttl\n",
    "            )\n",
    "    \n",
    "    async def get_or_set(self, key: str, factory: Callable[[], Awaitable[T]]) -> T:\n",
    "        \"\"\"Get from cache or compute and store.\"\"\"\n",
    "        cached = await self.get(key)\n",
    "        if cached is not None:\n",
    "            print(f\"Cache HIT for {key}\")\n",
    "            return cached\n",
    "        \n",
    "        print(f\"Cache MISS for {key}\")\n",
    "        value = await factory()\n",
    "        await self.set(key, value)\n",
    "        return value\n",
    "\n",
    "# Demonstrate the cache\n",
    "cache: AsyncCache[dict] = AsyncCache(ttl_seconds=10)\n",
    "\n",
    "async def expensive_fetch(user_id: int) -> dict:\n",
    "    \"\"\"Simulates expensive database fetch.\"\"\"\n",
    "    await asyncio.sleep(0.5)  # Expensive operation\n",
    "    return {\"id\": user_id, \"data\": \"expensive_data\"}\n",
    "\n",
    "# First call - cache miss\n",
    "user = await cache.get_or_set(\"user:1\", lambda: expensive_fetch(1))\n",
    "print(f\"Result: {user}\")\n",
    "\n",
    "# Second call - cache hit\n",
    "user = await cache.get_or_set(\"user:1\", lambda: expensive_fetch(1))\n",
    "print(f\"Result: {user}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc789cf6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"4-concurrent-tasks\"></a>\n",
    "## 4. Running Concurrent Tasks\n",
    "\n",
    "### 4.1 asyncio.gather - Wait for All\n",
    "\n",
    "Best for: Running multiple tasks and collecting all results together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2aeb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def fetch_service(name: str, delay: float) -> dict:\n",
    "    \"\"\"Simulate fetching from a service.\"\"\"\n",
    "    await asyncio.sleep(delay)\n",
    "    return {\"service\": name, \"delay\": delay}\n",
    "\n",
    "async def demonstrate_gather():\n",
    "    \"\"\"Show asyncio.gather usage patterns.\"\"\"\n",
    "    \n",
    "    # Basic gather - all results in order\n",
    "    print(\"Basic gather:\")\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    results = await asyncio.gather(\n",
    "        fetch_service(\"users\", 1.0),\n",
    "        fetch_service(\"orders\", 0.5),\n",
    "        fetch_service(\"products\", 0.8),\n",
    "    )\n",
    "    \n",
    "    elapsed = time.perf_counter() - start\n",
    "    print(f\"  Results: {results}\")\n",
    "    print(f\"  Total time: {elapsed:.2f}s (concurrent, not 2.3s sequential)\")\n",
    "    \n",
    "    # With return_exceptions=True - don't fail on first error\n",
    "    print(\"\\nGather with return_exceptions:\")\n",
    "    \n",
    "    async def failing_service():\n",
    "        await asyncio.sleep(0.2)\n",
    "        raise ValueError(\"Service failed!\")\n",
    "    \n",
    "    results = await asyncio.gather(\n",
    "        fetch_service(\"users\", 0.3),\n",
    "        failing_service(),\n",
    "        fetch_service(\"products\", 0.4),\n",
    "        return_exceptions=True  # Don't raise, return exceptions as results\n",
    "    )\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        if isinstance(result, Exception):\n",
    "            print(f\"  Task {i}: FAILED - {result}\")\n",
    "        else:\n",
    "            print(f\"  Task {i}: {result}\")\n",
    "\n",
    "await demonstrate_gather()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8356006",
   "metadata": {},
   "source": [
    "### 4.2 asyncio.wait - More Control\n",
    "\n",
    "Best for: When you need to handle tasks as they complete or need timeout control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447cf21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def task_with_name(name: str, delay: float) -> str:\n",
    "    \"\"\"Named task for demonstration.\"\"\"\n",
    "    await asyncio.sleep(delay)\n",
    "    return f\"{name} completed\"\n",
    "\n",
    "async def demonstrate_wait():\n",
    "    \"\"\"Show asyncio.wait usage patterns.\"\"\"\n",
    "    \n",
    "    tasks = [\n",
    "        asyncio.create_task(task_with_name(\"Fast\", 0.5), name=\"fast\"),\n",
    "        asyncio.create_task(task_with_name(\"Medium\", 1.0), name=\"medium\"),\n",
    "        asyncio.create_task(task_with_name(\"Slow\", 2.0), name=\"slow\"),\n",
    "    ]\n",
    "    \n",
    "    # Wait for first task to complete\n",
    "    print(\"FIRST_COMPLETED mode:\")\n",
    "    done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n",
    "    print(f\"  Done: {[t.get_name() for t in done]}\")\n",
    "    print(f\"  Pending: {[t.get_name() for t in pending]}\")\n",
    "    \n",
    "    # Wait for remaining with timeout\n",
    "    print(\"\\nWith timeout (0.6s):\")\n",
    "    done2, pending2 = await asyncio.wait(pending, timeout=0.6)\n",
    "    print(f\"  Done: {[t.get_name() for t in done2]}\")\n",
    "    print(f\"  Still pending: {[t.get_name() for t in pending2]}\")\n",
    "    \n",
    "    # Cancel remaining tasks\n",
    "    for task in pending2:\n",
    "        task.cancel()\n",
    "        try:\n",
    "            await task\n",
    "        except asyncio.CancelledError:\n",
    "            print(f\"  Cancelled: {task.get_name()}\")\n",
    "\n",
    "await demonstrate_wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f5fe4",
   "metadata": {},
   "source": [
    "### 4.3 asyncio.as_completed - Process Results Immediately\n",
    "\n",
    "Best for: Processing results as soon as they're available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966715d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def api_call(endpoint: str, delay: float) -> dict:\n",
    "    \"\"\"Simulate API call with variable response time.\"\"\"\n",
    "    await asyncio.sleep(delay)\n",
    "    return {\"endpoint\": endpoint, \"data\": f\"response from {endpoint}\"}\n",
    "\n",
    "async def demonstrate_as_completed():\n",
    "    \"\"\"Show asyncio.as_completed for streaming results.\"\"\"\n",
    "    \n",
    "    tasks = [\n",
    "        api_call(\"/users\", 1.5),\n",
    "        api_call(\"/orders\", 0.5),\n",
    "        api_call(\"/products\", 1.0),\n",
    "        api_call(\"/inventory\", 0.3),\n",
    "    ]\n",
    "    \n",
    "    print(\"Processing results as they complete:\")\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    # Results come in completion order, not submission order\n",
    "    for i, coro in enumerate(asyncio.as_completed(tasks)):\n",
    "        result = await coro\n",
    "        elapsed = time.perf_counter() - start\n",
    "        print(f\"  [{elapsed:.2f}s] Result {i+1}: {result['endpoint']}\")\n",
    "    \n",
    "    total = time.perf_counter() - start\n",
    "    print(f\"\\nAll completed in {total:.2f}s\")\n",
    "\n",
    "await demonstrate_as_completed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991ac7fc",
   "metadata": {},
   "source": [
    "### 4.4 TaskGroup (Python 3.11+) - Structured Concurrency\n",
    "\n",
    "Best for: Modern approach with automatic cleanup and better error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf32a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import sys\n",
    "\n",
    "async def service_call(name: str, delay: float, should_fail: bool = False) -> str:\n",
    "    \"\"\"Simulated service call.\"\"\"\n",
    "    await asyncio.sleep(delay)\n",
    "    if should_fail:\n",
    "        raise RuntimeError(f\"{name} failed!\")\n",
    "    return f\"{name}: success\"\n",
    "\n",
    "async def demonstrate_taskgroup():\n",
    "    \"\"\"Show TaskGroup for structured concurrency.\"\"\"\n",
    "    \n",
    "    print(f\"Python version: {sys.version_info.major}.{sys.version_info.minor}\")\n",
    "    \n",
    "    if sys.version_info >= (3, 11):\n",
    "        # Successful task group\n",
    "        print(\"\\nSuccessful TaskGroup:\")\n",
    "        results = []\n",
    "        \n",
    "        async with asyncio.TaskGroup() as tg:\n",
    "            # Create tasks within the group\n",
    "            task1 = tg.create_task(service_call(\"Service A\", 0.5))\n",
    "            task2 = tg.create_task(service_call(\"Service B\", 0.3))\n",
    "            task3 = tg.create_task(service_call(\"Service C\", 0.7))\n",
    "        \n",
    "        # All tasks are complete when we exit the context manager\n",
    "        print(f\"  Result 1: {task1.result()}\")\n",
    "        print(f\"  Result 2: {task2.result()}\")\n",
    "        print(f\"  Result 3: {task3.result()}\")\n",
    "        \n",
    "        # TaskGroup with error - all tasks are cancelled\n",
    "        print(\"\\nTaskGroup with error (demonstrates automatic cancellation):\")\n",
    "        try:\n",
    "            async with asyncio.TaskGroup() as tg:\n",
    "                tg.create_task(service_call(\"Good Service\", 0.5))\n",
    "                tg.create_task(service_call(\"Bad Service\", 0.2, should_fail=True))\n",
    "                tg.create_task(service_call(\"Another Good\", 0.4))\n",
    "        except* RuntimeError as eg:\n",
    "            print(f\"  Caught errors: {[str(e) for e in eg.exceptions]}\")\n",
    "    else:\n",
    "        print(\"TaskGroup requires Python 3.11+\")\n",
    "        print(\"Using gather with return_exceptions as alternative...\")\n",
    "\n",
    "await demonstrate_taskgroup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f7dcf8",
   "metadata": {},
   "source": [
    "### Comparison: When to Use Each\n",
    "\n",
    "| Function | Use Case | Error Handling | Order |\n",
    "|----------|----------|----------------|-------|\n",
    "| `gather` | Collect all results | Can return exceptions | Preserves input order |\n",
    "| `wait` | Need timeout/first-complete | Manual handling | Unordered sets |\n",
    "| `as_completed` | Process results immediately | Per-task handling | Completion order |\n",
    "| `TaskGroup` | Structured concurrency | Automatic cleanup | N/A (no return) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be05e6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"5-async-context-managers\"></a>\n",
    "## 5. Async Context Managers and Iterators\n",
    "\n",
    "### 5.1 Async Context Managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4aca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from contextlib import asynccontextmanager\n",
    "from typing import AsyncIterator\n",
    "\n",
    "# Method 1: Class-based async context manager\n",
    "class AsyncDatabaseConnection:\n",
    "    \"\"\"Async database connection with context manager.\"\"\"\n",
    "    \n",
    "    def __init__(self, connection_string: str):\n",
    "        self.connection_string = connection_string\n",
    "        self.connected = False\n",
    "    \n",
    "    async def __aenter__(self) -> 'AsyncDatabaseConnection':\n",
    "        \"\"\"Async enter - establish connection.\"\"\"\n",
    "        print(f\"Connecting to {self.connection_string}...\")\n",
    "        await asyncio.sleep(0.2)  # Simulate connection\n",
    "        self.connected = True\n",
    "        print(\"Connected!\")\n",
    "        return self\n",
    "    \n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb) -> bool:\n",
    "        \"\"\"Async exit - close connection.\"\"\"\n",
    "        print(\"Closing connection...\")\n",
    "        await asyncio.sleep(0.1)  # Simulate cleanup\n",
    "        self.connected = False\n",
    "        print(\"Connection closed!\")\n",
    "        return False  # Don't suppress exceptions\n",
    "    \n",
    "    async def query(self, sql: str) -> list:\n",
    "        \"\"\"Execute a query.\"\"\"\n",
    "        if not self.connected:\n",
    "            raise RuntimeError(\"Not connected!\")\n",
    "        await asyncio.sleep(0.1)  # Simulate query\n",
    "        return [{\"result\": f\"data for: {sql}\"}]\n",
    "\n",
    "# Test class-based context manager\n",
    "print(\"Class-based async context manager:\")\n",
    "async with AsyncDatabaseConnection(\"postgresql://localhost/db\") as db:\n",
    "    result = await db.query(\"SELECT * FROM users\")\n",
    "    print(f\"Query result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import asynccontextmanager\n",
    "\n",
    "# Method 2: Decorator-based async context manager\n",
    "@asynccontextmanager\n",
    "async def async_timer(name: str) -> AsyncIterator[None]:\n",
    "    \"\"\"Context manager to time async operations.\"\"\"\n",
    "    import time\n",
    "    start = time.perf_counter()\n",
    "    print(f\"[{name}] Starting...\")\n",
    "    try:\n",
    "        yield  # The body of the 'async with' runs here\n",
    "    finally:\n",
    "        elapsed = time.perf_counter() - start\n",
    "        print(f\"[{name}] Completed in {elapsed:.4f}s\")\n",
    "\n",
    "@asynccontextmanager\n",
    "async def managed_resource(resource_id: str) -> AsyncIterator[dict]:\n",
    "    \"\"\"Manage a resource lifecycle.\"\"\"\n",
    "    print(f\"Acquiring resource {resource_id}\")\n",
    "    await asyncio.sleep(0.1)\n",
    "    resource = {\"id\": resource_id, \"status\": \"active\"}\n",
    "    \n",
    "    try:\n",
    "        yield resource\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        resource[\"status\"] = \"error\"\n",
    "        raise\n",
    "    finally:\n",
    "        print(f\"Releasing resource {resource_id}\")\n",
    "        await asyncio.sleep(0.05)\n",
    "        resource[\"status\"] = \"released\"\n",
    "\n",
    "# Test decorator-based context managers\n",
    "print(\"Decorator-based async context managers:\")\n",
    "async with async_timer(\"database_operation\"):\n",
    "    async with managed_resource(\"res-123\") as resource:\n",
    "        print(f\"Using resource: {resource}\")\n",
    "        await asyncio.sleep(0.3)  # Simulate work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9cd1b1",
   "metadata": {},
   "source": [
    "### 5.2 Async Iterators and Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f9e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import AsyncIterator\n",
    "\n",
    "# Method 1: Async generator function\n",
    "async def async_range(start: int, stop: int, delay: float = 0.1) -> AsyncIterator[int]:\n",
    "    \"\"\"Async version of range.\"\"\"\n",
    "    for i in range(start, stop):\n",
    "        await asyncio.sleep(delay)  # Simulate async work\n",
    "        yield i\n",
    "\n",
    "# Method 2: Class-based async iterator\n",
    "class AsyncPaginator:\n",
    "    \"\"\"Paginate through a large dataset asynchronously.\"\"\"\n",
    "    \n",
    "    def __init__(self, total_items: int, page_size: int = 10):\n",
    "        self.total_items = total_items\n",
    "        self.page_size = page_size\n",
    "        self.current_page = 0\n",
    "    \n",
    "    def __aiter__(self) -> 'AsyncPaginator':\n",
    "        return self\n",
    "    \n",
    "    async def __anext__(self) -> list:\n",
    "        start = self.current_page * self.page_size\n",
    "        if start >= self.total_items:\n",
    "            raise StopAsyncIteration\n",
    "        \n",
    "        # Simulate fetching page from database\n",
    "        await asyncio.sleep(0.1)\n",
    "        \n",
    "        end = min(start + self.page_size, self.total_items)\n",
    "        items = list(range(start, end))\n",
    "        self.current_page += 1\n",
    "        \n",
    "        return items\n",
    "\n",
    "# Test async iterator\n",
    "print(\"Async range:\")\n",
    "async for num in async_range(0, 5, delay=0.1):\n",
    "    print(f\"  Got: {num}\")\n",
    "\n",
    "print(\"\\nAsync paginator:\")\n",
    "async for page in AsyncPaginator(total_items=25, page_size=10):\n",
    "    print(f\"  Page: {page}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ea267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-world example: Streaming API responses\n",
    "async def stream_events(event_source: str, count: int = 5) -> AsyncIterator[dict]:\n",
    "    \"\"\"Stream events from a source.\"\"\"\n",
    "    for i in range(count):\n",
    "        await asyncio.sleep(0.2)  # Simulate waiting for event\n",
    "        yield {\n",
    "            \"id\": i,\n",
    "            \"source\": event_source,\n",
    "            \"data\": f\"Event {i} data\",\n",
    "            \"timestamp\": asyncio.get_event_loop().time()\n",
    "        }\n",
    "\n",
    "# Async comprehension\n",
    "print(\"Streaming events with async comprehension:\")\n",
    "events = [event async for event in stream_events(\"sensor\", count=3)]\n",
    "for event in events:\n",
    "    print(f\"  {event}\")\n",
    "\n",
    "# Async filtering\n",
    "print(\"\\nFiltered events (even IDs only):\")\n",
    "even_events = [e async for e in stream_events(\"filter-test\", count=5) if e['id'] % 2 == 0]\n",
    "for event in even_events:\n",
    "    print(f\"  {event}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b361df9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"6-error-handling\"></a>\n",
    "## 6. Error Handling in Async Code\n",
    "\n",
    "### 6.1 Basic Exception Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a6fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import Optional\n",
    "\n",
    "class ServiceError(Exception):\n",
    "    \"\"\"Custom service error.\"\"\"\n",
    "    pass\n",
    "\n",
    "async def unreliable_service(success_rate: float = 0.5) -> dict:\n",
    "    \"\"\"Simulates an unreliable service.\"\"\"\n",
    "    import random\n",
    "    await asyncio.sleep(0.1)\n",
    "    \n",
    "    if random.random() > success_rate:\n",
    "        raise ServiceError(\"Service temporarily unavailable\")\n",
    "    \n",
    "    return {\"status\": \"success\", \"data\": \"valuable data\"}\n",
    "\n",
    "async def call_with_handling() -> Optional[dict]:\n",
    "    \"\"\"Call service with proper error handling.\"\"\"\n",
    "    try:\n",
    "        result = await unreliable_service(success_rate=0.3)\n",
    "        return result\n",
    "    except ServiceError as e:\n",
    "        print(f\"Service error: {e}\")\n",
    "        return None\n",
    "    except asyncio.CancelledError:\n",
    "        print(\"Task was cancelled\")\n",
    "        raise  # Always re-raise CancelledError\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {type(e).__name__}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test error handling\n",
    "print(\"Testing error handling (multiple attempts):\")\n",
    "for i in range(5):\n",
    "    result = await call_with_handling()\n",
    "    print(f\"  Attempt {i+1}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3753fa5",
   "metadata": {},
   "source": [
    "### 6.2 Handling Errors in Concurrent Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fd20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from dataclasses import dataclass\n",
    "from typing import Union, List\n",
    "\n",
    "@dataclass\n",
    "class Success:\n",
    "    value: any\n",
    "\n",
    "@dataclass  \n",
    "class Failure:\n",
    "    error: Exception\n",
    "\n",
    "Result = Union[Success, Failure]\n",
    "\n",
    "async def task_a() -> str:\n",
    "    await asyncio.sleep(0.2)\n",
    "    return \"A succeeded\"\n",
    "\n",
    "async def task_b() -> str:\n",
    "    await asyncio.sleep(0.1)\n",
    "    raise ValueError(\"B failed!\")\n",
    "\n",
    "async def task_c() -> str:\n",
    "    await asyncio.sleep(0.3)\n",
    "    return \"C succeeded\"\n",
    "\n",
    "async def safe_gather(*coros) -> List[Result]:\n",
    "    \"\"\"Gather that returns Success/Failure for each task.\"\"\"\n",
    "    results = await asyncio.gather(*coros, return_exceptions=True)\n",
    "    return [\n",
    "        Failure(r) if isinstance(r, Exception) else Success(r)\n",
    "        for r in results\n",
    "    ]\n",
    "\n",
    "# Demonstrate safe gathering\n",
    "print(\"Safe gather with mixed success/failure:\")\n",
    "results = await safe_gather(task_a(), task_b(), task_c())\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    match result:\n",
    "        case Success(value):\n",
    "            print(f\"  Task {i}: ✓ {value}\")\n",
    "        case Failure(error):\n",
    "            print(f\"  Task {i}: ✗ {type(error).__name__}: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927dff93",
   "metadata": {},
   "source": [
    "### 6.3 Timeout Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e58107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import TypeVar, Optional\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "async def slow_operation(duration: float) -> str:\n",
    "    \"\"\"An operation that takes a while.\"\"\"\n",
    "    await asyncio.sleep(duration)\n",
    "    return f\"Completed after {duration}s\"\n",
    "\n",
    "async def with_timeout(\n",
    "    coro,\n",
    "    timeout: float,\n",
    "    default: Optional[T] = None\n",
    ") -> Optional[T]:\n",
    "    \"\"\"Execute coroutine with timeout, return default on timeout.\"\"\"\n",
    "    try:\n",
    "        return await asyncio.wait_for(coro, timeout=timeout)\n",
    "    except asyncio.TimeoutError:\n",
    "        print(f\"Operation timed out after {timeout}s\")\n",
    "        return default\n",
    "\n",
    "# Test timeout handling\n",
    "print(\"Timeout handling:\")\n",
    "\n",
    "# This should succeed\n",
    "result = await with_timeout(slow_operation(0.5), timeout=1.0)\n",
    "print(f\"  Fast operation: {result}\")\n",
    "\n",
    "# This should timeout\n",
    "result = await with_timeout(slow_operation(2.0), timeout=0.5, default=\"TIMEOUT\")\n",
    "print(f\"  Slow operation: {result}\")\n",
    "\n",
    "# Using asyncio.timeout context manager (Python 3.11+)\n",
    "import sys\n",
    "if sys.version_info >= (3, 11):\n",
    "    print(\"\\nUsing asyncio.timeout context manager:\")\n",
    "    try:\n",
    "        async with asyncio.timeout(0.3):\n",
    "            result = await slow_operation(1.0)\n",
    "    except TimeoutError:\n",
    "        print(\"  Context manager timeout triggered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1c197e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"7-common-pitfalls\"></a>\n",
    "## 7. Common Pitfalls\n",
    "\n",
    "### 7.1 Blocking the Event Loop\n",
    "\n",
    "**The #1 async mistake:** Calling blocking code in async functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043aed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# ❌ BAD: Blocking the event loop\n",
    "async def bad_async_function():\n",
    "    \"\"\"This blocks the entire event loop!\"\"\"\n",
    "    time.sleep(1)  # ❌ Blocking call!\n",
    "    return \"Done\"\n",
    "\n",
    "# ✅ GOOD: Use asyncio.sleep for delays\n",
    "async def good_async_function():\n",
    "    \"\"\"Non-blocking async function.\"\"\"\n",
    "    await asyncio.sleep(1)  # ✅ Non-blocking\n",
    "    return \"Done\"\n",
    "\n",
    "# ✅ GOOD: Run blocking code in thread pool\n",
    "def cpu_intensive_work(n: int) -> int:\n",
    "    \"\"\"Simulate CPU-bound work.\"\"\"\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i * i\n",
    "    return total\n",
    "\n",
    "async def properly_wrapped_blocking():\n",
    "    \"\"\"Run blocking code without blocking the event loop.\"\"\"\n",
    "    loop = asyncio.get_running_loop()\n",
    "    \n",
    "    # Run in default thread pool executor\n",
    "    result = await loop.run_in_executor(None, cpu_intensive_work, 100000)\n",
    "    return result\n",
    "\n",
    "# Demonstrate the difference\n",
    "print(\"Running blocking code properly:\")\n",
    "\n",
    "async def demonstrate_blocking():\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    # Run multiple CPU tasks concurrently using thread pool\n",
    "    results = await asyncio.gather(\n",
    "        properly_wrapped_blocking(),\n",
    "        properly_wrapped_blocking(),\n",
    "        properly_wrapped_blocking(),\n",
    "    )\n",
    "    \n",
    "    elapsed = time.perf_counter() - start\n",
    "    print(f\"  Completed 3 CPU tasks in {elapsed:.2f}s (concurrent)\")\n",
    "    return results\n",
    "\n",
    "await demonstrate_blocking()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40818f8",
   "metadata": {},
   "source": [
    "### 7.2 Forgetting to Await"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a752ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import warnings\n",
    "\n",
    "async def fetch_data() -> dict:\n",
    "    await asyncio.sleep(0.1)\n",
    "    return {\"data\": \"result\"}\n",
    "\n",
    "async def demonstrate_missing_await():\n",
    "    \"\"\"Show what happens when you forget to await.\"\"\"\n",
    "    \n",
    "    # ❌ BAD: Forgot to await - returns coroutine object, not result!\n",
    "    result_bad = fetch_data()  # No await!\n",
    "    print(f\"Without await: {result_bad}\")\n",
    "    print(f\"Type: {type(result_bad)}\")\n",
    "    \n",
    "    # Clean up the unawaited coroutine to avoid warning\n",
    "    await result_bad\n",
    "    \n",
    "    # ✅ GOOD: Properly awaited\n",
    "    result_good = await fetch_data()\n",
    "    print(f\"\\nWith await: {result_good}\")\n",
    "    print(f\"Type: {type(result_good)}\")\n",
    "\n",
    "await demonstrate_missing_await()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b9013",
   "metadata": {},
   "source": [
    "### 7.3 Task Cancellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8cdd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def cancellable_task(name: str):\n",
    "    \"\"\"A task that handles cancellation gracefully.\"\"\"\n",
    "    try:\n",
    "        print(f\"[{name}] Starting work...\")\n",
    "        for i in range(10):\n",
    "            await asyncio.sleep(0.2)\n",
    "            print(f\"[{name}] Step {i+1}/10\")\n",
    "        print(f\"[{name}] Completed!\")\n",
    "        return f\"{name} finished\"\n",
    "    except asyncio.CancelledError:\n",
    "        print(f\"[{name}] Cancelled! Cleaning up...\")\n",
    "        # Perform cleanup here\n",
    "        await asyncio.sleep(0.1)  # Simulate cleanup\n",
    "        print(f\"[{name}] Cleanup complete\")\n",
    "        raise  # Always re-raise CancelledError!\n",
    "\n",
    "async def demonstrate_cancellation():\n",
    "    \"\"\"Show proper task cancellation.\"\"\"\n",
    "    \n",
    "    # Start a task\n",
    "    task = asyncio.create_task(cancellable_task(\"Worker\"))\n",
    "    \n",
    "    # Let it run for a bit\n",
    "    await asyncio.sleep(0.5)\n",
    "    \n",
    "    # Cancel the task\n",
    "    print(\"\\n--- Requesting cancellation ---\\n\")\n",
    "    task.cancel()\n",
    "    \n",
    "    # Wait for cancellation to complete\n",
    "    try:\n",
    "        await task\n",
    "    except asyncio.CancelledError:\n",
    "        print(\"\\nTask cancellation confirmed\")\n",
    "    \n",
    "    print(f\"Task state: cancelled={task.cancelled()}\")\n",
    "\n",
    "await demonstrate_cancellation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a408aa",
   "metadata": {},
   "source": [
    "### 7.4 Fire-and-Forget Tasks (Memory Leaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513b96ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import Set\n",
    "\n",
    "# ❌ BAD: Fire and forget without tracking\n",
    "async def bad_fire_and_forget():\n",
    "    \"\"\"Tasks can be garbage collected before completion!\"\"\"\n",
    "    asyncio.create_task(some_background_work())  # ❌ Not tracked!\n",
    "\n",
    "# ✅ GOOD: Track background tasks\n",
    "background_tasks: Set[asyncio.Task] = set()\n",
    "\n",
    "async def some_background_work():\n",
    "    await asyncio.sleep(0.5)\n",
    "    print(\"  Background work completed!\")\n",
    "\n",
    "def create_background_task(coro):\n",
    "    \"\"\"Create a tracked background task.\"\"\"\n",
    "    task = asyncio.create_task(coro)\n",
    "    background_tasks.add(task)\n",
    "    task.add_done_callback(background_tasks.discard)\n",
    "    return task\n",
    "\n",
    "async def demonstrate_tracked_tasks():\n",
    "    \"\"\"Show proper background task management.\"\"\"\n",
    "    print(\"Creating background tasks:\")\n",
    "    \n",
    "    # Create tracked tasks\n",
    "    create_background_task(some_background_work())\n",
    "    create_background_task(some_background_work())\n",
    "    \n",
    "    print(f\"  Active background tasks: {len(background_tasks)}\")\n",
    "    \n",
    "    # Wait for all background tasks\n",
    "    if background_tasks:\n",
    "        await asyncio.gather(*background_tasks)\n",
    "    \n",
    "    print(f\"  Active background tasks: {len(background_tasks)}\")\n",
    "\n",
    "await demonstrate_tracked_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3641e4f0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"8-async-ecosystem\"></a>\n",
    "## 8. Async Libraries Ecosystem\n",
    "\n",
    "### Overview of Major Async Libraries\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                        ASYNC PYTHON ECOSYSTEM                               │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                             │\n",
    "│  HTTP Clients           Databases              Caching/Queues              │\n",
    "│  ───────────           ─────────              ──────────────               │\n",
    "│  • httpx               • asyncpg (PostgreSQL) • aioredis                   │\n",
    "│  • aiohttp             • aiomysql             • arq (job queues)           │\n",
    "│                        • motor (MongoDB)      • aio-pika (RabbitMQ)        │\n",
    "│                        • aiosqlite                                         │\n",
    "│                                                                             │\n",
    "│  Web Frameworks         ORMs                  Other                        │\n",
    "│  ──────────────        ────                  ─────                         │\n",
    "│  • FastAPI             • SQLAlchemy 2.0      • aiofiles                    │\n",
    "│  • Starlette           • Tortoise-ORM        • aioboto3 (AWS)              │\n",
    "│  • Sanic               • SQLModel            • asyncssh                    │\n",
    "│  • Quart                                                                   │\n",
    "│                                                                             │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f52730d",
   "metadata": {},
   "source": [
    "### 8.1 HTTP Clients: httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2dafe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using httpx for async HTTP requests\n",
    "# Note: Install with `pip install httpx`\n",
    "\n",
    "import asyncio\n",
    "\n",
    "# Simulated httpx-like async client example\n",
    "# (In real code, you would import httpx)\n",
    "\n",
    "class MockAsyncClient:\n",
    "    \"\"\"Mock async HTTP client for demonstration.\"\"\"\n",
    "    \n",
    "    async def __aenter__(self):\n",
    "        print(\"Opening HTTP client connection pool\")\n",
    "        return self\n",
    "    \n",
    "    async def __aexit__(self, *args):\n",
    "        print(\"Closing HTTP client connection pool\")\n",
    "    \n",
    "    async def get(self, url: str) -> dict:\n",
    "        await asyncio.sleep(0.2)  # Simulate network latency\n",
    "        return {\"status\": 200, \"url\": url, \"data\": f\"Response from {url}\"}\n",
    "\n",
    "async def httpx_example():\n",
    "    \"\"\"Demonstrate async HTTP client patterns.\"\"\"\n",
    "    \n",
    "    # Using async context manager for connection pooling\n",
    "    async with MockAsyncClient() as client:\n",
    "        # Single request\n",
    "        response = await client.get(\"https://api.example.com/users\")\n",
    "        print(f\"Single request: {response}\")\n",
    "        \n",
    "        # Concurrent requests\n",
    "        urls = [\n",
    "            \"https://api.example.com/users\",\n",
    "            \"https://api.example.com/orders\",\n",
    "            \"https://api.example.com/products\",\n",
    "        ]\n",
    "        \n",
    "        responses = await asyncio.gather(\n",
    "            *[client.get(url) for url in urls]\n",
    "        )\n",
    "        print(f\"\\nConcurrent requests:\")\n",
    "        for resp in responses:\n",
    "            print(f\"  {resp['url']}: {resp['status']}\")\n",
    "\n",
    "await httpx_example()\n",
    "\n",
    "# Real httpx code would look like:\n",
    "print(\"\\n--- Real httpx code example ---\")\n",
    "print(\"\"\"\n",
    "import httpx\n",
    "\n",
    "async with httpx.AsyncClient() as client:\n",
    "    # GET request\n",
    "    response = await client.get('https://api.github.com/users/octocat')\n",
    "    \n",
    "    # POST request with JSON\n",
    "    response = await client.post(\n",
    "        'https://api.example.com/data',\n",
    "        json={'key': 'value'},\n",
    "        headers={'Authorization': 'Bearer token'}\n",
    "    )\n",
    "    \n",
    "    # Concurrent requests\n",
    "    responses = await asyncio.gather(\n",
    "        client.get('https://api.example.com/a'),\n",
    "        client.get('https://api.example.com/b'),\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30752c85",
   "metadata": {},
   "source": [
    "### 8.2 Database: asyncpg (PostgreSQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d18b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using asyncpg for async PostgreSQL queries\n",
    "# Note: Install with `pip install asyncpg`\n",
    "\n",
    "print(\"--- asyncpg pattern examples ---\")\n",
    "print(\"\"\"\n",
    "import asyncpg\n",
    "\n",
    "# Connection pool pattern (recommended for web apps)\n",
    "async def create_pool():\n",
    "    return await asyncpg.create_pool(\n",
    "        host='localhost',\n",
    "        database='mydb',\n",
    "        user='user',\n",
    "        password='password',\n",
    "        min_size=5,\n",
    "        max_size=20\n",
    "    )\n",
    "\n",
    "async def query_users(pool: asyncpg.Pool):\n",
    "    async with pool.acquire() as conn:\n",
    "        # Single row\n",
    "        user = await conn.fetchrow(\n",
    "            'SELECT * FROM users WHERE id = $1',\n",
    "            user_id\n",
    "        )\n",
    "        \n",
    "        # Multiple rows\n",
    "        users = await conn.fetch(\n",
    "            'SELECT * FROM users WHERE active = $1',\n",
    "            True\n",
    "        )\n",
    "        \n",
    "        # Transaction\n",
    "        async with conn.transaction():\n",
    "            await conn.execute(\n",
    "                'INSERT INTO users(name, email) VALUES($1, $2)',\n",
    "                'John', 'john@example.com'\n",
    "            )\n",
    "            await conn.execute(\n",
    "                'UPDATE accounts SET balance = balance - $1 WHERE user_id = $2',\n",
    "                100, user_id\n",
    "            )\n",
    "\n",
    "# Copy for bulk inserts (very fast!)\n",
    "async def bulk_insert(pool: asyncpg.Pool, records: list):\n",
    "    async with pool.acquire() as conn:\n",
    "        await conn.copy_records_to_table(\n",
    "            'users',\n",
    "            records=records,\n",
    "            columns=['name', 'email', 'created_at']\n",
    "        )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcd020f",
   "metadata": {},
   "source": [
    "### 8.3 Caching: Redis with aioredis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da3288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using redis-py (which includes async support)\n",
    "# Note: Install with `pip install redis`\n",
    "\n",
    "print(\"--- redis async pattern examples ---\")\n",
    "print(\"\"\"\n",
    "import redis.asyncio as redis\n",
    "\n",
    "# Connection pool\n",
    "pool = redis.ConnectionPool.from_url(\n",
    "    'redis://localhost:6379',\n",
    "    max_connections=10\n",
    ")\n",
    "\n",
    "async def get_redis():\n",
    "    return redis.Redis(connection_pool=pool)\n",
    "\n",
    "async def cache_example():\n",
    "    r = await get_redis()\n",
    "    \n",
    "    # Basic operations\n",
    "    await r.set('key', 'value', ex=3600)  # 1 hour expiry\n",
    "    value = await r.get('key')\n",
    "    \n",
    "    # Increment counter\n",
    "    await r.incr('page_views')\n",
    "    \n",
    "    # Hash operations\n",
    "    await r.hset('user:1', mapping={\n",
    "        'name': 'John',\n",
    "        'email': 'john@example.com'\n",
    "    })\n",
    "    user = await r.hgetall('user:1')\n",
    "    \n",
    "    # List operations (for queues)\n",
    "    await r.lpush('task_queue', 'task_data')\n",
    "    task = await r.brpop('task_queue', timeout=5)  # Blocking pop\n",
    "    \n",
    "    # Pub/Sub\n",
    "    pubsub = r.pubsub()\n",
    "    await pubsub.subscribe('channel')\n",
    "    \n",
    "    async for message in pubsub.listen():\n",
    "        if message['type'] == 'message':\n",
    "            print(f\"Received: {message['data']}\")\n",
    "\n",
    "# Cache decorator pattern\n",
    "def redis_cache(expire: int = 300):\n",
    "    def decorator(func):\n",
    "        async def wrapper(*args, **kwargs):\n",
    "            r = await get_redis()\n",
    "            key = f\"{func.__name__}:{args}:{kwargs}\"\n",
    "            \n",
    "            cached = await r.get(key)\n",
    "            if cached:\n",
    "                return json.loads(cached)\n",
    "            \n",
    "            result = await func(*args, **kwargs)\n",
    "            await r.set(key, json.dumps(result), ex=expire)\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82da7f82",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"9-fastapi-patterns\"></a>\n",
    "## 9. FastAPI Async Patterns\n",
    "\n",
    "### 9.1 Basic Async Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ff2b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastAPI async patterns demonstration\n",
    "# Note: Install with `pip install fastapi uvicorn`\n",
    "\n",
    "fastapi_code = '''\n",
    "from fastapi import FastAPI, Depends, HTTPException\n",
    "from typing import List, Optional\n",
    "import asyncio\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Basic async endpoint\n",
    "@app.get(\"/users/{user_id}\")\n",
    "async def get_user(user_id: int):\n",
    "    \"\"\"Async endpoint - use for I/O bound operations.\"\"\"\n",
    "    user = await fetch_user_from_db(user_id)\n",
    "    return user\n",
    "\n",
    "# Sync endpoint (runs in thread pool)\n",
    "@app.get(\"/compute/{n}\")\n",
    "def compute_heavy(n: int):\n",
    "    \"\"\"Sync endpoint - FastAPI runs this in thread pool automatically.\"\"\"\n",
    "    # CPU-bound work\n",
    "    result = sum(i * i for i in range(n))\n",
    "    return {\"result\": result}\n",
    "\n",
    "# Aggregating multiple services\n",
    "@app.get(\"/dashboard/{user_id}\")\n",
    "async def get_dashboard(user_id: int):\n",
    "    \"\"\"Fetch from multiple services concurrently.\"\"\"\n",
    "    user, orders, notifications = await asyncio.gather(\n",
    "        fetch_user(user_id),\n",
    "        fetch_orders(user_id),\n",
    "        fetch_notifications(user_id),\n",
    "    )\n",
    "    return {\n",
    "        \"user\": user,\n",
    "        \"orders\": orders,\n",
    "        \"notifications\": notifications\n",
    "    }\n",
    "'''\n",
    "\n",
    "print(\"FastAPI Basic Patterns:\")\n",
    "print(fastapi_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c46560",
   "metadata": {},
   "source": [
    "### 9.2 Dependency Injection with Async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0073a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastapi_deps = '''\n",
    "from fastapi import FastAPI, Depends\n",
    "from contextlib import asynccontextmanager\n",
    "from typing import AsyncGenerator\n",
    "\n",
    "# Async database session dependency\n",
    "async def get_db_session() -> AsyncGenerator[DatabaseSession, None]:\n",
    "    \"\"\"Yield a database session and ensure cleanup.\"\"\"\n",
    "    session = await create_session()\n",
    "    try:\n",
    "        yield session\n",
    "    finally:\n",
    "        await session.close()\n",
    "\n",
    "# Async HTTP client dependency\n",
    "async def get_http_client() -> AsyncGenerator[httpx.AsyncClient, None]:\n",
    "    \"\"\"Yield an HTTP client.\"\"\"\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        yield client\n",
    "\n",
    "# Using dependencies\n",
    "@app.get(\"/users/{user_id}\")\n",
    "async def get_user(\n",
    "    user_id: int,\n",
    "    db: DatabaseSession = Depends(get_db_session),\n",
    "    http: httpx.AsyncClient = Depends(get_http_client)\n",
    "):\n",
    "    user = await db.query(User).get(user_id)\n",
    "    \n",
    "    # Fetch additional data from external API\n",
    "    external_data = await http.get(f\"https://api.example.com/users/{user_id}\")\n",
    "    \n",
    "    return {\"user\": user, \"external\": external_data.json()}\n",
    "\n",
    "# Lifespan context for startup/shutdown\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    \"\"\"Manage application lifecycle.\"\"\"\n",
    "    # Startup\n",
    "    app.state.db_pool = await create_pool()\n",
    "    app.state.redis = await create_redis_client()\n",
    "    \n",
    "    yield  # Application runs here\n",
    "    \n",
    "    # Shutdown\n",
    "    await app.state.db_pool.close()\n",
    "    await app.state.redis.close()\n",
    "\n",
    "app = FastAPI(lifespan=lifespan)\n",
    "'''\n",
    "\n",
    "print(\"FastAPI Dependency Injection:\")\n",
    "print(fastapi_deps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9dcb61",
   "metadata": {},
   "source": [
    "### 9.3 Background Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffac9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastapi_background = '''\n",
    "from fastapi import FastAPI, BackgroundTasks\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "async def send_email(email: str, message: str):\n",
    "    \"\"\"Send email in background.\"\"\"\n",
    "    await asyncio.sleep(5)  # Simulate email sending\n",
    "    print(f\"Email sent to {email}\")\n",
    "\n",
    "async def log_action(user_id: int, action: str):\n",
    "    \"\"\"Log user action to analytics.\"\"\"\n",
    "    await asyncio.sleep(1)  # Simulate logging\n",
    "    print(f\"Logged {action} for user {user_id}\")\n",
    "\n",
    "@app.post(\"/users/\")\n",
    "async def create_user(\n",
    "    user: UserCreate,\n",
    "    background_tasks: BackgroundTasks\n",
    "):\n",
    "    \"\"\"Create user and send welcome email in background.\"\"\"\n",
    "    # Create user immediately\n",
    "    new_user = await db.create_user(user)\n",
    "    \n",
    "    # Schedule background tasks (don't block response)\n",
    "    background_tasks.add_task(\n",
    "        send_email, \n",
    "        new_user.email, \n",
    "        \"Welcome to our platform!\"\n",
    "    )\n",
    "    background_tasks.add_task(\n",
    "        log_action,\n",
    "        new_user.id,\n",
    "        \"user_created\"\n",
    "    )\n",
    "    \n",
    "    # Return immediately\n",
    "    return {\"id\": new_user.id, \"status\": \"created\"}\n",
    "\n",
    "# For more complex background jobs, use:\n",
    "# - Celery with async support\n",
    "# - arq (async job queue)\n",
    "# - dramatiq with async\n",
    "'''\n",
    "\n",
    "print(\"FastAPI Background Tasks:\")\n",
    "print(fastapi_background)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b271e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"10-testing-async\"></a>\n",
    "## 10. Testing Async Code\n",
    "\n",
    "### 10.1 Testing with pytest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytest_examples = '''\n",
    "# Install: pip install pytest pytest-asyncio\n",
    "\n",
    "import pytest\n",
    "import asyncio\n",
    "\n",
    "# Mark all tests in module as async\n",
    "pytestmark = pytest.mark.asyncio\n",
    "\n",
    "# Basic async test\n",
    "async def test_async_function():\n",
    "    result = await my_async_function()\n",
    "    assert result == expected_value\n",
    "\n",
    "# Test with fixtures\n",
    "@pytest.fixture\n",
    "async def db_session():\n",
    "    \"\"\"Async fixture for database session.\"\"\"\n",
    "    session = await create_test_session()\n",
    "    yield session\n",
    "    await session.rollback()\n",
    "    await session.close()\n",
    "\n",
    "async def test_create_user(db_session):\n",
    "    user = await create_user(db_session, name=\"Test User\")\n",
    "    assert user.id is not None\n",
    "    assert user.name == \"Test User\"\n",
    "\n",
    "# Test exceptions\n",
    "async def test_raises_exception():\n",
    "    with pytest.raises(ValueError):\n",
    "        await function_that_raises()\n",
    "\n",
    "# Test timeouts\n",
    "async def test_with_timeout():\n",
    "    async with asyncio.timeout(1.0):\n",
    "        result = await potentially_slow_function()\n",
    "    assert result is not None\n",
    "\n",
    "# Test concurrent execution\n",
    "async def test_concurrent_operations():\n",
    "    results = await asyncio.gather(\n",
    "        operation_a(),\n",
    "        operation_b(),\n",
    "        operation_c(),\n",
    "    )\n",
    "    assert all(r.success for r in results)\n",
    "\n",
    "# Mocking async functions\n",
    "from unittest.mock import AsyncMock, patch\n",
    "\n",
    "async def test_with_mock():\n",
    "    mock_fetch = AsyncMock(return_value={\"id\": 1, \"name\": \"Test\"})\n",
    "    \n",
    "    with patch(\"mymodule.fetch_user\", mock_fetch):\n",
    "        result = await get_user_data(1)\n",
    "    \n",
    "    mock_fetch.assert_called_once_with(1)\n",
    "    assert result[\"name\"] == \"Test\"\n",
    "'''\n",
    "\n",
    "print(\"pytest-asyncio Testing Patterns:\")\n",
    "print(pytest_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d58f97",
   "metadata": {},
   "source": [
    "### 10.2 Testing FastAPI Async Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafc081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastapi_testing = '''\n",
    "# Install: pip install httpx pytest-asyncio\n",
    "\n",
    "import pytest\n",
    "from httpx import AsyncClient, ASGITransport\n",
    "from myapp import app\n",
    "\n",
    "# Async test client fixture\n",
    "@pytest.fixture\n",
    "async def client():\n",
    "    async with AsyncClient(\n",
    "        transport=ASGITransport(app=app),\n",
    "        base_url=\"http://test\"\n",
    "    ) as client:\n",
    "        yield client\n",
    "\n",
    "# Test GET endpoint\n",
    "@pytest.mark.asyncio\n",
    "async def test_get_users(client):\n",
    "    response = await client.get(\"/users/\")\n",
    "    assert response.status_code == 200\n",
    "    assert isinstance(response.json(), list)\n",
    "\n",
    "# Test POST endpoint\n",
    "@pytest.mark.asyncio\n",
    "async def test_create_user(client):\n",
    "    response = await client.post(\n",
    "        \"/users/\",\n",
    "        json={\"name\": \"Test User\", \"email\": \"test@example.com\"}\n",
    "    )\n",
    "    assert response.status_code == 201\n",
    "    data = response.json()\n",
    "    assert data[\"name\"] == \"Test User\"\n",
    "\n",
    "# Test with authentication\n",
    "@pytest.mark.asyncio\n",
    "async def test_protected_endpoint(client):\n",
    "    # First, login to get token\n",
    "    login_response = await client.post(\n",
    "        \"/auth/login\",\n",
    "        json={\"username\": \"test\", \"password\": \"password\"}\n",
    "    )\n",
    "    token = login_response.json()[\"access_token\"]\n",
    "    \n",
    "    # Access protected endpoint\n",
    "    response = await client.get(\n",
    "        \"/users/me\",\n",
    "        headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "    )\n",
    "    assert response.status_code == 200\n",
    "\n",
    "# Test with database override\n",
    "@pytest.fixture\n",
    "async def override_db():\n",
    "    async def get_test_db():\n",
    "        # Return test database session\n",
    "        async with TestSession() as session:\n",
    "            yield session\n",
    "    \n",
    "    app.dependency_overrides[get_db] = get_test_db\n",
    "    yield\n",
    "    app.dependency_overrides.clear()\n",
    "\n",
    "@pytest.mark.asyncio\n",
    "async def test_with_test_db(client, override_db):\n",
    "    response = await client.get(\"/users/1\")\n",
    "    assert response.status_code == 200\n",
    "'''\n",
    "\n",
    "print(\"FastAPI Async Testing Patterns:\")\n",
    "print(fastapi_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8affd55",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"11-when-not-to-use\"></a>\n",
    "## 11. When NOT to Use Async\n",
    "\n",
    "### Decision Framework\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                    WHEN TO USE ASYNC - DECISION TREE                        │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                             │\n",
    "│  Is your workload primarily I/O bound?                                      │\n",
    "│  │                                                                          │\n",
    "│  ├─ YES: Do you need to handle many concurrent connections?                 │\n",
    "│  │   │                                                                      │\n",
    "│  │   ├─ YES: ✅ USE ASYNC                                                   │\n",
    "│  │   │   • Web servers (FastAPI, Starlette)                                │\n",
    "│  │   │   • API gateways                                                     │\n",
    "│  │   │   • Websocket servers                                                │\n",
    "│  │   │   • Microservices                                                    │\n",
    "│  │   │                                                                      │\n",
    "│  │   └─ NO: Consider complexity trade-off                                   │\n",
    "│  │       • Simple scripts → sync may be simpler                             │\n",
    "│  │       • Few concurrent tasks → sync is fine                              │\n",
    "│  │                                                                          │\n",
    "│  └─ NO (CPU bound):                                                         │\n",
    "│      │                                                                      │\n",
    "│      └─ ❌ DON'T USE ASYNC ALONE                                            │\n",
    "│          • Use multiprocessing for CPU parallelism                          │\n",
    "│          • Use ProcessPoolExecutor                                          │\n",
    "│          • Consider async + multiprocessing hybrid                          │\n",
    "│                                                                             │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682d341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When NOT to use async - Examples\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# ❌ BAD: Using async for CPU-bound work\n",
    "async def bad_cpu_bound():\n",
    "    \"\"\"This does NOT benefit from async!\"\"\"\n",
    "    # CPU work blocks the event loop\n",
    "    result = sum(i * i for i in range(1000000))\n",
    "    return result\n",
    "\n",
    "# ✅ GOOD: Use process pool for CPU-bound work\n",
    "# NOTE: In production scripts, use ProcessPoolExecutor with if __name__ == \"__main__\" guard\n",
    "# Here we use ThreadPoolExecutor for demonstration (works in notebooks)\n",
    "def cpu_work(n: int) -> int:\n",
    "    \"\"\"CPU-bound function.\"\"\"\n",
    "    return sum(i * i for i in range(n))\n",
    "\n",
    "async def good_cpu_bound():\n",
    "    \"\"\"Offload CPU work to thread/process pool.\"\"\"\n",
    "    loop = asyncio.get_running_loop()\n",
    "    \n",
    "    # Using ThreadPoolExecutor for notebook compatibility\n",
    "    # In production: use ProcessPoolExecutor for true parallelism\n",
    "    with ThreadPoolExecutor() as pool:\n",
    "        result = await loop.run_in_executor(pool, cpu_work, 1000000)\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"CPU-bound work patterns demonstrated\")\n",
    "print(\"\\nFor CPU-bound work, prefer:\")\n",
    "print(\"  1. multiprocessing.Pool (with if __name__ == '__main__' guard)\")\n",
    "print(\"  2. concurrent.futures.ProcessPoolExecutor (same guard needed)\")\n",
    "print(\"  3. Libraries like Dask, Ray for distributed computing\")\n",
    "print(\"\\nNote: ProcessPoolExecutor requires picklable functions,\")\n",
    "print(\"      which doesn't work directly in notebooks on Windows.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98da04",
   "metadata": {},
   "source": [
    "### Cases Where Sync is Preferred\n",
    "\n",
    "| Scenario | Why Sync is Better |\n",
    "|----------|--------------------|\n",
    "| Simple scripts | Async adds complexity without benefit |\n",
    "| CPU-bound processing | Async doesn't parallelize CPU work |\n",
    "| Single database query | No concurrency to exploit |\n",
    "| Legacy codebase | Mixing sync/async adds complexity |\n",
    "| Libraries lack async support | Wrapping sync code defeats purpose |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2b6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid approach: Async for I/O, ThreadPool for CPU simulation\n",
    "# NOTE: In production, use ProcessPoolExecutor with proper __main__ guard for true CPU parallelism\n",
    "\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import List\n",
    "\n",
    "def process_image(image_data: bytes) -> bytes:\n",
    "    \"\"\"CPU-intensive image processing (simulated).\"\"\"\n",
    "    import time\n",
    "    time.sleep(0.1)  # Simulate work\n",
    "    return b\"processed_\" + image_data[:10]\n",
    "\n",
    "async def fetch_image(url: str) -> bytes:\n",
    "    \"\"\"I/O-bound: Fetch image from URL.\"\"\"\n",
    "    await asyncio.sleep(0.05)  # Simulate network I/O\n",
    "    return f\"image_data_from_{url}\".encode()\n",
    "\n",
    "async def process_images_hybrid(urls: List[str]) -> List[bytes]:\n",
    "    \"\"\"Hybrid approach: async for I/O, thread pool for CPU simulation.\"\"\"\n",
    "    loop = asyncio.get_running_loop()\n",
    "    \n",
    "    # Step 1: Fetch all images concurrently (I/O bound)\n",
    "    print(\"Fetching images concurrently...\")\n",
    "    images = await asyncio.gather(*[fetch_image(url) for url in urls])\n",
    "    \n",
    "    # Step 2: Process images in parallel\n",
    "    # Using ThreadPoolExecutor for notebook compatibility\n",
    "    # In production with real CPU work: use ProcessPoolExecutor\n",
    "    print(\"Processing images in parallel...\")\n",
    "    with ThreadPoolExecutor(max_workers=4) as pool:\n",
    "        processed = await asyncio.gather(\n",
    "            *[loop.run_in_executor(pool, process_image, img) for img in images]\n",
    "        )\n",
    "    \n",
    "    return list(processed)\n",
    "\n",
    "# Demonstrate hybrid approach\n",
    "urls = [f\"https://example.com/image_{i}.jpg\" for i in range(5)]\n",
    "results = await process_images_hybrid(urls)\n",
    "print(f\"\\nProcessed {len(results)} images\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"  Image {i}: {result.decode()[:30]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9d4ff9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Async Programming Best Practices\n",
    "\n",
    "### Do's ✅\n",
    "\n",
    "1. **Use async for I/O-bound operations**: Database queries, HTTP requests, file I/O\n",
    "2. **Use `asyncio.gather` for concurrent operations**: When you need all results\n",
    "3. **Use `asyncio.TaskGroup` (3.11+)**: For structured concurrency with proper cleanup\n",
    "4. **Handle `CancelledError` properly**: Always re-raise after cleanup\n",
    "5. **Use connection pools**: For databases and HTTP clients\n",
    "6. **Test with pytest-asyncio**: Use proper async testing patterns\n",
    "\n",
    "### Don'ts ❌\n",
    "\n",
    "1. **Don't block the event loop**: No `time.sleep()`, no synchronous I/O\n",
    "2. **Don't forget to await**: Unawaited coroutines don't execute\n",
    "3. **Don't use async for CPU-bound work**: Use multiprocessing instead\n",
    "4. **Don't create tasks without tracking**: Leads to memory leaks\n",
    "5. **Don't mix sync and async carelessly**: Leads to blocking issues\n",
    "\n",
    "### Performance Tips 🚀\n",
    "\n",
    "1. **Batch database operations**: Use bulk inserts/updates\n",
    "2. **Use connection pooling**: Avoid connection overhead\n",
    "3. **Limit concurrency**: Use `asyncio.Semaphore` to prevent overwhelming resources\n",
    "4. **Profile your code**: Use `py-spy` or `scalene` for async profiling\n",
    "5. **Consider uvloop**: Drop-in replacement for faster event loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f16ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final example: Production-ready async service pattern\n",
    "\n",
    "import asyncio\n",
    "from typing import List, Optional\n",
    "from dataclasses import dataclass\n",
    "from contextlib import asynccontextmanager\n",
    "\n",
    "@dataclass\n",
    "class User:\n",
    "    id: int\n",
    "    name: str\n",
    "    email: str\n",
    "\n",
    "class UserService:\n",
    "    \"\"\"Production-ready async user service.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_concurrent: int = 10):\n",
    "        self._semaphore = asyncio.Semaphore(max_concurrent)\n",
    "        self._cache: dict[int, User] = {}\n",
    "    \n",
    "    async def get_user(self, user_id: int) -> Optional[User]:\n",
    "        \"\"\"Get user with caching and concurrency control.\"\"\"\n",
    "        # Check cache first\n",
    "        if user_id in self._cache:\n",
    "            return self._cache[user_id]\n",
    "        \n",
    "        # Limit concurrent database calls\n",
    "        async with self._semaphore:\n",
    "            # Double-check cache (another task might have populated it)\n",
    "            if user_id in self._cache:\n",
    "                return self._cache[user_id]\n",
    "            \n",
    "            # Fetch from database\n",
    "            user = await self._fetch_from_db(user_id)\n",
    "            if user:\n",
    "                self._cache[user_id] = user\n",
    "            return user\n",
    "    \n",
    "    async def get_users(self, user_ids: List[int]) -> List[User]:\n",
    "        \"\"\"Get multiple users concurrently.\"\"\"\n",
    "        tasks = [self.get_user(uid) for uid in user_ids]\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        \n",
    "        users = []\n",
    "        for result in results:\n",
    "            if isinstance(result, User):\n",
    "                users.append(result)\n",
    "            elif isinstance(result, Exception):\n",
    "                # Log error but continue\n",
    "                print(f\"Error fetching user: {result}\")\n",
    "        \n",
    "        return users\n",
    "    \n",
    "    async def _fetch_from_db(self, user_id: int) -> Optional[User]:\n",
    "        \"\"\"Simulate database fetch.\"\"\"\n",
    "        await asyncio.sleep(0.1)  # Simulate DB query\n",
    "        return User(id=user_id, name=f\"User_{user_id}\", email=f\"user{user_id}@example.com\")\n",
    "\n",
    "# Demonstrate the service\n",
    "service = UserService(max_concurrent=5)\n",
    "\n",
    "print(\"Fetching users with production patterns:\")\n",
    "users = await service.get_users([1, 2, 3, 4, 5])\n",
    "for user in users:\n",
    "    print(f\"  {user}\")\n",
    "\n",
    "print(\"\\n✅ Async programming notebook complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
