{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77bb0f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.9\n",
      "NumPy: 1.26.2\n",
      "Plotly: 6.5.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Plotly notebooks: force the Jupyter renderer.\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"Plotly:\", plotly.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed4acba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_ar(\n",
    "    phi: np.ndarray,\n",
    "    *,\n",
    "    c: float = 0.0,\n",
    "    sigma: float = 1.0,\n",
    "    n: int = 600,\n",
    "    burn_in: int = 200,\n",
    "    seed: int = 42,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Simulate a univariate AR(p): y_t = c + sum_i phi_i y_{t-i} + eps_t.\"\"\"\n",
    "    phi = np.asarray(phi, dtype=float)\n",
    "    p = int(phi.size)\n",
    "    if p < 1:\n",
    "        raise ValueError(\"phi must have length >= 1\")\n",
    "    if n <= 0:\n",
    "        raise ValueError(\"n must be positive\")\n",
    "    if burn_in < 0:\n",
    "        raise ValueError(\"burn_in must be >= 0\")\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    eps = rng.normal(loc=0.0, scale=sigma, size=n + burn_in)\n",
    "    y = np.zeros(n + burn_in, dtype=float)\n",
    "\n",
    "    # Start at t=p so y_{t-i} exists.\n",
    "    for t in range(p, n + burn_in):\n",
    "        lags = y[t - 1 : t - p - 1 : -1]  # [y_{t-1}, ..., y_{t-p}]\n",
    "        y[t] = c + float(phi @ lags) + eps[t]\n",
    "\n",
    "    return y[burn_in:]\n",
    "\n",
    "\n",
    "def make_lagged_matrix(y: np.ndarray, p: int, *, include_intercept: bool = True):\n",
    "    \"\"\"Build (X, y_target) for AR(p) regression.\n",
    "\n",
    "    For t = p..T-1:\n",
    "      y_target[t-p] = y[t]\n",
    "      X[t-p] = [1, y[t-1], ..., y[t-p]]\n",
    "    \"\"\"\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    p = int(p)\n",
    "    if p < 1:\n",
    "        raise ValueError(\"p must be >= 1\")\n",
    "    if y.ndim != 1:\n",
    "        raise ValueError(\"y must be 1D\")\n",
    "    n = y.size\n",
    "    if n <= p:\n",
    "        raise ValueError(f\"Need at least p+1 points; got n={n}, p={p}\")\n",
    "\n",
    "    # Columns are lag-1, lag-2, ..., lag-p.\n",
    "    lag_cols = [y[p - i : n - i] for i in range(1, p + 1)]\n",
    "    X = np.column_stack(lag_cols)\n",
    "    if include_intercept:\n",
    "        X = np.column_stack([np.ones(n - p, dtype=float), X])\n",
    "    y_target = y[p:]\n",
    "    return X, y_target\n",
    "\n",
    "\n",
    "def fit_ar_ols(y: np.ndarray, p: int, *, include_intercept: bool = True):\n",
    "    \"\"\"Fit AR(p) by OLS and return a small result dict.\"\"\"\n",
    "    X, y_target = make_lagged_matrix(y, p, include_intercept=include_intercept)\n",
    "    beta, *_ = np.linalg.lstsq(X, y_target, rcond=None)\n",
    "    y_hat_target = X @ beta\n",
    "    resid = y_target - y_hat_target\n",
    "    rss = float(resid @ resid)\n",
    "    n_eff = int(y_target.size)\n",
    "    k = int(X.shape[1])\n",
    "    sigma2 = rss / n_eff\n",
    "\n",
    "    y_hat = np.full_like(np.asarray(y, dtype=float), np.nan)\n",
    "    y_hat[p:] = y_hat_target\n",
    "\n",
    "    return {\n",
    "        \"p\": int(p),\n",
    "        \"include_intercept\": bool(include_intercept),\n",
    "        \"beta\": beta,\n",
    "        \"y_hat\": y_hat,\n",
    "        \"resid\": resid,\n",
    "        \"rss\": rss,\n",
    "        \"sigma2\": sigma2,\n",
    "        \"n_eff\": n_eff,\n",
    "        \"k\": k,\n",
    "    }\n",
    "\n",
    "\n",
    "def forecast_ar(beta: np.ndarray, y_history: np.ndarray, p: int, *, steps: int, include_intercept: bool = True):\n",
    "    \"\"\"Iterative multi-step forecast using the model's own predictions.\"\"\"\n",
    "    beta = np.asarray(beta, dtype=float)\n",
    "    y_hist = list(np.asarray(y_history, dtype=float).tolist())\n",
    "    p = int(p)\n",
    "    if steps < 1:\n",
    "        return np.array([], dtype=float)\n",
    "    if len(y_hist) < p:\n",
    "        raise ValueError(f\"Need at least p history points; got {len(y_hist)}\")\n",
    "\n",
    "    out = []\n",
    "    for _ in range(int(steps)):\n",
    "        lags = np.array(y_hist[-1 : -p - 1 : -1], dtype=float)\n",
    "        x = np.concatenate(([1.0], lags)) if include_intercept else lags\n",
    "        y_next = float(x @ beta)\n",
    "        y_hist.append(y_next)\n",
    "        out.append(y_next)\n",
    "    return np.array(out, dtype=float)\n",
    "\n",
    "\n",
    "def aic_bic_from_rss(rss: float, n: int, k: int):\n",
    "    \"\"\"AIC/BIC up to additive constants (sufficient for comparing p).\"\"\"\n",
    "    rss = float(rss)\n",
    "    n = int(n)\n",
    "    k = int(k)\n",
    "    if n <= 0:\n",
    "        raise ValueError(\"n must be positive\")\n",
    "    if rss <= 0:\n",
    "        rss = 1e-12\n",
    "    aic = 2 * k + n * np.log(rss / n)\n",
    "    bic = k * np.log(n) + n * np.log(rss / n)\n",
    "    return float(aic), float(bic)\n",
    "\n",
    "\n",
    "def ar_stationary(phi: np.ndarray):\n",
    "    \"\"\"Check covariance-stationarity for AR(p) via characteristic roots.\"\"\"\n",
    "    phi = np.asarray(phi, dtype=float)\n",
    "    coeffs = np.concatenate(([1.0], -phi))  # 1 - phi1 z - ... - phip z^p\n",
    "    roots = np.roots(coeffs)\n",
    "    return bool(np.all(np.abs(roots) > 1.0)), roots\n",
    "\n",
    "\n",
    "def acf(x: np.ndarray, nlags: int = 30):\n",
    "    \"\"\"Autocorrelation function for lags 0..nlags (simple, biased estimator).\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    x = x - np.mean(x)\n",
    "    denom = float(x @ x)\n",
    "    out = np.empty(int(nlags) + 1, dtype=float)\n",
    "    out[0] = 1.0\n",
    "    for k in range(1, int(nlags) + 1):\n",
    "        out[k] = float(x[:-k] @ x[k:]) / denom\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d668fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stationary (true process)? False\n",
      "Characteristic roots: [0.631+0.j    0.01 +0.488j 0.01 -0.488j]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 0 is different from 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStationary (true process)?\u001b[39m\u001b[33m\"\u001b[39m, is_stat)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCharacteristic roots:\u001b[39m\u001b[33m\"\u001b[39m, np.round(roots, \u001b[32m3\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m y = \u001b[43msimulate_ar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphi_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mc_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m=\u001b[49m\u001b[43msigma_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m700\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mburn_in\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m t = np.arange(y.size)\n\u001b[32m     13\u001b[39m train_n = \u001b[32m520\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36msimulate_ar\u001b[39m\u001b[34m(phi, c, sigma, n, burn_in, seed)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(p, n + burn_in):\n\u001b[32m     26\u001b[39m     lags = y[t - \u001b[32m1\u001b[39m : t - p - \u001b[32m1\u001b[39m : -\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# [y_{t-1}, ..., y_{t-p}]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     y[t] = c + \u001b[38;5;28mfloat\u001b[39m(\u001b[43mphi\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mlags\u001b[49m) + eps[t]\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y[burn_in:]\n",
      "\u001b[31mValueError\u001b[39m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 0 is different from 3)"
     ]
    }
   ],
   "source": [
    "# Ground-truth AR(3)\n",
    "phi_true = np.array([0.65, -0.25, 0.15])\n",
    "c_true = 0.2\n",
    "sigma_true = 0.7\n",
    "\n",
    "is_stat, roots = ar_stationary(phi_true)\n",
    "print(\"Stationary (true process)?\", is_stat)\n",
    "print(\"Characteristic roots:\", np.round(roots, 3))\n",
    "\n",
    "y = simulate_ar(phi_true, c=c_true, sigma=sigma_true, n=700, burn_in=300, seed=7)\n",
    "t = np.arange(y.size)\n",
    "\n",
    "train_n = 520\n",
    "y_train = y[:train_n]\n",
    "y_test = y[train_n:]\n",
    "t_test = t[train_n:]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=t, y=y, mode=\"lines\", name=\"series\"))\n",
    "fig.add_vline(x=train_n, line_dash=\"dash\", line_color=\"black\")\n",
    "fig.update_layout(title=\"Synthetic AR(3) series (train/test split)\", xaxis_title=\"t\", yaxis_title=\"y\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2b8f3f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m mse_dyn = []\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m ps:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     fit = fit_ar_ols(\u001b[43my_train\u001b[49m, p, include_intercept=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     11\u001b[39m     aic, bic = aic_bic_from_rss(fit[\u001b[33m\"\u001b[39m\u001b[33mrss\u001b[39m\u001b[33m\"\u001b[39m], fit[\u001b[33m\"\u001b[39m\u001b[33mn_eff\u001b[39m\u001b[33m\"\u001b[39m], fit[\u001b[33m\"\u001b[39m\u001b[33mk\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     12\u001b[39m     aics.append(aic)\n",
      "\u001b[31mNameError\u001b[39m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "P_MAX = 15\n",
    "\n",
    "ps = np.arange(1, P_MAX + 1)\n",
    "aics = []\n",
    "bics = []\n",
    "rss_list = []\n",
    "mse_dyn = []\n",
    "\n",
    "for p in ps:\n",
    "    fit = fit_ar_ols(y_train, p, include_intercept=True)\n",
    "    aic, bic = aic_bic_from_rss(fit[\"rss\"], fit[\"n_eff\"], fit[\"k\"])\n",
    "    aics.append(aic)\n",
    "    bics.append(bic)\n",
    "    rss_list.append(fit[\"rss\"])\n",
    "\n",
    "    # (Optional sanity metric) dynamic multi-step MSE on the test horizon\n",
    "    y_fc = forecast_ar(fit[\"beta\"], y_train, p, steps=y_test.size, include_intercept=True)\n",
    "    mse_dyn.append(float(np.mean((y_test - y_fc) ** 2)))\n",
    "\n",
    "aics = np.array(aics)\n",
    "bics = np.array(bics)\n",
    "mse_dyn = np.array(mse_dyn)\n",
    "\n",
    "p_best_aic = int(ps[np.argmin(aics)])\n",
    "p_best_bic = int(ps[np.argmin(bics)])\n",
    "print(\"Best p by AIC:\", p_best_aic)\n",
    "print(\"Best p by BIC:\", p_best_bic)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=[\"AIC (lower is better)\", \"BIC (lower is better)\"])\n",
    "fig.add_trace(go.Scatter(x=ps, y=aics, mode=\"lines+markers\", name=\"AIC\"), row=1, col=1)\n",
    "fig.add_vline(x=p_best_aic, line_dash=\"dash\", line_color=\"#1f77b4\", row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=ps, y=bics, mode=\"lines+markers\", name=\"BIC\"), row=1, col=2)\n",
    "fig.add_vline(x=p_best_bic, line_dash=\"dash\", line_color=\"#1f77b4\", row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"p\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"p\", row=1, col=2)\n",
    "fig.update_layout(title=\"Lag-order selection on training data\")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ps, y=mse_dyn, mode=\"lines+markers\", name=\"Dynamic forecast MSE\"))\n",
    "fig.update_layout(title=\"Forecast error vs lag order (dynamic multi-step)\", xaxis_title=\"p\", yaxis_title=\"MSE\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc7c625",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m P_SHOW = [\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m6\u001b[39m, \u001b[32m12\u001b[39m]\n\u001b[32m      3\u001b[39m fig = go.Figure()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m fig.add_trace(go.Scatter(x=\u001b[43mt_test\u001b[49m, y=y_test, mode=\u001b[33m\"\u001b[39m\u001b[33mlines\u001b[39m\u001b[33m\"\u001b[39m, name=\u001b[33m\"\u001b[39m\u001b[33mactual (test)\u001b[39m\u001b[33m\"\u001b[39m, line=\u001b[38;5;28mdict\u001b[39m(color=\u001b[33m\"\u001b[39m\u001b[33mblack\u001b[39m\u001b[33m\"\u001b[39m)))\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m P_SHOW:\n\u001b[32m      7\u001b[39m     fit = fit_ar_ols(y_train, p, include_intercept=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 't_test' is not defined"
     ]
    }
   ],
   "source": [
    "P_SHOW = [1, 2, 3, 6, 12]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=t_test, y=y_test, mode=\"lines\", name=\"actual (test)\", line=dict(color=\"black\")))\n",
    "\n",
    "for p in P_SHOW:\n",
    "    fit = fit_ar_ols(y_train, p, include_intercept=True)\n",
    "    y_fc = forecast_ar(fit[\"beta\"], y_train, p, steps=y_test.size, include_intercept=True)\n",
    "    mse = float(np.mean((y_test - y_fc) ** 2))\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=t_test,\n",
    "            y=y_fc,\n",
    "            mode=\"lines\",\n",
    "            name=f\"AR({p}) forecast (MSE={mse:.3f})\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Effect of lag order: multi-step forecasts on the same test window\",\n",
    "    xaxis_title=\"t\",\n",
    "    yaxis_title=\"y\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a88d84f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p_best_bic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m p_best = \u001b[43mp_best_bic\u001b[49m\n\u001b[32m      2\u001b[39m fit_best = fit_ar_ols(y_train, p_best, include_intercept=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# One-step predictions on the full series using true lags.\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'p_best_bic' is not defined"
     ]
    }
   ],
   "source": [
    "p_best = p_best_bic\n",
    "fit_best = fit_ar_ols(y_train, p_best, include_intercept=True)\n",
    "\n",
    "# One-step predictions on the full series using true lags.\n",
    "X_full, y_target_full = make_lagged_matrix(y, p_best, include_intercept=True)\n",
    "y_hat_target_full = X_full @ fit_best[\"beta\"]\n",
    "y_hat_full = np.full_like(y, np.nan)\n",
    "y_hat_full[p_best:] = y_hat_target_full\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=t, y=y, mode=\"lines\", name=\"actual\", line=dict(color=\"black\")))\n",
    "fig.add_trace(go.Scatter(x=t, y=y_hat_full, mode=\"lines\", name=f\"AR({p_best}) one-step prediction\"))\n",
    "fig.add_vline(x=train_n, line_dash=\"dash\", line_color=\"black\")\n",
    "fig.update_layout(title=\"Prediction vs actual (one-step ahead)\", xaxis_title=\"t\", yaxis_title=\"y\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4634ffb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit_best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Residuals from the training fit (one-step ahead on training window)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m resid = \u001b[43mfit_best\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mresid\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      3\u001b[39m fitted = y_train[p_best:] - resid\n\u001b[32m      5\u001b[39m res_acf = acf(resid, nlags=\u001b[32m30\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'fit_best' is not defined"
     ]
    }
   ],
   "source": [
    "# Residuals from the training fit (one-step ahead on training window)\n",
    "resid = fit_best[\"resid\"]\n",
    "fitted = y_train[p_best:] - resid\n",
    "\n",
    "res_acf = acf(resid, nlags=30)\n",
    "lags = np.arange(res_acf.size)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=2,\n",
    "    subplot_titles=[\n",
    "        \"Residuals over time (train)\",\n",
    "        \"Residual histogram (train)\",\n",
    "        \"Residual ACF (train)\",\n",
    "        \"Residuals vs fitted (train)\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(resid.size), y=resid, mode=\"lines\", name=\"residual\"),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_hline(y=0, line_color=\"gray\", line_width=1, row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Histogram(x=resid, nbinsx=40, name=\"residuals\"), row=1, col=2)\n",
    "\n",
    "fig.add_trace(go.Bar(x=lags, y=res_acf, name=\"ACF\"), row=2, col=1)\n",
    "fig.add_hline(y=0, line_color=\"gray\", line_width=1, row=2, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=fitted, y=resid, mode=\"markers\", name=\"resid vs fitted\", opacity=0.6), row=2, col=2)\n",
    "fig.add_hline(y=0, line_color=\"gray\", line_width=1, row=2, col=2)\n",
    "\n",
    "fig.update_layout(title=f\"Residual diagnostics for AR({p_best}) (fit on training)\")\n",
    "fig.update_xaxes(title_text=\"index\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"residual\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"lag\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"fitted\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"residual\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"count\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"ACF\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"residual\", row=2, col=2)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3b6da1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 0 is different from 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m y_stat = \u001b[43msimulate_ar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mburn_in\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m y_nonstat = simulate_ar(np.array([\u001b[32m1.02\u001b[39m]), c=\u001b[32m0.0\u001b[39m, sigma=\u001b[32m1.0\u001b[39m, n=\u001b[32m250\u001b[39m, burn_in=\u001b[32m200\u001b[39m, seed=\u001b[32m0\u001b[39m)\n\u001b[32m      4\u001b[39m fig = make_subplots(rows=\u001b[32m2\u001b[39m, cols=\u001b[32m1\u001b[39m, shared_xaxes=\u001b[38;5;28;01mTrue\u001b[39;00m, subplot_titles=[\u001b[33m\"\u001b[39m\u001b[33mStationary AR(1): φ=0.7\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mNon-stationary AR(1): φ=1.02\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36msimulate_ar\u001b[39m\u001b[34m(phi, c, sigma, n, burn_in, seed)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(p, n + burn_in):\n\u001b[32m     26\u001b[39m     lags = y[t - \u001b[32m1\u001b[39m : t - p - \u001b[32m1\u001b[39m : -\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# [y_{t-1}, ..., y_{t-p}]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     y[t] = c + \u001b[38;5;28mfloat\u001b[39m(\u001b[43mphi\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mlags\u001b[49m) + eps[t]\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y[burn_in:]\n",
      "\u001b[31mValueError\u001b[39m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 0 is different from 1)"
     ]
    }
   ],
   "source": [
    "y_stat = simulate_ar(np.array([0.7]), c=0.0, sigma=1.0, n=250, burn_in=200, seed=0)\n",
    "y_nonstat = simulate_ar(np.array([1.02]), c=0.0, sigma=1.0, n=250, burn_in=200, seed=0)\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, subplot_titles=[\"Stationary AR(1): φ=0.7\", \"Non-stationary AR(1): φ=1.02\"])\n",
    "fig.add_trace(go.Scatter(y=y_stat, mode=\"lines\", name=\"φ=0.7\"), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(y=y_nonstat, mode=\"lines\", name=\"φ=1.02\"), row=2, col=1)\n",
    "fig.update_layout(title=\"Stationarity matters: |φ|<1 vs |φ|>1\", xaxis_title=\"t\", yaxis_title=\"y\")\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}