{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c5b03b1",
   "metadata": {},
   "source": [
    "# DBSCAN — Density-Based Clustering (Finding crowds instead of shapes)\n",
    "\n",
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a clustering algorithm that **looks for crowds**: regions where points are packed together, separated by regions that are sparse.\n",
    "\n",
    "That density-first view gives you two superpowers:\n",
    "\n",
    "- **arbitrary shapes** (clusters don’t have to be “ball-shaped”)\n",
    "- **noise detection** (points that don’t belong anywhere can be labeled as noise)\n",
    "\n",
    "The cost: DBSCAN is sensitive to a distance scale (`eps`) and can struggle when clusters have **very different densities**.\n",
    "\n",
    "DBSCAN is also commonly used *after* dimensionality reduction (PCA/UMAP/t-SNE): first embed to a space where distance is meaningful, then run a density-based clusterer.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "By the end you should be able to:\n",
    "\n",
    "- explain DBSCAN as “finding crowds instead of shapes”\n",
    "- define ε-neighborhoods and distinguish **core / border / noise** points\n",
    "- describe density reachability and the **cluster expansion** process\n",
    "- see (with Plotly) how `eps` and `min_samples` change the result\n",
    "- compare DBSCAN with **k-means** and **HDBSCAN** (and know when to use which)\n",
    "\n",
    "---\n",
    "\n",
    "## Notation (quick)\n",
    "\n",
    "- Dataset: `X = {x1, …, xn}` with `xi ∈ R^d`\n",
    "- Distance metric: `dist(x, z)` (we’ll use Euclidean unless stated)\n",
    "- ε-neighborhood of point `p`:\n",
    "\n",
    "  `Nε(p) = { q ∈ X : dist(p, q) ≤ ε }`\n",
    "\n",
    "- `min_samples`: minimum number of points in `Nε(p)` (usually counting `p` itself) for `p` to be a **core** point\n",
    "- DBSCAN labels:\n",
    "  - cluster IDs: `0, 1, 2, ...`\n",
    "  - noise: `-1` (in `scikit-learn`)\n",
    "\n",
    "---\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "1. Intuition: finding crowds instead of shapes\n",
    "2. Density concepts: ε-neighborhood, core/border/noise\n",
    "3. Algorithm steps: density reachability + cluster expansion\n",
    "4. DBSCAN from scratch (NumPy)\n",
    "5. Plotly lab: effect of `eps` and `min_samples`\n",
    "6. Plotly lab: noise detection + choosing `eps`\n",
    "7. Comparison: DBSCAN vs k-means vs HDBSCAN\n",
    "8. `scikit-learn` DBSCAN: practical parameter map\n",
    "9. Practical checklist + pitfalls\n",
    "10. Exercises\n",
    "11. References\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a85e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "from plotly.colors import qualitative\n",
    "\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.datasets import make_moons, make_blobs\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9c1c2e",
   "metadata": {},
   "source": [
    "## 1) Intuition: “finding crowds instead of shapes”\n",
    "\n",
    "Many clustering algorithms start by assuming a **shape**.\n",
    "\n",
    "- k-means assumes clusters look like **spheres** (in your feature space): “assign points to the closest center.”\n",
    "- DBSCAN assumes clusters look like **crowds**: “a cluster is where you can keep walking from point to nearby point without ever crossing a sparse desert.”\n",
    "\n",
    "That’s why DBSCAN can discover non-convex clusters (like two interleaving moons) and also label outliers as *noise*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a9d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A classic non-convex dataset + some uniform noise\n",
    "X_moons, _ = make_moons(n_samples=450, noise=0.06, random_state=42)\n",
    "\n",
    "noise = rng.uniform(\n",
    "    low=X_moons.min(axis=0) - 0.6,\n",
    "    high=X_moons.max(axis=0) + 0.6,\n",
    "    size=(60, 2),\n",
    ")\n",
    "X = np.vstack([X_moons, noise])\n",
    "\n",
    "fig = px.scatter(x=X[:, 0], y=X[:, 1], title=\"Two moons + uniform noise (no clustering yet)\")\n",
    "fig.update_traces(marker=dict(size=6, opacity=0.85))\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2f4b9d",
   "metadata": {},
   "source": [
    "## 2) Density concepts: ε-neighborhood, core/border/noise\n",
    "\n",
    "DBSCAN is built from one local question:\n",
    "\n",
    "> “Around this point, is it crowded?”\n",
    "\n",
    "### ε-neighborhood\n",
    "\n",
    "Pick a radius `ε` (epsilon). The ε-neighborhood of a point `p` is all points within distance `ε`.\n",
    "\n",
    "### Core / border / noise points\n",
    "\n",
    "Given `ε` and `min_samples`:\n",
    "\n",
    "- **Core** point: has at least `min_samples` points in its ε-neighborhood.\n",
    "- **Border** point: not core, but lies inside the ε-neighborhood of a core point.\n",
    "- **Noise** point: neither core nor border.\n",
    "\n",
    "Let’s visualize a single ε-neighborhood as a circle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fef7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle_xy(center_xy: np.ndarray, radius: float, n: int = 200) -> tuple[np.ndarray, np.ndarray]:\n",
    "    t = np.linspace(0, 2 * np.pi, n)\n",
    "    cx, cy = center_xy\n",
    "    return cx + radius * np.cos(t), cy + radius * np.sin(t)\n",
    "\n",
    "\n",
    "eps_demo = 0.25\n",
    "p_idx = 25\n",
    "p = X[p_idx]\n",
    "\n",
    "dists = np.linalg.norm(X - p, axis=1)\n",
    "nbr_mask = dists <= eps_demo\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# All points (faded)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=X[:, 0],\n",
    "        y=X[:, 1],\n",
    "        mode=\"markers\",\n",
    "        name=\"all points\",\n",
    "        marker=dict(size=6, color=\"lightgray\", opacity=0.5),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Neighbors within eps\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=X[nbr_mask, 0],\n",
    "        y=X[nbr_mask, 1],\n",
    "        mode=\"markers\",\n",
    "        name=f\"Nε(p) (ε={eps_demo})\",\n",
    "        marker=dict(size=7, color=qualitative.Set2[1], opacity=0.9),\n",
    "    )\n",
    ")\n",
    "\n",
    "# The chosen point p\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[p[0]],\n",
    "        y=[p[1]],\n",
    "        mode=\"markers\",\n",
    "        name=\"p\",\n",
    "        marker=dict(size=11, color=qualitative.Set2[0], symbol=\"star\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Circle\n",
    "cx, cy = circle_xy(p, eps_demo)\n",
    "fig.add_trace(go.Scatter(x=cx, y=cy, mode=\"lines\", name=\"ε-ball\", line=dict(color=\"black\", width=1)))\n",
    "\n",
    "fig.update_layout(title=\"An ε-neighborhood is a circle around p\", legend=dict(orientation=\"h\"))\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45df2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_types(X: np.ndarray, eps: float, min_samples: int) -> np.ndarray:\n",
    "    \"\"\"Return an array of strings: 'core' / 'border' / 'noise' for each point.\"\"\"\n",
    "    X = np.asarray(X)\n",
    "    eps2 = float(eps) ** 2\n",
    "\n",
    "    sq = np.sum(X**2, axis=1, keepdims=True)\n",
    "    sq_dists = sq + sq.T - 2 * (X @ X.T)\n",
    "    sq_dists = np.maximum(sq_dists, 0.0)\n",
    "\n",
    "    nbr_counts = np.sum(sq_dists <= eps2, axis=1)\n",
    "    is_core = nbr_counts >= min_samples\n",
    "\n",
    "    # border: non-core point that is in the eps-neighborhood of at least one core point\n",
    "    is_border = (~is_core) & (np.any((sq_dists <= eps2) & is_core[None, :], axis=1))\n",
    "    is_noise = (~is_core) & (~is_border)\n",
    "\n",
    "    types = np.empty(X.shape[0], dtype=object)\n",
    "    types[is_core] = \"core\"\n",
    "    types[is_border] = \"border\"\n",
    "    types[is_noise] = \"noise\"\n",
    "    return types\n",
    "\n",
    "\n",
    "eps_demo = 0.25\n",
    "min_samples_demo = 6\n",
    "types = point_types(X, eps=eps_demo, min_samples=min_samples_demo)\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=X[:, 0],\n",
    "    y=X[:, 1],\n",
    "    color=types,\n",
    "    category_orders={\"color\": [\"core\", \"border\", \"noise\"]},\n",
    "    color_discrete_map={\"core\": qualitative.Set2[0], \"border\": qualitative.Set2[1], \"noise\": \"lightgray\"},\n",
    "    title=f\"Core / border / noise given ε={eps_demo}, min_samples={min_samples_demo}\",\n",
    ")\n",
    "fig.update_traces(marker=dict(size=6, opacity=0.9))\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e6e15b",
   "metadata": {},
   "source": [
    "## 3) Algorithm steps: density reachability + cluster expansion\n",
    "\n",
    "DBSCAN turns local density into clusters using **reachability**.\n",
    "\n",
    "### Density reachability\n",
    "\n",
    "- A point `q` is **directly density-reachable** from `p` if:\n",
    "  1) `q ∈ Nε(p)` and\n",
    "  2) `p` is a **core** point.\n",
    "\n",
    "- A point `q` is **density-reachable** from `p` if there exists a chain:\n",
    "\n",
    "  `p → p1 → p2 → ... → q`\n",
    "\n",
    "  where each step is directly density-reachable.\n",
    "\n",
    "Intuition: you can “walk” from `p` to `q` while always stepping inside ε-neighborhoods of **core** points.\n",
    "\n",
    "### Cluster expansion (the algorithmic idea)\n",
    "\n",
    "1. Pick an unvisited point.\n",
    "2. If it’s not core, it can’t start a cluster (it might later become a border point).\n",
    "3. If it **is** core, start a new cluster and grow it by repeatedly adding neighbors.\n",
    "\n",
    "You can think of this as BFS/DFS over a graph:\n",
    "\n",
    "- vertices are points\n",
    "- an edge exists if two points are within ε\n",
    "- but only **core** points are allowed to “expand” the frontier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b2c7a1",
   "metadata": {},
   "source": [
    "### Pseudocode (classic DBSCAN)\n",
    "\n",
    "```\n",
    "labels = UNASSIGNED\n",
    "cluster_id = 0\n",
    "\n",
    "for each point p:\n",
    "  if p is visited: continue\n",
    "  mark p visited\n",
    "  neighbors = Nε(p)\n",
    "  if |neighbors| < min_samples:\n",
    "    label p as NOISE   # might be relabeled later\n",
    "  else:\n",
    "    start new cluster C = cluster_id\n",
    "    expand(C, p, neighbors)\n",
    "    cluster_id += 1\n",
    "\n",
    "expand(C, p, neighbors):\n",
    "  label p as C\n",
    "  seed_set = neighbors\n",
    "  while seed_set not empty:\n",
    "    q = pop(seed_set)\n",
    "    if q not visited:\n",
    "      mark q visited\n",
    "      q_neighbors = Nε(q)\n",
    "      if |q_neighbors| >= min_samples:   # q is core\n",
    "        seed_set = seed_set ∪ q_neighbors\n",
    "    if q is UNASSIGNED or NOISE:\n",
    "      label q as C\n",
    "```\n",
    "\n",
    "Two small details to notice:\n",
    "\n",
    "- Border points can be labeled as noise *initially*, then later pulled into a cluster.\n",
    "- Border points that touch multiple clusters can be assigned depending on traversal order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a2c19",
   "metadata": {},
   "source": [
    "## 4) DBSCAN from scratch (NumPy)\n",
    "\n",
    "For learning, we’ll implement the algorithm with a simple (dense) distance matrix. This is **O(n²)** memory/time, which is fine for small demos.\n",
    "\n",
    "`scikit-learn` uses spatial indexing (KD-tree / ball tree) when possible for faster neighborhood queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb7f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan_from_scratch(X: np.ndarray, eps: float, min_samples: int) -> np.ndarray:\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    n = X.shape[0]\n",
    "\n",
    "    eps2 = float(eps) ** 2\n",
    "\n",
    "    # Squared Euclidean distance matrix via (x-y)^2 = x^2 + y^2 - 2 x·y\n",
    "    sq = np.sum(X**2, axis=1, keepdims=True)\n",
    "    sq_dists = sq + sq.T - 2 * (X @ X.T)\n",
    "    sq_dists = np.maximum(sq_dists, 0.0)\n",
    "\n",
    "    neighbors = [np.flatnonzero(sq_dists[i] <= eps2) for i in range(n)]\n",
    "    is_core = np.array([len(nbrs) >= min_samples for nbrs in neighbors], dtype=bool)\n",
    "\n",
    "    labels = np.full(n, -1, dtype=int)  # -1 = noise/unassigned\n",
    "    visited = np.zeros(n, dtype=bool)\n",
    "\n",
    "    cluster_id = 0\n",
    "\n",
    "    for p in range(n):\n",
    "        if visited[p]:\n",
    "            continue\n",
    "        visited[p] = True\n",
    "\n",
    "        if not is_core[p]:\n",
    "            continue\n",
    "\n",
    "        # Start a new cluster\n",
    "        labels[p] = cluster_id\n",
    "        seed_set = set(neighbors[p].tolist())\n",
    "        seed_set.discard(p)\n",
    "\n",
    "        while seed_set:\n",
    "            q = seed_set.pop()\n",
    "\n",
    "            if not visited[q]:\n",
    "                visited[q] = True\n",
    "                if is_core[q]:\n",
    "                    seed_set.update(neighbors[q].tolist())\n",
    "\n",
    "            # If q is unassigned/noise, assign it to this cluster\n",
    "            if labels[q] == -1:\n",
    "                labels[q] = cluster_id\n",
    "\n",
    "        cluster_id += 1\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def plot_clusters_2d(X: np.ndarray, labels: np.ndarray, title: str) -> go.Figure:\n",
    "    X = np.asarray(X)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    label_text = np.where(labels == -1, \"noise\", labels.astype(str))\n",
    "    fig = px.scatter(\n",
    "        x=X[:, 0],\n",
    "        y=X[:, 1],\n",
    "        color=label_text,\n",
    "        color_discrete_map={\"noise\": \"lightgray\"},\n",
    "        title=title,\n",
    "    )\n",
    "    fig.update_traces(marker=dict(size=6, opacity=0.9))\n",
    "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "    return fig\n",
    "\n",
    "\n",
    "eps = 0.25\n",
    "min_samples = 6\n",
    "\n",
    "labels_scratch = dbscan_from_scratch(X, eps=eps, min_samples=min_samples)\n",
    "labels_sklearn = DBSCAN(eps=eps, min_samples=min_samples).fit_predict(X)\n",
    "\n",
    "ari = adjusted_rand_score(labels_sklearn, labels_scratch)\n",
    "print(f\"Agreement with sklearn (ARI): {ari:.3f}\")\n",
    "\n",
    "plot_clusters_2d(X, labels_scratch, title=\"DBSCAN from scratch (NumPy)\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6c36ab",
   "metadata": {},
   "source": [
    "## 5) Plotly lab: effect of `eps` and `min_samples`\n",
    "\n",
    "DBSCAN has two knobs that shape everything:\n",
    "\n",
    "- `eps` (ε): how far you consider “nearby”\n",
    "- `min_samples`: how many neighbors you need to be a “crowd”\n",
    "\n",
    "If you remember one mental model:\n",
    "\n",
    "- **Increase `eps`** → neighborhoods connect more easily → clusters merge, less noise.\n",
    "- **Increase `min_samples`** → harder to be core → more noise, clusters can fragment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb2273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_labels(labels: np.ndarray) -> tuple[int, float]:\n",
    "    labels = np.asarray(labels)\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    noise_frac = float(np.mean(labels == -1))\n",
    "    return n_clusters, noise_frac\n",
    "\n",
    "\n",
    "eps_values = [0.18, 0.25, 0.35]\n",
    "min_samples_fixed = 6\n",
    "\n",
    "for eps in eps_values:\n",
    "    labels = DBSCAN(eps=eps, min_samples=min_samples_fixed).fit_predict(X)\n",
    "    n_clusters, noise_frac = describe_labels(labels)\n",
    "    title = f\"Vary ε: eps={eps}, min_samples={min_samples_fixed} | clusters={n_clusters}, noise={noise_frac:.1%}\"\n",
    "    plot_clusters_2d(X, labels, title=title).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b53f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_fixed = 0.25\n",
    "min_samples_values = [3, 6, 12]\n",
    "\n",
    "for m in min_samples_values:\n",
    "    labels = DBSCAN(eps=eps_fixed, min_samples=m).fit_predict(X)\n",
    "    n_clusters, noise_frac = describe_labels(labels)\n",
    "    title = f\"Vary min_samples: eps={eps_fixed}, min_samples={m} | clusters={n_clusters}, noise={noise_frac:.1%}\"\n",
    "    plot_clusters_2d(X, labels, title=title).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a3f26e",
   "metadata": {},
   "source": [
    "## 6) Plotly lab: noise detection + choosing `eps`\n",
    "\n",
    "DBSCAN’s noise label is often the feature you want the most.\n",
    "\n",
    "- It can act like a simple **outlier detector**.\n",
    "- It can keep a clustering result honest: “these points don’t really belong anywhere.”\n",
    "\n",
    "A common heuristic for choosing `eps` is the **k-distance plot**:\n",
    "\n",
    "1. Pick `k = min_samples`.\n",
    "2. For each point, compute the distance to its k-th nearest neighbor.\n",
    "3. Sort those distances; look for the “elbow”.\n",
    "\n",
    "The elbow is roughly where points transition from “in crowds” to “in sparse regions”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_distance_plot(X: np.ndarray, k: int) -> tuple[go.Figure, np.ndarray]:\n",
    "    nn = NearestNeighbors(n_neighbors=k)\n",
    "    nn.fit(X)\n",
    "    dists, _ = nn.kneighbors(X)\n",
    "    kth = np.sort(dists[:, -1])\n",
    "\n",
    "    fig = px.line(\n",
    "        y=kth,\n",
    "        title=f\"{k}-distance plot (sorted distances to the {k}th nearest neighbor)\",\n",
    "        labels={\"x\": \"points (sorted)\", \"y\": f\"distance to {k}th nearest neighbor\"},\n",
    "    )\n",
    "    return fig, kth\n",
    "\n",
    "\n",
    "k = 6\n",
    "fig, kth = k_distance_plot(X, k=k)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef99a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise detection demo: add a few extreme outliers\n",
    "outliers = rng.uniform(low=[-3.5, -3.5], high=[3.5, 3.5], size=(12, 2))\n",
    "X_out = np.vstack([X, outliers])\n",
    "\n",
    "eps = 0.25\n",
    "min_samples = 6\n",
    "labels = DBSCAN(eps=eps, min_samples=min_samples).fit_predict(X_out)\n",
    "\n",
    "n_clusters, noise_frac = describe_labels(labels)\n",
    "title = f\"DBSCAN noise detection | eps={eps}, min_samples={min_samples} | clusters={n_clusters}, noise={noise_frac:.1%}\"\n",
    "plot_clusters_2d(X_out, labels, title=title).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3a6d10",
   "metadata": {},
   "source": [
    "## 7) Comparison: DBSCAN vs k-means vs HDBSCAN\n",
    "\n",
    "A quick way to remember the tradeoffs:\n",
    "\n",
    "| Method | Needs `k`? | Finds non-convex shapes? | Labels noise? | Handles varying density well? |\n",
    "|---|---:|---:|---:|---:|\n",
    "| k-means | ✅ | ❌ | ❌ | ❌ |\n",
    "| DBSCAN | ❌ | ✅ | ✅ | ⚠️ (often struggles) |\n",
    "| HDBSCAN | ❌ | ✅ | ✅ | ✅ |\n",
    "\n",
    "- **k-means**: great for roughly spherical clusters; fast; but forces every point into a cluster.\n",
    "- **DBSCAN**: great when clusters are “dense blobs/curves” and you want noise detection.\n",
    "- **HDBSCAN**: like DBSCAN, but it builds a hierarchy over density scales and picks stable clusters — often better when density varies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a7c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same dataset, k-means vs DBSCAN\n",
    "labels_kmeans = KMeans(n_clusters=2, n_init=10, random_state=42).fit_predict(X)\n",
    "plot_clusters_2d(X, labels_kmeans, title=\"k-means (k=2) on two moons\").show()\n",
    "\n",
    "labels_db = DBSCAN(eps=0.25, min_samples=6).fit_predict(X)\n",
    "plot_clusters_2d(X, labels_db, title=\"DBSCAN on two moons (eps=0.25, min_samples=6)\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: HDBSCAN (not installed by default in many environments)\n",
    "try:\n",
    "    import hdbscan  # type: ignore\n",
    "except Exception:\n",
    "    hdbscan = None\n",
    "\n",
    "if hdbscan is None:\n",
    "    print(\n",
    "        \"HDBSCAN not installed. If you want to run this section locally, install with:\\n\"\n",
    "        \"  pip install hdbscan\\n\"\n",
    "        \"or (often easier):\\n\"\n",
    "        \"  conda install -c conda-forge hdbscan\"\n",
    "    )\n",
    "else:\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=20, min_samples=6)\n",
    "    labels_h = clusterer.fit_predict(X)\n",
    "    plot_clusters_2d(X, labels_h, title=\"HDBSCAN on two moons (auto density scale)\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e9bbdb",
   "metadata": {},
   "source": [
    "## 8) `scikit-learn` DBSCAN: practical parameter map\n",
    "\n",
    "Key parameters in `sklearn.cluster.DBSCAN`:\n",
    "\n",
    "- `eps`: distance threshold (your most important knob)\n",
    "- `min_samples`: how “crowded” you require a core point to be\n",
    "- `metric`: distance metric (`\"euclidean\"` default, but others are available)\n",
    "- `n_jobs`: parallelism for neighbor search (depends on sklearn version)\n",
    "\n",
    "Practical pattern: **scale features** before DBSCAN unless you already trust the units.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9354cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling matters: eps is in *distance units*\n",
    "X_weird = X.copy()\n",
    "X_weird[:, 0] *= 10.0  # stretch x-axis\n",
    "\n",
    "labels_unscaled = DBSCAN(eps=0.25, min_samples=6).fit_predict(X_weird)\n",
    "plot_clusters_2d(X_weird, labels_unscaled, title=\"DBSCAN on stretched data (no scaling)\").show()\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(X_weird)\n",
    "labels_scaled = DBSCAN(eps=0.25, min_samples=6).fit_predict(X_scaled)\n",
    "plot_clusters_2d(X_scaled, labels_scaled, title=\"DBSCAN after StandardScaler (distance scale restored)\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0cf2a8",
   "metadata": {},
   "source": [
    "## 9) Practical checklist + pitfalls\n",
    "\n",
    "- **Scaling is not optional** when features have different units (DBSCAN uses distances directly).\n",
    "- **Choosing `eps`** is the main art:\n",
    "  - k-distance plots help, but don’t over-trust the elbow.\n",
    "  - what counts as “near” depends on the metric and the embedding space.\n",
    "- **Varying density** is DBSCAN’s classic failure mode (one ε can’t fit all). Consider HDBSCAN.\n",
    "- **High dimensions** make distance less informative (neighbors become “all the same distance”).\n",
    "- **Border assignment ambiguity**: border points can be assigned to different clusters depending on traversal order.\n",
    "- **Complexity**: naive DBSCAN is O(n²); practical implementations rely on efficient neighbor search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d4b0ea",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. On the moons dataset, find an `eps` where DBSCAN merges both moons into one cluster. Explain why.\n",
    "2. Create a dataset with one **dense** blob and one **sparse** blob. Show where DBSCAN fails and explain how HDBSCAN helps.\n",
    "3. Implement a faster neighbor query (KD-tree / ball tree) and compare runtime vs the O(n²) version.\n",
    "4. Use DBSCAN on a PCA-reduced real dataset (e.g., digits) and inspect the noise points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2a0d19",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Ester, Kriegel, Sander, Xu (1996). *A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise (DBSCAN).* (KDD)\n",
    "- `scikit-learn` docs: DBSCAN (`sklearn.cluster.DBSCAN`)\n",
    "- Campello, Moulavi, Sander (2013). *Density-Based Clustering Based on Hierarchical Density Estimates (HDBSCAN).* (PAKDD)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
