{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fdc675f",
   "metadata": {},
   "source": [
    "# Fowlkes–Mallows Score (`fowlkes_mallows_score`)\n",
    "\n",
    "The **Fowlkes–Mallows index (FMI)** measures how similar two **labelings** of the same `n` samples are.\n",
    "\n",
    "It is most often used for **external clustering validation**:\n",
    "\n",
    "- `labels_true`: ground-truth classes (or a reference clustering)\n",
    "- `labels_pred`: cluster assignments produced by an algorithm\n",
    "\n",
    "FMI is a **pair-counting** metric: it looks at all pairs `(i, j)` and checks whether each pair is placed in the **same cluster** in both labelings.\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Build intuition with tiny examples + pairwise heatmaps.\n",
    "- Derive the FMI formula (pair precision/recall) and compute it via a contingency matrix.\n",
    "- Implement FMI from scratch in NumPy and match scikit-learn.\n",
    "- See how FMI reacts to **permutations**, **merges/splits**, and **label noise**.\n",
    "- Use FMI as a **model-selection objective** for a simple logistic regression classifier.\n",
    "\n",
    "## Quick import\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import fowlkes_mallows_score\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3016dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.datasets import make_blobs, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fowlkes_mallows_score as sk_fowlkes_mallows_score\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "rng = np.random.default_rng(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import sklearn\n",
    "import plotly\n",
    "\n",
    "print(\"python:\", sys.version.split()[0])\n",
    "print(\"numpy :\", np.__version__)\n",
    "print(\"sklearn:\", sklearn.__version__)\n",
    "print(\"plotly:\", plotly.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342a091",
   "metadata": {},
   "source": [
    "## 1) Pair-counting view (what FMI actually measures)\n",
    "\n",
    "Let $y^{(T)}$ be the **true** labels and $y^{(P)}$ be the **predicted** labels.\n",
    "\n",
    "For each pair of samples $(i, j)$ with $i<j$, define:\n",
    "\n",
    "- same-true: $\\mathbb{1}[y^{(T)}_i = y^{(T)}_j]$\n",
    "- same-pred: $\\mathbb{1}[y^{(P)}_i = y^{(P)}_j]$\n",
    "\n",
    "This turns clustering comparison into a **binary decision per pair** (together vs apart), yielding pairwise counts:\n",
    "\n",
    "- **TP**: together in both true and predicted\n",
    "- **FP**: together in predicted, apart in true\n",
    "- **FN**: together in true, apart in predicted\n",
    "- **TN**: apart in both (not used by FMI)\n",
    "\n",
    "Pairwise **precision** and **recall**:\n",
    "\n",
    "$$\n",
    "\\text{precision}_{\\text{pair}} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FP}},\\qquad\n",
    "\\text{recall}_{\\text{pair}} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}\n",
    "$$\n",
    "\n",
    "The Fowlkes–Mallows index is the geometric mean:\n",
    "\n",
    "$$\n",
    "\\mathrm{FMI} = \\sqrt{\\text{precision}_{\\text{pair}}\\,\\text{recall}_{\\text{pair}}}\n",
    "= \\frac{\\mathrm{TP}}{\\sqrt{(\\mathrm{TP}+\\mathrm{FP})(\\mathrm{TP}+\\mathrm{FN})}}\n",
    "$$\n",
    "\n",
    "Notes:\n",
    "\n",
    "- FMI is **label-permutation invariant** (cluster IDs are arbitrary).\n",
    "- FMI ignores **true negatives** (pairs separated in both clusterings). With many clusters, TN pairs dominate, so ignoring them keeps the metric focused on *who gets grouped together*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa6d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_confusion_counts_bruteforce(labels_true, labels_pred):\n",
    "    \"\"\"Pair confusion counts (TP, FP, FN, TN) in O(n^2).\n",
    "\n",
    "    A pair (i, j) with i<j is a 'positive' if the two samples are in the same cluster.\n",
    "    \"\"\"\n",
    "\n",
    "    labels_true = np.asarray(labels_true).ravel()\n",
    "    labels_pred = np.asarray(labels_pred).ravel()\n",
    "    if labels_true.shape != labels_pred.shape:\n",
    "        raise ValueError(f\"shape mismatch: true{labels_true.shape} vs pred{labels_pred.shape}\")\n",
    "\n",
    "    n = labels_true.size\n",
    "    tp = fp = fn = tn = 0\n",
    "\n",
    "    for i in range(n - 1):\n",
    "        for j in range(i + 1, n):\n",
    "            same_true = labels_true[i] == labels_true[j]\n",
    "            same_pred = labels_pred[i] == labels_pred[j]\n",
    "\n",
    "            if same_true and same_pred:\n",
    "                tp += 1\n",
    "            elif (not same_true) and same_pred:\n",
    "                fp += 1\n",
    "            elif same_true and (not same_pred):\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "\n",
    "def fowlkes_mallows_from_pair_counts(tp, fp, fn):\n",
    "    den = (tp + fp) * (tp + fn)\n",
    "    if den == 0:\n",
    "        return 0.0\n",
    "    return float(tp / np.sqrt(den))\n",
    "\n",
    "\n",
    "# Tiny example: 8 items, 3 true clusters\n",
    "labels_true = np.array([0, 0, 0, 1, 1, 2, 2, 2])\n",
    "\n",
    "# A predicted clustering that *merges* clusters 1 and 2\n",
    "labels_pred = np.array([0, 0, 0, 1, 1, 1, 1, 1])\n",
    "\n",
    "tp, fp, fn, tn = pair_confusion_counts_bruteforce(labels_true, labels_pred)\n",
    "\n",
    "precision_pair = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "recall_pair = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "fmi = fowlkes_mallows_from_pair_counts(tp, fp, fn)\n",
    "\n",
    "n = labels_true.size\n",
    "pairs_total = n * (n - 1) // 2\n",
    "\n",
    "print(f\"n={n}, total pairs={pairs_total}\")\n",
    "print(f\"TP={tp}, FP={fp}, FN={fn}, TN={tn}\")\n",
    "print(f\"pair-precision={precision_pair:.3f}, pair-recall={recall_pair:.3f}\")\n",
    "print(f\"FMI (pair counts)={fmi:.3f}\")\n",
    "print(f\"FMI (sklearn)     ={sk_fowlkes_mallows_score(labels_true, labels_pred):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dd6d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_cluster_matrix(labels):\n",
    "    labels = np.asarray(labels).ravel()\n",
    "    return labels[:, None] == labels[None, :]\n",
    "\n",
    "\n",
    "same_true = same_cluster_matrix(labels_true)\n",
    "same_pred = same_cluster_matrix(labels_pred)\n",
    "\n",
    "# Encode each (i,j) pair into a category:\n",
    "# -1 = diagonal, 0 = TN, 1 = FN, 2 = FP, 3 = TP\n",
    "pair_type = np.zeros_like(same_true, dtype=int)\n",
    "pair_type[(same_true) & (same_pred)] = 3\n",
    "pair_type[(~same_true) & (same_pred)] = 2\n",
    "pair_type[(same_true) & (~same_pred)] = 1\n",
    "pair_type[(~same_true) & (~same_pred)] = 0\n",
    "np.fill_diagonal(pair_type, -1)\n",
    "\n",
    "colorscale_pair = [\n",
    "    [0.00, \"#e0e0e0\"],\n",
    "    [0.125, \"#e0e0e0\"],  # -1 diag\n",
    "    [0.125, \"#ffffff\"],\n",
    "    [0.375, \"#ffffff\"],  # 0 TN\n",
    "    [0.375, \"#d73027\"],\n",
    "    [0.625, \"#d73027\"],  # 1 FN\n",
    "    [0.625, \"#4575b4\"],\n",
    "    [0.875, \"#4575b4\"],  # 2 FP\n",
    "    [0.875, \"#1a9850\"],\n",
    "    [1.00, \"#1a9850\"],  # 3 TP\n",
    "]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=3,\n",
    "    subplot_titles=[\n",
    "        \"Same cluster? (true)\",\n",
    "        \"Same cluster? (pred)\",\n",
    "        \"Pair types (TP/FP/FN/TN)\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Heatmap(z=same_true.astype(int), colorscale=\"Greys\", showscale=False),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Heatmap(z=same_pred.astype(int), colorscale=\"Greys\", showscale=False),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=pair_type,\n",
    "        zmin=-1,\n",
    "        zmax=3,\n",
    "        colorscale=colorscale_pair,\n",
    "        colorbar=dict(\n",
    "            title=\"pair\",\n",
    "            tickvals=[-1, 0, 1, 2, 3],\n",
    "            ticktext=[\"diag\", \"TN\", \"FN\", \"FP\", \"TP\"],\n",
    "        ),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=3,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"FMI compares clusterings by counting sample pairs\",\n",
    "    height=380,\n",
    ")\n",
    "fig.update_xaxes(showticklabels=False)\n",
    "fig.update_yaxes(showticklabels=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebfd8c7",
   "metadata": {},
   "source": [
    "## 2) Efficient computation via a contingency matrix\n",
    "\n",
    "The brute-force pair loop is $O(n^2)$.\n",
    "\n",
    "A much faster way uses the **contingency matrix** $N$:\n",
    "\n",
    "- rows = true clusters\n",
    "- columns = predicted clusters\n",
    "- $N_{ij}$ = number of samples that are in true cluster $i$ **and** predicted cluster $j$\n",
    "\n",
    "Let $\\binom{m}{2} = \\frac{m(m-1)}{2}$ be the number of unordered pairs inside a group of size $m$.\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\mathrm{TP} = \\sum_{i,j} \\binom{N_{ij}}{2}\n",
    "$$\n",
    "\n",
    "Also define row and column sums:\n",
    "\n",
    "$$\n",
    "a_i = \\sum_j N_{ij}\\quad (\\text{size of true cluster } i),\\qquad\n",
    "b_j = \\sum_i N_{ij}\\quad (\\text{size of predicted cluster } j)\n",
    "$$\n",
    "\n",
    "Pairs placed together by the **predicted** clustering:\n",
    "\n",
    "$$\n",
    "\\mathrm{TP}+\\mathrm{FP} = \\sum_j \\binom{b_j}{2}\n",
    "$$\n",
    "\n",
    "Pairs placed together by the **true** clustering:\n",
    "\n",
    "$$\n",
    "\\mathrm{TP}+\\mathrm{FN} = \\sum_i \\binom{a_i}{2}\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "\\mathrm{FMI} = \\frac{\\sum_{i,j} \\binom{N_{ij}}{2}}\n",
    "{\\sqrt{\\left(\\sum_j \\binom{b_j}{2}\\right)\\left(\\sum_i \\binom{a_i}{2}\\right)}}\n",
    "$$\n",
    "\n",
    "This avoids enumerating all pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7548157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb2(m):\n",
    "    m = np.asarray(m, dtype=np.int64)\n",
    "    return m * (m - 1) // 2\n",
    "\n",
    "\n",
    "def contingency_matrix_numpy(labels_true, labels_pred):\n",
    "    labels_true = np.asarray(labels_true).ravel()\n",
    "    labels_pred = np.asarray(labels_pred).ravel()\n",
    "    if labels_true.shape != labels_pred.shape:\n",
    "        raise ValueError(f\"shape mismatch: true{labels_true.shape} vs pred{labels_pred.shape}\")\n",
    "\n",
    "    _, t = np.unique(labels_true, return_inverse=True)\n",
    "    _, p = np.unique(labels_pred, return_inverse=True)\n",
    "\n",
    "    n_true = int(t.max()) + 1 if t.size else 0\n",
    "    n_pred = int(p.max()) + 1 if p.size else 0\n",
    "\n",
    "    cm = np.zeros((n_true, n_pred), dtype=np.int64)\n",
    "    np.add.at(cm, (t, p), 1)\n",
    "    return cm\n",
    "\n",
    "\n",
    "cm = contingency_matrix_numpy(labels_true, labels_pred)\n",
    "\n",
    "tp_fast = int(comb2(cm).sum())\n",
    "pred_pairs = int(comb2(cm.sum(axis=0)).sum())  # TP + FP\n",
    "true_pairs = int(comb2(cm.sum(axis=1)).sum())  # TP + FN\n",
    "\n",
    "fmi_fast = 0.0 if (pred_pairs == 0 or true_pairs == 0) else float(tp_fast / np.sqrt(pred_pairs * true_pairs))\n",
    "\n",
    "print(\"contingency matrix N (rows=true, cols=pred):\n",
    "\", cm)\n",
    "print(f\"TP={tp_fast}, TP+FP={pred_pairs}, TP+FN={true_pairs}\")\n",
    "print(\"FMI (from contingency) =\", round(fmi_fast, 6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9895f431",
   "metadata": {},
   "source": [
    "## 3) NumPy implementation (from scratch)\n",
    "\n",
    "Below is a minimal implementation that mirrors the scikit-learn definition.\n",
    "\n",
    "Implementation notes:\n",
    "\n",
    "- We use the contingency-matrix formula (fast, no $O(n^2)$ loops).\n",
    "- If either labeling has **no within-cluster pairs** (all singleton clusters), scikit-learn returns `0.0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f62b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fowlkes_mallows_score_numpy(labels_true, labels_pred):\n",
    "    \"\"\"Fowlkes–Mallows score between two labelings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels_true, labels_pred : array-like, shape (n_samples,)\n",
    "        Two labelings of the same samples. Values can be any hashable type.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fmi : float\n",
    "        In [0, 1]. 1 means identical pairwise grouping.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = contingency_matrix_numpy(labels_true, labels_pred)\n",
    "\n",
    "    tp = int(comb2(cm).sum())\n",
    "    pred_pairs = int(comb2(cm.sum(axis=0)).sum())  # TP + FP\n",
    "    true_pairs = int(comb2(cm.sum(axis=1)).sum())  # TP + FN\n",
    "\n",
    "    if pred_pairs == 0 or true_pairs == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return float(tp / np.sqrt(pred_pairs * true_pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219fe584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick correctness checks vs scikit-learn\n",
    "\n",
    "def check_case(name, y_t, y_p):\n",
    "    a = fowlkes_mallows_score_numpy(y_t, y_p)\n",
    "    b = sk_fowlkes_mallows_score(y_t, y_p)\n",
    "    ok = np.isclose(a, b)\n",
    "    print(f\"{name:28s} numpy={a:.6f}  sklearn={b:.6f}  ok={ok}\")\n",
    "    return ok\n",
    "\n",
    "\n",
    "ok_all = True\n",
    "ok_all &= check_case(\"perfect (permute labels)\", [0, 0, 1, 1], [1, 1, 0, 0])\n",
    "ok_all &= check_case(\"all singletons\", np.arange(6), np.arange(6))\n",
    "ok_all &= check_case(\"all same cluster\", np.zeros(6, dtype=int), np.zeros(6, dtype=int))\n",
    "ok_all &= check_case(\"random labels\", rng.integers(0, 4, 80), rng.integers(0, 5, 80))\n",
    "\n",
    "# A few randomized trials\n",
    "for _ in range(10):\n",
    "    y_t = rng.integers(0, rng.integers(2, 8), size=200)\n",
    "    y_p = rng.integers(0, rng.integers(2, 9), size=200)\n",
    "    ok_all &= np.isclose(fowlkes_mallows_score_numpy(y_t, y_p), sk_fowlkes_mallows_score(y_t, y_p))\n",
    "\n",
    "print(\"\n",
    "All checks passed?\", ok_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa76209",
   "metadata": {},
   "source": [
    "## 4) Behavior: permutations, merges/splits, and label noise\n",
    "\n",
    "We'll create a 2D dataset with obvious clusters and compare several predicted labelings:\n",
    "\n",
    "- **perfect**: identical to the ground truth\n",
    "- **permuted**: same clustering, different numeric IDs (should score 1.0)\n",
    "- **merged**: two clusters merged into one (more false positives)\n",
    "- **split**: one cluster split into two (more false negatives)\n",
    "- **noisy**: a fraction of labels randomly corrupted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1da533",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_true = make_blobs(\n",
    "    n_samples=450,\n",
    "    centers=3,\n",
    "    cluster_std=(0.9, 1.1, 0.8),\n",
    "    random_state=7,\n",
    ")\n",
    "\n",
    "# Different predicted labelings\n",
    "\n",
    "y_perfect = y_true.copy()\n",
    "\n",
    "y_permuted = (y_true + 1) % 3\n",
    "\n",
    "y_merged = y_true.copy()\n",
    "y_merged[y_merged == 2] = 1  # merge cluster 2 into cluster 1\n",
    "\n",
    "# Split cluster 0 into two by x-coordinate\n",
    "mask0 = y_true == 0\n",
    "x0 = X[mask0, 0]\n",
    "cut = np.median(x0)\n",
    "y_split = y_true.copy()\n",
    "y_split[mask0 & (X[:, 0] > cut)] = 3\n",
    "\n",
    "# Add label noise\n",
    "noise_frac = 0.12\n",
    "idx = rng.choice(X.shape[0], size=int(noise_frac * X.shape[0]), replace=False)\n",
    "y_noisy = y_true.copy()\n",
    "y_noisy[idx] = rng.integers(0, 4, size=idx.size)\n",
    "\n",
    "noisy_key = f\"noisy ({noise_frac:.0%})\"\n",
    "\n",
    "cases = {\n",
    "    \"true\": y_true,\n",
    "    \"perfect\": y_perfect,\n",
    "    \"permuted\": y_permuted,\n",
    "    \"merged\": y_merged,\n",
    "    \"split\": y_split,\n",
    "    noisy_key: y_noisy,\n",
    "}\n",
    "\n",
    "scores = {name: fowlkes_mallows_score_numpy(y_true, y) for name, y in cases.items() if name != \"true\"}\n",
    "\n",
    "for name, s in scores.items():\n",
    "    print(f\"{name:14s} FMI={s:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4bf053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize true labels and a few predicted labelings\n",
    "\n",
    "palette = px.colors.qualitative.Set2\n",
    "\n",
    "\n",
    "def label_colors(labels):\n",
    "    labels = np.asarray(labels)\n",
    "    uniq = np.unique(labels)\n",
    "    color_map = {int(k): palette[i % len(palette)] for i, k in enumerate(uniq)}\n",
    "    return [color_map[int(k)] for k in labels]\n",
    "\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=3,\n",
    "    subplot_titles=[\n",
    "        \"ground truth\",\n",
    "        f\"perfect (FMI={scores['perfect']:.3f})\",\n",
    "        f\"permuted (FMI={scores['permuted']:.3f})\",\n",
    "        f\"merged (FMI={scores['merged']:.3f})\",\n",
    "        f\"split (FMI={scores['split']:.3f})\",\n",
    "        f\"noisy (FMI={scores[noisy_key]:.3f})\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "panels = [\n",
    "    (\"true\", y_true),\n",
    "    (\"perfect\", y_perfect),\n",
    "    (\"permuted\", y_permuted),\n",
    "    (\"merged\", y_merged),\n",
    "    (\"split\", y_split),\n",
    "    (\"noisy\", y_noisy),\n",
    "]\n",
    "\n",
    "for k, (_, y) in enumerate(panels):\n",
    "    r = 1 + k // 3\n",
    "    c = 1 + k % 3\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=X[:, 0],\n",
    "            y=X[:, 1],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=6, color=label_colors(y), opacity=0.85),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=r,\n",
    "        col=c,\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=650, title=\"Same points, different labelings → different FMI\")\n",
    "fig.update_xaxes(showticklabels=False)\n",
    "fig.update_yaxes(showticklabels=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e467b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FMI as we increase label noise\n",
    "\n",
    "def corrupt_labels(y, frac, *, rng):\n",
    "    y = np.asarray(y).copy()\n",
    "    n = y.size\n",
    "    m = int(frac * n)\n",
    "    if m == 0:\n",
    "        return y\n",
    "\n",
    "    idx = rng.choice(n, size=m, replace=False)\n",
    "    labels = np.unique(y)\n",
    "    y[idx] = rng.choice(labels, size=m)\n",
    "    return y\n",
    "\n",
    "\n",
    "noise_grid = np.linspace(0, 0.8, 41)\n",
    "fmis = []\n",
    "for frac in noise_grid:\n",
    "    y_corrupt = corrupt_labels(y_true, frac, rng=rng)\n",
    "    fmis.append(fowlkes_mallows_score_numpy(y_true, y_corrupt))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=noise_grid, y=fmis, mode=\"lines+markers\"))\n",
    "fig.update_layout(\n",
    "    title=\"FMI decreases as we corrupt more labels\",\n",
    "    xaxis_title=\"fraction of labels randomly reassigned\",\n",
    "    yaxis_title=\"Fowlkes–Mallows index\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac65d75",
   "metadata": {},
   "source": [
    "## 5) Using FMI to tune a simple model (logistic regression)\n",
    "\n",
    "FMI expects **hard labels**.\n",
    "A classifier like logistic regression produces **scores** (probabilities), and we choose a threshold $t$:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i(t) = \\mathbb{1}[\\hat{p}_i \\ge t]\n",
    "$$\n",
    "\n",
    "Two important practical points:\n",
    "\n",
    "- FMI is **not differentiable** w.r.t. model parameters because it depends on discrete predictions.\n",
    "- A common workflow is:\n",
    "  1. **fit** the model with a differentiable loss (e.g. log loss)\n",
    "  2. **select** hyperparameters / thresholds by maximizing FMI on a validation set (grid search)\n",
    "\n",
    "Even though FMI is more common for clustering, it is defined for any pair of labelings — so it can also compare **class labels**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36af0569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_intercept(X: np.ndarray) -> np.ndarray:\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    return np.c_[np.ones((X.shape[0], 1)), X]\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=float)\n",
    "    out = np.empty_like(z)\n",
    "    pos = z >= 0\n",
    "    out[pos] = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "\n",
    "def log_loss_from_proba(y_true, p, eps=1e-15):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    p = np.clip(np.asarray(p, dtype=float), eps, 1 - eps)\n",
    "    return -np.mean(y_true * np.log(p) + (1 - y_true) * np.log(1 - p))\n",
    "\n",
    "\n",
    "def fit_logistic_regression_gd(\n",
    "    X,\n",
    "    y,\n",
    "    *,\n",
    "    lr=0.2,\n",
    "    max_iter=3000,\n",
    "    alpha=0.0,\n",
    "    tol=1e-8,\n",
    "):\n",
    "    \"\"\"Binary logistic regression with gradient descent + optional L2 penalty.\"\"\"\n",
    "\n",
    "    Xb = add_intercept(X)\n",
    "    y = np.asarray(y, dtype=float).ravel()\n",
    "\n",
    "    n, d = Xb.shape\n",
    "    w = np.zeros(d)\n",
    "    history = []\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        p = sigmoid(Xb @ w)\n",
    "        loss = log_loss_from_proba(y, p) + 0.5 * alpha * np.sum(w[1:] ** 2)\n",
    "        history.append(loss)\n",
    "\n",
    "        grad = (Xb.T @ (p - y)) / n\n",
    "        grad[1:] += alpha * w[1:]\n",
    "\n",
    "        w_new = w - lr * grad\n",
    "        if np.linalg.norm(w_new - w) < tol:\n",
    "            w = w_new\n",
    "            break\n",
    "        w = w_new\n",
    "\n",
    "    return w, np.asarray(history)\n",
    "\n",
    "\n",
    "def predict_proba_logreg(X, w):\n",
    "    return sigmoid(add_intercept(X) @ w)\n",
    "\n",
    "\n",
    "# A 2D dataset so we can visualize the decision boundary.\n",
    "X, y = make_classification(\n",
    "    n_samples=900,\n",
    "    n_features=2,\n",
    "    n_redundant=0,\n",
    "    n_informative=2,\n",
    "    n_clusters_per_class=1,\n",
    "    class_sep=1.1,\n",
    "    flip_y=0.05,\n",
    "    random_state=7,\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.35, random_state=7, stratify=y\n",
    ")\n",
    "\n",
    "w, history = fit_logistic_regression_gd(X_train, y_train, lr=0.25, max_iter=4000, alpha=1e-2)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=history, mode=\"lines\"))\n",
    "fig.update_layout(title=\"Logistic regression training loss (log loss)\", xaxis_title=\"iteration\", yaxis_title=\"loss\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ea8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep thresholds and choose the one that maximizes FMI on the validation set\n",
    "\n",
    "p_val = predict_proba_logreg(X_val, w)\n",
    "\n",
    "t_grid = np.linspace(0.01, 0.99, 199)\n",
    "fmi_grid = []\n",
    "\n",
    "for t in t_grid:\n",
    "    y_hat = (p_val >= t).astype(int)\n",
    "    fmi_grid.append(fowlkes_mallows_score_numpy(y_val, y_hat))\n",
    "\n",
    "fmi_grid = np.asarray(fmi_grid)\n",
    "\n",
    "best_idx = int(np.argmax(fmi_grid))\n",
    "best_t = float(t_grid[best_idx])\n",
    "best_fmi = float(fmi_grid[best_idx])\n",
    "\n",
    "print(f\"best threshold t*={best_t:.3f} -> FMI={best_fmi:.4f}\")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=t_grid, y=fmi_grid, mode=\"lines+markers\", name=\"FMI(t)\"))\n",
    "fig.add_vline(x=0.5, line_dash=\"dash\", line_color=\"gray\")\n",
    "fig.add_vline(x=best_t, line_dash=\"dash\", line_color=\"black\")\n",
    "fig.update_layout(\n",
    "    title=\"Choose a decision threshold by maximizing FMI\",\n",
    "    xaxis_title=\"threshold t\",\n",
    "    yaxis_title=\"Fowlkes–Mallows index\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how changing the threshold shifts the decision boundary\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# points\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=X_val[:, 0],\n",
    "        y=X_val[:, 1],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=6, color=y_val, colorscale=[[0, \"#4575b4\"], [1, \"#d73027\"]], opacity=0.8),\n",
    "        name=\"validation points\",\n",
    "    )\n",
    ")\n",
    "\n",
    "w0, w1, w2 = w\n",
    "\n",
    "\n",
    "def decision_line_xy(w0, w1, w2, threshold, x1_grid):\n",
    "    # p = sigmoid(w0 + w1*x1 + w2*x2) >= t  <=>  w0 + w1*x1 + w2*x2 >= log(t/(1-t))\n",
    "    logit_t = np.log(threshold / (1 - threshold))\n",
    "    if abs(w2) < 1e-12:\n",
    "        return None\n",
    "    x2 = (logit_t - w0 - w1 * x1_grid) / w2\n",
    "    return x2\n",
    "\n",
    "\n",
    "x1_min, x1_max = X_val[:, 0].min() - 0.5, X_val[:, 0].max() + 0.5\n",
    "x1_grid = np.linspace(x1_min, x1_max, 200)\n",
    "\n",
    "x2_05 = decision_line_xy(w0, w1, w2, 0.5, x1_grid)\n",
    "x2_best = decision_line_xy(w0, w1, w2, best_t, x1_grid)\n",
    "\n",
    "if x2_05 is not None:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x1_grid,\n",
    "            y=x2_05,\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"gray\", dash=\"dash\"),\n",
    "            name=\"boundary t=0.5\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "if x2_best is not None:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x1_grid,\n",
    "            y=x2_best,\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"black\", dash=\"dash\"),\n",
    "            name=f\"boundary t*={best_t:.3f}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Threshold choice changes which points are predicted positive\",\n",
    "    xaxis_title=\"x1\",\n",
    "    yaxis_title=\"x2\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef02b22",
   "metadata": {},
   "source": [
    "## 6) Pros, cons, and when to use FMI\n",
    "\n",
    "**Pros**\n",
    "\n",
    "- **Permutation invariant**: cluster IDs can be renamed without changing the score.\n",
    "- **Interpretable** as $\\sqrt{\\text{pair-precision}\\cdot\\text{pair-recall}}$.\n",
    "- **Works with different numbers of clusters** in the two labelings.\n",
    "- **Bounded** in $[0,1]$ (higher is better).\n",
    "\n",
    "**Cons / pitfalls**\n",
    "\n",
    "- **Not adjusted for chance**: random labelings can score non-zero depending on cluster sizes (compare with `adjusted_rand_score`).\n",
    "- **Ignores TN pairs** (pairs separated in both). That is often desirable, but it means FMI is not a full \"pair accuracy\" metric.\n",
    "- **Can be unintuitive when clusters are tiny**: if a labeling has all singleton clusters, there are no within-cluster pairs → FMI is `0.0` (even if the two labelings match).\n",
    "- FMI is **non-differentiable** w.r.t. model parameters (it depends on discrete assignments), so you typically use it for **model selection** (grid search), not direct gradient optimization.\n",
    "\n",
    "**Good use cases**\n",
    "\n",
    "- External clustering evaluation when you have **ground truth labels**.\n",
    "- Comparing two different clusterings of the same dataset (algorithm comparison, stability across runs).\n",
    "- Selecting clustering hyperparameters (e.g. choosing a cut level in hierarchical clustering) when a reference labeling exists.\n",
    "\n",
    "**Not a good fit**\n",
    "\n",
    "- Purely unsupervised evaluation (no reference labels): consider internal metrics like `silhouette_score` or `davies_bouldin_score`.\n",
    "- When you care about per-class errors, false positives vs false negatives *as samples* (use classification metrics like F1 / ROC-AUC).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ad82e2",
   "metadata": {},
   "source": [
    "## 7) Exercises\n",
    "\n",
    "1. Construct a case where one clustering is a **refinement** of the other (every predicted cluster is a subset of a true cluster). What happens to pair precision vs pair recall?\n",
    "2. Compare FMI vs `adjusted_rand_score` on random labelings as you vary the number of clusters.\n",
    "3. In the logistic regression example, compare the threshold that maximizes FMI vs the threshold that maximizes F1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cefea4",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Fowlkes, E. B., & Mallows, C. L. (1983). *A Method for Comparing Two Hierarchical Clusterings*. Journal of the American Statistical Association.\n",
    "- scikit-learn: `sklearn.metrics.fowlkes_mallows_score` documentation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
