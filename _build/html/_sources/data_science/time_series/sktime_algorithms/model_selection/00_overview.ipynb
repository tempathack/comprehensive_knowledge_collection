{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# sktime Model Selection & Time-Series Cross-Validation\n\nTime-series validation must respect **temporal order**. This notebook covers **sliding vs. expanding windows**, visualizes splits, and shows how to tune models with `ForecastingGridSearchCV`.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Forecasting horizon\n\nFor a forecast origin $T$, the **forecasting horizon** is\n\n\\[\n\text{fh} = \\{T+1, T+2, \\ldots, T+h\\}\n\\]\n\nsktime uses a `ForecastingHorizon` object to define these steps explicitly.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\n\nfrom sktime.datasets import load_airline\nfrom sktime.forecasting.model_selection import (\n    temporal_train_test_split,\n    ForecastingHorizon,\n    SlidingWindowSplitter,\n    ExpandingWindowSplitter,\n)\n\n# Load a classic monthly series\ny = load_airline()\n\n# Train/test split + forecasting horizon\ny_train, y_test = temporal_train_test_split(y, test_size=24)\nfh = ForecastingHorizon(y_test.index, is_relative=False)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Sliding vs. expanding windows\n\n- **Sliding window** keeps a fixed training length.\n- **Expanding window** grows the training set as time advances.\n\nBoth avoid leakage, but they answer different questions:\n- Sliding: \"How does the model perform on *recent* history?\"\n- Expanding: \"How does the model improve with *more data*?\"\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import plotly.express as px\n\n\ndef plot_cv_splits(y, splitter, max_splits=6, title=\"\"):\n    index = y.index\n    if hasattr(index, \"to_timestamp\"):\n        index = index.to_timestamp()\n    fig = go.Figure()\n\n    for split, (train_idx, test_idx) in enumerate(splitter.split(y)):\n        if split >= max_splits:\n            break\n        fig.add_trace(\n            go.Scatter(\n                x=index[train_idx],\n                y=[split] * len(train_idx),\n                mode=\"markers\",\n                marker=dict(color=\"rgba(120,120,120,0.6)\", size=6),\n                name=\"train\" if split == 0 else None,\n                showlegend=split == 0,\n            )\n        )\n        fig.add_trace(\n            go.Scatter(\n                x=index[test_idx],\n                y=[split] * len(test_idx),\n                mode=\"markers\",\n                marker=dict(color=\"rgba(255,127,14,0.9)\", size=6),\n                name=\"test\" if split == 0 else None,\n                showlegend=split == 0,\n            )\n        )\n\n    fig.update_layout(\n        title=title,\n        xaxis_title=\"Time\",\n        yaxis=dict(title=\"Split #\", autorange=\"reversed\"),\n        height=320 + 40 * max_splits,\n    )\n    return fig\n\nfh_steps = [1, 2, 3, 6, 12]\ncv_sliding = SlidingWindowSplitter(fh=fh_steps, window_length=60, step_length=12)\ncv_expanding = ExpandingWindowSplitter(fh=fh_steps, initial_window=60, step_length=12)\n\nfig = plot_cv_splits(y, cv_sliding, title=\"Sliding Window CV\")\nfig.show()\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "fig = plot_cv_splits(y, cv_expanding, title=\"Expanding Window CV\")\nfig.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Hyperparameter tuning with time-aware CV\n\n`sktime` provides `ForecastingGridSearchCV` to tune parameters while **respecting time order**.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from sktime.forecasting.naive import NaiveForecaster\nfrom sktime.forecasting.model_selection import ForecastingGridSearchCV\nfrom sktime.performance_metrics.forecasting import mean_absolute_error\n\nforecaster = NaiveForecaster()\nparam_grid = {\n    \"strategy\": [\"last\", \"mean\", \"drift\"],\n    \"window_length\": [3, 6, 12],\n}\n\n# Use expanding windows for tuning\ncv = ExpandingWindowSplitter(fh=fh_steps, initial_window=60, step_length=12)\n\ngscv = ForecastingGridSearchCV(\n    forecaster=forecaster,\n    param_grid=param_grid,\n    cv=cv,\n    scoring=mean_absolute_error,\n)\n\ngscv.fit(y_train)\n\nbest_forecaster = gscv.best_forecaster_\nprint(\"Best params:\", gscv.best_params_)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Pitfalls checklist\n\n- **Leakage**: never use future data to compute features or scalers.\n- **Horizon mismatch**: ensure `fh` aligns with how you evaluate.\n- **Changing seasonality**: prefer windowed CV when regimes drift.\n- **Sparse data**: keep `window_length` large enough to capture seasonality.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}