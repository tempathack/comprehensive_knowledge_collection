{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d90b9c1",
   "metadata": {},
   "source": [
    "# Kruskal–Wallis H test (one-way ANOVA on ranks) — from scratch\n",
    "\n",
    "The Kruskal–Wallis test answers:\n",
    "\n",
    "> “Do **two or more independent groups** differ in their **typical values** when I don't want to assume normality?”\n",
    "\n",
    "It is a **nonparametric** alternative to **one-way ANOVA**. Instead of comparing means, it **ranks all observations** and checks whether some groups systematically receive **higher (or lower) ranks**.\n",
    "\n",
    "## Learning goals\n",
    "- Know when Kruskal–Wallis is the right test (and when it isn't).\n",
    "- Understand the null/alternative hypotheses and the assumptions.\n",
    "- Compute the H statistic from ranks and rank sums.\n",
    "- Implement the test with **NumPy only** (including **tie correction**).\n",
    "- Interpret results (p-value + effect size) and visualize what’s happening with Plotly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8cfd10",
   "metadata": {},
   "source": [
    "## Notebook roadmap\n",
    "\n",
    "1. What the test is used for\n",
    "2. Hypotheses + assumptions\n",
    "3. Intuition: “ANOVA on ranks”\n",
    "4. The H statistic (with tie correction)\n",
    "5. A tiny worked example (ranks by hand)\n",
    "6. NumPy-only implementation\n",
    "7. A realistic simulation + Plotly visuals\n",
    "8. Tie correction demo\n",
    "9. Interpretation + reporting\n",
    "10. Pitfalls\n",
    "11. Exercises + references\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4e7037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "SEED = 7\n",
    "rng = np.random.default_rng(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import plotly\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"Plotly:\", plotly.__version__)\n",
    "print(\"Seed:\", SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1172c9c",
   "metadata": {},
   "source": [
    "## 1) What is the Kruskal–Wallis test used for?\n",
    "\n",
    "Use Kruskal–Wallis when you have:\n",
    "\n",
    "- **One categorical factor** with **2+ independent groups** (A/B/C/...)\n",
    "- A **numeric or ordinal outcome**\n",
    "- You want a test that does **not assume normality**\n",
    "\n",
    "Common situations:\n",
    "- A/B/C testing where the metric is skewed (e.g., time-on-page).\n",
    "- Comparing ratings (Likert-scale) across multiple groups.\n",
    "- Medical/biological measurements that are heavy-tailed or contain outliers.\n",
    "\n",
    "Relationship to other tests:\n",
    "- **One-way ANOVA**: compares means assuming (roughly) normal residuals.\n",
    "- **Mann–Whitney U**: compares **two** independent groups using ranks.\n",
    "  - Kruskal–Wallis is the natural extension to **k groups**.\n",
    "- **Friedman test**: the rank-based analogue for **repeated-measures / paired** designs (not Kruskal–Wallis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc559b1b",
   "metadata": {},
   "source": [
    "## 2) Hypotheses and assumptions\n",
    "\n",
    "### 2.1 Hypotheses\n",
    "\n",
    "Let there be $k$ groups.\n",
    "\n",
    "- **Null hypothesis $H_0$**: the groups come from the **same distribution** (equivalently: group label has no effect on the outcome).\n",
    "- **Alternative $H_1$**: **at least one** group tends to produce **larger or smaller values**.\n",
    "\n",
    "Important nuance:\n",
    "- Kruskal–Wallis is often described as a test of “medians”, but strictly it detects **distributional differences**.\n",
    "- If group distributions have **similar shapes/spreads**, then a significant result is commonly interpreted as a **difference in location** (typical value).\n",
    "\n",
    "### 2.2 Assumptions (practical)\n",
    "- Observations are **independent** within and across groups.\n",
    "- The outcome is at least **ordinal** (ranks make sense).\n",
    "- Groups are independent (between-subject design).\n",
    "\n",
    "If independence is violated, the p-value can be severely wrong.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9911f562",
   "metadata": {},
   "source": [
    "## 3) Intuition: “ANOVA on ranks”\n",
    "\n",
    "1. **Pool** all observations from all groups.\n",
    "2. Replace the raw values with their **ranks** (1 = smallest).\n",
    "3. Compute each group’s **sum of ranks** (or mean rank).\n",
    "\n",
    "If all groups really come from the same distribution, their ranks should be well-mixed and each group’s average rank should be close to the overall average rank:\n",
    "\n",
    "$$\n",
    "\\text{overall mean rank} = \\frac{N + 1}{2}\n",
    "$$\n",
    "\n",
    "where $N$ is the total number of observations.\n",
    "\n",
    "If one group tends to have larger values, it will accumulate larger ranks → the rank sums become very different → the test statistic grows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7e02c4",
   "metadata": {},
   "source": [
    "## 4) The H statistic (with tie correction)\n",
    "\n",
    "Let:\n",
    "- $k$ = number of groups\n",
    "- $n_i$ = sample size of group $i$\n",
    "- $N = \\sum_{i=1}^k n_i$ = total sample size\n",
    "- $R_i$ = **sum of ranks** in group $i$ (ranks computed on the pooled sample)\n",
    "\n",
    "The Kruskal–Wallis statistic is:\n",
    "\n",
    "$$\n",
    "H = \\frac{12}{N(N+1)} \\sum_{i=1}^k \\frac{R_i^2}{n_i} - 3(N+1)\n",
    "$$\n",
    "\n",
    "### Tie correction\n",
    "If there are ties in the pooled data, ranks are averaged. Ties reduce the variance of ranks, so we apply a correction:\n",
    "\n",
    "$$\n",
    "C = 1 - \\frac{\\sum_j (t_j^3 - t_j)}{N^3 - N}\n",
    "$$\n",
    "\n",
    "where $t_j$ are the sizes of tied groups (e.g., if the value 10 appears 4 times, one of the $t_j$ is 4).\n",
    "\n",
    "The tie-corrected statistic is:\n",
    "\n",
    "$$\n",
    "H_{\\text{corr}} = \\frac{H}{C}\n",
    "$$\n",
    "\n",
    "Under $H_0$ and with sufficiently large samples, $H_{\\text{corr}}$ is approximately $\\chi^2$ distributed with $k-1$ degrees of freedom.\n",
    "\n",
    "In this notebook we compute **H exactly** (NumPy-only) and estimate the p-value via a **permutation test** (also NumPy-only).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2802d0",
   "metadata": {},
   "source": [
    "## 5) Tiny worked example (see ranks explicitly)\n",
    "\n",
    "We’ll use three small groups so we can see the mechanics clearly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7e4e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = np.array([1, 3, 5])\n",
    "g2 = np.array([2, 4, 6])\n",
    "g3 = np.array([7, 8, 9])\n",
    "\n",
    "groups_tiny = [g1, g2, g3]\n",
    "group_names_tiny = [\"A\", \"B\", \"C\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b8f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankdata_average(x: np.ndarray):\n",
    "    \"\"\"Average ranks for ties (NumPy-only).\n",
    "\n",
    "    Returns\n",
    "    - ranks: float array of same shape as x (flattened)\n",
    "    - tie_counts: 1D int array containing sizes of tie groups (>1)\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    x = x.ravel()\n",
    "    n = x.size\n",
    "    if n == 0:\n",
    "        raise ValueError(\"x must be non-empty\")\n",
    "\n",
    "    order = np.argsort(x, kind=\"mergesort\")\n",
    "    sorted_x = x[order]\n",
    "\n",
    "    ranks_sorted = np.empty(n, dtype=float)\n",
    "    tie_counts = []\n",
    "\n",
    "    diffs = np.diff(sorted_x)\n",
    "    run_starts = np.r_[0, np.nonzero(diffs != 0)[0] + 1]\n",
    "    run_ends = np.r_[run_starts[1:], n]\n",
    "\n",
    "    for start, end in zip(run_starts, run_ends):\n",
    "        avg_rank = (start + 1 + end) / 2.0  # ranks are 1..n\n",
    "        ranks_sorted[start:end] = avg_rank\n",
    "        count = end - start\n",
    "        if count > 1:\n",
    "            tie_counts.append(count)\n",
    "\n",
    "    ranks = np.empty(n, dtype=float)\n",
    "    ranks[order] = ranks_sorted\n",
    "    return ranks, np.array(tie_counts, dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b414b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values_tiny = np.concatenate(groups_tiny)\n",
    "all_ranks_tiny, tie_counts_tiny = rankdata_average(all_values_tiny)\n",
    "\n",
    "labels_tiny = np.concatenate([\n",
    "    np.repeat(name, len(g)) for name, g in zip(group_names_tiny, groups_tiny)\n",
    "])\n",
    "\n",
    "table = np.column_stack([labels_tiny, all_values_tiny.astype(str), all_ranks_tiny.astype(str)])\n",
    "print(\"group  value  rank\")\n",
    "for row in table:\n",
    "    print(f\"{row[0]:>5}  {row[1]:>5}  {row[2]:>4}\")\n",
    "\n",
    "print(\"\\nTies:\", tie_counts_tiny if tie_counts_tiny.size else \"none\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a8f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize mean ranks (this is what the test is sensitive to)\n",
    "starts = np.r_[0, np.cumsum([len(g) for g in groups_tiny])[:-1]]\n",
    "rank_sums_tiny = np.add.reduceat(all_ranks_tiny, starts)\n",
    "ns_tiny = np.array([len(g) for g in groups_tiny])\n",
    "mean_ranks_tiny = rank_sums_tiny / ns_tiny\n",
    "overall_mean_rank_tiny = (len(all_ranks_tiny) + 1) / 2\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[go.Bar(x=group_names_tiny, y=mean_ranks_tiny, text=np.round(mean_ranks_tiny, 2), textposition=\"outside\")]\n",
    ")\n",
    "fig.add_hline(y=overall_mean_rank_tiny, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"overall mean rank\")\n",
    "fig.update_layout(\n",
    "    title=\"Tiny example: mean ranks by group\",\n",
    "    xaxis_title=\"Group\",\n",
    "    yaxis_title=\"Mean rank\",\n",
    "    yaxis=dict(range=[0, len(all_ranks_tiny) + 1]),\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbbf61b",
   "metadata": {},
   "source": [
    "## 6) NumPy-only Kruskal–Wallis implementation\n",
    "\n",
    "We’ll implement:\n",
    "\n",
    "- computing ranks (average ties)\n",
    "- computing $H$ and tie correction\n",
    "- estimating the p-value via a **permutation test**\n",
    "\n",
    "The permutation test is conceptually simple:\n",
    "- Under $H_0$ the group labels are exchangeable.\n",
    "- Shuffle which observations belong to which group (keeping group sizes fixed).\n",
    "- Recompute $H$ each time.\n",
    "- The p-value is the fraction of shuffled datasets where $H_{\\text{perm}} \\ge H_{\\text{obs}}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b7c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kruskal_wallis_h(*groups: np.ndarray):\n",
    "    \"\"\"Compute Kruskal–Wallis H statistic (tie-corrected), NumPy-only.\"\"\"\n",
    "    if len(groups) < 2:\n",
    "        raise ValueError(\"Need at least two groups\")\n",
    "\n",
    "    groups = [np.asarray(g).ravel().astype(float) for g in groups]\n",
    "    if any(g.size == 0 for g in groups):\n",
    "        raise ValueError(\"All groups must be non-empty\")\n",
    "\n",
    "    ns = np.array([g.size for g in groups], dtype=int)\n",
    "    k = len(groups)\n",
    "    n_total = int(ns.sum())\n",
    "\n",
    "    pooled = np.concatenate(groups)\n",
    "    ranks, tie_counts = rankdata_average(pooled)\n",
    "\n",
    "    starts = np.r_[0, np.cumsum(ns)[:-1]]\n",
    "    rank_sums = np.add.reduceat(ranks, starts)\n",
    "\n",
    "    H = (12.0 / (n_total * (n_total + 1.0))) * np.sum((rank_sums**2) / ns) - 3.0 * (n_total + 1.0)\n",
    "\n",
    "    if tie_counts.size:\n",
    "        tie_term = np.sum(tie_counts**3 - tie_counts)\n",
    "        C = 1.0 - tie_term / (n_total**3 - n_total)\n",
    "    else:\n",
    "        C = 1.0\n",
    "\n",
    "    H_corr = H / C\n",
    "\n",
    "    mean_ranks = rank_sums / ns\n",
    "    df = k - 1\n",
    "\n",
    "    # A common effect size for Kruskal–Wallis\n",
    "    epsilon_sq = max(0.0, (H_corr - (k - 1)) / (n_total - k)) if n_total > k else np.nan\n",
    "\n",
    "    details = {\n",
    "        \"H\": float(H_corr),\n",
    "        \"H_uncorrected\": float(H),\n",
    "        \"tie_correction_C\": float(C),\n",
    "        \"df\": int(df),\n",
    "        \"n_total\": int(n_total),\n",
    "        \"group_sizes\": ns,\n",
    "        \"rank_sums\": rank_sums,\n",
    "        \"mean_ranks\": mean_ranks,\n",
    "        \"epsilon_squared\": float(epsilon_sq),\n",
    "    }\n",
    "    return details\n",
    "\n",
    "\n",
    "def kruskal_wallis_permutation_test(*groups: np.ndarray, n_perm: int = 5000, seed: int = 0):\n",
    "    \"\"\"Permutation p-value for Kruskal–Wallis (NumPy-only).\n",
    "\n",
    "    Returns\n",
    "    - p_value\n",
    "    - H_obs\n",
    "    - H_perm: permutation distribution\n",
    "    \"\"\"\n",
    "    if n_perm <= 0:\n",
    "        raise ValueError(\"n_perm must be positive\")\n",
    "\n",
    "    groups = [np.asarray(g).ravel().astype(float) for g in groups]\n",
    "    ns = np.array([g.size for g in groups], dtype=int)\n",
    "    if any(ns == 0):\n",
    "        raise ValueError(\"All groups must be non-empty\")\n",
    "\n",
    "    pooled = np.concatenate(groups)\n",
    "    ranks, tie_counts = rankdata_average(pooled)\n",
    "    n_total = ranks.size\n",
    "    k = len(groups)\n",
    "    starts = np.r_[0, np.cumsum(ns)[:-1]]\n",
    "\n",
    "    # tie correction is constant under permutation (pooled values fixed)\n",
    "    if tie_counts.size:\n",
    "        tie_term = np.sum(tie_counts**3 - tie_counts)\n",
    "        C = 1.0 - tie_term / (n_total**3 - n_total)\n",
    "    else:\n",
    "        C = 1.0\n",
    "\n",
    "    rank_sums_obs = np.add.reduceat(ranks, starts)\n",
    "    H_obs = (12.0 / (n_total * (n_total + 1.0))) * np.sum((rank_sums_obs**2) / ns) - 3.0 * (n_total + 1.0)\n",
    "    H_obs /= C\n",
    "\n",
    "    rng_local = np.random.default_rng(seed)\n",
    "    H_perm = np.empty(n_perm, dtype=float)\n",
    "\n",
    "    for i in range(n_perm):\n",
    "        shuffled = rng_local.permutation(ranks)\n",
    "        rank_sums = np.add.reduceat(shuffled, starts)\n",
    "        H = (12.0 / (n_total * (n_total + 1.0))) * np.sum((rank_sums**2) / ns) - 3.0 * (n_total + 1.0)\n",
    "        H_perm[i] = H / C\n",
    "\n",
    "    # +1 correction avoids p=0 and is common for Monte Carlo/permutation tests\n",
    "    p_value = (1.0 + np.sum(H_perm >= H_obs)) / (n_perm + 1.0)\n",
    "\n",
    "    return float(p_value), float(H_obs), H_perm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1758b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "details_tiny = kruskal_wallis_h(*groups_tiny)\n",
    "p_tiny, H_obs_tiny, H_perm_tiny = kruskal_wallis_permutation_test(*groups_tiny, n_perm=5000, seed=SEED)\n",
    "\n",
    "print(\"Kruskal–Wallis (tiny example)\")\n",
    "print(\"H (tie-corrected):\", details_tiny[\"H\"])\n",
    "print(\"df:\", details_tiny[\"df\"])\n",
    "print(\"Permutation p-value:\", p_tiny)\n",
    "print(\"Mean ranks:\", np.round(details_tiny[\"mean_ranks\"], 3))\n",
    "print(\"Epsilon^2 (effect size):\", np.round(details_tiny[\"epsilon_squared\"], 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee46de1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=H_perm_tiny, nbinsx=40, name=\"H under H0 (permutations)\", opacity=0.75))\n",
    "fig.add_vline(x=H_obs_tiny, line_color=\"crimson\", line_width=3, annotation_text=\"observed H\", annotation_position=\"top\")\n",
    "fig.update_layout(\n",
    "    title=f\"Tiny example: permutation distribution of H (p ≈ {p_tiny:.4f})\",\n",
    "    xaxis_title=\"H statistic\",\n",
    "    yaxis_title=\"Count\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b6dce",
   "metadata": {},
   "source": [
    "### Interpreting the tiny example\n",
    "\n",
    "- A small p-value means: **datasets like this are rare under the null model** where group labels do not matter.\n",
    "- Kruskal–Wallis is an **omnibus** test:\n",
    "  - it can tell you “something differs”\n",
    "  - it does **not** tell you **which pairs** differ (that requires post-hoc tests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9c2b8c",
   "metadata": {},
   "source": [
    "## 7) A more realistic example + Plotly visuals\n",
    "\n",
    "We’ll simulate three groups with skewed (log-normal-like) outcomes.\n",
    "\n",
    "- Group A and B have similar typical values\n",
    "- Group C is shifted upward\n",
    "\n",
    "This setup is useful because:\n",
    "- one-way ANOVA relies on (roughly) normal residuals\n",
    "- Kruskal–Wallis is robust to skew/outliers because it works on ranks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c18c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 60\n",
    "\n",
    "# Skewed data: exponentiate normal noise (log-normal-ish)\n",
    "A = np.exp(rng.normal(loc=0.0, scale=0.6, size=n))\n",
    "B = np.exp(rng.normal(loc=0.05, scale=0.6, size=n))\n",
    "C = np.exp(rng.normal(loc=0.35, scale=0.6, size=n))\n",
    "\n",
    "groups = [A, B, C]\n",
    "group_names = [\"A\", \"B\", \"C\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6038268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plot of raw values (skew + group shift)\n",
    "fig = go.Figure()\n",
    "for name, values in zip(group_names, groups):\n",
    "    fig.add_trace(\n",
    "        go.Violin(\n",
    "            y=values,\n",
    "            name=name,\n",
    "            box_visible=True,\n",
    "            meanline_visible=True,\n",
    "            points=\"all\",\n",
    "            jitter=0.25,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Simulated skewed data: raw values by group\",\n",
    "    xaxis_title=\"Group\",\n",
    "    yaxis_title=\"Outcome value\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53bd20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "details = kruskal_wallis_h(*groups)\n",
    "p_value, H_obs, H_perm = kruskal_wallis_permutation_test(*groups, n_perm=8000, seed=SEED)\n",
    "\n",
    "print(\"Kruskal–Wallis (simulation)\")\n",
    "print(\"H (tie-corrected):\", np.round(details[\"H\"], 4))\n",
    "print(\"df:\", details[\"df\"])\n",
    "print(\"Permutation p-value:\", np.round(p_value, 6))\n",
    "print(\"Mean ranks:\", np.round(details[\"mean_ranks\"], 3))\n",
    "print(\"Epsilon^2 (effect size):\", np.round(details[\"epsilon_squared\"], 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abefb9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean ranks summarize the rank shift between groups\n",
    "overall_mean_rank = (details[\"n_total\"] + 1) / 2\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Bar(\n",
    "            x=group_names,\n",
    "            y=details[\"mean_ranks\"],\n",
    "            text=np.round(details[\"mean_ranks\"], 2),\n",
    "            textposition=\"outside\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig.add_hline(y=overall_mean_rank, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"overall mean rank\")\n",
    "fig.update_layout(\n",
    "    title=\"Simulation: mean ranks by group (rank-based signal)\",\n",
    "    xaxis_title=\"Group\",\n",
    "    yaxis_title=\"Mean rank\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb69094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize rank distributions directly\n",
    "pooled = np.concatenate(groups)\n",
    "ranks, _ = rankdata_average(pooled)\n",
    "labels = np.concatenate([np.repeat(name, len(g)) for name, g in zip(group_names, groups)])\n",
    "\n",
    "fig = go.Figure()\n",
    "start = 0\n",
    "for name, g in zip(group_names, groups):\n",
    "    end = start + len(g)\n",
    "    fig.add_trace(\n",
    "        go.Violin(\n",
    "            y=ranks[start:end],\n",
    "            name=name,\n",
    "            box_visible=True,\n",
    "            meanline_visible=True,\n",
    "            points=False,\n",
    "        )\n",
    "    )\n",
    "    start = end\n",
    "\n",
    "fig.add_hline(y=(len(ranks) + 1) / 2, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"overall mean rank\")\n",
    "fig.update_layout(\n",
    "    title=\"Simulation: rank distributions by group\",\n",
    "    xaxis_title=\"Group\",\n",
    "    yaxis_title=\"Rank (pooled)\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4df0e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation distribution of H under the null\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=H_perm, nbinsx=60, name=\"H under H0 (permutations)\", opacity=0.75))\n",
    "fig.add_vline(x=H_obs, line_color=\"crimson\", line_width=3, annotation_text=\"observed H\", annotation_position=\"top\")\n",
    "fig.update_layout(\n",
    "    title=f\"Simulation: permutation distribution of H (p ≈ {p_value:.6f})\",\n",
    "    xaxis_title=\"H statistic\",\n",
    "    yaxis_title=\"Count\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60be92d2",
   "metadata": {},
   "source": [
    "## 8) Tie correction demo\n",
    "\n",
    "Ties happen when:\n",
    "- the measurement is discrete (e.g., integer ratings)\n",
    "- values are rounded\n",
    "- the data have many repeated values\n",
    "\n",
    "Tie correction increases $H$ slightly (because ties reduce rank variance).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8f1fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_tied = np.round(A, 1)\n",
    "B_tied = np.round(B, 1)\n",
    "C_tied = np.round(C, 1)\n",
    "\n",
    "details_tied = kruskal_wallis_h(A_tied, B_tied, C_tied)\n",
    "print(\"With ties (rounded to 0.1)\")\n",
    "print(\"H_uncorrected:\", np.round(details_tied[\"H_uncorrected\"], 4))\n",
    "print(\"tie correction C:\", np.round(details_tied[\"tie_correction_C\"], 6))\n",
    "print(\"H_corrected:\", np.round(details_tied[\"H\"], 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6327f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare rank distributions when ties are introduced\n",
    "pooled_tied = np.concatenate([A_tied, B_tied, C_tied])\n",
    "ranks_tied, tie_counts = rankdata_average(pooled_tied)\n",
    "\n",
    "fig = go.Figure()\n",
    "start = 0\n",
    "for name, g in zip(group_names, [A_tied, B_tied, C_tied]):\n",
    "    end = start + len(g)\n",
    "    fig.add_trace(go.Violin(y=ranks_tied[start:end], name=name, box_visible=True, meanline_visible=True))\n",
    "    start = end\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Ranks with ties present (number of tie groups >1: {len(tie_counts)})\",\n",
    "    xaxis_title=\"Group\",\n",
    "    yaxis_title=\"Rank\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb878f6",
   "metadata": {},
   "source": [
    "## 9) How to interpret and report the result\n",
    "\n",
    "### 9.1 What does a significant result mean?\n",
    "\n",
    "If the p-value is below your significance level (e.g., $\\alpha=0.05$), you reject $H_0$.\n",
    "\n",
    "**Meaning**: the data provide evidence that **at least one group differs** in its distribution (often interpreted as a location/median difference if shapes are similar).\n",
    "\n",
    "### 9.2 What you should report\n",
    "- sample sizes per group\n",
    "- the statistic: $H$ (and whether tie-corrected)\n",
    "- degrees of freedom: $k-1$\n",
    "- p-value\n",
    "- an effect size (e.g., $\\varepsilon^2$ / epsilon-squared)\n",
    "\n",
    "Example write-up:\n",
    "\n",
    "> A Kruskal–Wallis test showed a difference between groups, $H(2)=8.31$, $p=0.015$, $\\varepsilon^2=0.12$.\n",
    "\n",
    "### 9.3 Post-hoc comparisons\n",
    "Kruskal–Wallis does not tell you *which* groups differ. If it’s significant, follow up with pairwise tests (e.g., Mann–Whitney U) and a multiple-comparisons correction (Bonferroni/Holm/Benjamini–Hochberg).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ed9ce7",
   "metadata": {},
   "source": [
    "## 10) Pitfalls and diagnostics\n",
    "\n",
    "- **Independence is crucial**: correlated/repeated measures invalidate the test.\n",
    "- **Different shapes/spreads**: a significant result may be driven by variance/shape differences, not just median shifts.\n",
    "- **Many ties**: use tie correction (built-in above). If ties are extreme, consider exact/permutation approaches.\n",
    "- **Omnibus nature**: significant does not identify which groups differ; use post-hoc tests.\n",
    "- **Practical significance**: always pair p-values with an effect size and plots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7bb370",
   "metadata": {},
   "source": [
    "## 11) Exercises\n",
    "\n",
    "1. Implement a **pairwise post-hoc** routine using permutation tests (with Holm correction).\n",
    "2. Compare permutation p-values vs the $\\chi^2$ approximation for increasing sample sizes.\n",
    "3. Construct a case where group medians are equal but spreads differ. Does Kruskal–Wallis reject?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e517a0",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Kruskal, W. H., & Wallis, W. A. (1952). *Use of ranks in one-criterion variance analysis*.\n",
    "- Conover, W. J. (1999). *Practical Nonparametric Statistics*.\n",
    "- SciPy documentation for `scipy.stats.kruskal` (useful for verification).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
