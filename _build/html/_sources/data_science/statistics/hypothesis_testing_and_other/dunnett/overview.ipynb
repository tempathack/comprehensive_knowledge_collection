{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "375393a8",
   "metadata": {},
   "source": [
    "# Dunnett’s Test — Multiple Comparisons vs a Control\n",
    "\n",
    "Dunnett’s test is designed for experiments where you compare **several treatments to a single control** and want to control the **family-wise error rate (FWER)**.\n",
    "\n",
    "## What you’ll learn\n",
    "- When Dunnett’s test is the right tool (and when it isn’t)\n",
    "- The test statistic and the “multiple comparisons vs control” adjustment\n",
    "- How to interpret **adjusted p-values** and **simultaneous confidence intervals**\n",
    "- A **NumPy-only** implementation (Monte Carlo approximation) with **Plotly** visuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8098dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "# Plotly rendering (CKC convention)\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "# Reproducibility\n",
    "rng = np.random.default_rng(7)\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994ef65",
   "metadata": {},
   "source": [
    "## 1) When to use Dunnett’s test\n",
    "\n",
    "Use Dunnett’s test when:\n",
    "- You have **one control group** and **m treatment groups**.\n",
    "- You care about **treatment vs control** comparisons (not every pair).\n",
    "- You want to control the probability of *any* false positive across those m tests (**FWER ≤ α**).\n",
    "\n",
    "Typical examples:\n",
    "- **Dose–response** studies (multiple doses vs placebo)\n",
    "- **A/B/n** experiments with a baseline\n",
    "- **Regression testing** (new versions vs current control)\n",
    "\n",
    "Not the right tool if:\n",
    "- You want **all pairwise comparisons** (use **Tukey’s HSD**).\n",
    "- Variances differ strongly between groups (consider **Welch-type** approaches).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bfcf6a",
   "metadata": {},
   "source": [
    "## 2) What problem it solves (multiple testing)\n",
    "\n",
    "For each treatment group *i* (compared to control *c*), the hypotheses are:\n",
    "\n",
    "- Two-sided:  \n",
    "  $H_{0,i}: \\mu_i = \\mu_c$ vs $H_{1,i}: \\mu_i \\ne \\mu_c$\n",
    "\n",
    "- One-sided (greater):  \n",
    "  $H_{0,i}: \\mu_i \\le \\mu_c$ vs $H_{1,i}: \\mu_i > \\mu_c$\n",
    "\n",
    "If you run *m* separate tests at level $\\alpha$, the chance of getting **at least one** false positive grows with *m*.\n",
    "Under independence (a useful intuition),\n",
    "\n",
    "$$\\mathrm{FWER} = 1 - (1 - \\alpha)^m.$$\n",
    "\n",
    "Dunnett’s test chooses a **single critical value** so that the *maximal* evidence against $H_0$ across treatments triggers a rejection only with probability $\\alpha$ under the global null.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d378f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "m = np.arange(1, 21)\n",
    "\n",
    "fwer_independent = 1 - (1 - alpha) ** m\n",
    "\n",
    "fig = px.line(\n",
    "    x=m,\n",
    "    y=fwer_independent,\n",
    "    markers=True,\n",
    "    labels={\"x\": \"Number of comparisons (m)\", \"y\": \"FWER (independence intuition)\"},\n",
    "    title=\"Why multiple t-tests inflate false positives\",\n",
    ")\n",
    "fig.add_hline(y=alpha, line_dash=\"dash\", annotation_text=\"Target α\", annotation_position=\"bottom right\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3fecaa",
   "metadata": {},
   "source": [
    "## 3) Key idea: correlated t-statistics\n",
    "\n",
    "All comparisons share the **same control mean**, so the treatment-vs-control statistics are **correlated**.\n",
    "Dunnett’s test uses the joint distribution of these correlated statistics to get a critical value $c_\\alpha$ such that:\n",
    "\n",
    "- Two-sided version:\n",
    "  $$\\mathbb{P}\\left(\\max_{i=1..m} |T_i| > c_\\alpha\\right) = \\alpha.$$\n",
    "\n",
    "This controls **FWER** and is typically **less conservative than Bonferroni**, because it accounts for correlation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34106d22",
   "metadata": {},
   "source": [
    "## 4) Model & assumptions\n",
    "\n",
    "Dunnett’s test is built on the one-way ANOVA model:\n",
    "\n",
    "$$y_{gj} = \\mu_g + \\varepsilon_{gj}, \\qquad \\varepsilon_{gj} \\overset{iid}{\\sim} \\mathcal{N}(0,\\sigma^2)$$\n",
    "\n",
    "Assumptions (the same spirit as pooled-variance ANOVA):\n",
    "- observations are independent\n",
    "- residuals are approximately normal (often reasonably robust for moderate *n*)\n",
    "- **homoscedasticity**: all groups share the same variance $\\sigma^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f7dfdc",
   "metadata": {},
   "source": [
    "## 5) Test statistic (pooled-variance, ANOVA-style)\n",
    "\n",
    "Let:\n",
    "- control size $n_c$ and treatment size $n_i$\n",
    "- sample means $\\bar y_c$ and $\\bar y_i$\n",
    "- pooled within-group mean square $\\mathrm{MSE}$ (from one-way ANOVA)\n",
    "- degrees of freedom $\\mathrm{df} = N_{\\text{total}} - k$ where $k$ is the number of groups\n",
    "\n",
    "Then for each treatment *i*:\n",
    "\n",
    "$$T_i = \\frac{\\bar y_i - \\bar y_c}{\\sqrt{\\mathrm{MSE}\\,(1/n_i + 1/n_c)}}.$$\n",
    "\n",
    "Dunnett’s test differs from running *m* t-tests not by the statistic, but by the **multiple-comparison adjustment** used for decisions, p-values, and confidence intervals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd9cb9",
   "metadata": {},
   "source": [
    "## 6) Correlation structure (why “Dunnett” is special)\n",
    "\n",
    "For two different treatments *i* and *j*, the differences $\\bar y_i - \\bar y_c$ and $\\bar y_j - \\bar y_c$ share the same control mean.\n",
    "That induces positive correlation.\n",
    "\n",
    "A convenient approximation for the correlation of the standardized mean differences is:\n",
    "\n",
    "$$\\mathrm{Corr}(T_i, T_j) \\approx \\frac{1}{\\sqrt{(1 + n_c/n_i)(1 + n_c/n_j)}} \\quad (i\\ne j).$$\n",
    "\n",
    "Balanced design example: if $n_c = n_i = n$, then $\\mathrm{Corr}(T_i, T_j) = 1/2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c555aa",
   "metadata": {},
   "source": [
    "## 7) NumPy-only Dunnett via Monte Carlo (educational, but accurate with enough samples)\n",
    "\n",
    "The exact Dunnett p-values/critical values come from a **multivariate t distribution**.\n",
    "Instead of calling a stats library, we’ll simulate it directly:\n",
    "\n",
    "1. Build the correlation matrix $R$ of the treatment-vs-control statistics.\n",
    "2. Sample $Z \\sim \\mathcal{N}(0, R)$.\n",
    "3. Sample an independent $U \\sim \\chi^2_{\\mathrm{df}}$.\n",
    "4. Form $T = Z / \\sqrt{U/\\mathrm{df}}$ (this is multivariate t).\n",
    "5. Use the distribution of $\\max_i |T_i|$ to get a critical value and adjusted p-values.\n",
    "\n",
    "This is the core principle behind Dunnett’s adjustment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abab5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Literal, Tuple\n",
    "\n",
    "Alternative = Literal[\"two-sided\", \"greater\", \"less\"]\n",
    "\n",
    "\n",
    "def pooled_mse(groups: Dict[str, np.ndarray]) -> Tuple[float, int]:\n",
    "    '''Pooled within-group mean square (ANOVA MSE).\n",
    "\n",
    "    MSE = SSE / df, where SSE = sum_g sum_j (y_gj - mean_g)^2\n",
    "    and df = N_total - k_groups.\n",
    "    '''\n",
    "    if len(groups) < 2:\n",
    "        raise ValueError(\"Need at least two groups (including control).\")\n",
    "\n",
    "    sse = 0.0\n",
    "    n_total = 0\n",
    "    for x in groups.values():\n",
    "        x = np.asarray(x, dtype=float)\n",
    "        if x.ndim != 1:\n",
    "            raise ValueError(\"Each group must be a 1D array.\")\n",
    "        n_total += x.size\n",
    "        sse += float(np.sum((x - x.mean()) ** 2))\n",
    "\n",
    "    k = len(groups)\n",
    "    df = n_total - k\n",
    "    if df <= 0:\n",
    "        raise ValueError(\"Not enough total samples to estimate pooled variance.\")\n",
    "\n",
    "    return sse / df, int(df)\n",
    "\n",
    "\n",
    "def dunnett_corr(n_control: int, n_treatments: np.ndarray) -> np.ndarray:\n",
    "    '''Correlation matrix for treatment-vs-control standardized mean differences.'''\n",
    "    n_treatments = np.asarray(n_treatments, dtype=float)\n",
    "    if np.any(n_treatments <= 0) or n_control <= 0:\n",
    "        raise ValueError(\"Sample sizes must be positive.\")\n",
    "\n",
    "    a = 1.0 + (n_control / n_treatments)\n",
    "    corr = 1.0 / np.sqrt(np.outer(a, a))\n",
    "    np.fill_diagonal(corr, 1.0)\n",
    "    return corr\n",
    "\n",
    "\n",
    "def dunnett_t_stats(\n",
    "    groups: Dict[str, np.ndarray],\n",
    "    control: str,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, float, int]:\n",
    "    '''Compute Dunnett t-statistics vs control.\n",
    "\n",
    "    Returns (treat_names, diffs, t_stats, mse, df)\n",
    "    '''\n",
    "    if control not in groups:\n",
    "        raise KeyError(f\"Control group '{control}' not found.\")\n",
    "\n",
    "    mse, df = pooled_mse(groups)\n",
    "\n",
    "    names = [g for g in groups.keys() if g != control]\n",
    "    if len(names) == 0:\n",
    "        raise ValueError(\"Need at least one treatment group besides control.\")\n",
    "\n",
    "    y_c = np.asarray(groups[control], dtype=float)\n",
    "    n_c = y_c.size\n",
    "    mean_c = float(y_c.mean())\n",
    "\n",
    "    diffs = []\n",
    "    t_stats = []\n",
    "\n",
    "    for g in names:\n",
    "        y = np.asarray(groups[g], dtype=float)\n",
    "        n_i = y.size\n",
    "        diff = float(y.mean()) - mean_c\n",
    "        se = float(np.sqrt(mse * (1.0 / n_i + 1.0 / n_c)))\n",
    "        diffs.append(diff)\n",
    "        t_stats.append(diff / se)\n",
    "\n",
    "    return np.array(names), np.array(diffs, dtype=float), np.array(t_stats, dtype=float), float(mse), int(df)\n",
    "\n",
    "\n",
    "def simulate_max_stat(\n",
    "    df: int,\n",
    "    corr: np.ndarray,\n",
    "    n_sim: int,\n",
    "    alternative: Alternative,\n",
    "    rng: np.random.Generator,\n",
    ") -> np.ndarray:\n",
    "    '''Simulate the max statistic used by Dunnett’s adjustment.'''\n",
    "    corr = np.asarray(corr, dtype=float)\n",
    "    if corr.ndim != 2 or corr.shape[0] != corr.shape[1]:\n",
    "        raise ValueError(\"corr must be a square matrix\")\n",
    "\n",
    "    m = corr.shape[0]\n",
    "    if m < 1:\n",
    "        raise ValueError(\"Need at least one treatment.\")\n",
    "\n",
    "    L = np.linalg.cholesky(corr)\n",
    "    z = rng.standard_normal((n_sim, m)) @ L.T\n",
    "\n",
    "    u = rng.chisquare(df, size=n_sim) / df\n",
    "    t = z / np.sqrt(u)[:, None]\n",
    "\n",
    "    if alternative == \"two-sided\":\n",
    "        return np.max(np.abs(t), axis=1)\n",
    "    if alternative == \"greater\":\n",
    "        return np.max(t, axis=1)\n",
    "    if alternative == \"less\":\n",
    "        return np.max(-t, axis=1)\n",
    "\n",
    "    raise ValueError(\"alternative must be 'two-sided', 'greater', or 'less'.\")\n",
    "\n",
    "\n",
    "def dunnett_test(\n",
    "    groups: Dict[str, np.ndarray],\n",
    "    control: str,\n",
    "    alpha: float = 0.05,\n",
    "    alternative: Alternative = \"two-sided\",\n",
    "    n_sim: int = 200_000,\n",
    "    seed: int = 7,\n",
    ") -> Dict[str, object]:\n",
    "    '''Monte Carlo Dunnett test (NumPy-only).\n",
    "\n",
    "    Returns a dict containing:\n",
    "    - names: treatment names\n",
    "    - diffs: mean(treatment) - mean(control)\n",
    "    - t: t-statistics\n",
    "    - p_adj: Dunnett-adjusted p-values (single-step)\n",
    "    - ci_low, ci_high: simultaneous CI for mean differences (two-sided)\n",
    "    - crit: Dunnett critical value for the max statistic\n",
    "    - mse, df: pooled variance estimate and df\n",
    "    - corr: correlation matrix among T_i\n",
    "    '''\n",
    "    if not (0 < alpha < 1):\n",
    "        raise ValueError(\"alpha must be in (0,1).\")\n",
    "\n",
    "    names, diffs, t_stats, mse, df = dunnett_t_stats(groups, control)\n",
    "\n",
    "    n_c = int(np.asarray(groups[control]).size)\n",
    "    n_t = np.array([int(np.asarray(groups[g]).size) for g in names], dtype=int)\n",
    "    corr = dunnett_corr(n_c, n_t)\n",
    "\n",
    "    sim_rng = np.random.default_rng(seed)\n",
    "    max_stat = simulate_max_stat(df=df, corr=corr, n_sim=n_sim, alternative=alternative, rng=sim_rng)\n",
    "\n",
    "    crit = float(np.quantile(max_stat, 1 - alpha))\n",
    "\n",
    "    if alternative == \"two-sided\":\n",
    "        t_for_p = np.abs(t_stats)\n",
    "    elif alternative == \"greater\":\n",
    "        t_for_p = t_stats\n",
    "    else:\n",
    "        t_for_p = -t_stats\n",
    "\n",
    "    p_adj = np.array([(max_stat >= float(t0)).mean() for t0 in t_for_p], dtype=float)\n",
    "\n",
    "    # Two-sided simultaneous CI for mean differences\n",
    "    se = np.sqrt(mse * (1.0 / n_t + 1.0 / n_c))\n",
    "    ci_low = diffs - crit * se\n",
    "    ci_high = diffs + crit * se\n",
    "\n",
    "    reject = p_adj < alpha\n",
    "\n",
    "    return {\n",
    "        \"names\": names,\n",
    "        \"diffs\": diffs,\n",
    "        \"t\": t_stats,\n",
    "        \"p_adj\": p_adj,\n",
    "        \"ci_low\": ci_low,\n",
    "        \"ci_high\": ci_high,\n",
    "        \"reject\": reject,\n",
    "        \"crit\": crit,\n",
    "        \"mse\": mse,\n",
    "        \"df\": df,\n",
    "        \"corr\": corr,\n",
    "        \"max_stat_sim\": max_stat,\n",
    "        \"alternative\": alternative,\n",
    "        \"alpha\": alpha,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80093717",
   "metadata": {},
   "source": [
    "## 8) Worked example (with visuals)\n",
    "\n",
    "We’ll simulate a small experiment with one control and three treatments.\n",
    "Two treatments have real effects, one does not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d935a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    \"Control\": rng.normal(loc=0.0, scale=1.0, size=22),\n",
    "    \"Dose 1\": rng.normal(loc=0.25, scale=1.0, size=20),\n",
    "    \"Dose 2\": rng.normal(loc=0.75, scale=1.0, size=18),\n",
    "    \"Dose 3\": rng.normal(loc=0.00, scale=1.0, size=24),\n",
    "}\n",
    "\n",
    "{g: (x.size, float(x.mean())) for g, x in groups.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83837818",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for name, x in groups.items():\n",
    "    fig.add_trace(go.Violin(y=x, name=name, box_visible=True, meanline_visible=True))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Simulated data by group\",\n",
    "    yaxis_title=\"Outcome\",\n",
    "    violinmode=\"group\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac986c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = dunnett_test(groups, control=\"Control\", alpha=0.05, alternative=\"two-sided\", n_sim=250_000, seed=1)\n",
    "res[\"crit\"], res[\"df\"], res[\"mse\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136147b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(res: Dict[str, object]) -> None:\n",
    "    names = res[\"names\"]\n",
    "    diffs = res[\"diffs\"]\n",
    "    t = res[\"t\"]\n",
    "    p = res[\"p_adj\"]\n",
    "    lo = res[\"ci_low\"]\n",
    "    hi = res[\"ci_high\"]\n",
    "    reject = res[\"reject\"]\n",
    "\n",
    "    header = f\"{'Treatment':<12} {'Diff':>9} {'t':>9} {'p_adj':>10} {'CI_low':>10} {'CI_high':>10} {'Reject':>8}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    for i in range(len(names)):\n",
    "        print(\n",
    "            f\"{str(names[i]):<12} \"\n",
    "            f\"{diffs[i]:9.4f} \"\n",
    "            f\"{t[i]:9.4f} \"\n",
    "            f\"{p[i]:10.4f} \"\n",
    "            f\"{lo[i]:10.4f} \"\n",
    "            f\"{hi[i]:10.4f} \"\n",
    "            f\"{str(bool(reject[i])):>8}\"\n",
    "        )\n",
    "\n",
    "print_results(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9306f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = res[\"names\"]\n",
    "diffs = res[\"diffs\"]\n",
    "lo = res[\"ci_low\"]\n",
    "hi = res[\"ci_high\"]\n",
    "reject = res[\"reject\"]\n",
    "\n",
    "colors = np.where(reject, \"#d62728\", \"#1f77b4\")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=names,\n",
    "        y=diffs,\n",
    "        marker_color=colors,\n",
    "        error_y=dict(type=\"data\", array=hi - diffs, arrayminus=diffs - lo),\n",
    "        name=\"Mean difference\",\n",
    "    )\n",
    ")\n",
    "fig.add_hline(y=0, line_dash=\"dash\")\n",
    "fig.update_layout(\n",
    "    title=\"Treatment − Control mean differences with Dunnett simultaneous CI\",\n",
    "    yaxis_title=\"Mean difference\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98170dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = res[\"corr\"]\n",
    "\n",
    "fig = px.imshow(\n",
    "    corr,\n",
    "    text_auto=\".2f\",\n",
    "    color_continuous_scale=\"Blues\",\n",
    "    title=\"Correlation among treatment-vs-control t-statistics\",\n",
    "    labels=dict(x=\"Treatment\", y=\"Treatment\", color=\"corr\"),\n",
    ")\n",
    "fig.update_xaxes(ticktext=res[\"names\"], tickvals=list(range(len(res[\"names\"])) ))\n",
    "fig.update_yaxes(ticktext=res[\"names\"], tickvals=list(range(len(res[\"names\"])) ))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4f6b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_stat = res[\"max_stat_sim\"]\n",
    "crit = res[\"crit\"]\n",
    "obs = np.abs(res[\"t\"])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=max_stat, nbinsx=60, name=\"Simulated max |T|\", opacity=0.75))\n",
    "fig.add_vline(x=crit, line_dash=\"dash\", line_color=\"black\", annotation_text=f\"crit ≈ {crit:.3f}\")\n",
    "for t0 in obs:\n",
    "    fig.add_vline(x=float(t0), line_color=\"red\", opacity=0.35)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Dunnett null distribution: max |T| (Monte Carlo)\",\n",
    "    xaxis_title=\"max |T|\",\n",
    "    yaxis_title=\"count\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8217e63d",
   "metadata": {},
   "source": [
    "## 9) How to interpret Dunnett results\n",
    "\n",
    "For each treatment vs control:\n",
    "\n",
    "- **Adjusted p-value**: the probability (under the global null) that *any* comparison would look at least this extreme.  \n",
    "  If `p_adj < α`, you can claim that treatment differs from control **while controlling FWER**.\n",
    "\n",
    "- **Sign of the difference / t-statistic**: direction of the effect (treatment higher vs lower than control).\n",
    "\n",
    "- **Simultaneous confidence interval**: a set of intervals for all treatment–control differences such that\n",
    "  all of them are correct at once with probability $1-\\alpha$.\n",
    "  If the CI excludes 0, it matches the “reject” decision.\n",
    "\n",
    "What it does **not** mean:\n",
    "- `p_adj = 0.03` is not the probability the null is true.\n",
    "- A non-rejection does not prove equality; it means “not enough evidence given the noise and sample sizes.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ce0ba",
   "metadata": {},
   "source": [
    "## 10) Quick insight: FWER control (simulation)\n",
    "\n",
    "Below we simulate the *global null* and compare how often we get **at least one** false positive.\n",
    "\n",
    "- **Naive**: compare each treatment to control at level $\\alpha$.\n",
    "- **Bonferroni**: compare each at level $\\alpha/m$.\n",
    "- **Dunnett**: use the max-|T| critical value.\n",
    "\n",
    "Everything uses the same df and correlation induced by the shared control.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e8bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_abs_t(df: int, n_sim: int, rng: np.random.Generator) -> np.ndarray:\n",
    "    z = rng.standard_normal(n_sim)\n",
    "    u = rng.chisquare(df, size=n_sim) / df\n",
    "    return np.abs(z / np.sqrt(u))\n",
    "\n",
    "\n",
    "m = len(res[\"names\"])\n",
    "df = int(res[\"df\"])\n",
    "\n",
    "sim_rng = np.random.default_rng(123)\n",
    "abs_t = simulate_abs_t(df=df, n_sim=400_000, rng=sim_rng)\n",
    "\n",
    "crit_unadj = float(np.quantile(abs_t, 1 - alpha))\n",
    "crit_bonf = float(np.quantile(abs_t, 1 - alpha / m))\n",
    "crit_dun = float(res[\"crit\"])\n",
    "\n",
    "crit_unadj, crit_bonf, crit_dun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e563980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate multivariate t under the global null\n",
    "n_exp = 80_000\n",
    "\n",
    "sim_rng = np.random.default_rng(456)\n",
    "L = np.linalg.cholesky(res[\"corr\"])\n",
    "z = sim_rng.standard_normal((n_exp, m)) @ L.T\n",
    "u = sim_rng.chisquare(df, size=n_exp) / df\n",
    "T = z / np.sqrt(u)[:, None]\n",
    "\n",
    "any_unadj = (np.abs(T) > crit_unadj).any(axis=1)\n",
    "any_bonf = (np.abs(T) > crit_bonf).any(axis=1)\n",
    "any_dun = (np.abs(T) > crit_dun).any(axis=1)\n",
    "\n",
    "fwer = {\n",
    "    \"Naive (α per test)\": float(any_unadj.mean()),\n",
    "    \"Bonferroni\": float(any_bonf.mean()),\n",
    "    \"Dunnett\": float(any_dun.mean()),\n",
    "}\n",
    "\n",
    "fig = px.bar(\n",
    "    x=list(fwer.keys()),\n",
    "    y=list(fwer.values()),\n",
    "    labels={\"x\": \"Method\", \"y\": \"Empirical FWER under global null\"},\n",
    "    title=f\"FWER control at α={alpha} (Monte Carlo)\",\n",
    ")\n",
    "fig.add_hline(y=alpha, line_dash=\"dash\", annotation_text=\"Target α\", annotation_position=\"bottom right\")\n",
    "fig.update_yaxes(range=[0, max(list(fwer.values()) + [alpha]) * 1.25])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeed107",
   "metadata": {},
   "source": [
    "## 11) Pitfalls & diagnostics\n",
    "\n",
    "- **Heteroscedasticity** (unequal variances) can distort pooled-variance methods; check residual spread by group.\n",
    "- **Non-normality** can matter for small *n*; use residual plots and consider robust/nonparametric alternatives.\n",
    "- **Only vs control**: if you later start caring about treatment-vs-treatment, switch to an all-pairs method.\n",
    "- **Power**: Dunnett is usually more powerful than Bonferroni for the same FWER because it leverages correlation.\n",
    "\n",
    "Practical workflow:\n",
    "1. Inspect plots (group distributions, residuals).\n",
    "2. If assumptions look reasonable, run Dunnett.\n",
    "3. Report mean differences with simultaneous CIs and adjusted p-values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08599ed6",
   "metadata": {},
   "source": [
    "## 12) Exercises\n",
    "\n",
    "1. Increase `n_sim` and see how stable the critical value `res[\"crit\"]` becomes.\n",
    "2. Make the design balanced (same *n* for all groups) and verify that the correlation off-diagonal is close to 0.5.\n",
    "3. Change `alternative` to `\"greater\"` and interpret the results when effects are negative.\n",
    "\n",
    "## References\n",
    "- Dunnett, C. W. (1955). *A multiple comparison procedure for comparing several treatments with a control.*\n",
    "- Many statistical software packages implement exact Dunnett p-values via multivariate t CDFs; this notebook uses Monte Carlo to keep the mechanics transparent.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
