{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doubly Truncated Weibull Minimum Distribution (`truncweibull_min`)\n",
    "\n",
    "`scipy.stats.truncweibull_min` is the **Weibull minimum** distribution restricted to an interval and re-normalized.\n",
    "Truncation is common when you only observe values within a window (instrument limits, study design, reporting rules) but the underlying phenomenon is still reasonably Weibull.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "- Write down the PDF/CDF/PPF and understand how truncation re-normalizes a base Weibull.\n",
    "- Compute moments using incomplete gamma functions and verify them numerically.\n",
    "- Interpret how the parameters `(c, a, b, loc, scale)` change the shape and the support.\n",
    "- Sample from the distribution with a **NumPy-only** inverse-transform algorithm.\n",
    "- Use `scipy.stats.truncweibull_min` for evaluation, simulation, and fitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook roadmap\n",
    "1) Title & classification\n",
    "2) Intuition & motivation\n",
    "3) Formal definition (PDF/CDF/PPF)\n",
    "4) Moments & properties\n",
    "5) Parameter interpretation\n",
    "6) Derivations (expectation, variance, likelihood)\n",
    "7) Sampling & simulation (NumPy-only)\n",
    "8) Visualization (PDF, CDF, Monte Carlo)\n",
    "9) SciPy integration (`scipy.stats.truncweibull_min`)\n",
    "10) Statistical use cases\n",
    "11) Pitfalls\n",
    "12) Summary\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- comfort with PDF/CDF and expectation\n",
    "- basic calculus substitutions\n",
    "- familiarity with the Gamma / incomplete Gamma functions (helpful but not required)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import scipy\n",
    "from scipy import integrate, optimize, special, stats\n",
    "from scipy.stats import truncweibull_min\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Record versions for reproducibility.\n",
    "VERSIONS = {\"numpy\": np.__version__, \"scipy\": scipy.__version__, \"plotly\": plotly.__version__}\n",
    "VERSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Title & Classification\n",
    "\n",
    "| Item | Value |\n",
    "|---|---|\n",
    "| Name | `truncweibull_min` (SciPy: `scipy.stats.truncweibull_min`) |\n",
    "| Type | Continuous |\n",
    "| Base distribution | Weibull minimum (`weibull_min`) |\n",
    "| Support (standardized) | $x \\in (a, b]$ |\n",
    "| Parameter space | $c>0$, $0\\le a<b\\le\\infty$ |\n",
    "| Location/scale | `loc ∈ ℝ`, `scale > 0` |\n",
    "\n",
    "SciPy defines the truncation bounds **in standardized form**:\n",
    "\n",
    "$$\n",
    "a = \\frac{u_\\ell - \\mathrm{loc}}{\\mathrm{scale}},\n",
    "\\qquad\n",
    "b = \\frac{u_r - \\mathrm{loc}}{\\mathrm{scale}},\n",
    "$$\n",
    "\n",
    "so the support in the original units is\n",
    "\n",
    "$$\n",
    "x \\in (u_\\ell, u_r] = (\\mathrm{loc} + a\\,\\mathrm{scale},\\; \\mathrm{loc} + b\\,\\mathrm{scale}].\n",
    "$$\n",
    "\n",
    "Unless stated otherwise, we work in the **standardized form** (`loc=0`, `scale=1`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Intuition & Motivation\n",
    "\n",
    "### What it models\n",
    "\n",
    "The Weibull minimum distribution is a staple model for **time-to-failure / lifetime** phenomena.\n",
    "A **truncated** Weibull is appropriate when the *physical process is still Weibull-like*, but you only observe outcomes inside a window:\n",
    "\n",
    "- **Left truncation** (e.g., detection limits): values below a threshold are unobservable.\n",
    "- **Right truncation** (e.g., instrument saturation, administrative cutoffs): values above a threshold are not recorded.\n",
    "- **Double truncation**: both happen.\n",
    "\n",
    "Truncation is not the same as censoring: with truncation, observations outside the window **never appear** in the dataset.\n",
    "\n",
    "### Typical real-world use cases\n",
    "\n",
    "- **Reliability testing** with a fixed observation period (components only recorded if they fail between times $u_\\ell$ and $u_r$).\n",
    "- **Survival analysis** with delayed entry (left truncation) and administrative endpoints (right truncation).\n",
    "- **Environmental measurements** (wind speeds, rainfall intensities) where sensors have detection/saturation limits.\n",
    "\n",
    "### Relations to other distributions\n",
    "\n",
    "- As $a\\to 0$ and $b\\to\\infty$, `truncweibull_min` reduces to the standard **Weibull minimum** distribution.\n",
    "- When $c=1$, Weibull becomes **Exponential**, and `truncweibull_min` becomes a **truncated exponential**.\n",
    "- When $c=2$ (with a suitable scale), Weibull relates to the **Rayleigh** distribution.\n",
    "- It is a special case of a generic **truncated distribution**: conditioning a base distribution to lie in $(a,b]$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Formal Definition\n",
    "\n",
    "### Base Weibull (standardized)\n",
    "\n",
    "For shape parameter $c>0$, the (standardized) Weibull minimum distribution has\n",
    "\n",
    "$$\n",
    "f_W(x;c) = c\\,x^{c-1} e^{-x^c},\\qquad x>0,\n",
    "$$\n",
    "\n",
    "$$\n",
    "F_W(x;c) = 1 - e^{-x^c},\\qquad x\\ge 0.\n",
    "$$\n",
    "\n",
    "Its survival function is $S_W(x;c)=e^{-x^c}$.\n",
    "\n",
    "### Truncated Weibull minimum\n",
    "\n",
    "Define the normalization constant\n",
    "\n",
    "$$\n",
    "Z(c,a,b) = \\mathbb{P}(a < W \\le b) = F_W(b;c) - F_W(a;c) = e^{-a^c} - e^{-b^c}.\n",
    "$$\n",
    "\n",
    "Then the truncated density is\n",
    "\n",
    "$$\n",
    "f(x; c,a,b) = \\frac{f_W(x;c)}{Z(c,a,b)}\n",
    "= \\frac{c\\,x^{c-1} e^{-x^c}}{e^{-a^c} - e^{-b^c}},\n",
    "\\qquad a < x \\le b.\n",
    "$$\n",
    "\n",
    "The CDF is\n",
    "\n",
    "$$\n",
    "F(x;c,a,b)=\n",
    "\\begin{cases}\n",
    "0, & x\\le a,\\\\\n",
    "\\dfrac{F_W(x;c)-F_W(a;c)}{F_W(b;c)-F_W(a;c)}\n",
    "=\\dfrac{e^{-a^c}-e^{-x^c}}{e^{-a^c}-e^{-b^c}}, & a < x \\le b,\\\\\n",
    "1, & x > b.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "A convenient form for the quantile function (PPF) is obtained by solving for $e^{-x^c}$:\n",
    "\n",
    "$$\n",
    "F^{-1}(q;c,a,b)\n",
    "= \\Bigl(-\\log\\bigl((1-q)e^{-a^c} + q e^{-b^c}\\bigr)\\Bigr)^{1/c},\\qquad 0<q<1.\n",
    "$$\n",
    "\n",
    "### Location/scale\n",
    "\n",
    "If $Y\\sim\\mathrm{truncweibull\\_min}(c,a,b)$ in standardized form, then\n",
    "\n",
    "$$\n",
    "X = \\mathrm{loc} + \\mathrm{scale}\\,Y\n",
    "$$\n",
    "\n",
    "has support $(\\mathrm{loc}+a\\,\\mathrm{scale},\\; \\mathrm{loc}+b\\,\\mathrm{scale}]$ and\n",
    "\n",
    "$$\n",
    "f_X(x)=\\frac{1}{\\mathrm{scale}} f_Y\\!\\left(\\frac{x-\\mathrm{loc}}{\\mathrm{scale}}\\right).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _logZ_truncweibull_min(c: float, a: float, b: float) -> float:\n",
    "    \"\"\"Stable log normalizer log(exp(-a^c) - exp(-b^c)).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    For b = inf, this is simply -a^c.\n",
    "    \"\"\"\n",
    "    if not (c > 0):\n",
    "        raise ValueError(\"c must be > 0\")\n",
    "    if not (a >= 0):\n",
    "        raise ValueError(\"a must be >= 0\")\n",
    "    if not (b > a):\n",
    "        raise ValueError(\"b must be > a\")\n",
    "\n",
    "    A = a**c\n",
    "    if np.isinf(b):\n",
    "        return -A\n",
    "\n",
    "    B = b**c\n",
    "    # exp(-A) - exp(-B) = exp(-A) * (1 - exp(-(B-A)))\n",
    "    return -A + np.log1p(-np.exp(-(B - A)))\n",
    "\n",
    "\n",
    "def truncweibull_min_logpdf(x: np.ndarray, c: float, a: float, b: float) -> np.ndarray:\n",
    "    \"\"\"Log-PDF of the standardized truncweibull_min(c, a, b).\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    logpdf = np.full_like(x, fill_value=-np.inf)\n",
    "    mask = (x > a) & (x <= b)\n",
    "    if not np.any(mask):\n",
    "        return logpdf\n",
    "\n",
    "    logZ = _logZ_truncweibull_min(c, a, b)\n",
    "    xm = x[mask]\n",
    "    logpdf[mask] = np.log(c) + (c - 1.0) * np.log(xm) - xm**c - logZ\n",
    "    return logpdf\n",
    "\n",
    "\n",
    "def truncweibull_min_pdf(x: np.ndarray, c: float, a: float, b: float) -> np.ndarray:\n",
    "    \"\"\"PDF of the standardized truncweibull_min(c, a, b).\"\"\"\n",
    "    return np.exp(truncweibull_min_logpdf(x, c, a, b))\n",
    "\n",
    "\n",
    "def truncweibull_min_cdf(x: np.ndarray, c: float, a: float, b: float) -> np.ndarray:\n",
    "    \"\"\"CDF of the standardized truncweibull_min(c, a, b).\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    out = np.zeros_like(x)\n",
    "\n",
    "    out[x > b] = 1.0\n",
    "    mask = (x > a) & (x <= b)\n",
    "    if not np.any(mask):\n",
    "        return out\n",
    "\n",
    "    A = a**c\n",
    "    xm = x[mask]\n",
    "    delta_x = xm**c - A\n",
    "\n",
    "    # Numerator: exp(-a^c) - exp(-x^c) = exp(-a^c) * (1 - exp(-(x^c-a^c)))\n",
    "    num = -np.expm1(-delta_x)\n",
    "\n",
    "    if np.isinf(b):\n",
    "        out[mask] = num\n",
    "        return out\n",
    "\n",
    "    delta_b = b**c - A\n",
    "    den = -np.expm1(-delta_b)\n",
    "    out[mask] = num / den\n",
    "    return out\n",
    "\n",
    "\n",
    "def truncweibull_min_ppf(q: np.ndarray, c: float, a: float, b: float) -> np.ndarray:\n",
    "    \"\"\"PPF (quantile function) of the standardized truncweibull_min(c, a, b).\"\"\"\n",
    "    q = np.asarray(q, dtype=float)\n",
    "    if np.any((q < 0) | (q > 1)):\n",
    "        raise ValueError(\"q must be in [0, 1]\")\n",
    "\n",
    "    A = a**c\n",
    "    sa = np.exp(-A)\n",
    "    sb = 0.0 if np.isinf(b) else np.exp(-(b**c))\n",
    "\n",
    "    s = (1.0 - q) * sa + q * sb\n",
    "    return (-np.log(s)) ** (1.0 / c)\n",
    "\n",
    "\n",
    "# Sanity check against SciPy\n",
    "c0, a0, b0 = 2.5, 0.3, 2.0\n",
    "x = np.linspace(a0 + 1e-6, b0, 500)\n",
    "q = np.linspace(1e-6, 1 - 1e-6, 500)\n",
    "\n",
    "pdf_err = np.max(np.abs(truncweibull_min_pdf(x, c0, a0, b0) - truncweibull_min.pdf(x, c0, a0, b0)))\n",
    "cdf_err = np.max(np.abs(truncweibull_min_cdf(x, c0, a0, b0) - truncweibull_min.cdf(x, c0, a0, b0)))\n",
    "ppf_err = np.max(np.abs(truncweibull_min_ppf(q, c0, a0, b0) - truncweibull_min.ppf(q, c0, a0, b0)))\n",
    "\n",
    "pdf_err, cdf_err, ppf_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Moments & Properties\n",
    "\n",
    "### Raw moments\n",
    "\n",
    "For $k\\ge 0$, the $k$-th raw moment exists (and is finite) whenever the support avoids $0$ or the left tail is integrable.\n",
    "For the standardized distribution with truncation $(a,b]$ and $a\\ge 0$:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^k]\n",
    "= \\frac{\\int_a^b x^k\\,c x^{c-1} e^{-x^c}\\,dx}{e^{-a^c} - e^{-b^c}}.\n",
    "$$\n",
    "\n",
    "With the substitution $t=x^c$, this becomes an incomplete gamma integral:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^k]\n",
    "= \\frac{\\gamma\\!\\left(1+\\frac{k}{c},\\,b^c\\right)\n",
    "        -\\gamma\\!\\left(1+\\frac{k}{c},\\,a^c\\right)}{e^{-a^c} - e^{-b^c}},\n",
    "$$\n",
    "\n",
    "where $\\gamma(s,x)$ is the **lower incomplete gamma** function.\n",
    "\n",
    "### Mean / variance / skewness / kurtosis\n",
    "\n",
    "Let $m_k = \\mathbb{E}[X^k]$. Then\n",
    "\n",
    "- Mean: $\\mu=m_1$\n",
    "- Variance: $\\sigma^2 = m_2 - m_1^2$\n",
    "- Skewness: $\\gamma_1 = \\mathbb{E}[(X-\\mu)^3]/\\sigma^3$\n",
    "- Excess kurtosis: $\\gamma_2 = \\mathbb{E}[(X-\\mu)^4]/\\sigma^4 - 3$\n",
    "\n",
    "### MGF / characteristic function\n",
    "\n",
    "The moment generating function (MGF) is\n",
    "\n",
    "$$\n",
    "M_X(t)=\\mathbb{E}[e^{tX}] = \\int_a^b e^{tx} f(x)\\,dx.\n",
    "$$\n",
    "\n",
    "- If $b<\\infty$, then the support is bounded and the MGF exists for **all** real $t$.\n",
    "- If $b=\\infty$, the MGF existence matches the base Weibull (e.g. for $c=1$ it only exists for $t<1$).\n",
    "\n",
    "The characteristic function always exists:\n",
    "\n",
    "$$\n",
    "\\varphi_X(t)=\\mathbb{E}[e^{itX}].\n",
    "$$\n",
    "\n",
    "Closed forms are generally not simple; numerical quadrature is typical.\n",
    "\n",
    "### Entropy\n",
    "\n",
    "The differential entropy is\n",
    "\n",
    "$$\n",
    "H(X) = -\\int_a^b f(x)\\log f(x)\\,dx.\n",
    "$$\n",
    "\n",
    "SciPy provides `truncweibull_min.entropy`, and we can also compute it numerically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncweibull_min_raw_moment(k: float, c: float, a: float, b: float) -> float:\n",
    "    \"\"\"Raw moment E[X^k] in standardized form.\n",
    "\n",
    "    Uses the formula with lower incomplete gamma:\n",
    "        E[X^k] = (γ(1+k/c, b^c) - γ(1+k/c, a^c)) / (exp(-a^c) - exp(-b^c)).\n",
    "    \"\"\"\n",
    "    if k < 0:\n",
    "        raise ValueError(\"This helper is written for k>=0.\")\n",
    "\n",
    "    s = 1.0 + k / c\n",
    "    A = a**c\n",
    "    B = np.inf if np.isinf(b) else b**c\n",
    "\n",
    "    gamma_s = special.gamma(s)\n",
    "    num = gamma_s * (special.gammainc(s, B) - special.gammainc(s, A))\n",
    "    den = np.exp(-A) - (0.0 if np.isinf(B) else np.exp(-B))\n",
    "    return float(num / den)\n",
    "\n",
    "\n",
    "def truncweibull_min_moments(c: float, a: float, b: float) -> dict:\n",
    "    m1 = truncweibull_min_raw_moment(1, c, a, b)\n",
    "    m2 = truncweibull_min_raw_moment(2, c, a, b)\n",
    "    m3 = truncweibull_min_raw_moment(3, c, a, b)\n",
    "    m4 = truncweibull_min_raw_moment(4, c, a, b)\n",
    "\n",
    "    var = m2 - m1**2\n",
    "    mu3 = m3 - 3 * m1 * m2 + 2 * m1**3\n",
    "    mu4 = m4 - 4 * m1 * m3 + 6 * (m1**2) * m2 - 3 * m1**4\n",
    "\n",
    "    skew = mu3 / (var ** 1.5)\n",
    "    kurt_excess = mu4 / (var**2) - 3.0\n",
    "\n",
    "    return {\"mean\": m1, \"var\": var, \"skew\": skew, \"kurt_excess\": kurt_excess}\n",
    "\n",
    "\n",
    "c1, a1, b1 = 1.7, 0.2, 2.0\n",
    "ours = truncweibull_min_moments(c1, a1, b1)\n",
    "scipy_mean, scipy_var, scipy_skew, scipy_kurt = truncweibull_min.stats(c1, a1, b1, moments=\"mvsk\")\n",
    "\n",
    "ours, (scipy_mean, scipy_var, scipy_skew, scipy_kurt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mgf_numeric(t: float, c: float, a: float, b: float) -> float:\n",
    "    \"\"\"Numerical MGF M(t)=E[e^{tX}] via quadrature.\"\"\"\n",
    "\n",
    "    def integrand(x: float) -> float:\n",
    "        return float(np.exp(t * x) * np.exp(truncweibull_min_logpdf(np.array([x]), c, a, b)[0]))\n",
    "\n",
    "    val, err = integrate.quad(integrand, a, b, limit=400)\n",
    "    return float(val)\n",
    "\n",
    "\n",
    "def cf_numeric(t: float, c: float, a: float, b: float) -> complex:\n",
    "    \"\"\"Numerical characteristic function φ(t)=E[e^{itX}] via quadrature.\"\"\"\n",
    "\n",
    "    def integrand_cos(x: float) -> float:\n",
    "        lp = truncweibull_min_logpdf(np.array([x]), c, a, b)[0]\n",
    "        return float(np.cos(t * x) * np.exp(lp))\n",
    "\n",
    "    def integrand_sin(x: float) -> float:\n",
    "        lp = truncweibull_min_logpdf(np.array([x]), c, a, b)[0]\n",
    "        return float(np.sin(t * x) * np.exp(lp))\n",
    "\n",
    "    re, _ = integrate.quad(integrand_cos, a, b, limit=400)\n",
    "    im, _ = integrate.quad(integrand_sin, a, b, limit=400)\n",
    "    return complex(re, im)\n",
    "\n",
    "\n",
    "def entropy_numeric(c: float, a: float, b: float) -> float:\n",
    "    \"\"\"Numerical differential entropy -E[log f(X)].\"\"\"\n",
    "\n",
    "    def integrand(x: float) -> float:\n",
    "        lp = truncweibull_min_logpdf(np.array([x]), c, a, b)[0]\n",
    "        if not np.isfinite(lp):\n",
    "            return 0.0\n",
    "        return float(-np.exp(lp) * lp)\n",
    "\n",
    "    val, _ = integrate.quad(integrand, a, b, limit=400)\n",
    "    return float(val)\n",
    "\n",
    "\n",
    "t_values = [-2.0, -1.0, 0.5]\n",
    "mgf_vals = [mgf_numeric(t, c1, a1, b1) for t in t_values]\n",
    "cf_vals = [cf_numeric(t, c1, a1, b1) for t in t_values]\n",
    "\n",
    "H_scipy = float(truncweibull_min.entropy(c1, a1, b1))\n",
    "H_num = entropy_numeric(c1, a1, b1)\n",
    "\n",
    "mgf_vals, cf_vals, H_scipy, H_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Parameter Interpretation\n",
    "\n",
    "### Shape parameter `c` (Weibull shape)\n",
    "\n",
    "In the (untruncated) Weibull minimum distribution:\n",
    "\n",
    "- $c<1$ produces a **decreasing** density on $(0,\\infty)$ with a heavy right tail (sub-exponential).\n",
    "- $c=1$ reduces to the **exponential** distribution.\n",
    "- $c>1$ produces a density that rises from 0 and then decays; the hazard rate is increasing.\n",
    "\n",
    "After truncation, the same tendencies remain, but the distribution is confined to $(a,b]$.\n",
    "\n",
    "### Truncation parameters `a` and `b`\n",
    "\n",
    "- Increasing `a` removes the left part of the support and shifts mass to the right.\n",
    "- Decreasing `b` removes the upper tail and forces the distribution to concentrate below `b`.\n",
    "- Limits:\n",
    "  - $b\\to\\infty$ gives a **left-truncated** Weibull.\n",
    "  - $a\\to 0$ and $b\\to\\infty$ recovers the base Weibull.\n",
    "\n",
    "### `loc` and `scale`\n",
    "\n",
    "- `loc` shifts the distribution.\n",
    "- `scale` stretches/compresses it.\n",
    "- The truncation bounds in the original units are $u_\\ell = \\mathrm{loc}+a\\,\\mathrm{scale}$ and $u_r = \\mathrm{loc}+b\\,\\mathrm{scale}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pdf_family_by_c(a: float, b: float, c_values: list[float]) -> go.Figure:\n",
    "    x = np.linspace(a + 1e-6, b, 800)\n",
    "    fig = go.Figure()\n",
    "    for c in c_values:\n",
    "        fig.add_trace(go.Scatter(x=x, y=truncweibull_min_pdf(x, c, a, b), mode=\"lines\", name=f\"c={c}\"))\n",
    "    fig.update_layout(\n",
    "        title=\"PDF changes with shape c (fixed a,b)\",\n",
    "        xaxis_title=\"x\",\n",
    "        yaxis_title=\"density\",\n",
    "        legend_title=\"shape\",\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_pdf_family_by_trunc(c: float, trunc_pairs: list[tuple[float, float]]) -> go.Figure:\n",
    "    fig = go.Figure()\n",
    "    for a, b in trunc_pairs:\n",
    "        x = np.linspace(a + 1e-6, b, 800)\n",
    "        fig.add_trace(go.Scatter(x=x, y=truncweibull_min_pdf(x, c, a, b), mode=\"lines\", name=f\"a={a}, b={b}\"))\n",
    "    fig.update_layout(\n",
    "        title=\"PDF changes with truncation (fixed c)\",\n",
    "        xaxis_title=\"x\",\n",
    "        yaxis_title=\"density\",\n",
    "        legend_title=\"(a,b)\",\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig1 = plot_pdf_family_by_c(a=0.2, b=2.0, c_values=[0.7, 1.0, 1.7, 3.0])\n",
    "fig2 = plot_pdf_family_by_trunc(c=1.7, trunc_pairs=[(0.0, 2.0), (0.2, 2.0), (0.2, 1.2), (0.8, 2.0)])\n",
    "fig1.show()\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### (a) Raw moment and expectation\n",
    "\n",
    "Let $X\\sim\\mathrm{truncweibull\\_min}(c,a,b)$ in standardized form.\n",
    "For $k\\ge 0$:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^k]\n",
    "= \\frac{1}{Z(c,a,b)}\\int_a^b x^k\\,c x^{c-1} e^{-x^c}\\,dx\n",
    "= \\frac{1}{Z(c,a,b)}\\int_a^b c x^{k+c-1} e^{-x^c}\\,dx.\n",
    "$$\n",
    "\n",
    "Substitute $t=x^c$ so that $dt=c x^{c-1}dx$ and $x^k=t^{k/c}$:\n",
    "\n",
    "$$\n",
    "\\int_a^b c x^{k+c-1} e^{-x^c}\\,dx\n",
    "= \\int_{a^c}^{b^c} t^{k/c} e^{-t}\\,dt\n",
    "= \\gamma\\!\\left(1+\\frac{k}{c}, b^c\\right) - \\gamma\\!\\left(1+\\frac{k}{c}, a^c\\right).\n",
    "$$\n",
    "\n",
    "Dividing by $Z(c,a,b)=e^{-a^c}-e^{-b^c}$ yields the raw moment formula used above.\n",
    "\n",
    "### (b) Variance\n",
    "\n",
    "Once $m_1=\\mathbb{E}[X]$ and $m_2=\\mathbb{E}[X^2]$ are available,\n",
    "\n",
    "$$\n",
    "\\mathrm{Var}(X)=m_2 - m_1^2.\n",
    "$$\n",
    "\n",
    "### (c) Likelihood\n",
    "\n",
    "Given i.i.d. observations $x_1,\\dots,x_n \\in (a,b]$, the log-likelihood (standardized form) is\n",
    "\n",
    "$$\n",
    "\\ell(c,a,b\\mid x)\n",
    "= \\sum_{i=1}^n \\log f(x_i;c,a,b)\n",
    "= n\\log c + (c-1)\\sum_{i=1}^n\\log x_i - \\sum_{i=1}^n x_i^c - n\\log\\bigl(e^{-a^c}-e^{-b^c}\\bigr).\n",
    "$$\n",
    "\n",
    "With `loc`/`scale`, use $y_i=(x_i-\\mathrm{loc})/\\mathrm{scale}$ and add the Jacobian term $-n\\log(\\mathrm{scale})$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglike_c_given_ab(c: float, x: np.ndarray, a: float, b: float) -> float:\n",
    "    \"\"\"Log-likelihood as a function of c, with (a,b) fixed in standardized form.\"\"\"\n",
    "    if c <= 0:\n",
    "        return -np.inf\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if np.any((x <= a) | (x > b)):\n",
    "        return -np.inf\n",
    "\n",
    "    logZ = _logZ_truncweibull_min(c, a, b)\n",
    "    n = x.size\n",
    "    return float(n * np.log(c) + (c - 1.0) * np.sum(np.log(x)) - np.sum(x**c) - n * logZ)\n",
    "\n",
    "\n",
    "# Example: MLE for c when (a,b) are known\n",
    "true_c, true_a, true_b = 1.8, 0.2, 2.0\n",
    "data = truncweibull_min.rvs(true_c, true_a, true_b, size=2000, random_state=rng)\n",
    "\n",
    "def nll(c: float) -> float:\n",
    "    return -loglike_c_given_ab(c, data, true_a, true_b)\n",
    "\n",
    "res = optimize.minimize_scalar(nll, bounds=(0.1, 10.0), method=\"bounded\")\n",
    "c_hat = float(res.x)\n",
    "\n",
    "c_hat, true_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Sampling & Simulation\n",
    "\n",
    "Because we have a closed-form PPF, sampling is straightforward via **inverse transform**.\n",
    "\n",
    "From the truncated CDF, one convenient identity is\n",
    "\n",
    "$$\n",
    "e^{-X^c} = (1-U)e^{-a^c} + U e^{-b^c},\\qquad U\\sim\\mathrm{Unif}(0,1).\n",
    "$$\n",
    "\n",
    "So the algorithm is:\n",
    "\n",
    "1. Sample $U\\sim\\mathrm{Unif}(0,1)$.\n",
    "2. Compute $S = (1-U)e^{-a^c} + U e^{-b^c}$.\n",
    "3. Return $X = (-\\log S)^{1/c}$.\n",
    "\n",
    "This uses only `log`, `exp`, and `power`, so it is easy to implement with NumPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncweibull_min_rvs_numpy(\n",
    "    c: float,\n",
    "    a: float,\n",
    "    b: float,\n",
    "    size: int,\n",
    "    rng: np.random.Generator | None = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"NumPy-only sampling for standardized truncweibull_min(c, a, b).\"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    u = rng.random(size)\n",
    "    return truncweibull_min_ppf(u, c, a, b)\n",
    "\n",
    "\n",
    "c2, a2, b2 = 1.7, 0.2, 2.0\n",
    "s_numpy = truncweibull_min_rvs_numpy(c2, a2, b2, size=20000, rng=rng)\n",
    "s_scipy = truncweibull_min.rvs(c2, a2, b2, size=20000, random_state=rng)\n",
    "\n",
    "np.mean(s_numpy), np.mean(s_scipy), truncweibull_min.mean(c2, a2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We’ll visualize:\n",
    "\n",
    "- PDF (analytic) and histogram of Monte Carlo samples\n",
    "- CDF (analytic) and empirical CDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3, a3, b3 = 1.7, 0.2, 2.0\n",
    "samples = truncweibull_min_rvs_numpy(c3, a3, b3, size=5000, rng=rng)\n",
    "\n",
    "x = np.linspace(a3 + 1e-6, b3, 600)\n",
    "pdf = truncweibull_min_pdf(x, c3, a3, b3)\n",
    "cdf = truncweibull_min_cdf(x, c3, a3, b3)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"PDF + histogram\", \"CDF + ECDF\"))\n",
    "\n",
    "# PDF + histogram\n",
    "fig.add_trace(go.Histogram(x=samples, histnorm=\"probability density\", nbinsx=40, name=\"samples\"), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=x, y=pdf, mode=\"lines\", name=\"pdf\"), row=1, col=1)\n",
    "\n",
    "# CDF + ECDF\n",
    "ecdf_x = np.sort(samples)\n",
    "ecdf_y = np.arange(1, ecdf_x.size + 1) / ecdf_x.size\n",
    "fig.add_trace(go.Scatter(x=x, y=cdf, mode=\"lines\", name=\"cdf\"), row=1, col=2)\n",
    "fig.add_trace(go.Scatter(x=ecdf_x, y=ecdf_y, mode=\"lines\", name=\"ecdf\"), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"density\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"probability\", row=1, col=2)\n",
    "fig.update_layout(title=f\"truncweibull_min(c={c3}, a={a3}, b={b3})\", bargap=0.05)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) SciPy Integration\n",
    "\n",
    "`scipy.stats.truncweibull_min` provides:\n",
    "\n",
    "- `pdf`, `logpdf`, `cdf`, `ppf`, `rvs`\n",
    "- `stats` and `moment`\n",
    "- `entropy`\n",
    "- `fit` (MLE-based parameter estimation)\n",
    "\n",
    "A common workflow is to **freeze** the distribution with parameters and then call methods on the frozen object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4, a4, b4 = 1.8, 0.2, 2.0\n",
    "rv = truncweibull_min(c4, a4, b4)  # frozen standardized distribution\n",
    "\n",
    "x0 = np.array([0.25, 0.5, 1.0, 1.8])\n",
    "rv.pdf(x0), rv.cdf(x0), rv.ppf([0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting: often (a,b) are known measurement bounds, so we fit c with a,b fixed.\n",
    "sim = rv.rvs(size=3000, random_state=rng)\n",
    "c_hat_fit, a_hat_fit, b_hat_fit, loc_hat_fit, scale_hat_fit = truncweibull_min.fit(sim, fa=a4, fb=b4, floc=0, fscale=1)\n",
    "c_hat_fit, (a_hat_fit, b_hat_fit, loc_hat_fit, scale_hat_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Statistical Use Cases\n",
    "\n",
    "### (a) Hypothesis testing\n",
    "\n",
    "A simple and interpretable test is whether the data are compatible with an **exponential** tail on $(a,b]$.\n",
    "Because Weibull with $c=1$ is exponential, we can test\n",
    "\n",
    "$$\n",
    "H_0: c = 1 \\quad\\text{(truncated exponential)}\n",
    "\\qquad\\text{vs}\\qquad\n",
    "H_1: c \\ne 1.\n",
    "$$\n",
    "\n",
    "We can use a likelihood ratio test (LRT) when $(a,b)$ are fixed/known.\n",
    "\n",
    "### (b) Bayesian modeling\n",
    "\n",
    "When you want full uncertainty quantification, treat $c$ as a parameter with a prior (e.g. a Gamma prior) and compute the posterior.\n",
    "\n",
    "### (c) Generative modeling\n",
    "\n",
    "Once parameters are estimated, the distribution is a handy **bounded generator** for synthetic lifetimes or severities (e.g. simulation studies, stress testing, Monte Carlo pipelines).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Likelihood ratio test for H0: c=1 vs H1: c free (a,b known)\n",
    "a5, b5 = 0.2, 2.0\n",
    "x_obs = truncweibull_min.rvs(1.8, a5, b5, size=800, random_state=rng)\n",
    "\n",
    "c_mle = float(optimize.minimize_scalar(lambda c: -loglike_c_given_ab(c, x_obs, a5, b5), bounds=(0.1, 10.0), method=\"bounded\").x)\n",
    "ll_alt = loglike_c_given_ab(c_mle, x_obs, a5, b5)\n",
    "ll_null = loglike_c_given_ab(1.0, x_obs, a5, b5)\n",
    "\n",
    "lrt = 2.0 * (ll_alt - ll_null)\n",
    "p_value = float(stats.chi2.sf(lrt, df=1))\n",
    "\n",
    "dict(c_mle=c_mle, lrt=lrt, p_value=p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b) Simple Bayesian inference for c with a,b fixed: grid posterior\n",
    "c_grid = np.linspace(0.2, 5.0, 600)\n",
    "\n",
    "# Prior: Gamma(shape=2, scale=1) on c (mean=2). Feel free to adjust.\n",
    "log_prior = stats.gamma(a=2.0, scale=1.0).logpdf(c_grid)\n",
    "log_like = np.array([loglike_c_given_ab(c, x_obs, a5, b5) for c in c_grid])\n",
    "\n",
    "log_post_unnorm = log_prior + log_like\n",
    "log_post = log_post_unnorm - special.logsumexp(log_post_unnorm) - np.log(c_grid[1] - c_grid[0])\n",
    "post = np.exp(log_post)\n",
    "\n",
    "c_mean = float(np.trapz(c_grid * post, c_grid))\n",
    "\n",
    "# 95% credible interval by CDF on the grid\n",
    "cdf_post = np.cumsum(post) * (c_grid[1] - c_grid[0])\n",
    "c_lo = float(np.interp(0.025, cdf_post, c_grid))\n",
    "c_hi = float(np.interp(0.975, cdf_post, c_grid))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=c_grid, y=post, mode=\"lines\", name=\"posterior\"))\n",
    "fig.add_vline(x=c_mean, line_dash=\"dash\", annotation_text=f\"mean={c_mean:.2f}\")\n",
    "fig.add_vrect(x0=c_lo, x1=c_hi, opacity=0.15, annotation_text=\"95% CI\")\n",
    "fig.update_layout(title=\"Posterior over c (a,b fixed)\", xaxis_title=\"c\", yaxis_title=\"density\")\n",
    "fig.show()\n",
    "\n",
    "dict(c_mean=c_mean, c_95=(c_lo, c_hi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) Generative modeling: fit c, then generate synthetic samples\n",
    "c_fit = float(truncweibull_min.fit(x_obs, fa=a5, fb=b5, floc=0, fscale=1)[0])\n",
    "rv_fit = truncweibull_min(c_fit, a5, b5)\n",
    "\n",
    "synthetic = rv_fit.rvs(size=5000, random_state=rng)\n",
    "\n",
    "fig = px.histogram(\n",
    "    x_obs,\n",
    "    nbins=40,\n",
    "    histnorm=\"probability density\",\n",
    "    opacity=0.55,\n",
    "    labels={\"value\": \"x\"},\n",
    "    title=f\"Observed vs synthetic (fit c={c_fit:.2f}, a={a5}, b={b5})\",\n",
    ")\n",
    "fig.add_trace(go.Histogram(x=synthetic, nbinsx=40, histnorm=\"probability density\", opacity=0.55, name=\"synthetic\"))\n",
    "\n",
    "x_line = np.linspace(a5 + 1e-6, b5, 600)\n",
    "fig.add_trace(go.Scatter(x=x_line, y=rv_fit.pdf(x_line), mode=\"lines\", name=\"fitted pdf\"))\n",
    "fig.update_layout(barmode=\"overlay\", xaxis_title=\"x\", yaxis_title=\"density\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Parameter validity**: require `c>0`, `a>=0`, `b>a`, and `scale>0`.\n",
    "- **Standardized bounds**: in SciPy, `a` and `b` are standardized; the actual cutoffs are `loc + a*scale` and `loc + b*scale`.\n",
    "- **Data outside support**: any observation $x\\le a$ or $x>b$ has likelihood 0 under the model.\n",
    "- **Numerical stability**: the normalizer $e^{-a^c}-e^{-b^c}$ can suffer cancellation when $b^c-a^c$ is tiny; prefer log-space or `expm1`-based forms.\n",
    "- **Fitting**: if you let `fit` estimate `a` and `b`, it may push them toward sample min/max; in many applications truncation bounds are known and should be fixed.\n",
    "- **MGF existence when $b=\\infty$**: for infinite upper bound, the MGF can diverge for $t>0$ depending on `c` (like the base Weibull).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `truncweibull_min` is a **Weibull minimum conditioned** to lie in $(a,b]$ (with `a,b` standardized in SciPy).\n",
    "- The PDF is the Weibull PDF divided by $Z=e^{-a^c}-e^{-b^c}$; the CDF and PPF follow in closed form.\n",
    "- Raw moments reduce to **incomplete gamma** differences, enabling mean/variance/skewness/kurtosis calculations.\n",
    "- Sampling is easy via the PPF and can be implemented with **NumPy only**.\n",
    "- For inference, `scipy.stats.truncweibull_min` supports evaluation, simulation, and MLE-based fitting; consider fixing truncation bounds when they are design constraints.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
