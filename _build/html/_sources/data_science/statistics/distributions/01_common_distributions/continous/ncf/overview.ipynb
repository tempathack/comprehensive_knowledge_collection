{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa55542d",
   "metadata": {},
   "source": [
    "# Noncentral F distribution (`ncf`)\n",
    "\n",
    "The **noncentral F distribution** is the distribution of many classical **F-statistics under an alternative hypothesis**.\n",
    "It generalizes the central F distribution by introducing a **noncentrality parameter** that captures “signal strength”.\n",
    "\n",
    "## Learning goals\n",
    "- Understand the generative story: **ratio of (noncentral) chi-square variables**.\n",
    "- Relate `ncf` to hypothesis testing (ANOVA / regression) and **power analysis**.\n",
    "- Write down the **PDF/CDF** (as a Poisson mixture) and interpret parameters.\n",
    "- Derive **mean/variance** and compute higher moments (skewness/kurtosis) when they exist.\n",
    "- Implement a **NumPy-only** sampler and validate it with Monte Carlo.\n",
    "- Use `scipy.stats.ncf` for `pdf`, `cdf`, `rvs`, and `fit`.\n",
    "\n",
    "## Prerequisites\n",
    "- Chi-square and F distributions; expectation/variance\n",
    "- Some comfort with special functions (Beta, Gamma) and log-likelihoods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d396355d",
   "metadata": {},
   "source": [
    "## Notebook roadmap\n",
    "\n",
    "1. Title & Classification\n",
    "2. Intuition & Motivation\n",
    "3. Formal Definition\n",
    "4. Moments & Properties\n",
    "5. Parameter Interpretation\n",
    "6. Derivations (Expectation, Variance, Likelihood)\n",
    "7. Sampling & Simulation (NumPy-only)\n",
    "8. Visualization (PDF, CDF, Monte Carlo)\n",
    "9. SciPy Integration\n",
    "10. Statistical Use Cases\n",
    "11. Pitfalls\n",
    "12. Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df667507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from scipy import optimize, special, stats\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "SEED = 7\n",
    "rng = np.random.default_rng(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd7cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import scipy\n",
    "import plotly\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"SciPy:\", scipy.__version__)\n",
    "print(\"Plotly:\", plotly.__version__)\n",
    "print(\"Seed:\", SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7ec6f4",
   "metadata": {},
   "source": [
    "## 1) Title & Classification\n",
    "\n",
    "- **Name**: `ncf` (Noncentral F distribution; SciPy: `scipy.stats.ncf`)\n",
    "- **Type**: **Continuous**\n",
    "- **Support (standard form)**: $x \\in (0,\\infty)$\n",
    "- **Parameter space (standard form)**:\n",
    "  - numerator degrees of freedom $\\nu_1 > 0$ (SciPy: `dfn`)\n",
    "  - denominator degrees of freedom $\\nu_2 > 0$ (SciPy: `dfd`)\n",
    "  - noncentrality $\\lambda \\ge 0$ (SciPy: `nc`)\n",
    "- **SciPy location/scale**: `loc \\in \\mathbb{R}`, `scale > 0` with\n",
    "  $$X = \\text{loc} + \\text{scale}\\,Y,\\qquad Y \\sim \\mathrm{NCF}(\\nu_1,\\nu_2,\\lambda).$$\n",
    "\n",
    "Unless stated otherwise, we work with the **standard form** (`loc=0`, `scale=1`).\n",
    "\n",
    "Notation you may see:\n",
    "- $X \\sim F_{\\text{nc}}(\\nu_1,\\nu_2,\\lambda)$ (noncentral F)\n",
    "- sometimes $\\nu_1$ / $\\nu_2$ are written as `df1` / `df2`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc3290b",
   "metadata": {},
   "source": [
    "## 2) Intuition & Motivation\n",
    "\n",
    "### What it models\n",
    "The central F distribution arises as a ratio of *two independent variance estimates*.\n",
    "The **noncentral** F appears when the numerator contains a **signal term** (e.g., the model explains real variation).\n",
    "\n",
    "A canonical setting is the classical linear model with Gaussian noise:\n",
    "- Under $H_0$ (no signal), an F-statistic has a **central** F distribution.\n",
    "- Under $H_1$ (signal present), the same statistic has a **noncentral** F distribution with noncentrality $\\lambda$.\n",
    "\n",
    "### Typical real-world use cases\n",
    "- **Power analysis** for ANOVA and regression F-tests\n",
    "- **Design of experiments**: sample size vs detectable effect size\n",
    "- **Model comparison** (nested models): distribution of the test statistic under alternatives\n",
    "\n",
    "### Relations to other distributions\n",
    "- **Central F**: $\\lambda=0$ recovers $F(\\nu_1,\\nu_2)$.\n",
    "- **Noncentral chi-square**: the noncentral F is a ratio involving a noncentral chi-square random variable.\n",
    "- **Noncentral t**: if $T \\sim \\mathrm{nct}(\\nu, \\delta)$ then $T^2 \\sim \\mathrm{ncf}(1,\\nu,\\delta^2)$.\n",
    "- **Poisson mixture**: $\\mathrm{ncf}$ can be written as a Poisson mixture of central F distributions (very useful computationally).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e61398",
   "metadata": {},
   "source": [
    "## 3) Formal Definition\n",
    "\n",
    "### Generative definition\n",
    "Let\n",
    "- $U \\sim \\chi'^2_{\\nu_1}(\\lambda)$ be a **noncentral chi-square** random variable with $\\nu_1$ degrees of freedom and noncentrality $\\lambda$.\n",
    "- $V \\sim \\chi^2_{\\nu_2}$ be an independent **central** chi-square random variable.\n",
    "\n",
    "Define\n",
    "$$\n",
    "X \\,=\\, \\frac{U/\\nu_1}{V/\\nu_2} \\,=\\, \\frac{\\nu_2}{\\nu_1}\\,\\frac{U}{V}.\n",
    "$$\n",
    "Then $X \\sim \\mathrm{NCF}(\\nu_1,\\nu_2,\\lambda)$.\n",
    "\n",
    "---\n",
    "\n",
    "### Central F building block\n",
    "For a **central** F random variable $Y \\sim F(d_1,d_2)$, $y>0$:\n",
    "\n",
    "**PDF**\n",
    "$$\n",
    " f_F(y; d_1,d_2)\n",
    " = \\frac{1}{B\\left(\\tfrac{d_1}{2},\\tfrac{d_2}{2}\\right)}\\left(\\frac{d_1}{d_2}\\right)^{d_1/2}\n",
    " \\frac{y^{d_1/2-1}}{\\left(1+\\tfrac{d_1}{d_2}y\\right)^{(d_1+d_2)/2}}.\n",
    "$$\n",
    "\n",
    "**CDF**\n",
    "$$\n",
    "F_F(y; d_1,d_2) = I_{z}(\\tfrac{d_1}{2},\\tfrac{d_2}{2}),\\qquad\n",
    "z = \\frac{d_1 y}{d_1 y + d_2},\n",
    "$$\n",
    "where $I_z(a,b)$ is the regularized incomplete beta function.\n",
    "\n",
    "---\n",
    "\n",
    "### Poisson-mixture representation (PDF and CDF)\n",
    "A key identity is that a noncentral chi-square is a **Poisson mixture** of central chi-squares:\n",
    "\n",
    "$$\n",
    "U\\mid K=k \\;\\sim\\; \\chi^2_{\\nu_1 + 2k},\n",
    "\\qquad\n",
    "K \\sim \\mathrm{Poisson}(\\lambda/2).\n",
    "$$\n",
    "\n",
    "Let\n",
    "$$w_k = \\mathbb{P}(K=k) = e^{-\\lambda/2}\\,\\frac{(\\lambda/2)^k}{k!}.$$\n",
    "\n",
    "Then $X$ is a Poisson mixture of central F distributions:\n",
    "\n",
    "**PDF**\n",
    "$$\n",
    " f_X(x;\\nu_1,\\nu_2,\\lambda) = \\sum_{k=0}^{\\infty} w_k\\, f_F\\bigl(x; \\nu_1+2k,\\nu_2\\bigr),\\qquad x>0.\n",
    "$$\n",
    "\n",
    "**CDF**\n",
    "$$\n",
    " F_X(x;\\nu_1,\\nu_2,\\lambda) = \\sum_{k=0}^{\\infty} w_k\\, I_{z}\\bigl(\\tfrac{\\nu_1}{2}+k,\\tfrac{\\nu_2}{2}\\bigr),\n",
    "\\qquad z = \\frac{\\nu_1 x}{\\nu_1 x + \\nu_2}.\n",
    "$$\n",
    "\n",
    "These series are the most common “closed forms” used in practice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f86ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_ncf_params(dfn: float, dfd: float, nc: float):\n",
    "    dfn = float(dfn)\n",
    "    dfd = float(dfd)\n",
    "    nc = float(nc)\n",
    "    if not (dfn > 0):\n",
    "        raise ValueError(f\"dfn must be > 0, got {dfn!r}\")\n",
    "    if not (dfd > 0):\n",
    "        raise ValueError(f\"dfd must be > 0, got {dfd!r}\")\n",
    "    if not (nc >= 0):\n",
    "        raise ValueError(f\"nc must be >= 0, got {nc!r}\")\n",
    "    return dfn, dfd, nc\n",
    "\n",
    "\n",
    "def f_logpdf(x, dfn: float, dfd: float):\n",
    "    \"\"\"Log-PDF of the central F(dfn, dfd) distribution (standard form).\"\"\"\n",
    "    dfn = float(dfn)\n",
    "    dfd = float(dfd)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    out = np.full_like(x, -np.inf, dtype=float)\n",
    "    mask = x > 0\n",
    "    xm = x[mask]\n",
    "\n",
    "    a = 0.5 * dfn\n",
    "    b = 0.5 * dfd\n",
    "\n",
    "    logc = a * np.log(dfn / dfd) - special.betaln(a, b)\n",
    "    out[mask] = logc + (a - 1.0) * np.log(xm) - (a + b) * np.log1p((dfn / dfd) * xm)\n",
    "    return out\n",
    "\n",
    "\n",
    "def f_pdf(x, dfn: float, dfd: float):\n",
    "    return np.exp(f_logpdf(x, dfn, dfd))\n",
    "\n",
    "\n",
    "def f_cdf(x, dfn: float, dfd: float):\n",
    "    \"\"\"CDF of the central F(dfn, dfd) distribution (standard form).\"\"\"\n",
    "    dfn = float(dfn)\n",
    "    dfd = float(dfd)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    out = np.zeros_like(x, dtype=float)\n",
    "    mask = x > 0\n",
    "    xm = x[mask]\n",
    "    z = (dfn * xm) / (dfn * xm + dfd)\n",
    "    out[mask] = special.betainc(0.5 * dfn, 0.5 * dfd, z)\n",
    "    return out\n",
    "\n",
    "\n",
    "# Quick sanity check vs SciPy's central F\n",
    "x_demo = np.linspace(0.1, 3.0, 5)\n",
    "print(\"max |pdf - scipy|:\", np.max(np.abs(f_pdf(x_demo, 5, 20) - stats.f.pdf(x_demo, 5, 20))))\n",
    "print(\"max |cdf - scipy|:\", np.max(np.abs(f_cdf(x_demo, 5, 20) - stats.f.cdf(x_demo, 5, 20))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276dc96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_weights_trunc(lam: float, tol: float = 1e-12, k_max: int = 10_000):\n",
    "    \"\"\"Truncate Poisson(lam) weights so that remaining tail mass is < tol.\"\"\"\n",
    "    lam = float(lam)\n",
    "    if lam < 0:\n",
    "        raise ValueError(\"lam must be >= 0\")\n",
    "\n",
    "    if lam == 0.0:\n",
    "        return np.array([1.0]), 1.0\n",
    "\n",
    "    weights = np.empty(k_max + 1, dtype=float)\n",
    "    weights[0] = np.exp(-lam)\n",
    "    mass = weights[0]\n",
    "\n",
    "    k = 0\n",
    "    # w_{k+1} = w_k * lam/(k+1)\n",
    "    while k < k_max and (1.0 - mass) > tol:\n",
    "        k += 1\n",
    "        weights[k] = weights[k - 1] * lam / k\n",
    "        mass += weights[k]\n",
    "\n",
    "    return weights[: k + 1], mass\n",
    "\n",
    "\n",
    "def ncf_pdf_series(x, dfn: float, dfd: float, nc: float, tol: float = 1e-12, k_max: int = 10_000):\n",
    "    \"\"\"PDF of ncf(dfn, dfd, nc) via Poisson-mixture series truncation.\"\"\"\n",
    "    dfn, dfd, nc = validate_ncf_params(dfn, dfd, nc)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    weights, mass = poisson_weights_trunc(nc / 2.0, tol=tol, k_max=k_max)\n",
    "\n",
    "    out = np.zeros_like(x, dtype=float)\n",
    "    for k, wk in enumerate(weights):\n",
    "        out += wk * f_pdf(x, dfn + 2 * k, dfd)\n",
    "\n",
    "    # Optional: renormalize because we truncated the Poisson tail.\n",
    "    return out / mass\n",
    "\n",
    "\n",
    "def ncf_cdf_series(x, dfn: float, dfd: float, nc: float, tol: float = 1e-12, k_max: int = 10_000):\n",
    "    \"\"\"CDF of ncf(dfn, dfd, nc) via Poisson-mixture series truncation.\"\"\"\n",
    "    dfn, dfd, nc = validate_ncf_params(dfn, dfd, nc)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    weights, mass = poisson_weights_trunc(nc / 2.0, tol=tol, k_max=k_max)\n",
    "\n",
    "    out = np.zeros_like(x, dtype=float)\n",
    "    for k, wk in enumerate(weights):\n",
    "        out += wk * f_cdf(x, dfn + 2 * k, dfd)\n",
    "\n",
    "    return out / mass\n",
    "\n",
    "\n",
    "# Compare series approximation to SciPy (moderate parameters)\n",
    "dfn, dfd, nc = 5, 20, 10\n",
    "x_grid = np.linspace(0.001, 6.0, 400)\n",
    "\n",
    "pdf_scipy = stats.ncf.pdf(x_grid, dfn, dfd, nc)\n",
    "cdf_scipy = stats.ncf.cdf(x_grid, dfn, dfd, nc)\n",
    "\n",
    "pdf_series = ncf_pdf_series(x_grid, dfn, dfd, nc, tol=1e-12)\n",
    "cdf_series = ncf_cdf_series(x_grid, dfn, dfd, nc, tol=1e-12)\n",
    "\n",
    "print(\"max |pdf_series - pdf_scipy|:\", float(np.max(np.abs(pdf_series - pdf_scipy))))\n",
    "print(\"max |cdf_series - cdf_scipy|:\", float(np.max(np.abs(cdf_series - cdf_scipy))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29522ac2",
   "metadata": {},
   "source": [
    "## 4) Moments & Properties\n",
    "\n",
    "### Existence of moments\n",
    "From the ratio representation $X = (U/\\nu_1)/(V/\\nu_2)$, negative moments of $V\\sim\\chi^2_{\\nu_2}$ appear.\n",
    "As a result:\n",
    "\n",
    "- The $r$-th raw moment $\\mathbb{E}[X^r]$ exists only if $\\nu_2 > 2r$.\n",
    "  - mean exists if $\\nu_2 > 2$\n",
    "  - variance exists if $\\nu_2 > 4$\n",
    "  - skewness needs $\\nu_2 > 6$\n",
    "  - kurtosis needs $\\nu_2 > 8$\n",
    "\n",
    "### Mean and variance (closed form)\n",
    "Let $X \\sim \\mathrm{NCF}(\\nu_1,\\nu_2,\\lambda)$.\n",
    "\n",
    "**Mean** (for $\\nu_2>2$):\n",
    "$$\n",
    "\\mathbb{E}[X] = \\frac{\\nu_2}{\\nu_2-2}\\left(1+\\frac{\\lambda}{\\nu_1}\\right)\n",
    "= \\frac{\\nu_2(\\nu_1+\\lambda)}{\\nu_1(\\nu_2-2)}.\n",
    "$$\n",
    "\n",
    "**Variance** (for $\\nu_2>4$):\n",
    "$$\n",
    "\\mathrm{Var}(X)\n",
    "= \\frac{2\\,(\\nu_2/\\nu_1)^2\\left[(\\nu_2-2)(\\nu_1+2\\lambda) + (\\nu_1+\\lambda)^2\\right]}{(\\nu_2-2)^2(\\nu_2-4)}.\n",
    "$$\n",
    "\n",
    "These reduce to the familiar central-F formulas when $\\lambda=0$.\n",
    "\n",
    "### Skewness and kurtosis\n",
    "Closed forms exist but get algebraically bulky.\n",
    "A practical approach is:\n",
    "1) compute raw moments $\\mathbb{E}[X],\\dots,\\mathbb{E}[X^4]$ (when they exist),\n",
    "2) convert to central moments, then to skewness/kurtosis.\n",
    "\n",
    "### MGF / characteristic function\n",
    "- The **MGF** $M_X(t)=\\mathbb{E}[e^{tX}]$ does **not** exist for any $t>0$ (polynomial right tail, like the central F).\n",
    "- The **Laplace transform** $\\mathbb{E}[e^{tX}]$ exists for $t<0$ and can be computed numerically.\n",
    "- The **characteristic function** $\\varphi_X(t)=\\mathbb{E}[e^{itX}]$ exists for all real $t$.\n",
    "\n",
    "### Entropy\n",
    "There is no simple elementary closed form in general.\n",
    "In practice, use numerical methods such as `scipy.stats.ncf.entropy` (which evaluates it numerically).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b0f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def ncx2_raw_moments(dof: float, nc: float, max_order: int = 4):\n",
    "    \"\"\"Raw moments E[U^r] for U ~ noncentral chi-square(dof, nc), for r=1..max_order.\n",
    "\n",
    "    Uses cumulants from log-MGF and converts cumulants -> raw moments.\n",
    "    \"\"\"\n",
    "    dof = float(dof)\n",
    "    nc = float(nc)\n",
    "\n",
    "    if max_order > 4:\n",
    "        raise ValueError(\"This helper is implemented up to order 4.\")\n",
    "\n",
    "    # cumulant κ_r = 2^{r-1} (r-1)! (dof + r*nc)\n",
    "    kappa = [None]\n",
    "    for r in range(1, max_order + 1):\n",
    "        kappa_r = (2 ** (r - 1)) * math.factorial(r - 1) * (dof + r * nc)\n",
    "        kappa.append(kappa_r)\n",
    "\n",
    "    k1 = kappa[1]\n",
    "    if max_order == 1:\n",
    "        return np.array([k1])\n",
    "\n",
    "    k2 = kappa[2]\n",
    "    m1 = k1\n",
    "    m2 = k2 + k1**2\n",
    "    if max_order == 2:\n",
    "        return np.array([m1, m2])\n",
    "\n",
    "    k3 = kappa[3]\n",
    "    m3 = k3 + 3 * k2 * k1 + k1**3\n",
    "    if max_order == 3:\n",
    "        return np.array([m1, m2, m3])\n",
    "\n",
    "    k4 = kappa[4]\n",
    "    m4 = k4 + 4 * k3 * k1 + 3 * (k2**2) + 6 * k2 * (k1**2) + k1**4\n",
    "    return np.array([m1, m2, m3, m4])\n",
    "\n",
    "\n",
    "def chisquare_neg_moment(dof: float, r: int):\n",
    "    \"\"\"E[V^{-r}] for V ~ chi-square(dof). Requires dof > 2r.\"\"\"\n",
    "    dof = float(dof)\n",
    "    r = int(r)\n",
    "    if dof <= 2 * r:\n",
    "        return np.nan\n",
    "\n",
    "    k = 0.5 * dof\n",
    "    theta = 2.0\n",
    "    # For Gamma(k, theta): E[V^{-r}] = theta^{-r} * Γ(k-r)/Γ(k)\n",
    "    return (theta ** (-r)) * special.gamma(k - r) / special.gamma(k)\n",
    "\n",
    "\n",
    "def ncf_raw_moments(dfn: float, dfd: float, nc: float):\n",
    "    \"\"\"Raw moments E[X^r] for X ~ ncf(dfn, dfd, nc), r=1..4 when they exist.\"\"\"\n",
    "    dfn, dfd, nc = validate_ncf_params(dfn, dfd, nc)\n",
    "\n",
    "    mU = ncx2_raw_moments(dfn, nc, max_order=4)\n",
    "\n",
    "    out = []\n",
    "    for r in range(1, 5):\n",
    "        ev_inv = chisquare_neg_moment(dfd, r)\n",
    "        if not np.isfinite(ev_inv):\n",
    "            out.append(np.nan)\n",
    "            continue\n",
    "        out.append(((dfd / dfn) ** r) * mU[r - 1] * ev_inv)\n",
    "\n",
    "    return np.array(out, dtype=float)\n",
    "\n",
    "\n",
    "def raw_to_central(m1, m2, m3, m4):\n",
    "    \"\"\"Convert raw moments to central moments (μ2, μ3, μ4).\"\"\"\n",
    "    mu = m1\n",
    "    mu2 = m2 - mu**2\n",
    "    mu3 = m3 - 3 * mu * m2 + 2 * mu**3\n",
    "    mu4 = m4 - 4 * mu * m3 + 6 * mu**2 * m2 - 3 * mu**4\n",
    "    return mu2, mu3, mu4\n",
    "\n",
    "\n",
    "def ncf_mean_closed(dfn: float, dfd: float, nc: float):\n",
    "    dfn, dfd, nc = validate_ncf_params(dfn, dfd, nc)\n",
    "    if dfd <= 2:\n",
    "        return np.nan\n",
    "    return dfd * (dfn + nc) / (dfn * (dfd - 2))\n",
    "\n",
    "\n",
    "def ncf_var_closed(dfn: float, dfd: float, nc: float):\n",
    "    dfn, dfd, nc = validate_ncf_params(dfn, dfd, nc)\n",
    "    if dfd <= 4:\n",
    "        return np.nan\n",
    "    num = 2 * (dfd / dfn) ** 2 * ((dfd - 2) * (dfn + 2 * nc) + (dfn + nc) ** 2)\n",
    "    den = (dfd - 2) ** 2 * (dfd - 4)\n",
    "    return num / den\n",
    "\n",
    "\n",
    "dfn, dfd, nc = 5, 20, 10\n",
    "m1, m2, m3, m4 = ncf_raw_moments(dfn, dfd, nc)\n",
    "mu2, mu3, mu4 = raw_to_central(m1, m2, m3, m4)\n",
    "\n",
    "skew = mu3 / (mu2 ** 1.5)\n",
    "excess_kurt = mu4 / (mu2**2) - 3.0\n",
    "\n",
    "print(\"Raw moments E[X^r], r=1..4:\", np.array([m1, m2, m3, m4]))\n",
    "print(\"Mean (closed):\", ncf_mean_closed(dfn, dfd, nc))\n",
    "print(\"Var  (closed):\", ncf_var_closed(dfn, dfd, nc))\n",
    "print(\"Skewness:\", skew)\n",
    "print(\"Excess kurtosis:\", excess_kurt)\n",
    "\n",
    "mvsk = stats.ncf.stats(dfn, dfd, nc, moments=\"mvsk\")\n",
    "print(\"SciPy mvsk:\", mvsk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39925f20",
   "metadata": {},
   "source": [
    "## 5) Parameter Interpretation\n",
    "\n",
    "### Degrees of freedom $\\nu_1$ (numerator)\n",
    "- Comes from the dimension of the signal/constraint being tested.\n",
    "- Larger $\\nu_1$ generally makes the distribution less “spiky” near 0 and less variable.\n",
    "\n",
    "### Degrees of freedom $\\nu_2$ (denominator)\n",
    "- Often corresponds to residual degrees of freedom.\n",
    "- Controls tail heaviness and moment existence: small $\\nu_2$ implies very heavy tails.\n",
    "\n",
    "### Noncentrality $\\lambda$\n",
    "- Encodes **how far from the null** you are.\n",
    "- In many tests, $\\lambda$ is proportional to **sample size × effect size²**.\n",
    "- Increasing $\\lambda$ shifts mass to the right (larger typical F-statistics) and increases power.\n",
    "\n",
    "Below we visualize how the PDF changes as we vary parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01e2f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pdf_family(dfn: float, dfd: float, ncs, x_max: float = 6.0):\n",
    "    x = np.linspace(0.001, x_max, 600)\n",
    "    fig = go.Figure()\n",
    "    for nc in ncs:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=x, y=stats.ncf.pdf(x, dfn, dfd, nc), mode=\"lines\", name=f\"nc={nc}\")\n",
    "        )\n",
    "    fig.update_layout(\n",
    "        title=f\"ncf PDF family (dfn={dfn}, dfd={dfd})\",\n",
    "        xaxis_title=\"x\",\n",
    "        yaxis_title=\"pdf(x)\",\n",
    "        width=900,\n",
    "        height=450,\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "plot_pdf_family(dfn=5, dfd=20, ncs=[0, 2, 5, 10, 20], x_max=8.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dd3baa",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### 6.1 Expectation\n",
    "Using $X = \\frac{\\nu_2}{\\nu_1}\\frac{U}{V}$ with independent $U$ and $V$:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X]\n",
    "= \\frac{\\nu_2}{\\nu_1}\\,\\mathbb{E}[U] \\,\\mathbb{E}[V^{-1}].\n",
    "$$\n",
    "\n",
    "For $U\\sim\\chi'^2_{\\nu_1}(\\lambda)$:\n",
    "$$\\mathbb{E}[U] = \\nu_1 + \\lambda.$$\n",
    "\n",
    "For $V\\sim\\chi^2_{\\nu_2}$ (a Gamma distribution), for $\\nu_2>2$:\n",
    "$$\\mathbb{E}[V^{-1}] = \\frac{1}{\\nu_2-2}.$$\n",
    "\n",
    "Putting it together:\n",
    "$$\n",
    "\\mathbb{E}[X] = \\frac{\\nu_2(\\nu_1+\\lambda)}{\\nu_1(\\nu_2-2)}.\n",
    "$$\n",
    "\n",
    "### 6.2 Variance\n",
    "Similarly,\n",
    "$$\n",
    "\\mathbb{E}[X^2] = \\left(\\frac{\\nu_2}{\\nu_1}\\right)^2 \\mathbb{E}[U^2] \\, \\mathbb{E}[V^{-2}].\n",
    "$$\n",
    "\n",
    "For $\\nu_2>4$,\n",
    "$$\\mathbb{E}[V^{-2}] = \\frac{1}{(\\nu_2-2)(\\nu_2-4)}.$$\n",
    "\n",
    "For $U\\sim\\chi'^2_{\\nu_1}(\\lambda)$,\n",
    "$$\n",
    "\\mathrm{Var}(U)=2(\\nu_1+2\\lambda)\n",
    "\\quad\\Rightarrow\\quad\n",
    "\\mathbb{E}[U^2] = \\mathrm{Var}(U) + \\mathbb{E}[U]^2.\n",
    "$$\n",
    "\n",
    "Then $\\mathrm{Var}(X)=\\mathbb{E}[X^2]-\\mathbb{E}[X]^2$ yields the closed form from Section 4.\n",
    "\n",
    "### 6.3 Likelihood\n",
    "Given data $x_1,\\dots,x_n$ assumed i.i.d. from $\\mathrm{NCF}(\\nu_1,\\nu_2,\\lambda)$, the likelihood is\n",
    "\n",
    "$$\n",
    "L(\\nu_1,\\nu_2,\\lambda) = \\prod_{i=1}^n f_X(x_i;\\nu_1,\\nu_2,\\lambda),\n",
    "\\qquad\n",
    "\\ell = \\sum_{i=1}^n \\log f_X(x_i;\\nu_1,\\nu_2,\\lambda).\n",
    "$$\n",
    "\n",
    "Because $f_X$ is a series (or special-function expression), MLE is typically done **numerically** with constraints $\\nu_1>0,\\nu_2>0,\\lambda\\ge 0$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11daddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood demo: estimate nc with dfn/dfd fixed\n",
    "\n",
    "dfn_true, dfd_true, nc_true = 5, 20, 10\n",
    "n = 2_000\n",
    "x = stats.ncf.rvs(dfn_true, dfd_true, nc_true, size=n, random_state=rng)\n",
    "\n",
    "\n",
    "def neg_loglik_nc(nc: float) -> float:\n",
    "    if nc < 0:\n",
    "        return np.inf\n",
    "    return float(-np.sum(stats.ncf.logpdf(x, dfn_true, dfd_true, nc)))\n",
    "\n",
    "\n",
    "res = optimize.minimize_scalar(neg_loglik_nc, bounds=(0.0, 40.0), method=\"bounded\")\n",
    "print(\"True nc:\", nc_true)\n",
    "print(\"Estimated nc (MLE, dfn/dfd fixed):\", float(res.x))\n",
    "print(\"Optimization success:\", res.success)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b556830",
   "metadata": {},
   "source": [
    "## 7) Sampling & Simulation (NumPy-only)\n",
    "\n",
    "A clean NumPy-only sampler comes directly from the Poisson-mixture construction.\n",
    "\n",
    "1) Draw $K \\sim \\mathrm{Poisson}(\\lambda/2)$.\n",
    "2) Draw $U \\sim \\chi^2_{\\nu_1+2K}$ (central chi-square).\n",
    "3) Draw $V \\sim \\chi^2_{\\nu_2}$.\n",
    "4) Return $X = (U/\\nu_1)/(V/\\nu_2)$.\n",
    "\n",
    "This works because a noncentral chi-square is a Poisson mixture of central chi-squares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf21d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncf_rvs_numpy(rng: np.random.Generator, dfn: float, dfd: float, nc: float, size):\n",
    "    \"\"\"Sample from ncf(dfn, dfd, nc) using NumPy only (Poisson-mixture sampler).\"\"\"\n",
    "    dfn, dfd, nc = validate_ncf_params(dfn, dfd, nc)\n",
    "\n",
    "    lam = 0.5 * nc\n",
    "    k = rng.poisson(lam, size=size)\n",
    "\n",
    "    # If df is an array, Generator.chisquare broadcasts and returns the same shape.\n",
    "    u = rng.chisquare(dfn + 2.0 * k)\n",
    "    v = rng.chisquare(dfd, size=size)\n",
    "\n",
    "    return (u / dfn) / (v / dfd)\n",
    "\n",
    "\n",
    "dfn, dfd, nc = 5, 20, 10\n",
    "samples = ncf_rvs_numpy(rng, dfn, dfd, nc, size=200_000)\n",
    "\n",
    "print(\"Sample mean:\", float(np.mean(samples)))\n",
    "print(\"Theory mean:\", ncf_mean_closed(dfn, dfd, nc))\n",
    "print(\"Sample var:\", float(np.var(samples)))\n",
    "print(\"Theory var:\", ncf_var_closed(dfn, dfd, nc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f899814",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We’ll visualize:\n",
    "- the PDF and CDF (SciPy vs the truncated-series implementation)\n",
    "- Monte Carlo samples (histogram and empirical CDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c4c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn, dfd, nc = 5, 20, 10\n",
    "\n",
    "# Monte Carlo samples\n",
    "n = 50_000\n",
    "s = ncf_rvs_numpy(rng, dfn, dfd, nc, size=n)\n",
    "\n",
    "# Grids\n",
    "x = np.linspace(0.001, 8.0, 700)\n",
    "\n",
    "pdf_scipy = stats.ncf.pdf(x, dfn, dfd, nc)\n",
    "cdf_scipy = stats.ncf.cdf(x, dfn, dfd, nc)\n",
    "\n",
    "pdf_series = ncf_pdf_series(x, dfn, dfd, nc)\n",
    "cdf_series = ncf_cdf_series(x, dfn, dfd, nc)\n",
    "\n",
    "# Empirical CDF\n",
    "s_sorted = np.sort(s)\n",
    "ecdf_y = (np.arange(1, n + 1) / n).astype(float)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"PDF\", \"CDF\"))\n",
    "\n",
    "# PDF panel\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x, y=pdf_scipy, mode=\"lines\", name=\"SciPy pdf\"), row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x, y=pdf_series, mode=\"lines\", name=\"Series pdf\", line=dict(dash=\"dash\")),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=s,\n",
    "        nbinsx=80,\n",
    "        histnorm=\"probability density\",\n",
    "        name=\"MC hist\",\n",
    "        opacity=0.35,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# CDF panel\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x, y=cdf_scipy, mode=\"lines\", name=\"SciPy cdf\"), row=1, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x, y=cdf_series, mode=\"lines\", name=\"Series cdf\", line=dict(dash=\"dash\")),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=s_sorted,\n",
    "        y=ecdf_y,\n",
    "        mode=\"lines\",\n",
    "        name=\"Empirical CDF\",\n",
    "        line=dict(width=1),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Noncentral F: dfn={dfn}, dfd={dfd}, nc={nc}\",\n",
    "    width=1100,\n",
    "    height=450,\n",
    ")\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"density\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"CDF\", row=1, col=2)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7eff26",
   "metadata": {},
   "source": [
    "## 9) SciPy Integration\n",
    "\n",
    "SciPy provides a full-featured implementation: `scipy.stats.ncf`.\n",
    "\n",
    "Common methods:\n",
    "- `pdf`, `logpdf`\n",
    "- `cdf`, `sf` (survival function), `logsf`\n",
    "- `ppf` (quantiles)\n",
    "- `rvs` (sampling)\n",
    "- `stats(moments='mvsk')`\n",
    "- `entropy` (numerical)\n",
    "- `scipy.stats.fit` for MLE with bounds/constraints\n",
    "\n",
    "Note: because `ncf` has multiple parameters (plus `loc`/`scale`), unconstrained fitting can be sensitive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0900c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncf = stats.ncf\n",
    "\n",
    "dfn, dfd, nc = 5, 20, 10\n",
    "x0 = 1.5\n",
    "\n",
    "print(\"pdf(x0):\", float(ncf.pdf(x0, dfn, dfd, nc)))\n",
    "print(\"cdf(x0):\", float(ncf.cdf(x0, dfn, dfd, nc)))\n",
    "\n",
    "s = ncf.rvs(dfn, dfd, nc, size=5, random_state=rng)\n",
    "print(\"rvs:\", s)\n",
    "\n",
    "print(\"mvsk:\", ncf.stats(dfn, dfd, nc, moments=\"mvsk\"))\n",
    "print(\"entropy:\", float(ncf.entropy(dfn, dfd, nc)))\n",
    "\n",
    "# Fitting example using scipy.stats.fit (global optimization by default)\n",
    "data = ncf.rvs(dfn, dfd, nc, size=400, random_state=rng)\n",
    "\n",
    "fit_res = stats.fit(\n",
    "    ncf,\n",
    "    data,\n",
    "    bounds={\n",
    "        # Fix loc/scale to standard form\n",
    "        \"loc\": (0.0, 0.0),\n",
    "        \"scale\": (1.0, 1.0),\n",
    "        # Either estimate or constrain shape parameters\n",
    "        \"dfn\": (dfn, dfn),\n",
    "        \"dfd\": (dfd, dfd),\n",
    "        \"nc\": (0.0, 50.0),\n",
    "    },\n",
    ")\n",
    "\n",
    "print(fit_res)\n",
    "print(\"nc_hat:\", float(fit_res.params.nc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a65df61",
   "metadata": {},
   "source": [
    "## 10) Statistical Use Cases\n",
    "\n",
    "### 10.1 Hypothesis testing: power of an F-test\n",
    "If an F-statistic has distribution:\n",
    "- under $H_0$: $F \\sim F(\\nu_1,\\nu_2)$\n",
    "- under $H_1$: $F \\sim F_{\\text{nc}}(\\nu_1,\\nu_2,\\lambda)$\n",
    "\n",
    "then for significance level $\\alpha$:\n",
    "- critical value $f_{\\text{crit}} = F^{-1}_{\\nu_1,\\nu_2}(1-\\alpha)$\n",
    "- **power** $= \\mathbb{P}(F > f_{\\text{crit}} \\mid H_1) = 1 - F_{\\text{nc}}(f_{\\text{crit}};\\nu_1,\\nu_2,\\lambda)$.\n",
    "\n",
    "### 10.2 Bayesian modeling: uncertain effect size\n",
    "In Bayesian design / power analysis, you might place a prior on an effect size parameter that implies a prior over $\\lambda$.\n",
    "Then the **expected power** is an average over that prior.\n",
    "\n",
    "### 10.3 Generative modeling\n",
    "The noncentral F is a flexible positive distribution for ratios; it can be used as a generative component when the process naturally looks like “signal+noise over noise”.\n",
    "Often, the most useful role is modeling (or simulating) the **distribution of a test statistic** under plausible alternatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9983a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power curve as a function of the noncentrality parameter\n",
    "\n",
    "dfn, dfd = 5, 20\n",
    "alpha = 0.05\n",
    "\n",
    "f_crit = stats.f.ppf(1 - alpha, dfn, dfd)\n",
    "\n",
    "nc_grid = np.linspace(0.0, 40.0, 300)\n",
    "power = stats.ncf.sf(f_crit, dfn, dfd, nc_grid)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=nc_grid, y=power, mode=\"lines\", name=\"power\"))\n",
    "fig.update_layout(\n",
    "    title=f\"Power vs noncentrality (dfn={dfn}, dfd={dfd}, α={alpha}, f_crit={f_crit:.3f})\",\n",
    "    xaxis_title=\"noncentrality nc\",\n",
    "    yaxis_title=\"power = P(F > f_crit | H1)\",\n",
    "    width=900,\n",
    "    height=450,\n",
    "    yaxis=dict(range=[0, 1]),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Bayesian-flavored: prior over nc -> distribution of power\n",
    "# (Here we use a simple Gamma prior on nc for illustration.)\n",
    "prior_nc = rng.gamma(shape=2.0, scale=5.0, size=50_000)  # mean 10\n",
    "prior_power = stats.ncf.sf(f_crit, dfn, dfd, prior_nc)\n",
    "\n",
    "print(\"E_prior[power]:\", float(np.mean(prior_power)))\n",
    "print(\"90% prior interval for power:\", np.quantile(prior_power, [0.05, 0.95]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c804920",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Invalid parameters**: require `dfn > 0`, `dfd > 0`, `nc >= 0`.\n",
    "- **Moment existence**: mean requires `dfd > 2`, variance `dfd > 4`, skewness `dfd > 6`, kurtosis `dfd > 8`.\n",
    "- **Numerical issues**:\n",
    "  - The PDF/CDF involve infinite series or special functions; naive truncation can be inaccurate for extreme parameters.\n",
    "  - Prefer `scipy.stats.ncf.logpdf`, `logcdf`, `sf`, `logsf` in tail computations.\n",
    "  - For very large `nc`, the Poisson mixture may need many terms.\n",
    "- **Fitting can be unstable**:\n",
    "  - Many parameters (including `loc`/`scale`) can lead to identifiability issues.\n",
    "  - Constrain/fix parameters when you have domain knowledge (e.g., `loc=0`, `scale=1`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17806f73",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `ncf` is the noncentral analogue of the F distribution and describes many **F-statistics under alternatives**.\n",
    "- It can be defined as a ratio of an independent **noncentral chi-square** and **central chi-square**.\n",
    "- The PDF/CDF are naturally expressed as a **Poisson mixture** of central F distributions.\n",
    "- Mean/variance have clean closed forms (when `dfd` is large enough); higher moments require stronger conditions.\n",
    "- A simple **NumPy-only** sampler uses the Poisson-mixture construction.\n",
    "- For practical work (tails, fitting, entropy), rely on `scipy.stats.ncf` and prefer log-domain functions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
