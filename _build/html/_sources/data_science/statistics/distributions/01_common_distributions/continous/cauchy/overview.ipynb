{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f3508e8",
   "metadata": {},
   "source": [
    "# Cauchy distribution\n",
    "\n",
    "The **Cauchy** distribution is the canonical example of a *heavy-tailed* continuous distribution where the usual intuition from the Central Limit Theorem breaks: **the mean and variance do not exist**.\n",
    "\n",
    "We'll treat it as a first-class modeling object (not just a pathological counterexample): it appears in ratio statistics, robust error models, and as the Student-t distribution with 1 degree of freedom.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffc4f6b",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "- Know the **definition** (PDF, CDF) and how it relates to **Student-t**.\n",
    "- Understand **why moments diverge** and what statistics are still well-behaved (median, quantiles).\n",
    "- Implement **sampling from scratch** with NumPy (inverse CDF).\n",
    "- Use `scipy.stats.cauchy` for evaluation, simulation, and MLE fitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44245ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy.stats import cauchy, norm\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "rng = np.random.default_rng(7)\n",
    "\n",
    "print(\"Python\", platform.python_version())\n",
    "print(\"NumPy\", np.__version__)\n",
    "print(\"SciPy\", scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce67a595",
   "metadata": {},
   "source": [
    "## 1) Title & classification\n",
    "\n",
    "- **Name**: `cauchy`\n",
    "- **Type**: **continuous** distribution\n",
    "- **Support**: $x \\in (-\\infty, \\infty)$\n",
    "- **Parameter space**: location $x_0 \\in \\mathbb{R}$ and scale $\\gamma > 0$\n",
    "\n",
    "We write:\n",
    "\n",
    "$$X \\sim \\mathrm{Cauchy}(x_0, \\gamma).$$\n",
    "\n",
    "The **standard Cauchy** is $\\mathrm{Cauchy}(0,1)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a978ce",
   "metadata": {},
   "source": [
    "## 2) Intuition & motivation\n",
    "\n",
    "### What it models\n",
    "The Cauchy distribution models **real-valued outcomes with extremely heavy tails**: large deviations are not just possible, they are *common enough* that averaging does not settle down.\n",
    "\n",
    "A useful tail heuristic:\n",
    "\n",
    "- Normal tails decay like $\\exp(-x^2)$\n",
    "- Cauchy tails decay like $1/x^2$ (so the survival function decays like $1/x$)\n",
    "\n",
    "This makes Cauchy a good model for *occasional, very large* values.\n",
    "\n",
    "### Typical real-world use cases\n",
    "- **Ratio statistics**: if $Z_1, Z_2 \\sim \\mathcal{N}(0,1)$ i.i.d., then $Z_1/Z_2$ is standard Cauchy.\n",
    "- **Robust error models**: using a Cauchy likelihood downweights outliers even more aggressively than a Student-t with larger degrees of freedom.\n",
    "- **Weakly-informative priors**: the (half-)Cauchy is a popular prior for scale parameters in Bayesian hierarchical models.\n",
    "\n",
    "### Relations to other distributions\n",
    "- **Student-t**: $\\mathrm{Cauchy}(0,1)$ is exactly Student-$t$ with $\\nu=1$ degree of freedom.\n",
    "- **Stable distributions**: Cauchy is *stable* with stability parameter $\\alpha=1$.\n",
    "- **Uniform → Cauchy**: if $U\\sim \\mathrm{Unif}(0,1)$ then $\\tan\\bigl(\\pi(U-\\tfrac{1}{2})\\bigr)$ is standard Cauchy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc452f2",
   "metadata": {},
   "source": [
    "## 3) Formal definition\n",
    "\n",
    "### PDF\n",
    "For $X \\sim \\mathrm{Cauchy}(x_0, \\gamma)$:\n",
    "\n",
    "$$\n",
    " f(x; x_0, \\gamma) = \\frac{1}{\\pi \\gamma\\left[1 + \\left(\\frac{x-x_0}{\\gamma}\\right)^2\\right]}.\n",
    "$$\n",
    "\n",
    "### CDF\n",
    "\n",
    "$$\n",
    " F(x; x_0, \\gamma) = \\frac{1}{\\pi}\\arctan\\left(\\frac{x-x_0}{\\gamma}\\right) + \\frac{1}{2}.\n",
    "$$\n",
    "\n",
    "### Quantile function (inverse CDF)\n",
    "\n",
    "$$\n",
    "F^{-1}(p) = x_0 + \\gamma\\,\\tan\\left(\\pi\\left(p-\\tfrac{1}{2}\\right)\\right),\\qquad p\\in(0,1).\n",
    "$$\n",
    "\n",
    "We'll implement these directly (NumPy-only) and cross-check against SciPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db39ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cauchy_pdf(x: np.ndarray, x0: float = 0.0, gamma: float = 1.0) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if gamma <= 0:\n",
    "        raise ValueError(\"gamma must be > 0\")\n",
    "    z = (x - x0) / gamma\n",
    "    return 1.0 / (np.pi * gamma * (1.0 + z * z))\n",
    "\n",
    "\n",
    "def cauchy_logpdf(x: np.ndarray, x0: float = 0.0, gamma: float = 1.0) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if gamma <= 0:\n",
    "        raise ValueError(\"gamma must be > 0\")\n",
    "    z = (x - x0) / gamma\n",
    "    return -np.log(np.pi * gamma) - np.log1p(z * z)\n",
    "\n",
    "\n",
    "def cauchy_cdf(x: np.ndarray, x0: float = 0.0, gamma: float = 1.0) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if gamma <= 0:\n",
    "        raise ValueError(\"gamma must be > 0\")\n",
    "    return 0.5 + np.arctan((x - x0) / gamma) / np.pi\n",
    "\n",
    "\n",
    "def cauchy_ppf(p: np.ndarray, x0: float = 0.0, gamma: float = 1.0) -> np.ndarray:\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    if gamma <= 0:\n",
    "        raise ValueError(\"gamma must be > 0\")\n",
    "    if np.any((p <= 0) | (p >= 1)):\n",
    "        raise ValueError(\"p must be in (0, 1)\")\n",
    "    return x0 + gamma * np.tan(np.pi * (p - 0.5))\n",
    "\n",
    "\n",
    "# Quick cross-check with SciPy\n",
    "x = np.linspace(-5, 5, 9)\n",
    "print(\"max |pdf - scipy|:\", np.max(np.abs(cauchy_pdf(x) - cauchy.pdf(x))))\n",
    "print(\"max |cdf - scipy|:\", np.max(np.abs(cauchy_cdf(x) - cauchy.cdf(x))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4d226f",
   "metadata": {},
   "source": [
    "## 4) Moments & properties\n",
    "\n",
    "### Mean, variance, skewness, kurtosis\n",
    "For a Cauchy distribution:\n",
    "\n",
    "- **Mean**: **undefined** (does not exist as a finite expectation)\n",
    "- **Variance**: **undefined** / infinite\n",
    "- **Skewness**: undefined\n",
    "- **Kurtosis**: undefined\n",
    "\n",
    "Even though the PDF is symmetric (when centered), the expectation fails because the integral is not **absolutely integrable**.\n",
    "\n",
    "What *does* exist and is often useful:\n",
    "\n",
    "- **Median**: $x_0$\n",
    "- **Mode**: $x_0$\n",
    "- **Quantiles**: $Q(p)=x_0+\\gamma\\tan(\\pi(p-1/2))$\n",
    "- **IQR**: $Q(0.75)-Q(0.25)=2\\gamma$  (so $\\gamma = \\tfrac{\\mathrm{IQR}}{2}$)\n",
    "\n",
    "### MGF and characteristic function\n",
    "- **MGF** $M_X(t)=\\mathbb{E}[e^{tX}]$ does **not** exist for any nonzero $t$.\n",
    "- The **characteristic function** does exist:\n",
    "\n",
    "$$\\varphi_X(t) = \\mathbb{E}[e^{itX}] = \\exp\\bigl(i x_0 t - \\gamma |t|\\bigr).$$\n",
    "\n",
    "### Entropy\n",
    "The (differential) entropy is finite:\n",
    "\n",
    "$$h(X)=\\log(4\\pi\\gamma).$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ef38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the characteristic function\n",
    "# φ(t) = exp(i x0 t - γ|t|)\n",
    "\n",
    "x0, gamma = 0.0, 1.0\n",
    "\n",
    "t = np.linspace(-12, 12, 2000)\n",
    "phi = np.exp(1j * x0 * t - gamma * np.abs(t))\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Re φ(t)\", \"Im φ(t)\"))\n",
    "fig.add_trace(go.Scatter(x=t, y=np.real(phi), mode=\"lines\", name=\"Re\"), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=t, y=np.imag(phi), mode=\"lines\", name=\"Im\"), row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"t\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"t\", row=1, col=2)\n",
    "fig.update_layout(width=950, height=350, showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871ce21a",
   "metadata": {},
   "source": [
    "## 5) Parameter interpretation\n",
    "\n",
    "- $x_0$ (**location**): shifts the distribution left/right. It is the **median** and **mode**.\n",
    "- $\\gamma$ (**scale**): stretches the distribution. It is the **half-width at half-maximum** (HWHM):\n",
    "\n",
    "$$f(x_0 \\pm \\gamma) = \\tfrac{1}{2} f(x_0).$$\n",
    "\n",
    "A practical, robust interpretation:\n",
    "\n",
    "- $Q(0.75)=x_0+\\gamma$ and $Q(0.25)=x_0-\\gamma$ so $\\gamma = \\tfrac{\\mathrm{IQR}}{2}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2eff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape changes: PDF and CDF for different (x0, γ)\n",
    "\n",
    "x = np.linspace(-10, 10, 2000)\n",
    "params = [\n",
    "    (0.0, 0.5),\n",
    "    (0.0, 1.0),\n",
    "    (0.0, 2.0),\n",
    "    (2.0, 1.0),\n",
    "]\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"PDF\", \"CDF\"))\n",
    "\n",
    "for x0, gamma in params:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=x, y=cauchy_pdf(x, x0=x0, gamma=gamma), mode=\"lines\", name=f\"x0={x0}, γ={gamma}\"),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=x, y=cauchy_cdf(x, x0=x0, gamma=gamma), mode=\"lines\", name=f\"x0={x0}, γ={gamma}\"),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"f(x)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"F(x)\", row=1, col=2)\n",
    "fig.update_layout(width=1000, height=420)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe98e33",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### Expectation (why the mean does not exist)\n",
    "For the standard Cauchy $f(x)=\\frac{1}{\\pi(1+x^2)}$:\n",
    "\n",
    "$$\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty} x\\,f(x)\\,dx$$\n",
    "\n",
    "The integrand is odd, and the *principal value* integral is 0, but the expectation is defined via **absolute integrability**:\n",
    "\n",
    "$$\\mathbb{E}[X]\\text{ exists if }\\int_{-\\infty}^{\\infty} |x| f(x)\\,dx < \\infty.$$\n",
    "\n",
    "However, for large $x$:\n",
    "\n",
    "$$|x|f(x) = \\frac{|x|}{\\pi(1+x^2)} \\sim \\frac{1}{\\pi |x|},$$\n",
    "\n",
    "and $\\int^\\infty \\frac{1}{x}\\,dx$ diverges. Therefore the mean is **undefined**.\n",
    "\n",
    "A useful explicit calculation for the truncated absolute moment:\n",
    "\n",
    "$$\n",
    "\\int_{-A}^{A} |x|\\,f(x)\\,dx\n",
    "= \\frac{2}{\\pi}\\int_0^A \\frac{x}{1+x^2}\\,dx\n",
    "= \\frac{1}{\\pi}\\log(1+A^2) \\xrightarrow[A\\to\\infty]{} \\infty.\n",
    "$$\n",
    "\n",
    "### Variance (why it does not exist)\n",
    "Similarly,\n",
    "\n",
    "$$\\mathbb{E}[X^2] = \\int x^2 f(x)\\,dx,$$\n",
    "\n",
    "but for large $x$, $x^2 f(x) \\sim \\frac{1}{\\pi}$, so the integral diverges linearly.\n",
    "\n",
    "### Likelihood\n",
    "Given i.i.d. data $x_1,\\dots,x_n$ from $\\mathrm{Cauchy}(x_0,\\gamma)$, the log-likelihood is:\n",
    "\n",
    "$$\n",
    "\\ell(x_0,\\gamma) = \\sum_{i=1}^n \\log f(x_i; x_0,\\gamma)\n",
    "= -n\\log(\\pi\\gamma) - \\sum_{i=1}^n \\log\\left(1 + \\left(\\frac{x_i-x_0}{\\gamma}\\right)^2\\right).\n",
    "$$\n",
    "\n",
    "The score equations (set derivatives to 0) have no simple closed form; MLE is typically found numerically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e367ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncated absolute moment grows ~ log A (so the mean cannot exist)\n",
    "\n",
    "A = np.logspace(0, 4, 30)  # 1 ... 10^4\n",
    "trunc_abs_moment = (1.0 / np.pi) * np.log1p(A * A)  # exact for standard Cauchy\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=A, y=trunc_abs_moment, mode=\"lines+markers\"))\n",
    "fig.update_xaxes(title_text=\"A\", type=\"log\")\n",
    "fig.update_yaxes(title_text=r\"∫_{-A}^{A} |x| f(x) dx\")\n",
    "fig.update_layout(title=\"Truncated E[|X|] diverges (log growth)\", width=850, height=420)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae42c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cauchy_loglik(x: np.ndarray, x0: float, gamma: float) -> float:\n",
    "    return float(np.sum(cauchy_logpdf(x, x0=x0, gamma=gamma)))\n",
    "\n",
    "\n",
    "def cauchy_mle_scipy(x: np.ndarray) -> tuple[float, float]:\n",
    "    \"\"\"MLE via SciPy optimizer on (x0, log_gamma).\"\"\"\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    def nll(theta: np.ndarray) -> float:\n",
    "        x0, log_gamma = float(theta[0]), float(theta[1])\n",
    "        gamma = float(np.exp(log_gamma))\n",
    "        return -cauchy_loglik(x, x0=x0, gamma=gamma)\n",
    "\n",
    "    # Robust start: median and IQR/2 (exact relationship for Cauchy)\n",
    "    x0_init = float(np.median(x))\n",
    "    q25, q75 = np.quantile(x, [0.25, 0.75])\n",
    "    gamma_init = float(max((q75 - q25) / 2.0, 1e-6))\n",
    "\n",
    "    res = optimize.minimize(\n",
    "        nll,\n",
    "        x0=np.array([x0_init, np.log(gamma_init)]),\n",
    "        method=\"Nelder-Mead\",\n",
    "        options={\"maxiter\": 5000},\n",
    "    )\n",
    "\n",
    "    x0_hat, log_gamma_hat = res.x\n",
    "    return float(x0_hat), float(np.exp(log_gamma_hat))\n",
    "\n",
    "\n",
    "# Demonstrate likelihood estimation on a sample\n",
    "true_x0, true_gamma = 0.0, 1.0\n",
    "x_sample = cauchy.rvs(loc=true_x0, scale=true_gamma, size=200, random_state=rng)\n",
    "\n",
    "x0_hat, gamma_hat = cauchy_mle_scipy(x_sample)\n",
    "print(\"true  (x0, γ) =\", (true_x0, true_gamma))\n",
    "print(\"MLE   (x0, γ) =\", (x0_hat, gamma_hat))\n",
    "\n",
    "# Compare to robust quantile-based estimator\n",
    "x0_med = float(np.median(x_sample))\n",
    "q25, q75 = np.quantile(x_sample, [0.25, 0.75])\n",
    "gamma_iqr = float((q75 - q25) / 2.0)\n",
    "print(\"median/IQR (x0, γ) =\", (x0_med, gamma_iqr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296fbb75",
   "metadata": {},
   "source": [
    "## 7) Sampling & simulation (NumPy-only)\n",
    "\n",
    "### Inverse CDF method\n",
    "Because we have a closed-form inverse CDF, sampling is straightforward:\n",
    "\n",
    "1. Draw $U \\sim \\mathrm{Unif}(0,1)$\n",
    "2. Return $X = F^{-1}(U) = x_0 + \\gamma\\tan\\bigl(\\pi(U-1/2)\\bigr)$\n",
    "\n",
    "This works because $F(X)$ is uniform for any continuous distribution.\n",
    "\n",
    "### Ratio-of-normals method (alternative)\n",
    "If $Z_1, Z_2 \\sim \\mathcal{N}(0,1)$ i.i.d., then $Z_1/Z_2$ is standard Cauchy. This provides another simple sampler.\n",
    "\n",
    "We'll implement both with NumPy and verify they agree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22847a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_cauchy_inverse_cdf(\n",
    "    rng: np.random.Generator,\n",
    "    size: int,\n",
    "    x0: float = 0.0,\n",
    "    gamma: float = 1.0,\n",
    "    eps: float = 1e-12,\n",
    ") -> np.ndarray:\n",
    "    if gamma <= 0:\n",
    "        raise ValueError(\"gamma must be > 0\")\n",
    "    u = rng.random(size)\n",
    "    u = np.clip(u, eps, 1.0 - eps)  # avoid tan(±π/2)\n",
    "    return x0 + gamma * np.tan(np.pi * (u - 0.5))\n",
    "\n",
    "\n",
    "def sample_cauchy_ratio_normals(\n",
    "    rng: np.random.Generator,\n",
    "    size: int,\n",
    "    x0: float = 0.0,\n",
    "    gamma: float = 1.0,\n",
    ") -> np.ndarray:\n",
    "    if gamma <= 0:\n",
    "        raise ValueError(\"gamma must be > 0\")\n",
    "    z1 = rng.standard_normal(size)\n",
    "    z2 = rng.standard_normal(size)\n",
    "    return x0 + gamma * (z1 / z2)\n",
    "\n",
    "\n",
    "# Quick sampler comparison\n",
    "n = 200_000\n",
    "x_inv = sample_cauchy_inverse_cdf(rng, n)\n",
    "x_rat = sample_cauchy_ratio_normals(rng, n)\n",
    "\n",
    "# Compare a few robust summaries (means are meaningless here)\n",
    "for name, x in [(\"inverse\", x_inv), (\"ratio\", x_rat)]:\n",
    "    med = float(np.median(x))\n",
    "    q25, q75 = np.quantile(x, [0.25, 0.75])\n",
    "    print(name, \"median\", med, \"IQR/2\", (q75 - q25) / 2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92488fe4",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We'll visualize:\n",
    "\n",
    "- the **PDF** and **CDF**\n",
    "- a **histogram of Monte Carlo samples** with PDF overlay\n",
    "- why the **running mean** fails to stabilize for Cauchy samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42222564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF and CDF (standard Cauchy)\n",
    "\n",
    "x = np.linspace(-10, 10, 4000)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"PDF\", \"CDF\"))\n",
    "fig.add_trace(go.Scatter(x=x, y=cauchy_pdf(x), mode=\"lines\", name=\"pdf\"), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=x, y=cauchy_cdf(x), mode=\"lines\", name=\"cdf\"), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"f(x)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"x\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"F(x)\", row=1, col=2)\n",
    "fig.update_layout(width=950, height=380, showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e93aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo samples: histogram + PDF overlay\n",
    "\n",
    "n = 200_000\n",
    "x_samp = sample_cauchy_inverse_cdf(rng, n)\n",
    "\n",
    "# Clip for visualization only (Cauchy produces extreme values)\n",
    "clip = 25\n",
    "x_vis = x_samp[np.abs(x_samp) <= clip]\n",
    "\n",
    "xbins = np.linspace(-clip, clip, 120)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=x_vis,\n",
    "        xbins=dict(start=-clip, end=clip, size=xbins[1] - xbins[0]),\n",
    "        histnorm=\"probability density\",\n",
    "        name=\"samples\",\n",
    "    )\n",
    ")\n",
    "\n",
    "xgrid = np.linspace(-clip, clip, 2000)\n",
    "fig.add_trace(go.Scatter(x=xgrid, y=cauchy_pdf(xgrid), mode=\"lines\", name=\"true pdf\", line=dict(width=3)))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Cauchy samples (n={n:,}) — histogram clipped to |x|≤{clip} for readability\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"density\",\n",
    "    width=950,\n",
    "    height=450,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"fraction clipped:\", 1.0 - (len(x_vis) / len(x_samp)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba6c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running mean vs running median: mean doesn't stabilize\n",
    "\n",
    "n = 50_000\n",
    "x = sample_cauchy_inverse_cdf(rng, n)\n",
    "\n",
    "running_mean = np.cumsum(x) / (np.arange(n) + 1)\n",
    "\n",
    "# Running median (O(n^2) naive) is expensive; approximate using block medians.\n",
    "block = 200\n",
    "m = n // block\n",
    "block_medians = np.array([np.median(x[i * block : (i + 1) * block]) for i in range(m)])\n",
    "running_block_median = np.cumsum(block_medians) / (np.arange(m) + 1)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    shared_xaxes=False,\n",
    "    vertical_spacing=0.12,\n",
    "    subplot_titles=(\"Running mean (highly unstable)\", f\"Average of block medians (block={block})\"),\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(x=np.arange(n), y=running_mean, mode=\"lines\", line=dict(width=1)), row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"mean\", row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=np.arange(m) * block, y=running_block_median, mode=\"lines\", line=dict(width=2)), row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"sample index\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"avg median\", row=2, col=1)\n",
    "\n",
    "fig.update_layout(width=950, height=650, showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80841c54",
   "metadata": {},
   "source": [
    "## 9) SciPy integration (`scipy.stats.cauchy`)\n",
    "\n",
    "SciPy parameterization matches the usual location/scale form:\n",
    "\n",
    "- `loc` = $x_0$\n",
    "- `scale` = $\\gamma$\n",
    "\n",
    "Key methods:\n",
    "\n",
    "- `cauchy.pdf(x, loc, scale)`\n",
    "- `cauchy.cdf(x, loc, scale)`\n",
    "- `cauchy.rvs(loc, scale, size, random_state)`\n",
    "- `cauchy.fit(data)`  (MLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0fcb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic SciPy usage\n",
    "\n",
    "x0, gamma = 1.5, 0.8\n",
    "x = np.array([-2.0, 0.0, 2.0])\n",
    "\n",
    "print(\"pdf:\", cauchy.pdf(x, loc=x0, scale=gamma))\n",
    "print(\"cdf:\", cauchy.cdf(x, loc=x0, scale=gamma))\n",
    "\n",
    "samples = cauchy.rvs(loc=x0, scale=gamma, size=5, random_state=rng)\n",
    "print(\"rvs:\", samples)\n",
    "\n",
    "# Fit (MLE) from samples\n",
    "n = 5_000\n",
    "data = cauchy.rvs(loc=x0, scale=gamma, size=n, random_state=rng)\n",
    "\n",
    "loc_hat, scale_hat = cauchy.fit(data)  # returns (loc, scale)\n",
    "\n",
    "# Robust quantile-based estimate (exact IQR relationship)\n",
    "loc_med = float(np.median(data))\n",
    "q25, q75 = np.quantile(data, [0.25, 0.75])\n",
    "scale_iqr = float((q75 - q25) / 2.0)\n",
    "\n",
    "print(\"true  (loc, scale) =\", (x0, gamma))\n",
    "print(\"fit   (loc, scale) =\", (loc_hat, scale_hat))\n",
    "print(\"IQR   (loc, scale) =\", (loc_med, scale_iqr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69df68a1",
   "metadata": {},
   "source": [
    "## 10) Statistical use cases\n",
    "\n",
    "### Hypothesis testing (location)\n",
    "Because the mean is undefined, tests based on the sample mean are not appropriate.\n",
    "\n",
    "A simple alternative is to test the **location** using the **sample median**. For known $\\gamma$, the sample median is asymptotically normal:\n",
    "\n",
    "$$\\tilde{X} \\approx \\mathcal{N}\\left(x_0,\\ \\frac{1}{4n f(x_0)^2}\\right)\n",
    "= \\mathcal{N}\\left(x_0,\\ \\frac{(\\pi\\gamma)^2}{4n}\\right).$$\n",
    "\n",
    "So an approximate z-test for $H_0: x_0=x_{0,0}$ is:\n",
    "\n",
    "$$z = \\frac{\\tilde{x} - x_{0,0}}{\\pi\\gamma/(2\\sqrt{n})}.$$\n",
    "\n",
    "### Bayesian modeling\n",
    "- **Cauchy likelihood**: a robust alternative to Gaussian noise (strong outlier downweighting).\n",
    "- **(Half-)Cauchy priors**: common weakly-informative priors for scales (e.g., hierarchical standard deviations).\n",
    "\n",
    "### Generative modeling\n",
    "- As a heavy-tailed component/noise distribution.\n",
    "- As a stable distribution: sums of independent Cauchy variables remain Cauchy (up to parameter updates).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfe0a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location test via the sample median (known γ)\n",
    "\n",
    "def median_z_test_cauchy_location(x: np.ndarray, x0_null: float, gamma: float) -> tuple[float, float]:\n",
    "    \"\"\"Approximate two-sided z-test for the location using the sample median.\n",
    "\n",
    "    Returns (z, p_value) using asymptotic normality of the median.\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if gamma <= 0:\n",
    "        raise ValueError(\"gamma must be > 0\")\n",
    "\n",
    "    n = x.size\n",
    "    med = float(np.median(x))\n",
    "    se = (np.pi * gamma) / (2.0 * np.sqrt(n))\n",
    "    z = (med - x0_null) / se\n",
    "\n",
    "    # two-sided p-value under N(0,1)\n",
    "    p = 2.0 * (1.0 - norm.cdf(abs(z)))\n",
    "    return float(z), float(p)\n",
    "\n",
    "\n",
    "# Simulate data under H0 and H1\n",
    "n = 301\n",
    "true_x0, gamma = 0.0, 1.0\n",
    "\n",
    "x_h0 = cauchy.rvs(loc=true_x0, scale=gamma, size=n, random_state=rng)\n",
    "print(\"H0 example:\", median_z_test_cauchy_location(x_h0, x0_null=0.0, gamma=gamma))\n",
    "\n",
    "x_h1 = cauchy.rvs(loc=0.7, scale=gamma, size=n, random_state=rng)\n",
    "print(\"H1 example:\", median_z_test_cauchy_location(x_h1, x0_null=0.0, gamma=gamma))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aabd1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple Bayesian example: posterior over x0 with known γ (grid approximation)\n",
    "\n",
    "# Model: x_i ~ Cauchy(x0, γ), prior: x0 ~ Cauchy(0, τ)\n",
    "\n",
    "tau = 2.0\n",
    "true_x0, gamma = 1.0, 1.0\n",
    "\n",
    "x = cauchy.rvs(loc=true_x0, scale=gamma, size=50, random_state=rng)\n",
    "\n",
    "# Grid over x0\n",
    "grid = np.linspace(-8, 8, 4001)\n",
    "\n",
    "dx = grid[1] - grid[0]\n",
    "\n",
    "log_prior = cauchy_logpdf(grid, x0=0.0, gamma=tau)\n",
    "log_like = np.sum(cauchy_logpdf(x[:, None], x0=grid[None, :], gamma=gamma), axis=0)\n",
    "log_post_unnorm = log_prior + log_like\n",
    "\n",
    "# Stabilize and normalize\n",
    "log_post_unnorm -= np.max(log_post_unnorm)\n",
    "post = np.exp(log_post_unnorm)\n",
    "post /= np.trapz(post, grid)\n",
    "\n",
    "post_cdf = np.cumsum(post) * dx\n",
    "post_cdf /= post_cdf[-1]\n",
    "\n",
    "# Posterior summaries\n",
    "x0_map = float(grid[np.argmax(post)])\n",
    "# posterior median\n",
    "x0_med = float(np.interp(0.5, post_cdf, grid))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=grid, y=post, mode=\"lines\", name=\"posterior density\"))\n",
    "fig.add_vline(x=true_x0, line=dict(dash=\"dash\"), annotation_text=\"true x0\")\n",
    "fig.add_vline(x=x0_map, line=dict(dash=\"dot\"), annotation_text=\"MAP\")\n",
    "fig.add_vline(x=x0_med, line=dict(dash=\"dot\"), annotation_text=\"post median\")\n",
    "fig.update_layout(\n",
    "    title=\"Posterior over location x0 (Cauchy likelihood, Cauchy prior; γ known)\",\n",
    "    xaxis_title=\"x0\",\n",
    "    yaxis_title=\"density\",\n",
    "    width=950,\n",
    "    height=420,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"true x0:\", true_x0)\n",
    "print(\"MAP:\", x0_map)\n",
    "print(\"posterior median:\", x0_med)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ef3824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative property: stability under addition\n",
    "\n",
    "# If X ~ Cauchy(x0, γ) and Y ~ Cauchy(y0, δ) independent,\n",
    "# then X+Y ~ Cauchy(x0+y0, γ+δ).\n",
    "\n",
    "n = 200_000\n",
    "x0, gamma = 0.0, 1.0\n",
    "y0, delta = 0.0, 2.0\n",
    "\n",
    "x = sample_cauchy_inverse_cdf(rng, n, x0=x0, gamma=gamma)\n",
    "y = sample_cauchy_inverse_cdf(rng, n, x0=y0, gamma=delta)\n",
    "z = x + y\n",
    "\n",
    "# Compare robust estimates (median and IQR/2)\n",
    "med_z = float(np.median(z))\n",
    "q25, q75 = np.quantile(z, [0.25, 0.75])\n",
    "scale_z = float((q75 - q25) / 2.0)\n",
    "\n",
    "print(\"theory median:\", x0 + y0)\n",
    "print(\"empirical median:\", med_z)\n",
    "print(\"theory scale:\", gamma + delta)\n",
    "print(\"empirical scale (IQR/2):\", scale_z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f2efce",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Invalid parameters**: the scale must satisfy $\\gamma>0$.\n",
    "- **Mean/variance-based methods break**: sample mean is not consistent and does not stabilize; moment-matching and CLT-based standard errors do not apply.\n",
    "- **Extreme values are normal**: Monte Carlo histograms often need clipping for visualization.\n",
    "- **Numerical issues in sampling**: inverse-CDF uses `tan(·)`, which explodes near $\\pm\\pi/2$; clip uniform draws away from 0 and 1.\n",
    "- **Likelihood optimization**: the log-likelihood can be relatively flat with multiple local optima for small samples; use robust initialization (median, IQR/2).\n",
    "- **Use `logpdf` for products**: working in log-space avoids underflow when multiplying many densities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c1b5db",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `cauchy` is a **continuous**, **heavy-tailed** distribution on $\\mathbb{R}$ with parameters $(x_0,\\gamma)$.\n",
    "- The **PDF/CDF/PPF** have simple closed forms; sampling via **inverse CDF** is easy.\n",
    "- **Mean and variance do not exist**; prefer **median/quantiles/IQR** for summaries.\n",
    "- It is Student-$t$ with $\\nu=1$ and is **stable** under addition.\n",
    "- In practice it is useful for **robust modeling** and as a **(half-)Cauchy prior** for scale parameters.\n",
    "\n",
    "References:\n",
    "- SciPy docs: `scipy.stats.cauchy`\n",
    "- Johnson, Kotz, Balakrishnan — *Continuous Univariate Distributions*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
