Search.setIndex({"docnames": ["backend/00_overview", "backend/api_design/00_overview", "backend/auth_security/00_overview", "backend/caching_queues/00_overview", "backend/communication_patterns/00_overview", "backend/data_storage_modeling/00_overview", "backend/observability/00_overview", "backend/resilience_performance/00_overview", "backend/testing_quality/00_overview", "book_index", "cybersecurity/00_overview", "cybersecurity/identity_access/00_overview", "cybersecurity/incident_response/00_overview", "cybersecurity/network_cloud_security/00_overview", "cybersecurity/secure_coding_owasp/00_overview", "cybersecurity/threat_modeling/00_overview", "cybersecurity/vulnerability_management/00_overview", "data_science/00_overview", "data_science/deeplearning/00_overview", "data_science/deeplearning/tabular_data/artificial_neural_networks/00_overview", "data_science/deeplearning/timeseries/lstm_and_gru/00_overview", "data_science/deeplearning/visual/cnn/00_overview", "data_science/deeplearning/visual/resnet/00_overview", "data_science/linear_algebra/00_overview", "data_science/machine_learning/00_overview", "data_science/machine_learning/dimensionality_reduction/tabular_data/dbscan/00_overview", "data_science/machine_learning/dimensionality_reduction/tabular_data/ica/00_overview", "data_science/machine_learning/dimensionality_reduction/tabular_data/isomap/00_overview", "data_science/machine_learning/dimensionality_reduction/tabular_data/lle/00_overview", "data_science/machine_learning/dimensionality_reduction/tabular_data/mds/00_overview", "data_science/machine_learning/dimensionality_reduction/tabular_data/pca/00_overview", "data_science/machine_learning/dimensionality_reduction/tabular_data/tsne/00_overview", "data_science/machine_learning/dimensionality_reduction/tabular_data/umap/00_overview", "data_science/machine_learning/metrics/tabular/classification/00_overview", "data_science/machine_learning/metrics/tabular/classification/accuracy_score/00_overview", "data_science/machine_learning/metrics/tabular/classification/auc/00_overview", "data_science/machine_learning/metrics/tabular/classification/average_precision_score/00_overview", "data_science/machine_learning/metrics/tabular/classification/balanced_accuracy_score/00_overview", "data_science/machine_learning/metrics/tabular/classification/brier_score_loss/00_overview", "data_science/machine_learning/metrics/tabular/classification/class_likelihood_ratios/00_overview", "data_science/machine_learning/metrics/tabular/classification/classification_report/00_overview", "data_science/machine_learning/metrics/tabular/classification/cohen_kappa_score/00_overview", "data_science/machine_learning/metrics/tabular/classification/confusion_matrix/00_overview", "data_science/machine_learning/metrics/tabular/classification/confusion_matrix_at_thresholds/00_overview", "data_science/machine_learning/metrics/tabular/classification/coverage_error/00_overview", "data_science/machine_learning/metrics/tabular/classification/d2_brier_score/00_overview", "data_science/machine_learning/metrics/tabular/classification/d2_log_loss_score/00_overview", "data_science/machine_learning/metrics/tabular/classification/dcg_score/00_overview", "data_science/machine_learning/metrics/tabular/classification/det_curve/00_overview", "data_science/machine_learning/metrics/tabular/classification/f1_score/00_overview", "data_science/machine_learning/metrics/tabular/classification/fbeta_score/00_overview", "data_science/machine_learning/metrics/tabular/classification/hamming_loss/00_overview", "data_science/machine_learning/metrics/tabular/classification/hinge_loss/00_overview", "data_science/machine_learning/metrics/tabular/classification/jaccard_score/00_overview", "data_science/machine_learning/metrics/tabular/classification/label_ranking_average_precision_score/00_overview", "data_science/machine_learning/metrics/tabular/classification/label_ranking_loss/00_overview", "data_science/machine_learning/metrics/tabular/classification/log_loss/00_overview", "data_science/machine_learning/metrics/tabular/classification/matthews_corrcoef/00_overview", "data_science/machine_learning/metrics/tabular/classification/multilabel_confusion_matrix/00_overview", "data_science/machine_learning/metrics/tabular/classification/ndcg_score/00_overview", "data_science/machine_learning/metrics/tabular/classification/precision_recall_curve/00_overview", "data_science/machine_learning/metrics/tabular/classification/precision_recall_fscore_support/00_overview", "data_science/machine_learning/metrics/tabular/classification/precision_score/00_overview", "data_science/machine_learning/metrics/tabular/classification/recall_score/00_overview", "data_science/machine_learning/metrics/tabular/classification/roc_auc_score/00_overview", "data_science/machine_learning/metrics/tabular/classification/roc_curve/00_overview", "data_science/machine_learning/metrics/tabular/classification/top_k_accuracy_score/00_overview", "data_science/machine_learning/metrics/tabular/classification/zero_one_loss/00_overview", "data_science/machine_learning/metrics/tabular/clustering/00_overview", "data_science/machine_learning/metrics/tabular/clustering/adjusted_mutual_info_score/00_overview", "data_science/machine_learning/metrics/tabular/clustering/adjusted_rand_score/00_overview", "data_science/machine_learning/metrics/tabular/clustering/calinski_harabasz_score/00_overview", "data_science/machine_learning/metrics/tabular/clustering/completeness_score/00_overview", "data_science/machine_learning/metrics/tabular/clustering/contingency_matrix/00_overview", "data_science/machine_learning/metrics/tabular/clustering/davies_bouldin_score/00_overview", "data_science/machine_learning/metrics/tabular/clustering/fowlkes_mallows_score/00_overview", "data_science/machine_learning/metrics/tabular/clustering/homogeneity_completeness_v_measure/00_overview", "data_science/machine_learning/metrics/tabular/clustering/homogeneity_score/00_overview", "data_science/machine_learning/metrics/tabular/clustering/mutual_info_score/00_overview", "data_science/machine_learning/metrics/tabular/clustering/normalized_mutual_info_score/00_overview", "data_science/machine_learning/metrics/tabular/clustering/pair_confusion_matrix/00_overview", "data_science/machine_learning/metrics/tabular/clustering/rand_score/00_overview", "data_science/machine_learning/metrics/tabular/clustering/silhouette_samples/00_overview", "data_science/machine_learning/metrics/tabular/clustering/silhouette_score/00_overview", "data_science/machine_learning/metrics/tabular/clustering/v_measure_score/00_overview", "data_science/machine_learning/metrics/tabular/regression/00_overview", "data_science/machine_learning/metrics/tabular/regression/d2_absolute_error_score/00_overview", "data_science/machine_learning/metrics/tabular/regression/d2_pinball_score/00_overview", "data_science/machine_learning/metrics/tabular/regression/d2_tweedie_score/00_overview", "data_science/machine_learning/metrics/tabular/regression/explained_variance_score/00_overview", "data_science/machine_learning/metrics/tabular/regression/max_error/00_overview", "data_science/machine_learning/metrics/tabular/regression/mean_absolute_error/00_overview", "data_science/machine_learning/metrics/tabular/regression/mean_absolute_percentage_error/00_overview", "data_science/machine_learning/metrics/tabular/regression/mean_gamma_deviance/00_overview", "data_science/machine_learning/metrics/tabular/regression/mean_pinball_loss/00_overview", "data_science/machine_learning/metrics/tabular/regression/mean_poisson_deviance/00_overview", "data_science/machine_learning/metrics/tabular/regression/mean_squared_error/00_overview", "data_science/machine_learning/metrics/tabular/regression/mean_squared_log_error/00_overview", "data_science/machine_learning/metrics/tabular/regression/mean_tweedie_deviance/00_overview", "data_science/machine_learning/metrics/tabular/regression/median_absolute_error/00_overview", "data_science/machine_learning/metrics/tabular/regression/r2_score/00_overview", "data_science/machine_learning/metrics/tabular/regression/root_mean_squared_error/00_overview", "data_science/machine_learning/metrics/tabular/regression/root_mean_squared_log_error/00_overview", "data_science/machine_learning/supervised_learning/tabular_data/gaussian_processes/00_overview", "data_science/machine_learning/supervised_learning/tabular_data/generalized_linear_models/00_overview", "data_science/machine_learning/supervised_learning/tabular_data/k_nearest_neighbors/00_overview", "data_science/machine_learning/supervised_learning/tabular_data/linear_and_quadratic_discriminant_analysis/00_overview", "data_science/machine_learning/supervised_learning/tabular_data/linear_regression_and_co/00_overview", "data_science/machine_learning/supervised_learning/tabular_data/naive_bayes/00_overview", "data_science/machine_learning/supervised_learning/tabular_data/support_vector_machines/00_overview", "data_science/machine_learning/supervised_learning/tabular_data/tree_based_algorithms/00_overview", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/01_arch_models/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/01_autoregressive_ar/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/01_kalman_filter/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/01_moving_average_ma/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/01_prophet/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/01_sarima/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/01_varma/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/01_vector_autoregression_var/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/02_arima_autoregressive_integrated_moving_average/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/02_bats/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/02_garch_models/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/02_sarimax/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/02_varmax/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/03_tbats/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/distancebased/k_neighbors_time_series_regressor/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/distancebased/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/ensemble/composable_time_series_forest_regressor/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/ensemble/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/ensemble/time_series_forest_regressor/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/kernelbased/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/kernelbased/rocket_regressor/overview", "data_science/machine_learning/supervised_learning/timeseries/regression/kernelbased/time_series_svr_tslearn/overview", "data_science/reinforcement_learning/00_overview", "data_science/reinforcement_learning/A2C/00_overview", "data_science/reinforcement_learning/ACKTR/00_overview", "data_science/reinforcement_learning/ACKTR/01_acktr_from_scratch", "data_science/reinforcement_learning/DDPG/00_overview", "data_science/reinforcement_learning/DDPG/01_ddpg_from_scratch", "data_science/reinforcement_learning/DQN/00_overview", "data_science/reinforcement_learning/GAIL/00_overview", "data_science/reinforcement_learning/HER/00_overview", "data_science/reinforcement_learning/PPO1/00_overview", "data_science/reinforcement_learning/PPO2/00_overview", "data_science/reinforcement_learning/SAC/00_overview", "data_science/reinforcement_learning/TD3/00_overview", "data_science/reinforcement_learning/TRPO/00_overview", "data_science/statistics/00_overview", "data_science/statistics/distributions/01_common_distributions/continous/alpha/overview", "data_science/statistics/distributions/01_common_distributions/continous/anglit/overview", "data_science/statistics/distributions/01_common_distributions/continous/arcsine/overview", "data_science/statistics/distributions/01_common_distributions/continous/argus/overview", "data_science/statistics/distributions/01_common_distributions/continous/beta/overview", "data_science/statistics/distributions/01_common_distributions/continous/bradford/overview", "data_science/statistics/distributions/01_common_distributions/continous/burr/overview", "data_science/statistics/distributions/01_common_distributions/continous/cauchy/overview", "data_science/statistics/distributions/01_common_distributions/continous/cosine/overview", "data_science/statistics/distributions/01_common_distributions/continous/crystalball/overview", "data_science/statistics/distributions/01_common_distributions/continous/dgamma/overview", "data_science/statistics/distributions/01_common_distributions/continous/dirichlet/overview", "data_science/statistics/distributions/01_common_distributions/continous/dpareto_lognorm/overview", "data_science/statistics/distributions/01_common_distributions/continous/dweibull/overview", "data_science/statistics/distributions/01_common_distributions/continous/expon/overview", "data_science/statistics/distributions/01_common_distributions/continous/exponnorm/overview", "data_science/statistics/distributions/01_common_distributions/continous/exponpow/overview", "data_science/statistics/distributions/01_common_distributions/continous/exponweib/overview", "data_science/statistics/distributions/01_common_distributions/continous/f/overview", "data_science/statistics/distributions/01_common_distributions/continous/fatiguelife/overview", "data_science/statistics/distributions/01_common_distributions/continous/fisk/overview", "data_science/statistics/distributions/01_common_distributions/continous/gamma/overview", "data_science/statistics/distributions/01_common_distributions/continous/gausshyper/overview", "data_science/statistics/distributions/01_common_distributions/continous/genexpon/overview", "data_science/statistics/distributions/01_common_distributions/continous/genextreme/overview", "data_science/statistics/distributions/01_common_distributions/continous/gengamma/overview", "data_science/statistics/distributions/01_common_distributions/continous/genhalflogistic/overview", "data_science/statistics/distributions/01_common_distributions/continous/landau/overview", "data_science/statistics/distributions/01_common_distributions/continous/laplace/overview", "data_science/statistics/distributions/01_common_distributions/continous/laplace_asymmetric/overview", "data_science/statistics/distributions/01_common_distributions/continous/levy/overview", "data_science/statistics/distributions/01_common_distributions/continous/levy_l/overview", "data_science/statistics/distributions/01_common_distributions/continous/loggamma/overview", "data_science/statistics/distributions/01_common_distributions/continous/logistic/overview", "data_science/statistics/distributions/01_common_distributions/continous/loglaplace/overview", "data_science/statistics/distributions/01_common_distributions/continous/lognorm/overview", "data_science/statistics/distributions/01_common_distributions/continous/loguniform/overview", "data_science/statistics/distributions/01_common_distributions/continous/matrix_normal/overview", "data_science/statistics/distributions/01_common_distributions/continous/maxwell/overview", "data_science/statistics/distributions/01_common_distributions/continous/mielke/overview", "data_science/statistics/distributions/01_common_distributions/continous/moyal/overview", "data_science/statistics/distributions/01_common_distributions/continous/multivariate_normal/overview", "data_science/statistics/distributions/01_common_distributions/continous/nakagami/overview", "data_science/statistics/distributions/01_common_distributions/continous/ncf/overview", "data_science/statistics/distributions/01_common_distributions/continous/nct/overview", "data_science/statistics/distributions/01_common_distributions/continous/ncx2/overview", "data_science/statistics/distributions/01_common_distributions/continous/norm/overview", "data_science/statistics/distributions/01_common_distributions/continous/norminvgauss/overview", "data_science/statistics/distributions/01_common_distributions/continous/pareto/overview", "data_science/statistics/distributions/01_common_distributions/continous/pearson3/overview", "data_science/statistics/distributions/01_common_distributions/continous/powerlaw/overview", "data_science/statistics/distributions/01_common_distributions/continous/powerlognorm/overview", "data_science/statistics/distributions/01_common_distributions/continous/powernorm/overview", "data_science/statistics/distributions/01_common_distributions/continous/rayleigh/overview", "data_science/statistics/distributions/01_common_distributions/continous/rdist/overview", "data_science/statistics/distributions/01_common_distributions/continous/recipinvgauss/overview", "data_science/statistics/distributions/01_common_distributions/continous/rel_breitwigner/overview", "data_science/statistics/distributions/01_common_distributions/continous/rice/overview", "data_science/statistics/distributions/01_common_distributions/continous/semicircular/overview", "data_science/statistics/distributions/01_common_distributions/continous/skewcauchy/overview", "data_science/statistics/distributions/01_common_distributions/continous/skewnorm/overview", "data_science/statistics/distributions/01_common_distributions/continous/studentized_range/overview", "data_science/statistics/distributions/01_common_distributions/continous/t/overview", "data_science/statistics/distributions/01_common_distributions/continous/trapezoid/overview", "data_science/statistics/distributions/01_common_distributions/continous/triang/overview", "data_science/statistics/distributions/01_common_distributions/continous/truncexpon/overview", "data_science/statistics/distributions/01_common_distributions/continous/truncnorm/overview", "data_science/statistics/distributions/01_common_distributions/continous/truncpareto/overview", "data_science/statistics/distributions/01_common_distributions/continous/truncweibull_min/overview", "data_science/statistics/distributions/01_common_distributions/continous/uniform/overview", "data_science/statistics/distributions/01_common_distributions/continous/wald/overview", "data_science/statistics/distributions/01_common_distributions/continous/weibull_max/overview", "data_science/statistics/distributions/01_common_distributions/continous/weibull_min/overview", "data_science/statistics/distributions/01_common_distributions/continous/wishart/overview", "data_science/statistics/distributions/01_common_distributions/continous/wrapcauchy/overview", "data_science/statistics/distributions/01_common_distributions/discret/bernoulli/overview", "data_science/statistics/distributions/01_common_distributions/discret/betabinom/overview", "data_science/statistics/distributions/01_common_distributions/discret/betanbinom/overview", "data_science/statistics/distributions/01_common_distributions/discret/binom/overview", "data_science/statistics/distributions/01_common_distributions/discret/boltzmann/overview", "data_science/statistics/distributions/01_common_distributions/discret/dirichlet_multinomial/overview", "data_science/statistics/distributions/01_common_distributions/discret/dlaplace/overview", "data_science/statistics/distributions/01_common_distributions/discret/multinomial/overview", "data_science/statistics/distributions/01_common_distributions/discret/nbinom/overview", "data_science/statistics/distributions/01_common_distributions/discret/nchypergeom_fisher/overview", "data_science/statistics/distributions/01_common_distributions/discret/nchypergeom_wallenius/overview", "data_science/statistics/distributions/01_common_distributions/discret/nhypergeom/overview", "data_science/statistics/distributions/01_common_distributions/discret/planck/overview", "data_science/statistics/distributions/01_common_distributions/discret/poisson/overview", "data_science/statistics/distributions/01_common_distributions/discret/poisson_binom/overview", "data_science/statistics/distributions/01_common_distributions/discret/randint/overview", "data_science/statistics/distributions/01_common_distributions/discret/skellam/overview", "data_science/statistics/distributions/01_common_distributions/discret/yulesimon/overview", "data_science/statistics/distributions/01_common_distributions/discret/zipfian/overview", "data_science/statistics/hypothesis_testing_and_other/anderson_darling/overview", "data_science/statistics/hypothesis_testing_and_other/anova/overview", "data_science/statistics/hypothesis_testing_and_other/bartlett/overview", "data_science/statistics/hypothesis_testing_and_other/bootstrap/overview", "data_science/statistics/hypothesis_testing_and_other/chi_square/overview", "data_science/statistics/hypothesis_testing_and_other/chi_square_goodness_of_fit/overview", "data_science/statistics/hypothesis_testing_and_other/dagostino_k2/overview", "data_science/statistics/hypothesis_testing_and_other/dunnett/overview", "data_science/statistics/hypothesis_testing_and_other/f_test/overview", "data_science/statistics/hypothesis_testing_and_other/fisher_exact/00_overview", "data_science/statistics/hypothesis_testing_and_other/fligner_killeen/overview", "data_science/statistics/hypothesis_testing_and_other/friedman/overview", "data_science/statistics/hypothesis_testing_and_other/jarque_bera/overview", "data_science/statistics/hypothesis_testing_and_other/kendall_tau/overview", "data_science/statistics/hypothesis_testing_and_other/kolmogorov_smirnov/overview", "data_science/statistics/hypothesis_testing_and_other/kruskal_wallis/overview", "data_science/statistics/hypothesis_testing_and_other/kurtosis_test/00_overview", "data_science/statistics/hypothesis_testing_and_other/levene/overview", "data_science/statistics/hypothesis_testing_and_other/mann_whitney_u/00_overview", "data_science/statistics/hypothesis_testing_and_other/odds_ratio/overview", "data_science/statistics/hypothesis_testing_and_other/pearson/overview", "data_science/statistics/hypothesis_testing_and_other/permutation_test/overview", "data_science/statistics/hypothesis_testing_and_other/skewness_test/overview", "data_science/statistics/hypothesis_testing_and_other/spearman/overview", "data_science/statistics/hypothesis_testing_and_other/t_test/overview", "data_science/statistics/hypothesis_testing_and_other/t_test/t_test_independent/overview", "data_science/statistics/hypothesis_testing_and_other/t_test/t_test_paired/overview", "data_science/statistics/hypothesis_testing_and_other/t_test_one_sample/overview", "data_science/statistics/hypothesis_testing_and_other/wilcoxon_signed_rank/overview", "data_science/time_series/00_overview", "data_science/time_series/anomaly_detection/00_overview", "data_science/time_series/classification/00_overview", "data_science/time_series/clustering/00_overview", "data_science/time_series/datasets/00_overview", "data_science/time_series/forecasting/00_overview", "data_science/time_series/forecasting/classical/00_overview", "data_science/time_series/forecasting/deep_learning/00_overview", "data_science/time_series/forecasting/machine_learning/00_overview", "data_science/time_series/metrics/00_overview", "data_science/time_series/pipelines/00_overview", "data_science/time_series/regression/00_overview", "data_science/time_series/sktime_algorithms/00_overview", "data_science/time_series/sktime_algorithms/anomaly_detection/00_overview", "data_science/time_series/sktime_algorithms/catalog/00_overview", "data_science/time_series/sktime_algorithms/classification/dictionary_based/00_overview", "data_science/time_series/sktime_algorithms/classification/distance_based/00_overview", "data_science/time_series/sktime_algorithms/classification/ensembles/00_overview", "data_science/time_series/sktime_algorithms/classification/interval_based/00_overview", "data_science/time_series/sktime_algorithms/classification/knn_classifier/00_overview", "data_science/time_series/sktime_algorithms/classification/rocket_classifier/00_overview", "data_science/time_series/sktime_algorithms/classification/shapelet_based/00_overview", "data_science/time_series/sktime_algorithms/classification/shapelet_transform_classifier/00_overview", "data_science/time_series/sktime_algorithms/classification/ts_forest_classifier/00_overview", "data_science/time_series/sktime_algorithms/clustering/00_overview", "data_science/time_series/sktime_algorithms/datatypes/00_overview", "data_science/time_series/sktime_algorithms/forecasting/arima/00_overview", "data_science/time_series/sktime_algorithms/forecasting/auto_arima/00_overview", "data_science/time_series/sktime_algorithms/forecasting/backtesting/00_overview", "data_science/time_series/sktime_algorithms/forecasting/bats_tbats/00_overview", "data_science/time_series/sktime_algorithms/forecasting/ensembles/00_overview", "data_science/time_series/sktime_algorithms/forecasting/ets/00_overview", "data_science/time_series/sktime_algorithms/forecasting/intermittent_demand/00_overview", "data_science/time_series/sktime_algorithms/forecasting/naive/00_overview", "data_science/time_series/sktime_algorithms/forecasting/probabilistic/00_overview", "data_science/time_series/sktime_algorithms/forecasting/reduction/00_overview", "data_science/time_series/sktime_algorithms/forecasting/seasonal_naive/00_overview", "data_science/time_series/sktime_algorithms/forecasting/strategies/00_overview", "data_science/time_series/sktime_algorithms/forecasting/theta/00_overview", "data_science/time_series/sktime_algorithms/model_selection/00_overview", "data_science/time_series/sktime_algorithms/registry/00_overview", "data_science/time_series/sktime_algorithms/registry/01_forecasting_catalog", "data_science/time_series/sktime_algorithms/registry/02_classification_catalog", "data_science/time_series/sktime_algorithms/registry/03_regression_catalog", "data_science/time_series/sktime_algorithms/registry/04_transformers_catalog", "data_science/time_series/sktime_algorithms/registry/05_clusterer_catalog", "data_science/time_series/sktime_algorithms/registry/06_annotation_catalog", "data_science/time_series/sktime_algorithms/regression/interval_based/00_overview", "data_science/time_series/sktime_algorithms/regression/knn_regressor/00_overview", "data_science/time_series/sktime_algorithms/regression/rocket_regressor/00_overview", "data_science/time_series/sktime_algorithms/regression/ts_forest_regressor/00_overview", "data_science/time_series/sktime_algorithms/segmentation_annotation/00_overview", "data_science/time_series/sktime_algorithms/transformers/preprocessing/00_overview", "data_science/time_series/sktime_algorithms/transformers/rocket_transformer/00_overview", "data_science/time_series/sktime_algorithms/transformers/tsfresh/00_overview", "data_science/time_series/transformers/00_overview", "data_science/time_series/transformers/fourier_terms/00_overview", "data_science/time_series/transformers/lag_features/00_overview", "data_science/time_series/transformers/rolling_window_features/00_overview", "devops/00_overview", "devops/CI_CD/argo_cd/00_overview", "devops/CI_CD/github_actions/00_overview", "devops/CI_CD/jenkins/00_overview", "devops/IAC/pulumi/00_overview", "devops/IAC/terraform/00_overview", "devops/ci_cd/00_overview", "devops/cloud/aws/_assets/aws_service_icons/README", "devops/cloud/aws/cloudformation/00_overview", "devops/cloud/aws/cloudfront/00_overview", "devops/cloud/aws/cloudwatch/00_overview", "devops/cloud/aws/dynamodb/00_overview", "devops/cloud/aws/ec2/00_overview", "devops/cloud/aws/ecs/00_overview", "devops/cloud/aws/eks/00_overview", "devops/cloud/aws/elasticache/00_overview", "devops/cloud/aws/emr/00_overview", "devops/cloud/aws/eventbridge/00_overview", "devops/cloud/aws/glue/00_overview", "devops/cloud/aws/lambda/00_overview", "devops/cloud/aws/mwaa/00_overview", "devops/cloud/aws/rds/00_overview", "devops/cloud/aws/s3/00_overview", "devops/cloud/aws/snowflake/00_overview", "devops/cloud/aws/sns/00_overview", "devops/cloud/aws/sqs/00_overview", "devops/cloud/aws/step_functions/00_overview", "devops/cloud/aws/vpc/00_overview", "devops/containerisation/docker/00_overview", "devops/containerisation/podman/00_overview", "devops/containers/00_overview", "devops/cost_capacity/00_overview", "devops/iac/00_overview", "devops/incident_response/00_overview", "devops/kubernetes/00_overview", "devops/kubernetes/config_maps/00_overview", "devops/kubernetes/cron_jobs/00_overview", "devops/kubernetes/deployments/00_overview", "devops/kubernetes/hpa/00_overview", "devops/kubernetes/ingress/00_overview", "devops/kubernetes/jobs/00_overview", "devops/kubernetes/kustomize/00_overview", "devops/kubernetes/namespaces/00_overview", "devops/kubernetes/persistent_volume_claims/00_overview", "devops/kubernetes/pods/00_overview", "devops/kubernetes/replica_sets/00_overview", "devops/kubernetes/secrets/00_overview", "devops/kubernetes/services/00_overview", "devops/kubernetes/stateful_sets/00_overview", "devops/kubernetes/storage_classes/00_overview", "devops/observability_sre/00_overview", "devops/telemetry_and_display/00_overview", "devops/telemetry_and_display/elasticsearch/00_overview", "devops/telemetry_and_display/grafana/00_overview", "devops/telemetry_and_display/kibana/00_overview", "devops/telemetry_and_display/logstash/00_overview", "devops/telemetry_and_display/prometheus/00_overview", "finance/00_overview", "finance/derivatives/00_overview", "finance/derivatives/black_scholes/00_overview", "finance/econometrics/00_overview", "finance/fixed_income/00_overview", "finance/portfolio/00_overview", "finance/portfolio/efficient_frontier/00_overview", "finance/portfolio/fama_french/00_overview", "finance/risk/00_overview", "finance/time_value_of_money/00_overview", "frontend/00_overview", "frontend/frameworks_architecture/00_overview", "frontend/performance_accessibility/00_overview", "frontend/security/00_overview", "frontend/state_data/00_overview", "frontend/testing/00_overview", "frontend/web_fundamentals/00_overview", "system_design/00_overview", "system_design/case_studies/00_overview", "system_design/data_consistency/00_overview", "system_design/design_checklists/00_overview", "system_design/reliability_dr/00_overview", "system_design/requirements_tradeoffs/00_overview", "system_design/scalability_patterns/00_overview"], "filenames": ["backend/00_overview.ipynb", "backend/api_design/00_overview.ipynb", "backend/auth_security/00_overview.ipynb", "backend/caching_queues/00_overview.ipynb", "backend/communication_patterns/00_overview.ipynb", "backend/data_storage_modeling/00_overview.ipynb", "backend/observability/00_overview.ipynb", "backend/resilience_performance/00_overview.ipynb", "backend/testing_quality/00_overview.ipynb", "book_index.ipynb", "cybersecurity/00_overview.ipynb", "cybersecurity/identity_access/00_overview.ipynb", "cybersecurity/incident_response/00_overview.ipynb", "cybersecurity/network_cloud_security/00_overview.ipynb", "cybersecurity/secure_coding_owasp/00_overview.ipynb", "cybersecurity/threat_modeling/00_overview.ipynb", "cybersecurity/vulnerability_management/00_overview.ipynb", "data_science/00_overview.ipynb", "data_science/deeplearning/00_overview.ipynb", "data_science/deeplearning/tabular_data/artificial_neural_networks/00_overview.ipynb", "data_science/deeplearning/timeseries/lstm_and_gru/00_overview.ipynb", "data_science/deeplearning/visual/cnn/00_overview.ipynb", "data_science/deeplearning/visual/resnet/00_overview.ipynb", "data_science/linear_algebra/00_overview.ipynb", "data_science/machine_learning/00_overview.ipynb", "data_science/machine_learning/dimensionality_reduction/tabular_data/dbscan/00_overview.ipynb", "data_science/machine_learning/dimensionality_reduction/tabular_data/ica/00_overview.ipynb", "data_science/machine_learning/dimensionality_reduction/tabular_data/isomap/00_overview.ipynb", "data_science/machine_learning/dimensionality_reduction/tabular_data/lle/00_overview.ipynb", "data_science/machine_learning/dimensionality_reduction/tabular_data/mds/00_overview.ipynb", "data_science/machine_learning/dimensionality_reduction/tabular_data/pca/00_overview.ipynb", "data_science/machine_learning/dimensionality_reduction/tabular_data/tsne/00_overview.ipynb", "data_science/machine_learning/dimensionality_reduction/tabular_data/umap/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/accuracy_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/auc/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/average_precision_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/balanced_accuracy_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/brier_score_loss/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/class_likelihood_ratios/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/classification_report/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/cohen_kappa_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/confusion_matrix/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/confusion_matrix_at_thresholds/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/coverage_error/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/d2_brier_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/d2_log_loss_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/dcg_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/det_curve/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/f1_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/fbeta_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/hamming_loss/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/hinge_loss/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/jaccard_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/label_ranking_average_precision_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/label_ranking_loss/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/log_loss/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/matthews_corrcoef/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/multilabel_confusion_matrix/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/ndcg_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/precision_recall_curve/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/precision_recall_fscore_support/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/precision_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/recall_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/roc_auc_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/roc_curve/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/top_k_accuracy_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/classification/zero_one_loss/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/clustering/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/clustering/adjusted_mutual_info_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/clustering/adjusted_rand_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/clustering/calinski_harabasz_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/clustering/completeness_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/clustering/contingency_matrix/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/clustering/davies_bouldin_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/clustering/fowlkes_mallows_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/clustering/homogeneity_completeness_v_measure/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/clustering/homogeneity_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/clustering/mutual_info_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/clustering/normalized_mutual_info_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/clustering/pair_confusion_matrix/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/clustering/rand_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/clustering/silhouette_samples/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/clustering/silhouette_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/clustering/v_measure_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/d2_absolute_error_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/d2_pinball_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/d2_tweedie_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/explained_variance_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/max_error/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/mean_absolute_error/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/mean_absolute_percentage_error/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/mean_gamma_deviance/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/mean_pinball_loss/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/mean_poisson_deviance/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/mean_squared_error/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/mean_squared_log_error/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/mean_tweedie_deviance/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/median_absolute_error/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/r2_score/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/root_mean_squared_error/00_overview.ipynb", "data_science/machine_learning/metrics/tabular/regression/root_mean_squared_log_error/00_overview.ipynb", "data_science/machine_learning/supervised_learning/tabular_data/gaussian_processes/00_overview.ipynb", "data_science/machine_learning/supervised_learning/tabular_data/generalized_linear_models/00_overview.ipynb", "data_science/machine_learning/supervised_learning/tabular_data/k_nearest_neighbors/00_overview.ipynb", "data_science/machine_learning/supervised_learning/tabular_data/linear_and_quadratic_discriminant_analysis/00_overview.ipynb", "data_science/machine_learning/supervised_learning/tabular_data/linear_regression_and_co/00_overview.ipynb", "data_science/machine_learning/supervised_learning/tabular_data/naive_bayes/00_overview.ipynb", "data_science/machine_learning/supervised_learning/tabular_data/support_vector_machines/00_overview.ipynb", "data_science/machine_learning/supervised_learning/tabular_data/tree_based_algorithms/00_overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/01_arch_models/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/01_autoregressive_ar/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/01_kalman_filter/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/01_moving_average_ma/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/01_prophet/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/01_sarima/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/01_varma/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/01_vector_autoregression_var/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/02_arima_autoregressive_integrated_moving_average/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/02_bats/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/02_garch_models/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/02_sarimax/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/02_varmax/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/classic_statistical/03_tbats/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/distancebased/k_neighbors_time_series_regressor/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/distancebased/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/ensemble/composable_time_series_forest_regressor/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/ensemble/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/ensemble/time_series_forest_regressor/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/kernelbased/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/kernelbased/rocket_regressor/overview.ipynb", "data_science/machine_learning/supervised_learning/timeseries/regression/kernelbased/time_series_svr_tslearn/overview.ipynb", "data_science/reinforcement_learning/00_overview.ipynb", "data_science/reinforcement_learning/A2C/00_overview.ipynb", "data_science/reinforcement_learning/ACKTR/00_overview.ipynb", "data_science/reinforcement_learning/ACKTR/01_acktr_from_scratch.ipynb", "data_science/reinforcement_learning/DDPG/00_overview.ipynb", "data_science/reinforcement_learning/DDPG/01_ddpg_from_scratch.ipynb", "data_science/reinforcement_learning/DQN/00_overview.ipynb", "data_science/reinforcement_learning/GAIL/00_overview.ipynb", "data_science/reinforcement_learning/HER/00_overview.ipynb", "data_science/reinforcement_learning/PPO1/00_overview.ipynb", "data_science/reinforcement_learning/PPO2/00_overview.ipynb", "data_science/reinforcement_learning/SAC/00_overview.ipynb", "data_science/reinforcement_learning/TD3/00_overview.ipynb", "data_science/reinforcement_learning/TRPO/00_overview.ipynb", "data_science/statistics/00_overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/alpha/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/anglit/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/arcsine/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/argus/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/beta/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/bradford/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/burr/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/cauchy/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/cosine/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/crystalball/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/dgamma/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/dirichlet/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/dpareto_lognorm/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/dweibull/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/expon/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/exponnorm/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/exponpow/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/exponweib/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/f/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/fatiguelife/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/fisk/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/gamma/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/gausshyper/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/genexpon/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/genextreme/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/gengamma/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/genhalflogistic/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/landau/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/laplace/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/laplace_asymmetric/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/levy/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/levy_l/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/loggamma/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/logistic/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/loglaplace/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/lognorm/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/loguniform/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/matrix_normal/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/maxwell/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/mielke/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/moyal/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/multivariate_normal/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/nakagami/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/ncf/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/nct/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/ncx2/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/norm/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/norminvgauss/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/pareto/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/pearson3/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/powerlaw/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/powerlognorm/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/powernorm/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/rayleigh/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/rdist/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/recipinvgauss/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/rel_breitwigner/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/rice/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/semicircular/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/skewcauchy/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/skewnorm/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/studentized_range/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/t/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/trapezoid/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/triang/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/truncexpon/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/truncnorm/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/truncpareto/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/truncweibull_min/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/uniform/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/wald/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/weibull_max/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/weibull_min/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/wishart/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/continous/wrapcauchy/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/bernoulli/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/betabinom/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/betanbinom/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/binom/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/boltzmann/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/dirichlet_multinomial/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/dlaplace/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/multinomial/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/nbinom/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/nchypergeom_fisher/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/nchypergeom_wallenius/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/nhypergeom/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/planck/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/poisson/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/poisson_binom/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/randint/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/skellam/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/yulesimon/overview.ipynb", "data_science/statistics/distributions/01_common_distributions/discret/zipfian/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/anderson_darling/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/anova/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/bartlett/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/bootstrap/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/chi_square/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/chi_square_goodness_of_fit/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/dagostino_k2/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/dunnett/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/f_test/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/fisher_exact/00_overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/fligner_killeen/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/friedman/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/jarque_bera/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/kendall_tau/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/kolmogorov_smirnov/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/kruskal_wallis/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/kurtosis_test/00_overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/levene/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/mann_whitney_u/00_overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/odds_ratio/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/pearson/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/permutation_test/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/skewness_test/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/spearman/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/t_test/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/t_test/t_test_independent/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/t_test/t_test_paired/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/t_test_one_sample/overview.ipynb", "data_science/statistics/hypothesis_testing_and_other/wilcoxon_signed_rank/overview.ipynb", "data_science/time_series/00_overview.ipynb", "data_science/time_series/anomaly_detection/00_overview.ipynb", "data_science/time_series/classification/00_overview.ipynb", "data_science/time_series/clustering/00_overview.ipynb", "data_science/time_series/datasets/00_overview.ipynb", "data_science/time_series/forecasting/00_overview.ipynb", "data_science/time_series/forecasting/classical/00_overview.ipynb", "data_science/time_series/forecasting/deep_learning/00_overview.ipynb", "data_science/time_series/forecasting/machine_learning/00_overview.ipynb", "data_science/time_series/metrics/00_overview.ipynb", "data_science/time_series/pipelines/00_overview.ipynb", "data_science/time_series/regression/00_overview.ipynb", "data_science/time_series/sktime_algorithms/00_overview.ipynb", "data_science/time_series/sktime_algorithms/anomaly_detection/00_overview.ipynb", "data_science/time_series/sktime_algorithms/catalog/00_overview.ipynb", "data_science/time_series/sktime_algorithms/classification/dictionary_based/00_overview.ipynb", "data_science/time_series/sktime_algorithms/classification/distance_based/00_overview.ipynb", "data_science/time_series/sktime_algorithms/classification/ensembles/00_overview.ipynb", "data_science/time_series/sktime_algorithms/classification/interval_based/00_overview.ipynb", "data_science/time_series/sktime_algorithms/classification/knn_classifier/00_overview.ipynb", "data_science/time_series/sktime_algorithms/classification/rocket_classifier/00_overview.ipynb", "data_science/time_series/sktime_algorithms/classification/shapelet_based/00_overview.ipynb", "data_science/time_series/sktime_algorithms/classification/shapelet_transform_classifier/00_overview.ipynb", "data_science/time_series/sktime_algorithms/classification/ts_forest_classifier/00_overview.ipynb", "data_science/time_series/sktime_algorithms/clustering/00_overview.ipynb", "data_science/time_series/sktime_algorithms/datatypes/00_overview.ipynb", "data_science/time_series/sktime_algorithms/forecasting/arima/00_overview.ipynb", "data_science/time_series/sktime_algorithms/forecasting/auto_arima/00_overview.ipynb", "data_science/time_series/sktime_algorithms/forecasting/backtesting/00_overview.ipynb", "data_science/time_series/sktime_algorithms/forecasting/bats_tbats/00_overview.ipynb", "data_science/time_series/sktime_algorithms/forecasting/ensembles/00_overview.ipynb", "data_science/time_series/sktime_algorithms/forecasting/ets/00_overview.ipynb", "data_science/time_series/sktime_algorithms/forecasting/intermittent_demand/00_overview.ipynb", "data_science/time_series/sktime_algorithms/forecasting/naive/00_overview.ipynb", "data_science/time_series/sktime_algorithms/forecasting/probabilistic/00_overview.ipynb", "data_science/time_series/sktime_algorithms/forecasting/reduction/00_overview.ipynb", "data_science/time_series/sktime_algorithms/forecasting/seasonal_naive/00_overview.ipynb", "data_science/time_series/sktime_algorithms/forecasting/strategies/00_overview.ipynb", "data_science/time_series/sktime_algorithms/forecasting/theta/00_overview.ipynb", "data_science/time_series/sktime_algorithms/model_selection/00_overview.ipynb", "data_science/time_series/sktime_algorithms/registry/00_overview.ipynb", "data_science/time_series/sktime_algorithms/registry/01_forecasting_catalog.ipynb", "data_science/time_series/sktime_algorithms/registry/02_classification_catalog.ipynb", "data_science/time_series/sktime_algorithms/registry/03_regression_catalog.ipynb", "data_science/time_series/sktime_algorithms/registry/04_transformers_catalog.ipynb", "data_science/time_series/sktime_algorithms/registry/05_clusterer_catalog.ipynb", "data_science/time_series/sktime_algorithms/registry/06_annotation_catalog.ipynb", "data_science/time_series/sktime_algorithms/regression/interval_based/00_overview.ipynb", "data_science/time_series/sktime_algorithms/regression/knn_regressor/00_overview.ipynb", "data_science/time_series/sktime_algorithms/regression/rocket_regressor/00_overview.ipynb", "data_science/time_series/sktime_algorithms/regression/ts_forest_regressor/00_overview.ipynb", "data_science/time_series/sktime_algorithms/segmentation_annotation/00_overview.ipynb", "data_science/time_series/sktime_algorithms/transformers/preprocessing/00_overview.ipynb", "data_science/time_series/sktime_algorithms/transformers/rocket_transformer/00_overview.ipynb", "data_science/time_series/sktime_algorithms/transformers/tsfresh/00_overview.ipynb", "data_science/time_series/transformers/00_overview.ipynb", "data_science/time_series/transformers/fourier_terms/00_overview.ipynb", "data_science/time_series/transformers/lag_features/00_overview.ipynb", "data_science/time_series/transformers/rolling_window_features/00_overview.ipynb", "devops/00_overview.ipynb", "devops/CI_CD/argo_cd/00_overview.ipynb", "devops/CI_CD/github_actions/00_overview.ipynb", "devops/CI_CD/jenkins/00_overview.ipynb", "devops/IAC/pulumi/00_overview.ipynb", "devops/IAC/terraform/00_overview.ipynb", "devops/ci_cd/00_overview.ipynb", "devops/cloud/aws/_assets/aws_service_icons/README.ipynb", "devops/cloud/aws/cloudformation/00_overview.ipynb", "devops/cloud/aws/cloudfront/00_overview.ipynb", "devops/cloud/aws/cloudwatch/00_overview.ipynb", "devops/cloud/aws/dynamodb/00_overview.ipynb", "devops/cloud/aws/ec2/00_overview.ipynb", "devops/cloud/aws/ecs/00_overview.ipynb", "devops/cloud/aws/eks/00_overview.ipynb", "devops/cloud/aws/elasticache/00_overview.ipynb", "devops/cloud/aws/emr/00_overview.ipynb", "devops/cloud/aws/eventbridge/00_overview.ipynb", "devops/cloud/aws/glue/00_overview.ipynb", "devops/cloud/aws/lambda/00_overview.ipynb", "devops/cloud/aws/mwaa/00_overview.ipynb", "devops/cloud/aws/rds/00_overview.ipynb", "devops/cloud/aws/s3/00_overview.ipynb", "devops/cloud/aws/snowflake/00_overview.ipynb", "devops/cloud/aws/sns/00_overview.ipynb", "devops/cloud/aws/sqs/00_overview.ipynb", "devops/cloud/aws/step_functions/00_overview.ipynb", "devops/cloud/aws/vpc/00_overview.ipynb", "devops/containerisation/docker/00_overview.ipynb", "devops/containerisation/podman/00_overview.ipynb", "devops/containers/00_overview.ipynb", "devops/cost_capacity/00_overview.ipynb", "devops/iac/00_overview.ipynb", "devops/incident_response/00_overview.ipynb", "devops/kubernetes/00_overview.ipynb", "devops/kubernetes/config_maps/00_overview.ipynb", "devops/kubernetes/cron_jobs/00_overview.ipynb", "devops/kubernetes/deployments/00_overview.ipynb", "devops/kubernetes/hpa/00_overview.ipynb", "devops/kubernetes/ingress/00_overview.ipynb", "devops/kubernetes/jobs/00_overview.ipynb", "devops/kubernetes/kustomize/00_overview.ipynb", "devops/kubernetes/namespaces/00_overview.ipynb", "devops/kubernetes/persistent_volume_claims/00_overview.ipynb", "devops/kubernetes/pods/00_overview.ipynb", "devops/kubernetes/replica_sets/00_overview.ipynb", "devops/kubernetes/secrets/00_overview.ipynb", "devops/kubernetes/services/00_overview.ipynb", "devops/kubernetes/stateful_sets/00_overview.ipynb", "devops/kubernetes/storage_classes/00_overview.ipynb", "devops/observability_sre/00_overview.ipynb", "devops/telemetry_and_display/00_overview.ipynb", "devops/telemetry_and_display/elasticsearch/00_overview.ipynb", "devops/telemetry_and_display/grafana/00_overview.ipynb", "devops/telemetry_and_display/kibana/00_overview.ipynb", "devops/telemetry_and_display/logstash/00_overview.ipynb", "devops/telemetry_and_display/prometheus/00_overview.ipynb", "finance/00_overview.ipynb", "finance/derivatives/00_overview.ipynb", "finance/derivatives/black_scholes/00_overview.ipynb", "finance/econometrics/00_overview.ipynb", "finance/fixed_income/00_overview.ipynb", "finance/portfolio/00_overview.ipynb", "finance/portfolio/efficient_frontier/00_overview.ipynb", "finance/portfolio/fama_french/00_overview.ipynb", "finance/risk/00_overview.ipynb", "finance/time_value_of_money/00_overview.ipynb", "frontend/00_overview.ipynb", "frontend/frameworks_architecture/00_overview.ipynb", "frontend/performance_accessibility/00_overview.ipynb", "frontend/security/00_overview.ipynb", "frontend/state_data/00_overview.ipynb", "frontend/testing/00_overview.ipynb", "frontend/web_fundamentals/00_overview.ipynb", "system_design/00_overview.ipynb", "system_design/case_studies/00_overview.ipynb", "system_design/data_consistency/00_overview.ipynb", "system_design/design_checklists/00_overview.ipynb", "system_design/reliability_dr/00_overview.ipynb", "system_design/requirements_tradeoffs/00_overview.ipynb", "system_design/scalability_patterns/00_overview.ipynb"], "titles": ["Backend \u2014 Overview", "API Design", "Auth &amp; Security", "Caching &amp; Queues", "Communication Patterns", "Data Storage &amp; Modeling", "Observability", "Resilience &amp; Performance", "Testing &amp; Quality", "Knowledge Archive", "Cybersecurity \u2014 Overview", "Identity &amp; Access", "Incident Response", "Network &amp; Cloud Security", "Secure Coding &amp; OWASP", "Threat Modeling", "Vulnerability Management", "Data Science \u2014 Overview", "Deep Learning \u2014 Overview", "Artificial Neural Networks (MLPs) for Tabular Data", "LSTM and GRU for Time Series Forecasting (from scratch + PyTorch)", "Convolutional Neural Networks (CNNs) for Image Data (from scratch NumPy + PyTorch)", "Residual Networks (ResNets) for Image Data (from scratch NumPy + PyTorch)", "Linear Algebra \u2014 Overview", "Machine Learning \u2014 Overview", "DBSCAN \u2014 Density-Based Clustering (Finding crowds instead of shapes)", "Independent Component Analysis (ICA)", "Isomap \u2014 Nonlinear Dimensionality Reduction (Geodesic Distances)", "Locally Linear Embedding (LLE) \u2014 Manifold Learning (From Scratch)", "Multidimensional Scaling (MDS) \u2014 \u201cRecreating a map using only pairwise distances\u201d", "Principal Component Analysis (PCA) + Kernel PCA", "t-SNE: Visualizing High-Dimensional Data (Preserve Friendships, Not Geography)", "UMAP (Uniform Manifold Approximation and Projection)", "Classification Metrics (Tabular)", "<code class=\"docutils literal notranslate\"><span class=\"pre\">accuracy_score</span></code> (classification accuracy)", "AUC / ROC AUC (Area Under the ROC Curve)", "average_precision_score (Average Precision, AP)", "balanced_accuracy_score", "brier_score_loss (Brier score)", "class_likelihood_ratios (LR+ / LR-)", "classification_report", "Cohen\u2019s Kappa (<code class=\"docutils literal notranslate\"><span class=\"pre\">cohen_kappa_score</span></code>)", "confusion_matrix", "confusion_matrix_at_thresholds", "coverage_error", "D\u00b2 Brier Score (<code class=\"docutils literal notranslate\"><span class=\"pre\">d2_brier_score</span></code>)", "D\u00b2 Log Loss Score (<code class=\"docutils literal notranslate\"><span class=\"pre\">d2_log_loss_score</span></code>)", "dcg_score (Discounted Cumulative Gain)", "det_curve", "F1 Score (<code class=\"docutils literal notranslate\"><span class=\"pre\">f1_score</span></code>)", "<code class=\"docutils literal notranslate\"><span class=\"pre\">fbeta_score</span></code> (F\u03b2 score)", "hamming_loss (bitwise error rate for multilabel classification)", "hinge_loss", "Jaccard Score (Jaccard Similarity / Intersection-over-Union)", "label_ranking_average_precision_score", "label_ranking_loss", "log_loss (cross-entropy / negative log-likelihood)", "matthews_corrcoef (Matthews Correlation Coefficient, MCC)", "multilabel_confusion_matrix", "<code class=\"docutils literal notranslate\"><span class=\"pre\">ndcg_score</span></code> \u2014 Normalized Discounted Cumulative Gain (NDCG)", "precision_recall_curve", "precision_recall_fscore_support", "precision_score", "recall_score", "roc_auc_score (ROC AUC)", "ROC Curve (Receiver Operating Characteristic)", "top_k_accuracy_score", "zero_one_loss (classification error / 1 - accuracy)", "Clustering Metrics (Tabular)", "Adjusted Mutual Information (AMI) \u2014 <code class=\"docutils literal notranslate\"><span class=\"pre\">adjusted_mutual_info_score</span></code>", "adjusted_rand_score (Adjusted Rand Index / ARI)", "calinski_harabasz_score", "Completeness score (clustering)", "Contingency Matrix (<code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn.metrics.cluster.contingency_matrix</span></code>)", "davies_bouldin_score (Davies\u2013Bouldin Index, DBI)", "Fowlkes\u2013Mallows Score (<code class=\"docutils literal notranslate\"><span class=\"pre\">fowlkes_mallows_score</span></code>)", "homogeneity_completeness_v_measure", "Homogeneity Score (<code class=\"docutils literal notranslate\"><span class=\"pre\">homogeneity_score</span></code>)", "Mutual Information Score (<code class=\"docutils literal notranslate\"><span class=\"pre\">mutual_info_score</span></code>)", "normalized_mutual_info_score", "pair_confusion_matrix", "Rand Score (Rand Index)", "silhouette_samples", "Silhouette Score \u2014 Clustering Validation (From Scratch)", "V-measure score (<code class=\"docutils literal notranslate\"><span class=\"pre\">v_measure_score</span></code>)", "Regression Metrics (Tabular)", "D\u00b2 Absolute Error Score (<code class=\"docutils literal notranslate\"><span class=\"pre\">d2_absolute_error_score</span></code>)", "D\u00b2 Pinball Score (<code class=\"docutils literal notranslate\"><span class=\"pre\">d2_pinball_score</span></code>)", "D\u00b2 Tweedie Score (<code class=\"docutils literal notranslate\"><span class=\"pre\">d2_tweedie_score</span></code>)", "Explained Variance Score (<code class=\"docutils literal notranslate\"><span class=\"pre\">explained_variance_score</span></code>)", "Max Error (<code class=\"docutils literal notranslate\"><span class=\"pre\">max_error</span></code>)", "mean_absolute_error (MAE)", "mean_absolute_percentage_error (MAPE)", "Mean Gamma Deviance (<code class=\"docutils literal notranslate\"><span class=\"pre\">mean_gamma_deviance</span></code>) \u2014 Regression Metric (From Scratch)", "mean_pinball_loss (Pinball / Quantile Loss)", "<code class=\"docutils literal notranslate\"><span class=\"pre\">mean_poisson_deviance</span></code>", "mean_squared_error (MSE)", "Mean Squared Logarithmic Error (MSLE)", "mean_tweedie_deviance (Mean Tweedie Deviance)", "median_absolute_error (MedAE)", "R\u00b2 Score (<code class=\"docutils literal notranslate\"><span class=\"pre\">r2_score</span></code>)", "Root Mean Squared Error (RMSE) \u2014 Regression Metric (From Scratch)", "Root Mean Squared Logarithmic Error (RMSLE) \u2014 Regression Metric (From Scratch)", "Gaussian Processes (GP) \u2014 Regression &amp; Probabilistic Classification", "Generalized Linear Models (GLMs)", "K-Nearest Neighbors (KNN) \u2014 Classification &amp; Regression (From Scratch)", "Linear and Quadratic Discriminant Analysis (LDA / QDA)", "Linear Regression &amp; Friends (OLS, Ridge, Lasso, Elastic Net)", "Naive Bayes (Gaussian, Multinomial, Complement, Bernoulli, Categorical) + Out-of-core", "Support Vector Machines (SVC + SVR)", "Tree-Based Algorithms (Decision Trees, Random Forests, Gradient Boosting)", "ARCH Models (Volatility Models)", "Autoregressive (AR) models (from scratch NumPy + Plotly)", "Kalman Filter \u2014 linear Gaussian state-space model (NumPy + Plotly)", "01 Moving Average (MA) Model", "Prophet forecaster (wrapper + from-scratch)", "SARIMA (Seasonal ARIMA): seasonality handling, differencing, and forecasting", "VARMA (Vector Autoregressive Moving Average)", "Vector Autoregression (VAR) from scratch (NumPy)", "ARIMA (Autoregressive Integrated Moving Average)", "BATS forecaster (multiple seasonality)", "GARCH(1,1) Models (Volatility Models)", "SARIMAX (Seasonal ARIMA with Exogenous Variables)", "VARMAX (VARMA with eXogenous inputs)", "TBATS forecaster (multiple seasonality)", "K-Nearest Neighbors Time Series Regressor (KNN-TS) \u2014 analog forecasting from scratch", "Distance-based time-series regression (KNN)", "ComposableTimeSeriesForestRegressor (sktime-style TSF)", "Ensembles (Time-Series Forest)", "TimeSeriesForestRegressor (TSF): interval features + tree ensemble", "Kernel-based regression (SVR, ROCKET)", "RocketRegressor (sktime-style) \u2014 ROCKET features + RidgeCV", "TimeSeriesSVRTslearn (tslearn-style) \u2014 Support Vector Regression for time series", "Reinforcement Learning \u2014 Overview", "A2C (Advantage Actor-Critic) \u2014 Low-Level PyTorch Implementation (CartPole-v1)", "ACKTR (Actor\u2013Critic using Kronecker-Factored Trust Region)", "ACKTR from scratch (low-level PyTorch) \u2014 CartPole-v1", "DDPG (Deep Deterministic Policy Gradient) \u2014 Continuous Control", "DDPG (Deep Deterministic Policy Gradient) \u2014 from scratch in PyTorch", "Deep Q-Networks (DQN) for Discrete Action Spaces \u2014 Low-Level PyTorch", "Generative Adversarial Imitation Learning (GAIL) \u2014 low-level PyTorch", "Hindsight Experience Replay (HER) \u2014 low-level PyTorch (DDPG) in a goal-based environment", "PPO1 (PPO-Clip) \u2014 low-level PyTorch implementation", "Proximal Policy Optimization 2 (PPO2) \u2014 from scratch in PyTorch", "Soft Actor-Critic (SAC) for Continuous Action Spaces (low-level PyTorch)", "Twin Delayed DDPG (TD3) \u2014 from scratch in PyTorch", "TRPO (Trust Region Policy Optimization) \u2014 low-level PyTorch implementation", "Statistics \u2014 Overview", "Alpha distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">alpha</span></code>)", "Anglit distribution", "Arcsine Distribution", "ARGUS distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">argus</span></code>)", "Beta Distribution \u2014 Modeling Uncertain Probabilities", "Bradford Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">bradford</span></code>)", "Burr Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">burr</span></code>, Burr Type III / Dagum)", "Cauchy distribution", "Cosine distribution (continuous)", "Crystal Ball distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">crystalball</span></code>)", "<code class=\"docutils literal notranslate\"><span class=\"pre\">dgamma</span></code> (Double Gamma) Distribution", "Dirichlet Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">dirichlet</span></code>) \u2014 Modeling Random Probability Vectors", "Double Pareto Lognormal distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">dpareto_lognorm</span></code>)", "<code class=\"docutils literal notranslate\"><span class=\"pre\">dweibull</span></code> (Double Weibull) Distribution", "Exponential Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">expon</span></code>)", "<code class=\"docutils literal notranslate\"><span class=\"pre\">exponnorm</span></code> (Exponentially Modified Normal / exGaussian)", "Exponential power distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">exponpow</span></code>)", "Exponentiated Weibull distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">exponweib</span></code>)", "F distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">f</span></code>)", "Fatigue-life distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">fatiguelife</span></code>) \u2014 Birnbaum\u2013Saunders model for fatigue failures", "Fisk distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">fisk</span></code>) \u2014 the log-logistic workhorse", "Gamma distribution", "<code class=\"docutils literal notranslate\"><span class=\"pre\">gausshyper</span></code> (Gauss hypergeometric) distribution", "Generalized exponential distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">genexpon</span></code>)", "<code class=\"docutils literal notranslate\"><span class=\"pre\">genextreme</span></code> (Generalized Extreme Value / GEV) distribution", "Generalized Gamma distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">gengamma</span></code>)", "Generalized Half-Logistic (<code class=\"docutils literal notranslate\"><span class=\"pre\">genhalflogistic</span></code>) Distribution \u2014 A Bounded, Logistic-Like Family", "Landau distribution", "Laplace distribution: <code class=\"docutils literal notranslate\"><span class=\"pre\">laplace</span></code> (double exponential)", "Asymmetric Laplace Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">laplace_asymmetric</span></code>)", "L\u00e9vy (<code class=\"docutils literal notranslate\"><span class=\"pre\">levy</span></code>) distribution", "Left-skewed L\u00e9vy distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">levy_l</span></code>)", "Log-Gamma distribution", "Logistic distribution \u2014 the \u201csigmoid\u201d law on \u211d", "Log-Laplace Distribution \u2014 a log-symmetric, heavy-tailed model on <span class=\"math notranslate nohighlight\">\\((0,\\infty)\\)</span>", "Lognormal Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">lognorm</span></code>)", "Loguniform Distribution \u2014 Uniform in Log Space", "Matrix Normal distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">matrix_normal</span></code>) \u2014 Gaussian random matrices with separable covariance", "Maxwell distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">maxwell</span></code>)", "Mielke Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">mielke</span></code>, Mielke Beta-Kappa / Dagum)", "Moyal distribution \u2014 a Landau-like energy-loss model", "Multivariate Normal distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">multivariate_normal</span></code>)", "Nakagami distribution", "Noncentral F distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">ncf</span></code>)", "<code class=\"docutils literal notranslate\"><span class=\"pre\">nct</span></code> (Noncentral t) distribution", "Noncentral Chi-Square distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">ncx2</span></code>) \u2014 squared norms &amp; test power", "Normal Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">norm</span></code>)", "Normal Inverse Gaussian Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">norminvgauss</span></code>)", "Pareto distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">pareto</span></code>) \u2014 heavy-tailed power laws", "Pearson type III distribution", "Power Function Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">powerlaw</span></code>)", "Power log-normal distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">powerlognorm</span></code>)", "Power Normal Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">powernorm</span></code>) \u2014 a proportional-hazards / \u201cminimum of Normals\u201d family", "Rayleigh distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">rayleigh</span></code>)", "R Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">rdist</span></code>) \u2014 Symmetric Beta on <span class=\"math notranslate nohighlight\">\\([-1, 1]\\)</span>", "Reciprocal Inverse Gaussian Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">recipinvgauss</span></code>)", "Relativistic Breit\u2013Wigner (<code class=\"docutils literal notranslate\"><span class=\"pre\">rel_breitwigner</span></code>) distribution", "<code class=\"docutils literal notranslate\"><span class=\"pre\">rice</span></code> (Rice / Rician distribution)", "Semicircular Distribution (Wigner semicircle)", "Skewed Cauchy distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">skewcauchy</span></code>)", "Skew-normal distribution", "Studentized Range Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">studentized_range</span></code>)", "Student\u2019s t distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">t</span></code>)", "Trapezoid Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">trapezoid</span></code>)", "Triangular Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">triang</span></code>)", "Truncated Exponential Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">truncexpon</span></code>)", "Truncated Normal distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">truncnorm</span></code>)", "Truncated Pareto Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">truncpareto</span></code>) \u2014 Bounded Power Laws", "Doubly Truncated Weibull Minimum Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">truncweibull_min</span></code>)", "Uniform Distribution \u2014 Bounded Randomness", "Wald (Inverse Gaussian) distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">wald</span></code>)", "Weibull maximum distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">weibull_max</span></code>)", "Weibull minimum distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">weibull_min</span></code>)", "Wishart distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">wishart</span></code>) \u2014 Random scatter / covariance matrices", "Wrapped Cauchy distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">wrapcauchy</span></code>)", "Bernoulli distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">bernoulli</span></code>)", "Beta-Binomial (<code class=\"docutils literal notranslate\"><span class=\"pre\">betabinom</span></code>) Distribution", "<code class=\"docutils literal notranslate\"><span class=\"pre\">betanbinom</span></code> (Beta-Negative Binomial)", "<code class=\"docutils literal notranslate\"><span class=\"pre\">binom</span></code> (Binomial distribution)", "Boltzmann distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">scipy.stats.boltzmann</span></code>)", "Dirichlet\u2013Multinomial Distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">dirichlet_multinomial</span></code>)", "Discrete Laplace: <code class=\"docutils literal notranslate\"><span class=\"pre\">dlaplace</span></code> (two-sided geometric)", "<code class=\"docutils literal notranslate\"><span class=\"pre\">multinomial</span></code> (Multinomial distribution)", "<code class=\"docutils literal notranslate\"><span class=\"pre\">nbinom</span></code> (Negative binomial distribution)", "<code class=\"docutils literal notranslate\"><span class=\"pre\">nchypergeom_fisher</span></code> (Fisher\u2019s noncentral hypergeometric distribution)", "<code class=\"docutils literal notranslate\"><span class=\"pre\">nchypergeom_wallenius</span></code> (Wallenius\u2019 noncentral hypergeometric distribution)", "Negative hypergeometric distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">nhypergeom</span></code>)", "Planck distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">planck</span></code>)", "<code class=\"docutils literal notranslate\"><span class=\"pre\">poisson</span></code> (Poisson distribution)", "Poisson binomial distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">poisson_binom</span></code>)", "Random integer (discrete uniform) distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">randint</span></code>)", "<code class=\"docutils literal notranslate\"><span class=\"pre\">skellam</span></code> (Skellam distribution)", "Yule\u2013Simon distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">yulesimon</span></code>)", "Zipfian distribution (<code class=\"docutils literal notranslate\"><span class=\"pre\">zipfian</span></code>)", "Anderson\u2013Darling Test (Goodness-of-Fit / Normality)", "ANOVA (One-Way): Analysis of Variance from Scratch (NumPy)", "Bartlett\u2019s test (homogeneity of variances)", "Bootstrap Hypothesis Testing (from scratch)", "Chi-square Tests (Goodness-of-Fit &amp; Independence)", "Chi-square goodness-of-fit test (\u03c7\u00b2 GOF)", "D\u2019Agostino\u2019s <span class=\"math notranslate nohighlight\">\\(K^2\\)</span> normality test (<code class=\"docutils literal notranslate\"><span class=\"pre\">dagostino_k2</span></code>)", "Dunnett\u2019s Test \u2014 Multiple Comparisons vs a Control", "F-test (Variance Ratio Test)", "Fisher\u2019s Exact Test (2\u00d72) \u2014 Intuition + NumPy Implementation", "Fligner\u2013Killeen Test (robust test for equal variances)", "Friedman Test (Nonparametric Repeated-Measures ANOVA)", "Jarque\u2013Bera normality test (<code class=\"docutils literal notranslate\"><span class=\"pre\">jarque_bera</span></code>)", "Kendall\u2019s Tau (Rank Correlation) \u2014 Measure + Hypothesis Test", "Kolmogorov\u2013Smirnov (KS) test (one-sample + two-sample)", "Kruskal\u2013Wallis H test (one-way ANOVA on ranks) \u2014 from scratch", "Kurtosis Test (Anscombe\u2013Glynn)", "Levene\u2019s Test (Homogeneity of Variances)", "Mann\u2013Whitney U Test (Wilcoxon Rank-Sum) \u2014 From Scratch with NumPy", "Odds Ratio: Interpretation + Hypothesis Test (2\u00d72 tables)", "Pearson correlation test (Pearson\u2019s r)", "Permutation Test (Randomization Test)", "Skewness Test (D\u2019Agostino)", "Spearman Rank Correlation Test (Spearman\u2019s \u03c1)", "Student\u2019s t-test (one-sample, paired, two-sample)", "Independent two-sample t-test (<code class=\"docutils literal notranslate\"><span class=\"pre\">t_test_independent</span></code>)", "Paired t-test (<code class=\"docutils literal notranslate\"><span class=\"pre\">ttest_rel</span></code>) \u2014 comparing means with paired data", "One-sample t-test (Student\u2019s t-test)", "Wilcoxon Signed-Rank Test (paired, nonparametric)", "Time Series \u2014 Core Overview", "Time Series Anomaly Detection", "Time Series Classification", "Time Series Clustering", "Time Series Datasets", "Forecasting \u2014 Overview", "Forecasting \u2014 Classical", "Forecasting \u2014 Deep Learning", "Forecasting \u2014 Machine Learning", "Time Series Forecast Metrics", "Time Series Pipelines", "Time Series Regression", "sktime Algorithms - Overview", "sktime Time Series Anomaly Detection", "sktime Algorithms Catalog and Taxonomy", "Dictionary-Based Time Series Classification", "Distance-Based Time Series Classification", "Ensemble Time Series Classification", "Interval-Based Time Series Classification", "KNeighborsTimeSeriesClassifier", "RocketClassifier", "Shapelet-Based Time Series Classification", "ShapeletTransformClassifier", "TimeSeriesForestClassifier", "sktime Time Series Clustering", "sktime Data Containers &amp; mtypes", "ARIMA", "AutoARIMA", "Backtesting &amp; Evaluation", "BATS/TBATS Forecasting (Multiple Seasonality)", "Forecasting Ensembles &amp; Composition in sktime", "ETS (Exponential Smoothing)", "Intermittent Demand Forecasting (Croston, SBA, TSB)", "Naive Forecasting", "Probabilistic Forecasting &amp; Prediction Intervals", "Reduction-Based Forecasting (Tabularization)", "Seasonal Naive Forecasting", "Forecasting Strategies (Recursive, Direct, Multioutput)", "Theta Method", "sktime Model Selection &amp; Time-Series Cross-Validation", "sktime Estimator Registry - Full Catalog", "sktime Forecasters Catalog", "sktime Time Series Classifiers Catalog", "sktime Time Series Regressors Catalog", "sktime Time Series Transformers Catalog", "sktime Time Series Clusterers Catalog", "sktime Series Annotators Catalog", "Interval-Based Time Series Regression", "KNeighborsTimeSeriesRegressor", "RocketRegressor", "TimeSeriesForestRegressor", "sktime Series Annotation (Anomalies, Change Points, Segmentation)", "sktime Preprocessing Transformers", "RocketTransformer", "TSFreshFeatureExtractor", "Time Series Transformers", "Fourier Terms for Seasonality", "Lag Features for Time Series", "Rolling Window Features", "DevOps \u2014 Overview", "Argo CD (GitOps Continuous Delivery for Kubernetes)", "GitHub Actions (CI/CD)", "Jenkins (CI/CD)", "Pulumi (Infrastructure as Code with real languages)", "Terraform (Infrastructure as Code)", "CI/CD", "AWS service icons", "AWS CloudFormation", "AWS CloudFront", "Amazon CloudWatch", "Amazon DynamoDB", "Amazon EC2 (Elastic Compute Cloud)", "Amazon ECS (Elastic Container Service)", "Amazon EKS (Elastic Kubernetes Service)", "Amazon ElastiCache", "Amazon EMR (Elastic MapReduce)", "Amazon EventBridge", "AWS Glue", "AWS Lambda", "AWS Managed Workflows for Apache Airflow (MWAA)", "Amazon RDS (Relational Database Service)", "Amazon S3 (Simple Storage Service)", "Snowflake (Cloud Data Platform)", "Amazon SNS (Simple Notification Service)", "Amazon SQS (Simple Queue Service)", "AWS Step Functions", "Amazon VPC (Virtual Private Cloud)", "Docker (Containerisation)", "Podman (Containerisation)", "Containers", "Cost &amp; Capacity", "Infrastructure as Code", "Incident Response", "Kubernetes", "ConfigMaps", "CronJobs", "Deployments (Stateless workloads)", "HPA (Horizontal Pod Autoscaler)", "Ingress", "Jobs", "Kustomize (manage YAML at scale)", "Namespaces", "Persistent Volumes (PV) &amp; PersistentVolumeClaims (PVC)", "Pods", "ReplicaSets (Replicas)", "Secrets", "Services", "StatefulSets (Stateful workloads)", "StorageClasses", "Observability &amp; SRE", "Telemetry &amp; Display (Observability)", "Elasticsearch", "Grafana", "Kibana", "Logstash", "Prometheus", "Finance \u2014 Overview", "Derivatives", "Black-Scholes Option Pricing", "Financial Econometrics", "Fixed Income", "Portfolio Theory", "Efficient Frontier (Mean-Variance)", "Fama-French Factor Model (Toy Example)", "Risk", "Time Value of Money", "Frontend \u2014 Overview", "Frameworks &amp; Architecture", "Performance &amp; Accessibility", "Frontend Security", "State &amp; Data", "Frontend Testing", "Web Fundamentals", "System Design \u2014 Overview", "Case Studies", "Consistency Models", "Design Checklists", "Reliability &amp; DR", "Requirements &amp; Tradeoffs", "Scalability Patterns"], "terms": {"api": [0, 33, 36, 40, 41, 42, 43, 44, 46, 48, 49, 52, 54, 55, 58, 59, 60, 61, 62, 63, 66, 67, 68, 69, 71, 72, 74, 76, 77, 79, 80, 82, 84, 85, 86, 87, 88, 89, 92, 93, 94, 98, 100, 101, 102, 110, 120, 122, 124, 129, 143, 145, 148, 160, 167, 169, 173, 179, 183, 195, 198, 212, 220, 229, 233, 236, 295, 305, 308, 323, 331, 332, 333, 334, 335, 339, 341, 342, 343, 344, 348, 349, 352, 353, 356, 357, 358, 359, 367, 375, 376], "servic": [4, 6, 87, 163, 169, 239, 303, 331, 334, 338, 340, 341, 342, 345, 346, 347, 348, 349, 350, 353, 356, 357, 358, 359, 364, 367, 369, 371, 372, 374, 378, 381, 382, 384, 385, 386], "data": [0, 2, 9, 14, 20, 25, 26, 27, 28, 29, 30, 32, 35, 36, 37, 38, 41, 45, 46, 49, 50, 52, 53, 59, 67, 69, 72, 74, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 120, 121, 122, 124, 127, 131, 132, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 261, 262, 264, 265, 266, 269, 270, 271, 283, 285, 287, 295, 300, 306, 308, 310, 314, 322, 323, 335, 338, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 355, 356, 357, 358, 359, 365, 373, 374, 376, 378, 379, 381, 382, 383, 384, 385, 389, 397, 400], "layer": [20, 21, 22, 27, 138, 139, 140, 141, 143, 144, 145, 146, 175, 214, 342, 346, 358, 359, 360, 384], "reliabl": [38, 41, 45, 46, 89, 90, 110, 111, 117, 134, 148, 152, 154, 162, 165, 167, 168, 169, 170, 171, 173, 180, 183, 187, 197, 199, 200, 201, 203, 216, 220, 223, 225, 226, 234, 237, 242, 247, 248, 252, 258, 285, 311, 339, 355, 356, 358, 404], "design": [0, 7, 9, 21, 22, 64, 87, 97, 103, 107, 108, 112, 113, 116, 117, 118, 120, 124, 125, 134, 142, 159, 174, 191, 192, 197, 209, 213, 216, 233, 234, 237, 238, 243, 249, 251, 252, 257, 264, 267, 268, 270, 295, 341, 347, 352, 355, 368, 382, 386, 398, 405], "auth": [0, 14, 332, 340, 341, 344, 347, 351, 353, 355, 377, 382], "secur": [0, 1, 10, 15, 332, 333, 338, 339, 342, 343, 344, 345, 346, 350, 351, 353, 357, 359, 360, 372, 381, 382, 397], "cach": [0, 7, 19, 20, 332, 339, 342, 345, 353, 401, 410], "queue": [0, 4, 162, 163, 169, 170, 171, 172, 178, 180, 218, 239, 338, 340, 342, 345, 353, 354, 373, 385], "storag": [0, 145, 334, 335, 338, 342, 346, 348, 350, 351, 353, 358, 359, 373, 374, 378, 379, 381, 382], "model": [0, 10, 20, 21, 25, 27, 28, 29, 31, 32, 34, 35, 39, 41, 45, 50, 52, 53, 56, 57, 64, 65, 67, 69, 74, 77, 78, 83, 84, 89, 90, 95, 101, 102, 103, 105, 116, 117, 119, 123, 125, 127, 129, 131, 132, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 228, 243, 244, 246, 247, 248, 250, 252, 253, 254, 256, 257, 259, 260, 262, 263, 265, 267, 268, 269, 270, 271, 275, 280, 281, 283, 284, 287, 288, 293, 295, 299, 301, 302, 303, 308, 309, 314, 316, 318, 321, 322, 323, 326, 327, 328, 340, 341, 342, 343, 344, 349, 350, 351, 352, 356, 359, 381, 386, 392, 395, 404], "observ": [0, 26, 29, 30, 32, 38, 46, 47, 57, 69, 87, 93, 94, 95, 99, 103, 104, 112, 114, 115, 116, 117, 118, 120, 121, 122, 127, 134, 139, 140, 143, 149, 150, 152, 153, 156, 157, 160, 161, 162, 163, 164, 165, 167, 168, 171, 173, 176, 177, 178, 179, 182, 183, 185, 186, 192, 193, 194, 195, 196, 197, 198, 199, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 218, 219, 221, 222, 223, 224, 225, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 302, 305, 308, 330, 331, 335, 340, 349, 350, 356, 368, 382, 383], "resili": [0, 382, 385], "perform": [0, 1, 30, 31, 34, 35, 37, 49, 52, 64, 65, 67, 92, 99, 102, 105, 108, 110, 113, 122, 135, 139, 144, 146, 148, 151, 153, 170, 171, 172, 181, 189, 224, 229, 233, 265, 267, 269, 271, 288, 299, 309, 310, 334, 338, 340, 359, 367, 379, 397], "test": [0, 19, 20, 21, 22, 27, 35, 37, 38, 39, 41, 46, 50, 53, 57, 64, 67, 70, 87, 89, 90, 91, 92, 93, 95, 96, 99, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 119, 120, 121, 122, 124, 125, 127, 131, 134, 138, 145, 228, 271, 280, 281, 287, 289, 290, 291, 293, 294, 297, 298, 299, 301, 302, 306, 309, 310, 320, 321, 323, 324, 325, 332, 333, 334, 336, 353, 359, 378, 385, 395, 397], "qualiti": [0, 19, 34, 36, 38, 45, 47, 50, 51, 56, 64, 67, 69, 83, 108, 113, 195, 200, 209, 214, 217, 225, 226, 230, 234, 242, 258, 259, 269, 340, 350], "placehold": [17, 18, 23, 24, 133, 147, 272, 273, 274, 276, 277, 278, 279, 282, 342, 346, 348, 350], "note": [9, 19, 20, 21, 22, 27, 29, 34, 36, 39, 41, 46, 49, 51, 59, 65, 72, 73, 75, 77, 81, 84, 88, 92, 93, 100, 105, 107, 110, 113, 114, 117, 120, 124, 132, 136, 138, 141, 142, 143, 150, 159, 161, 162, 163, 165, 167, 168, 169, 172, 173, 174, 176, 177, 184, 185, 186, 188, 189, 191, 193, 194, 197, 198, 200, 205, 207, 208, 211, 213, 216, 217, 218, 220, 221, 222, 223, 229, 230, 231, 236, 237, 238, 239, 240, 241, 242, 243, 245, 248, 256, 258, 263, 267, 268, 270, 271, 332, 339, 343, 344, 346, 348, 349, 351, 352, 353, 354, 356, 357, 358, 359, 376], "refer": [0, 10, 131, 132, 141, 152, 155, 156, 158, 161, 166, 168, 170, 175, 178, 180, 181, 186, 196, 199, 200, 209, 210, 226, 228, 230, 285, 330, 343, 351, 387, 397, 404], "exampl": [0, 1, 2, 10, 26, 27, 30, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 70, 71, 72, 75, 76, 78, 79, 80, 82, 86, 87, 88, 91, 92, 94, 96, 97, 98, 99, 106, 108, 110, 111, 114, 116, 121, 127, 129, 139, 140, 142, 143, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 178, 179, 181, 183, 185, 187, 190, 191, 192, 194, 195, 197, 202, 204, 206, 207, 208, 211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 251, 252, 254, 256, 261, 269, 270, 271, 285, 296, 303, 311, 315, 317, 318, 326, 330, 338, 339, 340, 341, 342, 344, 345, 347, 349, 350, 354, 356, 357, 359, 366, 367, 369, 370, 374, 375, 378, 379, 387, 397, 404], "A": [2, 9, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 33, 36, 37, 38, 39, 41, 45, 47, 49, 50, 52, 53, 56, 57, 59, 64, 65, 67, 68, 69, 70, 72, 75, 77, 78, 81, 84, 85, 86, 87, 89, 90, 92, 94, 95, 96, 97, 98, 99, 103, 104, 106, 107, 109, 111, 112, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 134, 135, 136, 137, 139, 142, 148, 150, 151, 152, 154, 155, 156, 157, 158, 160, 163, 165, 167, 168, 170, 171, 173, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 198, 199, 200, 202, 203, 204, 207, 209, 210, 211, 212, 215, 216, 219, 220, 221, 222, 223, 224, 228, 235, 238, 240, 244, 247, 248, 249, 253, 254, 256, 258, 259, 262, 264, 265, 266, 267, 269, 271, 275, 280, 284, 285, 287, 288, 291, 292, 293, 295, 296, 297, 298, 302, 304, 305, 307, 318, 322, 327, 328, 331, 332, 333, 334, 335, 338, 348, 349, 353, 355, 356, 357, 358, 359, 365, 366, 367, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 381, 382, 383, 384, 385, 386, 389, 393], "structur": [0, 2, 9, 10, 21, 26, 27, 28, 29, 31, 33, 57, 59, 68, 70, 83, 85, 97, 108, 111, 112, 114, 115, 116, 117, 119, 122, 135, 137, 157, 185, 186, 189, 192, 197, 199, 203, 219, 237, 245, 255, 260, 266, 267, 271, 300, 327, 328, 330, 353, 371, 381, 382, 384, 385, 387, 397, 404], "long": [4, 9, 20, 31, 32, 39, 67, 84, 97, 99, 103, 111, 114, 121, 131, 138, 139, 140, 141, 148, 149, 163, 173, 175, 178, 188, 197, 212, 236, 240, 241, 248, 264, 271, 300, 323, 332, 333, 342, 343, 352, 355, 356, 358, 359, 368, 382], "form": [9, 20, 28, 30, 31, 32, 39, 45, 49, 50, 53, 59, 81, 91, 96, 97, 99, 100, 106, 109, 110, 111, 113, 116, 120, 121, 122, 132, 135, 136, 140, 144, 146, 148, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 162, 163, 165, 166, 168, 169, 170, 171, 175, 176, 178, 179, 181, 182, 183, 184, 185, 186, 187, 189, 190, 192, 193, 194, 199, 201, 202, 204, 205, 207, 208, 210, 211, 212, 215, 216, 217, 219, 220, 221, 222, 223, 224, 226, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 246, 249, 254, 262, 266, 327, 381, 384, 385], "hub": [9, 333, 358], "engin": [9, 103, 110, 143, 165, 167, 172, 200, 218, 220, 237, 243, 329, 346, 348, 350, 351, 353, 358, 359, 382], "financ": [9, 45, 87, 94, 114, 119, 121, 122, 169, 172, 177, 183, 195, 197, 210, 218, 259], "navig": [9, 113, 140, 222], "jump": [9, 34, 49, 67, 90, 99, 112, 176, 177, 178, 179, 207, 222, 239, 256, 283], "follow": [9, 26, 69, 92, 111, 113, 135, 137, 142, 143, 151, 153, 154, 156, 158, 163, 166, 170, 173, 174, 177, 178, 179, 185, 186, 188, 190, 196, 203, 205, 210, 216, 218, 225, 228, 232, 233, 234, 237, 247, 250, 252, 257, 258, 259, 261, 264, 266, 267, 268, 280, 295, 300, 331], "foundat": [9, 29, 73, 137, 189, 271], "end": [8, 9, 19, 20, 21, 22, 25, 27, 30, 31, 32, 34, 37, 38, 39, 46, 52, 56, 59, 65, 67, 72, 77, 81, 83, 87, 88, 89, 91, 92, 94, 100, 103, 107, 108, 109, 110, 114, 116, 117, 118, 120, 122, 125, 127, 129, 134, 135, 137, 138, 139, 140, 141, 142, 143, 145, 146, 148, 149, 150, 152, 154, 155, 156, 157, 158, 161, 164, 165, 166, 169, 170, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 184, 185, 187, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 210, 211, 212, 213, 214, 215, 216, 217, 219, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 247, 248, 251, 252, 253, 255, 257, 259, 260, 263, 264, 266, 267, 270, 275, 289, 315, 322, 335, 340, 346, 358, 382], "start": [9, 19, 20, 21, 22, 25, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 49, 52, 56, 59, 64, 65, 67, 69, 72, 89, 91, 92, 98, 99, 103, 105, 109, 112, 113, 114, 115, 116, 117, 118, 119, 122, 123, 125, 127, 129, 131, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 150, 151, 152, 154, 155, 157, 158, 159, 164, 165, 167, 168, 169, 170, 171, 172, 174, 175, 181, 183, 185, 187, 188, 189, 192, 195, 198, 199, 200, 201, 204, 205, 208, 209, 211, 213, 215, 219, 220, 222, 227, 233, 235, 236, 240, 244, 248, 249, 250, 252, 254, 257, 260, 264, 270, 275, 283, 286, 289, 292, 293, 295, 296, 306, 308, 313, 316, 322, 333, 340, 346, 347, 348, 349, 356, 358, 359, 370, 371, 384], "overview": [9, 50, 53, 89, 126, 128, 129, 130, 144, 197, 256, 372, 381, 386], "drill": [9, 381, 384], "its": [9, 25, 26, 27, 28, 31, 38, 51, 53, 57, 69, 70, 73, 74, 78, 81, 83, 86, 88, 89, 91, 92, 95, 96, 97, 100, 101, 104, 105, 106, 108, 112, 116, 118, 119, 121, 123, 134, 136, 138, 139, 146, 148, 150, 160, 162, 163, 165, 166, 167, 168, 175, 176, 177, 179, 180, 183, 184, 185, 190, 194, 196, 197, 199, 203, 204, 205, 206, 208, 209, 210, 211, 213, 220, 221, 224, 228, 229, 230, 231, 232, 235, 238, 240, 242, 244, 245, 252, 253, 257, 266, 268, 269, 270, 287, 292, 293, 333, 334, 351, 358, 378], "sub": [2, 4, 9, 77, 86, 87, 168, 216, 217, 221, 236, 289, 294, 318, 345, 354], "section": [0, 9, 10, 17, 18, 20, 22, 23, 24, 25, 32, 84, 89, 93, 101, 122, 133, 136, 141, 143, 144, 147, 160, 165, 166, 171, 174, 175, 180, 188, 191, 199, 204, 206, 207, 208, 214, 221, 228, 266, 267, 268, 272, 273, 274, 276, 277, 278, 279, 282, 283, 312, 330, 387, 397, 404], "add": [3, 9, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 57, 58, 60, 61, 62, 63, 65, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 86, 88, 91, 93, 94, 95, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 113, 116, 117, 118, 122, 123, 125, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 149, 150, 152, 158, 163, 167, 168, 175, 176, 183, 190, 194, 204, 206, 208, 211, 216, 222, 229, 237, 239, 246, 247, 252, 253, 256, 257, 260, 261, 262, 267, 269, 270, 272, 273, 274, 276, 277, 278, 279, 282, 296, 300, 302, 327, 332, 333, 334, 335, 341, 344, 347, 357, 358, 383, 384, 385], "new": [9, 20, 25, 31, 38, 73, 90, 103, 105, 110, 111, 113, 114, 117, 121, 123, 135, 137, 143, 146, 157, 160, 199, 210, 228, 231, 232, 240, 246, 249, 250, 255, 259, 261, 263, 331, 334, 335, 341, 349, 359, 367, 370, 381], "page": [9, 46, 134, 240, 241, 245, 257, 337, 381, 383, 384, 386], "under": [9, 22, 28, 33, 36, 39, 41, 51, 59, 64, 65, 67, 78, 84, 86, 87, 88, 89, 90, 91, 94, 96, 97, 99, 101, 103, 107, 112, 113, 118, 120, 121, 122, 137, 138, 139, 141, 146, 149, 150, 151, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 174, 175, 176, 177, 178, 181, 182, 183, 184, 185, 187, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 215, 216, 217, 219, 221, 222, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 245, 246, 247, 249, 250, 253, 254, 255, 256, 257, 259, 260, 262, 263, 265, 266, 267, 268, 280, 287, 335, 340, 352, 358, 359, 389], "relev": [9, 47, 50, 341], "topic": [9, 51, 77, 117, 159, 231, 280, 340, 354, 355], "folder": [9, 117, 123, 126, 128, 130, 136, 352, 371], "wire": [9, 136, 334], "them": [9, 19, 22, 26, 27, 29, 30, 34, 36, 37, 39, 50, 51, 69, 73, 75, 77, 86, 89, 91, 103, 108, 111, 113, 116, 117, 125, 136, 138, 141, 151, 153, 154, 158, 162, 163, 165, 167, 168, 171, 172, 176, 180, 184, 187, 192, 200, 209, 214, 216, 218, 219, 220, 229, 231, 234, 235, 236, 244, 248, 249, 254, 259, 260, 270, 305, 334, 338, 346, 347, 358, 359, 368, 371, 374, 376, 382, 385, 386], "toc": 9, "keep": [9, 19, 20, 21, 22, 25, 29, 30, 31, 32, 35, 36, 39, 47, 52, 57, 59, 65, 69, 70, 73, 74, 75, 88, 90, 99, 101, 104, 105, 109, 110, 113, 115, 116, 122, 132, 134, 136, 143, 144, 146, 149, 159, 160, 163, 164, 167, 169, 174, 176, 178, 180, 182, 184, 185, 190, 203, 207, 208, 209, 211, 214, 218, 219, 224, 227, 228, 229, 231, 236, 240, 243, 245, 247, 249, 251, 257, 260, 263, 265, 266, 269, 270, 285, 296, 299, 300, 310, 319, 323, 331, 333, 334, 339, 340, 343, 344, 346, 347, 348, 349, 353, 356, 357, 358, 365, 367, 368, 371, 375, 376], "short": [9, 20, 27, 28, 103, 112, 114, 116, 117, 121, 123, 125, 127, 129, 131, 132, 138, 151, 166, 209, 215, 218, 239, 285, 289, 292, 293, 299, 304, 306, 307, 323, 332, 350, 356], "link": [9, 46, 53, 67, 88, 97, 98, 104, 113, 144, 148, 162, 164, 168, 180, 181, 200, 220, 236, 240, 243, 266], "out": [4, 9, 20, 21, 22, 28, 30, 31, 32, 35, 36, 38, 39, 41, 45, 46, 47, 49, 50, 51, 53, 56, 57, 59, 65, 70, 74, 75, 78, 87, 88, 91, 98, 100, 110, 112, 113, 115, 116, 119, 125, 132, 138, 139, 140, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 183, 184, 185, 187, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 241, 243, 245, 247, 252, 253, 254, 264, 265, 301, 331, 333, 334, 335, 354, 355, 356, 376], "deeper": [9, 21, 22, 110, 189, 285], "notebook": [9, 19, 20, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 138, 141, 145, 148, 149, 150, 151, 152, 153, 154, 155, 156, 160, 161, 164, 165, 166, 167, 168, 170, 171, 172, 173, 174, 175, 177, 178, 179, 181, 182, 184, 187, 188, 192, 193, 196, 199, 200, 202, 203, 204, 206, 207, 210, 215, 217, 220, 222, 224, 225, 226, 227, 228, 230, 231, 232, 233, 236, 239, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 280, 283, 295, 296, 308, 310, 311, 312, 313, 314, 315, 316, 317, 343, 346, 350, 351, 352, 353, 356, 357], "thei": [2, 9, 21, 26, 27, 29, 31, 36, 38, 39, 47, 53, 59, 70, 73, 81, 83, 89, 91, 92, 97, 99, 101, 104, 110, 113, 117, 119, 123, 125, 139, 142, 148, 151, 154, 155, 158, 159, 160, 161, 166, 168, 172, 173, 175, 178, 180, 182, 184, 185, 187, 191, 207, 209, 211, 212, 214, 216, 222, 228, 232, 233, 240, 243, 244, 245, 246, 247, 251, 252, 255, 256, 261, 263, 265, 268, 302, 310, 328, 329, 332, 334, 358, 359, 367, 374, 375, 376, 389], "grow": [9, 25, 36, 69, 73, 86, 87, 88, 91, 93, 95, 96, 97, 98, 101, 102, 103, 104, 105, 138, 143, 148, 150, 155, 164, 166, 167, 188, 189, 201, 205, 206, 207, 217, 218, 239, 243, 244, 247, 248, 249, 257, 266, 267, 268, 271, 299, 310, 381, 382], "backend": [4, 9, 115, 138, 144, 145, 334, 335, 341, 344, 345, 349, 351, 369, 373, 379, 381], "cybersecur": 9, "scienc": [9, 30, 167, 269], "devop": 9, "frontend": 9, "system": [0, 3, 7, 9, 10, 28, 30, 49, 56, 59, 90, 107, 110, 113, 163, 171, 172, 196, 197, 206, 207, 215, 302, 330, 334, 335, 340, 342, 344, 346, 347, 350, 352, 353, 354, 355, 356, 358, 359, 367, 368, 374, 378, 381, 382, 386, 387, 397, 405], "ident": [10, 22, 26, 34, 45, 50, 53, 64, 70, 74, 75, 77, 84, 86, 89, 98, 102, 104, 116, 138, 141, 144, 145, 146, 150, 151, 152, 153, 154, 165, 166, 170, 171, 173, 176, 177, 178, 179, 180, 181, 183, 184, 185, 187, 188, 190, 191, 193, 198, 200, 202, 205, 207, 210, 214, 215, 216, 220, 226, 228, 229, 230, 231, 234, 235, 236, 237, 246, 247, 252, 258, 262, 265, 267, 268, 344, 367, 371, 377, 378], "defens": [173, 260], "depth": [22, 110, 209, 340], "practic": [0, 10, 29, 31, 38, 47, 49, 50, 56, 57, 59, 67, 72, 75, 95, 100, 104, 108, 113, 114, 116, 117, 120, 121, 122, 123, 124, 129, 134, 135, 136, 138, 140, 143, 144, 148, 149, 150, 152, 154, 155, 156, 157, 158, 159, 161, 163, 164, 166, 167, 169, 170, 171, 172, 173, 174, 175, 176, 178, 179, 183, 184, 187, 188, 189, 191, 192, 193, 195, 196, 197, 198, 199, 201, 203, 206, 208, 209, 210, 211, 213, 215, 218, 219, 220, 221, 222, 224, 225, 227, 228, 229, 231, 232, 233, 234, 237, 239, 240, 241, 248, 249, 255, 256, 263, 270, 271, 280, 295, 330, 372, 381, 382, 383, 384, 387, 397, 404], "access": [2, 5, 10, 26, 140, 334, 335, 339, 341, 342, 343, 345, 349, 350, 351, 352, 353, 357, 359, 372, 373, 376, 383, 397], "code": [1, 17, 18, 22, 23, 24, 35, 86, 91, 95, 101, 108, 113, 117, 123, 133, 136, 137, 138, 139, 140, 142, 144, 145, 147, 153, 182, 184, 193, 194, 201, 206, 207, 211, 225, 230, 232, 264, 272, 273, 274, 276, 277, 278, 279, 282, 359, 376, 383], "owasp": 10, "threat": [10, 400], "vulner": [], "manag": [111, 306, 331, 332, 333, 334, 335, 338, 339, 341, 342, 343, 344, 345, 346, 348, 349, 351, 352, 353, 354, 355, 356, 359, 367, 369, 374, 375, 378], "incid": [10, 112, 114, 231, 330, 340, 383, 384], "respons": [4, 10, 113, 123, 163, 182, 185, 218, 224, 247, 248, 249, 251, 260, 263, 330, 339, 342, 344, 345, 349, 355, 383, 384], "network": [10, 20, 52, 106, 109, 135, 136, 141, 143, 145, 146, 162, 163, 196, 206, 213, 215, 223, 240, 332, 333, 334, 335, 338, 339, 342, 343, 344, 345, 346, 349, 350, 351, 352, 357, 369, 372, 374, 377, 378, 381], "cloud": [205, 328, 332, 333, 334, 335, 352, 358, 369, 373, 377, 379, 386], "statist": [29, 33, 36, 46, 49, 52, 65, 67, 70, 75, 81, 87, 88, 90, 91, 96, 99, 101, 103, 105, 107, 108, 110, 120, 124, 127, 131, 132, 136, 142, 228, 242, 245, 248, 255, 259, 261, 262, 264, 271, 289, 305, 318, 325, 328, 329, 340], "ml": [30, 33, 41, 53, 68, 85, 105, 253, 269, 328, 329, 340, 343, 344, 345, 346, 347, 350, 352, 353, 354, 355, 356, 357], "time": [6, 19, 21, 22, 25, 26, 28, 29, 30, 31, 32, 36, 38, 41, 45, 51, 53, 57, 65, 67, 69, 73, 77, 83, 86, 89, 91, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 124, 127, 129, 130, 131, 134, 136, 138, 139, 140, 141, 143, 144, 145, 146, 148, 150, 152, 154, 159, 160, 162, 163, 164, 165, 167, 168, 169, 170, 171, 173, 178, 179, 180, 182, 183, 185, 186, 187, 189, 195, 196, 197, 199, 203, 206, 208, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 225, 226, 227, 230, 231, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 245, 246, 247, 248, 250, 255, 256, 257, 258, 260, 262, 263, 264, 265, 266, 268, 269, 283, 290, 291, 294, 296, 299, 300, 301, 303, 304, 306, 307, 311, 319, 322, 323, 324, 325, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350, 351, 353, 355, 368, 375, 381, 382, 384, 386, 387], "seri": [6, 21, 89, 92, 100, 102, 111, 112, 113, 114, 115, 116, 117, 121, 122, 123, 124, 127, 129, 130, 131, 134, 151, 161, 165, 170, 173, 174, 191, 192, 193, 195, 208, 219, 220, 227, 229, 235, 238, 242, 245, 246, 248, 255, 256, 258, 263, 264, 265, 266, 269, 290, 291, 293, 294, 299, 300, 301, 302, 304, 305, 306, 307, 308, 309, 319, 324, 325, 327, 329, 340, 381, 386], "learn": [20, 33, 35, 36, 38, 40, 41, 42, 43, 44, 45, 48, 49, 52, 54, 55, 58, 59, 60, 61, 62, 63, 66, 68, 71, 74, 75, 76, 78, 79, 80, 82, 85, 90, 93, 95, 112, 113, 115, 116, 120, 126, 127, 128, 129, 132, 146, 153, 189, 194, 214, 284, 288, 289, 292, 293, 296, 300, 301, 306, 312, 318, 322, 328, 331, 332, 333, 342, 352, 358, 359, 371, 381, 383, 384, 386], "linear": [20, 21, 22, 27, 29, 31, 32, 35, 41, 47, 49, 52, 59, 64, 67, 74, 78, 91, 92, 93, 95, 98, 99, 102, 105, 109, 110, 112, 114, 115, 117, 119, 120, 122, 123, 130, 131, 132, 134, 135, 138, 139, 140, 141, 142, 143, 144, 145, 146, 157, 163, 168, 171, 176, 183, 184, 185, 189, 191, 194, 208, 211, 212, 215, 217, 221, 222, 226, 227, 230, 237, 239, 241, 243, 244, 248, 250, 254, 255, 259, 265, 280, 286, 291, 293, 308, 309, 320, 327], "algebra": [27, 28, 29, 45, 51, 112, 113, 117, 185, 191, 221, 224, 225, 233, 244], "machin": [30, 46, 52, 103, 110, 113, 189, 194, 252, 253, 259, 306, 332, 341, 342, 346, 352, 356], "deep": [19, 20, 21, 22, 32, 134, 214, 288, 300, 312, 407], "reinforc": [134, 138, 139, 141, 224, 228], "ci": [116, 120, 124, 173, 178, 179, 182, 184, 186, 194, 196, 201, 216, 220, 222, 223, 226, 239, 243, 249, 250, 255, 261, 262, 265, 267, 268, 269, 330, 331, 334, 335, 338, 344], "cd": [154, 211, 213, 330, 335, 338], "infrastructur": [332, 333, 338, 342, 349, 371, 383], "oper": [33, 35, 36, 39, 49, 64, 97, 107, 116, 119, 122, 146, 153, 167, 173, 177, 181, 189, 199, 214, 238, 333, 335, 338, 340, 341, 342, 344, 345, 346, 350, 351, 352, 353, 378, 381, 384], "iac": [330, 334, 335, 338, 339, 344, 354, 356, 357], "containeris": [], "kubernet": [330, 332, 333, 334, 335, 346, 358, 359, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 386], "sre": [330, 381], "telemetri": 341, "displai": [104, 207, 389, 393, 394], "cost": [25, 34, 35, 37, 49, 50, 56, 57, 64, 65, 67, 87, 91, 93, 94, 98, 102, 103, 105, 110, 117, 125, 132, 144, 146, 154, 174, 185, 187, 189, 212, 226, 230, 232, 233, 235, 241, 280, 287, 289, 308, 330, 338, 341, 342, 343, 344, 346, 349, 350, 351, 352, 353, 355, 357, 368, 381, 382], "capac": [87, 138, 139, 144, 145, 330, 341, 342, 343, 344, 381, 386], "core": [20, 22, 26, 29, 30, 32, 96, 97, 100, 103, 105, 107, 110, 113, 114, 115, 117, 134, 136, 140, 143, 144, 148, 152, 157, 158, 177, 180, 183, 185, 193, 195, 201, 202, 203, 211, 215, 218, 229, 246, 249, 253, 258, 269, 295, 343, 346, 352, 399], "theori": [52, 78, 89, 98, 136, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 163, 165, 166, 168, 169, 170, 171, 172, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 196, 201, 203, 204, 205, 206, 207, 208, 209, 210, 212, 214, 217, 218, 219, 221, 222, 223, 224, 227, 228, 229, 230, 231, 234, 235, 240, 241, 242, 246, 387], "instrument": [157, 174, 175, 216], "quantit": 202, "method": [25, 26, 27, 28, 29, 30, 31, 32, 34, 37, 50, 52, 59, 67, 70, 72, 75, 81, 84, 92, 94, 99, 101, 103, 104, 107, 109, 119, 120, 122, 124, 128, 134, 135, 145, 146, 148, 149, 150, 151, 152, 153, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 169, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198, 199, 200, 202, 203, 204, 205, 207, 209, 210, 212, 213, 214, 215, 216, 217, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 244, 245, 249, 251, 252, 254, 258, 259, 260, 263, 265, 267, 268, 269, 270, 271, 281, 283, 286, 289, 297, 298, 303, 326, 339, 381, 386], "valu": [19, 20, 26, 27, 28, 29, 31, 32, 35, 36, 38, 39, 41, 46, 47, 50, 51, 52, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 78, 81, 83, 84, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 127, 129, 131, 132, 135, 136, 137, 142, 145, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 228, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 249, 252, 253, 255, 257, 259, 261, 265, 271, 280, 285, 286, 288, 296, 300, 301, 303, 305, 306, 308, 313, 315, 316, 317, 318, 327, 328, 329, 331, 334, 335, 338, 340, 341, 342, 345, 347, 353, 357, 365, 371, 376, 383, 387, 389, 394], "monei": 387, "fix": [6, 26, 28, 30, 31, 35, 36, 37, 41, 45, 46, 50, 51, 52, 53, 57, 65, 67, 69, 70, 74, 86, 87, 88, 89, 90, 92, 93, 94, 98, 100, 101, 102, 103, 104, 107, 108, 110, 113, 116, 122, 123, 125, 127, 134, 137, 138, 139, 145, 146, 148, 149, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 208, 209, 211, 213, 214, 215, 216, 218, 219, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 234, 235, 236, 237, 238, 240, 241, 242, 243, 247, 251, 252, 253, 255, 256, 257, 261, 263, 264, 265, 267, 269, 271, 299, 310, 331, 341, 381, 385, 387], "incom": [154, 160, 168, 187, 196, 387], "deriv": [28, 30, 36, 37, 38, 39, 41, 49, 53, 56, 57, 65, 67, 70, 72, 75, 84, 89, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 107, 108, 109, 111, 119, 121, 134, 135, 137, 140, 143, 144, 146, 228, 242, 244, 245, 250, 264, 295, 345, 387], "portfolio": [26, 111, 121, 387, 389, 393], "risk": [26, 38, 45, 46, 56, 67, 74, 87, 94, 95, 99, 111, 121, 171, 172, 199, 200, 212, 236, 242, 251, 261, 305, 308, 387, 389, 393, 394], "econometr": [113, 122, 387], "web": [59, 145, 160, 210, 236, 342, 343, 344, 345, 350, 358, 359, 367, 369, 372, 384, 397, 399], "fundament": [21, 73, 181, 397], "ui": [253, 331, 333, 381, 383, 384], "architectur": [19, 21, 22, 134, 139, 144, 145, 335, 337, 341, 347, 385, 397, 407], "framework": [27, 32, 173, 346, 348, 393, 397], "state": [4, 25, 116, 117, 118, 119, 120, 122, 123, 124, 132, 134, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 148, 158, 160, 161, 165, 166, 173, 189, 191, 194, 199, 210, 216, 220, 227, 232, 233, 234, 235, 238, 239, 242, 243, 244, 259, 264, 270, 331, 334, 335, 338, 341, 346, 347, 348, 351, 356, 357, 359, 367, 368, 373, 374, 397, 398], "roadmap": [], "convent": [30, 36, 45, 49, 53, 57, 59, 72, 78, 81, 83, 86, 88, 89, 91, 92, 95, 98, 99, 104, 116, 152, 154, 157, 158, 165, 167, 168, 170, 172, 173, 174, 177, 179, 181, 182, 184, 185, 187, 188, 193, 195, 196, 198, 200, 203, 210, 211, 215, 217, 219, 226, 231, 232, 238, 249, 258, 268, 270, 285], "wide": [91, 96, 100, 102, 125, 144, 151, 165, 168, 169, 173, 202, 203, 220, 233, 242, 250, 251, 318, 319], "track": [22, 35, 36, 46, 49, 59, 64, 67, 86, 87, 88, 97, 100, 134, 138, 140, 141, 160, 163, 175, 205, 222, 329, 340, 351, 356], "ckc": [152, 165, 167, 168, 173, 174, 177, 181, 182, 184, 188, 193, 196, 198, 200, 203, 210, 211, 215, 217, 249, 268, 338, 342], "regist": [134, 142, 143, 285, 311, 343, 356], "tradeoff": [25, 32, 33, 34, 48, 49, 65, 103, 109, 113, 123, 146, 280, 333, 382, 398], "scale": [5, 20, 21, 22, 25, 26, 27, 28, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 50, 51, 52, 53, 57, 64, 65, 70, 72, 73, 77, 81, 83, 84, 86, 87, 88, 89, 91, 94, 95, 96, 99, 100, 101, 102, 104, 107, 108, 110, 111, 112, 116, 117, 119, 125, 131, 132, 135, 136, 137, 138, 139, 140, 141, 143, 144, 146, 148, 150, 152, 153, 155, 157, 158, 159, 160, 166, 170, 174, 176, 179, 181, 182, 183, 184, 185, 186, 189, 190, 191, 192, 193, 195, 201, 202, 205, 209, 210, 211, 212, 214, 217, 218, 222, 224, 225, 226, 227, 228, 230, 231, 232, 233, 236, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 260, 261, 262, 264, 265, 266, 267, 268, 269, 280, 285, 287, 291, 295, 296, 299, 303, 305, 319, 326, 332, 333, 340, 341, 342, 343, 344, 345, 346, 349, 350, 353, 367, 368, 378, 381, 382, 385], "pattern": [0, 5, 10, 20, 25, 26, 30, 41, 46, 51, 74, 89, 93, 97, 101, 103, 105, 109, 113, 114, 115, 116, 119, 122, 124, 125, 127, 129, 131, 148, 159, 162, 163, 173, 179, 184, 185, 198, 204, 211, 213, 221, 223, 237, 239, 240, 241, 253, 254, 271, 284, 289, 291, 292, 300, 302, 330, 334, 335, 339, 341, 342, 344, 345, 346, 347, 351, 352, 355, 356, 359, 367, 376, 381, 383, 384, 385, 386, 387, 397, 404], "requir": [25, 29, 36, 38, 39, 46, 51, 52, 56, 59, 64, 69, 70, 72, 73, 74, 77, 78, 81, 84, 87, 88, 91, 92, 93, 94, 95, 97, 98, 102, 107, 111, 115, 117, 118, 120, 121, 124, 140, 143, 144, 146, 148, 150, 154, 157, 159, 160, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 187, 189, 191, 192, 193, 194, 195, 196, 199, 202, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 225, 226, 228, 231, 232, 234, 238, 240, 241, 243, 244, 246, 248, 253, 257, 258, 262, 264, 265, 270, 297, 298, 300, 315, 322, 332, 333, 338, 342, 344, 345, 350, 351, 355, 369, 373, 376, 378, 382, 404, 407], "consist": [1, 5, 28, 32, 35, 46, 52, 73, 93, 103, 107, 122, 134, 151, 155, 156, 158, 159, 185, 186, 190, 206, 208, 218, 222, 229, 245, 247, 250, 253, 258, 261, 266, 270, 296, 323, 333, 334, 335, 338, 341, 344, 367, 384, 404], "scalabl": [32, 404], "dr": [20, 91, 205, 404], "checklist": [31, 122, 248, 267], "case": [29, 35, 38, 45, 49, 50, 52, 56, 59, 64, 67, 69, 74, 75, 78, 88, 95, 100, 101, 109, 112, 113, 115, 117, 120, 121, 122, 139, 143, 228, 243, 244, 250, 251, 253, 254, 255, 257, 259, 261, 263, 265, 266, 269, 286, 287, 288, 289, 292, 300, 318, 338, 340, 341, 343, 344, 345, 346, 347, 349, 350, 351, 352, 353, 354, 355, 356, 382, 404], "studi": [69, 90, 213, 216, 221, 232, 233, 249, 251, 252, 261, 265, 267, 404], "goal": [35, 37, 69, 78, 90, 93, 95, 101, 102, 132, 139, 142, 146, 151, 153, 159, 161, 185, 288], "robust": [57, 73, 86, 87, 91, 94, 96, 100, 101, 110, 113, 125, 139, 144, 148, 151, 152, 155, 158, 166, 168, 171, 173, 175, 176, 177, 178, 179, 181, 182, 188, 192, 194, 199, 200, 203, 204, 207, 210, 220, 226, 227, 230, 232, 239, 243, 244, 248, 249, 250, 253, 255, 257, 263, 266, 267, 268, 269, 270, 287, 288, 289, 301, 309, 323, 329], "rest": [4, 36, 39, 49, 50, 53, 64, 109, 260, 343, 376], "graphql": [4, 343], "grpc": [], "version": [20, 25, 30, 37, 46, 53, 65, 75, 93, 105, 107, 109, 110, 112, 117, 118, 122, 123, 129, 134, 138, 142, 143, 144, 146, 148, 150, 153, 156, 160, 165, 166, 170, 172, 173, 179, 182, 184, 191, 192, 195, 199, 203, 204, 210, 212, 213, 214, 216, 219, 220, 221, 222, 223, 228, 232, 234, 235, 237, 238, 240, 242, 246, 249, 250, 251, 254, 256, 257, 261, 263, 264, 265, 271, 283, 284, 285, 288, 308, 318, 331, 332, 333, 334, 335, 339, 344, 346, 350, 351, 352, 358, 359, 367, 371, 375, 381, 382, 384, 385], "sql": [346, 351, 352, 353], "nosql": 341, "search": [25, 26, 28, 31, 47, 49, 50, 59, 67, 73, 74, 75, 83, 84, 99, 146, 178, 184, 226, 227, 233, 234, 285, 293, 318, 340, 341, 381, 384], "rate": [19, 21, 22, 29, 31, 35, 36, 37, 38, 39, 41, 45, 46, 50, 56, 57, 64, 65, 67, 88, 91, 92, 95, 96, 98, 104, 108, 110, 122, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 152, 156, 161, 163, 164, 165, 168, 170, 173, 177, 178, 179, 180, 182, 184, 186, 188, 190, 193, 196, 198, 201, 203, 210, 216, 223, 224, 225, 226, 229, 235, 241, 242, 247, 249, 250, 252, 253, 254, 255, 256, 257, 259, 260, 266, 267, 339, 340, 345, 347, 355, 369, 381, 383, 386, 389], "limit": [20, 26, 32, 49, 50, 70, 78, 88, 90, 106, 110, 134, 139, 140, 143, 145, 149, 150, 151, 153, 155, 160, 164, 172, 174, 175, 192, 194, 195, 197, 199, 204, 206, 207, 208, 209, 210, 213, 214, 215, 216, 217, 219, 224, 227, 228, 230, 231, 233, 234, 236, 238, 240, 241, 256, 266, 269, 312, 313, 314, 315, 316, 317, 333, 339, 345, 354, 358, 369, 370, 372, 374], "load": [21, 22, 94, 111, 119, 140, 172, 310, 333, 338, 339, 342, 343, 344, 345, 350, 353, 355, 368, 369, 371, 377, 385, 399], "balanc": [1, 33, 34, 46, 49, 57, 67, 77, 78, 81, 84, 91, 102, 103, 108, 110, 159, 209, 223, 230, 239, 249, 270, 339, 342, 343, 344, 369, 377, 385], "log": [6, 19, 21, 22, 26, 31, 32, 33, 34, 35, 36, 37, 39, 41, 45, 47, 49, 50, 51, 52, 53, 57, 59, 64, 65, 67, 69, 72, 73, 75, 77, 78, 84, 88, 90, 92, 96, 101, 104, 106, 107, 110, 112, 116, 118, 119, 120, 122, 124, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 246, 247, 248, 250, 251, 252, 254, 257, 258, 260, 264, 265, 266, 267, 269, 280, 323, 332, 333, 334, 335, 340, 341, 342, 343, 346, 348, 349, 350, 352, 358, 359, 374, 383, 384, 386, 389], "trace": [6, 28, 29, 30, 35, 36, 41, 50, 57, 113, 165, 185, 221, 340, 380, 381, 383, 386], "metric": [6, 19, 21, 22, 25, 27, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 99, 100, 104, 105, 106, 107, 108, 109, 110, 112, 125, 127, 129, 131, 132, 138, 142, 144, 146, 210, 245, 252, 257, 263, 265, 266, 285, 287, 289, 290, 291, 293, 294, 295, 303, 320, 321, 322, 324, 325, 340, 342, 345, 349, 350, 351, 368, 383, 386, 405], "fastapi": 1, "templat": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 65, 67, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 280, 338, 358, 371, 383, 389, 393, 394], "concept": [0, 10, 110, 118, 134, 220, 285, 330, 343, 346, 349, 350, 351, 352, 353, 356, 365, 366, 367, 369, 370, 372, 374, 375, 376, 377, 378, 379, 381, 387, 397, 404], "softwar": [249, 342], "cia": [], "triad": [], "control": [2, 4, 15, 26, 87, 90, 94, 98, 103, 104, 107, 109, 110, 111, 116, 119, 121, 122, 123, 129, 134, 138, 139, 141, 142, 143, 144, 145, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 183, 185, 187, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 205, 207, 209, 210, 212, 214, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 237, 240, 241, 242, 245, 250, 251, 252, 256, 259, 260, 261, 263, 265, 266, 325, 332, 333, 335, 338, 339, 340, 342, 344, 345, 346, 352, 353, 357, 359, 366, 367, 369, 370, 371, 372, 374, 375, 376, 377, 378, 379, 381, 382, 384], "appsec": [], "top": [10, 27, 29, 30, 31, 33, 34, 35, 38, 39, 46, 47, 53, 56, 59, 64, 66, 67, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 100, 104, 106, 107, 108, 112, 113, 117, 118, 122, 125, 135, 136, 146, 168, 169, 185, 189, 196, 204, 221, 228, 230, 232, 236, 241, 243, 244, 245, 247, 251, 253, 254, 255, 256, 257, 259, 260, 261, 265, 268, 284, 286, 291, 342, 352, 358, 381, 382, 384, 385], "10": [10, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 41, 47, 49, 50, 52, 57, 59, 64, 65, 67, 70, 72, 75, 77, 78, 81, 83, 84, 86, 87, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 103, 104, 107, 108, 109, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 129, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 228, 242, 244, 250, 253, 254, 255, 258, 263, 264, 265, 269, 270, 271, 280, 285, 288, 289, 291, 295, 296, 299, 300, 310, 311, 318, 319, 322, 323, 328, 329, 334, 340, 349, 357, 368, 374, 381, 386, 389, 393], "tl": [339, 369, 376, 377, 382], "dn": [335, 339, 342, 358, 359, 369, 377, 378], "firewal": [342, 357], "segment": [13, 49, 74, 78, 81, 112, 127, 136, 156, 206, 243, 259, 283, 285, 289, 295, 317], "op": [141, 259, 340, 343, 350], "secret": [331, 332, 333, 334, 335, 338, 349, 351, 353, 358, 365, 369, 370, 371, 374], "map": [20, 21, 22, 27, 30, 31, 32, 53, 64, 77, 78, 100, 104, 113, 115, 116, 117, 118, 127, 129, 130, 131, 132, 134, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 167, 168, 169, 172, 173, 175, 176, 177, 180, 183, 185, 187, 188, 190, 195, 196, 197, 199, 204, 208, 211, 212, 213, 214, 215, 217, 218, 219, 222, 228, 229, 230, 231, 232, 234, 235, 237, 238, 240, 252, 253, 266, 268, 285, 318, 331, 344, 356, 358, 359, 382], "collect": [33, 68, 85, 118, 134, 136, 139, 140, 141, 142, 143, 144, 145, 146, 232, 245, 246, 247, 263, 266, 271, 284, 285, 286, 295, 322, 340, 382, 386], "each": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 45, 47, 49, 51, 53, 56, 58, 59, 61, 64, 65, 67, 68, 69, 72, 73, 74, 75, 77, 78, 81, 82, 83, 84, 86, 89, 92, 94, 98, 100, 101, 103, 106, 107, 108, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 129, 131, 134, 136, 137, 138, 139, 140, 141, 144, 145, 146, 154, 159, 166, 167, 168, 177, 181, 185, 186, 189, 195, 199, 204, 205, 209, 210, 212, 221, 224, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 243, 244, 245, 246, 247, 248, 249, 250, 251, 255, 256, 257, 259, 260, 263, 264, 265, 266, 268, 270, 285, 286, 289, 292, 293, 295, 296, 300, 306, 318, 332, 334, 341, 355, 358, 372, 378, 381, 382, 393, 394], "contain": [2, 12, 28, 29, 38, 46, 47, 56, 57, 64, 65, 72, 77, 83, 84, 95, 98, 99, 102, 112, 113, 115, 119, 127, 142, 146, 151, 152, 158, 159, 161, 178, 190, 191, 203, 217, 222, 223, 228, 230, 232, 233, 235, 238, 245, 247, 249, 250, 252, 253, 255, 256, 257, 259, 263, 266, 267, 283, 286, 287, 288, 289, 292, 300, 318, 330, 332, 333, 334, 335, 349, 352, 365, 366, 367, 368, 370, 373, 374, 375, 376, 378], "intuit": [20, 37, 40, 42, 43, 44, 48, 49, 50, 52, 54, 55, 58, 59, 60, 61, 62, 63, 66, 69, 71, 74, 75, 76, 79, 80, 82, 87, 100, 108, 115, 117, 122, 127, 135, 138, 142, 143, 144, 145, 146, 228, 243, 245, 249, 250, 256, 259, 262, 266, 295, 296, 303, 308, 312, 316], "runnabl": [131, 132, 371], "often": [19, 20, 22, 25, 26, 28, 29, 30, 31, 34, 37, 38, 39, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 72, 73, 74, 75, 77, 78, 81, 83, 88, 91, 92, 93, 94, 96, 97, 98, 101, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 131, 132, 138, 139, 140, 141, 142, 143, 144, 145, 148, 150, 151, 152, 153, 154, 155, 156, 158, 159, 161, 162, 163, 165, 166, 167, 168, 169, 171, 172, 173, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 203, 205, 207, 208, 209, 210, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 289, 291, 300, 303, 309, 316, 318, 323, 327, 328, 332, 333, 334, 335, 339, 342, 344, 345, 347, 348, 350, 353, 356, 357, 358, 359, 369, 373, 378, 379, 381, 382, 383, 384, 385], "plotli": [19, 20, 21, 22, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 134, 135, 137, 139, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 275, 280, 281, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 389, 393, 394], "infer": [107, 112, 113, 115, 139, 148, 154, 160, 161, 165, 168, 169, 172, 173, 175, 179, 182, 183, 187, 188, 190, 195, 196, 200, 204, 205, 206, 210, 211, 213, 214, 215, 216, 219, 222, 226, 228, 229, 232, 233, 234, 237, 240, 248, 263, 340, 342, 343, 345, 347, 348, 349, 350, 351, 355, 357], "hypothesi": [67, 108, 228, 244, 246, 247, 251, 253, 254, 256, 257, 258, 259, 263, 268, 269, 270], "distribut": [7, 26, 31, 34, 35, 38, 39, 41, 49, 65, 73, 77, 78, 84, 87, 88, 89, 91, 92, 94, 95, 98, 99, 101, 107, 108, 113, 116, 121, 136, 139, 140, 142, 143, 144, 146, 243, 246, 248, 249, 251, 252, 253, 255, 257, 258, 259, 261, 264, 267, 297, 298, 305, 311, 333, 339, 341, 342, 344, 346, 351, 358, 381, 382], "bayesian": [103, 113, 115, 228, 243], "supervis": [27, 29, 30, 32, 70, 73, 74, 81, 84, 103, 126, 127, 128, 141, 306, 328], "unsupervis": [70, 72, 73, 74, 75, 77, 81], "dimension": [25, 28, 29, 30, 32, 52, 108, 109, 125, 132, 134, 142, 159, 185, 186, 197, 230, 237, 291, 325], "reduct": [25, 28, 31, 32, 39, 52, 73, 103, 119, 127, 131, 145, 152, 169, 180, 190, 224, 288, 308, 312, 314, 328], "cnn": [], "rnn": [], "transform": [19, 26, 29, 30, 31, 32, 36, 47, 59, 64, 97, 102, 106, 109, 116, 119, 122, 124, 131, 148, 149, 151, 152, 153, 154, 156, 157, 160, 163, 167, 168, 172, 173, 174, 175, 177, 179, 180, 183, 184, 187, 189, 190, 191, 193, 195, 197, 200, 202, 203, 204, 205, 207, 211, 213, 215, 216, 218, 219, 221, 222, 223, 227, 232, 233, 237, 240, 241, 244, 247, 248, 252, 255, 258, 259, 281, 283, 284, 285, 291, 295, 300, 301, 313, 314, 316, 317, 320, 322, 324, 325, 327, 328, 329, 346, 347, 348, 350, 353, 371, 381, 383, 385], "tabular": [32, 110, 129], "vision": 22, "classic": [21, 22, 26, 28, 32, 46, 47, 52, 70, 90, 100, 103, 104, 105, 106, 107, 108, 109, 110, 113, 122, 134, 136, 142, 143, 144, 150, 151, 152, 154, 161, 166, 169, 171, 172, 173, 179, 180, 185, 187, 190, 191, 194, 195, 197, 203, 204, 205, 206, 209, 211, 212, 213, 215, 218, 224, 227, 231, 236, 238, 240, 241, 243, 244, 245, 250, 252, 253, 254, 256, 259, 261, 269, 271, 289, 300, 303, 310, 312], "forecast": [38, 87, 92, 94, 97, 111, 114, 119, 122, 237, 281, 283, 284, 285, 296, 299, 311, 323, 327, 328], "space": [21, 22, 25, 27, 28, 29, 30, 31, 32, 37, 45, 50, 51, 52, 56, 69, 74, 102, 103, 106, 109, 112, 116, 117, 119, 120, 122, 124, 134, 137, 138, 141, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 185, 186, 187, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 248, 265, 284, 291, 295, 340, 357, 358, 359], "volatil": [112, 119, 122, 195, 259, 393, 395], "algorithm": [29, 32, 69, 73, 75, 77, 81, 83, 99, 109, 113, 134, 135, 137, 140, 141, 142, 144, 145, 150, 159, 162, 166, 168, 173, 175, 181, 185, 193, 195, 196, 199, 202, 203, 208, 209, 216, 217, 218, 226, 228, 230, 231, 233, 237, 284, 289, 295, 296, 311, 316], "from": [1, 26, 27, 32, 33, 37, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 58, 60, 61, 62, 63, 66, 68, 69, 70, 71, 72, 76, 79, 80, 81, 82, 104, 106, 108, 111, 114, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 129, 131, 132, 134, 135, 137, 140, 141, 142, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 248, 249, 253, 254, 255, 256, 258, 262, 263, 264, 265, 270, 271, 275, 281, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 323, 324, 325, 326, 328, 331, 332, 333, 334, 335, 337, 338, 339, 340, 345, 346, 347, 348, 350, 351, 353, 356, 357, 358, 359, 365, 369, 371, 373, 377, 381, 385, 389, 393, 394], "scratch": [27, 29, 37, 39, 41, 45, 50, 51, 52, 53, 69, 70, 72, 73, 78, 81, 95, 104, 106, 108, 111, 119, 126, 140, 141, 146, 155, 192, 204, 207, 222, 238, 244, 252, 253, 254, 255, 256, 258, 263, 267, 270, 358], "demo": [21, 22, 25, 30, 32, 41, 57, 81, 94, 98, 103, 104, 108, 111, 121, 122, 126, 128, 134, 148, 150, 151, 154, 159, 162, 163, 165, 167, 168, 172, 174, 176, 180, 183, 184, 185, 187, 188, 189, 191, 194, 195, 199, 201, 202, 204, 205, 206, 207, 208, 209, 210, 211, 212, 214, 215, 220, 221, 222, 224, 227, 228, 229, 234, 241, 260, 267, 287, 289, 301, 303, 306, 338, 340, 343, 344, 346, 349, 350, 351, 356], "you": [6, 19, 20, 21, 22, 25, 26, 30, 31, 32, 34, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 73, 74, 75, 77, 78, 81, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 103, 104, 106, 108, 109, 110, 112, 113, 114, 115, 116, 117, 122, 125, 127, 128, 129, 134, 135, 137, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 153, 154, 156, 158, 159, 160, 161, 164, 165, 166, 167, 170, 171, 172, 175, 176, 177, 178, 179, 185, 187, 189, 191, 192, 194, 195, 199, 202, 204, 206, 207, 210, 212, 216, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 250, 252, 253, 254, 258, 259, 262, 263, 264, 267, 269, 270, 271, 280, 281, 287, 288, 293, 294, 296, 301, 304, 306, 307, 308, 309, 310, 311, 323, 324, 339, 343, 345, 346, 349, 350, 351, 352, 353, 354, 356, 357, 366, 367, 369, 370, 372, 374, 375, 378, 379, 382, 383, 384, 385, 386], "want": [20, 25, 26, 29, 30, 31, 32, 37, 39, 47, 51, 56, 57, 59, 64, 65, 67, 74, 84, 86, 89, 91, 95, 102, 103, 105, 107, 108, 109, 110, 112, 113, 115, 125, 129, 134, 135, 140, 142, 143, 145, 148, 149, 150, 153, 154, 156, 158, 159, 160, 161, 164, 166, 169, 170, 171, 172, 173, 174, 176, 177, 182, 184, 186, 187, 190, 195, 196, 197, 199, 201, 202, 203, 206, 207, 211, 214, 215, 216, 217, 221, 222, 223, 225, 227, 233, 234, 237, 238, 239, 243, 245, 247, 248, 249, 251, 252, 253, 255, 257, 258, 263, 264, 265, 266, 269, 270, 271, 284, 285, 306, 309, 331, 332, 333, 334, 335, 339, 344, 345, 346, 349, 350, 351, 353, 355, 366, 371], "evalu": [30, 33, 34, 35, 36, 37, 38, 41, 42, 45, 46, 47, 51, 52, 53, 56, 57, 59, 64, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 87, 89, 90, 91, 92, 94, 96, 97, 98, 99, 100, 102, 107, 110, 113, 137, 140, 145, 148, 149, 150, 152, 154, 155, 156, 157, 159, 160, 163, 164, 165, 166, 170, 173, 174, 175, 177, 178, 179, 182, 183, 185, 189, 191, 192, 193, 195, 196, 197, 199, 200, 202, 203, 204, 205, 207, 208, 209, 210, 212, 215, 216, 219, 220, 222, 223, 224, 226, 227, 228, 230, 232, 233, 235, 238, 239, 240, 241, 242, 253, 256, 280, 281, 283, 303, 310, 340, 343, 350, 356, 383], "For": [19, 21, 22, 25, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 67, 69, 70, 73, 74, 75, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 118, 119, 120, 121, 122, 123, 125, 127, 129, 132, 134, 135, 136, 137, 138, 139, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 258, 259, 260, 261, 262, 264, 265, 266, 267, 269, 270, 285, 292, 293, 306, 308, 310, 318, 322, 323, 327, 328, 329, 338, 339, 343, 344, 345, 347, 357], "sktime": [130, 271, 275, 281, 290, 291, 294, 302, 304, 307, 309, 320, 321, 324, 325, 326, 327], "align": [20, 26, 27, 28, 29, 32, 35, 56, 59, 65, 67, 74, 77, 81, 87, 94, 114, 125, 130, 132, 135, 137, 148, 152, 163, 165, 166, 172, 173, 177, 179, 181, 184, 197, 198, 199, 200, 202, 205, 214, 225, 237, 241, 252, 255, 261, 265, 285, 287, 289, 290, 299, 305, 306, 310, 358, 359], "self": [20, 21, 22, 27, 28, 29, 30, 83, 105, 106, 108, 109, 110, 115, 120, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 161, 209, 222, 248, 331, 332, 333, 334, 342, 344], "cross": [19, 21, 22, 25, 27, 33, 34, 35, 39, 41, 45, 46, 49, 50, 51, 57, 65, 67, 87, 91, 92, 94, 98, 99, 100, 101, 104, 107, 116, 140, 155, 164, 166, 167, 176, 178, 182, 192, 197, 202, 206, 212, 222, 223, 228, 243, 253, 262, 285, 319, 333, 335, 340, 347, 350, 357, 371, 379, 383], "prerequisit": [37, 159, 185], "chart": [30, 94, 122, 242, 255, 285, 305, 331, 371, 384], "ar": [1, 5, 19, 20, 21, 22, 25, 26, 27, 28, 29, 31, 32, 34, 35, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 74, 75, 77, 78, 81, 83, 84, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 132, 134, 138, 139, 140, 141, 142, 143, 145, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 270, 271, 280, 284, 286, 287, 288, 292, 293, 300, 302, 304, 305, 307, 308, 317, 322, 326, 327, 328, 329, 331, 332, 333, 334, 335, 337, 338, 339, 342, 343, 346, 347, 348, 350, 352, 354, 355, 358, 359, 365, 369, 373, 375, 376, 378, 379, 382, 384, 385, 386], "embed": [19, 25, 30, 31, 32, 159, 292, 293, 345, 358], "where": [21, 22, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 41, 46, 49, 50, 52, 57, 59, 64, 65, 67, 69, 72, 73, 75, 77, 81, 83, 86, 87, 88, 89, 90, 91, 92, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 112, 114, 117, 118, 119, 122, 123, 127, 128, 129, 132, 134, 135, 138, 139, 140, 141, 142, 143, 144, 146, 148, 149, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198, 199, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 213, 214, 216, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 251, 252, 255, 256, 257, 259, 260, 261, 262, 263, 265, 266, 267, 270, 285, 287, 295, 300, 303, 322, 331, 333, 334, 335, 339, 340, 341, 342, 343, 344, 347, 349, 351, 353, 357, 359, 384, 389], "make": [20, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 41, 46, 51, 52, 64, 65, 67, 73, 74, 77, 78, 81, 83, 87, 88, 90, 92, 93, 94, 97, 98, 99, 101, 102, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 118, 119, 121, 122, 127, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, 157, 158, 160, 161, 165, 168, 169, 172, 173, 174, 176, 177, 178, 179, 181, 183, 185, 186, 187, 188, 190, 191, 192, 193, 195, 197, 198, 199, 201, 202, 204, 205, 206, 207, 208, 209, 210, 211, 212, 217, 218, 219, 220, 226, 229, 232, 234, 237, 238, 239, 241, 243, 244, 246, 247, 249, 250, 252, 253, 255, 257, 259, 260, 263, 264, 269, 280, 287, 288, 291, 333, 334, 335, 338, 348, 349, 355, 370, 379, 381, 383], "behavior": [46, 49, 51, 52, 53, 73, 77, 86, 87, 89, 90, 91, 92, 95, 97, 98, 99, 102, 103, 107, 110, 113, 116, 123, 127, 138, 139, 142, 143, 149, 150, 151, 153, 157, 158, 161, 163, 164, 165, 166, 167, 168, 169, 170, 172, 178, 182, 184, 188, 190, 192, 195, 196, 198, 199, 200, 202, 203, 204, 205, 206, 208, 209, 214, 215, 219, 220, 221, 223, 234, 237, 240, 241, 242, 254, 258, 269, 284, 322, 329, 332, 338, 339, 340, 366, 379], "visibl": [31, 78, 94, 107, 112, 135, 137, 179, 243, 250, 258, 269, 331, 340, 355], "cover": [17, 18, 23, 24, 29, 45, 78, 87, 117, 133, 143, 147, 178, 181, 193, 202, 206, 208, 230, 231, 239, 244, 267, 268, 271, 272, 273, 274, 276, 277, 278, 279, 282, 299, 310], "neural": [20, 56, 96, 106, 135, 139, 181, 223], "mlp": [21, 134, 138, 139, 140, 141, 144, 145, 146], "regular": [28, 33, 34, 36, 45, 46, 52, 64, 65, 69, 78, 94, 98, 104, 106, 109, 110, 115, 135, 137, 140, 141, 150, 151, 152, 153, 158, 159, 166, 169, 173, 176, 177, 180, 184, 190, 191, 197, 199, 202, 203, 208, 210, 213, 226, 228, 231, 235, 236, 246, 302], "lstm": [], "gru": [], "tempor": [139, 271, 284, 299, 310], "resnet": [], "modern": [29, 107, 181, 218, 227, 231, 235, 262, 292, 346, 375], "explain": [0, 10, 19, 21, 22, 25, 26, 30, 31, 33, 53, 70, 77, 84, 85, 86, 87, 103, 106, 108, 109, 110, 111, 112, 113, 114, 116, 118, 121, 122, 125, 127, 135, 137, 140, 161, 166, 169, 188, 191, 195, 206, 210, 217, 228, 231, 241, 242, 243, 244, 248, 250, 255, 256, 258, 259, 262, 263, 264, 265, 280, 297, 298, 330, 335, 345, 387, 394, 397, 404], "math": [20, 22, 29, 30, 34, 45, 52, 73, 86, 87, 91, 94, 98, 99, 103, 107, 110, 114, 134, 135, 138, 139, 141, 142, 143, 144, 146, 157, 158, 161, 162, 163, 171, 174, 183, 191, 194, 195, 198, 206, 209, 211, 212, 213, 218, 224, 225, 226, 230, 231, 233, 236, 239, 240, 241, 244, 245, 246, 247, 248, 250, 252, 255, 260, 261, 266, 267, 268, 269, 270, 368], "pytorch": [135, 137], "implement": [19, 20, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 39, 41, 45, 50, 52, 53, 65, 69, 70, 72, 78, 81, 88, 90, 95, 96, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 117, 118, 120, 121, 123, 124, 125, 126, 127, 128, 129, 131, 132, 135, 136, 137, 141, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 185, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 201, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 249, 250, 252, 253, 254, 255, 256, 260, 261, 262, 263, 265, 271, 284, 303, 305, 331, 333, 359, 369], "visual": [19, 25, 29, 32, 34, 35, 37, 38, 39, 45, 47, 49, 50, 51, 52, 53, 57, 59, 65, 67, 69, 72, 73, 75, 77, 78, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 117, 118, 119, 121, 122, 123, 125, 127, 129, 136, 137, 138, 141, 142, 143, 144, 145, 146, 228, 242, 243, 244, 246, 252, 253, 256, 258, 259, 260, 261, 263, 264, 266, 267, 292, 296, 310, 312, 313, 314, 315, 316, 318, 328, 340, 356, 381, 383, 384, 385, 394], "an": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 38, 39, 45, 47, 49, 51, 53, 56, 57, 59, 64, 65, 67, 70, 72, 74, 75, 77, 81, 83, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 116, 117, 119, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 283, 288, 289, 293, 300, 322, 331, 332, 333, 334, 335, 339, 342, 343, 345, 346, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 369, 373, 382, 383, 384, 386, 393], "usual": [19, 21, 22, 25, 26, 28, 31, 32, 35, 36, 41, 45, 46, 47, 49, 50, 53, 59, 65, 69, 72, 73, 74, 78, 92, 98, 99, 101, 107, 109, 110, 112, 113, 117, 134, 137, 141, 144, 146, 148, 150, 151, 155, 156, 159, 160, 163, 169, 171, 173, 175, 177, 179, 180, 184, 186, 188, 192, 193, 196, 197, 199, 200, 204, 205, 207, 209, 213, 214, 215, 219, 220, 222, 228, 229, 230, 232, 233, 234, 236, 237, 240, 241, 243, 245, 247, 249, 250, 251, 255, 260, 261, 263, 265, 267, 268, 269, 296, 328, 333, 335, 339, 357, 358, 359, 374, 376, 382, 383, 386], "multi": [19, 39, 53, 92, 94, 101, 102, 107, 111, 112, 114, 116, 120, 123, 125, 131, 132, 138, 143, 189, 194, 200, 280, 306, 308, 331, 334, 341, 344, 345, 346, 351, 357, 358, 372, 408], "perceptron": 19, "stack": [19, 20, 27, 77, 100, 112, 115, 117, 118, 123, 138, 140, 146, 160, 185, 243, 261, 301, 338, 342, 348, 358, 359, 384, 385, 386], "activ": [19, 20, 21, 22, 26, 27, 31, 109, 135, 138, 139, 141, 142, 144, 145, 146, 153, 223, 269, 344], "relu": [19, 21, 22, 138, 139, 141, 144, 145], "gelu": 19, "great": [19, 25, 29, 31, 32, 34, 35, 46, 49, 53, 57, 67, 73, 89, 98, 99, 105, 106, 107, 108, 110, 112, 151, 177, 256, 263, 268, 269, 341, 358, 382], "tool": [19, 31, 46, 47, 115, 116, 148, 161, 179, 188, 196, 214, 237, 247, 249, 251, 253, 266, 267, 269, 304, 307, 315, 331, 333, 334, 335, 344, 346, 348, 350, 351, 352, 353, 354, 358, 359, 371, 374], "becaus": [19, 21, 26, 29, 35, 37, 38, 41, 46, 49, 52, 53, 57, 64, 67, 70, 72, 73, 75, 78, 81, 86, 89, 90, 91, 92, 93, 95, 96, 97, 99, 100, 101, 102, 105, 106, 108, 111, 113, 114, 117, 119, 123, 136, 137, 144, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 221, 222, 223, 224, 225, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 248, 249, 251, 252, 253, 254, 255, 256, 257, 260, 261, 262, 264, 265, 266, 267, 268, 269, 296, 311, 358], "can": [2, 6, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 123, 124, 125, 127, 129, 131, 132, 134, 135, 138, 139, 140, 141, 142, 143, 144, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 249, 251, 252, 254, 256, 257, 258, 259, 260, 263, 264, 265, 266, 267, 269, 270, 271, 285, 286, 287, 288, 292, 293, 294, 295, 296, 301, 302, 308, 316, 318, 319, 320, 322, 323, 324, 325, 327, 329, 331, 332, 334, 335, 338, 339, 340, 341, 343, 344, 346, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 365, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 378, 379, 381, 382, 383, 384, 385, 386, 389], "understand": [19, 21, 22, 26, 29, 30, 38, 47, 56, 59, 67, 70, 73, 74, 78, 81, 88, 89, 91, 92, 94, 96, 98, 100, 103, 104, 105, 106, 107, 108, 110, 112, 114, 115, 117, 118, 123, 137, 138, 141, 143, 144, 145, 146, 148, 153, 155, 158, 159, 160, 161, 164, 165, 166, 167, 170, 171, 172, 175, 176, 177, 178, 179, 185, 191, 192, 197, 199, 203, 204, 206, 207, 210, 214, 216, 221, 222, 224, 228, 229, 232, 233, 234, 237, 238, 240, 243, 244, 246, 248, 250, 252, 254, 257, 258, 262, 264, 266, 267, 269, 285, 294, 331, 332, 333, 334, 335, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 371, 381, 382, 383, 385, 386], "just": [19, 27, 34, 36, 38, 45, 46, 47, 52, 56, 59, 73, 88, 90, 92, 93, 95, 97, 102, 103, 104, 105, 107, 108, 109, 112, 121, 142, 146, 148, 155, 161, 169, 186, 193, 211, 217, 220, 221, 224, 228, 233, 236, 242, 243, 245, 251, 252, 254, 256, 257, 261, 262, 263, 264, 265, 268, 271, 318, 356, 369, 383], "matrix": [19, 21, 22, 25, 26, 28, 33, 35, 37, 42, 43, 56, 58, 64, 65, 67, 68, 70, 72, 74, 80, 83, 84, 95, 103, 106, 107, 109, 110, 113, 118, 122, 136, 146, 186, 189, 206, 230, 249, 253, 287, 332], "multipl": [19, 20, 22, 25, 26, 29, 31, 32, 39, 45, 51, 53, 59, 65, 72, 73, 77, 83, 84, 88, 91, 92, 93, 94, 95, 96, 98, 99, 101, 102, 103, 113, 116, 117, 118, 119, 123, 125, 134, 142, 143, 146, 153, 154, 155, 160, 161, 162, 166, 182, 183, 184, 186, 191, 192, 194, 198, 199, 203, 208, 209, 210, 213, 221, 222, 224, 230, 237, 242, 243, 246, 251, 252, 253, 256, 257, 259, 265, 266, 267, 268, 269, 271, 296, 301, 334, 341, 347, 353, 354, 355, 356, 357, 359, 369, 379, 384, 385], "train": [19, 20, 30, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 69, 72, 75, 77, 78, 81, 83, 84, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 112, 116, 119, 120, 122, 124, 125, 127, 132, 137, 138, 139, 145, 271, 280, 281, 287, 289, 290, 291, 292, 293, 294, 297, 298, 299, 301, 302, 306, 308, 309, 310, 320, 321, 323, 324, 325, 328, 340, 342, 344, 346, 350, 352, 353, 356, 357], "gradient": [19, 20, 28, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 65, 67, 69, 70, 73, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 92, 95, 99, 122, 136, 139, 140, 141, 144, 145, 151, 159, 306], "descent": [19, 28, 34, 36, 38, 39, 41, 46, 49, 50, 51, 52, 56, 57, 59, 65, 67, 69, 75, 78, 83, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97, 98, 101, 102], "loss": [19, 20, 21, 22, 32, 33, 35, 36, 37, 39, 41, 47, 49, 50, 52, 55, 57, 64, 65, 69, 73, 75, 78, 81, 83, 85, 86, 89, 91, 93, 96, 97, 98, 99, 100, 101, 104, 109, 110, 114, 135, 136, 137, 138, 140, 142, 148, 153, 157, 172, 175, 176, 177, 194, 196, 229, 239, 280], "via": [19, 20, 21, 22, 25, 26, 29, 30, 31, 32, 39, 46, 49, 50, 56, 57, 59, 64, 65, 67, 69, 70, 73, 78, 86, 88, 89, 90, 93, 96, 97, 98, 99, 104, 109, 112, 113, 114, 116, 117, 118, 119, 120, 122, 124, 125, 134, 136, 138, 139, 142, 143, 144, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 165, 167, 168, 169, 172, 174, 175, 177, 178, 179, 181, 182, 183, 184, 185, 187, 189, 190, 191, 192, 194, 195, 196, 197, 198, 200, 201, 202, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 219, 220, 221, 222, 224, 225, 226, 228, 229, 230, 232, 233, 236, 237, 239, 241, 242, 245, 246, 247, 251, 252, 254, 256, 257, 258, 259, 260, 262, 264, 265, 266, 267, 269, 270, 284, 285, 288, 295, 306, 308, 322, 332, 333, 335, 338, 339, 340, 343, 344, 346, 347, 348, 350, 353, 355, 356, 358, 359, 365, 372, 376, 378, 383, 386], "backprop": [19, 20, 21, 22, 135, 136, 138, 141, 143], "On": [19, 22, 25, 29, 30, 37, 38, 39, 45, 46, 57, 86, 87, 91, 92, 98, 103, 108, 109, 119, 129, 134, 150, 168, 184, 196, 222, 247, 251, 252, 341, 346, 358, 359, 363], "mani": [4, 19, 20, 25, 26, 29, 31, 32, 34, 35, 36, 37, 47, 49, 50, 51, 52, 59, 65, 67, 69, 70, 73, 74, 75, 77, 78, 81, 83, 84, 88, 90, 91, 92, 93, 96, 98, 99, 100, 103, 104, 105, 108, 110, 111, 113, 117, 119, 121, 122, 125, 131, 134, 138, 139, 143, 144, 148, 150, 152, 154, 155, 160, 161, 162, 163, 165, 166, 167, 168, 170, 173, 174, 175, 176, 179, 183, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 200, 201, 203, 205, 207, 208, 209, 210, 213, 214, 215, 216, 220, 221, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 280, 291, 294, 295, 303, 305, 306, 309, 318, 328, 331, 332, 334, 335, 340, 349, 354, 356, 359, 371, 373, 376, 382, 383, 385], "world": [19, 107, 108, 110, 228, 238, 244, 263, 299, 339, 342, 348], "problem": [19, 22, 26, 28, 29, 30, 32, 34, 36, 37, 38, 39, 41, 46, 47, 49, 50, 51, 53, 56, 65, 73, 77, 78, 86, 87, 89, 90, 94, 95, 97, 101, 104, 107, 109, 112, 113, 135, 143, 146, 158, 173, 178, 179, 185, 193, 197, 203, 206, 211, 222, 228, 230, 238, 239, 240, 242, 259, 267, 280, 306, 358, 381, 393], "tree": [19, 25, 31, 105, 127, 142, 230, 289, 293, 294, 318, 321, 327, 328], "base": [1, 2, 5, 19, 31, 32, 33, 34, 35, 36, 38, 39, 41, 45, 47, 50, 51, 52, 54, 56, 57, 59, 65, 67, 69, 70, 72, 73, 74, 77, 78, 81, 84, 86, 87, 89, 91, 95, 96, 101, 102, 103, 105, 108, 109, 112, 114, 115, 118, 122, 123, 124, 125, 127, 129, 136, 138, 140, 144, 148, 151, 154, 155, 156, 160, 163, 164, 165, 167, 172, 174, 175, 178, 181, 183, 184, 187, 188, 193, 196, 198, 200, 204, 207, 209, 211, 212, 213, 214, 217, 218, 222, 223, 226, 227, 228, 229, 232, 233, 234, 235, 237, 239, 241, 242, 243, 245, 247, 248, 250, 252, 253, 254, 255, 257, 258, 260, 262, 264, 265, 267, 268, 270, 280, 284, 285, 288, 293, 294, 295, 300, 301, 308, 313, 314, 316, 317, 319, 322, 323, 327, 328, 331, 333, 335, 340, 341, 348, 351, 352, 355, 358, 368, 382, 383, 384, 386], "xgboost": 19, "lightgbm": 19, "catboost": 19, "strongest": 19, "tend": [19, 26, 27, 32, 37, 52, 53, 65, 69, 70, 72, 77, 92, 93, 98, 105, 107, 108, 110, 111, 112, 114, 144, 148, 150, 161, 193, 194, 199, 208, 224, 226, 234, 243, 247, 252, 255, 257, 259, 260, 262, 263, 265, 268, 270], "shine": [19, 29, 108, 245], "when": [19, 20, 22, 25, 26, 27, 28, 29, 31, 41, 45, 47, 51, 52, 53, 56, 78, 83, 103, 104, 108, 110, 111, 113, 115, 119, 120, 123, 124, 134, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 248, 250, 252, 257, 259, 261, 262, 263, 264, 271, 280, 296, 302, 303, 310, 318, 322, 323, 327, 331, 332, 333, 334, 335, 338, 339, 340, 341, 342, 344, 345, 346, 347, 349, 350, 351, 354, 357, 367, 368, 370, 371, 374, 378, 379, 381, 384, 385, 386], "have": [19, 22, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 41, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 111, 112, 114, 115, 118, 119, 122, 123, 125, 127, 129, 131, 132, 138, 139, 140, 145, 148, 149, 151, 153, 154, 155, 157, 158, 160, 162, 163, 166, 167, 170, 171, 172, 173, 174, 175, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 199, 200, 201, 204, 205, 206, 207, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 227, 228, 230, 232, 233, 234, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 270, 271, 280, 303, 304, 306, 307, 328, 332, 334, 345, 354, 375, 389], "lot": [19, 32, 36, 53, 70, 78, 81, 92, 96, 99, 102, 104, 107, 109, 150, 151, 211, 225, 234, 244, 250, 258, 260, 262, 265, 266, 382], "categor": [19, 56, 72, 134, 136, 140, 142, 143, 159, 223, 227, 228, 238, 243, 247, 251, 257, 261, 322], "featur": [19, 20, 21, 22, 25, 26, 29, 30, 31, 32, 36, 37, 38, 46, 50, 52, 53, 56, 65, 69, 74, 78, 83, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 100, 101, 102, 103, 105, 106, 112, 115, 116, 117, 122, 125, 127, 128, 130, 153, 168, 174, 189, 191, 193, 194, 196, 197, 202, 207, 210, 212, 213, 219, 220, 223, 228, 236, 242, 254, 256, 262, 284, 286, 289, 291, 292, 293, 294, 295, 301, 310, 313, 314, 316, 320, 321, 324, 325, 326, 334, 341, 343, 345, 346, 347, 350, 351, 352, 353, 355, 369, 383], "need": [4, 5, 19, 22, 25, 28, 29, 30, 32, 34, 35, 36, 37, 39, 45, 46, 49, 52, 57, 64, 65, 72, 73, 74, 77, 78, 81, 83, 86, 88, 94, 100, 101, 103, 105, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 138, 146, 148, 149, 151, 153, 155, 157, 158, 162, 164, 170, 171, 173, 175, 176, 178, 179, 180, 184, 185, 186, 187, 188, 191, 192, 193, 195, 198, 199, 202, 204, 206, 207, 208, 209, 212, 213, 215, 218, 220, 221, 222, 224, 226, 228, 230, 231, 232, 233, 235, 238, 239, 240, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, 258, 259, 262, 263, 267, 268, 269, 271, 288, 296, 300, 323, 331, 332, 333, 334, 335, 339, 341, 342, 349, 350, 351, 354, 355, 356, 357, 359, 365, 368, 369, 371, 373, 378, 381, 382, 385], "combin": [19, 26, 28, 36, 39, 49, 50, 51, 72, 84, 89, 90, 103, 107, 108, 111, 112, 115, 116, 122, 135, 139, 151, 157, 159, 160, 165, 171, 174, 187, 192, 193, 209, 232, 246, 247, 248, 251, 254, 256, 258, 264, 288, 301, 309, 312, 315, 317, 322, 323, 328, 329, 372, 384], "other": [19, 25, 30, 32, 34, 37, 49, 51, 72, 74, 75, 77, 78, 83, 90, 95, 107, 114, 118, 122, 123, 141, 208, 228, 251, 253, 254, 255, 257, 268, 270, 319, 329, 331, 338, 346, 349, 350, 355, 356, 357, 358, 359], "modal": [19, 114, 194, 200], "By": [19, 21, 22, 25, 30, 31, 32, 46, 65, 72, 77, 78, 88, 92, 100, 103, 107, 108, 109, 110, 122, 134, 135, 137, 138, 140, 143, 150, 154, 156, 166, 177, 187, 193, 197, 202, 206, 210, 225, 226, 228, 230, 231, 232, 233, 234, 236, 239, 242, 243, 247, 248, 253, 255, 259, 263, 264, 265, 266, 267, 270], "should": [1, 19, 21, 22, 25, 28, 30, 31, 32, 34, 36, 38, 45, 46, 56, 59, 65, 69, 70, 75, 77, 78, 83, 87, 88, 92, 96, 97, 100, 102, 103, 105, 107, 108, 109, 110, 112, 113, 114, 116, 118, 122, 125, 134, 135, 137, 138, 139, 140, 141, 142, 143, 145, 146, 149, 150, 153, 154, 156, 160, 161, 164, 168, 169, 171, 173, 175, 177, 181, 182, 183, 184, 186, 187, 189, 190, 193, 197, 198, 201, 202, 204, 206, 208, 210, 214, 216, 220, 221, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 238, 239, 240, 243, 244, 245, 247, 248, 250, 253, 254, 256, 258, 259, 262, 263, 264, 266, 267, 268, 270, 271, 299, 305, 354, 368, 376, 384], "abl": [19, 21, 22, 25, 30, 31, 32, 46, 65, 72, 77, 88, 92, 100, 103, 107, 108, 109, 110, 122, 134, 135, 137, 138, 140, 143, 150, 154, 177, 187, 206, 210, 225, 226, 228, 230, 231, 232, 233, 236, 239, 242, 243, 247, 248, 253, 256, 259, 263, 264, 266, 267, 270, 358, 376], "how": [4, 19, 20, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 39, 45, 47, 49, 50, 51, 52, 56, 57, 59, 64, 65, 67, 70, 72, 73, 75, 78, 81, 83, 87, 89, 90, 91, 92, 94, 96, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 111, 117, 118, 119, 121, 123, 125, 127, 131, 134, 135, 138, 139, 140, 143, 144, 145, 146, 151, 152, 153, 155, 157, 158, 159, 160, 162, 163, 165, 168, 169, 170, 171, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 208, 209, 210, 211, 213, 214, 215, 216, 217, 218, 219, 221, 222, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 248, 255, 258, 259, 260, 263, 264, 266, 268, 269, 271, 285, 295, 296, 301, 306, 308, 310, 318, 322, 328, 334, 335, 339, 342, 343, 344, 351, 357], "turn": [19, 25, 29, 31, 34, 35, 39, 45, 49, 56, 65, 67, 73, 75, 81, 92, 104, 107, 108, 125, 127, 129, 131, 141, 145, 150, 154, 171, 174, 183, 219, 221, 248, 258, 259, 265, 267, 291, 324, 328, 382, 385], "predict": [19, 20, 22, 31, 33, 34, 35, 36, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 84, 86, 87, 88, 89, 90, 91, 92, 93, 95, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 114, 115, 116, 119, 121, 125, 127, 129, 131, 132, 134, 135, 136, 159, 165, 170, 183, 190, 209, 210, 224, 226, 228, 234, 236, 237, 239, 271, 280, 281, 284, 285, 287, 288, 289, 290, 291, 293, 294, 295, 297, 298, 301, 302, 303, 304, 306, 307, 308, 309, 319, 320, 321, 322, 323, 324, 325, 341, 351, 378], "mini": [19, 35, 52, 95, 139, 143, 144, 145, 209], "batch": [19, 20, 21, 22, 34, 35, 52, 65, 95, 98, 108, 114, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 156, 170, 214, 224, 226, 259, 342, 343, 344, 346, 347, 348, 350, 355, 356, 366, 370, 386], "sgd": [19, 21, 22, 52, 64, 139, 141, 143], "curv": [19, 21, 22, 25, 27, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 45, 47, 49, 52, 53, 56, 57, 59, 78, 87, 88, 89, 94, 95, 97, 98, 101, 102, 105, 109, 110, 134, 135, 136, 137, 138, 139, 140, 141, 145, 146, 153, 157, 186, 191, 192, 193, 195, 196, 203, 206, 219, 227, 232, 235, 248, 250, 256, 258, 261, 267, 391], "build": [19, 20, 21, 22, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 47, 49, 51, 52, 53, 56, 57, 59, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 83, 84, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 106, 107, 109, 110, 111, 112, 115, 116, 117, 118, 119, 120, 123, 125, 127, 131, 132, 134, 136, 141, 143, 145, 148, 151, 162, 165, 171, 172, 174, 175, 176, 178, 179, 185, 186, 188, 189, 194, 198, 202, 203, 207, 208, 212, 214, 217, 219, 221, 225, 229, 237, 241, 242, 243, 244, 245, 246, 247, 249, 250, 252, 254, 255, 259, 260, 262, 265, 266, 267, 268, 269, 270, 271, 285, 289, 296, 303, 305, 306, 311, 313, 315, 328, 329, 331, 332, 333, 334, 335, 336, 340, 342, 346, 347, 350, 357, 358, 359, 371, 382, 383, 384], "result": [19, 21, 25, 32, 36, 39, 46, 47, 49, 52, 53, 59, 70, 72, 73, 78, 81, 83, 84, 86, 87, 89, 94, 101, 103, 112, 116, 120, 122, 124, 143, 150, 153, 154, 161, 177, 181, 186, 191, 204, 218, 220, 221, 222, 238, 239, 245, 251, 255, 258, 264, 267, 268, 271, 333, 335, 345, 356, 389], "diagnos": [19, 27, 83, 107, 112, 114, 144, 194, 242, 247, 381], "common": [19, 22, 25, 26, 27, 28, 29, 31, 32, 35, 37, 38, 40, 41, 42, 43, 44, 45, 48, 50, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 88, 89, 96, 99, 100, 103, 105, 106, 107, 109, 110, 113, 114, 115, 116, 117, 118, 122, 123, 125, 134, 138, 139, 140, 141, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 165, 167, 168, 169, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 200, 201, 204, 205, 206, 207, 208, 209, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 227, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 244, 245, 246, 248, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 267, 268, 270, 271, 280, 284, 286, 290, 295, 296, 299, 303, 327, 329, 331, 332, 333, 334, 335, 338, 339, 341, 342, 343, 344, 345, 346, 348, 350, 351, 352, 353, 354, 356, 357, 358, 372, 382, 383], "pitfal": [19, 35, 40, 42, 43, 44, 45, 48, 54, 55, 58, 60, 61, 62, 63, 64, 66, 69, 71, 75, 76, 79, 80, 82, 88, 117, 228], "overfit": [19, 22, 49, 100, 107, 110, 138, 140, 327], "lr": [19, 20, 21, 22, 34, 35, 36, 37, 38, 41, 45, 46, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 75, 78, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 165, 170, 172, 176, 184, 202, 203, 208, 222, 229, 233], "x": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 280, 281, 284, 285, 286, 287, 288, 289, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 316, 317, 318, 319, 322, 323, 326, 327, 328, 329, 349, 382, 389, 393, 394], "mathbb": [19, 26, 29, 30, 31, 32, 35, 36, 37, 38, 39, 41, 45, 49, 50, 52, 56, 57, 59, 64, 65, 67, 69, 70, 73, 74, 75, 77, 78, 81, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 117, 118, 121, 122, 123, 125, 129, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 244, 245, 249, 251, 254, 258, 268, 284, 285, 292, 295, 296, 303, 393], "r": [19, 20, 21, 22, 25, 26, 27, 29, 30, 31, 32, 35, 36, 37, 38, 39, 46, 47, 49, 50, 52, 53, 56, 57, 64, 65, 69, 70, 72, 73, 74, 75, 77, 83, 84, 86, 87, 88, 90, 91, 92, 93, 95, 96, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 113, 118, 121, 122, 125, 127, 129, 131, 132, 134, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 183, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 227, 228, 230, 232, 233, 234, 235, 236, 237, 238, 240, 244, 246, 248, 249, 251, 252, 254, 255, 256, 258, 260, 261, 264, 265, 267, 270, 284, 285, 292, 295, 296, 316, 317, 322, 338, 389, 393], "n": [7, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 135, 136, 137, 139, 140, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 232, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 263, 264, 265, 266, 267, 268, 269, 270, 280, 286, 287, 289, 292, 295, 299, 300, 301, 303, 304, 305, 306, 307, 308, 316, 319, 323, 327, 328, 329, 355, 367, 368, 372, 383, 389, 394], "d": [19, 20, 25, 27, 28, 29, 30, 31, 32, 35, 37, 38, 39, 45, 46, 49, 57, 59, 64, 67, 69, 70, 74, 75, 77, 78, 81, 83, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 114, 115, 117, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 136, 137, 138, 139, 141, 144, 145, 150, 152, 155, 156, 157, 158, 159, 161, 162, 163, 165, 170, 172, 174, 175, 176, 177, 178, 180, 181, 182, 184, 185, 186, 187, 188, 190, 191, 192, 193, 195, 196, 198, 199, 200, 203, 204, 206, 208, 209, 210, 211, 213, 216, 217, 218, 219, 221, 222, 224, 225, 228, 229, 231, 232, 233, 237, 240, 242, 245, 246, 251, 252, 253, 254, 255, 258, 259, 260, 261, 262, 263, 265, 266, 267, 268, 269, 270, 271, 285, 292, 293, 295, 296, 297, 298, 316, 340, 358, 359, 389], "row": [19, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 56, 57, 59, 64, 67, 69, 70, 72, 74, 75, 77, 78, 81, 84, 86, 87, 88, 90, 92, 95, 96, 97, 98, 100, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 131, 132, 134, 135, 137, 143, 144, 146, 149, 151, 155, 159, 163, 164, 167, 168, 171, 172, 175, 176, 177, 178, 179, 181, 182, 186, 189, 191, 192, 200, 204, 207, 210, 213, 216, 221, 222, 224, 226, 227, 228, 230, 231, 232, 233, 237, 241, 244, 245, 246, 247, 248, 251, 253, 254, 255, 256, 257, 258, 259, 261, 262, 263, 264, 265, 267, 289, 295, 296, 308, 311, 312, 313, 314, 315, 316, 317, 323, 328, 341, 353], "sampl": [19, 20, 21, 22, 26, 27, 28, 30, 31, 32, 33, 35, 36, 37, 38, 39, 41, 45, 47, 51, 52, 53, 56, 57, 58, 64, 65, 68, 69, 70, 72, 73, 75, 78, 81, 82, 84, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 110, 112, 113, 114, 116, 117, 119, 122, 125, 127, 129, 132, 134, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 228, 242, 243, 244, 246, 248, 251, 252, 254, 257, 258, 259, 265, 268, 270, 289, 318, 319, 340, 381, 385], "label": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 38, 39, 45, 46, 47, 49, 52, 53, 56, 64, 65, 67, 68, 72, 74, 77, 81, 83, 87, 90, 91, 92, 93, 96, 97, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 139, 140, 142, 148, 151, 152, 157, 159, 161, 162, 163, 167, 170, 181, 183, 184, 186, 193, 194, 195, 197, 202, 203, 211, 214, 216, 218, 219, 220, 221, 222, 223, 224, 227, 228, 229, 230, 235, 238, 242, 243, 244, 249, 250, 251, 252, 253, 254, 255, 256, 257, 260, 263, 265, 266, 269, 270, 284, 285, 287, 295, 316, 317, 322, 333, 340, 346, 359, 367, 371, 372, 374, 375, 377, 378, 381, 386, 394], "y": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 275, 280, 281, 284, 285, 286, 287, 288, 289, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 315, 316, 317, 318, 319, 322, 323, 326, 327, 328, 329, 382, 389, 393, 394], "0": [19, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 59, 64, 65, 69, 70, 72, 73, 74, 75, 78, 81, 83, 84, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 198, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 254, 255, 256, 257, 258, 259, 260, 263, 264, 265, 266, 267, 268, 269, 270, 271, 280, 284, 285, 286, 287, 288, 289, 292, 293, 295, 296, 297, 298, 299, 300, 301, 303, 305, 306, 308, 310, 312, 313, 314, 315, 316, 317, 318, 319, 322, 323, 327, 328, 329, 334, 335, 338, 340, 342, 343, 345, 346, 348, 351, 353, 355, 356, 357, 358, 359, 366, 367, 370, 374, 375, 378, 383, 386, 389, 393, 394], "first": [19, 20, 21, 22, 25, 29, 30, 31, 32, 35, 38, 39, 41, 47, 51, 59, 74, 87, 89, 91, 94, 97, 107, 108, 109, 112, 115, 136, 138, 143, 144, 146, 150, 151, 152, 153, 155, 161, 162, 165, 166, 171, 177, 178, 179, 180, 182, 188, 192, 193, 194, 195, 199, 202, 203, 205, 207, 209, 214, 217, 218, 222, 223, 224, 225, 228, 231, 234, 235, 237, 238, 239, 242, 245, 248, 256, 260, 265, 268, 300, 303, 306, 315, 323, 327, 328, 332, 334, 345, 356, 359], "z_1": [19, 155, 186, 194, 200, 205, 209], "xw_1": 19, "b_1": [19, 90, 96, 97, 98, 99, 123], "a_1": [19, 99, 117, 123], "mathrm": [19, 22, 26, 30, 31, 34, 35, 36, 38, 45, 47, 49, 52, 57, 59, 64, 65, 69, 70, 73, 74, 75, 81, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 107, 109, 112, 113, 118, 119, 125, 132, 134, 135, 140, 141, 142, 143, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 249, 252, 254, 258, 261, 263, 265, 267, 268, 270, 271, 288, 389], "output": [19, 20, 21, 22, 27, 34, 35, 37, 39, 41, 46, 47, 49, 50, 53, 56, 67, 70, 72, 84, 87, 90, 92, 93, 94, 96, 97, 100, 101, 102, 103, 114, 117, 118, 123, 131, 134, 135, 136, 137, 138, 140, 141, 142, 145, 169, 178, 186, 209, 214, 223, 259, 285, 308, 319, 332, 333, 334, 335, 338, 346, 348, 352, 356, 371, 385, 400], "logit": [19, 21, 22, 34, 35, 38, 39, 41, 45, 46, 50, 51, 53, 64, 65, 78, 104, 134, 136, 140, 142, 143, 168, 181, 223, 261], "ell": [19, 35, 51, 52, 56, 92, 93, 96, 117, 118, 123, 136, 139, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241], "a_1w_2": 19, "b_2": [19, 258, 264], "probabl": [19, 26, 32, 33, 34, 35, 36, 41, 46, 48, 49, 50, 51, 52, 56, 60, 65, 69, 72, 73, 75, 78, 103, 104, 108, 109, 110, 114, 134, 139, 140, 141, 142, 143, 148, 149, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 227, 228, 229, 231, 232, 233, 234, 235, 236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 270, 288, 303], "sigmoid": [19, 20, 34, 35, 36, 38, 39, 41, 45, 46, 49, 50, 51, 53, 56, 57, 64, 65, 67, 69, 75, 78, 103, 104, 109, 132, 140, 168], "import": [1, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 38, 39, 41, 45, 57, 69, 78, 89, 90, 91, 94, 95, 96, 97, 99, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 271, 275, 280, 281, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 334, 335, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 369, 389, 393, 394], "np": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 275, 280, 281, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 389, 393, 394], "express": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 51, 52, 53, 57, 59, 64, 65, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 116, 134, 135, 136, 137, 138, 139, 140, 142, 143, 148, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 169, 170, 171, 172, 173, 174, 176, 179, 180, 182, 183, 184, 185, 186, 187, 188, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 231, 232, 233, 235, 236, 238, 239, 241, 242, 243, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 258, 259, 260, 261, 262, 265, 266, 267, 268, 270, 271, 275, 280, 281, 285, 286, 288, 290, 291, 294, 296, 297, 298, 300, 302, 304, 305, 307, 309, 310, 311, 312, 313, 314, 315, 316, 317, 320, 321, 324, 325, 326, 332, 334, 335, 356], "px": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 51, 52, 53, 57, 59, 64, 65, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 116, 134, 136, 138, 139, 140, 142, 143, 148, 150, 151, 152, 153, 154, 156, 157, 158, 160, 161, 162, 163, 165, 166, 169, 174, 176, 179, 180, 183, 184, 186, 187, 188, 190, 194, 195, 196, 197, 198, 199, 201, 202, 203, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 231, 232, 233, 235, 236, 239, 241, 242, 243, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 258, 259, 261, 262, 265, 266, 267, 268, 270, 271, 275, 280, 281, 285, 286, 288, 290, 291, 294, 296, 297, 298, 300, 302, 304, 307, 309, 310, 311, 312, 313, 314, 315, 316, 317, 320, 321, 324, 325, 326], "graph_object": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 275, 280, 281, 284, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 389, 393, 394], "go": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 275, 280, 281, 284, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 334, 349, 374, 389, 393, 394], "os": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 332, 335, 342, 353, 358, 359], "io": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 280, 331, 332, 333, 335, 358, 359, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 381, 386], "pio": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 280], "sklearn": [19, 21, 22, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 125, 127, 129, 131, 132, 287, 289, 290, 291, 293, 294, 306, 320, 321, 324, 325], "make_moon": [19, 25, 30, 31, 103, 105, 110], "linear_model": [19, 34, 35, 37, 38, 46, 64, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 104, 107, 131, 291, 320, 324, 325], "logisticregress": [19, 34, 35, 37, 38, 46, 64, 104], "accuracy_scor": [19, 21, 22, 33, 38, 67, 69, 104, 105, 106, 108, 109, 110], "confusion_matrix": [19, 21, 22, 33], "log_loss": [19, 33, 36, 46, 51, 53, 110], "model_select": [19, 21, 22, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 51, 56, 57, 64, 67, 69, 75, 78, 87, 88, 89, 91, 92, 93, 96, 104, 105, 106, 107, 108, 110, 271, 281, 297, 298, 302, 304, 306, 307, 309, 310, 323], "train_test_split": [19, 21, 22, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 51, 56, 57, 64, 67, 69, 75, 78, 87, 88, 89, 91, 92, 93, 96, 104, 105, 106, 107, 108, 110], "preprocess": [19, 25, 26, 28, 29, 30, 31, 32, 35, 52, 74, 103, 105, 107, 108, 109, 110, 112, 162, 197, 227, 241, 281, 326, 356], "standardscal": [19, 25, 26, 28, 29, 30, 31, 32, 35, 52, 74, 103, 105, 107, 108, 109, 110], "torch": [19, 20, 21, 22, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146], "nn": [19, 21, 22, 25, 27, 32, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146], "util": [19, 20, 21, 22, 86, 87, 127, 131, 132, 134, 138, 139, 140, 141, 142, 143, 161, 229, 230, 237, 299, 308, 311, 312, 313, 314, 315, 316, 317, 340, 368], "dataload": [19, 20, 21, 22], "tensordataset": [19, 21, 22], "default": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 280, 296, 331, 332, 334, 335, 338, 346, 347, 348, 351, 352, 357, 359, 371, 372, 373, 376, 377, 378, 379], "plotly_whit": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 65, 67, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 280, 389, 393, 394], "render": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 403], "environ": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 137, 138, 143, 144, 145, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 285, 300, 331, 332, 333, 334, 335, 338, 344, 348, 349, 350, 353, 357, 358, 365, 371, 372, 378, 379], "get": [1, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 283, 311, 312, 313, 314, 315, 316, 317, 338, 339, 340, 341, 343, 344, 345, 352, 354, 355, 358, 378, 379, 382, 383], "plotly_render": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270], "set_printopt": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 106, 107, 108, 109, 110, 111, 113, 114, 115, 117, 118, 119, 121, 123, 134, 135, 136, 137, 138, 140, 141, 143, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270], "precis": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 41, 45, 46, 47, 51, 52, 54, 56, 57, 59, 60, 61, 62, 64, 65, 67, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 121, 123, 134, 135, 136, 140, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 262, 263, 264, 265, 266, 268, 269, 270, 322], "suppress": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 106, 107, 108, 109, 110, 111, 113, 114, 115, 117, 118, 119, 121, 123, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270], "true": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 269, 270, 271, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 298, 300, 304, 305, 306, 307, 308, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 331, 332, 333, 334, 339, 341, 343, 344, 345, 346, 348, 349, 350, 351, 355, 357, 365, 376, 379, 383, 393, 394], "seed": [19, 20, 21, 22, 26, 31, 32, 35, 38, 39, 45, 47, 50, 51, 52, 64, 73, 74, 77, 81, 83, 105, 106, 108, 111, 112, 114, 117, 118, 121, 122, 123, 127, 129, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 157, 158, 162, 163, 176, 183, 191, 194, 195, 198, 209, 211, 212, 213, 217, 218, 221, 223, 229, 234, 235, 237, 238, 240, 241, 242, 244, 249, 250, 251, 252, 253, 257, 259, 263, 265, 268, 269, 271, 275, 281, 286, 287, 289, 292, 297, 298, 299, 302, 304, 305, 307, 308, 309, 326, 327, 328, 329, 393, 394], "42": [19, 20, 21, 22, 25, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37, 41, 45, 46, 52, 53, 59, 64, 65, 70, 72, 73, 74, 75, 78, 81, 84, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 102, 103, 107, 109, 110, 111, 112, 114, 117, 118, 122, 134, 136, 138, 140, 141, 143, 144, 145, 146, 148, 150, 151, 153, 154, 156, 160, 161, 165, 166, 169, 173, 179, 180, 186, 187, 189, 190, 197, 199, 201, 202, 205, 206, 208, 210, 212, 214, 216, 219, 220, 221, 224, 225, 226, 227, 231, 232, 233, 234, 236, 239, 242, 243, 245, 246, 248, 250, 251, 252, 254, 255, 256, 258, 259, 261, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 280, 281, 289, 291, 294, 297, 298, 300, 302, 303, 304, 306, 307, 309, 310, 312, 320, 321, 323, 324, 326, 386, 394], "rng": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 136, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 280, 284, 293, 295, 296, 300, 301, 303, 306, 312, 313, 314, 315, 316, 317, 318, 319, 322, 323], "random": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 127, 129, 130, 131, 132, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 218, 219, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 264, 265, 266, 267, 269, 270, 271, 275, 280, 281, 284, 286, 287, 289, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 312, 313, 314, 315, 316, 317, 318, 319, 322, 323, 326, 327, 328, 329, 393, 394], "default_rng": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 280, 284, 293, 295, 296, 300, 301, 303, 306, 312, 313, 314, 315, 316, 317, 318, 319, 322, 323], "warn": [19, 20, 21, 22, 39, 46, 83, 87, 100, 109, 120, 122, 124, 140, 142, 152, 174, 188, 200, 205, 209, 211, 233, 237, 240], "manual_se": [19, 20, 21, 22, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146], "catch_warn": [19, 20, 21, 22, 174, 209, 237], "filterwarn": [19, 20, 21, 22, 120, 122, 124, 140, 142], "ignor": [19, 20, 21, 22, 25, 37, 46, 47, 49, 50, 53, 57, 59, 67, 69, 70, 72, 74, 75, 77, 84, 86, 87, 88, 89, 93, 98, 99, 100, 109, 117, 119, 120, 122, 124, 127, 131, 132, 140, 142, 143, 156, 159, 164, 168, 173, 174, 175, 184, 205, 207, 209, 220, 229, 230, 231, 237, 246, 250, 253, 265, 266, 268], "messag": [4, 19, 20, 21, 22, 88, 109, 119, 140, 142, 153, 181, 191, 212, 223, 224, 227, 228, 231, 234, 238, 241, 333, 353, 354, 355, 356, 384, 385], "cuda": [19, 20, 21, 22, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146], "initi": [19, 20, 21, 22, 25, 29, 31, 35, 47, 70, 73, 74, 81, 83, 84, 89, 99, 103, 111, 119, 121, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 155, 157, 159, 161, 163, 165, 167, 168, 173, 175, 187, 188, 195, 205, 207, 208, 211, 212, 214, 222, 224, 228, 233, 237, 239, 256], "categori": [19, 38, 52, 53, 75, 77, 81, 84, 113, 120, 122, 124, 159, 223, 224, 228, 233, 234, 240, 251], "userwarn": [19, 39, 46, 115, 120, 122, 124, 134, 136, 138, 139, 141, 143, 144, 145, 146], "has_cuda": 19, "is_avail": [19, 20, 21, 22, 134, 138, 139, 141, 142, 143, 144, 145], "manual_seed_al": [19, 138, 139, 143, 144, 145], "devic": [19, 20, 21, 22, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 260, 266, 296, 341], "els": [19, 20, 21, 22, 25, 27, 28, 29, 30, 31, 32, 34, 37, 38, 39, 45, 47, 50, 51, 52, 53, 57, 59, 64, 65, 67, 69, 72, 73, 75, 77, 81, 83, 84, 86, 87, 88, 89, 91, 92, 95, 96, 97, 98, 100, 101, 102, 105, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 151, 152, 154, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 169, 170, 172, 173, 174, 180, 182, 184, 185, 187, 189, 190, 192, 196, 197, 201, 202, 204, 207, 208, 209, 210, 211, 212, 214, 216, 218, 219, 220, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 249, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 295, 296, 299, 303, 310, 311], "cpu": [19, 20, 21, 22, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 340, 342, 343, 349, 358, 368, 374, 381, 383, 385], "mean": [19, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 68, 69, 70, 75, 78, 85, 86, 87, 88, 89, 90, 91, 95, 99, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 118, 119, 120, 122, 124, 125, 127, 129, 131, 132, 136, 138, 140, 141, 142, 143, 145, 162, 164, 165, 168, 169, 170, 171, 176, 180, 182, 186, 189, 190, 199, 201, 208, 209, 214, 215, 217, 223, 228, 229, 246, 249, 252, 254, 255, 260, 261, 264, 271, 280, 281, 286, 287, 288, 289, 292, 294, 296, 299, 301, 305, 308, 310, 312, 313, 314, 315, 316, 317, 318, 323, 326, 328, 329, 392], "entiti": 19, "custom": [19, 41, 99, 105, 134, 144, 145, 161, 162, 163, 214, 225, 226, 230, 232, 233, 243, 245, 263, 268, 332, 333, 339, 340, 342, 347, 368, 371, 385], "transact": [4, 5, 19, 148, 341, 351, 353], "patient": [19, 224], "column": [19, 20, 26, 30, 32, 46, 53, 57, 67, 69, 72, 75, 78, 84, 93, 107, 110, 112, 115, 117, 118, 122, 142, 189, 246, 247, 251, 253, 261, 271, 280, 285, 306, 311, 312, 313, 314, 315, 316, 317, 328, 341, 348, 394], "heterogen": [19, 183, 224, 225, 228, 233, 236, 237, 288], "numer": [19, 22, 28, 29, 30, 36, 46, 50, 53, 57, 64, 65, 69, 70, 73, 75, 77, 78, 83, 86, 87, 88, 89, 92, 93, 95, 98, 100, 101, 102, 103, 107, 108, 112, 113, 118, 122, 135, 140, 142, 146, 148, 149, 150, 151, 152, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 227, 228, 231, 232, 233, 234, 235, 237, 238, 239, 240, 241, 243, 244, 246, 250, 251, 255, 256, 257, 260, 262, 264, 266, 267, 269, 381, 386], "miss": [19, 20, 29, 31, 32, 46, 49, 53, 86, 90, 91, 96, 97, 99, 105, 108, 112, 113, 116, 122, 129, 132, 139, 159, 175, 185, 221, 228, 230, 231, 253, 254, 260, 265, 271, 275, 285, 296, 312, 322, 323, 328, 340, 345, 366, 367], "imag": [19, 31, 32, 53, 155, 173, 175, 176, 178, 179, 181, 185, 190, 201, 204, 205, 207, 331, 332, 333, 339, 342, 343, 349, 352, 355, 358, 359, 360, 365, 366, 367, 370, 371, 374, 375, 376, 378], "text": [19, 21, 22, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 45, 46, 47, 49, 51, 52, 56, 57, 64, 65, 67, 69, 72, 73, 74, 75, 78, 81, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 103, 104, 106, 109, 110, 111, 112, 113, 114, 117, 120, 121, 122, 132, 134, 135, 137, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 225, 226, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 263, 265, 266, 267, 268, 269, 270, 280, 318, 322, 341, 350, 382, 385, 393], "smaller": [19, 22, 27, 31, 32, 35, 38, 45, 84, 107, 109, 110, 112, 124, 134, 138, 139, 141, 142, 148, 160, 161, 165, 167, 168, 169, 170, 178, 182, 190, 192, 195, 196, 199, 202, 203, 213, 215, 218, 227, 229, 231, 232, 233, 235, 240, 241, 248, 250, 253, 256, 257, 258, 260, 264, 265, 266, 268, 269], "noisier": [19, 87, 89, 105, 109, 138, 250], "right": [19, 20, 28, 31, 32, 34, 35, 36, 37, 46, 56, 57, 64, 67, 69, 70, 74, 75, 78, 87, 88, 91, 92, 93, 95, 96, 97, 98, 99, 102, 103, 104, 105, 107, 110, 116, 124, 125, 134, 135, 136, 138, 139, 140, 142, 146, 148, 149, 150, 151, 152, 153, 154, 155, 157, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 280, 283, 293, 296, 303, 327, 328, 338, 340, 346, 361, 367, 373], "induct": [19, 21, 288], "bia": [19, 21, 22, 41, 53, 64, 77, 101, 102, 106, 110, 118, 131, 134, 136, 138, 141, 142, 143, 144, 145, 146, 159, 184, 189, 198, 214, 221, 232, 241, 247, 258, 268, 303, 327], "less": [19, 20, 25, 31, 32, 38, 41, 46, 47, 50, 64, 65, 69, 74, 77, 86, 87, 89, 92, 93, 96, 97, 98, 102, 103, 107, 108, 110, 125, 138, 145, 148, 159, 164, 168, 176, 182, 189, 190, 191, 193, 209, 210, 213, 218, 224, 227, 229, 241, 245, 246, 249, 250, 255, 256, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 331, 332, 333, 371], "obviou": [19, 75, 112, 234, 280], "specif": [19, 31, 32, 36, 37, 39, 57, 64, 65, 84, 89, 94, 98, 100, 106, 108, 116, 122, 132, 140, 141, 160, 168, 192, 203, 230, 242, 244, 253, 255, 262, 266, 268, 283, 296, 304, 307, 313, 346, 347, 355, 357, 358, 359, 369, 371, 375, 378, 384], "two": [19, 20, 21, 22, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 41, 46, 47, 50, 51, 53, 57, 59, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 83, 84, 87, 88, 89, 90, 93, 94, 97, 98, 99, 103, 104, 105, 106, 107, 108, 109, 110, 113, 116, 122, 123, 124, 125, 127, 131, 134, 136, 139, 140, 143, 144, 145, 146, 148, 150, 152, 155, 156, 161, 162, 163, 165, 166, 172, 173, 174, 175, 176, 177, 178, 180, 182, 183, 184, 185, 188, 191, 192, 194, 196, 198, 201, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 220, 223, 224, 226, 227, 230, 231, 232, 233, 234, 236, 237, 238, 240, 242, 243, 244, 247, 248, 249, 252, 253, 254, 255, 257, 258, 259, 260, 261, 262, 264, 265, 268, 269, 270, 287, 305, 355, 356, 359], "habit": [19, 107, 266], "standard": [19, 20, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 49, 50, 51, 52, 53, 56, 59, 65, 67, 70, 74, 77, 78, 83, 89, 93, 94, 95, 96, 100, 102, 103, 104, 105, 111, 112, 113, 114, 118, 122, 132, 134, 138, 139, 141, 143, 146, 148, 150, 151, 153, 154, 155, 158, 159, 160, 163, 165, 166, 167, 168, 169, 170, 171, 175, 176, 178, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 198, 199, 201, 202, 204, 205, 207, 208, 209, 210, 212, 213, 215, 218, 219, 220, 221, 222, 224, 225, 226, 228, 230, 231, 232, 233, 234, 235, 236, 239, 240, 241, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 256, 258, 259, 260, 261, 262, 266, 267, 268, 269, 270, 285, 318, 329, 333, 334, 335, 351, 355, 356, 373, 378, 379, 382, 385], "help": [19, 25, 26, 29, 31, 39, 45, 49, 65, 70, 77, 83, 92, 98, 103, 105, 112, 116, 119, 138, 139, 146, 148, 150, 163, 165, 170, 172, 177, 182, 183, 185, 189, 195, 199, 206, 207, 208, 211, 213, 216, 218, 222, 226, 230, 234, 240, 247, 250, 256, 260, 261, 266, 267, 269, 285, 297, 298, 305, 332, 333, 339, 340, 343, 346, 348, 351, 352, 358, 359, 372, 381], "optim": [19, 20, 21, 22, 26, 52, 75, 77, 83, 91, 92, 95, 103, 105, 109, 110, 113, 114, 119, 134, 138, 141, 142, 144, 145, 148, 149, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 169, 171, 173, 174, 175, 176, 177, 178, 179, 180, 181, 188, 190, 191, 192, 193, 195, 197, 199, 204, 205, 206, 209, 210, 211, 212, 213, 214, 215, 216, 217, 220, 222, 223, 224, 225, 226, 227, 228, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 255, 270, 316, 341, 346, 361, 386, 392, 393], "treat": [19, 37, 39, 49, 50, 51, 53, 59, 64, 67, 69, 70, 81, 83, 91, 93, 97, 98, 107, 109, 113, 116, 117, 132, 134, 151, 154, 155, 163, 165, 174, 187, 188, 190, 193, 200, 204, 209, 211, 215, 216, 218, 222, 224, 232, 233, 237, 241, 244, 245, 256, 260, 264, 267, 332, 333, 335, 340, 346, 347, 359, 382, 385], "carefulli": [19, 32, 119, 134, 163, 182, 190, 222, 238, 240, 251, 259, 261, 286, 346, 368, 371], "we": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 69, 70, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 131, 132, 134, 135, 136, 137, 138, 139, 141, 142, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 271, 280, 284, 285, 287, 303, 306, 317, 318, 322, 328, 381, 393, 394], "ll": [19, 20, 25, 28, 30, 31, 32, 34, 35, 45, 46, 47, 50, 52, 53, 57, 59, 65, 67, 69, 73, 75, 77, 78, 81, 88, 89, 90, 93, 94, 98, 99, 100, 101, 102, 104, 110, 112, 113, 118, 120, 124, 125, 127, 136, 138, 146, 148, 149, 150, 151, 153, 154, 155, 156, 158, 159, 160, 161, 167, 170, 172, 175, 176, 177, 178, 185, 187, 189, 191, 192, 194, 195, 199, 202, 204, 206, 207, 210, 212, 216, 220, 221, 222, 223, 224, 225, 226, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 250, 252, 255, 256, 257, 258, 261, 262, 263, 265, 266, 267, 270, 354], "us": [5, 7, 19, 20, 21, 22, 25, 27, 28, 30, 31, 32, 33, 52, 103, 104, 106, 108, 109, 110, 115, 116, 117, 118, 120, 121, 122, 123, 124, 127, 129, 130, 132, 134, 136, 137, 138, 139, 141, 142, 143, 145, 146, 228, 244, 248, 250, 252, 256, 258, 261, 263, 271, 280, 283, 284, 285, 290, 291, 294, 295, 296, 299, 303, 305, 306, 308, 310, 318, 320, 322, 323, 325, 327, 328, 329, 337, 359, 381, 393, 394], "simpl": [19, 22, 25, 26, 27, 28, 34, 35, 37, 41, 45, 46, 51, 52, 56, 57, 67, 69, 77, 83, 86, 87, 88, 90, 92, 93, 94, 95, 98, 99, 100, 101, 105, 109, 110, 111, 112, 113, 114, 118, 119, 120, 122, 123, 125, 129, 132, 135, 136, 137, 138, 139, 140, 141, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 187, 188, 190, 191, 192, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 245, 247, 250, 251, 254, 255, 257, 259, 260, 262, 265, 267, 280, 288, 303, 304, 305, 307, 308, 319, 322, 331, 338, 339, 340, 341, 344, 345, 347, 349, 371], "2d": [19, 27, 29, 30, 31, 32, 34, 37, 38, 39, 46, 47, 49, 51, 52, 53, 56, 59, 65, 67, 72, 74, 75, 81, 83, 84, 86, 87, 89, 91, 92, 96, 97, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 113, 117, 123, 125, 127, 129, 131, 132, 140, 141, 152, 159, 164, 178, 185, 186, 189, 194, 201, 205, 206, 221, 222, 228, 230, 246, 253, 258], "so": [19, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 111, 113, 114, 116, 117, 119, 122, 123, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 280, 285, 287, 295, 318, 322, 323, 339, 347, 350, 355, 356, 358, 359, 374, 375, 376, 377, 382, 383], "decis": [19, 35, 36, 37, 38, 39, 41, 45, 51, 52, 56, 57, 64, 75, 78, 81, 94, 103, 106, 109, 111, 127, 129, 139, 163, 196, 212, 242, 249, 256, 258, 259, 262, 265, 269, 270, 271, 291, 294, 305, 308, 340], "even": [19, 22, 28, 29, 32, 34, 38, 41, 56, 57, 69, 70, 74, 75, 77, 81, 89, 91, 99, 100, 104, 108, 111, 120, 122, 124, 132, 140, 143, 148, 149, 154, 155, 156, 158, 161, 165, 167, 169, 176, 178, 194, 199, 202, 204, 206, 207, 218, 221, 229, 230, 237, 239, 240, 242, 243, 244, 248, 250, 254, 255, 261, 262, 264, 265, 323, 376], "though": [19, 22, 57, 69, 70, 75, 77, 81, 91, 148, 155, 199, 221, 240, 250, 255, 265, 351], "s": [19, 21, 22, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 46, 47, 49, 52, 53, 57, 59, 64, 65, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 93, 95, 99, 101, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 204, 205, 206, 207, 208, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 250, 253, 254, 256, 257, 258, 260, 263, 268, 271, 280, 287, 288, 292, 293, 296, 299, 303, 304, 307, 313, 323, 327, 328, 332, 334, 335, 338, 340, 341, 342, 343, 344, 345, 346, 347, 349, 350, 351, 352, 354, 355, 358, 359, 366, 369, 379, 393], "still": [19, 21, 22, 28, 29, 30, 32, 34, 35, 37, 49, 51, 52, 56, 64, 65, 70, 78, 91, 92, 99, 100, 101, 107, 110, 112, 113, 114, 116, 123, 139, 141, 145, 150, 152, 153, 155, 161, 170, 171, 173, 175, 176, 177, 178, 181, 199, 200, 208, 211, 213, 214, 216, 217, 219, 232, 238, 240, 245, 247, 248, 251, 253, 258, 259, 260, 263, 264, 265, 269, 270, 297, 298, 355, 359, 385], "To": [19, 20, 21, 22, 27, 28, 31, 34, 49, 67, 74, 78, 88, 102, 105, 112, 113, 122, 125, 134, 138, 140, 146, 156, 167, 171, 172, 174, 181, 186, 189, 199, 207, 210, 217, 218, 222, 224, 232, 238, 246, 252, 266, 269, 270, 345], "issu": [19, 22, 70, 77, 108, 113, 117, 123, 148, 152, 154, 155, 158, 159, 162, 173, 177, 178, 179, 187, 188, 191, 192, 194, 195, 201, 207, 210, 214, 215, 217, 218, 228, 232, 239, 240, 241, 243, 250, 255, 258, 266, 280, 332, 379], "intention": [19, 73, 83, 94, 96, 113, 115, 268, 332, 333, 339, 340, 342, 350], "stretch": [19, 25, 132, 149, 150, 154, 155, 156, 161, 163, 164, 169, 172, 173, 175, 177, 179, 180, 181, 188, 189, 195, 198, 200, 201, 203, 204, 207, 210, 213, 216, 217, 220, 236, 287], "one": [4, 19, 21, 22, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 46, 49, 50, 52, 53, 56, 57, 59, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 87, 89, 94, 95, 96, 97, 99, 101, 105, 106, 108, 109, 110, 111, 114, 115, 116, 117, 118, 121, 123, 124, 125, 129, 135, 137, 139, 140, 141, 148, 150, 152, 153, 157, 159, 160, 161, 162, 163, 164, 166, 169, 170, 171, 172, 174, 177, 178, 179, 185, 186, 188, 189, 192, 195, 197, 198, 199, 202, 203, 206, 207, 208, 209, 211, 212, 216, 219, 221, 222, 225, 226, 227, 228, 230, 232, 233, 234, 236, 237, 238, 242, 244, 245, 247, 249, 250, 251, 252, 253, 255, 258, 259, 261, 262, 263, 264, 265, 267, 268, 269, 270, 280, 296, 308, 318, 327, 328, 332, 333, 334, 338, 341, 342, 343, 350, 353, 354, 355, 358, 359, 369, 370, 373, 374, 382, 383, 385, 386], "n_sampl": [19, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 45, 46, 47, 49, 51, 52, 53, 56, 57, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 83, 84, 86, 87, 88, 89, 91, 92, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 125, 127, 159, 185, 221], "2000": [19, 26, 27, 28, 32, 34, 35, 37, 38, 45, 46, 49, 57, 64, 67, 69, 77, 90, 97, 104, 105, 108, 109, 111, 116, 119, 134, 138, 141, 145, 148, 149, 151, 152, 153, 154, 155, 156, 161, 166, 167, 168, 172, 173, 174, 176, 177, 178, 184, 188, 190, 193, 202, 208, 210, 211, 212, 216, 222, 225, 235, 240, 242, 247, 255, 266, 267], "x_raw": [19, 52, 83, 93, 95, 107], "nois": [19, 20, 26, 28, 29, 32, 41, 47, 52, 56, 57, 74, 77, 87, 89, 90, 91, 92, 93, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 112, 114, 115, 117, 119, 120, 123, 124, 125, 127, 129, 131, 132, 134, 136, 138, 140, 141, 144, 145, 148, 149, 155, 157, 158, 161, 163, 164, 166, 168, 173, 176, 177, 179, 181, 182, 183, 184, 185, 186, 188, 189, 191, 192, 193, 194, 195, 198, 199, 201, 205, 207, 208, 210, 211, 214, 217, 218, 219, 221, 222, 239, 243, 244, 248, 249, 250, 253, 254, 255, 257, 262, 263, 264, 265, 267, 268, 270, 280, 284, 295, 296, 297, 298, 300, 305, 306, 318, 319, 323, 329, 394], "25": [19, 21, 22, 25, 27, 28, 30, 31, 32, 36, 37, 38, 39, 46, 50, 51, 53, 57, 69, 72, 74, 75, 81, 83, 87, 89, 91, 92, 93, 96, 99, 101, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 117, 118, 122, 123, 125, 127, 131, 132, 135, 136, 140, 141, 142, 143, 145, 146, 148, 150, 153, 154, 155, 159, 161, 162, 164, 166, 167, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178, 179, 181, 183, 186, 189, 192, 194, 199, 206, 207, 210, 213, 214, 216, 217, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 240, 241, 242, 244, 245, 246, 247, 249, 250, 252, 257, 260, 261, 263, 266, 267, 268, 270, 288, 314, 317, 318, 319, 322, 358, 359, 389, 393], "random_st": [19, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 51, 52, 56, 57, 64, 67, 69, 74, 75, 77, 78, 83, 87, 88, 89, 91, 92, 93, 96, 103, 104, 105, 106, 107, 108, 109, 110, 127, 129, 131, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 289, 291, 294, 306, 320, 321, 324], "forc": [19, 20, 22, 25, 28, 73, 75, 84, 107, 108, 112, 115, 123, 125, 196, 214, 216, 228, 230, 233, 245], "mismatch": [19, 31, 34, 49, 50, 51, 59, 67, 69, 75, 86, 90, 91, 92, 93, 94, 96, 97, 101, 102, 104, 112, 138, 154, 177, 186, 190, 201, 205, 215, 227, 241, 242, 246, 247, 268, 310], "astyp": [19, 20, 21, 22, 25, 26, 27, 31, 32, 34, 35, 36, 37, 38, 39, 41, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 93, 98, 104, 105, 106, 108, 109, 115, 119, 120, 122, 124, 127, 131, 138, 140, 141, 142, 143, 144, 145, 191, 221, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 247, 251, 257, 261, 270, 296], "float64": [19, 32, 69, 73, 92, 115, 116, 122, 138, 139, 178, 184, 199, 209, 327, 328, 329], "int64": [19, 21, 22, 69, 70, 72, 73, 75, 81, 84, 134, 136, 139, 140, 141, 142, 143, 270], "val": [19, 34, 35, 36, 37, 41, 47, 49, 50, 51, 56, 59, 67, 70, 78, 81, 83, 99, 102, 106, 116, 135, 137, 158, 164, 199, 204, 209, 216, 230, 280], "split": [19, 20, 29, 32, 34, 46, 53, 59, 64, 65, 73, 77, 78, 81, 88, 95, 100, 101, 102, 105, 107, 112, 117, 118, 119, 120, 122, 123, 124, 127, 129, 144, 146, 153, 157, 158, 170, 172, 182, 191, 195, 211, 212, 221, 222, 223, 230, 234, 235, 237, 238, 240, 243, 246, 247, 251, 257, 261, 263, 280, 287, 289, 290, 291, 293, 294, 299, 306, 310, 311, 312, 313, 314, 315, 316, 317, 320, 321, 323, 324, 325, 331, 332, 357], "x_train_raw": 19, "x_temp_raw": 19, "y_train": [19, 20, 21, 22, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 53, 56, 57, 59, 64, 65, 67, 69, 75, 78, 87, 89, 91, 92, 93, 103, 105, 107, 112, 119, 120, 122, 124, 125, 127, 129, 131, 132, 271, 280, 287, 289, 290, 291, 293, 294, 297, 298, 299, 302, 304, 306, 307, 309, 310, 319, 320, 321, 323, 324, 325], "y_temp": 19, "test_siz": [19, 21, 22, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 51, 53, 56, 57, 64, 67, 69, 75, 78, 87, 88, 89, 91, 92, 93, 96, 104, 105, 106, 107, 108, 110, 271, 281, 297, 298, 302, 304, 306, 307, 309, 310, 323], "30": [19, 20, 21, 22, 27, 31, 32, 34, 35, 36, 38, 45, 47, 53, 56, 59, 64, 69, 70, 75, 78, 81, 84, 87, 90, 95, 97, 107, 108, 110, 112, 115, 117, 118, 120, 122, 124, 125, 127, 129, 131, 132, 135, 136, 138, 142, 145, 148, 151, 155, 163, 166, 181, 193, 201, 205, 209, 210, 214, 220, 221, 224, 226, 227, 228, 230, 233, 235, 236, 237, 245, 246, 247, 248, 250, 251, 254, 255, 259, 260, 261, 263, 264, 265, 266, 268, 269, 270, 280, 288, 289, 297, 298, 301, 318, 322, 327, 329, 344, 346, 348, 366, 389], "stratifi": [19, 21, 22, 34, 35, 36, 37, 38, 39, 41, 45, 46, 49, 56, 57, 64, 67, 69, 75, 78, 104, 105, 106, 108, 263], "x_val_raw": 19, "x_test_raw": 19, "y_val": [19, 34, 35, 36, 37, 39, 41, 45, 47, 49, 50, 51, 56, 57, 59, 65, 67, 69, 73, 75, 78, 107], "y_test": [19, 20, 21, 22, 35, 36, 38, 39, 41, 46, 49, 50, 53, 57, 64, 87, 89, 91, 92, 93, 107, 112, 119, 120, 124, 125, 127, 129, 131, 132, 271, 287, 289, 290, 291, 293, 294, 297, 298, 299, 302, 304, 306, 307, 309, 310, 319, 320, 321, 323, 324, 325], "50": [19, 20, 30, 31, 32, 34, 36, 37, 39, 41, 47, 49, 50, 51, 53, 59, 64, 65, 69, 70, 72, 73, 77, 78, 81, 86, 88, 91, 92, 93, 94, 95, 96, 99, 100, 101, 104, 110, 114, 115, 116, 119, 122, 123, 125, 127, 129, 134, 135, 136, 139, 141, 142, 145, 146, 150, 153, 155, 156, 157, 158, 162, 163, 168, 172, 175, 179, 185, 186, 191, 192, 196, 202, 204, 205, 211, 213, 215, 218, 226, 228, 229, 230, 231, 232, 233, 237, 239, 240, 241, 244, 245, 246, 247, 248, 252, 253, 254, 255, 258, 263, 265, 266, 268, 270, 280, 284, 288, 295, 300, 316, 317, 319, 322, 389], "onli": [2, 19, 22, 25, 26, 28, 30, 34, 35, 36, 38, 39, 41, 45, 46, 47, 51, 52, 53, 56, 59, 64, 65, 67, 69, 70, 73, 74, 77, 78, 81, 83, 84, 86, 87, 88, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 107, 109, 110, 112, 113, 114, 116, 117, 122, 125, 127, 131, 132, 134, 136, 138, 139, 140, 141, 144, 145, 152, 166, 168, 173, 180, 181, 184, 185, 188, 193, 215, 216, 224, 226, 228, 230, 232, 233, 236, 239, 242, 245, 250, 252, 253, 254, 255, 256, 258, 259, 261, 262, 263, 265, 271, 280, 303, 331, 334, 335, 341, 343, 346, 350, 351, 352, 353, 355, 356, 357, 358, 359, 367, 374, 386, 389], "scaler": [19, 52, 74, 105, 109, 310], "fit": [19, 25, 27, 28, 32, 35, 37, 38, 39, 45, 46, 49, 52, 53, 64, 65, 67, 74, 75, 78, 83, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 100, 102, 103, 104, 105, 106, 107, 109, 110, 114, 115, 116, 118, 119, 120, 122, 124, 127, 129, 131, 132, 134, 136, 138, 146, 150, 151, 152, 153, 154, 155, 156, 157, 159, 162, 163, 164, 165, 166, 169, 170, 172, 174, 175, 176, 177, 178, 181, 182, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 218, 219, 221, 222, 223, 226, 228, 229, 232, 236, 237, 239, 243, 248, 262, 263, 271, 280, 281, 284, 287, 289, 291, 293, 295, 301, 303, 308, 310, 315, 318, 321, 322, 323, 324, 325, 331, 332, 333, 334, 335, 341, 349, 351, 359, 371], "x_train": [19, 20, 21, 22, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 53, 56, 57, 59, 64, 65, 67, 69, 75, 78, 87, 89, 91, 92, 93, 103, 105, 107, 119, 122, 125, 127, 129, 131, 132, 287, 289, 290, 291, 293, 294, 306, 319, 320, 321, 324, 325], "x_val": [19, 34, 35, 36, 37, 39, 41, 45, 47, 49, 50, 51, 56, 57, 59, 65, 67, 69, 75, 78, 107], "x_test": [19, 20, 21, 22, 35, 36, 38, 39, 41, 46, 49, 50, 53, 57, 64, 87, 89, 91, 92, 93, 103, 107, 122, 125, 127, 129, 131, 132, 150, 154, 167, 168, 174, 181, 182, 184, 186, 187, 189, 193, 199, 287, 289, 290, 291, 293, 294, 306, 319, 320, 321, 324, 325], "shape": [19, 20, 21, 22, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 112, 113, 115, 117, 118, 119, 122, 123, 125, 127, 129, 131, 132, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 153, 154, 155, 156, 157, 159, 160, 170, 171, 173, 174, 175, 177, 178, 179, 182, 184, 186, 187, 188, 189, 191, 192, 195, 197, 199, 201, 202, 206, 209, 210, 212, 214, 215, 217, 222, 225, 226, 228, 230, 231, 233, 234, 235, 237, 238, 239, 240, 241, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 264, 265, 266, 267, 268, 270, 271, 283, 291, 295, 296, 303, 327, 346, 347, 356], "fig": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 275, 280, 281, 284, 285, 286, 287, 288, 289, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 322, 323, 326, 327, 328, 329, 389, 393, 394], "scatter": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 250, 252, 253, 254, 255, 256, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 280, 281, 284, 287, 289, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 315, 316, 317, 318, 319, 322, 323, 326, 327, 329, 356, 389, 393, 394], "color": [19, 21, 22, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 49, 50, 52, 53, 56, 57, 64, 65, 67, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 129, 131, 132, 139, 140, 142, 143, 150, 156, 157, 159, 161, 177, 185, 189, 196, 202, 206, 210, 219, 221, 222, 224, 227, 228, 230, 233, 238, 243, 244, 246, 248, 249, 250, 251, 252, 254, 255, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 280, 284, 287, 288, 292, 293, 296, 299, 305, 308, 310, 312, 317, 322, 327, 328, 329, 393], "str": [19, 20, 25, 27, 29, 31, 32, 34, 37, 41, 46, 49, 52, 53, 57, 59, 65, 69, 70, 72, 73, 74, 77, 78, 81, 83, 84, 86, 87, 92, 95, 96, 97, 99, 101, 103, 104, 105, 106, 108, 109, 110, 115, 118, 119, 120, 124, 125, 127, 129, 131, 132, 134, 135, 137, 138, 141, 143, 144, 157, 165, 185, 204, 211, 212, 221, 228, 237, 238, 239, 249, 250, 251, 252, 254, 255, 257, 258, 259, 261, 264, 266, 267, 268, 269, 270, 275, 286, 287, 288, 289, 292, 300, 312, 313, 314, 315, 316, 317, 318, 339, 350, 381], "titl": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 228, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 275, 280, 281, 284, 285, 286, 287, 288, 289, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 322, 323, 326, 327, 328, 329, 389, 393, 394], "raw": [19, 29, 31, 38, 41, 47, 52, 59, 64, 65, 69, 73, 74, 86, 87, 89, 92, 96, 100, 101, 102, 107, 119, 125, 131, 136, 143, 145, 152, 153, 157, 160, 174, 179, 183, 184, 191, 192, 198, 204, 206, 211, 213, 225, 228, 240, 245, 247, 252, 253, 257, 259, 261, 263, 265, 266, 267, 322, 331, 346, 348, 352, 353, 371, 382, 385], "feature_1": 19, "feature_2": 19, "class": [19, 20, 21, 22, 27, 28, 29, 30, 33, 34, 35, 36, 38, 39, 41, 45, 46, 49, 50, 51, 52, 53, 57, 58, 61, 65, 67, 69, 75, 77, 78, 83, 84, 104, 105, 108, 109, 110, 113, 115, 120, 124, 125, 127, 129, 131, 132, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 155, 181, 189, 211, 224, 227, 233, 238, 258, 267, 285, 286, 287, 288, 289, 292, 293, 311, 312, 314, 315, 316, 317, 332, 334, 356, 359, 373, 379], "update_trac": [19, 21, 22, 25, 27, 28, 70, 90, 104, 105, 106, 108, 228, 259], "marker": [19, 21, 22, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 45, 47, 49, 50, 52, 53, 56, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 120, 124, 125, 127, 131, 132, 140, 141, 145, 146, 152, 155, 156, 158, 161, 164, 167, 168, 169, 170, 173, 174, 176, 178, 179, 180, 181, 183, 186, 188, 189, 190, 192, 193, 197, 200, 205, 208, 209, 218, 219, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 247, 248, 249, 252, 253, 254, 255, 256, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 284, 287, 301, 303, 305, 306, 308, 310, 317, 318, 319, 322, 328, 383, 393, 394], "dict": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 143, 144, 146, 148, 150, 152, 153, 155, 156, 157, 158, 160, 161, 164, 165, 166, 167, 168, 169, 170, 173, 174, 175, 176, 177, 178, 179, 180, 181, 184, 185, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 215, 216, 217, 219, 221, 227, 228, 230, 231, 233, 237, 238, 240, 241, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 280, 284, 287, 292, 293, 295, 296, 299, 305, 308, 310, 312, 313, 314, 316, 317, 319, 322, 327, 328, 329, 389, 393], "size": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 119, 120, 121, 122, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 248, 249, 252, 254, 257, 258, 259, 260, 261, 263, 265, 266, 267, 268, 270, 280, 284, 289, 293, 295, 296, 299, 300, 303, 310, 312, 313, 314, 315, 316, 317, 318, 319, 322, 323, 328, 338, 342, 346, 349, 352, 354, 358, 361, 382, 393, 394], "opac": [19, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 41, 49, 50, 56, 64, 65, 67, 70, 75, 77, 78, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 109, 110, 112, 115, 122, 127, 135, 137, 140, 146, 149, 150, 151, 152, 153, 154, 157, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 210, 211, 213, 215, 216, 218, 219, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 244, 245, 246, 247, 248, 249, 250, 252, 253, 257, 258, 260, 261, 262, 263, 264, 265, 267, 268, 269, 284, 289, 318, 328, 394], "show": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 266, 267, 268, 269, 270, 271, 275, 280, 281, 284, 285, 286, 287, 288, 289, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 322, 323, 326, 327, 328, 329, 331, 334, 335, 338, 340, 341, 344, 345, 347, 355, 381, 384], "x_all": [19, 20, 31, 125, 252], "zero": [13, 19, 20, 21, 22, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 41, 46, 47, 49, 50, 51, 52, 53, 56, 57, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 152, 154, 156, 158, 159, 160, 161, 162, 164, 167, 169, 170, 172, 173, 178, 179, 182, 183, 185, 186, 187, 189, 190, 193, 194, 196, 197, 198, 199, 200, 201, 203, 206, 213, 217, 219, 220, 221, 222, 223, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 244, 247, 248, 251, 252, 253, 255, 261, 262, 265, 267, 270, 271, 280, 303, 305, 353], "unit": [8, 19, 20, 25, 26, 30, 46, 56, 69, 74, 78, 87, 90, 91, 93, 94, 95, 98, 101, 102, 107, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 138, 154, 159, 162, 163, 165, 169, 170, 173, 175, 186, 187, 189, 192, 202, 203, 204, 205, 209, 213, 214, 216, 222, 234, 235, 236, 253, 260, 265, 266, 268, 269, 303, 331, 332, 333, 340, 346, 353, 358, 359, 374, 402], "varianc": [19, 26, 29, 31, 36, 41, 85, 88, 93, 95, 98, 101, 102, 103, 104, 106, 108, 112, 113, 114, 116, 118, 119, 122, 123, 143, 146, 189, 228, 242, 247, 253, 254, 255, 256, 257, 258, 260, 262, 263, 265, 269, 271, 288, 289, 305, 323, 392], "z": [19, 20, 21, 22, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 49, 50, 51, 53, 56, 57, 64, 65, 67, 69, 72, 73, 74, 75, 78, 81, 84, 89, 90, 94, 96, 97, 98, 99, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 117, 118, 121, 122, 125, 134, 138, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 213, 214, 216, 218, 219, 220, 221, 222, 225, 227, 228, 229, 230, 232, 234, 235, 236, 237, 238, 239, 240, 242, 245, 246, 247, 248, 249, 252, 254, 255, 259, 260, 263, 266, 268, 269, 270, 286, 287, 295, 303, 305, 316, 326, 359, 382, 385, 389], "def": [1, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 280, 285, 286, 287, 289, 292, 295, 301, 303, 306, 310, 311, 312, 313, 314, 315, 316, 317, 319, 328, 350, 389, 393, 394], "decision_boundary_figur": [19, 37], "x2d": 19, "prob_fn": 19, "grid_n": [19, 134, 159], "250": [19, 28, 31, 46, 52, 56, 64, 65, 67, 69, 84, 86, 87, 90, 91, 92, 94, 109, 110, 111, 112, 114, 121, 123, 129, 134, 136, 138, 139, 149, 153, 164, 173, 175, 176, 185, 205, 206, 219, 220, 224, 228, 229, 260, 269, 299], "pad": [19, 21, 22, 27, 31, 103, 131, 144, 159, 256, 269], "asarrai": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 138, 139, 140, 141, 142, 143, 144, 145, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 280, 303, 389], "x0_min": [19, 38, 56, 67], "x0_max": [19, 38, 56, 67], "min": [19, 21, 22, 25, 27, 29, 30, 34, 37, 38, 39, 45, 46, 47, 49, 52, 56, 59, 64, 67, 69, 72, 73, 75, 78, 83, 86, 87, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 114, 115, 117, 120, 122, 123, 124, 125, 127, 129, 131, 132, 136, 138, 139, 140, 142, 143, 144, 146, 148, 149, 150, 152, 154, 156, 158, 159, 162, 163, 164, 166, 170, 174, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 193, 196, 199, 200, 201, 202, 206, 209, 212, 214, 215, 216, 217, 219, 220, 225, 228, 229, 230, 231, 232, 233, 238, 239, 240, 241, 246, 247, 248, 250, 251, 254, 256, 260, 261, 262, 263, 265, 266, 267, 268, 270, 275, 287, 289, 312, 318, 393], "max": [19, 21, 22, 25, 27, 30, 32, 34, 35, 37, 38, 39, 45, 46, 49, 52, 56, 64, 67, 69, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 114, 115, 117, 118, 119, 120, 122, 123, 124, 125, 127, 129, 131, 132, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 244, 246, 248, 249, 250, 251, 254, 256, 257, 258, 260, 261, 262, 263, 266, 267, 268, 269, 275, 289, 303, 312, 318, 340, 393], "x1_min": [19, 34, 37, 38, 52, 56, 67, 75, 78], "x1_max": [19, 34, 37, 38, 52, 56, 67, 75, 78], "xs": [19, 27, 30, 37, 52, 103, 104, 105, 106, 108, 109, 110, 146, 156, 157, 158, 159, 160, 162, 163, 165, 166, 167, 169, 170, 172, 176, 180, 183, 184, 185, 190, 192, 194, 195, 196, 197, 198, 199, 203, 204, 205, 208, 209, 214, 215, 217, 218, 221, 228, 229, 232, 233, 242, 248, 254, 258, 267, 268], "linspac": [19, 25, 26, 27, 28, 30, 31, 34, 37, 38, 39, 41, 45, 46, 49, 50, 51, 52, 53, 56, 57, 67, 69, 70, 72, 74, 75, 77, 78, 86, 87, 88, 89, 90, 91, 92, 94, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 115, 134, 143, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 227, 231, 232, 233, 235, 236, 237, 238, 240, 241, 242, 244, 246, 248, 250, 252, 254, 256, 258, 261, 262, 263, 264, 266, 267, 268, 269, 286, 287, 288, 289, 295, 301, 306, 313, 316, 319, 389, 393], "ys": [19, 21, 22, 27, 37, 47, 95, 103, 104, 105, 106, 108, 109, 110, 156, 158, 162, 163, 169, 172, 176, 180, 183, 190, 194, 195, 197, 198, 203, 205, 208, 209, 228, 230, 258, 267, 268], "xx": [19, 34, 37, 38, 53, 103, 104, 105, 106, 108, 109, 110, 151, 181, 193, 211, 269], "yy": [19, 29, 34, 37, 38, 53, 103, 104, 105, 106, 108, 109, 110, 179, 269], "meshgrid": [19, 34, 37, 38, 41, 49, 56, 57, 67, 96, 97, 98, 99, 103, 104, 105, 106, 107, 108, 109, 110, 134, 185, 189, 254, 389], "grid": [19, 21, 22, 34, 37, 38, 49, 51, 56, 67, 74, 75, 83, 86, 98, 103, 104, 106, 107, 108, 109, 110, 146, 148, 149, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163, 164, 165, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 185, 187, 189, 191, 193, 196, 197, 200, 202, 206, 208, 210, 211, 212, 213, 215, 216, 218, 219, 220, 222, 223, 225, 229, 231, 232, 233, 234, 237, 240, 241, 248, 256, 266, 268], "c_": [19, 20, 21, 22, 26, 28, 30, 34, 37, 38, 41, 45, 47, 49, 50, 53, 56, 57, 64, 65, 67, 69, 75, 78, 83, 84, 88, 95, 103, 104, 105, 106, 108, 109, 150, 165, 190, 193, 211, 249], "ravel": [19, 32, 34, 37, 38, 49, 53, 56, 67, 73, 75, 81, 99, 103, 104, 105, 106, 108, 109, 110, 134, 148, 159, 185, 189, 241, 242, 243, 244, 246, 248, 251, 252, 255, 257, 259, 262, 264, 270], "prob": [19, 21, 22, 46, 50, 72, 73, 74, 78, 104, 106, 122, 134, 143, 144, 170, 180, 186, 225, 240, 247, 258, 270], "reshap": [19, 21, 22, 34, 37, 38, 56, 59, 67, 78, 86, 87, 88, 89, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 120, 124, 125, 127, 132, 134, 138, 140, 141, 143, 144, 145, 148, 151, 169, 180, 185, 189, 190, 194, 197, 212, 214, 241, 246, 254, 263, 267, 347], "figur": [19, 20, 21, 22, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 75, 77, 78, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 257, 258, 259, 260, 261, 262, 263, 264, 266, 267, 268, 269, 270, 271, 280, 281, 284, 287, 289, 292, 293, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 310, 312, 313, 314, 315, 317, 318, 319, 322, 323, 326, 327, 328, 329, 389, 393, 394], "surfac": [15, 19, 27, 28, 32, 38, 49, 57, 67, 96, 99, 103, 106, 107, 108, 114, 156, 158, 193, 200, 237, 288], "add_trac": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 280, 281, 284, 287, 289, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 315, 316, 317, 318, 319, 322, 323, 326, 327, 328, 329, 389, 393, 394], "contour": [19, 34, 37, 38, 56, 67, 96, 97, 98, 99, 103, 104, 105, 106, 107, 108, 109, 110, 154, 159, 185, 187, 189, 254], "zmin": [19, 21, 22, 26, 51, 53, 57, 67, 73, 75, 81, 118, 134, 255], "zmax": [19, 21, 22, 26, 51, 53, 57, 67, 73, 75, 81, 118, 134, 255], "colorscal": [19, 20, 21, 22, 26, 27, 28, 31, 32, 34, 35, 37, 38, 39, 41, 49, 50, 51, 53, 56, 67, 69, 72, 75, 78, 81, 84, 89, 103, 104, 105, 106, 108, 109, 110, 118, 134, 138, 156, 167, 168, 185, 189, 228, 230, 237, 246, 261, 287, 393], "rdbu": [19, 21, 22, 26, 28, 34, 38, 56, 57, 67, 78, 104, 105, 106, 108, 109, 118, 134, 138, 139, 185, 246, 255], "reversescal": [19, 28, 34], "75": [19, 30, 34, 36, 38, 39, 47, 49, 53, 59, 64, 83, 96, 101, 104, 105, 106, 107, 108, 122, 135, 136, 137, 141, 150, 154, 155, 161, 168, 170, 171, 175, 176, 178, 181, 186, 189, 192, 193, 195, 202, 207, 222, 223, 226, 228, 230, 237, 242, 249, 252, 257, 264, 265, 268], "colorbar": [19, 27, 28, 31, 32, 34, 35, 38, 50, 53, 56, 67, 69, 73, 75, 78, 89, 96, 97, 98, 99, 103, 104, 105, 106, 108, 118, 134, 138, 156, 159, 167, 168, 189, 228, 230, 246], "p": [19, 20, 21, 22, 25, 26, 27, 29, 30, 31, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 87, 90, 93, 94, 95, 96, 103, 104, 105, 106, 108, 110, 113, 115, 120, 122, 124, 125, 127, 131, 132, 134, 136, 138, 139, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 222, 223, 225, 226, 227, 228, 229, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 249, 252, 255, 257, 259, 261, 265, 271, 287, 303, 305, 306, 328, 333, 358, 359, 389], "line": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 275, 280, 281, 284, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 358, 382, 389, 393, 394], "black": [19, 20, 25, 27, 28, 29, 30, 31, 34, 37, 38, 41, 47, 49, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 78, 83, 84, 89, 91, 93, 96, 97, 98, 99, 100, 102, 103, 105, 107, 109, 110, 112, 113, 116, 118, 120, 122, 124, 127, 129, 131, 132, 146, 149, 150, 151, 159, 160, 161, 164, 169, 174, 176, 177, 179, 181, 184, 185, 196, 197, 198, 200, 202, 204, 206, 210, 217, 218, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 240, 241, 243, 244, 245, 247, 248, 249, 250, 252, 254, 255, 256, 258, 260, 261, 262, 263, 264, 266, 267, 268, 269, 270, 280, 393], "width": [19, 25, 26, 27, 28, 30, 31, 32, 34, 35, 37, 38, 39, 46, 49, 50, 52, 53, 56, 64, 67, 69, 78, 83, 86, 87, 88, 90, 91, 94, 96, 97, 99, 100, 103, 104, 105, 106, 108, 109, 110, 111, 114, 115, 117, 118, 119, 120, 121, 123, 124, 125, 134, 135, 136, 137, 139, 143, 146, 149, 151, 152, 155, 160, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 178, 180, 181, 182, 184, 190, 191, 192, 193, 194, 196, 197, 199, 200, 201, 204, 205, 206, 208, 210, 211, 215, 217, 222, 225, 228, 229, 230, 231, 233, 244, 245, 248, 253, 254, 256, 258, 260, 262, 264, 265, 268, 269, 270, 287, 292, 293, 295, 308, 316], "showscal": [19, 21, 22, 27, 28, 31, 32, 34, 35, 37, 38, 39, 41, 49, 50, 51, 53, 56, 67, 72, 73, 75, 78, 81, 84, 89, 103, 107, 109, 110, 118, 185, 189, 254, 393], "fals": [19, 21, 22, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 149, 151, 155, 159, 163, 164, 168, 170, 175, 176, 177, 178, 179, 181, 182, 185, 189, 204, 207, 210, 221, 222, 224, 228, 230, 232, 234, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 281, 286, 287, 288, 289, 292, 295, 297, 298, 300, 302, 304, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 323, 346, 348, 351, 389, 393, 394], "point": [19, 20, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 46, 49, 50, 52, 56, 65, 67, 68, 69, 70, 73, 74, 75, 77, 78, 81, 83, 86, 90, 92, 94, 96, 98, 99, 101, 103, 106, 109, 110, 112, 116, 117, 125, 127, 140, 141, 145, 146, 148, 149, 150, 153, 154, 157, 159, 165, 170, 171, 172, 174, 177, 180, 181, 182, 185, 188, 189, 195, 197, 199, 200, 201, 203, 205, 206, 207, 209, 211, 212, 213, 214, 217, 219, 221, 222, 226, 229, 230, 231, 234, 238, 242, 243, 245, 247, 248, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 268, 269, 270, 280, 284, 285, 287, 296, 301, 305, 308, 317, 331, 340, 348, 349, 350, 351, 352, 353, 357, 369], "mode": [19, 20, 21, 22, 25, 26, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 131, 132, 134, 136, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 151, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 199, 200, 201, 203, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 250, 252, 253, 254, 255, 256, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 280, 284, 287, 289, 292, 295, 299, 300, 301, 303, 305, 306, 308, 310, 312, 313, 314, 315, 316, 317, 318, 319, 322, 327, 328, 329, 346, 351, 359, 373, 389, 393, 394], "viridi": [19, 20, 21, 22, 27, 32, 34, 35, 50, 67, 69, 78, 81, 89, 103, 104, 105, 106, 108, 109, 134, 138, 156, 159, 167, 168, 189, 228, 230, 237, 393], "name": [1, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 254, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 275, 280, 281, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 334, 335, 338, 340, 342, 343, 344, 346, 347, 348, 349, 350, 352, 354, 356, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 381, 382, 383, 385, 386, 389, 393, 394], "update_layout": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 280, 281, 284, 287, 288, 289, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 315, 316, 317, 318, 319, 322, 323, 326, 327, 328, 329, 389, 393, 394], "xaxis_titl": [19, 20, 21, 22, 26, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 52, 53, 56, 57, 59, 64, 65, 69, 70, 72, 74, 75, 77, 78, 83, 86, 87, 88, 89, 90, 91, 92, 94, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122, 124, 125, 127, 129, 131, 132, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 172, 173, 174, 175, 176, 177, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 257, 258, 259, 260, 261, 262, 263, 264, 266, 267, 268, 269, 270, 271, 280, 287, 288, 289, 292, 293, 296, 300, 301, 303, 306, 310, 312, 313, 314, 315, 318, 319, 327, 328, 329, 389, 393, 394], "yaxis_titl": [19, 20, 21, 22, 26, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 52, 53, 56, 57, 59, 64, 65, 69, 70, 72, 74, 75, 77, 78, 83, 86, 87, 88, 89, 90, 91, 92, 94, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122, 124, 125, 127, 129, 131, 132, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 172, 173, 174, 175, 176, 177, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 257, 258, 259, 260, 261, 262, 263, 264, 266, 267, 268, 269, 270, 271, 280, 287, 288, 293, 296, 300, 301, 303, 306, 312, 313, 314, 315, 318, 319, 327, 328, 329, 389, 393, 394], "legend": [19, 20, 25, 37, 47, 49, 56, 67, 78, 93, 95, 96, 111, 113, 121, 122, 143, 159, 167, 179, 189, 233, 254], "orient": [19, 20, 25, 29, 37, 47, 49, 56, 67, 83, 86, 95, 96, 106, 109, 111, 113, 121, 122, 143, 149, 167, 179, 189, 233, 254, 260], "h": [19, 20, 21, 22, 25, 27, 31, 37, 38, 46, 47, 49, 50, 53, 56, 59, 67, 69, 72, 77, 78, 83, 84, 95, 96, 109, 110, 111, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 139, 140, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 246, 254, 259, 260, 285, 286, 299, 300, 303, 304, 305, 306, 307, 308, 310, 328, 382], "yanchor": [19, 20, 37, 47, 49, 56, 67, 95, 111, 113, 121, 122, 135, 137, 143, 179, 233, 242, 254], "bottom": [19, 20, 28, 37, 47, 49, 56, 67, 95, 111, 113, 117, 121, 122, 143, 179, 233, 242, 243, 244, 245, 249, 254, 256], "02": [19, 20, 21, 22, 29, 36, 37, 39, 41, 46, 47, 49, 52, 56, 57, 59, 67, 72, 77, 93, 103, 111, 112, 113, 114, 115, 116, 117, 121, 122, 127, 129, 136, 138, 151, 166, 168, 169, 172, 178, 179, 180, 190, 197, 198, 205, 208, 215, 218, 222, 231, 236, 237, 246, 247, 251, 253, 254, 255, 263, 295, 300, 366, 386, 393, 394], "xanchor": [19, 20, 31, 37, 47, 49, 67, 111, 113, 121, 122, 135, 137, 143, 179, 233, 254], "return": [1, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 280, 284, 285, 286, 287, 289, 292, 295, 301, 303, 306, 310, 311, 312, 313, 314, 315, 316, 317, 319, 322, 328, 345, 350, 381, 386, 389, 393], "classifi": [19, 34, 37, 38, 39, 41, 46, 49, 52, 56, 57, 67, 75, 78, 103, 106, 108, 109, 160, 172, 192, 197, 199, 221, 230, 234, 235, 253, 285, 291, 293, 311, 315, 324], "draw": [19, 29, 31, 50, 64, 105, 106, 108, 114, 122, 148, 149, 154, 155, 157, 158, 159, 160, 161, 162, 165, 166, 168, 169, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 184, 185, 186, 187, 189, 190, 191, 195, 196, 199, 200, 202, 203, 204, 205, 206, 207, 208, 209, 210, 217, 218, 220, 221, 223, 224, 226, 227, 228, 229, 232, 234, 236, 237, 238, 239, 240, 241, 245, 246, 250, 256, 260, 263, 269, 305], "singl": [19, 20, 22, 25, 31, 35, 36, 38, 39, 45, 46, 47, 49, 50, 56, 57, 59, 64, 72, 73, 77, 83, 84, 86, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 105, 107, 108, 110, 114, 119, 127, 132, 134, 136, 142, 143, 146, 148, 151, 153, 156, 158, 161, 164, 172, 174, 176, 181, 185, 186, 189, 197, 198, 200, 201, 202, 204, 211, 212, 217, 221, 223, 224, 232, 233, 235, 236, 237, 240, 242, 243, 244, 246, 248, 249, 250, 252, 254, 256, 258, 262, 267, 269, 271, 288, 296, 299, 301, 331, 332, 334, 341, 346, 373, 382], "straight": [19, 27, 29, 30, 196, 248, 262, 265, 285], "our": [19, 27, 29, 34, 35, 37, 39, 46, 49, 52, 53, 57, 64, 65, 67, 69, 83, 87, 88, 89, 91, 97, 98, 101, 102, 105, 110, 115, 116, 148, 149, 152, 158, 159, 160, 162, 164, 165, 166, 167, 169, 171, 173, 174, 178, 179, 181, 183, 186, 188, 189, 190, 193, 195, 196, 197, 198, 201, 206, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 237, 248, 252, 253, 258, 262, 264, 265, 267, 268], "underfit": [19, 97], "log_reg": 19, "max_it": [19, 26, 29, 31, 32, 34, 35, 37, 38, 46, 49, 64, 72, 74, 75, 81, 83, 84, 88, 93, 95, 98, 104, 107, 109, 110, 132, 158, 171, 185, 204, 227, 232, 233, 246, 266], "eval_sklearn_binari": 19, "predict_proba": [19, 35, 38, 46, 50, 64, 103, 104, 105, 106, 108], "pred": [19, 20, 21, 22, 34, 37, 39, 41, 49, 53, 56, 57, 59, 69, 70, 73, 75, 77, 78, 81, 88, 89, 93, 96, 109, 110, 113, 119, 122, 125, 127, 129, 131, 271, 281, 287, 289, 290, 291, 293, 294, 297, 298, 302, 304, 306, 307, 308, 309, 319, 320, 321, 323, 324, 325, 394], "acc": [19, 34, 37, 38, 41, 52, 53, 56, 57, 67, 78, 108, 109, 110, 117, 123, 170, 193, 214], "float": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 301, 303, 312, 313, 314, 315, 316, 317, 389], "logloss": [19, 64], "baseline_metr": 19, "lambda": [19, 27, 28, 29, 30, 36, 77, 84, 93, 98, 103, 104, 109, 114, 116, 120, 124, 134, 135, 136, 140, 141, 142, 146, 151, 152, 153, 158, 163, 165, 169, 173, 175, 178, 179, 180, 181, 184, 186, 189, 190, 192, 193, 195, 196, 201, 202, 203, 204, 205, 210, 213, 215, 216, 218, 221, 226, 230, 231, 235, 236, 237, 240, 244, 247, 256, 263, 300, 312, 313, 314, 315, 316, 317, 323, 338, 339, 340, 342, 347, 350, 352, 354, 356], "mix": [19, 20, 30, 36, 47, 73, 74, 84, 107, 110, 114, 139, 152, 172, 185, 189, 203, 209, 218, 225, 243, 257, 268, 308, 346], "input": [19, 20, 21, 22, 29, 46, 88, 98, 108, 109, 111, 112, 113, 115, 117, 127, 129, 132, 135, 136, 141, 188, 201, 209, 229, 255, 262, 285, 296, 308, 333, 338, 346, 356, 385], "anoth": [19, 21, 22, 72, 74, 83, 95, 102, 105, 110, 116, 149, 155, 158, 199, 200, 211, 230, 233, 234, 238, 242, 245, 265, 345], "produc": [19, 22, 26, 28, 29, 32, 35, 49, 51, 52, 56, 59, 64, 65, 67, 75, 83, 84, 93, 96, 102, 103, 105, 106, 110, 112, 113, 116, 117, 121, 137, 140, 148, 150, 155, 157, 163, 165, 166, 167, 173, 175, 179, 182, 186, 187, 188, 190, 199, 202, 204, 208, 209, 210, 214, 215, 216, 218, 219, 222, 223, 224, 225, 231, 232, 235, 237, 239, 240, 242, 244, 248, 250, 251, 257, 261, 262, 263, 265, 268, 288, 317, 347, 354, 355, 381], "thi": [0, 10, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 86, 87, 88, 89, 90, 91, 92, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 171, 172, 173, 174, 176, 177, 178, 179, 181, 182, 183, 184, 186, 187, 189, 191, 192, 193, 196, 198, 199, 200, 201, 203, 204, 206, 207, 210, 211, 212, 213, 215, 216, 217, 220, 221, 222, 223, 224, 225, 228, 229, 238, 239, 241, 242, 243, 244, 245, 246, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280, 282, 283, 285, 287, 289, 291, 296, 303, 304, 306, 307, 308, 310, 311, 327, 330, 331, 335, 338, 339, 340, 341, 343, 344, 346, 347, 350, 351, 352, 353, 355, 356, 357, 358, 379, 382, 384, 387, 389, 393, 397, 404], "small": [19, 20, 25, 27, 28, 29, 31, 32, 35, 37, 38, 39, 41, 45, 46, 51, 52, 53, 56, 57, 65, 67, 72, 73, 74, 77, 78, 81, 83, 84, 87, 88, 91, 94, 96, 97, 98, 99, 100, 101, 102, 103, 106, 107, 108, 109, 110, 111, 112, 113, 114, 117, 120, 122, 124, 125, 129, 132, 134, 138, 140, 141, 142, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 163, 164, 165, 166, 167, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 190, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 205, 206, 209, 210, 211, 212, 213, 214, 215, 217, 218, 219, 220, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 269, 270, 280, 287, 292, 312, 317, 319, 327, 347, 349, 350, 358, 359, 365, 394], "piecewis": [19, 67, 78, 86, 87, 94, 105, 110, 115, 151, 157, 158, 161, 176, 177, 181, 182, 197, 207, 211, 212], "bend": [19, 30, 36], "around": [19, 22, 25, 28, 31, 45, 69, 70, 74, 81, 86, 103, 105, 108, 109, 110, 146, 149, 150, 152, 156, 158, 159, 161, 163, 168, 176, 177, 181, 182, 183, 202, 204, 205, 206, 217, 218, 219, 221, 222, 224, 226, 230, 239, 243, 245, 250, 254, 255, 256, 262, 265, 268, 270, 293, 334, 341], "hidden": [19, 20, 140, 141, 142, 208, 355], "quad": [19, 28, 29, 30, 35, 38, 41, 45, 50, 51, 52, 53, 56, 57, 70, 73, 74, 75, 77, 81, 84, 86, 87, 89, 90, 93, 95, 96, 97, 98, 99, 101, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 119, 123, 134, 135, 136, 137, 139, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 162, 163, 164, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 195, 196, 198, 199, 200, 201, 202, 203, 204, 205, 206, 209, 210, 211, 212, 213, 214, 216, 217, 218, 219, 221, 222, 223, 224, 225, 226, 228, 230, 232, 233, 234, 235, 236, 238, 240, 247, 249, 250, 264, 288, 301, 322, 327, 389, 393], "rightarrow": [19, 45, 46, 51, 52, 87, 93, 96, 100, 101, 104, 105, 109, 112, 119, 149, 150, 153, 154, 159, 161, 162, 163, 164, 166, 172, 175, 176, 182, 185, 191, 192, 195, 196, 198, 199, 210, 213, 217, 218, 219, 220, 223, 227, 233, 235, 236, 238, 240, 247], "w_2": [19, 211], "sigma": [19, 20, 29, 30, 31, 32, 35, 36, 38, 45, 46, 51, 53, 56, 57, 65, 67, 87, 89, 92, 93, 94, 96, 97, 102, 103, 106, 108, 111, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 131, 132, 137, 138, 140, 145, 151, 153, 156, 158, 160, 161, 163, 164, 165, 166, 168, 170, 171, 174, 176, 181, 183, 184, 185, 186, 188, 189, 190, 192, 193, 197, 200, 201, 202, 204, 205, 209, 210, 211, 212, 214, 215, 216, 218, 219, 220, 223, 226, 227, 229, 230, 232, 233, 236, 238, 239, 242, 243, 244, 248, 249, 250, 254, 259, 260, 263, 264, 266, 267, 269, 270, 288, 305, 389, 393], "frac": [19, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 118, 121, 122, 124, 125, 127, 129, 134, 135, 139, 141, 142, 143, 146, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 268, 280, 288, 303, 319, 323, 327, 329, 389, 393], "e": [19, 20, 21, 22, 25, 26, 27, 28, 29, 31, 32, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 251, 252, 254, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 295, 296, 301, 303, 306, 311, 320, 334, 335, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350, 351, 353, 354, 355, 356, 357, 358, 359, 366, 368, 381, 382, 384, 386, 389, 393], "entropi": [19, 21, 22, 26, 31, 33, 35, 39, 41, 45, 50, 51, 67, 69, 104, 135, 136, 140, 142, 146, 169, 180, 188, 193, 201, 208, 214, 228, 325], "comput": [19, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 71, 73, 74, 76, 77, 78, 82, 83, 84, 86, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 107, 109, 111, 112, 113, 114, 116, 117, 118, 125, 127, 129, 134, 135, 136, 138, 140, 142, 143, 144, 145, 146, 148, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 249, 250, 251, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 288, 289, 293, 310, 318, 325, 331, 334, 335, 338, 343, 344, 346, 348, 349, 350, 351, 353, 355, 356, 357], "stabli": [19, 154, 160, 163, 164, 165, 167, 171, 174, 176, 187, 199, 204, 213, 222, 224, 226, 235, 241], "mathcal": [19, 22, 32, 35, 45, 52, 53, 73, 83, 96, 98, 103, 105, 106, 108, 109, 111, 113, 121, 122, 125, 134, 135, 136, 137, 138, 139, 143, 144, 145, 146, 148, 151, 155, 158, 160, 163, 166, 167, 169, 171, 172, 175, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 192, 193, 194, 195, 196, 197, 199, 200, 201, 203, 205, 208, 209, 210, 212, 214, 215, 218, 221, 224, 226, 227, 228, 230, 236, 237, 239, 241, 249, 258, 264, 318, 319], "l": [19, 20, 21, 22, 29, 31, 32, 34, 35, 37, 38, 41, 45, 51, 52, 53, 56, 57, 64, 67, 70, 72, 74, 75, 81, 86, 89, 94, 95, 98, 103, 107, 109, 110, 116, 117, 119, 123, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 148, 150, 152, 153, 159, 161, 162, 163, 165, 173, 176, 178, 180, 181, 184, 185, 188, 189, 191, 192, 194, 195, 196, 198, 202, 204, 205, 206, 209, 211, 212, 213, 214, 215, 217, 220, 221, 223, 224, 225, 226, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 244, 249, 284, 292, 293, 295, 316, 317, 322], "sum_i": [19, 31, 45, 46, 50, 53, 57, 65, 69, 70, 75, 78, 81, 88, 89, 90, 91, 92, 95, 96, 97, 100, 107, 109, 111, 112, 117, 118, 123, 154, 158, 159, 162, 168, 169, 170, 176, 182, 186, 187, 190, 193, 196, 201, 203, 209, 213, 221, 223, 227, 228, 229, 230, 231, 235, 236, 237, 239, 243, 244, 247, 259, 265], "left": [19, 28, 31, 32, 34, 35, 39, 47, 49, 57, 59, 67, 69, 70, 75, 78, 88, 91, 92, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 107, 110, 111, 112, 113, 117, 121, 122, 124, 125, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 254, 255, 256, 258, 259, 261, 264, 265, 267, 268, 269, 270, 280, 284, 293, 303, 305, 327], "ell_i": [19, 56, 67], "y_i": [19, 28, 29, 31, 32, 34, 35, 36, 37, 38, 45, 46, 50, 51, 52, 53, 56, 59, 64, 65, 67, 73, 77, 81, 83, 84, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 107, 109, 110, 125, 127, 129, 132, 159, 167, 168, 170, 178, 179, 183, 184, 186, 190, 196, 199, 201, 204, 206, 207, 214, 215, 216, 219, 228, 229, 230, 231, 249, 255, 262, 265, 268, 270, 319], "kei": [4, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 34, 35, 37, 38, 39, 45, 49, 52, 56, 64, 65, 67, 69, 77, 84, 88, 92, 93, 94, 95, 96, 97, 102, 103, 104, 107, 113, 114, 116, 118, 122, 125, 133, 134, 136, 139, 140, 141, 143, 144, 145, 147, 149, 150, 151, 152, 153, 155, 156, 157, 159, 163, 165, 166, 167, 168, 169, 170, 171, 173, 174, 176, 177, 178, 181, 182, 184, 185, 186, 190, 191, 192, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 204, 205, 207, 209, 210, 213, 214, 215, 218, 219, 221, 222, 226, 230, 231, 232, 233, 234, 235, 236, 237, 239, 242, 244, 245, 250, 251, 252, 254, 256, 259, 260, 263, 268, 272, 273, 274, 276, 277, 278, 279, 282, 286, 295, 299, 308, 311, 312, 313, 314, 315, 316, 317, 331, 332, 333, 335, 338, 339, 340, 341, 342, 345, 346, 349, 350, 352, 353, 355, 356, 358, 359, 365, 376, 382, 389, 400], "fact": [19, 29, 56, 81, 94, 100, 161, 166, 168, 171, 173, 178, 180, 182, 184, 186, 188, 189, 190, 192, 194, 196, 212, 219, 220, 233, 239, 240, 254], "partial": [19, 22, 38, 53, 56, 64, 65, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 101, 102, 109, 112, 113, 119, 122, 127, 131, 132, 153, 154, 158, 159, 169, 178, 196, 200, 209, 215, 227, 229, 232, 237], "maximum": [19, 25, 26, 27, 28, 29, 30, 31, 32, 36, 46, 51, 52, 83, 85, 90, 91, 92, 94, 96, 98, 101, 102, 105, 106, 110, 114, 115, 117, 119, 122, 125, 127, 129, 138, 141, 148, 151, 154, 155, 157, 158, 159, 163, 165, 170, 172, 174, 175, 176, 184, 187, 188, 189, 194, 196, 198, 199, 204, 212, 213, 215, 217, 222, 223, 224, 225, 227, 229, 234, 235, 240, 241, 242, 246, 254, 256, 333, 340, 389], "exp": [2, 19, 20, 21, 22, 26, 30, 31, 32, 34, 35, 36, 38, 39, 41, 45, 46, 49, 50, 51, 53, 56, 57, 59, 64, 65, 67, 69, 75, 78, 88, 90, 92, 93, 95, 97, 98, 102, 103, 104, 106, 108, 109, 120, 124, 132, 134, 140, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 246, 248, 250, 251, 252, 254, 255, 256, 257, 258, 261, 264, 266, 267, 269, 389], "bce_with_logits_loss": 19, "logaddexp": [19, 35, 41, 56, 59, 154, 160, 181, 187, 218, 237], "accuracy_from_logit": 19, "init_mlp": 19, "in_dim": [19, 139, 140, 143], "hidden_dim": 19, "he": [19, 22], "good": [1, 19, 21, 26, 27, 29, 31, 32, 35, 36, 39, 45, 47, 49, 52, 64, 69, 70, 75, 88, 101, 102, 105, 107, 108, 112, 119, 134, 136, 140, 146, 150, 153, 154, 155, 156, 159, 162, 164, 165, 169, 174, 181, 183, 184, 187, 188, 190, 198, 203, 207, 209, 210, 211, 212, 213, 218, 222, 225, 228, 234, 245, 248, 251, 254, 255, 262, 263, 265, 266, 267, 268, 275, 280, 331, 332, 333, 335, 351, 381, 383], "w1": [19, 21, 22, 52, 75, 78, 100, 211], "normal": [19, 20, 21, 22, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 45, 46, 50, 51, 52, 53, 57, 64, 65, 67, 68, 69, 70, 72, 77, 78, 79, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 112, 113, 114, 115, 116, 119, 120, 122, 124, 125, 127, 129, 131, 132, 134, 138, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 190, 192, 193, 197, 198, 201, 202, 203, 204, 205, 206, 207, 209, 210, 212, 213, 216, 217, 218, 219, 221, 222, 226, 228, 230, 232, 233, 235, 236, 237, 238, 239, 240, 241, 243, 246, 249, 250, 253, 256, 257, 259, 261, 262, 263, 265, 266, 268, 269, 270, 280, 284, 287, 293, 295, 296, 297, 298, 299, 300, 301, 305, 306, 308, 312, 313, 314, 315, 316, 317, 318, 319, 322, 323, 327, 328, 329, 334, 348, 359, 381, 385, 394], "sqrt": [19, 20, 21, 22, 26, 27, 29, 30, 46, 57, 69, 74, 75, 83, 86, 90, 91, 92, 94, 96, 97, 99, 101, 102, 103, 104, 105, 106, 110, 111, 113, 114, 117, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 135, 136, 142, 146, 148, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 163, 166, 167, 169, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 214, 215, 218, 219, 220, 221, 223, 224, 225, 226, 228, 230, 231, 232, 234, 235, 236, 239, 240, 242, 243, 244, 246, 247, 248, 249, 250, 252, 254, 255, 256, 258, 259, 260, 261, 262, 264, 265, 266, 267, 268, 269, 270, 280, 329, 389, 393], "b1": [19, 90, 94, 96, 97, 98, 99, 107, 109, 123, 170, 184, 205, 216, 261], "dtype": [19, 20, 21, 22, 25, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 303, 327, 328, 329, 389], "w2": [19, 75, 78, 211, 248, 264], "b2": [19, 109, 216, 248, 258, 261, 264], "mlp_forward": 19, "param": [19, 20, 21, 22, 96, 98, 99, 105, 109, 116, 119, 122, 127, 129, 131, 132, 136, 144, 146, 154, 155, 156, 160, 163, 165, 166, 167, 168, 170, 171, 172, 173, 174, 176, 177, 181, 184, 188, 189, 191, 192, 194, 197, 199, 205, 210, 211, 213, 214, 219, 222, 223, 225, 227, 229, 231, 234, 235, 236, 238, 239, 240, 241, 310, 352], "z1": [19, 30, 74, 155, 170, 194, 218, 246, 262], "a1": [19, 94, 117, 123, 165, 170, 184, 209, 216, 242, 258, 264], "mlp_loss_and_grad": 19, "weight_decai": [19, 21, 22], "sum": [19, 20, 21, 22, 25, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 95, 96, 97, 98, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 114, 119, 122, 125, 129, 134, 136, 140, 141, 144, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 247, 249, 251, 252, 253, 255, 256, 257, 259, 261, 262, 263, 265, 270, 275, 280, 296, 383, 386, 393], "dl": 19, "dlogit": [19, 21, 22], "dw2": 19, "t": [6, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 56, 57, 59, 64, 65, 67, 69, 70, 72, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 98, 99, 100, 101, 102, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 245, 246, 247, 248, 250, 251, 252, 254, 255, 257, 258, 259, 260, 261, 263, 264, 265, 270, 271, 280, 284, 285, 286, 287, 289, 292, 293, 295, 296, 297, 298, 299, 300, 303, 304, 305, 306, 307, 308, 310, 313, 314, 315, 316, 317, 318, 319, 322, 323, 327, 328, 329, 331, 333, 334, 339, 341, 342, 343, 347, 349, 355, 357, 358, 359, 379, 386, 389, 393], "db2": 19, "axi": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 115, 117, 118, 119, 120, 122, 123, 124, 125, 127, 129, 131, 138, 140, 141, 146, 148, 150, 155, 157, 159, 160, 164, 165, 167, 168, 173, 175, 178, 182, 183, 184, 185, 186, 189, 193, 194, 198, 199, 200, 202, 206, 207, 209, 210, 212, 217, 221, 226, 228, 230, 231, 232, 237, 244, 245, 246, 247, 248, 249, 250, 251, 253, 258, 260, 261, 262, 264, 266, 267, 268, 269, 270, 306, 318, 393], "da1": 19, "dz1": 19, "dw1": 19, "db1": [19, 90, 96, 98], "grad": [19, 20, 34, 35, 37, 41, 45, 46, 49, 50, 53, 57, 59, 64, 65, 67, 69, 75, 78, 88, 93, 95, 100, 109, 136, 146, 151, 159, 228], "train_numpy_mlp": 19, "32": [19, 20, 75, 81, 107, 127, 129, 138, 140, 141, 142, 158, 201, 223, 253, 285], "epoch": [19, 20, 21, 22, 35, 36, 37, 45, 46, 52, 59, 140, 142, 143], "200": [19, 20, 25, 31, 34, 35, 37, 41, 49, 50, 51, 52, 69, 70, 72, 74, 75, 78, 81, 84, 86, 88, 89, 90, 92, 93, 95, 96, 97, 98, 99, 100, 101, 106, 107, 112, 113, 114, 117, 118, 123, 127, 129, 134, 136, 138, 139, 140, 141, 142, 144, 145, 148, 152, 155, 160, 161, 164, 168, 170, 175, 176, 178, 179, 180, 181, 182, 183, 184, 188, 193, 196, 199, 200, 201, 202, 203, 204, 205, 207, 209, 217, 219, 222, 224, 225, 226, 227, 228, 229, 230, 231, 233, 235, 238, 239, 240, 242, 248, 254, 258, 260, 261, 262, 264, 266, 284, 289, 293, 294, 306, 321, 340, 382, 384, 386, 389], "batch_siz": [19, 20, 21, 22, 35, 108, 139, 140, 141, 142, 144, 145, 247], "128": [19, 81, 105, 134, 136, 138, 139, 140, 142, 143, 144, 146, 214, 240, 349], "1e": [19, 20, 21, 22, 26, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 45, 46, 47, 49, 50, 52, 53, 56, 57, 59, 64, 65, 67, 69, 72, 74, 75, 78, 81, 83, 84, 88, 89, 90, 92, 93, 95, 97, 101, 102, 103, 104, 105, 106, 107, 108, 109, 112, 114, 116, 118, 120, 124, 125, 132, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 163, 164, 165, 167, 168, 169, 170, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 184, 185, 187, 189, 190, 191, 192, 193, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 208, 209, 210, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 239, 240, 241, 242, 244, 246, 250, 251, 252, 256, 261, 266, 286, 389], "rng_local": [19, 20, 21, 22, 26, 27, 29, 35, 38, 39, 45, 50, 52, 64, 69, 77, 83, 109, 114, 117, 123, 148, 195, 220, 250, 257, 259, 263, 265, 268, 269], "histori": [6, 19, 20, 31, 34, 36, 37, 38, 45, 46, 47, 49, 50, 51, 53, 56, 59, 65, 75, 89, 90, 91, 92, 93, 96, 97, 98, 99, 112, 115, 116, 117, 119, 122, 123, 125, 127, 131, 146, 185, 305, 306, 310, 312, 331, 356], "train_loss": [19, 21, 22, 34, 36, 37, 56], "val_loss": [19, 56, 110], "train_acc": [19, 21, 22, 34, 56], "val_acc": [19, 37, 56], "y_train_col": 19, "y_val_col": 19, "rang": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 149, 151, 155, 157, 158, 159, 160, 163, 164, 165, 171, 174, 175, 176, 179, 181, 184, 185, 188, 191, 192, 193, 195, 197, 200, 202, 203, 204, 206, 207, 211, 212, 213, 214, 215, 219, 221, 222, 224, 225, 227, 228, 229, 230, 231, 232, 233, 234, 237, 238, 239, 240, 242, 243, 244, 246, 249, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 269, 270, 286, 287, 289, 292, 293, 295, 299, 300, 301, 303, 306, 313, 316, 318, 327, 341, 357, 372, 382, 384, 393], "idx": [19, 20, 21, 22, 27, 28, 31, 32, 34, 35, 39, 41, 45, 64, 70, 72, 74, 75, 77, 83, 86, 87, 90, 91, 95, 96, 99, 101, 105, 110, 120, 122, 124, 125, 127, 129, 131, 132, 138, 139, 140, 144, 145, 146, 165, 181, 185, 219, 220, 221, 225, 232, 236, 245, 252, 255, 256, 260, 262, 263, 265, 286, 289, 296, 300, 393], "permut": [19, 20, 21, 22, 26, 34, 35, 37, 47, 50, 53, 59, 64, 65, 70, 72, 77, 81, 84, 95, 101, 102, 105, 110, 234, 237, 242, 245, 253, 256, 257, 260, 266, 267, 270], "batch_idx": 19, "xb": [19, 20, 21, 22, 34, 35, 37, 49, 50, 53, 64, 75, 107, 163, 195, 197, 228, 262, 306], "yb": [19, 20, 21, 22, 35, 262], "_": [19, 20, 21, 22, 25, 27, 29, 31, 32, 34, 35, 36, 37, 38, 41, 45, 46, 47, 49, 50, 51, 52, 53, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 93, 94, 95, 96, 99, 100, 101, 102, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 152, 153, 154, 155, 157, 158, 160, 161, 162, 163, 164, 166, 171, 172, 173, 176, 184, 185, 187, 189, 191, 192, 193, 194, 196, 197, 199, 202, 203, 204, 205, 210, 213, 214, 215, 216, 219, 221, 223, 224, 226, 227, 228, 230, 231, 232, 233, 236, 237, 241, 242, 244, 246, 248, 251, 252, 253, 254, 255, 257, 259, 260, 265, 266, 268, 270, 271, 285, 289, 295, 303, 304, 306, 307, 308, 313, 314, 315, 316, 317, 318, 327, 394], "train_logit": 19, "val_logit": 19, "append": [19, 20, 21, 22, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 46, 47, 49, 50, 51, 52, 53, 56, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 106, 107, 108, 109, 110, 112, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 129, 131, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 157, 159, 160, 162, 163, 165, 185, 191, 197, 199, 200, 209, 213, 221, 224, 227, 228, 231, 233, 236, 240, 244, 247, 249, 252, 254, 257, 258, 259, 262, 266, 267, 269, 286, 287, 289, 292, 293, 295, 296, 299, 300, 306, 311, 312, 313, 314, 315, 316, 317, 318, 327, 393], "params_np": 19, "hist_np": 19, "eval_numpy_mlp": 19, "numpy_metr": 19, "over": [4, 19, 20, 25, 30, 31, 32, 35, 36, 45, 46, 47, 49, 51, 52, 57, 59, 64, 65, 67, 72, 73, 74, 78, 83, 84, 86, 87, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 107, 108, 109, 112, 113, 114, 116, 118, 120, 122, 124, 127, 129, 131, 132, 134, 137, 138, 139, 140, 143, 146, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 184, 185, 186, 187, 189, 190, 191, 193, 194, 196, 199, 200, 202, 204, 205, 206, 208, 209, 210, 211, 213, 214, 215, 216, 219, 220, 221, 222, 225, 226, 228, 229, 230, 231, 234, 235, 236, 237, 238, 239, 240, 241, 246, 247, 253, 255, 262, 271, 289, 299, 303, 305, 308, 311, 318, 322, 327, 329, 334, 340, 346, 348, 352, 357, 359, 381, 382, 384], "accuraci": [19, 21, 22, 33, 36, 38, 39, 42, 45, 46, 49, 52, 53, 56, 64, 65, 66, 69, 75, 78, 89, 90, 92, 104, 105, 106, 108, 117, 157, 199, 200, 220, 224, 233, 242, 243, 253, 263, 264, 267, 288, 289, 291, 301, 318, 322], "yaxi": [19, 21, 22, 27, 31, 34, 35, 36, 37, 38, 39, 49, 53, 57, 64, 65, 72, 78, 84, 91, 92, 93, 140, 141, 153, 191, 192, 227, 230, 231, 244, 252, 257, 260, 266, 269, 296, 310], "probs_np_test": 19, "preds_np_test": 19, "cm": [19, 21, 22, 34, 37, 39, 41, 57, 73, 75, 159, 175], "imshow": [19, 21, 22, 31, 32, 37, 41, 49, 53, 57, 70, 73, 74, 77, 78, 103, 107, 139, 157, 219, 221, 222, 249, 251, 253, 255], "text_auto": [19, 21, 22, 37, 41, 57, 70, 73, 74, 77, 78, 107, 221, 249, 251], "color_continuous_scal": [19, 21, 22, 31, 32, 37, 41, 57, 70, 77, 78, 103, 139, 249, 251, 253, 255], "blue": [19, 21, 22, 26, 32, 34, 37, 39, 41, 49, 51, 53, 57, 69, 70, 72, 77, 78, 84, 108, 110, 184, 185, 189, 230, 233, 246, 247, 249, 251, 255, 261, 287, 299, 331, 336], "confus": [19, 21, 22, 33, 35, 37, 42, 43, 53, 58, 64, 65, 67, 68, 70, 72, 73, 74, 75, 78, 80, 81, 114, 154, 162, 163, 166, 167, 168, 169, 177, 181, 183, 186, 195, 197, 198, 210, 214, 218, 219, 229, 231, 232, 234], "count": [19, 21, 22, 25, 26, 28, 31, 34, 35, 36, 37, 38, 39, 41, 46, 47, 49, 50, 51, 53, 57, 64, 65, 69, 70, 72, 73, 74, 77, 78, 84, 87, 88, 89, 91, 92, 95, 97, 98, 99, 101, 102, 105, 107, 110, 112, 117, 118, 122, 123, 124, 125, 134, 136, 140, 142, 150, 152, 158, 159, 162, 169, 170, 171, 176, 193, 204, 212, 223, 224, 225, 227, 228, 229, 231, 232, 233, 234, 235, 237, 238, 239, 240, 241, 243, 245, 246, 247, 249, 251, 252, 253, 255, 256, 257, 260, 261, 262, 263, 268, 270, 285, 286, 295, 311, 312, 313, 314, 315, 316, 317, 318, 322, 335, 340, 343, 367, 382, 384], "update_xax": [19, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 35, 37, 38, 39, 45, 46, 47, 50, 51, 52, 56, 64, 65, 67, 70, 73, 74, 75, 77, 78, 81, 84, 86, 87, 88, 90, 92, 95, 96, 97, 98, 100, 102, 103, 104, 108, 111, 112, 113, 114, 115, 117, 118, 119, 121, 123, 125, 134, 135, 137, 139, 143, 144, 146, 148, 149, 151, 154, 155, 160, 163, 164, 167, 168, 171, 172, 175, 176, 177, 178, 179, 181, 182, 184, 185, 187, 189, 191, 192, 197, 199, 203, 204, 207, 210, 216, 220, 222, 224, 225, 226, 231, 232, 233, 237, 240, 241, 245, 247, 248, 249, 254, 256, 258, 261, 262, 263, 264, 265, 267, 295, 316], "tickmod": [19, 21, 22, 32, 34, 53, 110, 139, 268, 270], "arrai": [19, 21, 22, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 123, 125, 134, 139, 140, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 161, 162, 163, 164, 165, 166, 167, 168, 170, 172, 173, 174, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 208, 209, 210, 212, 213, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 257, 258, 259, 260, 261, 263, 265, 266, 267, 268, 269, 270, 284, 286, 288, 292, 295, 306, 317, 318, 322, 393, 394], "tickval": [19, 21, 22, 32, 34, 53, 75, 110, 139, 249, 255, 268, 270], "update_yax": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 35, 37, 38, 39, 41, 45, 46, 47, 50, 51, 52, 56, 59, 64, 65, 67, 69, 70, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 90, 92, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 108, 110, 111, 112, 113, 114, 115, 118, 119, 121, 122, 125, 134, 135, 137, 140, 144, 146, 148, 149, 151, 154, 155, 160, 163, 164, 167, 168, 171, 172, 175, 176, 177, 178, 179, 181, 182, 185, 187, 189, 191, 192, 204, 207, 210, 216, 222, 224, 226, 231, 232, 233, 237, 240, 241, 243, 244, 245, 247, 248, 249, 254, 256, 258, 259, 261, 262, 263, 265, 267], "give": [19, 21, 22, 25, 30, 31, 34, 37, 38, 45, 49, 50, 52, 64, 65, 67, 73, 81, 87, 93, 94, 96, 100, 101, 103, 104, 108, 109, 121, 125, 134, 148, 149, 150, 151, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 171, 172, 173, 176, 177, 179, 181, 182, 183, 184, 186, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 204, 205, 208, 209, 210, 214, 215, 216, 217, 220, 221, 222, 223, 225, 227, 228, 229, 230, 232, 233, 235, 236, 238, 239, 240, 241, 243, 251, 255, 256, 263, 265, 289, 312, 344, 348, 356, 377], "automat": [19, 21, 22, 27, 103, 138, 144, 180, 217, 262, 263, 333, 338, 340, 345, 349, 358, 368, 370, 373, 386], "differenti": [19, 21, 22, 34, 35, 36, 37, 38, 39, 41, 47, 49, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 75, 77, 78, 81, 83, 84, 90, 91, 92, 94, 96, 101, 144, 148, 149, 151, 153, 154, 155, 156, 157, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 182, 185, 186, 187, 188, 189, 190, 192, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 207, 208, 209, 210, 211, 212, 214, 215, 216, 218, 219, 220, 221, 222, 223, 226, 227, 229, 231, 232, 235, 236, 239, 240], "manual": [19, 21, 22, 51, 64, 86, 100, 105, 108, 331, 332, 333, 335, 344, 351, 382], "battl": [19, 138, 193], "adam": [19, 20, 21, 22, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146], "momentum": [19, 21, 22, 31, 118, 136], "easi": [19, 22, 37, 49, 50, 65, 70, 73, 83, 84, 86, 89, 91, 92, 100, 101, 102, 117, 125, 142, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 165, 166, 167, 168, 173, 174, 177, 179, 180, 181, 182, 184, 186, 187, 188, 189, 192, 193, 197, 198, 199, 200, 201, 202, 203, 204, 205, 207, 208, 210, 211, 212, 213, 215, 216, 218, 219, 225, 226, 228, 233, 239, 240, 280, 332], "x_train_t": 19, "tensor": [19, 20, 22, 134, 136, 139, 140, 141, 142, 143, 144, 145, 146], "float32": [19, 20, 21, 22, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146], "y_train_t": 19, "x_val_t": 19, "y_val_t": 19, "x_test_t": 19, "y_test_t": 19, "train_load": [19, 20, 21, 22], "shuffl": [19, 20, 21, 22, 34, 37, 53, 64, 70, 73, 77, 78, 81, 110, 142, 143, 163, 238, 243, 253, 256, 257, 262, 263, 271], "val_load": 19, "256": [19, 21, 22, 35, 138, 141, 142, 144, 145, 148, 149, 156, 343, 354, 355], "torch_model": 19, "sequenti": [19, 21, 22, 109, 110, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 218, 232], "criterion": [19, 37, 49, 67, 74, 110, 118, 157, 247, 257], "bcewithlogitsloss": 19, "paramet": [1, 19, 20, 21, 22, 26, 28, 29, 34, 35, 36, 37, 39, 41, 46, 49, 50, 53, 56, 57, 59, 64, 65, 67, 69, 74, 75, 77, 78, 86, 87, 88, 92, 94, 96, 97, 98, 99, 100, 101, 104, 106, 110, 112, 113, 114, 115, 117, 118, 120, 122, 123, 124, 125, 127, 129, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 228, 242, 246, 247, 250, 251, 256, 263, 266, 268, 269, 284, 295, 310, 322, 338, 351, 356, 379], "03": [19, 21, 22, 28, 32, 35, 38, 39, 45, 110, 115, 116, 122, 123, 125, 132, 136, 143, 157, 186, 199, 200, 248, 249, 252, 261, 299, 327, 389, 394], "run_epoch": 19, "loader": [19, 20, 21, 22], "eval": [19, 20, 21, 22, 28, 134, 139, 140, 144], "total_loss": [19, 20, 140], "total_correct": 19, "zero_grad": [19, 20, 21, 22, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146], "backward": [19, 20, 21, 22, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146], "step": [19, 21, 22, 31, 32, 34, 35, 36, 39, 41, 47, 50, 51, 56, 64, 67, 73, 77, 78, 83, 86, 89, 90, 93, 94, 96, 97, 98, 99, 101, 102, 107, 109, 110, 111, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 129, 135, 136, 137, 138, 139, 140, 141, 144, 145, 149, 150, 158, 162, 164, 169, 177, 178, 184, 223, 226, 227, 231, 232, 233, 234, 235, 238, 239, 240, 241, 244, 248, 249, 256, 264, 265, 269, 270, 271, 280, 287, 299, 301, 306, 308, 310, 323, 326, 328, 332, 333, 346, 347, 370, 382], "no_grad": [19, 20, 21, 22, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146], "item": [19, 20, 21, 22, 27, 29, 32, 36, 37, 38, 41, 45, 47, 50, 53, 57, 69, 72, 73, 75, 84, 86, 89, 94, 100, 103, 107, 110, 113, 114, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 152, 157, 169, 180, 184, 185, 186, 189, 190, 197, 199, 201, 205, 208, 214, 216, 218, 219, 224, 225, 226, 232, 233, 234, 237, 240, 241, 242, 243, 248, 249, 252, 253, 254, 256, 258, 264, 267, 268, 295, 308, 312, 313, 314, 315, 316, 317, 339, 341], "torch_hist": 19, "120": [19, 20, 27, 28, 31, 51, 67, 70, 86, 87, 96, 97, 98, 100, 102, 105, 107, 109, 110, 115, 122, 123, 125, 127, 129, 131, 148, 149, 151, 155, 158, 166, 167, 168, 176, 177, 182, 185, 188, 192, 193, 196, 197, 200, 204, 205, 207, 208, 210, 218, 220, 222, 225, 233, 247, 250, 254, 262, 280, 284, 289, 301, 303, 305, 310, 317, 318, 323, 328, 394], "torch_predict_proba": 19, "xt": [19, 30], "detach": [19, 21, 22, 134, 136, 138, 140, 142, 144, 146], "probs_torch_test": 19, "preds_torch_test": 19, "torch_metr": 19, "toi": [19, 20, 21, 22, 26, 32, 35, 36, 38, 47, 50, 53, 59, 64, 65, 72, 74, 81, 83, 93, 99, 108, 139, 140, 146, 165, 178, 204, 227, 248, 253, 265], "both": [19, 20, 25, 26, 28, 32, 35, 38, 41, 46, 47, 49, 50, 53, 57, 59, 64, 65, 69, 70, 74, 75, 77, 81, 84, 86, 88, 89, 91, 92, 93, 97, 101, 103, 107, 110, 111, 113, 119, 122, 141, 143, 144, 145, 151, 152, 154, 155, 157, 159, 160, 166, 172, 174, 176, 177, 178, 179, 182, 187, 188, 192, 196, 199, 205, 207, 210, 211, 214, 216, 225, 226, 228, 231, 233, 236, 238, 239, 243, 245, 248, 251, 253, 254, 255, 256, 260, 262, 263, 267, 268, 270, 291, 310, 358, 371, 389], "outperform": [19, 302], "probabilist": [19, 34, 37, 38, 39, 41, 45, 46, 51, 56, 57, 67, 78, 108, 113, 153, 163, 280, 285, 308], "numpy_mlp": 19, "torch_mlp": 19, "test_acc": [19, 21, 22], "test_logloss": 19, "bar": [19, 21, 22, 26, 30, 32, 34, 37, 38, 41, 45, 47, 51, 56, 59, 77, 81, 83, 84, 86, 88, 89, 90, 92, 96, 99, 100, 101, 102, 104, 107, 108, 110, 111, 112, 114, 119, 120, 121, 122, 124, 127, 129, 131, 132, 144, 146, 151, 162, 167, 168, 169, 175, 178, 180, 183, 189, 190, 192, 194, 196, 209, 210, 213, 218, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 257, 259, 260, 261, 263, 265, 266, 268, 270, 280, 285, 286, 288, 311, 312, 313, 314, 315, 316, 317, 394], "lower": [19, 20, 21, 22, 32, 37, 38, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 72, 73, 74, 78, 86, 87, 88, 94, 95, 96, 103, 105, 106, 109, 110, 112, 116, 120, 124, 139, 141, 142, 143, 151, 152, 157, 158, 160, 168, 169, 171, 172, 173, 176, 178, 179, 180, 181, 184, 185, 190, 194, 195, 196, 197, 199, 200, 212, 213, 214, 215, 216, 217, 219, 221, 227, 228, 229, 231, 237, 246, 249, 250, 251, 252, 253, 255, 257, 258, 259, 260, 261, 268, 280, 288, 305], "better": [19, 21, 22, 25, 26, 32, 36, 37, 38, 41, 45, 46, 51, 53, 56, 57, 64, 72, 73, 74, 75, 78, 83, 86, 87, 88, 91, 92, 95, 96, 99, 100, 101, 106, 108, 112, 113, 116, 134, 138, 143, 144, 149, 158, 160, 170, 171, 175, 176, 182, 188, 198, 203, 206, 226, 237, 246, 253, 259, 261, 270, 280, 285, 295, 334, 358, 368, 371], "try": [19, 20, 21, 22, 25, 27, 28, 29, 31, 32, 35, 45, 46, 47, 50, 53, 57, 64, 65, 74, 83, 89, 90, 98, 102, 105, 107, 108, 109, 110, 112, 115, 116, 118, 120, 124, 134, 135, 137, 138, 139, 141, 142, 143, 144, 145, 174, 178, 185, 202, 214, 220, 225, 237, 238, 243, 246, 247, 248, 251, 253, 254, 258, 260, 262, 264, 265, 266, 267, 268, 269, 285, 286, 287, 288, 289, 292, 300, 301, 303, 306, 311, 312, 313, 314, 315, 316, 317, 318, 338, 355, 356, 381, 386], "instead": [19, 22, 27, 30, 31, 32, 36, 38, 41, 46, 49, 50, 51, 56, 59, 64, 65, 70, 72, 81, 83, 84, 91, 97, 98, 101, 102, 103, 104, 107, 108, 109, 113, 119, 124, 135, 141, 143, 144, 145, 153, 163, 165, 167, 169, 185, 186, 194, 201, 210, 217, 221, 222, 223, 231, 249, 253, 257, 260, 262, 263, 265, 266, 268, 269, 270, 332, 334, 339, 342, 343, 344, 351, 382], "hot": [19, 38, 46, 56, 57, 104, 108, 120, 139, 140, 230, 341, 382], "high": [19, 25, 28, 29, 32, 34, 35, 36, 37, 39, 41, 46, 47, 49, 52, 53, 57, 59, 64, 65, 72, 74, 77, 78, 81, 83, 84, 87, 89, 94, 106, 108, 109, 117, 122, 134, 138, 140, 141, 142, 143, 144, 145, 150, 151, 157, 159, 160, 164, 172, 173, 175, 178, 183, 189, 200, 204, 209, 223, 225, 226, 230, 236, 237, 238, 239, 241, 245, 248, 255, 258, 262, 268, 291, 305, 339, 340, 341, 344, 345, 348, 351, 352, 353, 355, 356, 357, 367, 382, 386, 394, 407], "cardin": [19, 340, 381, 386], "missing": [19, 122, 275], "indic": [19, 28, 29, 34, 35, 46, 53, 59, 64, 69, 73, 81, 94, 105, 115, 116, 119, 120, 122, 125, 129, 136, 138, 139, 160, 184, 185, 196, 201, 217, 221, 226, 230, 231, 254, 255, 258, 284, 287, 296, 303, 322, 331, 384, 394], "don": [19, 21, 22, 25, 26, 30, 31, 32, 36, 41, 46, 64, 69, 70, 74, 77, 78, 81, 83, 96, 98, 99, 104, 105, 107, 109, 110, 114, 143, 146, 151, 158, 163, 182, 192, 199, 212, 223, 227, 232, 242, 244, 252, 253, 255, 256, 257, 263, 266, 268, 270, 341, 342, 343, 347, 349, 355, 358, 379], "imput": [19, 122, 271, 281, 323, 326], "hope": 19, "weight": [19, 21, 22, 26, 27, 29, 30, 32, 34, 35, 36, 37, 38, 39, 45, 46, 47, 50, 51, 52, 53, 56, 57, 59, 64, 65, 72, 74, 77, 78, 84, 86, 87, 88, 90, 93, 95, 98, 99, 102, 103, 104, 106, 108, 109, 110, 111, 113, 114, 131, 134, 135, 136, 142, 152, 153, 157, 159, 167, 170, 177, 181, 182, 183, 191, 193, 194, 198, 208, 209, 211, 214, 232, 234, 242, 244, 255, 280, 301, 302, 393], "decai": [19, 22, 91, 92, 99, 103, 111, 112, 121, 142, 154, 155, 157, 160, 161, 162, 168, 173, 176, 177, 180, 181, 187, 188, 196, 204, 209, 210, 213, 216, 219, 227, 235, 240, 241], "dropout": [19, 20, 22, 223], "earli": [19, 20, 22, 36, 37, 117, 134, 138, 141, 143, 153, 161, 165, 201, 220, 339, 371, 381], "stop": [19, 36, 37, 110, 111, 134, 143, 165, 166, 225, 234, 255, 266, 304, 307, 342, 348, 358, 359, 381], "strong": [5, 19, 30, 32, 52, 57, 74, 86, 93, 98, 105, 108, 109, 110, 111, 112, 119, 121, 122, 125, 134, 140, 153, 155, 160, 162, 163, 164, 174, 187, 201, 205, 213, 214, 231, 242, 243, 244, 245, 248, 250, 252, 253, 258, 265, 267, 268, 280, 287, 289, 291, 294, 297, 298, 300, 302, 304, 307, 309, 327, 328, 331, 332, 333, 334, 359, 372, 406], "valid": [19, 22, 29, 30, 31, 34, 35, 36, 37, 39, 41, 45, 46, 47, 49, 50, 51, 53, 57, 59, 65, 67, 69, 74, 75, 78, 84, 86, 87, 91, 92, 93, 95, 96, 98, 99, 100, 101, 102, 110, 112, 119, 122, 123, 131, 135, 137, 138, 139, 143, 144, 145, 149, 152, 153, 154, 156, 159, 161, 162, 164, 165, 166, 167, 168, 169, 172, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 188, 190, 191, 192, 193, 195, 196, 197, 198, 200, 201, 203, 209, 211, 213, 215, 216, 217, 218, 222, 223, 226, 227, 229, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 248, 251, 254, 256, 262, 263, 269, 270, 285, 288, 299, 308, 319, 335, 350, 355, 356, 371, 381], "protocol": [19, 215, 234, 343, 345, 354], "more": [19, 21, 22, 25, 26, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 50, 51, 52, 53, 57, 59, 64, 65, 67, 69, 73, 74, 75, 77, 81, 86, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 123, 125, 132, 134, 138, 139, 141, 142, 143, 144, 145, 148, 150, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 181, 182, 184, 188, 190, 192, 193, 195, 196, 197, 198, 199, 200, 202, 204, 205, 206, 207, 208, 209, 211, 213, 214, 215, 218, 219, 220, 221, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 236, 237, 238, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 258, 259, 260, 263, 264, 266, 268, 269, 270, 280, 285, 288, 289, 302, 308, 310, 317, 329, 332, 333, 339, 343, 346, 347, 349, 353, 356, 374, 385], "than": [19, 20, 21, 22, 26, 31, 32, 34, 35, 37, 38, 39, 41, 45, 46, 49, 51, 56, 57, 59, 64, 65, 67, 69, 70, 74, 81, 83, 86, 87, 88, 89, 90, 91, 92, 93, 96, 97, 98, 99, 100, 101, 102, 105, 108, 109, 111, 112, 113, 114, 117, 118, 119, 121, 125, 129, 134, 143, 144, 145, 149, 150, 151, 153, 154, 155, 158, 159, 160, 161, 163, 164, 170, 171, 173, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186, 188, 195, 199, 200, 203, 206, 207, 209, 215, 217, 218, 220, 224, 225, 227, 228, 230, 231, 234, 236, 242, 244, 245, 246, 249, 250, 251, 252, 253, 256, 258, 259, 260, 261, 263, 265, 268, 269, 270, 280, 285, 304, 307, 319, 352, 355, 359, 383, 385], "doubt": [19, 165, 244, 250], "sweep": [19, 30, 31, 32, 35, 36, 39, 41, 50, 57, 65, 75, 78, 101, 103, 105, 109, 160, 301], "against": [19, 26, 30, 38, 41, 45, 49, 52, 57, 59, 69, 70, 89, 92, 95, 100, 102, 141, 145, 148, 150, 151, 152, 155, 156, 158, 160, 161, 163, 164, 166, 168, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 194, 195, 197, 198, 199, 200, 201, 202, 206, 207, 208, 210, 215, 216, 217, 219, 220, 222, 225, 227, 228, 234, 237, 238, 239, 241, 242, 243, 244, 245, 248, 249, 251, 252, 253, 254, 256, 258, 260, 261, 262, 263, 269, 328, 385], "calibr": [19, 35, 46, 47, 49, 50, 52, 56, 64, 65, 67, 88, 89, 90, 109, 113, 114, 115, 149, 151, 158, 163, 171, 176, 180, 196, 206, 209, 212, 213, 217, 218, 219, 229, 233, 244, 256], "your": [19, 20, 21, 22, 25, 29, 30, 32, 35, 37, 38, 39, 41, 45, 47, 50, 53, 57, 67, 83, 86, 87, 88, 90, 91, 93, 96, 97, 98, 101, 107, 110, 112, 113, 115, 122, 129, 145, 146, 149, 151, 152, 153, 154, 156, 158, 161, 162, 163, 169, 171, 173, 181, 187, 189, 190, 193, 198, 199, 212, 214, 215, 222, 225, 229, 234, 235, 242, 243, 244, 245, 246, 248, 250, 253, 255, 256, 257, 258, 261, 262, 263, 267, 268, 269, 270, 271, 280, 283, 284, 285, 287, 288, 295, 300, 304, 305, 307, 311, 312, 313, 314, 315, 316, 317, 318, 331, 332, 333, 334, 335, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 355, 357, 359, 367, 368, 372, 379, 383, 384], "drive": [19, 46, 122, 200, 254, 262, 271, 294, 340], "total": [19, 20, 30, 37, 41, 57, 67, 72, 73, 74, 75, 77, 78, 81, 84, 86, 100, 101, 122, 134, 139, 141, 142, 157, 159, 165, 167, 168, 193, 196, 197, 212, 215, 221, 224, 225, 228, 231, 232, 233, 234, 239, 240, 243, 245, 246, 247, 249, 251, 252, 255, 256, 257, 261, 270, 311], "doe": [19, 27, 28, 30, 31, 34, 35, 46, 47, 50, 51, 53, 57, 59, 69, 72, 73, 74, 77, 81, 89, 90, 97, 98, 99, 100, 103, 108, 112, 114, 122, 136, 138, 145, 146, 148, 150, 152, 154, 159, 160, 161, 163, 164, 166, 168, 170, 172, 174, 178, 179, 183, 184, 187, 188, 191, 192, 195, 199, 200, 204, 205, 206, 209, 210, 212, 217, 218, 220, 221, 222, 224, 226, 229, 230, 237, 238, 239, 240, 241, 242, 243, 244, 246, 248, 249, 253, 254, 255, 259, 265, 266, 267, 268, 269, 270, 271, 302, 304, 307, 310, 343, 346, 350, 351, 352, 353, 356, 357, 358, 369, 377], "replac": [19, 21, 22, 27, 28, 31, 32, 35, 41, 50, 53, 57, 59, 64, 69, 70, 72, 73, 75, 77, 78, 81, 83, 84, 86, 90, 91, 95, 99, 100, 104, 107, 110, 115, 116, 119, 122, 125, 132, 136, 138, 140, 143, 146, 154, 157, 171, 172, 185, 187, 189, 190, 225, 226, 229, 232, 234, 245, 251, 252, 253, 255, 257, 265, 266, 268, 333, 334, 348, 350, 359, 366, 375, 376, 378, 389], "tanh": [19, 20, 26, 64, 109, 134, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 212, 229, 255], "chang": [1, 5, 19, 20, 22, 25, 27, 28, 29, 31, 32, 34, 36, 37, 39, 45, 46, 47, 49, 50, 51, 52, 53, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 89, 90, 91, 96, 97, 99, 100, 103, 104, 105, 107, 108, 109, 110, 112, 116, 117, 119, 122, 123, 125, 134, 135, 136, 138, 139, 140, 141, 143, 144, 145, 146, 150, 153, 154, 155, 159, 160, 164, 165, 167, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 182, 184, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201, 202, 206, 207, 208, 209, 210, 212, 213, 214, 215, 216, 217, 219, 220, 222, 228, 229, 230, 233, 235, 238, 239, 240, 241, 242, 243, 244, 245, 249, 250, 251, 252, 253, 255, 256, 258, 259, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 275, 285, 287, 303, 310, 317, 331, 333, 334, 335, 338, 339, 347, 365, 368, 371, 375, 377, 381, 383], "speed": [19, 21, 31, 32, 110, 132, 134, 136, 167, 171, 172, 186, 193, 195, 201, 203, 216, 220, 266, 267, 287, 332, 386], "final": [19, 35, 39, 41, 46, 52, 56, 59, 67, 74, 81, 83, 84, 98, 100, 110, 141, 142, 144, 153, 157, 159, 165, 167, 179, 186, 188, 194, 214, 232, 240, 252, 263, 264, 371, 381, 386], "multiclass": [19, 41, 46, 50, 52, 64, 77], "softmax": [19, 21, 22, 46, 56, 90, 104, 134], "g": [19, 20, 22, 25, 26, 27, 28, 29, 31, 32, 35, 36, 37, 38, 39, 41, 45, 47, 49, 50, 51, 52, 53, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 127, 129, 134, 135, 136, 138, 139, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 179, 180, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 254, 256, 257, 258, 259, 261, 263, 264, 265, 266, 267, 268, 269, 295, 296, 317, 318, 320, 322, 334, 335, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350, 351, 353, 354, 355, 356, 357, 358, 359, 366, 368, 382, 384, 386], "uci": 19, "http": [0, 4, 19, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 96, 98, 99, 100, 101, 102, 134, 138, 139, 140, 141, 142, 144, 145, 146, 256, 285, 331, 332, 333, 334, 335, 337, 339, 350, 352, 354, 358, 359, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 381, 382, 383, 384, 385, 386, 403], "org": [19, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 96, 98, 99, 100, 101, 102, 138, 140, 141, 142, 144, 256, 331, 332, 334, 346], "doc": [17, 18, 19, 23, 24, 25, 26, 27, 29, 30, 32, 36, 37, 38, 40, 42, 43, 44, 46, 47, 48, 51, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 71, 72, 73, 76, 79, 80, 81, 82, 83, 84, 96, 99, 103, 105, 107, 109, 110, 133, 134, 138, 139, 140, 141, 143, 145, 147, 155, 161, 177, 178, 189, 204, 228, 246, 267, 270, 272, 273, 274, 276, 277, 278, 279, 282, 331, 332, 333, 334, 335, 338, 340, 341, 344, 347, 349, 350, 357, 358, 359, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 381, 382, 383, 384, 385, 386], "stabl": [19, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 98, 99, 100, 101, 102, 105, 106, 107, 111, 112, 113, 114, 116, 117, 122, 123, 148, 149, 151, 152, 154, 155, 158, 159, 160, 163, 164, 165, 166, 168, 171, 172, 174, 175, 178, 179, 181, 182, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 204, 205, 206, 207, 208, 210, 213, 214, 215, 216, 217, 218, 219, 220, 221, 224, 225, 227, 228, 232, 235, 236, 237, 238, 240, 241, 246, 247, 249, 251, 261, 262, 264, 270, 280, 288, 302, 317, 334, 335, 347, 359, 367, 374, 375, 377, 378, 381], "index": [19, 20, 25, 28, 29, 34, 36, 41, 47, 50, 56, 57, 68, 72, 73, 75, 78, 83, 84, 90, 91, 92, 96, 99, 101, 102, 112, 115, 116, 118, 120, 122, 124, 125, 127, 129, 131, 132, 138, 155, 160, 168, 172, 175, 178, 179, 182, 221, 222, 224, 227, 232, 234, 238, 242, 253, 275, 280, 281, 285, 287, 288, 289, 292, 293, 296, 297, 298, 300, 301, 302, 303, 304, 306, 307, 309, 310, 311, 313, 314, 315, 316, 317, 318, 323, 326, 327, 328, 329, 335, 339, 341, 351, 381, 384, 385, 394], "html": [19, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 96, 98, 99, 100, 101, 102, 134, 138, 139, 140, 144, 145, 285, 339, 382, 384, 385, 389, 393, 394], "goodfellow": [19, 20], "bengio": [19, 20], "courvil": [19, 20], "chapter": [19, 20, 113, 116], "scikit": [19, 29, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 66, 67, 68, 71, 72, 74, 75, 76, 77, 78, 79, 80, 82, 84, 85, 86, 90, 93, 95, 99, 100, 104, 106, 120, 127], "mlpclassifi": 19, "recurr": [20, 143, 151, 231, 237], "sequenc": [20, 110, 113, 125, 132, 143, 172, 222, 230, 237, 287, 290, 295, 296, 323], "carri": [20, 107, 113, 227, 263], "much": [20, 22, 26, 27, 30, 37, 41, 46, 47, 50, 74, 75, 77, 78, 83, 84, 87, 89, 91, 98, 99, 100, 102, 103, 105, 107, 113, 119, 124, 134, 135, 136, 137, 143, 146, 154, 160, 164, 168, 175, 182, 183, 219, 227, 228, 229, 237, 242, 246, 250, 261, 262, 265, 381], "easier": [20, 22, 25, 31, 67, 86, 87, 95, 137, 141, 148, 154, 174, 184, 212, 221, 255, 262, 264, 266], "season": [20, 112, 115, 119, 125, 129, 131, 132, 172, 242, 280, 296, 297, 298, 299, 301, 302, 304, 305, 306, 308, 309, 310], "delai": [20, 114, 122, 123, 138, 139, 163, 164, 169, 177, 178, 196, 216], "effect": [20, 26, 31, 32, 37, 47, 52, 72, 74, 81, 83, 84, 89, 91, 94, 97, 98, 99, 105, 107, 108, 109, 114, 115, 117, 118, 122, 123, 134, 143, 150, 154, 156, 160, 163, 165, 166, 167, 168, 169, 171, 173, 177, 180, 183, 184, 187, 188, 189, 190, 192, 193, 194, 197, 198, 200, 201, 202, 204, 206, 208, 209, 210, 220, 221, 224, 225, 239, 241, 242, 243, 246, 249, 250, 254, 257, 260, 261, 263, 264, 265, 266, 267, 268, 270], "regim": [20, 32, 35, 112, 119, 122, 161, 170, 205, 228, 259, 295, 310, 317, 322], "without": [20, 21, 22, 25, 26, 28, 30, 38, 50, 70, 75, 93, 94, 96, 100, 103, 105, 107, 108, 109, 110, 112, 114, 117, 122, 123, 125, 132, 134, 138, 139, 140, 146, 150, 153, 154, 161, 170, 182, 185, 189, 202, 205, 209, 211, 213, 214, 218, 226, 229, 232, 234, 236, 238, 243, 244, 245, 247, 253, 256, 260, 261, 262, 265, 266, 267, 280, 285, 289, 295, 309, 323, 335, 341, 342, 343, 346, 350, 351, 352, 353, 356, 358, 359, 365, 371, 376, 381, 382, 383, 384], "vanish": [20, 149, 163, 192, 202, 206, 211, 215], "explod": [20, 92, 93, 97, 112, 118, 138, 139, 143, 155, 164, 178, 230, 271, 285], "In": [20, 21, 22, 26, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 41, 46, 47, 52, 53, 56, 57, 59, 64, 67, 69, 70, 72, 73, 74, 75, 78, 81, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 117, 121, 122, 127, 131, 132, 134, 135, 136, 137, 138, 139, 141, 142, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 250, 251, 252, 254, 257, 260, 261, 266, 267, 268, 270, 271, 275, 281, 285, 290, 291, 293, 294, 295, 296, 297, 298, 302, 304, 307, 308, 309, 310, 319, 320, 321, 323, 324, 325, 326, 327, 335, 339, 340, 341, 343, 348, 349, 351, 352, 354, 356, 357, 374, 375, 382, 384, 386, 389], "pure": [20, 21, 22, 30, 53, 70, 72, 73, 75, 77, 84, 110, 112, 116, 171, 181, 211, 226, 252], "through": [3, 20, 22, 39, 46, 59, 93, 103, 109, 117, 129, 138, 139, 141, 148, 152, 171, 173, 179, 180, 186, 188, 199, 203, 209, 214, 215, 226, 270, 333, 354, 358, 369, 375, 386], "task": [20, 22, 33, 34, 49, 67, 68, 81, 84, 85, 96, 110, 121, 139, 140, 141, 152, 180, 183, 188, 190, 212, 236, 260, 266, 283, 296, 306, 311, 312, 313, 314, 315, 316, 317, 332, 333, 342, 343, 349, 350, 355, 356, 366, 368, 370, 371, 376], "reproduc": [20, 32, 65, 77, 86, 103, 129, 136, 139, 142, 148, 152, 153, 159, 160, 165, 166, 167, 173, 174, 177, 179, 181, 184, 185, 188, 193, 196, 198, 199, 200, 203, 210, 212, 215, 216, 220, 249, 250, 256, 263, 268, 271, 275, 281, 297, 298, 302, 304, 307, 309, 326, 346], "dynam": [20, 45, 111, 112, 116, 117, 118, 119, 125, 135, 141, 146, 189, 233, 237, 240, 287, 290, 295, 322, 323, 373, 379, 386], "sy": [20, 65, 75, 112, 117, 118, 123, 144, 146, 153, 170, 191, 195, 221, 223, 228, 230, 234, 235, 237, 238, 240, 246, 251, 255, 257, 261], "subplot": [20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 56, 57, 64, 67, 69, 70, 73, 74, 75, 77, 78, 81, 84, 86, 87, 88, 90, 92, 94, 95, 96, 97, 98, 100, 103, 104, 106, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 143, 144, 146, 149, 151, 155, 159, 163, 164, 167, 168, 171, 172, 175, 176, 177, 178, 179, 181, 182, 185, 189, 191, 192, 204, 207, 210, 216, 222, 224, 226, 231, 232, 233, 237, 239, 241, 244, 245, 247, 248, 254, 256, 258, 259, 261, 262, 263, 264, 265, 267, 271, 295, 297, 298, 308, 316, 323], "make_subplot": [20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 56, 57, 64, 67, 69, 70, 73, 74, 75, 77, 78, 81, 84, 86, 87, 88, 90, 92, 94, 95, 96, 97, 98, 100, 103, 104, 106, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 143, 144, 146, 149, 151, 155, 163, 164, 167, 168, 171, 172, 175, 176, 177, 178, 179, 181, 182, 185, 189, 191, 192, 204, 207, 210, 216, 222, 224, 226, 231, 232, 233, 237, 239, 241, 244, 245, 247, 248, 254, 256, 258, 259, 261, 262, 263, 264, 265, 267, 295, 308, 316, 323], "dataset": [20, 25, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 106, 107, 108, 109, 110, 125, 127, 131, 132, 150, 159, 167, 172, 173, 174, 195, 200, 205, 206, 208, 216, 228, 241, 244, 247, 248, 254, 255, 256, 257, 262, 264, 265, 267, 268, 270, 271, 281, 287, 288, 289, 290, 291, 293, 294, 295, 297, 298, 302, 303, 304, 307, 309, 310, 320, 321, 323, 324, 325, 326, 346, 348, 351, 352, 353], "print": [20, 21, 22, 25, 27, 28, 30, 31, 32, 34, 35, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 65, 67, 70, 72, 73, 75, 77, 78, 81, 83, 84, 86, 87, 88, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 117, 118, 119, 120, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 148, 149, 150, 151, 153, 154, 155, 156, 158, 159, 160, 162, 163, 164, 165, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 185, 186, 187, 189, 191, 192, 193, 194, 195, 196, 198, 201, 202, 203, 204, 206, 207, 209, 211, 212, 213, 217, 218, 220, 221, 222, 223, 224, 225, 227, 228, 229, 231, 234, 235, 237, 238, 240, 241, 242, 243, 244, 245, 246, 249, 251, 252, 253, 254, 255, 257, 258, 259, 261, 262, 265, 267, 268, 269, 270, 271, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 297, 298, 300, 301, 303, 304, 306, 307, 310, 311, 312, 313, 314, 315, 316, 317, 318, 320, 321, 324, 325, 339, 340, 346, 348, 349, 350, 351, 352, 353, 356], "python": [20, 65, 75, 112, 113, 114, 115, 117, 118, 123, 135, 136, 137, 138, 142, 143, 144, 146, 153, 155, 168, 170, 175, 177, 178, 181, 182, 185, 191, 192, 195, 204, 207, 209, 210, 221, 222, 223, 230, 234, 235, 237, 238, 240, 246, 251, 257, 261, 267, 269, 334, 338, 339, 341, 342, 344, 347, 348, 349, 350, 353, 354, 355, 357, 358, 359], "__version__": [20, 49, 53, 65, 75, 93, 101, 110, 112, 113, 117, 118, 120, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 142, 144, 146, 148, 151, 153, 154, 155, 158, 160, 162, 163, 165, 166, 168, 170, 173, 175, 176, 177, 178, 179, 181, 182, 183, 185, 187, 189, 191, 192, 193, 194, 195, 196, 198, 199, 202, 204, 207, 209, 210, 211, 212, 213, 216, 217, 218, 220, 221, 222, 223, 224, 225, 228, 234, 235, 237, 238, 240, 241, 246, 251, 254, 256, 257, 259, 261, 267, 268, 269], "window": [20, 99, 112, 129, 134, 136, 138, 139, 140, 142, 143, 144, 145, 178, 213, 216, 219, 231, 236, 239, 271, 280, 284, 286, 287, 289, 290, 292, 293, 306, 312, 322, 328, 351, 358, 368], "x_": [20, 21, 22, 27, 35, 59, 88, 89, 103, 105, 107, 109, 113, 114, 116, 118, 119, 122, 123, 141, 148, 149, 155, 159, 160, 163, 166, 172, 173, 179, 183, 184, 185, 190, 199, 201, 204, 215, 217, 220, 221, 223, 225, 228, 232, 233, 237, 238, 241, 242, 244, 252, 256, 259, 263, 267, 287, 289, 292, 293, 318, 327], "dot": [20, 28, 30, 34, 38, 47, 49, 50, 51, 52, 56, 57, 59, 67, 69, 70, 73, 74, 77, 78, 83, 86, 87, 88, 89, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 107, 108, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 139, 143, 146, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 250, 252, 254, 255, 256, 259, 262, 263, 266, 267, 268, 269, 270, 285, 286, 289, 295, 299, 301, 306, 308, 314, 322, 323, 327, 328], "x_t": [20, 112, 113, 114, 116, 118, 119, 120, 122, 123, 124, 129, 132, 141, 218, 239, 242, 250, 265, 296], "length": [20, 30, 35, 36, 39, 52, 64, 65, 72, 74, 78, 86, 89, 98, 101, 102, 103, 106, 108, 109, 112, 115, 116, 122, 123, 124, 125, 127, 129, 131, 134, 136, 138, 139, 141, 142, 143, 144, 145, 156, 165, 178, 185, 206, 207, 212, 213, 214, 222, 228, 230, 232, 236, 237, 244, 263, 266, 271, 286, 293, 295, 299, 306, 308, 310, 313, 314, 316, 318, 319], "target": [20, 21, 22, 28, 29, 31, 32, 45, 50, 56, 65, 78, 87, 88, 90, 93, 95, 96, 97, 98, 100, 102, 103, 105, 107, 110, 111, 112, 114, 117, 118, 121, 122, 123, 127, 129, 132, 134, 141, 143, 144, 146, 156, 158, 164, 176, 177, 181, 182, 196, 204, 209, 221, 232, 233, 234, 242, 247, 249, 258, 262, 269, 270, 285, 296, 306, 308, 312, 313, 315, 316, 317, 318, 319, 328, 331, 332, 335, 347, 348, 354, 368, 371, 386], "next": [20, 30, 101, 103, 111, 113, 114, 117, 122, 125, 127, 131, 132, 143, 144, 162, 192, 193, 211, 231, 233, 234, 237, 239, 244, 252, 271, 280, 356, 381], "simplest": [20, 34, 67, 100, 217], "readabl": [20, 22, 52, 105, 110, 155, 175, 178, 183, 207, 376], "make_toy_seri": 20, "int": [1, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 87, 90, 91, 95, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 261, 262, 263, 264, 266, 267, 268, 269, 270, 275, 280, 287, 292, 296, 301, 305, 306, 312, 313, 314, 315, 316, 317], "800": [20, 21, 35, 36, 41, 45, 46, 56, 69, 81, 83, 95, 98, 99, 106, 108, 117, 118, 121, 123, 146, 148, 149, 150, 151, 152, 154, 156, 157, 158, 164, 167, 168, 171, 172, 173, 174, 177, 181, 183, 185, 188, 193, 194, 195, 196, 200, 203, 204, 206, 208, 212, 213, 214, 215, 216, 217, 218, 219, 220, 222, 229, 255, 258, 261, 267], "15": [20, 27, 31, 32, 34, 35, 36, 39, 41, 46, 49, 50, 52, 53, 56, 57, 64, 67, 70, 75, 77, 81, 87, 88, 89, 92, 99, 101, 103, 104, 105, 107, 108, 109, 111, 112, 114, 116, 117, 118, 119, 120, 122, 123, 124, 127, 131, 132, 135, 137, 139, 141, 142, 145, 149, 150, 151, 153, 154, 155, 158, 159, 160, 162, 163, 165, 166, 167, 168, 169, 170, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 189, 191, 192, 193, 194, 195, 196, 198, 199, 201, 202, 204, 207, 209, 210, 211, 212, 213, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 237, 238, 239, 240, 241, 242, 246, 247, 250, 255, 259, 260, 261, 267, 268, 269, 270, 280, 295, 299, 305, 316, 319, 323, 346, 348, 386], "arang": [20, 21, 22, 27, 28, 29, 31, 32, 34, 36, 37, 41, 45, 46, 47, 52, 53, 56, 57, 59, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 89, 90, 91, 93, 95, 96, 99, 100, 101, 102, 104, 105, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 129, 131, 132, 134, 136, 139, 140, 141, 142, 143, 144, 145, 148, 152, 153, 154, 155, 156, 158, 160, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 205, 208, 209, 214, 215, 216, 218, 219, 220, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 246, 247, 248, 249, 251, 253, 254, 255, 256, 261, 263, 270, 280, 284, 289, 292, 293, 296, 299, 300, 301, 305, 306, 308, 312, 314, 315, 317, 318, 319, 322, 323, 327, 328, 329, 394], "trend": [20, 112, 113, 115, 116, 122, 124, 125, 127, 129, 131, 132, 172, 262, 280, 295, 296, 300, 301, 302, 306, 309, 316, 323, 327, 340, 381, 386], "non": [1, 20, 25, 27, 28, 31, 32, 33, 34, 35, 36, 39, 45, 46, 47, 52, 53, 57, 59, 64, 65, 67, 73, 74, 75, 83, 84, 86, 87, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 107, 108, 109, 110, 112, 113, 117, 118, 122, 123, 125, 139, 154, 157, 158, 162, 165, 166, 168, 170, 172, 173, 181, 185, 186, 187, 194, 199, 204, 205, 209, 210, 211, 212, 213, 221, 223, 225, 226, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 246, 248, 249, 250, 251, 252, 253, 254, 255, 257, 258, 259, 260, 261, 262, 264, 266, 267, 268, 269, 270, 271, 297, 298, 300, 343, 345, 346, 348, 349, 350, 351, 352, 354, 356, 357, 365], "trivial": [20, 28, 37, 41, 47, 57], "sin": [20, 25, 26, 27, 28, 89, 103, 105, 106, 109, 110, 115, 116, 120, 123, 124, 125, 127, 129, 131, 132, 149, 150, 151, 156, 161, 164, 168, 175, 178, 181, 194, 201, 204, 205, 206, 207, 216, 219, 238, 246, 248, 280, 284, 286, 287, 289, 295, 296, 299, 300, 301, 305, 306, 308, 312, 313, 314, 315, 316, 317, 318, 319, 322, 323, 327, 328, 329], "pi": [20, 25, 26, 27, 28, 35, 36, 41, 47, 57, 84, 89, 103, 105, 106, 108, 115, 116, 117, 120, 123, 124, 125, 127, 129, 131, 132, 134, 136, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 155, 156, 157, 158, 160, 161, 164, 165, 167, 168, 172, 175, 178, 179, 181, 183, 185, 186, 188, 189, 190, 192, 194, 195, 197, 199, 201, 203, 204, 205, 206, 207, 208, 210, 214, 218, 219, 221, 222, 230, 232, 236, 237, 246, 248, 254, 258, 261, 264, 266, 267, 268, 269, 280, 286, 287, 289, 295, 296, 299, 300, 301, 305, 306, 308, 313, 316, 318, 319, 323, 327, 328, 329, 389], "17": [20, 70, 75, 89, 131, 135, 141, 142, 149, 155, 156, 158, 171, 178, 179, 187, 188, 201, 210, 217, 225, 227, 228, 231, 237, 240, 250, 253, 266, 358], "8": [20, 26, 27, 28, 29, 30, 31, 32, 36, 39, 41, 49, 50, 51, 56, 59, 65, 67, 72, 75, 81, 83, 86, 87, 88, 90, 91, 95, 99, 100, 106, 107, 110, 114, 115, 120, 122, 125, 135, 136, 138, 139, 141, 144, 146, 228, 246, 253, 258, 263, 269, 270, 275, 281, 284, 292, 293, 296, 297, 298, 299, 302, 303, 304, 305, 306, 307, 309, 310, 312, 313, 314, 315, 316, 317, 318, 323, 326, 327, 328, 329, 338, 349, 389], "0025": 20, "make_window": 20, "series_1d": 20, "ndarrai": [20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 38, 41, 46, 49, 52, 57, 65, 69, 70, 73, 75, 77, 86, 88, 95, 96, 97, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 129, 131, 132, 134, 138, 139, 140, 141, 142, 143, 144, 148, 151, 152, 153, 155, 156, 157, 158, 159, 160, 162, 163, 165, 166, 168, 170, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 188, 189, 192, 193, 194, 195, 196, 198, 199, 200, 202, 203, 204, 207, 209, 210, 211, 212, 213, 215, 216, 217, 220, 221, 222, 223, 224, 227, 228, 229, 232, 234, 235, 237, 238, 240, 241, 249, 250, 251, 252, 253, 254, 257, 258, 259, 261, 264, 266, 267, 268, 269, 270], "seq_len": 20, "target_idx": [20, 125], "len": [20, 21, 22, 25, 27, 29, 30, 31, 32, 34, 36, 37, 45, 47, 50, 52, 53, 56, 59, 64, 69, 70, 73, 75, 81, 83, 86, 87, 90, 91, 93, 95, 96, 97, 98, 99, 101, 102, 103, 104, 109, 110, 112, 114, 116, 117, 118, 119, 123, 124, 125, 127, 131, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 151, 154, 155, 156, 157, 162, 165, 173, 175, 179, 181, 185, 187, 188, 196, 204, 222, 224, 227, 231, 232, 236, 239, 242, 243, 244, 246, 249, 250, 252, 253, 255, 257, 259, 260, 269, 275, 280, 285, 286, 287, 289, 292, 293, 296, 299, 301, 303, 306, 310, 311, 312, 314, 384, 393], "none": [20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 67, 69, 70, 72, 73, 74, 75, 77, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 161, 164, 165, 167, 168, 169, 170, 171, 172, 173, 175, 177, 179, 180, 181, 184, 185, 186, 187, 189, 190, 191, 192, 194, 195, 197, 200, 201, 202, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 218, 219, 220, 221, 222, 225, 228, 229, 230, 233, 236, 237, 238, 240, 243, 244, 246, 247, 249, 250, 251, 253, 255, 256, 257, 258, 260, 262, 263, 264, 265, 266, 268, 270, 285, 306, 310, 312, 313, 314, 315, 316, 317, 327, 345, 358, 359, 377, 378, 394], "900": [20, 28, 31, 32, 37, 39, 46, 53, 67, 74, 75, 83, 104, 105, 106, 108, 115, 116, 123, 144, 149, 152, 157, 158, 164, 165, 167, 172, 173, 174, 176, 178, 179, 180, 181, 187, 188, 191, 192, 193, 200, 204, 206, 208, 210, 215, 218, 220, 222, 225, 229, 245, 248, 250, 255, 264, 268], "18": [20, 25, 27, 29, 53, 74, 75, 78, 83, 86, 95, 103, 105, 117, 120, 122, 123, 124, 125, 131, 135, 141, 142, 153, 160, 163, 166, 193, 197, 201, 212, 217, 224, 226, 229, 230, 231, 233, 234, 235, 247, 249, 250, 255, 260, 266, 268], "split_t": 20, "train_mean": 20, "train_std": 20, "std": [20, 26, 27, 35, 36, 37, 38, 39, 41, 45, 46, 49, 51, 53, 56, 57, 65, 67, 69, 70, 72, 73, 74, 78, 83, 89, 91, 92, 93, 95, 101, 103, 107, 113, 117, 120, 122, 124, 125, 127, 129, 131, 132, 134, 136, 138, 140, 142, 143, 144, 146, 157, 163, 174, 175, 178, 181, 183, 185, 188, 192, 194, 197, 203, 208, 210, 214, 215, 218, 225, 232, 236, 242, 243, 245, 248, 252, 254, 256, 258, 261, 264, 266, 267, 268, 269, 286, 289, 294, 305, 318, 328, 329], "y_scale": 20, "60": [20, 21, 22, 25, 26, 31, 35, 36, 37, 41, 45, 47, 50, 52, 53, 59, 64, 70, 72, 73, 78, 84, 87, 90, 92, 96, 98, 99, 100, 101, 102, 104, 107, 108, 109, 111, 116, 117, 120, 122, 123, 125, 127, 129, 131, 132, 134, 136, 140, 142, 144, 149, 150, 152, 153, 156, 162, 164, 165, 167, 170, 171, 172, 174, 175, 176, 179, 184, 185, 188, 189, 197, 206, 208, 212, 214, 215, 221, 226, 228, 232, 233, 234, 235, 237, 238, 240, 241, 242, 243, 246, 247, 248, 249, 250, 253, 254, 255, 256, 257, 258, 262, 263, 264, 265, 267, 269, 271, 288, 296, 310, 312, 313, 317, 318, 319, 340, 350, 355, 389], "y_all": [20, 21, 22, 31, 125], "train_mask": 20, "test_mask": 20, "t_train": 20, "t_test": [20, 112, 125, 127, 129, 131, 132], "add_vlin": [20, 31, 34, 36, 37, 38, 39, 41, 46, 49, 50, 51, 52, 53, 56, 57, 64, 65, 67, 69, 74, 75, 77, 78, 84, 86, 87, 88, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 110, 112, 115, 117, 122, 123, 125, 142, 143, 148, 149, 150, 151, 155, 160, 161, 162, 163, 164, 169, 172, 173, 174, 175, 176, 177, 178, 179, 181, 183, 184, 186, 193, 194, 196, 197, 198, 200, 204, 206, 211, 212, 213, 215, 216, 218, 220, 223, 226, 227, 229, 231, 232, 233, 234, 235, 236, 238, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 265, 266, 268, 270, 280, 292, 308, 317, 322], "line_dash": [20, 29, 31, 34, 36, 37, 39, 41, 46, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 74, 75, 77, 78, 84, 86, 87, 88, 90, 93, 94, 96, 97, 98, 99, 100, 101, 102, 110, 112, 115, 117, 122, 123, 125, 142, 146, 148, 149, 151, 160, 161, 162, 163, 164, 169, 172, 173, 174, 176, 177, 179, 181, 183, 184, 186, 193, 194, 196, 197, 198, 200, 204, 211, 212, 213, 215, 216, 217, 218, 220, 222, 223, 226, 227, 229, 231, 232, 233, 234, 235, 236, 238, 240, 241, 243, 245, 246, 247, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 268, 270, 280, 292, 308, 317, 322], "dash": [20, 29, 31, 34, 35, 36, 37, 38, 39, 41, 45, 46, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 74, 75, 77, 78, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 109, 110, 111, 112, 113, 114, 116, 117, 118, 120, 121, 122, 123, 124, 125, 127, 131, 132, 142, 143, 146, 148, 149, 150, 151, 155, 160, 161, 164, 166, 167, 169, 170, 173, 174, 175, 176, 177, 178, 179, 181, 183, 184, 186, 191, 193, 196, 197, 198, 200, 202, 204, 206, 210, 211, 212, 213, 215, 216, 217, 218, 220, 222, 223, 226, 227, 229, 231, 232, 233, 234, 235, 236, 238, 240, 241, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 280, 292, 308, 312, 313, 314, 317, 319, 322, 327, 328], "line_color": [20, 29, 31, 34, 36, 37, 39, 41, 46, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 74, 75, 77, 78, 84, 86, 87, 88, 90, 93, 94, 96, 97, 98, 99, 100, 101, 102, 110, 112, 115, 117, 122, 123, 125, 142, 146, 148, 149, 151, 160, 161, 164, 169, 172, 174, 176, 177, 179, 181, 184, 186, 193, 196, 197, 198, 200, 204, 212, 215, 217, 218, 220, 223, 226, 227, 229, 232, 233, 234, 235, 236, 238, 240, 241, 242, 243, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 270, 280, 292, 308, 317, 322], "vanilla": [20, 135, 136, 143, 149, 164], "h_t": [20, 121], "anh": 20, "w_x": [20, 232], "w_h": 20, "h_": [20, 111, 121, 184, 241, 249, 257], "b": [20, 21, 22, 26, 27, 29, 36, 38, 39, 47, 50, 51, 52, 53, 56, 57, 67, 69, 70, 72, 73, 75, 77, 78, 87, 89, 91, 92, 94, 96, 98, 101, 102, 104, 105, 107, 108, 109, 110, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 125, 127, 129, 131, 132, 134, 135, 139, 146, 149, 150, 151, 152, 154, 157, 160, 163, 167, 168, 170, 171, 172, 174, 176, 181, 182, 184, 185, 187, 188, 189, 191, 192, 193, 194, 196, 199, 200, 202, 203, 204, 207, 209, 210, 211, 212, 215, 217, 219, 222, 223, 224, 228, 238, 240, 243, 245, 248, 249, 250, 251, 252, 253, 254, 256, 257, 258, 259, 260, 261, 262, 264, 266, 268, 269, 284, 287, 288, 295, 296, 313, 316, 317, 318, 322, 349, 355, 372], "backpropag": [20, 21, 136], "repeat": [20, 29, 32, 64, 70, 72, 73, 77, 78, 81, 84, 99, 102, 104, 107, 116, 149, 158, 161, 164, 167, 169, 180, 190, 204, 223, 224, 226, 231, 233, 234, 241, 243, 245, 246, 255, 256, 257, 260, 263, 265, 267, 268, 269, 286, 296, 299, 331, 335, 338, 339], "jacobian": [20, 151, 159, 165, 166, 167, 168, 173, 183, 197, 201, 202, 204, 205, 216], "lead": [20, 29, 45, 56, 57, 59, 86, 87, 94, 102, 113, 125, 144, 151, 167, 173, 176, 185, 190, 191, 193, 205, 218, 220, 224, 245, 374], "almost": [20, 22, 46, 89, 100, 103, 105, 107, 109, 150, 163, 186, 211, 223, 227, 230, 239, 248, 266, 268, 269, 333], "signal": [20, 30, 36, 89, 107, 108, 110, 112, 113, 122, 123, 134, 135, 140, 142, 151, 156, 157, 161, 166, 176, 190, 191, 192, 193, 194, 195, 201, 205, 222, 229, 242, 250, 257, 267, 317, 322, 340, 383, 386], "unstabl": [20, 21, 22, 26, 28, 39, 41, 45, 57, 89, 90, 92, 99, 106, 107, 114, 117, 122, 134, 140, 142, 146, 148, 155, 168, 171, 175, 177, 178, 179, 182, 184, 187, 191, 195, 196, 204, 205, 210, 213, 217, 220, 227, 228, 240], "updat": [4, 20, 22, 25, 26, 29, 39, 45, 73, 77, 83, 96, 104, 107, 109, 135, 138, 141, 146, 152, 153, 155, 162, 170, 182, 183, 185, 186, 189, 190, 194, 196, 198, 201, 212, 219, 220, 221, 225, 226, 230, 234, 269, 302, 331, 333, 334, 335, 338, 341, 343, 348, 349, 350, 356, 367, 376, 378], "clip": [20, 26, 34, 36, 37, 38, 41, 46, 49, 50, 53, 56, 57, 64, 67, 75, 77, 78, 84, 86, 87, 88, 93, 95, 97, 98, 102, 103, 104, 108, 109, 114, 134, 135, 136, 138, 139, 140, 141, 144, 145, 146, 149, 150, 151, 155, 156, 157, 159, 161, 163, 165, 168, 173, 175, 176, 178, 181, 182, 188, 194, 196, 198, 200, 202, 203, 204, 206, 207, 209, 212, 214, 215, 222, 223, 224, 226, 228, 237, 238, 240, 241, 242, 252, 253, 256, 264, 266, 267], "choos": [20, 26, 28, 30, 31, 34, 35, 36, 37, 39, 41, 49, 50, 51, 53, 57, 59, 64, 65, 67, 69, 70, 72, 75, 77, 78, 83, 87, 88, 94, 98, 99, 102, 104, 109, 112, 113, 115, 125, 127, 131, 134, 163, 168, 171, 181, 189, 193, 196, 199, 200, 206, 219, 222, 225, 229, 234, 238, 240, 241, 244, 245, 248, 249, 255, 266, 267, 269, 341, 342, 343, 344, 350, 351, 357, 385], "what": [2, 6, 17, 18, 20, 23, 24, 25, 26, 31, 32, 34, 35, 36, 39, 51, 52, 53, 59, 73, 74, 77, 86, 88, 90, 91, 97, 99, 100, 104, 108, 109, 122, 125, 131, 133, 134, 138, 147, 158, 223, 228, 238, 246, 255, 272, 273, 274, 275, 276, 277, 278, 279, 282, 296, 308, 311, 373, 379, 381, 383], "overwrit": 20, "expos": [20, 45, 52, 57, 91, 92, 141, 142, 143, 149, 151, 156, 162, 164, 165, 172, 180, 186, 192, 195, 203, 204, 207, 209, 213, 222, 223, 224, 226, 227, 228, 229, 230, 231, 232, 234, 239, 261, 285, 288, 295, 322, 335, 357, 377, 381, 386], "c_t": 20, "term": [20, 22, 28, 33, 38, 41, 43, 45, 46, 50, 52, 64, 69, 70, 77, 78, 83, 86, 87, 93, 95, 97, 98, 100, 102, 103, 106, 107, 109, 112, 113, 115, 116, 118, 122, 123, 124, 140, 143, 144, 148, 151, 153, 156, 158, 160, 163, 164, 165, 167, 168, 170, 171, 172, 175, 177, 179, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 199, 203, 204, 208, 209, 213, 215, 216, 219, 221, 225, 228, 229, 231, 232, 240, 242, 244, 246, 250, 254, 255, 256, 271, 323, 339, 352, 382], "With": [20, 27, 34, 45, 50, 53, 56, 57, 59, 67, 75, 78, 81, 84, 86, 87, 89, 90, 91, 94, 95, 96, 97, 98, 99, 101, 102, 105, 107, 108, 111, 118, 131, 134, 140, 143, 153, 154, 158, 159, 161, 165, 167, 170, 171, 172, 174, 176, 177, 178, 179, 185, 188, 189, 190, 196, 198, 200, 201, 204, 210, 213, 214, 215, 216, 217, 220, 221, 223, 224, 226, 227, 228, 229, 232, 233, 235, 236, 240, 241, 242, 243, 247, 248, 251, 252, 253, 254, 255, 256, 257, 258, 260, 262, 267, 280, 342], "z_t": [20, 111, 121, 230, 303], "concaten": [20, 21, 22, 35, 37, 39, 41, 49, 53, 57, 59, 67, 70, 72, 81, 84, 90, 101, 102, 107, 109, 110, 111, 112, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 129, 139, 141, 144, 151, 161, 163, 165, 170, 174, 182, 184, 204, 208, 220, 221, 227, 243, 245, 246, 248, 252, 256, 257, 260, 263, 266, 267, 296, 299, 305, 306], "equat": [20, 109, 117, 118, 122, 138, 144, 145, 148, 153, 155, 158, 161, 169, 197, 202, 213, 215, 220, 221, 227, 232, 233, 240], "egin": [20, 81, 152, 156, 217], "i_t": 20, "w_i": [20, 28, 34, 45, 46, 65, 67, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 125, 167], "b_i": 20, "ext": [20, 81, 152, 193, 217, 231, 261, 264, 267, 270, 289, 310], "f_t": [20, 111, 192, 214, 250], "w_f": 20, "b_f": 20, "forget": [20, 112, 209, 268], "o_t": [20, 141], "w_o": 20, "b_o": 20, "g_t": [20, 134, 139], "w_g": 20, "b_g": 20, "candid": [20, 26, 30, 59, 65, 89, 110, 115, 120, 124, 152, 158, 160, 168, 199, 206, 218, 238, 240, 285, 292, 301, 333], "odot": [20, 45, 263], "inform": [20, 22, 25, 45, 47, 49, 50, 53, 59, 64, 65, 68, 72, 73, 77, 79, 103, 107, 109, 110, 111, 112, 113, 114, 118, 121, 122, 146, 150, 151, 155, 157, 165, 172, 179, 194, 204, 210, 214, 217, 219, 221, 230, 232, 238, 240, 241, 254, 263, 264, 270, 294], "write": [3, 5, 20, 22, 28, 32, 51, 56, 67, 72, 86, 95, 98, 102, 107, 114, 122, 135, 137, 138, 140, 145, 148, 149, 150, 151, 152, 153, 154, 155, 158, 160, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 185, 186, 187, 189, 190, 191, 192, 193, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 208, 209, 210, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 240, 242, 251, 257, 267, 269, 332, 334, 335, 341, 345, 348, 352, 358, 373, 383, 385, 386], "merg": [20, 25, 72, 81, 159, 230, 246, 332], "w_z": 20, "b_z": 20, "r_t": [20, 111, 116, 121, 134, 136, 140, 141, 143, 394], "w_r": 20, "b_r": [20, 123], "reset": [20, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146], "ild": 20, "_t": [20, 113, 117, 118, 120, 121, 122, 123, 125, 134, 139, 140, 141, 142, 143, 280, 284, 285, 296, 328], "b_h": [20, 123], "interpol": [20, 27, 103, 173, 199, 267], "between": [20, 26, 29, 31, 32, 35, 38, 41, 52, 53, 57, 65, 68, 69, 70, 74, 75, 78, 79, 81, 83, 91, 93, 94, 95, 96, 101, 102, 103, 104, 105, 106, 107, 110, 113, 117, 122, 125, 132, 146, 157, 161, 162, 169, 172, 173, 177, 183, 185, 188, 199, 200, 203, 204, 209, 211, 213, 214, 216, 221, 224, 228, 229, 231, 234, 240, 243, 244, 248, 249, 252, 255, 256, 257, 259, 261, 262, 263, 265, 266, 267, 268, 270, 280, 285, 288, 290, 331, 347, 352, 353, 356, 358, 371, 373, 375, 379], "old": [20, 21, 22, 73, 134, 135, 140, 142, 143, 146, 263, 367, 370, 382], "vs": [1, 2, 20, 21, 34, 35, 37, 39, 47, 52, 53, 57, 59, 64, 65, 72, 74, 75, 81, 83, 86, 87, 88, 89, 90, 92, 94, 95, 96, 98, 99, 100, 103, 104, 108, 109, 111, 119, 121, 124, 125, 127, 129, 134, 138, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 222, 223, 225, 226, 227, 228, 229, 232, 234, 235, 236, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 251, 254, 256, 257, 258, 259, 262, 268, 269, 270, 280, 281, 288, 296, 297, 298, 301, 302, 304, 307, 309, 312, 314, 318, 319, 322, 323, 331, 332, 335, 341, 344, 352, 358, 379, 382, 398, 401, 402, 406, 409], "decid": [20, 30, 49, 50, 53, 89, 106, 107, 122, 123, 159, 161, 225, 242, 248, 253, 308, 331, 339], "tini": [20, 28, 29, 31, 32, 36, 46, 49, 53, 64, 70, 75, 77, 78, 81, 84, 86, 87, 91, 92, 94, 95, 97, 99, 108, 110, 135, 137, 138, 139, 144, 148, 150, 154, 161, 162, 163, 164, 172, 173, 182, 188, 189, 193, 198, 200, 209, 212, 214, 215, 216, 220, 221, 226, 227, 233, 236, 237, 240, 242, 246, 248, 251, 252, 253, 254, 256, 258, 262, 264, 265, 266, 270, 280, 334], "numpylstmforecast": 20, "numpygruforecast": 20, "take": [20, 27, 28, 30, 36, 38, 51, 56, 70, 74, 77, 78, 91, 99, 107, 108, 119, 125, 134, 136, 139, 143, 145, 148, 152, 153, 156, 160, 161, 164, 166, 167, 172, 180, 184, 186, 193, 194, 198, 199, 200, 201, 203, 204, 205, 206, 213, 215, 217, 219, 222, 226, 228, 233, 234, 238, 250, 255, 261, 264, 265, 333, 344, 350, 351, 393], "run": [4, 20, 21, 22, 25, 26, 27, 31, 36, 46, 57, 69, 70, 73, 75, 77, 81, 83, 84, 111, 113, 114, 116, 121, 122, 132, 134, 136, 138, 140, 141, 142, 143, 145, 146, 148, 149, 155, 160, 164, 167, 173, 175, 178, 179, 180, 195, 196, 206, 220, 223, 225, 230, 236, 242, 246, 248, 249, 250, 251, 253, 254, 255, 259, 264, 266, 267, 268, 285, 287, 289, 303, 331, 332, 333, 334, 335, 338, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 367, 368, 370, 374, 375, 376, 382, 385], "head": [20, 21, 22, 115, 116, 118, 122, 134, 137, 140, 142, 222, 241, 243, 253, 271, 285, 286, 303, 306, 311, 312, 313, 314, 315, 316, 317, 323, 327, 328, 329, 332], "last": [20, 75, 94, 107, 112, 114, 116, 119, 121, 125, 127, 131, 132, 135, 136, 137, 142, 143, 145, 146, 153, 160, 161, 167, 201, 207, 209, 213, 217, 225, 227, 230, 232, 234, 250, 261, 264, 271, 275, 281, 290, 291, 293, 294, 296, 297, 298, 301, 302, 303, 304, 305, 307, 308, 309, 310, 319, 320, 321, 323, 324, 325, 326, 381, 384, 389], "also": [20, 25, 30, 31, 32, 33, 36, 37, 45, 49, 50, 52, 56, 57, 67, 69, 72, 73, 75, 77, 83, 86, 88, 90, 92, 96, 97, 98, 101, 103, 106, 108, 110, 112, 116, 125, 127, 134, 136, 141, 142, 143, 145, 150, 151, 154, 159, 160, 163, 164, 165, 167, 168, 169, 171, 172, 174, 175, 176, 177, 178, 181, 183, 184, 187, 188, 189, 190, 192, 193, 194, 195, 198, 199, 202, 207, 208, 209, 211, 212, 213, 215, 216, 217, 218, 219, 220, 223, 225, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 245, 246, 247, 250, 251, 253, 255, 256, 257, 261, 263, 264, 266, 267, 268, 269, 289, 304, 307, 320, 334, 339, 340, 349, 351, 354, 358, 369, 383], "mse_loss": [20, 134, 138, 140, 141, 142, 143, 144, 145, 146], "y_hat": [20, 28, 38, 41, 49, 51, 53, 69, 75, 86, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 102, 110, 112, 117, 118, 123, 125, 127, 131, 262, 327], "diff": [20, 34, 35, 36, 47, 59, 64, 65, 74, 77, 78, 83, 88, 93, 94, 97, 98, 102, 106, 115, 119, 122, 132, 158, 161, 172, 173, 174, 175, 176, 177, 184, 189, 195, 201, 206, 207, 209, 212, 225, 229, 239, 249, 256, 257, 263, 266, 267, 268, 270, 280, 297, 298, 315, 323, 331, 334, 335], "dy": [20, 31, 119, 165, 172, 173, 174, 176, 178, 180, 183, 187, 188, 190, 207, 219, 255], "clip_grads_": 20, "max_norm": [20, 139, 141], "total_sq": 20, "total_norm": 20, "12": [20, 21, 22, 25, 26, 28, 29, 30, 31, 32, 37, 38, 39, 45, 46, 47, 50, 52, 53, 59, 64, 65, 67, 70, 72, 74, 75, 78, 81, 83, 84, 86, 89, 90, 91, 92, 93, 103, 104, 105, 107, 109, 112, 114, 115, 116, 117, 118, 119, 122, 123, 125, 127, 129, 131, 132, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 228, 242, 243, 246, 248, 250, 251, 253, 254, 255, 256, 257, 260, 261, 267, 269, 271, 280, 286, 296, 297, 298, 299, 301, 302, 303, 305, 306, 307, 308, 309, 310, 312, 315, 317, 323, 328, 329, 349, 358, 359, 389, 393], "k": [20, 21, 22, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 41, 46, 49, 51, 52, 57, 59, 66, 67, 69, 70, 75, 78, 86, 90, 93, 94, 97, 98, 99, 100, 103, 104, 106, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 131, 132, 134, 139, 140, 141, 143, 144, 146, 148, 150, 151, 152, 153, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 168, 169, 171, 172, 173, 174, 177, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 195, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 209, 210, 211, 213, 214, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 249, 251, 252, 253, 254, 255, 256, 257, 258, 259, 261, 263, 264, 271, 288, 295, 300, 308, 319, 322, 327, 345, 371, 389], "init_weight": 20, "gener": [20, 21, 22, 29, 35, 36, 37, 38, 39, 45, 46, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 73, 74, 77, 78, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 98, 100, 103, 107, 108, 112, 113, 118, 120, 124, 127, 129, 131, 132, 136, 139, 141, 142, 143, 144, 146, 228, 242, 245, 247, 249, 250, 254, 256, 259, 261, 262, 263, 265, 266, 267, 268, 269, 271, 295, 304, 305, 307, 308, 322, 323, 331, 332, 334, 335, 343, 346, 350, 352, 355, 359, 365, 366, 371], "fan_in": [20, 21, 22], "fan_out": [20, 21, 22], "xavier": 20, "glorot": 20, "uniform": [20, 25, 26, 29, 31, 34, 38, 45, 46, 59, 78, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 107, 109, 110, 114, 131, 139, 140, 141, 144, 146, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 164, 165, 167, 168, 169, 171, 172, 173, 174, 176, 178, 181, 182, 186, 187, 190, 194, 195, 198, 199, 200, 201, 202, 203, 204, 207, 208, 209, 211, 212, 213, 214, 215, 218, 219, 220, 222, 223, 226, 227, 230, 232, 233, 234, 237, 240, 241, 251, 253, 256, 258, 262, 265, 266, 267, 301, 318], "__init__": [20, 21, 22, 27, 28, 105, 106, 110, 115, 120, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 201, 389], "beta": [20, 31, 33, 37, 46, 49, 50, 72, 88, 95, 104, 109, 112, 115, 118, 119, 121, 122, 136, 143, 146, 148, 150, 153, 154, 157, 158, 159, 160, 161, 163, 168, 170, 171, 173, 174, 178, 179, 186, 191, 197, 198, 200, 206, 210, 211, 212, 214, 217, 218, 220, 222, 227, 228, 231, 236, 237, 239, 240, 303, 327, 394], "tupl": [20, 21, 22, 25, 27, 28, 29, 31, 32, 41, 52, 69, 70, 103, 107, 110, 117, 118, 119, 120, 123, 124, 125, 127, 129, 131, 132, 134, 138, 139, 140, 141, 143, 144, 145, 148, 151, 153, 155, 156, 157, 159, 160, 161, 163, 165, 168, 169, 173, 174, 175, 176, 177, 178, 181, 182, 185, 189, 190, 192, 194, 195, 196, 197, 199, 200, 201, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 220, 221, 222, 227, 228, 230, 231, 236, 237, 238, 240, 241, 249, 252, 254, 266, 267, 268, 285, 312, 313, 314, 315, 316, 317], "9": [20, 21, 22, 27, 28, 36, 39, 41, 47, 49, 51, 56, 59, 64, 65, 67, 70, 72, 75, 77, 81, 83, 84, 87, 90, 91, 97, 100, 103, 104, 107, 108, 115, 118, 122, 123, 124, 125, 131, 135, 136, 137, 138, 141, 144, 145, 146, 228, 245, 246, 256, 258, 261, 269, 271, 280, 284, 286, 305, 310, 314, 317, 322, 323, 328, 329, 389, 393], "999": [20, 39, 49, 57, 108, 140, 148, 161, 163, 164, 171, 174, 179, 180, 181, 182, 186, 188, 193, 195, 197, 198, 199, 200, 201, 202, 213, 219, 224, 225, 231, 233, 239, 244, 253, 261], "ep": [20, 21, 22, 26, 29, 31, 34, 36, 37, 38, 39, 46, 49, 50, 53, 56, 57, 65, 67, 69, 75, 77, 78, 83, 90, 92, 93, 95, 97, 102, 104, 105, 111, 112, 114, 116, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 136, 138, 139, 141, 142, 143, 144, 149, 150, 155, 159, 163, 165, 166, 168, 175, 176, 178, 179, 181, 182, 200, 202, 207, 222, 223, 225, 242, 246, 252, 389], "beta1": [20, 94, 107, 157, 168, 236, 239], "beta2": [20, 50, 239, 248, 264], "m": [20, 25, 26, 27, 28, 30, 32, 35, 36, 39, 46, 47, 52, 57, 69, 70, 74, 75, 77, 81, 83, 84, 86, 87, 91, 99, 100, 103, 105, 108, 109, 110, 112, 113, 116, 117, 118, 119, 120, 123, 124, 125, 127, 129, 131, 132, 142, 143, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 169, 170, 171, 174, 175, 176, 178, 180, 183, 184, 186, 187, 192, 193, 194, 195, 196, 197, 198, 201, 203, 204, 205, 207, 209, 211, 212, 214, 216, 217, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 247, 249, 252, 254, 255, 256, 259, 261, 270, 280, 287, 296, 300, 301, 303, 306, 358, 359, 383], "zeros_lik": [20, 21, 22, 31, 34, 37, 41, 47, 49, 57, 59, 67, 72, 75, 78, 81, 84, 87, 88, 89, 93, 95, 97, 98, 110, 116, 118, 119, 140, 146, 148, 149, 150, 152, 153, 154, 156, 164, 165, 166, 167, 168, 169, 171, 172, 173, 174, 178, 179, 181, 182, 183, 184, 186, 187, 190, 191, 193, 196, 197, 198, 201, 203, 204, 206, 207, 211, 212, 213, 215, 216, 217, 218, 220, 225, 226, 232, 234, 235, 236, 237, 240, 241, 246, 254, 264, 266, 267], "v": [20, 21, 22, 26, 27, 28, 29, 30, 37, 52, 57, 68, 69, 70, 72, 73, 76, 77, 78, 92, 94, 101, 103, 108, 110, 113, 114, 120, 124, 125, 132, 134, 135, 136, 137, 139, 140, 141, 142, 143, 146, 151, 152, 153, 158, 160, 162, 163, 164, 166, 169, 176, 180, 184, 186, 187, 190, 191, 192, 193, 195, 196, 197, 202, 203, 206, 208, 209, 210, 212, 213, 218, 221, 223, 224, 226, 228, 229, 232, 234, 238, 239, 240, 242, 244, 245, 246, 247, 252, 254, 264, 268, 331, 333, 358, 359], "lr_t": [20, 91, 92, 94], "store": [2, 20, 103, 105, 116, 137, 138, 139, 141, 144, 185, 296, 332, 333, 334, 335, 338, 341, 345, 347, 351, 352, 353, 354, 355, 357, 358, 359, 365, 376, 381, 382, 384, 386], "per": [4, 20, 29, 31, 33, 35, 36, 37, 38, 39, 43, 47, 49, 51, 52, 53, 56, 57, 59, 75, 77, 78, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 108, 110, 116, 117, 118, 124, 125, 127, 129, 131, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 159, 162, 166, 168, 172, 193, 203, 205, 214, 224, 225, 226, 227, 230, 231, 233, 236, 237, 241, 242, 243, 246, 247, 248, 249, 250, 253, 257, 259, 266, 268, 287, 295, 308, 313, 318, 331, 333, 334, 340, 341, 349, 356, 357, 371, 372, 377, 378, 383, 384, 386], "timestep": [20, 134, 136, 141, 142, 143], "intermedi": [20, 73], "input_s": 20, "hidden_s": [20, 134, 136, 139, 140, 141, 143, 144, 145, 146], "w_y": [20, 102], "b_y": [20, 102], "last_h": 20, "c": [20, 21, 22, 25, 26, 28, 29, 30, 31, 32, 34, 37, 39, 41, 46, 50, 52, 57, 59, 64, 69, 70, 72, 73, 74, 75, 77, 81, 83, 84, 86, 87, 89, 91, 92, 93, 94, 100, 101, 102, 104, 105, 108, 112, 115, 116, 117, 118, 119, 122, 123, 131, 132, 139, 145, 148, 149, 151, 152, 157, 158, 160, 164, 170, 171, 173, 174, 175, 176, 177, 178, 182, 184, 185, 187, 190, 192, 193, 202, 204, 211, 212, 215, 217, 221, 222, 225, 234, 235, 242, 243, 244, 245, 246, 248, 249, 251, 252, 253, 254, 255, 257, 258, 259, 261, 265, 267, 268, 286, 287, 288, 289, 292, 295, 296, 297, 298, 334, 347, 372, 389], "i": [20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 41, 45, 46, 47, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 123, 125, 127, 129, 131, 132, 134, 135, 137, 138, 139, 140, 141, 145, 146, 150, 152, 154, 155, 156, 157, 158, 159, 161, 162, 163, 165, 170, 172, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 198, 199, 200, 203, 204, 206, 207, 208, 209, 210, 211, 213, 214, 216, 217, 218, 219, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 237, 239, 240, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 262, 263, 264, 265, 266, 268, 269, 270, 271, 287, 289, 292, 295, 296, 297, 298, 299, 300, 301, 305, 306, 316, 318, 319, 329, 334, 393], "f": [20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 57, 59, 61, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 280, 285, 288, 289, 297, 298, 300, 304, 305, 306, 307, 311, 313, 319, 327, 328, 329, 334, 339, 345, 348, 350, 351, 352, 357, 358, 359, 372], "o": [20, 25, 27, 35, 39, 41, 64, 65, 70, 73, 74, 75, 81, 83, 97, 103, 125, 155, 181, 185, 189, 226, 227, 230, 231, 232, 233, 236, 237, 241, 246, 247, 255, 347], "c_next": 20, "tanh_c": 20, "h_next": [20, 111], "c_prev": 20, "assert": [20, 21, 22, 32, 35, 41, 45, 90, 102, 134, 140, 142, 148, 160, 165, 166, 210, 220, 251], "dh": 20, "dc": [20, 101, 180], "revers": [20, 35, 36, 41, 53, 64, 65, 97, 111, 112, 116, 121, 122, 134, 136, 140, 142, 143, 146, 219, 265, 287, 310], "do": [2, 20, 28, 30, 31, 32, 39, 41, 45, 46, 47, 49, 50, 64, 69, 70, 72, 73, 77, 84, 87, 89, 91, 99, 100, 102, 104, 105, 107, 108, 109, 118, 122, 134, 135, 137, 138, 142, 143, 145, 153, 154, 155, 160, 161, 166, 167, 168, 175, 177, 178, 179, 182, 187, 188, 195, 202, 204, 207, 209, 213, 225, 226, 227, 228, 231, 232, 233, 234, 235, 237, 239, 240, 243, 244, 246, 247, 248, 250, 252, 253, 254, 255, 256, 257, 259, 261, 262, 263, 267, 268, 269, 271, 338, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 371, 372, 374, 376, 378, 382, 386], "dc_total": 20, "df": [20, 25, 31, 39, 50, 74, 87, 90, 93, 101, 111, 115, 116, 118, 121, 122, 143, 145, 151, 153, 154, 162, 165, 166, 169, 170, 172, 174, 176, 177, 178, 181, 182, 185, 187, 189, 190, 191, 192, 193, 194, 196, 198, 199, 200, 201, 202, 203, 208, 209, 210, 213, 214, 216, 218, 221, 222, 224, 226, 227, 229, 231, 233, 235, 236, 240, 242, 244, 246, 247, 248, 249, 250, 252, 253, 254, 257, 258, 259, 262, 267, 268, 269, 270, 286, 287, 289, 292, 311, 312, 313, 314, 315, 316, 317, 323, 328, 358, 394], "di": 20, "dg": 20, "pre": [20, 39, 110, 135, 146, 151, 244, 259, 270, 344, 352], "dai": [20, 87, 98, 107, 115, 125, 226, 238, 253, 353, 355, 358, 366, 384], "daf": 20, "dao": 20, "dag": [20, 350, 356], "dz": [20, 51, 148, 157, 161, 181, 184, 188, 194, 199, 202, 268], "propag": [20, 73, 113, 116, 125, 167, 385], "previou": [20, 123, 180, 213, 240, 271], "train_numpy_model": 20, "64": [20, 21, 22, 31, 32, 65, 81, 101, 136, 137, 139, 140, 142, 143, 146, 289], "2e": [20, 50, 59, 78, 94, 97, 136, 183, 225, 229, 235], "max_grad_norm": [20, 134, 136, 139, 142, 143], "verbose_everi": 20, "20": [20, 25, 26, 29, 36, 37, 41, 47, 50, 51, 52, 53, 59, 67, 70, 75, 77, 84, 88, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 106, 107, 108, 110, 114, 115, 117, 118, 119, 123, 125, 131, 132, 135, 136, 137, 138, 139, 140, 142, 144, 145, 150, 151, 152, 153, 159, 166, 169, 170, 175, 177, 180, 184, 191, 192, 196, 201, 202, 203, 207, 210, 211, 213, 215, 216, 217, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 236, 237, 239, 241, 242, 244, 246, 247, 248, 249, 250, 251, 252, 254, 255, 258, 260, 262, 264, 265, 266, 267, 269, 270, 284, 288, 293, 295, 299, 305, 306, 312, 313, 314, 315, 316, 317, 322, 332, 351, 355], "opt": [20, 21, 22, 140, 159, 163, 209], "bidx": 20, "grad_norm": 20, "avg": [20, 32, 47, 49, 104, 106, 108, 139, 140, 155, 175], "6f": [20, 45, 49, 59, 70, 75, 78, 84, 151, 165, 172, 174, 186, 192, 201, 203, 217, 225, 229, 243, 246, 251, 252, 253, 257, 259, 270], "3f": [20, 21, 22, 25, 26, 27, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 53, 57, 64, 65, 67, 69, 70, 72, 74, 75, 77, 78, 83, 87, 89, 90, 91, 93, 94, 96, 98, 99, 100, 105, 108, 109, 110, 112, 125, 127, 131, 132, 136, 139, 142, 146, 148, 165, 176, 177, 178, 179, 185, 191, 193, 196, 200, 206, 209, 212, 221, 223, 226, 228, 229, 231, 232, 240, 242, 243, 244, 245, 246, 249, 250, 252, 253, 254, 255, 256, 258, 259, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 297, 298, 304, 307], "predict_numpi": [20, 21, 22], "unscal": [20, 30, 74, 122], "x_scale": [20, 25, 30, 91, 107], "fast_run": [20, 21, 22, 134, 136, 138, 140, 142, 144, 145, 146, 159, 185, 221], "epochs_numpi": [20, 21, 22], "80": [20, 27, 30, 31, 32, 36, 37, 38, 41, 47, 50, 59, 64, 67, 69, 70, 72, 75, 77, 81, 83, 86, 87, 92, 93, 99, 100, 103, 104, 106, 107, 108, 110, 113, 121, 123, 124, 132, 136, 137, 141, 142, 144, 146, 149, 150, 154, 156, 157, 161, 163, 167, 178, 179, 180, 183, 186, 187, 188, 191, 192, 195, 196, 197, 198, 199, 201, 204, 205, 208, 209, 211, 213, 219, 222, 225, 228, 230, 232, 233, 237, 241, 242, 246, 247, 248, 249, 252, 253, 255, 256, 259, 261, 262, 264, 265, 266, 268, 269, 286, 293, 295, 305, 314, 318, 322, 358, 359, 369, 372, 377], "lstm_np": 20, "hist_lstm_np": 20, "mse": [20, 38, 47, 86, 90, 92, 93, 98, 99, 100, 102, 107, 109, 110, 112, 137, 138, 141, 145, 249], "y_pred_test_lstm": 20, "y_true_test": 20, "One": [20, 31, 47, 73, 84, 91, 92, 103, 104, 109, 110, 112, 114, 120, 127, 131, 132, 135, 137, 140, 146, 150, 157, 159, 162, 166, 173, 177, 179, 185, 186, 205, 209, 214, 219, 221, 234, 236, 242, 244, 245, 249, 252, 257, 266, 267, 270, 285, 347, 372], "region": [20, 25, 35, 64, 65, 99, 103, 110, 136, 140, 143, 149, 157, 173, 174, 184, 192, 193, 197, 199, 200, 211, 214, 220, 252, 261, 296, 322, 334, 335, 338, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 381, 382, 383, 384, 385, 386, 408], "mae": [20, 86, 87, 89, 93, 96, 97, 98, 99, 100, 102, 122, 125, 127, 129, 131, 132, 271, 280, 297, 298, 299, 301, 303, 304, 307, 320, 321], "ab": [20, 21, 22, 26, 27, 29, 31, 34, 39, 41, 47, 51, 52, 56, 59, 65, 74, 75, 77, 78, 83, 86, 88, 90, 91, 92, 93, 96, 98, 99, 101, 103, 105, 107, 109, 112, 114, 116, 117, 118, 120, 122, 124, 125, 132, 138, 140, 141, 142, 143, 144, 146, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 165, 166, 167, 170, 171, 172, 173, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 194, 195, 197, 198, 201, 202, 203, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 222, 225, 227, 228, 229, 230, 232, 233, 235, 237, 239, 240, 242, 245, 246, 248, 249, 252, 255, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 280, 299, 301], "4f": [20, 21, 22, 28, 37, 38, 45, 47, 51, 59, 65, 67, 72, 75, 78, 81, 87, 90, 93, 94, 95, 96, 98, 100, 102, 134, 142, 146, 151, 158, 165, 172, 174, 178, 181, 201, 209, 223, 229, 231, 242, 243, 244, 245, 246, 249, 250, 252, 253, 254, 255, 257, 259, 260, 261, 262, 263, 265, 266, 267, 268, 269, 270, 271], "rollout_forecast_numpi": 20, "seed_window_scaled_1d": 20, "copi": [20, 25, 27, 31, 32, 36, 37, 41, 46, 47, 52, 57, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 87, 88, 89, 90, 93, 95, 96, 97, 99, 100, 101, 103, 105, 107, 115, 116, 117, 119, 120, 122, 123, 124, 125, 137, 138, 139, 140, 141, 144, 145, 199, 230, 238, 240, 258, 265, 280, 285, 312, 313, 314, 315, 316, 317, 334, 335, 353, 358, 371, 382], "roll": [20, 29, 32, 100, 114, 117, 119, 122, 134, 136, 140, 141, 142, 143, 145, 230, 238, 246, 247, 299, 308, 315, 323, 328, 338, 343, 344, 367, 375, 378, 381], "recurs": [20, 111, 113, 116, 117, 121, 122, 123, 127, 237, 302, 306], "roll_step": 20, "seed_window": 20, "future_tru": 20, "future_pred_sc": 20, "future_pr": 20, "rollout": [20, 134, 143, 144, 146, 331, 374, 375], "box": [20, 29, 35, 47, 59, 69, 70, 81, 92, 110, 116, 119, 122, 124, 134, 138, 141, 143, 186, 199, 225, 243, 248, 250, 252, 253, 264, 266, 267, 270, 300, 301, 323], "inspect": [20, 25, 36, 46, 67, 73, 74, 81, 83, 84, 93, 101, 102, 110, 122, 127, 131, 132, 199, 224, 232, 233, 234, 241, 246, 247, 249, 254, 271, 293, 294, 296, 315, 355, 358, 359], "The": [20, 21, 22, 25, 26, 28, 29, 30, 31, 32, 35, 36, 38, 39, 45, 47, 50, 51, 52, 53, 56, 59, 64, 65, 67, 73, 74, 75, 78, 81, 85, 86, 88, 89, 90, 91, 93, 94, 95, 97, 99, 100, 101, 102, 106, 109, 111, 113, 114, 115, 117, 118, 119, 122, 127, 129, 132, 134, 135, 136, 138, 139, 140, 141, 142, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 241, 245, 248, 249, 261, 269, 271, 280, 285, 286, 287, 288, 290, 291, 294, 295, 300, 302, 309, 318, 323, 324, 327, 328, 329, 331, 339, 345, 347, 356, 359, 367, 368, 378, 379, 384, 385, 389, 393, 394], "plot": [17, 18, 20, 23, 24, 25, 29, 31, 35, 36, 37, 38, 45, 52, 59, 64, 69, 70, 73, 74, 87, 88, 89, 90, 91, 92, 94, 95, 97, 100, 101, 102, 104, 105, 107, 108, 109, 110, 113, 115, 116, 117, 119, 120, 122, 123, 124, 125, 127, 131, 132, 133, 138, 140, 142, 143, 144, 145, 147, 148, 150, 152, 154, 156, 157, 159, 160, 161, 162, 163, 165, 168, 169, 170, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 189, 190, 192, 194, 195, 196, 198, 199, 200, 202, 207, 211, 215, 219, 220, 224, 225, 228, 229, 230, 236, 239, 241, 242, 243, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258, 259, 261, 262, 263, 264, 265, 267, 268, 269, 270, 272, 273, 274, 276, 277, 278, 279, 282, 328], "below": [20, 28, 29, 30, 36, 37, 41, 45, 46, 49, 51, 52, 56, 57, 64, 65, 67, 69, 70, 73, 74, 75, 77, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 100, 101, 103, 104, 107, 109, 110, 113, 116, 117, 122, 123, 135, 138, 139, 142, 143, 144, 148, 149, 150, 151, 152, 153, 156, 157, 158, 160, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 176, 177, 178, 179, 188, 189, 190, 191, 195, 197, 199, 200, 201, 206, 208, 209, 212, 214, 216, 219, 221, 224, 225, 226, 227, 228, 229, 230, 234, 236, 237, 239, 242, 243, 245, 249, 250, 251, 252, 253, 254, 256, 257, 259, 260, 262, 263, 264, 267, 268, 269, 270, 285, 288, 318, 332, 333, 334, 335, 339, 342, 343, 346, 348, 349, 350, 351, 352, 354, 356, 357], "lstm_gate_mat": 20, "x_one": 20, "col": [20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 56, 57, 64, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 84, 86, 87, 88, 90, 92, 95, 96, 97, 98, 100, 103, 104, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 131, 132, 134, 135, 137, 143, 144, 146, 149, 151, 155, 163, 164, 167, 168, 171, 172, 175, 176, 177, 178, 179, 181, 182, 185, 189, 191, 192, 200, 204, 207, 210, 216, 222, 224, 226, 231, 232, 233, 237, 241, 244, 245, 247, 248, 254, 256, 258, 259, 261, 262, 263, 264, 265, 267, 271, 295, 308, 316, 323, 394], "subplot_titl": [20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 56, 64, 67, 69, 70, 73, 74, 75, 77, 78, 81, 84, 86, 87, 88, 90, 92, 95, 96, 97, 98, 100, 103, 104, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 131, 132, 134, 143, 144, 146, 149, 151, 155, 163, 164, 167, 168, 171, 172, 175, 176, 177, 178, 179, 181, 182, 185, 189, 191, 192, 204, 207, 210, 216, 222, 224, 226, 231, 232, 233, 237, 241, 244, 245, 247, 248, 254, 258, 259, 261, 262, 263, 264, 265, 267, 295, 308, 316], "horizontal_spac": [20, 32, 67, 84, 117, 119, 123, 189, 204, 248, 259], "08": [20, 21, 22, 27, 29, 32, 34, 39, 47, 84, 109, 115, 116, 119, 121, 123, 146, 151, 157, 163, 165, 172, 188, 207, 211, 215, 221, 230, 237, 264, 393], "vertical_spac": [20, 26, 32, 47, 50, 52, 84, 111, 114, 115, 116, 117, 119, 121, 122, 123, 144, 146, 155, 175, 247, 248, 254, 256, 323], "heatmap": [20, 21, 22, 26, 27, 34, 37, 39, 41, 49, 51, 53, 67, 69, 72, 73, 75, 78, 81, 84, 96, 97, 98, 99, 103, 107, 108, 109, 118, 134, 138, 139, 154, 156, 167, 168, 185, 187, 189, 221, 230, 237, 238, 246, 253, 261, 287], "coloraxi": [20, 69, 185], "height": [20, 21, 22, 26, 27, 28, 29, 31, 32, 35, 37, 39, 46, 50, 51, 52, 53, 56, 64, 69, 70, 73, 75, 78, 83, 84, 86, 87, 88, 92, 100, 104, 105, 106, 108, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 129, 131, 132, 134, 135, 136, 137, 143, 144, 146, 149, 152, 155, 156, 164, 167, 168, 171, 172, 173, 174, 175, 176, 178, 181, 182, 185, 189, 191, 192, 193, 196, 200, 206, 207, 210, 211, 212, 215, 217, 222, 225, 226, 228, 229, 231, 233, 244, 245, 248, 254, 256, 259, 260, 261, 264, 265, 268, 284, 295, 299, 305, 308, 310, 316, 317, 322, 323, 327, 328, 329], "750": [20, 28, 31, 35, 46, 64, 83, 105, 120, 124, 127, 131, 132, 134, 164, 228, 245], "title_text": [20, 26, 27, 28, 29, 30, 31, 32, 37, 38, 39, 45, 46, 47, 50, 51, 52, 56, 64, 67, 69, 70, 73, 74, 77, 78, 81, 84, 86, 87, 88, 90, 92, 95, 96, 97, 98, 100, 103, 104, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 123, 125, 134, 143, 144, 146, 149, 151, 155, 163, 164, 167, 168, 171, 172, 175, 176, 177, 178, 179, 181, 185, 189, 191, 192, 204, 207, 210, 216, 222, 224, 226, 231, 232, 233, 237, 241, 244, 245, 247, 248, 254, 256, 258, 259, 261, 262, 263, 264, 265, 267], "bit": [20, 31, 32, 51, 69, 78, 184, 234, 238, 264, 381, 382], "simpler": [20, 69, 97, 101, 116, 161, 182, 209, 214], "concat": [20, 29, 102, 224, 306], "concat2": 20, "h_tild": 20, "h_prev": 20, "dh_tild": 20, "dh_prev": 20, "da_h": 20, "dconcat2": 20, "drh_prev": 20, "da_r": 20, "dconcat_r": 20, "da_z": 20, "dconcat_z": 20, "dconcat": 20, "gru_np": 20, "hist_gru_np": 20, "y_pred_test_gru": 20, "gru_gate_mat": 20, "06": [20, 21, 22, 25, 26, 27, 28, 29, 32, 46, 52, 97, 110, 111, 115, 121, 144, 165, 188, 189, 253, 255, 256, 263, 348], "380": [20, 31, 39, 75, 87, 92, 136, 143, 149, 155, 164, 168, 175, 176, 178, 182, 185, 215, 222, 228, 244, 245, 259], "care": [20, 29, 31, 32, 34, 35, 36, 37, 39, 41, 45, 47, 49, 50, 52, 56, 64, 65, 67, 70, 73, 74, 75, 77, 81, 86, 87, 89, 91, 92, 96, 99, 101, 103, 105, 108, 109, 113, 119, 122, 143, 154, 159, 163, 164, 171, 173, 175, 178, 179, 186, 187, 198, 202, 224, 241, 244, 245, 249, 250, 254, 263, 265, 266, 267, 268, 269, 323, 331, 332, 335, 341, 358, 368], "autograd": [20, 21, 22, 136, 137, 145, 146], "effici": [20, 25, 65, 73, 109, 137, 139, 144, 145, 148, 150, 151, 152, 158, 159, 163, 169, 170, 177, 180, 185, 190, 206, 215, 220, 221, 224, 225, 233, 237, 254, 300, 308, 325, 341, 368, 382, 392], "kernel": [20, 21, 22, 31, 131, 138, 139, 170, 185, 204, 221, 222, 291, 358, 359], "exact": [20, 26, 31, 35, 38, 41, 67, 83, 90, 112, 113, 138, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 169, 171, 172, 173, 179, 180, 182, 183, 184, 188, 190, 195, 196, 198, 199, 200, 201, 206, 209, 211, 212, 213, 215, 218, 220, 221, 223, 225, 228, 231, 232, 233, 234, 235, 236, 237, 239, 240, 242, 245, 246, 247, 249, 252, 256, 257, 263, 268, 269, 284, 285, 288, 379, 393], "comparison": [20, 35, 36, 37, 38, 45, 50, 57, 64, 65, 69, 73, 75, 96, 97, 100, 108, 122, 155, 156, 158, 160, 163, 165, 168, 169, 171, 173, 174, 175, 188, 191, 193, 209, 215, 217, 224, 225, 233, 240, 241, 243, 251, 253, 254, 255, 258, 259, 260, 264, 266, 267, 281], "fair": [20, 158, 161, 176, 238, 281], "windowdataset": 20, "__len__": [20, 141], "__getitem__": 20, "torchrnnforecast": 20, "modul": [20, 21, 22, 31, 33, 34, 35, 36, 37, 38, 45, 49, 50, 51, 52, 53, 56, 59, 64, 65, 68, 69, 70, 73, 74, 77, 81, 83, 84, 85, 86, 87, 88, 89, 92, 96, 98, 99, 100, 101, 110, 122, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 213, 271, 275, 281, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 297, 298, 300, 301, 302, 303, 304, 306, 307, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 323, 324, 325, 326, 334, 335, 389], "rnn_type": 20, "super": [20, 21, 22, 105, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 164, 165, 180, 188], "batch_first": 20, "elif": [20, 27, 34, 45, 52, 53, 59, 69, 72, 75, 86, 87, 88, 89, 96, 97, 98, 100, 101, 109, 120, 124, 125, 139, 141, 143, 151, 158, 161, 197, 210, 220, 230, 242, 245, 249, 250, 251, 255, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 295], "rais": [20, 21, 22, 27, 28, 29, 31, 34, 35, 36, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 108, 109, 110, 111, 112, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 135, 137, 139, 141, 143, 144, 145, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 381, 389], "valueerror": [20, 27, 28, 29, 31, 34, 35, 36, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 108, 109, 110, 111, 112, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 135, 137, 139, 141, 145, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270], "must": [20, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 132, 134, 139, 141, 145, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 263, 264, 265, 266, 267, 269, 270, 271, 304, 307, 310, 333, 334, 344, 345, 347, 350, 352, 357, 358, 369, 374, 389], "h_last": [20, 121], "train_torch_model": 20, "40": [20, 21, 22, 28, 36, 41, 47, 50, 53, 56, 59, 64, 67, 72, 73, 87, 90, 94, 99, 100, 101, 106, 107, 108, 112, 118, 119, 122, 125, 127, 131, 132, 134, 135, 138, 139, 142, 145, 162, 165, 167, 170, 171, 182, 185, 186, 189, 191, 193, 194, 204, 206, 215, 216, 217, 221, 223, 225, 226, 229, 230, 232, 233, 234, 236, 243, 244, 245, 246, 247, 248, 250, 252, 257, 258, 260, 261, 262, 263, 265, 267, 268, 269, 270, 287, 288, 292, 299, 310, 318, 319], "loss_fn": 20, "mseloss": 20, "set_to_non": [20, 21, 22, 134, 136, 138, 139, 140, 141, 142, 143, 144], "clip_grad_norm_": [20, 134, 138, 139, 140, 141, 142, 143], "predict_torch": 20, "pick_devic": 20, "except": [20, 21, 22, 25, 28, 31, 32, 46, 50, 53, 65, 78, 83, 101, 102, 104, 110, 115, 118, 120, 124, 134, 135, 137, 138, 143, 144, 145, 178, 185, 225, 237, 238, 243, 246, 248, 251, 253, 258, 260, 262, 264, 265, 267, 268, 269, 285, 286, 287, 288, 289, 292, 300, 301, 303, 306, 311, 312, 313, 314, 315, 316, 317, 318, 338, 355, 356, 381], "pass": [20, 22, 34, 36, 38, 46, 47, 51, 56, 64, 65, 75, 88, 89, 93, 98, 101, 103, 108, 109, 115, 127, 129, 131, 132, 138, 144, 145, 146, 149, 169, 180, 185, 190, 195, 199, 219, 225, 231, 234, 240, 260, 269, 308, 333, 355, 356], "epochs_torch": [20, 21, 22], "torch_lstm": 20, "torch_gru": 20, "hist_torch_lstm": 20, "hist_torch_gru": 20, "y_pred_test_torch_lstm": 20, "y_pred_test_torch_gru": 20, "did": [20, 36, 46, 49, 51, 67, 88, 109, 122, 134, 141, 180, 189, 201, 234, 240, 244, 248, 256, 263, 266, 340, 381], "too": [20, 26, 27, 28, 29, 31, 32, 34, 38, 46, 52, 67, 74, 81, 89, 92, 97, 99, 104, 107, 108, 112, 113, 116, 119, 123, 125, 127, 129, 131, 132, 134, 135, 136, 138, 139, 140, 141, 142, 143, 146, 157, 159, 160, 166, 170, 171, 172, 173, 180, 182, 183, 185, 187, 190, 195, 199, 207, 209, 212, 224, 225, 228, 230, 231, 234, 236, 242, 244, 247, 250, 253, 256, 259, 340, 346, 373, 381, 382, 383], "harder": [20, 25, 46, 52, 56, 104, 109, 112, 117, 123, 138, 140, 141, 143, 233, 308], "error": [20, 22, 28, 33, 34, 37, 38, 41, 44, 45, 46, 48, 50, 52, 53, 57, 70, 75, 81, 84, 85, 88, 89, 92, 95, 98, 100, 107, 109, 110, 112, 113, 116, 119, 123, 124, 132, 134, 136, 138, 139, 141, 143, 144, 145, 146, 148, 149, 153, 155, 157, 158, 161, 163, 174, 175, 176, 177, 178, 179, 181, 182, 183, 186, 188, 189, 194, 195, 197, 198, 200, 201, 207, 208, 209, 212, 219, 221, 222, 225, 226, 228, 229, 230, 231, 236, 237, 240, 243, 244, 248, 249, 250, 252, 253, 258, 259, 261, 263, 264, 266, 268, 269, 280, 284, 299, 300, 301, 302, 306, 308, 311, 312, 313, 314, 315, 316, 317, 338, 340, 341, 344, 347, 348, 355, 356, 381, 382, 383, 386], "accumul": [20, 167, 200, 210, 225, 240, 257, 370], "drift": [20, 45, 69, 111, 112, 116, 119, 138, 150, 165, 170, 173, 178, 186, 195, 218, 237, 239, 241, 310, 323, 331, 333, 335, 338, 340, 371, 389], "If": [20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 51, 52, 53, 56, 57, 59, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 89, 90, 91, 93, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 125, 129, 134, 135, 137, 138, 139, 140, 142, 143, 144, 145, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 206, 209, 210, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 280, 287, 288, 304, 305, 307, 332, 338, 346, 353, 355, 359, 365, 377, 379, 384, 389], "stronger": [20, 26, 31, 110, 123, 141, 158, 160, 191, 192, 202, 288], "futur": [20, 114, 115, 116, 117, 118, 119, 122, 125, 141, 146, 153, 159, 181, 189, 224, 225, 226, 228, 234, 236, 271, 285, 305, 306, 310], "seq2seq": 20, "exogen": [20, 113, 117, 125, 285, 301, 306, 322], "calendar": [20, 116, 123, 125, 306], "holidai": [20, 115, 123], "covari": [20, 26, 28, 103, 106, 107, 112, 114, 116, 117, 118, 122, 123, 146, 162, 168, 172, 194, 228, 236, 262, 393], "teacher": 20, "schedul": [20, 107, 134, 136, 139, 142, 143, 144, 332, 333, 342, 344, 346, 347, 348, 349, 350, 356, 366, 374, 379, 384, 386], "increas": [20, 25, 26, 27, 32, 34, 35, 36, 37, 41, 50, 69, 70, 73, 74, 75, 77, 81, 84, 89, 91, 93, 94, 98, 100, 106, 107, 110, 111, 115, 117, 118, 119, 122, 123, 125, 134, 138, 139, 140, 141, 142, 146, 148, 152, 153, 159, 160, 163, 164, 165, 169, 170, 171, 173, 174, 176, 178, 180, 181, 183, 185, 186, 189, 191, 193, 196, 197, 198, 199, 200, 201, 203, 204, 205, 207, 209, 211, 212, 213, 215, 216, 218, 220, 221, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 238, 239, 241, 243, 245, 247, 249, 250, 253, 254, 255, 257, 259, 260, 262, 263, 264, 265, 267, 268, 269, 289, 318, 349, 368, 381, 389], "compar": [20, 21, 22, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 45, 47, 49, 50, 51, 52, 53, 56, 57, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 112, 113, 116, 117, 122, 123, 124, 125, 127, 131, 132, 134, 138, 142, 143, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 180, 181, 183, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 209, 210, 211, 212, 214, 215, 217, 218, 220, 222, 223, 224, 225, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 265, 266, 267, 269, 270, 280, 287, 295, 308, 312, 322, 331, 335, 358, 359], "stabil": [1, 20, 28, 37, 69, 70, 75, 78, 91, 93, 106, 107, 108, 112, 113, 117, 122, 134, 135, 136, 139, 140, 141, 142, 144, 146, 149, 151, 153, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 177, 178, 179, 181, 185, 189, 190, 193, 194, 195, 196, 198, 199, 200, 201, 202, 203, 205, 208, 212, 213, 216, 219, 220, 221, 222, 223, 225, 231, 232, 233, 234, 235, 238, 239, 240, 244, 250, 251, 252, 259, 260, 261, 263, 266, 269, 288, 319, 323, 368], "second": [20, 22, 26, 30, 32, 38, 46, 77, 78, 105, 110, 111, 114, 116, 121, 146, 148, 151, 152, 154, 159, 163, 166, 171, 179, 182, 184, 186, 187, 190, 192, 193, 195, 202, 203, 205, 207, 211, 212, 215, 223, 225, 227, 236, 239, 250, 334, 345, 355, 368, 386], "compon": [20, 27, 29, 38, 47, 74, 106, 113, 115, 117, 119, 120, 148, 151, 152, 155, 156, 163, 168, 169, 173, 179, 181, 185, 186, 188, 189, 191, 192, 193, 199, 201, 205, 207, 209, 211, 213, 216, 220, 223, 226, 228, 230, 233, 234, 235, 237, 238, 239, 264, 271, 297, 298, 300, 302, 309, 323, 332, 334, 344, 350, 358, 398, 402], "longer": [20, 21, 22, 103, 136, 138, 140, 141, 142, 144, 146, 148, 153, 162, 171, 173, 179, 184, 190, 195, 211, 212, 213, 215, 220, 264, 355], "period": [20, 103, 112, 114, 115, 116, 119, 120, 121, 122, 124, 125, 127, 129, 131, 132, 139, 140, 145, 156, 213, 216, 225, 239, 256, 271, 280, 296, 299, 300, 301, 303, 306, 323, 327, 340, 343, 347, 349, 350, 366], "differ": [20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 39, 41, 45, 46, 47, 48, 49, 50, 51, 52, 53, 59, 60, 65, 67, 69, 70, 72, 75, 77, 78, 81, 83, 84, 87, 88, 89, 94, 95, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 114, 116, 117, 118, 122, 129, 131, 138, 143, 145, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 161, 162, 163, 165, 169, 171, 172, 174, 176, 181, 182, 184, 185, 186, 187, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 219, 220, 222, 223, 227, 228, 229, 230, 232, 233, 235, 236, 237, 238, 240, 242, 243, 245, 246, 247, 248, 249, 251, 253, 254, 255, 256, 257, 258, 261, 264, 265, 267, 268, 269, 271, 280, 288, 289, 292, 296, 308, 310, 313, 315, 319, 323, 331, 334, 341, 346, 355, 358, 371, 373, 379], "direct": [20, 22, 26, 30, 31, 32, 35, 37, 41, 47, 49, 51, 57, 64, 72, 73, 75, 78, 87, 90, 99, 101, 106, 108, 113, 135, 136, 142, 146, 149, 154, 159, 168, 170, 184, 185, 186, 187, 188, 189, 201, 202, 207, 209, 214, 222, 224, 230, 231, 232, 233, 236, 237, 241, 246, 249, 250, 253, 256, 258, 260, 262, 264, 265, 266, 267, 268, 271, 339, 356, 357, 359, 374], "see": [6, 20, 21, 22, 25, 26, 28, 29, 31, 32, 35, 39, 45, 46, 47, 51, 52, 53, 56, 59, 67, 75, 77, 78, 81, 83, 86, 88, 89, 90, 104, 105, 107, 108, 109, 110, 113, 114, 117, 122, 123, 129, 135, 136, 137, 140, 141, 145, 146, 153, 154, 159, 161, 162, 163, 168, 171, 178, 179, 183, 185, 186, 191, 194, 198, 199, 204, 206, 208, 213, 214, 222, 223, 225, 230, 231, 234, 235, 236, 242, 243, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 280, 285, 289, 308, 311, 312, 315, 328, 331, 332, 333, 334, 335, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 371, 381, 382, 383, 384, 385, 386], "affect": [20, 38, 46, 52, 57, 72, 74, 99, 105, 111, 112, 114, 122, 154, 164, 169, 185, 187, 190, 195, 202, 213, 214, 217, 238, 246, 256, 265, 269, 371], "hochreit": 20, "schmidhub": 20, "1997": [20, 98, 196, 245], "cho": 20, "et": [20, 22, 31, 59, 134, 138, 139, 142, 144, 181, 243, 264, 309], "al": [20, 22, 31, 59, 134, 138, 139, 142, 144, 177, 181, 243, 264], "2014": [20, 31], "phrase": [20, 100, 262], "represent": [20, 29, 51, 74, 108, 110, 113, 114, 117, 118, 124, 148, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 170, 172, 173, 174, 177, 181, 182, 185, 188, 189, 193, 195, 200, 202, 205, 206, 208, 209, 210, 219, 222, 225, 226, 228, 229, 231, 236, 240, 284, 286], "encod": [2, 20, 21, 52, 57, 67, 75, 103, 108, 110, 113, 120, 159, 191, 196, 208, 211, 212, 221, 225, 238, 255, 271, 296, 335, 338, 349, 376, 383, 400], "decod": [20, 349], "introduc": [20, 90, 103, 109, 113, 116, 118, 119, 122, 162, 167, 175, 187, 191, 192, 195, 200, 205, 207, 240, 257, 331, 371], "like": [21, 22, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 39, 46, 47, 50, 52, 64, 65, 67, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 120, 122, 124, 125, 131, 135, 136, 138, 140, 142, 143, 145, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 189, 190, 191, 192, 193, 195, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 223, 224, 225, 227, 228, 229, 231, 232, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 250, 251, 253, 255, 256, 257, 260, 261, 263, 264, 266, 268, 269, 270, 285, 289, 296, 304, 307, 308, 312, 316, 318, 334, 335, 340, 342, 344, 346, 347, 351, 352, 353, 356, 358, 359, 366, 369, 370, 377, 378, 379, 381, 382, 386], "audio": [21, 26], "spectrogram": 21, "some": [21, 22, 25, 27, 29, 32, 34, 36, 37, 47, 51, 52, 57, 59, 69, 72, 78, 81, 83, 89, 96, 100, 102, 107, 108, 110, 113, 127, 129, 131, 132, 140, 142, 149, 161, 169, 173, 176, 177, 181, 182, 191, 192, 196, 205, 207, 208, 209, 213, 218, 219, 220, 221, 229, 230, 231, 233, 234, 237, 244, 246, 247, 248, 251, 252, 254, 255, 257, 263, 302, 351, 356, 359, 372], "work": [21, 26, 27, 28, 32, 34, 35, 41, 46, 47, 51, 56, 57, 59, 65, 67, 69, 70, 73, 75, 81, 83, 84, 87, 88, 96, 105, 109, 110, 112, 116, 119, 125, 127, 132, 138, 141, 142, 145, 148, 151, 153, 154, 155, 156, 157, 158, 159, 165, 166, 167, 168, 170, 171, 172, 173, 174, 177, 178, 183, 184, 185, 186, 187, 188, 189, 190, 191, 194, 195, 197, 198, 199, 200, 201, 202, 204, 205, 210, 211, 214, 216, 219, 221, 222, 223, 226, 228, 229, 230, 231, 235, 237, 238, 240, 241, 251, 255, 260, 270, 286, 289, 306, 346, 350, 354, 355, 356, 370, 372, 374, 382, 383], "three": [21, 26, 29, 31, 32, 38, 39, 52, 69, 78, 84, 93, 110, 145, 151, 161, 166, 172, 177, 186, 188, 195, 197, 202, 210, 211, 233, 243, 244, 249, 254, 257, 295, 303, 394], "bias": [21, 51, 89, 112, 122, 123, 134, 145, 162, 194, 207, 214, 232, 245, 247, 258, 288], "local": [21, 22, 25, 27, 29, 31, 52, 103, 104, 105, 109, 113, 127, 129, 131, 132, 135, 145, 155, 192, 195, 204, 209, 253, 284, 285, 286, 287, 289, 291, 292, 293, 295, 311, 312, 313, 314, 315, 316, 317, 318, 319, 329, 335, 341, 348, 352, 358, 359, 373, 377, 401], "edg": [21, 22, 25, 27, 32, 45, 46, 50, 53, 59, 77, 84, 87, 92, 98, 100, 149, 156, 159, 168, 171, 178, 194, 202, 211, 222, 223, 230, 233, 234, 266, 339, 369, 385], "corner": [21, 159, 192, 196, 228], "translat": [21, 28, 29, 107, 150, 168, 192, 271, 335], "same": [21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 41, 45, 46, 47, 49, 50, 51, 52, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 104, 105, 107, 108, 110, 112, 113, 114, 115, 116, 117, 122, 123, 124, 125, 127, 129, 132, 140, 141, 142, 143, 145, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 190, 191, 192, 193, 196, 198, 201, 206, 211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 224, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 243, 244, 245, 246, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 259, 261, 262, 263, 264, 265, 267, 268, 270, 296, 308, 328, 331, 332, 333, 335, 338, 341, 346, 353, 355, 358, 359, 365, 374, 389], "appear": [21, 49, 53, 57, 59, 73, 83, 102, 108, 109, 114, 148, 150, 153, 155, 159, 162, 175, 176, 177, 178, 180, 181, 185, 186, 187, 191, 194, 195, 196, 198, 199, 201, 203, 205, 206, 209, 210, 215, 216, 221, 222, 224, 228, 229, 230, 232, 234, 236, 241, 246, 257, 271, 289, 292, 300, 322], "anywher": [21, 25, 250, 333], "share": [21, 22, 59, 74, 106, 117, 134, 140, 153, 159, 169, 172, 196, 205, 207, 224, 244, 249, 252, 308, 312, 313, 314, 315, 316, 317, 333, 334, 338, 353, 358, 359, 371, 374, 384], "reus": [21, 22, 107, 134, 138, 139, 143, 188, 192, 193, 195, 198, 308, 332, 342, 365, 384], "across": [6, 21, 22, 27, 28, 32, 35, 36, 37, 38, 39, 41, 46, 47, 49, 51, 64, 65, 69, 70, 72, 73, 75, 77, 78, 84, 87, 88, 89, 91, 92, 93, 94, 96, 99, 100, 106, 108, 113, 116, 117, 125, 127, 129, 134, 139, 143, 151, 165, 170, 184, 185, 209, 217, 221, 224, 225, 226, 228, 230, 237, 238, 243, 244, 247, 249, 250, 252, 256, 257, 258, 259, 263, 265, 267, 268, 280, 285, 286, 288, 293, 299, 308, 318, 322, 323, 332, 333, 334, 335, 344, 350, 353, 356, 357, 365, 371, 377, 381, 382, 383, 385, 386], "whole": [21, 29, 36, 51, 65, 67, 141, 159, 172, 212, 251, 287, 352], "includ": [6, 21, 22, 35, 41, 46, 51, 69, 78, 86, 89, 91, 92, 93, 94, 98, 99, 100, 102, 103, 107, 108, 109, 112, 113, 114, 116, 118, 122, 134, 135, 136, 139, 144, 145, 149, 156, 157, 158, 159, 160, 161, 162, 165, 169, 171, 173, 179, 182, 186, 189, 190, 191, 194, 198, 202, 204, 206, 207, 209, 210, 211, 212, 213, 220, 229, 233, 235, 237, 238, 239, 240, 241, 242, 245, 249, 250, 251, 257, 260, 262, 263, 264, 266, 267, 268, 269, 285, 286, 296, 299, 313, 315, 317, 323, 334, 338, 339, 343, 345, 346, 348, 350, 351, 352, 353, 354, 356, 357, 359, 371, 381, 384], "equival": [21, 30, 35, 36, 39, 45, 46, 47, 51, 56, 64, 69, 78, 84, 86, 87, 88, 89, 91, 92, 94, 95, 96, 97, 99, 100, 101, 102, 104, 109, 110, 118, 122, 146, 149, 150, 151, 153, 158, 160, 162, 163, 164, 166, 167, 168, 172, 173, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 194, 195, 197, 198, 199, 200, 202, 205, 206, 209, 211, 217, 219, 220, 222, 224, 228, 229, 230, 231, 234, 235, 237, 238, 240, 243, 251, 253, 254, 257, 261, 266], "workflow": [4, 21, 34, 39, 50, 52, 75, 110, 151, 157, 158, 161, 165, 168, 171, 172, 174, 178, 179, 183, 202, 209, 215, 216, 220, 226, 233, 236, 245, 248, 249, 254, 261, 284, 301, 308, 312, 333, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 351, 352, 353, 354, 355, 356, 357], "channel": [4, 21, 22, 26, 190, 205, 383], "stride": [15, 21, 22, 96, 97, 98, 99, 125], "why": [21, 25, 27, 28, 29, 31, 35, 39, 45, 46, 47, 52, 57, 65, 72, 77, 81, 84, 102, 112, 114, 125, 127, 135, 137, 138, 139, 144, 145, 152, 159, 161, 162, 166, 168, 177, 179, 182, 183, 185, 188, 195, 196, 197, 203, 204, 205, 206, 209, 211, 214, 215, 217, 222, 228, 231, 238, 244, 248, 252, 256, 295, 334, 335, 340, 344, 350, 356], "far": [21, 22, 25, 26, 29, 31, 32, 35, 47, 74, 81, 92, 94, 99, 103, 105, 125, 143, 146, 148, 157, 160, 163, 173, 175, 178, 179, 182, 183, 191, 209, 214, 219, 220, 243, 256, 266, 267, 268, 284], "fewer": [21, 22, 50, 72, 87, 99, 100, 106, 107, 109, 117, 225, 233, 234, 245, 247, 333, 358], "dens": [21, 22, 25, 28, 32, 99], "basic": [21, 26, 27, 28, 29, 32, 39, 41, 50, 64, 70, 73, 81, 87, 88, 92, 93, 96, 97, 98, 100, 101, 110, 113, 114, 116, 117, 123, 138, 139, 141, 143, 145, 150, 155, 157, 158, 159, 162, 163, 170, 173, 175, 183, 185, 194, 195, 198, 201, 202, 209, 211, 212, 213, 216, 217, 218, 221, 222, 223, 224, 225, 227, 228, 229, 230, 234, 235, 236, 237, 238, 240, 244, 245, 246, 248, 251, 253, 254, 256, 267, 269, 270, 331, 332, 333, 334, 335, 340, 342, 343, 346, 348, 350, 351, 352, 353, 356, 357, 358, 359, 381, 384, 386], "download": [21, 22, 115, 142, 144, 146, 332, 333, 335, 339, 352], "conv2d": [21, 22], "maxpool": [21, 22], "idea": [21, 22, 27, 29, 30, 32, 34, 46, 53, 70, 88, 96, 97, 99, 100, 104, 105, 107, 108, 110, 113, 115, 140, 141, 145, 158, 159, 183, 197, 209, 227, 230, 236, 245, 247, 251, 252, 254, 256, 263, 267, 268, 269, 271, 327, 331, 338, 342, 348, 356, 359, 382, 384], "panda": [21, 22, 29, 32, 36, 50, 64, 74, 93, 96, 101, 102, 111, 115, 116, 118, 119, 120, 121, 122, 124, 125, 127, 129, 131, 132, 134, 136, 138, 140, 141, 142, 145, 224, 243, 253, 259, 271, 275, 280, 281, 285, 286, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 323, 324, 325, 326, 327, 328, 329, 394], "pd": [21, 22, 29, 32, 36, 50, 64, 74, 93, 101, 102, 111, 115, 116, 118, 119, 120, 121, 122, 124, 125, 127, 129, 131, 132, 134, 136, 138, 140, 141, 142, 145, 213, 224, 243, 253, 259, 271, 275, 280, 281, 285, 286, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 323, 324, 325, 326, 327, 328, 329, 394], "load_digit": [21, 22, 31, 32], "function": [21, 22, 26, 31, 33, 34, 35, 36, 37, 38, 39, 45, 46, 47, 49, 52, 56, 59, 64, 65, 67, 73, 78, 83, 85, 87, 88, 92, 93, 94, 95, 96, 97, 98, 100, 104, 105, 107, 109, 110, 112, 113, 115, 127, 128, 129, 131, 132, 136, 140, 141, 142, 145, 180, 193, 201, 208, 214, 228, 248, 252, 254, 256, 261, 263, 264, 269, 280, 322, 334, 338, 339, 346, 347, 349, 353, 354, 381, 386], "torch_avail": [21, 22, 134, 135, 137, 138, 144, 145], "_torch_import_error": [21, 22, 134, 135, 137, 138, 145], "configur": [21, 22, 50, 134, 136, 138, 140, 142, 145, 146, 331, 333, 334, 335, 339, 341, 346, 348, 349, 350, 355, 358, 365, 366, 369, 376, 383, 385], "set": [21, 22, 25, 26, 28, 29, 30, 34, 35, 36, 37, 38, 39, 41, 46, 47, 50, 51, 52, 56, 57, 59, 65, 67, 68, 69, 73, 74, 75, 78, 81, 83, 84, 87, 89, 90, 91, 92, 93, 95, 96, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 122, 125, 127, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 151, 153, 154, 155, 157, 158, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 206, 207, 208, 211, 212, 213, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 247, 249, 251, 252, 253, 256, 263, 269, 285, 292, 293, 310, 313, 314, 315, 316, 317, 332, 334, 335, 338, 340, 341, 342, 345, 346, 351, 355, 357, 358, 366, 367, 368, 370, 371, 372, 373, 374, 377, 379, 382, 386, 393], "lr_numpi": [21, 22], "05": [21, 22, 27, 29, 31, 34, 36, 37, 39, 41, 47, 49, 51, 56, 57, 59, 65, 69, 73, 75, 84, 87, 88, 89, 93, 94, 95, 96, 97, 98, 100, 101, 102, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 134, 135, 136, 137, 139, 141, 144, 146, 148, 151, 152, 170, 172, 173, 174, 176, 177, 178, 179, 182, 184, 185, 186, 191, 192, 193, 194, 196, 201, 203, 207, 209, 211, 212, 213, 216, 218, 220, 222, 225, 227, 228, 230, 233, 234, 235, 236, 237, 241, 242, 243, 244, 245, 247, 248, 249, 251, 252, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 305, 308, 323, 328, 389], "lr_torch": [21, 22], "run_grad_check": [21, 22], "offlin": [21, 22, 140, 142, 144], "friendli": [21, 22, 39, 47, 73, 96, 106, 107, 136, 140, 142, 144, 210], "grayscal": [21, 22], "pixel": [21, 22, 53, 135, 137], "roughli": [21, 22, 25, 26, 27, 29, 30, 37, 49, 51, 70, 74, 86, 87, 91, 93, 95, 96, 101, 104, 112, 119, 124, 134, 160, 169, 180, 184, 190, 193, 195, 208, 211, 218, 228, 234, 239, 242, 243, 246, 247, 255, 257, 258, 262, 264, 265, 267, 280], "16": [21, 22, 39, 74, 75, 77, 78, 81, 104, 105, 134, 135, 141, 142, 149, 153, 154, 155, 156, 158, 161, 162, 163, 164, 166, 170, 171, 172, 173, 177, 178, 179, 182, 183, 186, 187, 188, 189, 191, 195, 197, 198, 201, 202, 203, 206, 207, 209, 211, 212, 213, 216, 217, 221, 222, 225, 229, 230, 231, 233, 237, 240, 246, 247, 250, 258, 270, 280, 308, 334, 357, 358, 359], "dimens": [21, 22, 25, 29, 30, 31, 32, 83, 103, 106, 112, 113, 154, 175, 186, 187, 189, 191, 202, 340, 386], "w": [21, 22, 26, 27, 28, 30, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 74, 75, 77, 78, 81, 84, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 98, 100, 101, 102, 104, 105, 108, 109, 113, 115, 116, 125, 131, 134, 135, 144, 151, 152, 158, 160, 163, 165, 166, 169, 170, 172, 173, 175, 178, 181, 186, 188, 190, 193, 196, 197, 198, 200, 202, 203, 204, 206, 210, 212, 213, 216, 217, 221, 227, 229, 230, 233, 235, 240, 242, 248, 249, 252, 257, 258, 259, 264, 270, 280, 286, 299, 301, 329, 358, 359, 393], "choic": [21, 22, 27, 28, 30, 31, 34, 35, 37, 38, 41, 50, 52, 53, 59, 64, 69, 70, 72, 73, 75, 77, 78, 81, 83, 84, 86, 90, 91, 99, 102, 103, 104, 108, 110, 116, 119, 131, 132, 134, 135, 138, 139, 141, 143, 146, 149, 150, 153, 176, 181, 182, 183, 184, 193, 194, 196, 197, 200, 206, 224, 225, 227, 230, 234, 238, 239, 241, 245, 248, 252, 263, 265, 268, 270, 285, 286, 295, 308, 351, 356, 378], "36": [21, 22, 75, 78, 107, 115, 127, 142, 204, 221, 225, 240, 261, 271, 297, 298, 305, 323], "img": [21, 22], "facet_col": [21, 22, 29, 102], "facet_col_wrap": [21, 22], "grai": [21, 22, 31, 34, 35, 36, 46, 50, 51, 52, 53, 57, 59, 64, 65, 67, 69, 75, 77, 78, 84, 86, 87, 88, 90, 91, 94, 99, 100, 112, 115, 117, 120, 123, 124, 127, 131, 132, 142, 143, 172, 174, 177, 181, 186, 204, 212, 215, 223, 233, 234, 238, 241, 243, 246, 251, 256, 257, 260, 261, 265, 270, 280, 312, 317, 322], "layout": [21, 22, 26, 31, 32, 37, 84, 122, 135, 137, 192, 209, 227, 235, 241, 331, 357], "annot": [21, 22, 33, 41, 72, 135, 137, 186, 284, 285, 369, 371, 383, 386], "showticklabel": [21, 22, 31, 32, 75, 83, 260, 295, 316], "coloraxis_showscal": [21, 22, 31, 41, 77, 221, 251], "margin": [21, 22, 29, 35, 41, 52, 53, 69, 72, 73, 78, 84, 111, 117, 165, 169, 170, 185, 186, 188, 189, 203, 206, 224, 225, 226, 228, 231, 236, 240, 246, 253, 261, 265, 284, 295, 316, 317, 322], "correl": [21, 22, 26, 29, 30, 32, 33, 34, 103, 107, 108, 116, 117, 118, 119, 120, 123, 127, 137, 138, 139, 185, 187, 189, 194, 195, 202, 221, 228, 230, 237, 239, 245, 257, 263, 266, 268, 270, 271, 288, 340, 383], "flip": [21, 22, 26, 28, 30, 32, 35, 39, 41, 51, 65, 67, 77, 78, 139, 150, 158, 161, 170, 172, 185, 203, 208, 258, 264, 270], "j": [21, 22, 27, 28, 29, 31, 32, 35, 39, 41, 46, 47, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 90, 91, 92, 93, 96, 97, 98, 99, 101, 103, 105, 107, 108, 109, 110, 112, 114, 116, 117, 118, 119, 120, 122, 123, 125, 132, 134, 135, 136, 137, 138, 139, 143, 144, 145, 156, 157, 159, 160, 164, 165, 168, 169, 170, 174, 183, 184, 185, 187, 189, 193, 199, 201, 202, 205, 209, 219, 221, 222, 225, 226, 227, 228, 230, 234, 236, 237, 238, 239, 241, 242, 243, 247, 248, 249, 252, 253, 254, 255, 257, 258, 265, 267, 270, 287, 297, 298], "sum_": [21, 22, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 41, 45, 46, 47, 51, 52, 56, 57, 59, 64, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 105, 107, 108, 110, 111, 112, 114, 117, 118, 119, 120, 123, 124, 125, 127, 129, 132, 134, 136, 137, 139, 143, 144, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 210, 211, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 245, 247, 250, 252, 253, 254, 255, 256, 257, 264, 266, 267, 268, 270, 280, 287, 288, 295, 297, 298, 300, 301, 316, 319, 329], "u": [21, 22, 26, 27, 29, 30, 53, 64, 69, 70, 78, 87, 94, 113, 117, 118, 120, 122, 123, 124, 127, 129, 131, 132, 139, 144, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 222, 223, 224, 226, 227, 232, 233, 235, 236, 237, 238, 240, 241, 249, 252, 253, 256, 257, 264, 265, 266, 267, 270, 333], "kh": [21, 22, 113], "kw": [21, 22], "power": [21, 22, 59, 64, 88, 93, 98, 104, 105, 109, 120, 124, 131, 148, 152, 154, 157, 160, 161, 165, 166, 168, 170, 172, 173, 175, 178, 181, 182, 183, 184, 187, 190, 195, 197, 201, 205, 207, 216, 220, 237, 240, 241, 247, 248, 249, 254, 259, 260, 263, 264, 265, 266, 268, 290, 306, 309, 325, 334, 383], "recept": [21, 22, 131], "field": [21, 22, 34, 131, 141, 149, 169, 185, 347, 382, 384, 385], "patch": [16, 21, 22, 28, 32, 185, 342, 343, 344, 345, 350, 351, 371], "everywher": [21, 91, 92, 107, 145, 159, 180, 262, 288, 383], "conv2d_single_channel_na": [21, 22], "img_p": [21, 22], "constant": [21, 22, 28, 31, 45, 53, 57, 67, 73, 78, 81, 88, 91, 92, 93, 94, 95, 97, 98, 100, 102, 104, 106, 108, 110, 111, 112, 113, 114, 116, 118, 119, 122, 125, 131, 136, 142, 148, 150, 151, 156, 157, 159, 161, 162, 165, 170, 171, 172, 174, 175, 177, 179, 183, 184, 186, 188, 192, 201, 202, 203, 204, 206, 207, 212, 213, 214, 216, 217, 219, 220, 221, 222, 224, 226, 228, 229, 230, 233, 236, 238, 239, 242, 244, 255, 257, 262, 389], "hp": [21, 22, 141], "wp": [21, 22], "out_h": [21, 22], "out_w": [21, 22, 96], "pick": [5, 21, 22, 25, 28, 30, 31, 32, 34, 35, 36, 39, 41, 49, 50, 64, 65, 67, 73, 74, 78, 81, 83, 84, 94, 99, 103, 105, 106, 107, 108, 118, 125, 139, 165, 206, 219, 221, 238, 240, 242, 245, 247, 251, 254, 255, 259, 260, 263, 266, 267, 308, 342, 357, 365, 373, 382], "kx": [21, 22, 184, 215], "ky": [21, 22], "fx": [21, 22, 209], "fy": [21, 22], "horizont": [5, 21, 22, 169, 175, 185, 201, 220, 345, 385], "vertic": [21, 22, 25, 52, 53, 78, 90, 159, 185, 206, 212, 251, 256, 368], "zmid": [21, 22, 138, 246], "naiv": [21, 22, 25, 65, 70, 81, 89, 106, 123, 135, 150, 155, 160, 162, 168, 172, 175, 181, 191, 193, 205, 208, 214, 218, 224, 227, 230, 234, 236, 237, 239, 240, 241, 245, 249, 256, 258, 271, 280, 281, 299, 301, 310, 323], "320": [21, 22, 31, 69, 118, 119, 135, 136, 137, 185, 264, 284, 295, 310, 322], "conv": [21, 22, 131], "suppos": [21, 22, 35, 87, 91, 96, 97, 111, 174, 206, 227, 237, 245, 246, 247, 248, 265, 268], "would": [21, 22, 31, 34, 37, 39, 41, 51, 56, 67, 78, 97, 124, 168, 175, 179, 199, 221, 225, 235, 243, 245, 246, 249, 251, 253, 256, 258, 260, 261, 262, 263, 265, 266, 268, 269, 271, 343, 382, 384], "connect": [21, 25, 27, 29, 32, 70, 77, 86, 90, 91, 96, 100, 103, 109, 110, 113, 121, 135, 143, 151, 152, 156, 158, 165, 166, 167, 171, 174, 175, 176, 177, 179, 182, 187, 188, 190, 198, 202, 205, 208, 209, 220, 222, 229, 232, 234, 235, 239, 241, 246, 248, 331, 332, 344, 345, 348, 350, 351, 353, 357, 358, 359, 383, 384], "everi": [21, 22, 25, 27, 29, 36, 37, 38, 39, 64, 70, 73, 75, 83, 86, 87, 90, 91, 93, 95, 96, 101, 105, 112, 114, 134, 139, 141, 144, 145, 185, 199, 220, 221, 249, 251, 253, 255, 261, 264, 285, 295, 366, 368, 377, 383, 384], "n_params_dens": [21, 22], "n_params_conv2d": [21, 22], "c_in": [21, 22], "c_out": [21, 22], "_df": [21, 22], "datafram": [21, 22, 29, 32, 36, 50, 64, 74, 93, 101, 102, 111, 115, 118, 121, 122, 134, 136, 138, 140, 141, 142, 145, 224, 243, 253, 259, 271, 280, 285, 286, 287, 288, 289, 292, 296, 299, 311, 312, 313, 314, 315, 316, 317, 319, 323, 328, 329, 353, 394], "512": [21, 22, 35, 64, 140, 142, 343], "textposit": [21, 22, 29, 37, 64, 81, 90, 91, 244, 254, 255, 257, 259, 263], "outsid": [21, 22, 47, 56, 81, 103, 112, 114, 142, 149, 156, 167, 172, 174, 184, 195, 197, 206, 211, 214, 216, 226, 227, 229, 232, 236, 239, 240, 241, 244, 254, 257, 259, 263, 269, 338, 358, 359, 369, 373], "number": [21, 22, 25, 26, 27, 28, 31, 35, 36, 38, 39, 46, 47, 49, 50, 51, 53, 56, 57, 59, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 87, 88, 91, 92, 94, 98, 101, 104, 105, 109, 110, 112, 115, 116, 118, 119, 124, 125, 127, 129, 132, 139, 140, 141, 142, 143, 144, 145, 146, 150, 152, 153, 162, 166, 167, 169, 176, 178, 179, 186, 194, 196, 199, 200, 201, 204, 205, 206, 209, 211, 214, 215, 221, 223, 224, 226, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 248, 249, 250, 251, 253, 255, 257, 258, 260, 263, 270, 297, 298, 300, 327, 343, 349, 367, 368, 369, 375], "forward": [21, 22, 37, 45, 100, 113, 117, 122, 123, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 308, 339, 359, 375], "im2col": [21, 22], "col2im": [21, 22], "maxpool2d": [21, 22], "flatten": [21, 22, 32, 73, 132, 134, 140, 143, 185, 227, 257], "clariti": [1, 21, 139, 173, 296, 372], "correct": [21, 29, 34, 37, 41, 46, 49, 51, 52, 53, 56, 57, 67, 75, 81, 89, 94, 103, 104, 108, 113, 122, 134, 144, 148, 158, 160, 162, 163, 167, 169, 171, 173, 174, 175, 179, 186, 190, 197, 199, 220, 225, 226, 233, 236, 242, 243, 244, 245, 246, 249, 255, 256, 259, 260, 261, 263, 266, 267, 269, 270, 296, 303, 339, 409], "_pad2d": [21, 22], "out_shap": [21, 22, 241], "h_pad": [21, 22], "w_pad": [21, 22], "x_p": [21, 22, 201], "empti": [21, 22, 25, 27, 35, 37, 45, 47, 53, 57, 59, 65, 73, 74, 77, 78, 81, 83, 84, 91, 92, 99, 108, 112, 114, 115, 116, 118, 119, 125, 131, 132, 141, 148, 149, 151, 152, 154, 156, 158, 164, 165, 166, 168, 169, 170, 176, 180, 181, 185, 187, 188, 190, 191, 193, 194, 195, 197, 204, 213, 214, 219, 221, 222, 228, 230, 234, 236, 237, 238, 240, 242, 243, 252, 253, 254, 255, 256, 257, 259, 260, 262, 263, 265, 268, 270, 312, 313, 314, 315, 316, 317, 355], "i_end": [21, 22], "j_end": [21, 22, 125, 132], "transpos": [21, 22, 113], "x_shape": [21, 22], "cols_reshap": [21, 22], "standard_norm": [21, 22, 26, 74, 111, 117, 118, 121, 123, 152, 155, 158, 166, 167, 178, 179, 185, 186, 188, 189, 192, 193, 200, 209, 210, 218, 221, 242, 244, 246, 247, 249, 254, 268], "dw": [21, 22, 221], "db": [21, 22, 132, 233, 345, 351, 358, 359, 370, 376, 378], "_cach": [21, 22], "w_col": [21, 22], "dout": [21, 22], "dout_col": [21, 22], "dcol": [21, 22], "dx": [21, 22, 35, 148, 149, 151, 152, 153, 155, 156, 158, 159, 162, 164, 165, 166, 168, 169, 170, 171, 173, 175, 177, 178, 179, 182, 183, 184, 187, 188, 190, 195, 196, 198, 199, 200, 201, 202, 203, 204, 205, 207, 208, 209, 211, 212, 213, 215, 216, 217, 218, 220, 222, 255, 267], "vw": [21, 22], "vb": [21, 22], "_mask": [21, 22], "pool": [21, 22, 106, 209, 230, 233, 244, 245, 256, 257, 260, 263, 267], "simplic": [21, 22, 103, 125, 134, 154, 187], "assum": [21, 22, 25, 26, 29, 36, 38, 46, 47, 49, 51, 52, 56, 57, 64, 65, 67, 73, 74, 83, 95, 96, 98, 103, 104, 106, 107, 108, 111, 112, 113, 114, 117, 119, 125, 139, 141, 154, 158, 161, 162, 164, 165, 168, 173, 178, 180, 181, 186, 187, 189, 191, 193, 196, 197, 200, 201, 207, 211, 215, 222, 223, 224, 225, 228, 230, 237, 239, 241, 242, 244, 245, 248, 252, 253, 254, 255, 256, 257, 259, 263, 264, 266, 267, 268, 269, 270, 271, 303, 322, 334, 386], "divis": [21, 22, 49, 50, 92, 93, 178, 179, 195, 233], "x_reshap": [21, 22], "mask": [21, 22, 27, 29, 31, 32, 37, 38, 47, 49, 50, 52, 53, 64, 69, 70, 72, 73, 77, 78, 81, 83, 84, 86, 87, 88, 95, 98, 100, 101, 120, 134, 140, 145, 148, 149, 151, 153, 154, 160, 164, 165, 166, 167, 168, 169, 171, 172, 173, 174, 179, 181, 182, 183, 184, 186, 187, 191, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 207, 211, 215, 216, 218, 219, 220, 223, 226, 228, 230, 235, 239, 240, 241, 251, 252, 254, 255, 258, 264, 265, 266, 268, 280, 286, 287, 288, 289, 292, 300, 318, 353, 393], "denom": [21, 22, 37, 41, 50, 53, 57, 67, 69, 70, 72, 78, 83, 92, 96, 97, 101, 112, 114, 119, 120, 124, 127, 129, 131, 132, 157, 163, 171, 177, 193, 204, 207, 213, 218, 222, 228, 229, 234, 246, 248, 255, 258, 262, 265, 270, 280], "keepdim": [21, 22, 25, 26, 28, 29, 46, 47, 56, 59, 73, 77, 78, 83, 105, 106, 108, 125, 127, 144, 159, 186, 202, 228, 230, 246, 248, 258, 262, 264, 393], "dx_reshap": [21, 22], "_shape": [21, 22], "softmax_cross_entropi": [21, 22], "finit": [21, 22, 27, 29, 69, 94, 95, 97, 100, 101, 103, 114, 117, 121, 148, 149, 150, 152, 153, 154, 155, 156, 158, 160, 161, 163, 164, 165, 167, 170, 172, 174, 175, 176, 178, 179, 181, 182, 184, 186, 187, 188, 189, 190, 198, 202, 204, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 219, 220, 221, 222, 225, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 247, 253, 254, 255, 256, 258, 259, 263, 267], "wai": [4, 21, 25, 26, 28, 32, 35, 36, 37, 39, 46, 49, 50, 53, 59, 70, 73, 75, 78, 90, 93, 95, 96, 97, 99, 101, 103, 104, 108, 109, 110, 113, 141, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 158, 160, 161, 162, 163, 164, 168, 170, 171, 174, 175, 176, 180, 182, 184, 185, 187, 189, 192, 195, 197, 198, 199, 200, 203, 206, 208, 209, 210, 211, 213, 214, 218, 219, 220, 221, 222, 224, 225, 226, 228, 229, 230, 232, 234, 235, 237, 241, 242, 244, 245, 246, 249, 251, 252, 253, 256, 259, 260, 261, 262, 263, 269, 281, 285, 311, 327, 346, 353, 359, 384], "verifi": [21, 22, 30, 37, 45, 49, 57, 67, 70, 72, 77, 78, 81, 83, 87, 88, 89, 93, 94, 96, 98, 99, 113, 142, 146, 150, 151, 155, 175, 182, 185, 188, 189, 198, 206, 207, 211, 216, 225, 228, 230, 249, 250, 251, 255, 258, 264, 358, 359], "kept": [21, 41, 214, 236, 346], "off": [0, 10, 21, 22, 30, 41, 50, 52, 53, 74, 91, 92, 94, 102, 103, 112, 114, 118, 119, 134, 136, 138, 139, 141, 144, 160, 171, 173, 185, 190, 197, 214, 229, 249, 256, 258, 261, 308, 330, 333, 342, 343, 370, 387, 397, 404], "grad_check_conv2d": [21, 22], "6": [21, 28, 29, 34, 39, 47, 50, 51, 56, 65, 67, 72, 84, 95, 119, 120, 121, 122, 124, 125, 127, 129, 131, 132, 135, 137, 141, 145, 146, 228, 244, 246, 256, 259, 269, 275, 284, 287, 289, 290, 291, 292, 294, 295, 296, 297, 298, 301, 303, 308, 310, 312, 316, 320, 321, 322, 323, 324, 325, 327, 328, 329, 335, 338, 341, 346, 351, 389, 394], "oc": [21, 22], "integ": [21, 22, 28, 31, 34, 36, 38, 41, 45, 46, 47, 49, 52, 56, 57, 59, 64, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 108, 109, 110, 127, 129, 131, 138, 139, 141, 144, 145, 153, 164, 165, 169, 198, 203, 209, 210, 213, 221, 222, 224, 225, 226, 227, 228, 230, 232, 233, 234, 235, 236, 237, 240, 241, 245, 247, 253, 255, 256, 257, 262, 263, 265, 269, 300], "ic": [21, 22], "out_p": [21, 22], "loss_p": [21, 22], "out_m": [21, 22], "loss_m": [21, 22], "num": [21, 22, 31, 37, 41, 49, 53, 57, 86, 129, 159, 166, 170, 182, 191, 199, 200, 212, 214, 215, 216, 227, 234, 248, 250, 251, 254, 262], "ana": [21, 22], "rel_err": [21, 22], "5f": [21, 22, 148], "3e": [21, 22, 28, 88, 93, 98, 100, 140, 142, 143, 144, 146, 172, 176, 183, 186, 229, 230], "rng_model": [21, 22], "conv1": [21, 22], "relu1": [21, 22], "pool1": 21, "conv2": [21, 22], "relu2": [21, 22], "pool2": 21, "flat": [21, 22, 27, 28, 32, 67, 78, 99, 114, 132, 146, 155, 157, 158, 171, 173, 184, 200, 205, 207, 211, 215, 217, 229], "fc": [21, 22, 170], "buffer": [4, 21, 22, 52, 109, 134, 136, 138, 139, 140, 145, 355, 385], "v_c1_w": 21, "v_c1_b": 21, "v_c2_w": 21, "v_c2_b": 21, "v_fc_w": [21, 22], "v_fc_b": [21, 22], "forward_numpi": [21, 22], "backward_numpi": [21, 22], "step_numpi": [21, 22], "global": [21, 22, 27, 29, 31, 49, 51, 53, 94, 125, 136, 143, 191, 242, 247, 249, 339, 341, 352, 386, 401], "argmax": [21, 22, 34, 37, 41, 49, 53, 57, 65, 69, 70, 72, 73, 74, 75, 78, 81, 83, 90, 103, 105, 106, 108, 110, 134, 139, 140, 148, 149, 153, 154, 155, 157, 161, 164, 168, 173, 175, 176, 184, 187, 197, 204, 219, 229, 234, 238, 240, 256, 393], "iterate_minibatch": [21, 22], "y_": [21, 22, 35, 36, 46, 47, 51, 56, 59, 67, 88, 89, 96, 99, 101, 105, 109, 112, 114, 116, 117, 118, 119, 122, 123, 125, 132, 160, 166, 190, 197, 239, 243, 249, 263, 267, 271, 280, 287, 296, 297, 298, 305, 306, 317, 322, 323, 328, 329], "rng_": [21, 22], "sl": [21, 22, 117, 123], "yield": [21, 22, 28, 41, 51, 57, 64, 75, 89, 94, 97, 99, 104, 108, 109, 122, 134, 135, 136, 139, 148, 151, 154, 156, 159, 160, 162, 164, 165, 166, 170, 171, 172, 173, 174, 178, 183, 184, 187, 190, 191, 196, 198, 199, 200, 201, 202, 203, 204, 205, 209, 212, 213, 214, 216, 218, 220, 221, 223, 224, 227, 228, 229, 230, 233, 234, 235, 236, 240, 245, 263, 264, 305, 391], "history_numpi": [21, 22], "yhat_train": [21, 22], "yhat_test": [21, 22], "02d": [21, 22, 108], "elaps": [21, 22, 134, 136, 138, 140, 141, 145], "2f": [21, 22, 27, 30, 31, 32, 34, 37, 39, 41, 49, 51, 53, 57, 64, 65, 69, 73, 74, 78, 89, 90, 91, 96, 99, 100, 104, 120, 124, 136, 139, 141, 142, 146, 169, 172, 176, 178, 184, 185, 197, 203, 209, 211, 212, 216, 228, 237, 243, 246, 247, 249, 251, 253, 254, 260, 264, 266, 267, 268, 319], "dfn": [21, 22, 166, 189, 191], "after": [21, 22, 25, 26, 28, 30, 32, 36, 39, 47, 49, 50, 56, 59, 67, 73, 74, 78, 89, 94, 97, 103, 105, 108, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 134, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 148, 151, 153, 156, 159, 160, 162, 167, 168, 172, 173, 174, 175, 184, 185, 188, 201, 202, 204, 206, 209, 211, 213, 215, 216, 220, 224, 225, 230, 231, 233, 234, 237, 238, 241, 243, 244, 252, 254, 256, 258, 260, 263, 266, 267, 268, 270, 300, 334, 335, 338, 355, 373, 381, 382], "misclassif": [21, 22, 51, 67, 109], "x0": [21, 22, 34, 37, 41, 53, 56, 64, 67, 74, 75, 91, 106, 108, 109, 113, 114, 119, 127, 129, 135, 137, 148, 151, 153, 155, 156, 159, 163, 166, 168, 170, 174, 175, 179, 181, 184, 188, 191, 192, 195, 199, 202, 204, 205, 211, 213, 214, 216, 222, 224, 225, 228, 239, 241, 260, 262, 266, 267, 269, 284, 289, 299, 312, 318], "out1": [21, 22], "yhat": [21, 22, 92, 115, 280], "list": [21, 22, 27, 29, 31, 32, 35, 36, 41, 45, 47, 52, 59, 73, 81, 83, 84, 88, 105, 110, 112, 115, 116, 117, 118, 119, 120, 122, 123, 124, 127, 129, 131, 134, 138, 139, 140, 141, 143, 144, 146, 157, 158, 161, 162, 195, 213, 216, 228, 230, 237, 238, 244, 246, 249, 252, 254, 258, 283, 284, 285, 286, 287, 288, 295, 299, 308, 311, 312, 313, 314, 315, 316, 317, 352], "mi": [21, 22, 38, 73, 84, 88, 98, 113, 122, 160, 304, 307], "n_show": [21, 22], "misclassifi": [21, 22, 52, 67], "zip": [21, 22, 27, 32, 37, 47, 64, 73, 109, 122, 124, 127, 129, 138, 139, 140, 141, 144, 145, 146, 151, 159, 163, 172, 178, 181, 200, 209, 226, 230, 234, 242, 243, 244, 247, 252, 257, 259, 260, 270, 312, 313, 314, 315, 316, 317, 349, 350], "conveni": [21, 28, 35, 36, 45, 52, 65, 78, 95, 102, 104, 108, 114, 150, 151, 152, 153, 157, 158, 160, 161, 163, 164, 167, 168, 169, 171, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188, 190, 193, 195, 198, 199, 202, 203, 205, 207, 208, 211, 212, 213, 214, 216, 219, 220, 221, 222, 227, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 241, 249, 255, 256, 260, 328], "etc": [21, 22, 32, 35, 36, 46, 69, 70, 72, 78, 83, 87, 88, 94, 95, 103, 118, 122, 142, 148, 159, 165, 166, 173, 179, 182, 183, 187, 192, 198, 199, 220, 221, 225, 226, 236, 239, 240, 241, 246, 252, 254, 256, 258, 260, 263, 264, 288, 300, 325, 331, 333, 334, 335, 338, 341, 343, 347, 348, 349, 354, 355, 358, 365, 371, 383, 384], "runtimeerror": [21, 22, 83, 115, 120, 124, 127, 131, 132, 141, 144, 145, 153, 170, 180, 204, 211, 220, 228, 237, 262, 266, 389], "avail": [21, 22, 25, 50, 53, 65, 69, 72, 73, 83, 84, 97, 108, 111, 115, 122, 125, 127, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 159, 160, 167, 173, 174, 177, 185, 187, 192, 208, 211, 216, 221, 225, 228, 229, 235, 237, 243, 246, 248, 253, 262, 264, 267, 268, 284, 287, 295, 300, 308, 332, 333, 334, 344, 345, 347, 350, 351, 352, 357, 359, 367, 368, 381, 409], "noisi": [21, 22, 28, 29, 30, 32, 34, 49, 57, 69, 75, 78, 86, 87, 89, 90, 103, 107, 129, 138, 141, 142, 145, 160, 166, 176, 181, 205, 209, 218, 221, 222, 229, 245, 258, 329, 340], "init": [21, 22, 31, 32, 73, 74, 77, 142, 143, 144, 145, 175, 334, 335, 358], "restrict": [21, 22, 72, 87, 88, 114, 117, 142, 190, 203, 214, 216, 228, 263, 269, 331, 339, 382], "cuda_ok": [21, 22, 142], "bool": [21, 22, 25, 27, 29, 32, 37, 46, 53, 57, 70, 81, 83, 99, 100, 108, 109, 112, 114, 115, 117, 118, 119, 120, 123, 124, 127, 131, 134, 136, 138, 139, 140, 142, 143, 144, 145, 146, 159, 170, 179, 181, 188, 212, 221, 224, 226, 230, 231, 232, 233, 236, 239, 241, 247, 249, 250, 251, 253, 266, 267, 270, 312, 313, 314, 315, 316, 317, 382], "xtr": [21, 22, 103], "from_numpi": [21, 22], "ytr": [21, 22], "xte": [21, 22, 103], "yte": [21, 22], "train_eval_load": [21, 22], "test_load": [21, 22], "tinycnn": 21, "kernel_s": [21, 22, 131], "batchnorm2d": [21, 22], "eval_load": [21, 22], "cross_entropi": [21, 22, 56], "dim": [21, 22, 31, 32, 105, 125, 127, 129, 131, 134, 136, 138, 139, 140, 141, 144, 145, 146, 340], "yhat_al": [21, 22], "history_torch": [21, 22], "batch_loss": [21, 22], "test_loss": [21, 22], "train_loss_ev": [21, 22], "test_loss_ev": [21, 22], "dft": [21, 22], "stall": [21, 141], "third": [21, 89, 148, 159, 185, 197, 212, 220, 230, 264, 371], "cs231n": [21, 22], "built": [22, 25, 27, 32, 47, 73, 103, 106, 109, 110, 148, 153, 159, 166, 183, 193, 200, 209, 221, 224, 230, 245, 247, 249, 254, 255, 257, 340, 353, 354, 356, 358, 371], "back": [22, 26, 39, 91, 92, 97, 102, 107, 109, 112, 114, 115, 119, 131, 138, 163, 175, 193, 220, 228, 233, 263, 308, 331, 338, 348, 351, 375, 381, 385], "matter": [22, 25, 29, 30, 31, 34, 35, 37, 45, 46, 47, 49, 50, 51, 57, 59, 67, 70, 72, 74, 81, 83, 84, 89, 90, 92, 93, 96, 97, 99, 101, 102, 109, 112, 114, 118, 127, 134, 143, 148, 156, 157, 160, 165, 166, 173, 179, 199, 203, 204, 211, 212, 215, 220, 221, 233, 236, 237, 240, 242, 243, 244, 245, 247, 248, 249, 252, 253, 255, 256, 257, 259, 260, 263, 266, 267, 269, 270, 287, 289, 293, 295, 297, 298, 335, 340], "becom": [22, 25, 26, 27, 28, 29, 30, 32, 39, 45, 46, 53, 67, 70, 72, 74, 78, 81, 83, 87, 88, 90, 91, 92, 95, 96, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 112, 114, 117, 123, 125, 134, 135, 138, 140, 146, 148, 150, 152, 153, 154, 157, 158, 161, 163, 164, 165, 168, 169, 170, 171, 173, 174, 175, 176, 180, 182, 183, 187, 189, 190, 193, 195, 196, 201, 202, 203, 205, 206, 209, 213, 214, 215, 216, 218, 220, 222, 226, 229, 230, 233, 234, 235, 236, 240, 241, 242, 246, 247, 248, 249, 252, 253, 254, 256, 257, 264, 266, 268, 270, 293, 331, 340, 350, 355, 358, 368, 382, 384], "flow": [4, 22, 197, 215, 331, 338, 341, 344, 346, 347, 355, 357, 381, 382], "block": [22, 69, 73, 74, 81, 94, 118, 123, 135, 136, 137, 145, 155, 171, 172, 174, 175, 176, 179, 185, 189, 194, 202, 207, 208, 212, 217, 219, 237, 241, 245, 246, 250, 252, 256, 263, 270, 332, 333, 334, 335, 342, 352, 355, 357], "fall": [22, 47, 70, 115, 131, 138, 142, 151, 168, 193, 211, 214, 225, 228, 233, 259, 305, 389], "extra": [22, 31, 32, 38, 45, 47, 53, 65, 67, 78, 81, 83, 84, 89, 90, 98, 102, 109, 119, 122, 136, 139, 142, 143, 144, 146, 158, 160, 170, 171, 199, 203, 207, 224, 225, 226, 228, 230, 242, 251, 253, 254, 261, 266, 288, 293, 368], "isn": [22, 32, 53, 81, 99, 102, 103, 105, 169, 211, 226, 230, 236, 237, 249, 253, 257, 268, 339, 379], "recap": 22, "introduct": [22, 35, 64, 65, 107, 117, 123, 178, 189, 261, 263, 381, 384, 385, 386], "00_overview": [22, 136, 285], "ipynb": [22, 126, 128, 129, 130, 135, 136, 137, 284, 285, 295, 322], "loop": [22, 31, 41, 75, 113, 118, 122, 137, 138, 139, 140, 143, 145, 148, 193, 209, 236, 288, 334, 356, 403], "imagenet": 22, "perfect": [22, 29, 37, 38, 41, 45, 46, 51, 57, 59, 64, 69, 70, 72, 74, 75, 78, 81, 84, 86, 87, 88, 90, 91, 92, 93, 100, 101, 104, 105, 217, 265, 267], "mechan": [22, 122, 149, 176, 188, 199, 213, 227, 229, 232, 233, 240, 245, 249, 257, 259, 268, 303, 331, 332, 333], "remov": [22, 26, 30, 89, 111, 116, 119, 141, 149, 156, 211, 214, 216, 222, 233, 252, 255, 268, 331, 339, 358, 377, 389], "tick": 22, "look": [22, 25, 26, 28, 29, 30, 31, 32, 34, 35, 38, 41, 45, 46, 50, 51, 53, 56, 57, 65, 67, 69, 70, 73, 74, 75, 77, 78, 81, 84, 89, 91, 93, 95, 97, 98, 103, 104, 105, 108, 109, 110, 112, 113, 114, 116, 119, 122, 125, 135, 138, 140, 143, 145, 148, 149, 157, 160, 167, 168, 169, 171, 172, 173, 181, 182, 183, 184, 186, 189, 191, 195, 201, 204, 206, 208, 210, 211, 213, 214, 215, 218, 219, 220, 221, 228, 239, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 253, 254, 255, 256, 259, 261, 265, 266, 267, 269, 313, 317, 318, 335, 353, 355, 381, 386], "locat": [22, 115, 148, 150, 153, 157, 158, 160, 162, 163, 166, 173, 174, 175, 176, 179, 182, 183, 185, 189, 191, 195, 199, 202, 205, 209, 210, 212, 213, 214, 217, 222, 226, 230, 235, 239, 240, 241, 245, 256, 257, 260, 268, 270, 339, 348, 353], "knob": [22, 25, 31, 32, 104, 115, 136, 140, 153, 210], "context": [22, 52, 105, 113, 121, 148, 167, 197, 218, 220, 239, 241, 242, 246, 261, 265, 332, 349, 358, 372, 381], "onc": [4, 22, 26, 27, 28, 32, 35, 36, 51, 68, 73, 76, 99, 103, 113, 138, 158, 161, 165, 172, 199, 216, 225, 232, 233, 241, 248, 249, 250, 251, 252, 256, 258, 271, 285, 332, 333, 347, 354, 355], "whether": [22, 30, 47, 53, 75, 77, 83, 93, 110, 142, 143, 145, 148, 149, 153, 154, 156, 157, 158, 160, 161, 163, 164, 166, 173, 177, 183, 184, 186, 190, 197, 198, 200, 208, 211, 212, 216, 217, 218, 220, 222, 225, 226, 228, 236, 237, 238, 239, 242, 245, 248, 250, 251, 252, 253, 254, 256, 257, 258, 259, 263, 264, 265, 266, 267, 315, 317, 322, 331], "spatial": [22, 25, 26, 32, 242], "shrink": [22, 53, 99, 103, 107, 113, 143, 159, 164, 174, 190, 200, 203, 235, 247, 264, 265], "slide": [22, 99, 129, 271, 286, 293, 299], "surpris": [22, 113, 151, 158, 161, 218, 242, 245, 248, 251, 252, 256, 261, 263, 266, 335, 342, 359, 379], "degrad": [22, 26, 45, 87, 108, 142], "wors": [22, 37, 38, 41, 45, 46, 69, 70, 86, 87, 88, 89, 90, 99, 100, 143, 304, 307, 340], "full": [22, 25, 27, 29, 32, 35, 38, 41, 49, 50, 52, 56, 57, 59, 67, 75, 77, 78, 81, 83, 84, 94, 106, 108, 111, 112, 113, 115, 119, 121, 122, 123, 125, 127, 132, 135, 137, 139, 141, 144, 158, 160, 161, 172, 173, 182, 185, 187, 191, 199, 202, 207, 210, 212, 213, 216, 218, 221, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 239, 241, 243, 248, 252, 255, 258, 264, 270, 287, 289, 308, 334, 341, 342, 359, 382], "heta": [22, 137, 193, 217], "aren": [22, 35, 36, 46, 109, 119, 138, 226, 230, 251, 263], "behav": [22, 37, 39, 52, 70, 73, 78, 83, 84, 92, 93, 97, 98, 101, 102, 103, 105, 107, 112, 125, 148, 153, 154, 155, 157, 160, 161, 163, 164, 166, 168, 170, 174, 175, 179, 181, 182, 185, 187, 188, 195, 204, 210, 212, 221, 230, 253, 255, 259, 261, 262, 267, 280, 296, 344, 359, 381], "path": [6, 7, 22, 31, 32, 67, 96, 97, 98, 99, 107, 114, 117, 119, 123, 150, 162, 178, 179, 195, 239, 287, 289, 311, 312, 313, 314, 315, 316, 317, 331, 332, 339, 340, 348, 352, 359, 367, 369, 374, 381], "rout": [1, 22, 150, 180, 225, 236, 338, 339, 340, 344, 347, 350, 357, 369, 381, 383, 384, 385, 386], "sketch": [22, 94, 135, 137, 157, 165, 166, 168, 177, 185, 189, 195, 201, 202, 213, 343, 346, 348, 349, 350, 351, 352, 354, 356, 357, 407], "rac": [22, 81, 152, 156, 160, 162, 193, 217, 231, 261, 264, 267, 270, 271], "big": [22, 30, 31, 32, 35, 45, 47, 51, 52, 56, 59, 64, 67, 81, 87, 91, 93, 95, 96, 97, 98, 103, 110, 111, 114, 121, 122, 135, 138, 139, 140, 141, 142, 144, 145, 146, 150, 151, 158, 159, 161, 163, 169, 170, 174, 176, 178, 184, 185, 186, 188, 189, 190, 194, 195, 197, 198, 199, 200, 201, 204, 205, 206, 210, 212, 213, 214, 219, 221, 224, 227, 228, 229, 231, 234, 235, 237, 239, 242, 254, 255, 265, 394], "which": [22, 25, 26, 29, 30, 31, 34, 37, 38, 52, 53, 56, 57, 64, 69, 73, 74, 75, 81, 83, 86, 90, 92, 93, 94, 96, 97, 98, 99, 100, 102, 103, 105, 109, 111, 116, 117, 119, 121, 124, 127, 144, 148, 150, 151, 152, 154, 155, 157, 158, 159, 160, 162, 164, 165, 166, 168, 169, 170, 172, 173, 174, 175, 176, 178, 179, 180, 182, 183, 184, 186, 187, 189, 190, 191, 192, 195, 196, 197, 198, 199, 201, 202, 203, 204, 207, 208, 209, 211, 213, 215, 217, 218, 219, 220, 222, 223, 224, 225, 229, 230, 231, 232, 234, 235, 239, 240, 241, 242, 243, 244, 248, 251, 252, 253, 255, 257, 258, 259, 260, 263, 264, 271, 286, 287, 290, 294, 300, 308, 331, 339, 342, 370, 372, 373, 374, 389], "residualblock": 22, "meant": [22, 31, 47, 110, 115, 116, 146, 255, 334, 335], "fastest": [22, 31, 220, 384], "faith": [22, 32, 132], "dataclass": [22, 29, 30, 52, 103, 108, 109, 110, 138, 139, 141, 142, 143, 144, 211, 227, 258, 267], "dskip": 22, "re": [22, 27, 30, 31, 32, 34, 38, 46, 52, 57, 73, 74, 77, 78, 81, 87, 105, 107, 109, 110, 113, 116, 119, 120, 124, 143, 146, 151, 153, 154, 155, 158, 159, 163, 164, 165, 166, 168, 169, 172, 173, 174, 175, 176, 178, 179, 180, 181, 187, 188, 191, 192, 193, 199, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 222, 224, 225, 226, 228, 229, 231, 232, 233, 237, 238, 239, 240, 241, 243, 244, 248, 249, 254, 256, 260, 261, 263, 264, 266, 268, 269, 270, 334, 338, 370, 371], "low": [4, 22, 25, 27, 28, 29, 30, 32, 35, 36, 46, 49, 51, 53, 64, 65, 72, 77, 83, 84, 87, 89, 91, 92, 93, 94, 96, 99, 101, 105, 106, 112, 121, 135, 137, 138, 143, 145, 153, 154, 157, 170, 175, 187, 190, 197, 203, 209, 223, 225, 226, 227, 236, 237, 238, 241, 245, 247, 251, 252, 254, 255, 258, 259, 260, 261, 262, 268, 269, 303, 305, 333, 340, 341, 345, 353, 394], "level": [22, 29, 31, 32, 41, 47, 49, 51, 52, 75, 84, 87, 91, 92, 93, 94, 96, 99, 105, 109, 120, 121, 125, 127, 129, 135, 137, 138, 143, 145, 159, 171, 172, 178, 179, 183, 184, 190, 191, 192, 218, 227, 228, 243, 244, 245, 247, 249, 250, 251, 252, 254, 256, 257, 259, 260, 261, 262, 263, 266, 267, 268, 269, 285, 296, 334, 335, 339, 340, 342, 346, 348, 352, 353, 357, 374, 382, 393, 407], "catch": [22, 90, 287, 355, 366], "mistak": [22, 34, 38, 51, 56, 57, 67, 69, 90, 94, 96, 102, 107, 110, 268, 288, 372, 382], "few": [22, 25, 30, 36, 46, 47, 51, 56, 57, 64, 65, 69, 73, 75, 83, 86, 89, 91, 93, 96, 99, 107, 111, 112, 114, 119, 125, 134, 151, 152, 155, 165, 170, 174, 175, 178, 179, 181, 185, 186, 193, 194, 196, 200, 202, 203, 215, 217, 225, 232, 234, 240, 241, 248, 250, 252, 254, 258, 261, 263, 300, 327, 359], "entri": [22, 27, 28, 29, 30, 51, 53, 57, 73, 81, 113, 127, 159, 185, 186, 189, 206, 209, 216, 230, 237, 347, 349, 357, 378], "ish": [22, 26, 32, 35, 57, 64, 87, 91, 93, 108, 110, 115, 123, 136, 146, 153, 157, 160, 168, 179, 188, 196, 199, 215, 228, 243, 255, 257, 258, 385], "res1": 22, "v_conv1_w": 22, "v_conv1_b": 22, "v_res1_c1_w": 22, "v_res1_c1_b": 22, "v_res1_c2_w": 22, "v_res1_c2_b": 22, "saniti": [22, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 47, 49, 53, 59, 70, 73, 74, 77, 81, 83, 84, 95, 96, 110, 112, 138, 143, 144, 148, 149, 150, 151, 152, 153, 154, 156, 158, 160, 161, 163, 164, 165, 166, 169, 170, 171, 172, 173, 176, 177, 178, 179, 181, 183, 184, 185, 186, 187, 190, 191, 192, 193, 195, 196, 198, 200, 201, 202, 203, 204, 206, 208, 209, 210, 212, 216, 217, 219, 220, 221, 222, 223, 225, 227, 228, 229, 230, 232, 233, 234, 235, 237, 240, 241, 253, 254, 260, 264, 353], "befor": [5, 22, 25, 27, 31, 32, 47, 49, 67, 84, 89, 93, 95, 102, 103, 107, 108, 110, 112, 117, 120, 122, 124, 127, 131, 132, 136, 138, 139, 141, 144, 145, 146, 153, 162, 181, 189, 206, 225, 227, 231, 234, 235, 242, 243, 244, 247, 254, 259, 261, 263, 266, 267, 268, 269, 270, 284, 301, 314, 316, 319, 323, 328, 333, 334, 335, 338, 339, 352, 367], "now": [22, 49, 81, 99, 119, 143, 157, 160, 162, 164, 165, 179, 205, 209, 213, 219, 242, 250, 259, 271, 340, 359, 382], "defin": [22, 25, 26, 29, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 50, 51, 52, 53, 56, 57, 59, 65, 69, 70, 72, 73, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 107, 111, 112, 114, 116, 117, 118, 119, 121, 122, 123, 125, 134, 135, 137, 139, 141, 142, 144, 146, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 170, 171, 172, 173, 174, 175, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 221, 222, 223, 224, 227, 228, 229, 230, 231, 232, 233, 234, 235, 237, 238, 239, 241, 244, 250, 251, 254, 255, 261, 264, 266, 267, 268, 270, 271, 275, 281, 285, 290, 291, 294, 295, 297, 298, 302, 304, 307, 309, 310, 320, 321, 324, 325, 326, 327, 329, 331, 332, 334, 335, 340, 356, 357, 358, 359, 369, 371, 373, 379, 384, 386, 409], "higher": [22, 26, 30, 32, 35, 36, 37, 45, 46, 50, 53, 64, 65, 73, 75, 86, 88, 101, 105, 111, 116, 117, 134, 138, 141, 142, 143, 146, 154, 171, 173, 179, 180, 182, 184, 187, 191, 197, 204, 211, 219, 224, 225, 227, 228, 235, 240, 241, 249, 251, 253, 257, 261, 263, 265, 269, 334, 341, 342, 345, 353, 374, 389], "batchnorm": 22, "resblock": 22, "ch": [22, 67], "bn1": 22, "bn2": 22, "tinyresnet": 22, "stem": 22, "block1": 22, "cell": [22, 32, 59, 75, 78, 107, 112, 127, 131, 132, 135, 137, 153, 154, 187, 201, 207, 209, 213, 217, 228, 230, 232, 243, 246, 250, 251, 258, 261, 270, 271, 275, 281, 285, 290, 291, 293, 294, 297, 298, 302, 303, 304, 307, 309, 310, 319, 320, 321, 323, 324, 325, 326, 389], "abov": [22, 37, 39, 56, 57, 64, 65, 77, 81, 88, 89, 98, 101, 103, 111, 136, 139, 141, 143, 150, 151, 153, 156, 164, 167, 169, 172, 174, 177, 179, 182, 183, 185, 187, 190, 196, 203, 205, 210, 212, 213, 214, 216, 218, 219, 220, 221, 222, 229, 235, 240, 246, 247, 250, 256, 257, 262, 266, 268, 269], "let": [22, 25, 28, 29, 30, 35, 36, 37, 38, 41, 46, 47, 50, 52, 57, 59, 65, 67, 69, 70, 72, 73, 75, 77, 78, 81, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 101, 102, 103, 105, 107, 109, 110, 111, 114, 116, 117, 118, 119, 120, 122, 123, 125, 129, 135, 136, 142, 145, 146, 148, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 194, 195, 196, 197, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 244, 245, 249, 250, 252, 253, 254, 257, 258, 260, 262, 263, 264, 267, 268, 270, 280, 281, 285, 288, 296, 299, 301, 303, 308, 323, 335, 347, 355, 357, 358, 371, 373, 384, 386], "up": [22, 26, 27, 29, 30, 32, 45, 46, 52, 53, 64, 69, 70, 72, 73, 74, 77, 83, 92, 96, 98, 104, 105, 106, 107, 108, 111, 112, 113, 117, 121, 131, 134, 136, 138, 139, 140, 141, 143, 144, 145, 146, 150, 151, 153, 155, 157, 160, 161, 165, 166, 168, 169, 171, 172, 177, 178, 179, 180, 184, 185, 190, 191, 192, 193, 194, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 213, 214, 217, 219, 220, 221, 225, 226, 227, 229, 231, 233, 235, 236, 237, 240, 241, 242, 244, 246, 247, 252, 257, 259, 260, 265, 268, 328, 332, 334, 335, 338, 342, 344, 346, 349, 351, 352, 355, 356, 357, 358, 359, 365, 366, 367, 368, 381], "larger": [22, 30, 32, 35, 36, 41, 52, 64, 65, 74, 77, 83, 84, 88, 89, 92, 93, 95, 98, 101, 102, 109, 113, 114, 118, 119, 138, 139, 141, 142, 143, 144, 146, 148, 153, 154, 155, 157, 159, 161, 162, 165, 166, 167, 169, 171, 172, 173, 174, 175, 176, 178, 179, 182, 183, 187, 188, 190, 191, 193, 194, 195, 196, 199, 200, 202, 203, 204, 206, 209, 213, 215, 218, 219, 221, 224, 225, 226, 227, 228, 229, 231, 232, 233, 235, 240, 241, 242, 244, 248, 250, 252, 253, 255, 256, 257, 258, 259, 260, 264, 265, 266, 269, 327, 338], "bigger": [22, 38, 84, 91, 92, 107, 138, 186, 261, 269], "gpu": [22, 143, 145, 342], "huge": [22, 30, 46, 49, 73, 90, 92, 93, 98, 101, 105, 113, 148, 170, 171, 178, 180, 182, 183, 184, 217, 219, 235, 246, 263, 266, 365], "ecosystem": [22, 332, 333, 344, 346, 350], "real": [8, 22, 25, 26, 29, 30, 31, 35, 36, 37, 38, 50, 52, 56, 59, 77, 81, 88, 98, 104, 107, 108, 109, 112, 117, 121, 141, 156, 174, 184, 190, 207, 208, 228, 238, 243, 246, 249, 255, 260, 262, 263, 267, 285, 299, 318, 335, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 351, 352, 353, 354, 355, 356, 357, 389], "alwai": [22, 25, 30, 32, 34, 38, 39, 41, 45, 46, 50, 57, 74, 84, 86, 87, 89, 93, 94, 97, 100, 101, 102, 105, 107, 114, 116, 138, 140, 141, 150, 161, 165, 167, 169, 173, 174, 177, 178, 179, 186, 195, 201, 204, 206, 208, 211, 212, 213, 216, 217, 219, 231, 233, 234, 238, 241, 245, 248, 250, 251, 252, 254, 255, 257, 258, 261, 263, 264, 265, 266, 267, 268, 269, 270, 333, 335, 343, 351, 359, 372, 382], "prototyp": [22, 292, 295, 316], "iter": [22, 29, 31, 34, 38, 41, 49, 50, 53, 57, 64, 65, 75, 78, 86, 87, 88, 91, 92, 93, 94, 95, 100, 101, 104, 107, 110, 112, 127, 131, 132, 139, 140, 145, 146, 165, 185, 204, 231, 236, 237, 308], "similar": [22, 29, 30, 32, 33, 34, 36, 45, 65, 68, 70, 74, 75, 81, 83, 89, 90, 104, 105, 109, 110, 117, 125, 132, 143, 148, 171, 181, 196, 202, 206, 209, 220, 221, 242, 243, 244, 250, 251, 252, 253, 257, 260, 270, 285, 295, 319, 359], "know": [22, 25, 26, 30, 32, 34, 35, 46, 47, 51, 56, 78, 84, 87, 94, 99, 108, 113, 117, 122, 152, 154, 155, 158, 161, 168, 171, 175, 178, 180, 184, 187, 198, 200, 202, 203, 207, 212, 213, 215, 217, 219, 222, 233, 237, 240, 245, 246, 252, 253, 257, 264, 269, 285, 339, 343, 346, 349, 350, 351, 352, 353, 354, 356, 357, 371, 381, 382, 384, 385], "happen": [22, 29, 31, 38, 39, 45, 70, 72, 75, 83, 86, 88, 89, 105, 114, 125, 139, 141, 161, 162, 167, 168, 174, 175, 188, 196, 207, 214, 216, 217, 222, 231, 234, 236, 242, 243, 246, 248, 250, 257, 258, 263, 267, 355, 358, 373, 381], "hood": [22, 107, 161, 171, 358], "debug": [22, 73, 81, 84, 296, 304, 307, 340, 346, 358, 359, 374, 381, 385, 386], "satur": [22, 45, 93, 95, 98, 171, 174, 198, 208, 216, 265, 340, 381, 386], "veri": [22, 25, 28, 29, 31, 32, 34, 35, 36, 39, 45, 46, 49, 50, 53, 56, 57, 64, 65, 67, 70, 77, 83, 84, 89, 92, 93, 97, 98, 99, 100, 102, 103, 104, 105, 109, 110, 138, 142, 146, 148, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 163, 165, 166, 167, 170, 171, 172, 173, 175, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 199, 205, 207, 208, 210, 211, 214, 215, 217, 219, 220, 222, 224, 228, 229, 230, 232, 233, 235, 237, 240, 241, 242, 244, 245, 246, 247, 248, 250, 252, 253, 256, 257, 258, 259, 261, 262, 264, 265, 266, 268, 296, 341, 345, 352, 355, 356], "reduc": [3, 7, 22, 25, 46, 51, 52, 57, 74, 78, 87, 89, 96, 98, 99, 105, 107, 110, 112, 119, 123, 134, 137, 138, 139, 141, 142, 144, 145, 148, 158, 159, 166, 170, 171, 173, 177, 180, 182, 183, 185, 191, 193, 197, 199, 203, 207, 210, 211, 216, 221, 223, 228, 232, 233, 237, 241, 247, 248, 250, 252, 257, 263, 265, 268, 270, 280, 284, 288, 303, 334, 339, 343, 345, 349, 355, 357, 358, 359, 368, 371, 372], "advanc": [22, 160, 219, 220, 310], "2015": [22, 87, 88, 139, 280, 303], "recognit": [22, 30, 46], "stat": [29, 32, 86, 87, 94, 104, 120, 124, 127, 131, 132, 136, 140, 141, 144, 146, 148, 150, 160, 163, 165, 170, 176, 177, 179, 186, 190, 191, 196, 202, 206, 212, 216, 220, 223, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 251, 252, 253, 255, 257, 258, 259, 260, 261, 262, 264, 265, 266, 267, 268, 269, 270, 295, 358, 383], "vector": [26, 28, 30, 31, 32, 34, 38, 45, 47, 52, 53, 67, 70, 81, 84, 91, 93, 96, 97, 103, 108, 112, 113, 122, 123, 125, 127, 129, 131, 134, 139, 140, 141, 143, 146, 150, 154, 160, 167, 168, 174, 177, 181, 185, 186, 187, 189, 193, 200, 201, 202, 205, 206, 208, 209, 211, 213, 217, 219, 221, 223, 224, 225, 226, 228, 229, 230, 231, 233, 234, 236, 237, 240, 242, 253, 254, 258, 261, 264, 267, 268, 286, 289, 291, 308, 318, 324, 328], "project": [26, 30, 31, 106, 107, 113, 146, 185, 202, 206, 212, 260, 331, 334, 338, 343, 349, 351, 352, 354, 356, 357, 358], "norm": [25, 28, 49, 72, 74, 75, 81, 83, 90, 94, 95, 101, 103, 104, 108, 109, 120, 124, 127, 131, 132, 138, 140, 141, 143, 148, 151, 155, 157, 158, 160, 163, 168, 170, 175, 176, 178, 179, 181, 183, 185, 186, 188, 192, 197, 199, 200, 202, 208, 210, 211, 212, 214, 218, 221, 292, 293], "inner": [27, 29, 69, 109, 149, 164, 195, 305], "product": [27, 29, 30, 47, 56, 59, 99, 107, 108, 109, 116, 122, 135, 140, 146, 149, 155, 158, 161, 178, 183, 185, 193, 200, 204, 207, 208, 221, 226, 232, 237, 241, 246, 252, 255, 256, 266, 267, 269, 296, 332, 333, 338, 339, 343, 344, 348, 358, 374, 381, 385], "elimin": 46, "condit": [56, 65, 72, 73, 84, 87, 91, 94, 95, 96, 99, 100, 109, 112, 113, 116, 117, 118, 119, 122, 123, 139, 148, 150, 151, 153, 158, 165, 168, 172, 173, 177, 179, 180, 189, 191, 199, 200, 203, 205, 207, 208, 211, 213, 214, 215, 216, 224, 225, 228, 229, 233, 235, 236, 239, 253, 261, 263, 332, 334, 341], "factor": [26, 30, 38, 45, 88, 92, 94, 97, 98, 101, 102, 103, 107, 109, 117, 118, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 151, 159, 161, 170, 177, 183, 184, 185, 189, 202, 205, 208, 221, 224, 228, 237, 243, 244, 253, 257, 392], "qr": 87, "svd": [29, 107], "eigendecomposit": [27, 29, 30, 189], "geometr": [27, 31, 32, 39, 69, 70, 75, 109, 112, 150, 162, 183, 184, 189, 205, 211, 212, 223, 225, 227, 238, 240], "numpi": [26, 27, 28, 29, 30, 31, 32, 36, 37, 39, 41, 45, 50, 52, 53, 69, 70, 72, 78, 81, 88, 95, 103, 104, 106, 107, 108, 109, 111, 114, 115, 117, 120, 121, 123, 124, 125, 126, 127, 129, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 152, 166, 168, 173, 180, 181, 184, 185, 188, 193, 215, 216, 224, 226, 228, 230, 232, 233, 236, 239, 242, 245, 250, 252, 253, 254, 255, 256, 258, 261, 262, 263, 265, 271, 275, 280, 281, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 389, 393, 394], "regress": [29, 39, 41, 49, 50, 53, 74, 87, 88, 92, 98, 99, 106, 108, 113, 115, 116, 119, 123, 127, 128, 131, 134, 136, 138, 139, 146, 157, 166, 176, 177, 181, 185, 189, 191, 194, 207, 208, 214, 223, 236, 242, 244, 245, 248, 249, 252, 254, 258, 261, 283, 285, 296, 306, 320, 321, 327, 328], "classif": [35, 36, 38, 39, 40, 41, 42, 43, 45, 46, 49, 50, 52, 57, 64, 65, 66, 70, 74, 75, 81, 104, 106, 108, 128, 228, 283, 285, 290, 291, 293, 294, 296], "cluster": [31, 32, 74, 75, 77, 78, 79, 80, 99, 110, 112, 161, 207, 222, 226, 236, 256, 260, 262, 263, 264, 269, 283, 285, 331, 335, 343, 344, 345, 346, 353, 366, 369, 370, 372, 373, 376, 377, 379, 382], "manifold": [27, 29, 30, 31, 74], "usag": [38, 116, 142, 143, 146, 152, 155, 162, 163, 165, 170, 173, 175, 181, 184, 185, 188, 193, 196, 198, 201, 202, 203, 209, 215, 222, 225, 227, 237, 270, 340, 385], "applic": [25, 26, 67, 113, 148, 171, 178, 186, 195, 209, 216, 225, 229, 239, 245, 338, 339, 340, 341, 342, 346, 347, 351, 353, 358, 367, 368, 376, 378, 382], "pack": [25, 32], "togeth": [25, 26, 30, 31, 32, 37, 45, 72, 75, 77, 81, 107, 122, 177, 185, 191, 212, 221, 253, 374], "separ": [25, 26, 30, 31, 32, 37, 38, 52, 75, 84, 87, 89, 94, 102, 103, 105, 106, 108, 109, 113, 118, 134, 140, 145, 160, 192, 197, 209, 243, 244, 249, 252, 269, 271, 295, 303, 306, 323, 331, 335, 346, 349, 352, 353, 355, 359, 365, 372], "spars": [25, 28, 32, 51, 52, 53, 103, 107, 108, 109, 140, 141, 159, 176, 228, 246, 286, 310], "That": [25, 27, 30, 31, 32, 38, 41, 45, 46, 49, 50, 59, 65, 69, 72, 75, 77, 78, 81, 83, 86, 87, 100, 101, 103, 104, 105, 107, 113, 114, 121, 148, 158, 162, 172, 173, 179, 184, 188, 197, 202, 210, 213, 233, 244, 246, 249, 250, 251, 254, 256, 260, 264, 266, 269, 371], "view": [25, 31, 32, 51, 52, 64, 65, 95, 100, 101, 109, 111, 115, 116, 119, 121, 125, 146, 148, 153, 154, 163, 164, 168, 170, 176, 179, 181, 182, 185, 189, 193, 195, 207, 208, 211, 212, 222, 224, 228, 231, 233, 234, 237, 239, 240, 241, 242, 246, 248, 253, 254, 263, 266, 270, 271, 284, 285, 358, 372, 384], "superpow": 25, "arbitrari": [25, 26, 59, 69, 73, 75, 77, 81, 100, 125, 153, 219, 227, 255, 256, 260, 262, 263, 265], "ball": [25, 233], "belong": [25, 32, 77, 230, 257, 285], "sensit": [2, 25, 26, 28, 31, 32, 37, 38, 39, 41, 45, 46, 49, 52, 56, 57, 64, 65, 67, 74, 83, 86, 87, 90, 94, 96, 98, 100, 103, 108, 109, 145, 148, 149, 154, 160, 161, 163, 166, 168, 173, 174, 175, 176, 179, 180, 182, 187, 188, 191, 192, 195, 197, 199, 200, 205, 207, 208, 210, 211, 217, 219, 221, 246, 250, 252, 253, 254, 255, 256, 257, 258, 259, 262, 263, 264, 265, 267, 270, 286, 287, 332, 334, 335, 338, 343, 365, 376, 389], "distanc": [25, 28, 31, 32, 51, 70, 72, 73, 74, 77, 81, 84, 96, 101, 103, 104, 107, 109, 130, 132, 141, 148, 164, 177, 189, 201, 203, 205, 219, 221, 229, 248, 254, 256, 263, 284, 288, 290, 292, 313, 316, 319], "struggl": [25, 103, 303], "commonli": [25, 32, 39, 41, 52, 57, 59, 73, 74, 83, 92, 110, 112, 129, 134, 142, 159, 171, 175, 183, 190, 204, 205, 220, 221, 222, 241, 242, 244, 251, 257, 259, 263, 264, 267, 270, 333, 340, 341, 343, 345, 346, 347, 348, 349, 351, 352, 353, 354, 355, 358, 359, 381, 382, 383, 384, 385], "pca": [25, 32, 105, 189, 221], "umap": [25, 30], "sne": [25, 30], "emb": [25, 27, 31, 32, 284], "meaning": [25, 29, 30, 31, 32, 41, 46, 50, 74, 81, 83, 86, 89, 100, 110, 125, 178, 179, 192, 197, 262, 265, 266, 271], "distinguish": [25, 26, 38, 156, 293, 296], "describ": [25, 32, 68, 72, 73, 105, 113, 122, 174, 175, 180, 185, 186, 188, 191, 199, 209, 221, 233, 234, 257, 258, 260, 265, 270, 285, 322, 331, 333, 335, 338, 373], "process": [25, 94, 111, 112, 114, 117, 119, 121, 139, 144, 150, 156, 157, 163, 169, 171, 174, 176, 178, 179, 185, 189, 191, 194, 195, 201, 205, 214, 216, 218, 221, 222, 225, 229, 233, 235, 236, 237, 239, 240, 242, 245, 250, 300, 322, 342, 343, 346, 347, 348, 349, 350, 352, 354, 355, 356, 358, 359, 381, 382, 385], "x1": [25, 26, 30, 34, 37, 41, 46, 49, 52, 53, 56, 64, 65, 67, 70, 72, 73, 74, 75, 77, 78, 81, 84, 91, 93, 103, 104, 105, 106, 107, 108, 109, 110, 127, 129, 135, 137, 151, 159, 163, 164, 174, 181, 183, 184, 189, 194, 196, 202, 208, 213, 216, 218, 226, 228, 230, 241, 260, 262, 264, 265, 266, 267, 269, 284, 289, 299, 312, 318], "xn": [25, 27, 269], "xi": [25, 104, 202, 219, 230], "dist": [25, 27, 29, 32, 74, 83, 105, 125, 136, 140, 142, 143, 144, 146, 152, 153, 154, 156, 160, 166, 168, 169, 174, 180, 181, 182, 183, 184, 187, 190, 193, 194, 196, 197, 200, 201, 205, 208, 211, 213, 219, 221, 223, 234, 241, 287, 292, 333], "euclidean": [25, 28, 29, 31, 32, 73, 74, 83, 101, 105, 125, 186, 287, 295, 319], "unless": [25, 47, 74, 77, 92, 99, 101, 105, 106, 114, 122, 125, 148, 152, 158, 160, 161, 165, 166, 173, 177, 184, 191, 192, 199, 205, 207, 210, 211, 216, 220, 237, 238, 246, 261, 296, 335, 342, 351, 354, 358, 366, 371, 375], "n\u03b5": 25, "q": [25, 31, 38, 41, 46, 47, 56, 59, 86, 87, 94, 113, 120, 122, 124, 125, 134, 138, 143, 144, 145, 146, 148, 151, 153, 154, 155, 157, 160, 161, 164, 165, 168, 171, 172, 173, 174, 175, 176, 179, 180, 183, 184, 185, 187, 189, 193, 196, 197, 199, 200, 201, 202, 203, 205, 207, 209, 213, 216, 219, 220, 221, 222, 223, 224, 225, 226, 229, 231, 235, 236, 237, 246, 248, 252, 253, 261, 305], "minimum": [25, 27, 56, 67, 74, 95, 96, 102, 119, 127, 129, 140, 142, 143, 145, 167, 178, 184, 193, 212, 219, 227, 231, 267, 393], "itself": [25, 30, 52, 73, 88, 113, 116, 117, 123, 226, 229, 240, 252, 255, 262, 263, 264, 265, 350, 356, 358, 369], "id": [1, 25, 69, 70, 72, 73, 75, 77, 78, 81, 84, 134, 136, 142, 143, 144, 145, 238, 241, 296, 332, 334, 335, 338, 339, 342, 343, 344, 347, 349, 350, 381, 382], "qualit": [25, 70, 75, 83, 140, 230, 234, 235], "kmean": [25, 69, 74, 77, 83], "make_blob": [25, 52, 56, 67, 69, 74, 75, 77, 104, 106, 108, 109], "adjusted_rand_scor": [25, 68, 75, 77, 81], "neighbor": [25, 27, 28, 31, 32, 83, 287, 319], "nearestneighbor": [25, 27, 28, 32], "sphere": [25, 186, 202], "assign": [25, 32, 35, 56, 69, 72, 73, 74, 75, 77, 81, 83, 84, 138, 141, 152, 159, 204, 206, 212, 217, 238, 253, 260, 263, 267, 270, 285, 295, 316, 322, 359], "closest": [25, 31, 32, 39, 74], "center": [25, 26, 27, 28, 29, 30, 52, 56, 64, 67, 69, 70, 72, 73, 74, 75, 77, 81, 83, 84, 89, 90, 99, 103, 104, 106, 107, 108, 109, 112, 114, 148, 149, 151, 155, 156, 158, 159, 160, 161, 163, 175, 176, 178, 181, 185, 189, 194, 202, 205, 206, 209, 210, 212, 217, 222, 227, 229, 230, 233, 242, 244, 245, 250, 254, 255, 256, 264], "walk": [25, 116, 165, 178, 186, 188, 195, 239], "nearbi": [25, 31, 32, 105, 339], "ever": [25, 29, 32, 39, 109], "desert": 25, "discov": [25, 26, 138, 285, 295, 345, 348, 384, 386], "convex": [25, 31, 52, 67, 74, 83, 86, 87, 91, 92, 93, 94, 96, 97, 99, 101, 109, 157, 391], "interleav": 25, "moon": [25, 30, 74, 83, 103], "outlier": [25, 31, 52, 83, 86, 87, 92, 94, 95, 96, 100, 109, 113, 119, 125, 148, 155, 157, 160, 166, 177, 179, 182, 184, 187, 188, 194, 199, 207, 210, 214, 217, 222, 242, 244, 248, 250, 252, 254, 255, 257, 258, 259, 263, 264, 265, 266, 268, 269, 270, 280, 284, 285, 322], "x_moon": [25, 30, 110], "450": [21, 22, 25, 29, 35, 37, 46, 57, 64, 75, 78, 83, 88, 100, 104, 105, 108, 110, 111, 113, 115, 117, 119, 125, 134, 146, 152, 155, 175, 176, 178, 191, 196, 207, 210, 225, 244, 260, 268], "vstack": [25, 34, 37, 41, 53, 64, 70, 72, 73, 74, 81, 83, 84, 106, 107, 108, 110, 119, 123, 125, 129, 159, 253], "yet": [25, 35, 36, 65, 108, 141, 280], "85": [25, 27, 31, 32, 35, 36, 37, 56, 64, 67, 70, 75, 89, 94, 99, 107, 108, 135, 137, 139, 142, 159, 222, 237, 245, 250, 260, 261, 263, 270, 299], "scaleanchor": [25, 29, 30, 31, 35, 45, 53, 65, 70, 74, 83, 104, 105, 106, 108, 140, 178, 228, 230, 248], "scaleratio": [25, 29, 30, 31, 35, 45, 65, 70, 74, 83, 104, 105, 106, 108, 140, 178, 228, 230, 248], "question": [17, 18, 23, 24, 25, 28, 31, 32, 35, 70, 73, 87, 89, 107, 133, 147, 157, 159, 164, 172, 177, 190, 197, 200, 208, 218, 219, 228, 231, 233, 241, 243, 244, 245, 250, 251, 253, 255, 256, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 282, 310, 340], "radiu": [25, 27, 74, 118, 132, 135, 140, 146, 164, 167, 186, 201, 205, 206, 220, 222, 357, 359], "epsilon": [25, 92, 98, 109, 132, 134, 136, 138, 139, 140, 141, 142, 143, 145, 152, 257], "all": [25, 26, 27, 28, 29, 31, 32, 34, 35, 36, 38, 45, 47, 49, 50, 51, 53, 57, 64, 67, 68, 70, 72, 73, 74, 75, 77, 78, 83, 84, 86, 88, 89, 90, 92, 95, 99, 100, 101, 103, 107, 110, 111, 112, 113, 114, 116, 117, 118, 122, 123, 125, 127, 129, 132, 139, 145, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 178, 179, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 227, 228, 229, 230, 233, 234, 235, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 249, 251, 252, 253, 255, 257, 258, 259, 260, 261, 263, 266, 267, 269, 270, 271, 275, 280, 285, 311, 312, 313, 314, 315, 316, 317, 334, 356, 358, 373, 377, 379, 381, 382, 385], "within": [25, 46, 52, 59, 74, 75, 77, 83, 92, 106, 108, 109, 116, 125, 127, 129, 132, 141, 181, 184, 194, 214, 216, 217, 233, 238, 243, 244, 245, 249, 250, 252, 257, 259, 263, 266, 268, 295, 341, 355], "given": [25, 27, 28, 30, 35, 41, 67, 68, 69, 70, 72, 73, 77, 78, 83, 84, 88, 95, 100, 102, 108, 111, 112, 113, 117, 121, 123, 125, 127, 129, 132, 137, 139, 145, 148, 151, 154, 155, 157, 159, 162, 163, 165, 166, 167, 169, 170, 174, 177, 179, 184, 185, 186, 187, 189, 191, 193, 195, 199, 200, 202, 204, 207, 210, 211, 213, 214, 216, 221, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 237, 239, 240, 242, 244, 245, 246, 249, 250, 251, 256, 261, 266, 270, 285, 287, 289, 295, 301, 316, 319, 393], "ha": [25, 27, 29, 30, 32, 34, 36, 37, 39, 41, 45, 52, 53, 57, 65, 70, 73, 74, 75, 81, 83, 86, 89, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 107, 108, 112, 116, 117, 118, 119, 121, 129, 138, 140, 141, 148, 149, 150, 151, 152, 153, 154, 156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 171, 172, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 244, 247, 248, 251, 252, 253, 254, 255, 257, 259, 262, 263, 264, 268, 269, 270, 285, 327, 333, 344, 349, 351, 368, 377, 389], "least": [4, 11, 25, 27, 28, 46, 74, 83, 91, 92, 96, 97, 99, 100, 104, 107, 108, 111, 117, 118, 122, 123, 127, 129, 167, 171, 176, 186, 194, 209, 212, 225, 234, 237, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 306, 333, 334, 342, 343, 347, 349, 354, 355, 376], "li": [25, 28, 30, 38, 83, 156, 179, 183, 194, 217], "insid": [25, 59, 73, 75, 77, 81, 99, 109, 113, 114, 115, 117, 118, 136, 149, 151, 156, 159, 165, 174, 176, 187, 195, 197, 202, 206, 212, 213, 216, 217, 222, 226, 232, 237, 241, 243, 245, 260, 305, 327, 331, 332, 333, 345, 351, 352, 357, 358, 372, 374, 377], "neither": [25, 53, 135, 137], "nor": 25, "circl": [25, 30, 65, 74, 105, 106, 109, 112, 114, 117, 118, 167, 222], "circle_xi": 25, "center_xi": 25, "cx": [25, 53, 74, 153, 169, 171, 172, 174, 184, 201, 217], "cy": [25, 53, 74, 92], "co": [25, 27, 28, 77, 81, 103, 105, 106, 115, 116, 120, 124, 127, 129, 131, 132, 149, 150, 151, 156, 161, 164, 175, 178, 194, 201, 202, 204, 205, 206, 216, 222, 229, 248, 300, 327, 381, 382, 384, 385], "eps_demo": 25, "p_idx": 25, "linalg": [25, 26, 27, 28, 29, 30, 49, 72, 74, 75, 81, 83, 86, 90, 95, 96, 97, 99, 100, 101, 103, 104, 106, 107, 109, 112, 113, 115, 117, 118, 119, 122, 123, 136, 138, 140, 141, 185, 186, 189, 194, 202, 206, 221, 249, 292, 293, 306, 327, 394], "nbr_mask": 25, "fade": [25, 190, 201, 205], "lightgrai": [25, 247, 263], "set2": [25, 75, 83], "chosen": [25, 26, 27, 31, 32, 39, 41, 57, 65, 83, 94, 103, 104, 110, 115, 120, 123, 124, 125, 127, 129, 131, 135, 161, 176, 177, 195, 202, 206, 208, 209, 211, 215, 217, 222, 229, 232, 250, 251, 255, 258, 261, 263, 266, 287], "11": [25, 27, 28, 32, 35, 39, 49, 64, 65, 81, 88, 93, 102, 107, 108, 116, 118, 131, 135, 137, 138, 141, 145, 228, 246, 250, 253, 255, 256, 258, 268, 270, 280, 289, 310, 323, 328, 329, 358, 389], "symbol": [25, 28, 30, 56, 65, 70, 72, 73, 74, 83, 84, 90, 91, 96, 97, 99, 103, 105, 109, 140, 152, 167, 225, 228, 243, 286], "star": [25, 28, 41, 65, 83, 105, 228, 230], "point_typ": 25, "string": [25, 73, 75, 97, 115, 134, 135, 136, 137, 142, 143, 144, 145, 153, 261, 270, 334, 335, 339, 354, 381, 384], "eps2": 25, "sq": [25, 38, 347, 349, 354, 356], "sq_dist": 25, "nbr_count": 25, "is_cor": 25, "is_bord": 25, "ani": [25, 28, 35, 36, 38, 39, 46, 52, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 81, 83, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 100, 102, 103, 107, 108, 109, 110, 111, 113, 114, 115, 118, 120, 124, 125, 134, 141, 143, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 257, 259, 260, 261, 262, 263, 264, 265, 266, 267, 280, 317, 324, 339, 343, 346, 350, 351, 352, 353, 354, 356, 357, 375, 393], "is_nois": 25, "type": [19, 25, 27, 28, 30, 31, 32, 39, 45, 57, 64, 65, 74, 75, 77, 91, 92, 93, 95, 97, 98, 102, 108, 109, 110, 116, 122, 135, 136, 137, 139, 141, 142, 143, 144, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 247, 248, 249, 250, 252, 255, 256, 258, 259, 261, 266, 269, 271, 283, 311, 312, 334, 335, 342, 343, 347, 350, 355, 356, 367, 368, 376, 379, 382, 383, 385, 386], "object": [25, 26, 28, 29, 30, 32, 34, 35, 38, 39, 41, 45, 47, 51, 52, 53, 56, 67, 70, 72, 73, 74, 75, 77, 81, 84, 86, 87, 89, 91, 92, 93, 94, 95, 97, 99, 104, 107, 109, 110, 113, 120, 123, 124, 127, 131, 132, 135, 137, 144, 155, 158, 159, 160, 167, 177, 180, 182, 189, 203, 208, 209, 213, 216, 223, 228, 231, 232, 233, 234, 239, 240, 249, 285, 310, 331, 334, 335, 339, 352, 353, 369, 371, 372, 373, 382], "min_samples_demo": 25, "category_ord": [25, 116], "color_discrete_map": 25, "directli": [25, 29, 35, 36, 39, 41, 45, 46, 47, 50, 56, 59, 69, 70, 72, 73, 74, 78, 90, 93, 94, 97, 98, 101, 102, 104, 106, 113, 119, 121, 125, 135, 144, 155, 162, 166, 168, 169, 170, 171, 173, 184, 185, 186, 188, 191, 196, 199, 200, 210, 212, 214, 220, 225, 226, 227, 228, 229, 232, 239, 240, 243, 244, 245, 249, 252, 255, 257, 259, 263, 268, 270, 323, 349, 359, 374, 375, 385], "exist": [25, 59, 73, 75, 77, 91, 104, 105, 107, 112, 138, 142, 146, 148, 149, 150, 151, 152, 153, 156, 158, 159, 160, 161, 163, 165, 166, 167, 170, 174, 176, 177, 178, 179, 180, 181, 183, 184, 186, 188, 190, 193, 198, 199, 202, 203, 204, 205, 211, 212, 213, 214, 215, 216, 219, 220, 221, 222, 224, 225, 227, 229, 230, 232, 233, 234, 235, 238, 239, 241, 251, 256, 331, 333, 335, 341, 346, 348, 350, 356, 367], "chain": [25, 38, 53, 88, 93, 97, 165, 228, 281, 301, 326], "p1": [25, 108, 159, 176, 228, 237, 246, 261], "p2": [25, 159, 228, 237], "while": [25, 26, 27, 28, 29, 30, 31, 35, 38, 39, 51, 52, 53, 57, 59, 64, 65, 67, 69, 90, 91, 92, 97, 98, 99, 109, 110, 132, 134, 138, 139, 140, 141, 146, 148, 151, 152, 153, 154, 156, 158, 160, 162, 163, 166, 169, 170, 178, 179, 180, 183, 185, 187, 190, 191, 193, 195, 197, 200, 203, 208, 209, 210, 211, 214, 215, 217, 219, 227, 231, 232, 233, 234, 236, 240, 243, 245, 247, 249, 251, 253, 260, 261, 265, 266, 269, 287, 300, 310, 344, 346, 348, 350, 355, 367], "unvisit": 25, "might": [25, 29, 30, 35, 65, 105, 149, 177, 191, 209, 225, 233, 234, 250, 252, 253, 255, 263, 264, 265, 270, 351, 357, 371], "later": [25, 35, 65, 141, 150, 195, 198, 233, 243, 249, 252, 267, 332, 333, 339, 347, 382], "repeatedli": [25, 104, 107, 108, 109, 171, 217, 243, 251, 255, 256, 263, 271, 355], "ad": [25, 36, 53, 87, 89, 90, 99, 100, 103, 110, 116, 121, 122, 123, 136, 138, 141, 145, 152, 154, 159, 168, 173, 175, 176, 182, 187, 189, 208, 214, 222, 230, 237, 239, 240, 261, 267, 333, 341, 353, 357, 358, 370], "think": [25, 26, 28, 32, 36, 39, 51, 53, 70, 78, 84, 87, 98, 103, 108, 110, 113, 118, 122, 123, 148, 156, 157, 161, 162, 163, 164, 165, 168, 174, 195, 198, 199, 201, 214, 218, 219, 228, 234, 239, 242, 248, 252, 260, 346, 358], "bf": [25, 328], "graph": [25, 28, 29, 31, 83, 136, 143, 146, 212, 334, 335, 350, 356], "allow": [25, 31, 32, 46, 86, 88, 106, 116, 117, 129, 146, 148, 152, 173, 177, 183, 190, 193, 194, 196, 201, 204, 209, 220, 221, 224, 231, 235, 238, 241, 263, 290, 342, 347, 350, 357], "expand": [17, 18, 23, 24, 25, 114, 116, 133, 147, 164, 165, 174, 181, 203, 204, 206, 215, 232, 233, 271, 272, 273, 274, 276, 277, 278, 279, 282, 299], "frontier": [25, 392], "unassign": 25, "cluster_id": [25, 346], "visit": [25, 146, 241], "continu": [25, 27, 32, 38, 59, 69, 74, 78, 83, 88, 93, 98, 104, 109, 110, 114, 120, 122, 124, 127, 134, 136, 138, 139, 140, 141, 142, 143, 145, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 225, 226, 227, 229, 231, 233, 235, 236, 238, 240, 241, 242, 245, 246, 247, 255, 256, 259, 260, 261, 265, 267, 270, 285, 303, 308, 312, 313, 314, 315, 316, 317, 318, 333, 355, 385], "mark": [25, 172, 251, 317, 370], "relabel": [25, 69, 72, 73, 77, 78, 233, 359], "seed_set": 25, "pop": [25, 27, 135, 137, 141], "q_neighbor": 25, "detail": [25, 30, 32, 38, 65, 83, 108, 139, 141, 143, 144, 148, 160, 165, 166, 173, 179, 199, 212, 220, 230, 247, 251, 254, 255, 256, 257, 259, 271, 342, 347, 350, 358], "notic": [25, 50, 53, 56, 88, 97, 103, 159, 183, 253, 259], "pull": [25, 31, 74, 86, 91, 164, 211, 214, 358, 359, 386], "touch": [25, 109], "depend": [8, 25, 29, 30, 32, 35, 36, 38, 41, 45, 46, 47, 50, 52, 53, 57, 59, 64, 67, 73, 75, 77, 78, 84, 86, 87, 88, 91, 93, 94, 95, 96, 97, 98, 100, 101, 107, 109, 111, 112, 113, 114, 115, 116, 121, 122, 134, 138, 139, 140, 143, 144, 154, 161, 163, 165, 168, 170, 172, 173, 174, 177, 178, 183, 184, 185, 188, 193, 194, 197, 204, 206, 207, 208, 209, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 226, 228, 230, 231, 233, 236, 237, 238, 239, 242, 244, 245, 248, 251, 252, 256, 261, 263, 264, 265, 266, 268, 270, 271, 280, 284, 285, 288, 295, 300, 308, 316, 328, 332, 334, 335, 339, 341, 342, 346, 349, 350, 351, 358, 359, 371, 373, 377, 379], "travers": [25, 175, 188], "order": [4, 25, 26, 27, 28, 29, 30, 36, 39, 41, 46, 47, 56, 59, 64, 65, 67, 73, 81, 88, 89, 94, 95, 97, 99, 100, 102, 105, 106, 110, 111, 114, 115, 116, 117, 118, 120, 121, 122, 124, 125, 136, 146, 150, 152, 153, 157, 160, 166, 168, 173, 178, 183, 184, 185, 190, 191, 192, 195, 198, 200, 203, 204, 205, 206, 209, 212, 215, 217, 221, 230, 237, 239, 240, 242, 252, 253, 256, 257, 260, 261, 265, 270, 271, 297, 298, 299, 310, 328, 335, 338, 341, 346, 347, 351, 353, 354, 355, 358, 378], "n\u00b2": [25, 242], "memori": [25, 83, 103, 105, 108, 112, 114, 117, 138, 139, 144, 145, 162, 185, 210, 241, 343, 345, 349, 368, 374], "fine": [25, 32, 69, 102, 149, 150, 151, 154, 158, 161, 170, 219, 237], "kd": 25, "possibl": [25, 27, 29, 30, 35, 37, 45, 46, 59, 74, 86, 87, 88, 90, 107, 109, 119, 123, 143, 148, 154, 155, 156, 167, 172, 173, 178, 179, 180, 184, 188, 203, 204, 211, 215, 217, 225, 229, 230, 232, 233, 235, 237, 238, 241, 251, 260, 263, 267, 275, 333, 339, 354, 385], "faster": [25, 31, 32, 64, 75, 101, 109, 110, 138, 143, 146, 157, 161, 171, 173, 178, 196, 200, 219, 229, 230, 234, 235, 237, 240, 241, 260, 303, 339, 381, 385], "queri": [7, 25, 103, 125, 152, 176, 229, 285, 311, 339, 340, 341, 345, 346, 348, 352, 353, 381, 382, 383, 401], "dbscan_from_scratch": 25, "squar": [25, 26, 27, 28, 29, 35, 38, 45, 46, 52, 72, 73, 74, 77, 81, 85, 86, 87, 88, 89, 91, 92, 93, 94, 99, 107, 111, 113, 118, 119, 121, 125, 127, 129, 131, 132, 139, 143, 148, 151, 166, 169, 172, 174, 178, 179, 180, 182, 183, 184, 185, 186, 189, 190, 191, 192, 194, 196, 197, 198, 201, 205, 209, 210, 211, 221, 224, 229, 230, 236, 238, 240, 241, 249, 250, 251, 252, 253, 254, 256, 257, 259, 295, 306, 316], "flatnonzero": [25, 35, 64, 252], "nbr": [25, 27], "tolist": [25, 35, 37, 41, 46, 52, 57, 59, 112, 119, 125, 127, 131, 151, 226, 230, 232, 306], "discard": [25, 115, 151, 214], "plot_clusters_2d": 25, "label_text": 25, "labels_scratch": 25, "labels_sklearn": 25, "fit_predict": [25, 74, 77, 83, 295], "ari": [25, 72, 73, 77, 81, 84], "agreement": [25, 33, 57, 69, 70, 81, 188, 255, 265], "everyth": [25, 31, 53, 64, 65, 69, 72, 84, 103, 107, 109, 110, 142, 176, 195, 209, 242, 249, 266, 269, 339, 371, 383], "consid": [25, 29, 32, 35, 37, 52, 57, 64, 65, 67, 75, 77, 78, 86, 91, 92, 93, 94, 95, 97, 99, 100, 101, 102, 105, 110, 113, 119, 141, 148, 152, 153, 161, 163, 165, 166, 167, 169, 172, 173, 177, 178, 179, 182, 190, 194, 196, 199, 205, 207, 208, 213, 214, 216, 217, 218, 220, 226, 228, 235, 236, 237, 239, 241, 242, 243, 244, 245, 246, 248, 249, 250, 251, 252, 256, 257, 259, 260, 265, 266, 267, 268, 269, 270, 287, 331, 341, 342, 351, 352, 355, 366], "rememb": [25, 32, 51, 102, 110, 162, 172, 175, 176, 183, 186, 187, 189, 192, 195, 212, 215, 229, 240, 246, 247, 264, 265, 342], "mental": [25, 28, 29, 31, 32, 81, 91, 103, 104, 105, 107, 153, 154, 169, 172, 177, 194, 195, 230, 238, 265, 267, 285, 359, 381], "easili": [25, 39], "fragment": [25, 32, 127, 129], "describe_label": 25, "n_cluster": [25, 74, 77, 83, 84], "noise_frac": [25, 75], "eps_valu": [25, 176], "35": [25, 28, 29, 34, 35, 41, 57, 64, 69, 74, 75, 77, 78, 83, 88, 92, 95, 96, 97, 102, 105, 107, 110, 115, 117, 120, 122, 123, 124, 125, 127, 131, 132, 137, 140, 142, 145, 159, 162, 163, 164, 173, 176, 181, 183, 189, 191, 194, 200, 206, 207, 208, 213, 215, 218, 219, 223, 226, 230, 231, 233, 235, 237, 240, 241, 245, 248, 249, 252, 255, 256, 257, 260, 261, 263, 265, 268, 269, 270, 284, 285, 288, 289, 305], "min_samples_fix": 25, "vari": [25, 30, 37, 67, 75, 90, 103, 107, 111, 113, 121, 125, 154, 157, 160, 163, 164, 165, 166, 168, 171, 173, 175, 177, 179, 183, 184, 187, 191, 192, 193, 197, 199, 204, 205, 209, 214, 215, 218, 220, 223, 224, 225, 226, 227, 228, 229, 231, 240, 241, 243, 244, 247, 248, 251, 252, 256, 265, 269, 308, 318, 346, 359, 369], "eps_fix": 25, "min_samples_valu": 25, "most": [4, 25, 26, 30, 32, 34, 35, 46, 50, 51, 52, 59, 67, 70, 73, 74, 75, 81, 87, 88, 91, 93, 96, 102, 103, 105, 107, 109, 110, 112, 122, 125, 127, 131, 132, 135, 137, 139, 141, 142, 148, 151, 153, 159, 160, 176, 178, 179, 183, 188, 190, 191, 193, 201, 202, 203, 207, 209, 211, 212, 213, 214, 217, 218, 220, 221, 222, 226, 229, 230, 231, 232, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 245, 247, 248, 250, 251, 254, 255, 258, 260, 261, 262, 270, 271, 275, 281, 285, 290, 291, 293, 294, 297, 298, 300, 302, 304, 307, 309, 310, 311, 319, 320, 321, 323, 324, 325, 326, 327, 333, 339, 340, 342, 343, 346, 347, 357, 372, 381, 382, 383, 389], "It": [0, 10, 25, 26, 28, 30, 32, 35, 36, 37, 38, 49, 50, 52, 56, 57, 64, 67, 73, 75, 83, 84, 86, 87, 88, 89, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 110, 113, 114, 115, 134, 136, 137, 140, 145, 148, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 162, 163, 165, 166, 167, 168, 169, 170, 171, 173, 174, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 221, 222, 224, 225, 227, 228, 229, 235, 236, 238, 239, 240, 241, 242, 243, 244, 247, 248, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 264, 265, 266, 267, 268, 269, 270, 291, 294, 304, 307, 309, 311, 312, 313, 314, 315, 316, 317, 325, 330, 331, 333, 334, 335, 339, 341, 343, 344, 345, 346, 350, 351, 352, 353, 355, 356, 357, 367, 370, 373, 374, 377, 378, 383, 384, 385, 386, 387, 397, 404], "act": [25, 96, 109, 131, 134, 138, 140, 141, 142, 143, 144, 145, 146, 152, 158, 182, 200, 204, 227, 229, 292, 352, 358], "detector": [25, 131, 157, 175, 193, 204, 266, 284], "honest": [25, 38, 45, 107], "realli": [25, 31, 32, 34, 35, 257, 269], "heurist": [25, 50, 112, 114, 119, 125, 132, 144, 155, 159, 192, 195, 224, 236], "th": [25, 53, 122, 152, 154, 157, 165, 166, 169, 172, 180, 187, 191, 192, 200, 201, 203, 209, 216, 225, 229, 231, 232, 234, 236, 240], "nearest": [25, 27, 28, 31, 32, 74, 287, 319], "sort": [1, 25, 27, 29, 30, 31, 35, 36, 39, 46, 47, 52, 53, 59, 64, 65, 73, 83, 99, 103, 109, 110, 120, 124, 125, 127, 131, 132, 148, 152, 153, 154, 156, 158, 160, 162, 163, 166, 167, 168, 169, 170, 172, 173, 174, 176, 177, 180, 181, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 205, 207, 208, 209, 214, 215, 216, 218, 219, 220, 221, 229, 234, 237, 240, 242, 248, 254, 256, 259, 260, 265, 270, 312, 313, 314, 315, 316, 317, 340, 341, 345], "those": [25, 26, 27, 28, 29, 31, 32, 36, 52, 78, 81, 91, 99, 103, 109, 113, 131, 134, 158, 175, 184, 189, 194, 203, 207, 217, 221, 222, 239, 244, 245, 249, 255, 256, 265, 266, 318, 354, 355], "elbow": 25, "transit": [25, 27, 31, 136, 137, 138, 139, 144, 145, 146, 157, 168, 171, 172, 357], "k_distance_plot": 25, "n_neighbor": [25, 27, 28, 29, 31, 105, 125, 287, 290, 319], "kneighbor": [25, 27, 32, 125], "kth": [25, 28, 105, 125, 260], "extrem": [25, 37, 45, 49, 50, 57, 64, 65, 83, 84, 86, 88, 90, 96, 98, 99, 101, 105, 107, 141, 143, 148, 149, 154, 155, 157, 160, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 186, 187, 188, 190, 191, 192, 195, 196, 199, 200, 203, 204, 206, 207, 208, 209, 210, 213, 214, 215, 217, 219, 220, 222, 225, 227, 229, 231, 233, 236, 237, 240, 241, 242, 244, 245, 248, 249, 250, 252, 254, 255, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 333], "x_out": 25, "handl": [3, 25, 29, 35, 37, 41, 46, 49, 50, 59, 64, 65, 81, 83, 92, 97, 98, 100, 101, 102, 107, 109, 110, 113, 122, 134, 135, 137, 153, 156, 158, 161, 164, 171, 190, 197, 199, 206, 209, 219, 222, 233, 234, 240, 285, 296, 300, 306, 312, 319, 323, 331, 335, 340, 341, 344, 347, 348, 354, 355, 356], "well": [25, 27, 28, 29, 32, 34, 35, 36, 38, 45, 46, 50, 52, 56, 59, 64, 65, 67, 73, 87, 88, 89, 93, 105, 107, 113, 116, 125, 145, 151, 155, 157, 158, 159, 160, 163, 165, 166, 174, 179, 188, 193, 195, 200, 202, 206, 207, 208, 210, 214, 218, 229, 230, 232, 237, 242, 244, 245, 257, 260, 262, 265, 271, 286, 289, 297, 298, 305, 309, 334, 365, 382, 386], "spheric": [25, 74, 189, 221], "fast": [8, 25, 27, 29, 31, 32, 35, 73, 74, 75, 81, 105, 108, 109, 110, 125, 131, 140, 143, 150, 151, 153, 154, 160, 165, 166, 169, 170, 171, 174, 175, 177, 186, 205, 207, 208, 211, 214, 218, 219, 226, 227, 232, 233, 237, 247, 255, 258, 261, 269, 286, 291, 332, 341, 345, 379, 381, 382, 386], "blob": [25, 70, 73, 74, 81, 83, 84, 108, 140, 141, 142, 146, 347], "hierarchi": 25, "labels_kmean": 25, "n_init": [25, 29, 70, 72, 73, 74, 77, 81, 83, 84], "labels_db": 25, "option": [25, 29, 30, 31, 32, 34, 37, 38, 46, 49, 51, 56, 57, 67, 75, 88, 89, 93, 94, 96, 97, 98, 100, 101, 102, 104, 109, 110, 111, 112, 113, 115, 116, 121, 124, 125, 130, 132, 134, 138, 140, 141, 142, 143, 144, 145, 153, 155, 158, 162, 165, 167, 168, 174, 175, 185, 191, 192, 193, 202, 203, 204, 212, 218, 220, 227, 230, 237, 238, 240, 248, 251, 252, 253, 258, 259, 260, 262, 266, 267, 269, 270, 285, 288, 300, 331, 333, 334, 335, 338, 339, 341, 343, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 357, 359, 371, 372, 388], "instal": [25, 31, 32, 110, 115, 132, 135, 136, 137, 138, 139, 144, 145, 146, 248, 251, 267, 284, 285, 286, 287, 288, 289, 292, 295, 300, 303, 311, 312, 313, 314, 315, 316, 317, 318, 351, 359, 368, 369, 371, 379], "pip": [25, 31, 32, 115, 136, 138, 139, 144, 145, 311, 312, 313, 314, 315, 316, 317, 325], "conda": 25, "forg": 25, "min_cluster_s": 25, "labels_h": 25, "auto": [25, 27, 31, 32, 37, 49, 53, 57, 73, 74, 78, 103, 105, 107, 115, 134, 139, 144, 145, 157, 219, 222, 251, 253, 270, 271, 341, 342, 343, 346], "threshold": [25, 33, 38, 43, 48, 60, 65, 69, 75, 90, 107, 108, 110, 134, 139, 140, 141, 143, 148, 152, 159, 164, 167, 172, 176, 181, 196, 198, 209, 210, 216, 218, 221, 240, 242, 243, 245, 256, 258, 267, 269, 284, 322, 340, 383, 384], "n_job": [25, 105], "parallel": [25, 26, 105, 134, 143, 332, 356, 370], "alreadi": [25, 29, 46, 47, 151, 152, 153, 188, 198, 200, 206, 211, 215, 225, 240, 348, 356, 385], "trust": [13, 25, 29, 31, 84, 96, 113, 136, 140, 143, 255, 263, 356, 358], "x_weird": 25, "labels_unsc": 25, "fit_transform": [25, 26, 27, 28, 29, 30, 31, 32, 52, 74, 109, 131, 326], "labels_sc": 25, "restor": [25, 209, 351], "main": [25, 32, 33, 40, 98, 136, 142, 144, 169, 179, 186, 189, 190, 243, 250, 285, 308, 331, 332, 333, 356], "art": 25, "failur": [7, 25, 50, 73, 90, 99, 104, 152, 154, 162, 165, 168, 169, 171, 173, 187, 199, 216, 218, 219, 220, 223, 224, 225, 226, 231, 234, 235, 237, 251, 332, 333, 338, 340, 347, 349, 356, 370], "ambigu": [25, 26, 30, 92, 99, 203], "complex": [3, 25, 105, 109, 110, 112, 122, 138, 151, 153, 164, 165, 167, 179, 181, 182, 189, 190, 201, 203, 204, 205, 208, 212, 213, 214, 216, 217, 222, 224, 232, 233, 234, 240, 241, 255, 300, 334, 341], "reli": [25, 27, 51, 83, 110, 114, 138, 148, 163, 167, 179, 182, 183, 191, 204, 209, 233, 247, 254, 257, 262, 265, 269, 270, 290, 338, 367, 373, 379], "creat": [25, 30, 31, 34, 35, 36, 37, 41, 45, 46, 47, 49, 51, 53, 59, 65, 70, 72, 73, 75, 77, 81, 83, 84, 86, 87, 95, 96, 97, 98, 99, 100, 102, 104, 107, 108, 110, 112, 114, 115, 121, 122, 131, 135, 137, 141, 151, 153, 161, 163, 165, 166, 169, 175, 178, 195, 199, 203, 208, 211, 219, 221, 222, 231, 234, 240, 242, 243, 244, 246, 247, 250, 252, 253, 255, 258, 261, 262, 263, 264, 265, 266, 267, 268, 291, 323, 328, 329, 331, 333, 334, 335, 338, 339, 340, 341, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 367, 372, 374, 375, 383, 384, 386, 394], "fail": [7, 25, 27, 29, 34, 118, 120, 124, 134, 141, 144, 145, 152, 153, 155, 163, 180, 183, 185, 189, 204, 216, 223, 225, 228, 236, 238, 242, 243, 244, 246, 247, 248, 250, 252, 254, 256, 258, 259, 262, 263, 270, 285, 288, 300, 318, 333, 338, 348, 355, 356, 370, 381], "runtim": [25, 28, 144, 149, 164, 234, 255, 318, 332, 334, 346, 349, 358, 359], "digit": [25, 31, 32, 38, 106, 108, 190, 205, 286, 341], "ester": 25, "kriegel": 25, "sander": 25, "xu": 25, "1996": 25, "larg": [25, 27, 28, 29, 30, 31, 39, 46, 52, 53, 56, 57, 64, 70, 73, 74, 78, 83, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 107, 108, 109, 110, 111, 112, 113, 116, 121, 124, 125, 129, 131, 132, 135, 138, 139, 140, 142, 143, 148, 150, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 175, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 204, 205, 206, 207, 208, 209, 210, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 250, 251, 252, 253, 254, 256, 257, 258, 259, 262, 264, 265, 266, 267, 268, 269, 270, 280, 284, 287, 290, 310, 324, 325, 332, 333, 339, 342, 344, 346, 347, 353, 354], "databas": [25, 334, 335, 341, 342, 345, 348, 350, 352, 353, 358, 370, 373, 378, 386], "kdd": 25, "campello": 25, "moulavi": 25, "2013": [25, 160], "hierarch": [25, 75, 155, 170, 183, 187, 198, 203, 205, 209, 218, 226, 228, 231, 235, 236, 237, 268, 280], "estim": [25, 26, 27, 35, 37, 39, 41, 56, 78, 81, 87, 88, 96, 103, 104, 106, 110, 114, 117, 119, 120, 122, 124, 135, 136, 137, 138, 140, 141, 142, 144, 145, 148, 149, 150, 152, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 167, 168, 170, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 204, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 256, 257, 258, 260, 261, 263, 266, 267, 268, 269, 283, 286, 287, 288, 292, 295, 296, 299, 305, 312, 313, 314, 315, 316, 317, 322], "pakdd": 25, "blind": [26, 30, 67], "sourc": [17, 18, 23, 24, 26, 27, 30, 59, 118, 133, 140, 142, 144, 145, 146, 147, 153, 158, 169, 170, 175, 177, 181, 185, 186, 197, 204, 209, 217, 218, 229, 231, 233, 272, 273, 274, 276, 277, 278, 279, 282, 331, 333, 335, 337, 345, 346, 347, 348, 349, 383, 385, 386, 410], "mixtur": [26, 148, 151, 152, 154, 156, 157, 159, 163, 166, 167, 169, 170, 173, 176, 179, 181, 186, 187, 188, 189, 190, 194, 195, 203, 204, 208, 210, 211, 213, 218, 220, 224, 226, 228, 230, 235, 236, 237, 239, 241, 248, 254, 258, 264], "recov": [26, 29, 93, 107, 114, 134, 165, 166, 170, 173, 174, 178, 190, 191, 192, 193, 195, 199, 200, 202, 211, 212, 214, 215, 216, 221, 222, 223, 224, 225, 227, 230, 232, 233, 235, 241], "origin": [26, 27, 28, 30, 31, 37, 39, 49, 53, 57, 64, 73, 74, 78, 81, 91, 92, 97, 102, 103, 105, 107, 116, 119, 120, 122, 124, 125, 139, 140, 141, 142, 143, 146, 157, 161, 165, 174, 175, 180, 182, 183, 201, 205, 216, 219, 247, 248, 259, 265, 266, 267, 280, 299, 308, 310, 315, 323, 326, 339], "speaker": 26, "talk": [26, 357, 358, 359], "microphon": 26, "record": [26, 35, 36, 64, 65, 114, 118, 134, 138, 139, 140, 142, 148, 160, 165, 166, 173, 179, 199, 212, 214, 216, 220, 233, 256, 312, 313, 314, 315, 316, 317, 333, 335, 381, 386], "tri": [26, 27, 28, 29, 30, 31, 32, 52, 65, 103, 109, 110, 140, 159], "individu": [26, 45, 107, 225, 232, 233, 261, 270, 374], "assumpt": [26, 28, 30, 35, 74, 91, 96, 101, 103, 105, 106, 117, 118, 122, 123, 125, 139, 161, 162, 166, 169, 171, 172, 185, 202, 209, 215, 236, 242, 245, 254, 255, 256, 258, 259, 260, 261, 264, 270, 359], "uncorrelated": 26, "counterexampl": [26, 155], "clt": [26, 155, 157, 169, 172, 178, 183, 194, 207, 226, 237, 266, 267, 268], "eigenvalu": [26, 27, 28, 29, 30, 117, 118, 189, 206, 221], "eigenvector": [26, 27, 28, 29, 189, 221], "style": [0, 10, 26, 30, 32, 38, 46, 52, 83, 84, 87, 88, 93, 94, 97, 104, 108, 109, 110, 115, 116, 120, 122, 123, 124, 125, 128, 129, 130, 135, 136, 140, 141, 142, 143, 152, 157, 168, 171, 176, 178, 185, 186, 196, 197, 198, 209, 212, 213, 215, 219, 220, 222, 224, 229, 236, 241, 242, 258, 261, 280, 286, 288, 308, 322, 330, 333, 334, 335, 340, 341, 346, 350, 353, 354, 381, 387, 397, 404], "unknown": [26, 29, 46, 109, 110, 113, 127, 134, 136, 138, 139, 141, 143, 144, 145, 146, 151, 152, 169, 174, 176, 181, 182, 184, 188, 189, 190, 192, 193, 196, 200, 210, 212, 215, 224, 225, 227, 238, 241, 242, 250, 258, 266, 269, 311, 341], "measur": [26, 29, 30, 31, 32, 33, 36, 38, 41, 44, 45, 47, 49, 50, 51, 53, 55, 56, 61, 64, 67, 68, 69, 72, 73, 74, 76, 77, 81, 87, 89, 90, 91, 92, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 112, 114, 117, 123, 134, 140, 151, 152, 157, 161, 163, 174, 183, 184, 185, 186, 188, 189, 194, 197, 198, 199, 201, 202, 205, 207, 208, 209, 211, 212, 213, 214, 215, 216, 220, 222, 229, 241, 243, 245, 246, 247, 252, 256, 257, 259, 260, 261, 262, 263, 265, 266, 267, 268, 269, 270, 319, 340, 389], "instantan": [26, 171, 220], "sa": [26, 216], "hat": [26, 28, 34, 35, 36, 37, 39, 46, 49, 50, 51, 52, 53, 57, 64, 65, 67, 75, 77, 78, 81, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 112, 113, 118, 122, 125, 127, 129, 132, 134, 135, 136, 140, 143, 146, 153, 158, 159, 162, 169, 171, 174, 176, 178, 180, 181, 182, 183, 184, 186, 189, 194, 195, 196, 198, 200, 201, 202, 203, 209, 213, 215, 217, 218, 220, 221, 223, 224, 226, 227, 229, 230, 231, 233, 236, 238, 241, 245, 256, 263, 280, 284, 285, 288, 295, 301, 303, 304, 307, 308, 316, 319], "xw": [26, 45, 51, 86, 89, 91, 92, 93, 94, 96, 104], "identifi": [26, 89, 114, 171, 173, 185, 191, 199, 201, 233, 237, 251, 257, 284, 285, 296, 335, 381, 386], "sign": [26, 30, 52, 57, 83, 86, 90, 91, 92, 99, 101, 107, 109, 111, 116, 118, 123, 150, 158, 160, 161, 171, 172, 173, 175, 176, 177, 190, 195, 201, 202, 207, 208, 220, 221, 222, 233, 242, 247, 248, 249, 253, 256, 258, 260, 262, 264, 265, 266, 267, 269, 295, 313, 316, 339, 352], "decomposit": [26, 28, 30, 31, 32, 89, 100, 107, 111, 116, 136, 153, 163, 243, 315], "imagin": [26, 29, 30, 31, 32, 57, 105, 107, 110, 214, 233, 245, 256, 263], "peopl": [26, 47, 73, 96, 101, 114, 140, 143, 151, 225, 242, 243, 253, 260, 267, 268], "room": [26, 31, 163], "acoust": 26, "simul": [26, 29, 37, 41, 53, 81, 88, 89, 95, 99, 111, 112, 113, 119, 120, 121, 124, 125, 141, 228, 242, 243, 244, 245, 246, 247, 248, 250, 252, 253, 254, 256, 257, 259, 260, 262, 263, 264, 266, 268, 269, 270, 271, 299, 305], "attempt": [26, 141, 221, 224, 225, 237], "synthet": [26, 29, 34, 36, 37, 38, 39, 41, 46, 49, 51, 53, 57, 59, 65, 67, 70, 72, 81, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 107, 108, 110, 115, 116, 122, 124, 127, 129, 131, 132, 149, 153, 156, 157, 158, 159, 160, 161, 163, 165, 166, 167, 168, 172, 173, 174, 175, 184, 185, 186, 188, 190, 192, 193, 195, 196, 199, 202, 203, 204, 205, 209, 210, 212, 214, 215, 216, 218, 221, 222, 224, 231, 233, 237, 238, 241, 244, 254, 256, 262, 266, 269, 270, 280, 284, 295, 299, 300, 303, 305, 308, 316, 317, 322, 394], "2500": [26, 35, 39, 45, 49, 57, 65, 69, 78, 93, 108, 121, 141, 164, 169, 171, 187, 197, 206, 210, 214, 215, 227, 228, 248], "s1": [26, 30, 47, 166, 177, 183, 192, 199, 201, 205, 207, 230, 266, 296], "s2": [26, 30, 141, 166, 183, 192, 195, 207, 228, 230, 231, 244, 250, 266, 296], "s3": [26, 192, 334, 335, 338, 339, 343, 346, 347, 348, 349, 350, 351, 354, 355, 357, 385], "7": [26, 28, 29, 31, 32, 34, 39, 47, 49, 51, 52, 56, 65, 67, 84, 86, 87, 95, 100, 111, 115, 120, 121, 122, 124, 125, 127, 129, 131, 132, 135, 137, 141, 144, 146, 228, 244, 246, 253, 256, 258, 259, 269, 275, 280, 281, 287, 293, 296, 297, 298, 300, 301, 302, 304, 307, 308, 309, 310, 313, 315, 317, 318, 323, 326, 327, 328, 329, 333, 341, 350, 353, 389, 393], "sawtooth": 26, "ramp": [26, 171, 211, 217], "det": [26, 33, 48, 117, 118], "shared_xax": [26, 47, 50, 52, 70, 103, 111, 112, 113, 115, 116, 117, 118, 119, 121, 122, 123, 144, 146, 155, 207, 247, 256, 323], "column_titl": [26, 114], "showlegend": [26, 27, 28, 29, 30, 31, 32, 39, 45, 46, 52, 64, 67, 69, 70, 74, 75, 81, 83, 84, 87, 90, 91, 93, 96, 97, 98, 100, 103, 105, 109, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 131, 132, 134, 143, 146, 149, 151, 155, 163, 164, 168, 175, 176, 177, 178, 179, 181, 182, 204, 207, 210, 222, 224, 228, 230, 232, 242, 243, 244, 245, 248, 250, 252, 253, 254, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 295, 308, 310, 316], "650": [26, 37, 64, 70, 75, 84, 100, 104, 108, 111, 114, 117, 121, 131, 134, 144, 146, 155, 175, 178, 248, 265, 268], "gotcha": [26, 30, 78, 100, 193], "bug": [26, 90, 178, 185, 187, 220], "doesn": [26, 30, 31, 45, 49, 52, 69, 70, 72, 77, 78, 81, 90, 91, 102, 110, 125, 155, 169, 183, 206, 228, 230, 239, 243, 247, 252, 254, 255, 271, 331], "multipli": [26, 30, 31, 39, 92, 95, 96, 108, 123, 148, 151, 153, 155, 159, 160, 163, 167, 168, 170, 172, 173, 183, 186, 189, 190, 192, 200, 203, 207, 208, 220, 221, 230, 233, 235, 236, 244, 247, 252, 261, 268], "divid": [26, 31, 38, 46, 49, 50, 57, 59, 73, 74, 77, 78, 83, 88, 89, 100, 101, 156, 159, 160, 164, 168, 173, 194, 206, 209, 210, 211, 212, 213, 214, 216, 220, 227, 246, 247, 250, 255], "correspond": [26, 34, 35, 36, 49, 69, 73, 81, 90, 91, 95, 96, 98, 102, 104, 113, 122, 139, 150, 160, 163, 166, 167, 172, 175, 176, 177, 179, 183, 185, 186, 190, 191, 195, 196, 197, 198, 200, 203, 209, 211, 213, 215, 218, 219, 224, 227, 230, 232, 233, 238, 240, 251, 254, 260, 261, 267, 269], "leav": [26, 36, 59, 64, 89, 93, 107, 110, 114, 183, 230, 265, 297, 298, 357], "unchang": [26, 36, 38, 46, 47, 59, 64, 89, 90, 93, 156, 170, 180, 265], "success": [26, 109, 119, 140, 150, 152, 153, 159, 162, 165, 166, 170, 179, 181, 188, 191, 192, 205, 212, 213, 214, 223, 224, 226, 227, 228, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 251, 355, 356, 370], "canon": [26, 104, 109, 117, 150, 155, 159, 162, 172, 178, 183, 189, 191, 194, 196, 201, 202, 205, 210, 213, 217, 218, 221, 222, 223, 236, 268, 287], "amplitud": [26, 103, 190, 201, 205, 318], "relationship": [26, 32, 52, 57, 68, 78, 92, 95, 97, 98, 102, 104, 114, 122, 154, 155, 164, 173, 179, 181, 187, 189, 196, 201, 231, 234, 255, 257, 261, 265, 328], "absent": [26, 70, 108, 341], "cov": [26, 30, 41, 57, 64, 103, 106, 108, 113, 114, 159, 185, 189, 194, 221, 226, 228, 230, 239, 262, 268, 271, 393], "entir": [26, 35, 36, 65, 69, 161, 162, 178, 196, 219, 245, 250, 254, 255, 256], "joint": [26, 31, 41, 73, 78, 94, 103, 122, 136, 159, 185, 205, 234, 246, 249], "strictli": [26, 35, 36, 38, 56, 59, 64, 88, 92, 93, 95, 98, 120, 124, 148, 153, 154, 156, 159, 164, 165, 168, 173, 175, 178, 179, 187, 188, 196, 199, 200, 201, 204, 206, 208, 213, 220, 224, 228, 229, 232, 255, 257, 265], "here": [17, 18, 23, 24, 26, 27, 28, 29, 31, 32, 38, 47, 59, 64, 73, 89, 96, 98, 104, 107, 108, 109, 115, 117, 120, 122, 124, 125, 133, 134, 139, 142, 143, 146, 147, 154, 155, 158, 160, 165, 168, 172, 177, 179, 180, 182, 186, 187, 189, 190, 191, 193, 197, 199, 200, 201, 202, 204, 205, 206, 214, 222, 225, 228, 231, 237, 240, 241, 244, 245, 250, 252, 253, 255, 256, 259, 260, 263, 264, 265, 267, 272, 273, 274, 276, 277, 278, 279, 280, 282, 303], "obvious": 26, "4000": [26, 50, 57, 64, 75, 92, 95, 134, 138, 145, 150, 153, 155, 157, 161, 166, 175, 176, 180, 190, 192, 193, 196, 199, 201, 202, 203, 215, 227, 242, 256, 262, 264, 266], "corr": [26, 32, 107, 242, 249, 253, 255, 257, 263, 265], "corrcoef": [26, 107, 108, 255], "x\u00b2": [26, 105, 201], "mere": 26, "ones": [26, 27, 28, 29, 34, 35, 37, 41, 45, 46, 49, 50, 53, 57, 59, 64, 65, 69, 70, 74, 75, 77, 78, 86, 87, 88, 89, 91, 93, 95, 96, 100, 101, 104, 109, 112, 115, 117, 118, 119, 120, 122, 123, 124, 136, 139, 140, 143, 144, 145, 247, 263, 270, 306, 327, 394], "guarante": [26, 32, 97, 98, 100, 104, 114, 132, 170, 171, 176, 197, 354, 358], "properti": [26, 34, 38, 46, 56, 67, 69, 72, 77, 86, 92, 93, 95, 96, 120, 124, 135, 137, 140, 141, 144, 146, 228, 244, 271, 335, 352, 355], "match": [26, 27, 28, 29, 30, 32, 34, 35, 37, 38, 39, 41, 45, 46, 47, 52, 53, 56, 57, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 117, 123, 124, 125, 134, 135, 137, 138, 143, 144, 148, 149, 153, 155, 156, 158, 159, 160, 164, 165, 166, 169, 171, 173, 174, 175, 176, 178, 179, 181, 182, 190, 193, 195, 196, 197, 198, 199, 201, 202, 205, 206, 207, 208, 211, 216, 218, 219, 220, 221, 222, 224, 225, 226, 227, 231, 232, 233, 236, 237, 238, 245, 246, 247, 248, 249, 250, 252, 254, 255, 256, 258, 259, 260, 263, 264, 267, 268, 269, 270, 287, 331, 345, 347, 377, 384, 385], "notion": [26, 32, 74, 83, 104, 105, 230], "come": [26, 29, 32, 49, 53, 59, 67, 81, 98, 114, 148, 151, 154, 160, 161, 169, 173, 178, 180, 181, 188, 191, 203, 205, 208, 210, 211, 219, 220, 227, 230, 235, 236, 239, 240, 242, 243, 246, 249, 253, 255, 256, 257, 258, 263, 265, 267, 269, 374], "central": [26, 148, 151, 155, 156, 157, 158, 159, 160, 161, 165, 174, 184, 186, 189, 190, 192, 193, 194, 199, 200, 206, 211, 214, 220, 223, 225, 228, 232, 233, 236, 252, 254, 258, 261, 264, 269, 347, 348, 350, 352, 353, 359, 381, 383, 385], "theorem": [26, 143, 155, 172, 185, 194, 221, 227, 269], "variabl": [26, 32, 57, 69, 72, 77, 84, 89, 90, 101, 109, 116, 117, 123, 134, 136, 138, 139, 141, 143, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 165, 166, 167, 169, 171, 172, 174, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 194, 197, 198, 199, 200, 201, 203, 206, 208, 209, 210, 211, 212, 213, 214, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 234, 235, 236, 237, 238, 239, 247, 250, 251, 252, 255, 256, 259, 261, 267, 268, 280, 285, 288, 322, 329, 335, 353, 365, 383], "find": [26, 27, 28, 30, 36, 37, 49, 67, 83, 99, 103, 106, 109, 125, 169, 174, 180, 204, 220, 227, 234, 242, 248, 287, 291, 312, 314, 316, 318, 381, 382, 386, 393], "histogram": [26, 28, 29, 34, 35, 38, 39, 45, 64, 69, 87, 89, 95, 98, 99, 101, 107, 110, 112, 120, 124, 125, 127, 131, 132, 134, 140, 142, 143, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 228, 231, 235, 236, 238, 242, 243, 244, 245, 246, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 286, 297, 298, 381, 386], "nbinsx": [26, 38, 64, 65, 87, 95, 98, 112, 120, 124, 125, 127, 131, 132, 142, 149, 150, 152, 157, 160, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 179, 180, 181, 182, 184, 185, 190, 191, 192, 193, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 210, 211, 215, 216, 219, 221, 238, 244, 245, 246, 247, 248, 249, 250, 252, 254, 257, 258, 259, 260, 262, 263, 264, 267, 268, 269], "65": [26, 36, 52, 86, 87, 91, 97, 106, 112, 122, 125, 134, 136, 137, 145, 146, 185, 188, 195, 197, 206, 222, 229, 231, 237, 246, 247, 248, 253, 256, 260, 262, 269, 270, 305], "barmod": [26, 29, 32, 34, 35, 38, 39, 41, 56, 59, 64, 65, 77, 84, 86, 88, 89, 95, 100, 101, 102, 107, 108, 150, 157, 161, 165, 169, 170, 176, 202, 203, 206, 216, 221, 223, 225, 238, 243, 245, 246, 247, 248, 250, 252, 259, 262, 263, 265, 267, 269, 270, 280, 288, 394], "overlai": [26, 29, 34, 35, 36, 38, 39, 64, 65, 78, 89, 91, 92, 93, 95, 125, 140, 150, 151, 153, 154, 155, 156, 157, 161, 165, 168, 169, 170, 172, 175, 176, 177, 178, 181, 182, 183, 186, 187, 188, 196, 198, 201, 202, 203, 206, 214, 215, 216, 221, 225, 245, 247, 248, 250, 252, 254, 262, 263, 264, 267, 269, 270, 296, 328, 331, 358, 372], "quantifi": [26, 32, 89, 113, 172, 209, 224, 305, 409], "excess": [26, 149, 150, 151, 152, 153, 154, 156, 158, 159, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 180, 181, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 227, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 254, 258, 394], "kappa": [26, 33, 149, 152, 158, 177, 191], "hard": [26, 29, 34, 35, 36, 37, 38, 39, 45, 46, 47, 49, 50, 51, 53, 56, 64, 65, 72, 75, 78, 96, 99, 111, 114, 139, 141, 149, 151, 174, 196, 197, 211, 212, 213, 214, 215, 219, 221, 227, 241, 245, 371, 381, 384], "exactli": [4, 26, 29, 34, 35, 37, 45, 51, 53, 59, 67, 81, 86, 87, 88, 91, 93, 97, 103, 107, 114, 143, 150, 152, 154, 155, 156, 159, 160, 161, 165, 167, 168, 169, 170, 171, 172, 174, 181, 182, 183, 184, 186, 187, 188, 190, 192, 193, 194, 197, 198, 199, 200, 202, 206, 210, 212, 213, 214, 219, 220, 223, 227, 228, 229, 230, 233, 234, 235, 237, 238, 242, 244, 248, 251, 253, 255, 257, 258, 260, 262, 263, 269, 270, 355], "proxi": [26, 119, 136, 344, 374, 383], "variant": [26, 29, 41, 52, 59, 74, 96, 97, 102, 108, 113, 128, 139, 142, 144, 145, 199, 244, 245, 246, 251, 253, 259, 263, 266, 267, 286, 292, 303], "contrast": [26, 77, 101, 113, 243], "deviat": [26, 30, 74, 92, 98, 113, 138, 142, 149, 155, 157, 158, 161, 163, 169, 174, 176, 177, 181, 194, 197, 199, 205, 207, 208, 209, 210, 213, 214, 222, 229, 241, 242, 248, 250, 254, 258, 259, 266, 268, 269, 284, 287, 329], "standardize_1d": 26, "excess_kurtosi": [26, 152, 158, 161, 163, 168, 174, 181, 184, 193, 196, 198, 214, 219, 224, 227, 228, 236, 238, 254], "negentropy_proxi": 26, "n_ref": 26, "20000": [26, 114, 134, 148, 216, 253, 263], "cosh": [26, 149, 207, 229, 235], "scalar": [26, 73, 96, 97, 101, 108, 127, 134, 146, 153, 177, 181, 185, 189, 207, 227, 230, 233, 263], "kurt_": [26, 157, 160, 165, 170, 176, 229, 241], "kurt_x": 26, "neg_": [26, 64], "neg_x": 26, "group": [26, 31, 32, 41, 47, 56, 59, 75, 81, 83, 84, 86, 88, 90, 101, 102, 107, 108, 160, 166, 193, 204, 205, 209, 223, 224, 225, 238, 242, 243, 244, 245, 246, 247, 249, 250, 251, 253, 256, 257, 259, 260, 261, 263, 265, 266, 268, 269, 280, 285, 288, 295, 340, 342, 343, 344, 345, 346, 350, 351, 355, 357, 358, 359, 386, 394], "subtract": [26, 41, 69, 70, 134, 183, 184, 198, 201, 214, 229, 235, 239], "rotat": [26, 28, 29, 32, 189, 222, 376], "approxim": [26, 27, 29, 31, 35, 36, 67, 83, 86, 90, 91, 97, 102, 103, 104, 105, 110, 112, 113, 115, 119, 125, 135, 136, 137, 138, 139, 140, 143, 145, 146, 151, 153, 154, 155, 156, 157, 161, 167, 168, 169, 170, 171, 174, 175, 178, 180, 181, 183, 187, 188, 189, 191, 192, 194, 197, 198, 199, 200, 202, 203, 204, 206, 208, 209, 211, 213, 218, 219, 224, 225, 227, 228, 229, 230, 231, 232, 233, 235, 237, 239, 240, 241, 242, 243, 244, 245, 246, 248, 249, 250, 251, 252, 254, 256, 257, 258, 259, 261, 262, 263, 264, 265, 266, 268, 269, 270, 287, 303], "remain": [26, 30, 31, 70, 89, 97, 110, 113, 117, 122, 123, 148, 153, 155, 156, 159, 166, 174, 175, 179, 191, 208, 209, 210, 211, 216, 217, 222, 225, 230, 232, 233, 234, 235, 236, 243, 247, 251, 270, 379], "focu": [26, 31, 32, 45, 53, 97, 103, 117, 158, 160, 171, 173, 189, 201, 207, 238, 239, 250, 303, 323], "x_white": 26, "xc": [26, 27, 30, 106, 108, 109, 265], "eigval": [26, 27, 29, 30, 117, 118, 206], "eigvec": [26, 27, 29, 30], "eigh": [26, 27, 28, 29, 30, 106], "argsort": [26, 27, 28, 29, 30, 35, 36, 45, 47, 59, 64, 65, 67, 73, 86, 87, 88, 89, 95, 103, 105, 106, 108, 125, 247, 252, 253, 257, 260, 265, 270], "d_inv_sqrt": 26, "diag": [26, 29, 75, 81, 103, 113, 115, 117, 123, 185, 189, 206, 221, 230], "w_white": 26, "cov_x": 26, "cov_xw": 26, "leftarrow": [26, 73, 96, 102, 135, 137, 138, 139, 145, 181, 189], "orthogon": [26, 29, 118, 142], "previous": [26, 335], "found": [26, 27, 46, 47, 99, 153, 155, 158, 166, 180, 181, 233, 234, 249, 262, 311], "nonlinear": [26, 28, 29, 30, 31, 32, 104, 110, 113, 125, 148, 221, 255, 265], "itertool": [26, 73], "corr_matrix": 26, "a0": [26, 94, 158, 159, 165, 170, 171, 173, 178, 182, 184, 186, 190, 196, 198, 201, 211, 212, 216, 224, 225, 228, 229, 237], "b0": [26, 89, 90, 94, 96, 97, 98, 99, 107, 123, 164, 170, 171, 178, 182, 184, 186, 190, 196, 201, 205, 211, 212, 215, 216, 224, 225, 237], "match_by_correl": 26, "s_true": [26, 181, 187, 199], "s_est": 26, "perm": [26, 37, 50, 53, 59, 64, 65, 69, 70, 73, 78, 81, 84, 101, 102, 105, 110, 140, 243, 253, 256, 257], "best_perm": 26, "best_scor": [26, 83], "inf": [26, 27, 28, 31, 35, 36, 37, 39, 47, 52, 64, 65, 70, 72, 73, 74, 81, 83, 84, 89, 93, 100, 103, 114, 120, 124, 125, 132, 134, 141, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 178, 179, 180, 182, 183, 184, 186, 187, 188, 190, 191, 192, 193, 194, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 246, 251, 259, 262, 268, 269, 287], "score": [26, 30, 33, 34, 35, 37, 39, 47, 51, 52, 56, 57, 59, 66, 67, 68, 69, 70, 71, 74, 76, 85, 90, 91, 92, 104, 105, 106, 108, 109, 110, 137, 138, 148, 153, 155, 158, 161, 163, 180, 181, 189, 192, 193, 198, 202, 214, 215, 219, 220, 227, 229, 232, 239, 240, 248, 253, 254, 255, 260, 264, 266, 271, 280, 310, 349], "s_match": 26, "n_compon": [26, 27, 28, 29, 30, 31, 32, 106], "s_pca": 26, "s_ica": 26, "s_pca_match": 26, "perm_pca": 26, "signs_pca": 26, "c_pca_raw": 26, "s_ica_match": 26, "perm_ica": 26, "signs_ica": 26, "c_ica_raw": 26, "abs_corr_pca": 26, "abs_corr_ica": 26, "solid": [26, 32, 52, 196, 266], "famili": [26, 29, 65, 93, 105, 106, 108, 127, 146, 149, 150, 152, 153, 154, 156, 163, 164, 165, 166, 170, 172, 173, 179, 181, 183, 187, 188, 191, 193, 195, 196, 197, 198, 199, 202, 203, 206, 207, 209, 210, 212, 215, 218, 227, 232, 235, 243, 249, 280, 283, 285, 287, 288, 311, 312, 313, 314, 315, 316, 317, 318, 343], "sensor": [26, 99, 112, 114, 119, 163, 175, 186, 189, 194, 210, 211, 216, 229, 236, 250, 350], "extract": [26, 116, 127, 131, 146, 153, 181, 189, 289, 294, 295, 313, 314, 316, 318, 326, 329], "deflat": [26, 210], "fun": [26, 29, 109, 159, 181, 212, 224, 233], "logcosh": 26, "cube": 26, "tol": [26, 29, 31, 49, 72, 74, 75, 81, 83, 95, 104, 107, 109, 114, 132, 158, 165, 185, 191, 193, 204, 227, 232, 233, 256, 266], "converg": [26, 31, 52, 95, 104, 107, 109, 114, 119, 148, 150, 157, 161, 165, 166, 167, 173, 180, 190, 192, 196, 206, 210, 211, 219, 220, 224, 237, 240, 263, 269], "mixing_": 26, "components_": [26, 30], "matric": [26, 29, 34, 37, 39, 41, 49, 57, 73, 87, 103, 113, 117, 118, 120, 123, 124, 139, 189, 206, 280], "ground": [26, 27, 32, 41, 68, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 108, 112, 127, 211], "truth": [26, 27, 32, 38, 41, 68, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 107, 108, 116, 117, 123, 127, 131, 156, 167, 182, 331], "life": [26, 165, 218, 220], "clearli": [26, 243, 244, 255, 257, 258, 267], "labels_sourc": 26, "labels_compon": 26, "c1": [26, 74, 165, 170, 172, 175, 199, 216, 251, 261], "c2": [26, 74, 175, 182, 216, 251, 261], "c3": [26, 216], "420": [26, 28, 31, 32, 39, 46, 51, 52, 56, 69, 70, 83, 84, 86, 87, 88, 92, 100, 104, 108, 116, 120, 125, 129, 132, 134, 136, 143, 149, 152, 155, 164, 167, 168, 171, 172, 173, 174, 175, 176, 178, 181, 184, 192, 196, 200, 210, 215, 222, 225, 226, 228, 229, 231, 233, 244, 245, 259, 261, 264, 265, 299, 305, 308, 327, 328, 329], "thing": [26, 29, 31, 47, 114, 161, 210, 233, 265, 386], "denois": [26, 29, 30, 31, 89], "artifact": [26, 30, 114, 211, 331, 332, 333, 350, 352, 358], "latent": [26, 30, 59, 148, 149, 150, 159, 163, 167, 169, 180, 181, 188, 189, 194, 195, 199, 200, 203, 205, 208, 211, 224, 226, 234], "behind": [3, 26, 52, 73, 94, 135, 166, 178, 196, 209, 224, 238, 249, 250, 251, 264, 382, 385], "asset": [26, 111, 183, 337, 339, 352], "market": [26, 122, 230, 237, 346, 389, 394], "sector": 26, "driver": [26, 119, 122, 123, 342, 351, 358, 373, 379], "construct": [26, 34, 41, 51, 67, 74, 75, 88, 89, 98, 111, 118, 136, 141, 143, 149, 157, 162, 163, 167, 186, 191, 192, 197, 200, 205, 208, 209, 211, 224, 226, 236, 239, 251, 257, 259, 270], "eeg": 26, "meg": 26, "ey": [26, 27, 28, 29, 51, 103, 104, 106, 107, 113, 117, 118, 123, 136, 139, 174, 185, 189, 221, 344], "blink": 26, "muscl": 26, "fmri": 26, "addit": [5, 26, 73, 83, 89, 95, 97, 102, 108, 110, 112, 115, 116, 117, 136, 137, 141, 143, 150, 155, 156, 159, 163, 169, 171, 172, 175, 179, 182, 183, 184, 193, 194, 196, 198, 205, 210, 214, 226, 231, 233, 235, 236, 237, 238, 239, 255, 271, 302, 323, 332, 342, 352], "constraint": [26, 28, 30, 32, 35, 36, 65, 90, 93, 95, 119, 134, 135, 140, 143, 149, 150, 151, 156, 157, 158, 159, 160, 164, 170, 172, 174, 184, 185, 187, 190, 191, 192, 194, 195, 196, 197, 198, 206, 208, 211, 213, 214, 215, 216, 217, 219, 221, 222, 227, 228, 229, 230, 233, 234, 285, 290, 332, 333, 351, 352, 357, 404, 409], "wrong": [26, 32, 34, 38, 39, 45, 46, 47, 49, 51, 52, 56, 57, 67, 69, 74, 83, 89, 99, 108, 110, 113, 116, 251, 253, 256, 257, 268, 296, 379, 381, 384], "uninterpret": 26, "check": [26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 47, 49, 50, 53, 59, 65, 70, 73, 74, 75, 77, 81, 83, 84, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 107, 110, 112, 114, 116, 117, 122, 134, 135, 137, 138, 142, 143, 144, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 244, 246, 248, 249, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 264, 265, 266, 269, 297, 298, 331, 332, 333, 334, 335, 343, 350, 353, 372], "recoveri": [12, 26, 114, 153, 237], "hyv\u00e4rinen": 26, "oja": 26, "cardoso": 26, "1998": [26, 30, 109], "principl": [26, 92, 98, 116, 119, 135, 167, 192, 203, 204, 205, 214, 215, 221, 224, 242, 249, 265, 331, 358, 359], "isometr": 27, "preserv": [27, 35, 176, 189, 245, 253, 319, 355], "along": [27, 30, 113, 140, 141, 189, 296], "crow": 27, "fli": 27, "mislead": [27, 30, 34, 35, 37, 38, 46, 49, 50, 53, 57, 67, 74, 78, 83, 89, 92, 122, 187, 196, 222, 236, 245, 250, 255, 258, 262, 264, 384], "heapq": 27, "scipi": [27, 29, 32, 37, 69, 73, 94, 103, 104, 108, 109, 119, 120, 124, 127, 131, 132, 228, 242, 244, 248, 250, 251, 253, 254, 255, 256, 257, 258, 259, 265, 266, 269, 270], "orthogonal_procrust": 27, "sklearnisomap": 27, "pairwise_dist": 27, "dijkstra": 27, "floyd": 27, "warshal": 27, "citi": [27, 29, 105, 160, 196, 198], "river": [27, 172], "bridg": [27, 98, 111, 235, 358, 359], "place": [27, 29, 31, 32, 33, 59, 64, 68, 75, 85, 99, 153, 154, 160, 171, 172, 179, 187, 191, 209, 221, 228, 234, 268, 344, 352, 353, 357, 358, 383], "street": 27, "sheet": 27, "3d": [27, 28, 29, 30, 31, 32, 125, 127, 129, 131, 132, 138, 145, 185], "But": [27, 34, 37, 45, 52, 89, 104, 116, 154, 158, 175, 181, 188, 197, 228, 245], "unrol": [27, 29], "make_swiss_rol": [27, 28, 29, 31, 32], "350": [27, 30, 31, 37, 65, 73, 78, 87, 92, 97, 100, 106, 114, 118, 119, 125, 134, 155, 164, 171, 175, 176, 178, 185, 207], "parameter": [27, 104, 122, 123, 139, 141, 149, 150, 152, 154, 155, 156, 157, 158, 161, 162, 163, 164, 167, 169, 173, 176, 177, 179, 180, 181, 183, 186, 187, 188, 190, 192, 193, 194, 196, 197, 198, 200, 201, 202, 205, 207, 208, 210, 212, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 239, 241, 261, 309, 335], "5\u03c0": 27, "21": [27, 30, 74, 75, 77, 91, 107, 115, 118, 122, 131, 134, 135, 142, 153, 158, 165, 175, 217, 229, 243, 249, 250, 267, 305, 314, 327], "column_stack": [27, 46, 86, 87, 89, 90, 93, 96, 97, 99, 100, 101, 107, 110, 112, 115, 119, 122, 124, 127, 129, 131, 132, 159, 174, 181, 189, 247, 251, 257, 270, 306, 327, 394], "scatter_3d": [27, 28, 228], "intrins": [27, 28, 32, 69], "coordin": [27, 28, 29, 30, 32, 47, 74, 75, 87, 107, 140, 141, 150, 159, 171, 174, 201, 202, 205, 206, 212, 214, 228, 230, 350, 356], "scene": [27, 28, 32, 382, 389], "aspectmod": 27, "geometri": [27, 28, 31, 32, 69, 70, 74, 81, 84, 109, 135, 206, 217, 393], "node": [27, 110, 170, 332, 343, 344, 345, 349, 372, 373, 377], "knn_graph": 27, "undirect": 27, "nbr_dict": 27, "connected_compon": 27, "comp": [27, 47, 74, 213], "cid": 27, "ensure_connected_knn_graph": 27, "k_start": 27, "k_max": [27, 59, 69, 191, 225, 235, 239, 240], "n_comp": 27, "stai": [27, 31, 32, 41, 53, 57, 69, 70, 72, 77, 86, 90, 92, 97, 107, 135, 140, 149, 150, 170, 171, 174, 176, 200, 211, 240, 244, 247, 252, 358, 371, 379], "k_target": 27, "subset": [27, 31, 32, 37, 46, 52, 67, 75, 109, 110, 115, 132, 141, 173, 202, 237, 270], "clutter": 27, "n_vi": [27, 158, 166], "160": [27, 96, 99, 101, 103, 123, 189, 218, 220, 259, 317, 329], "idx_vi": 27, "xv": 27, "tv": 27, "neighbors_v": 27, "k_v": 27, "zs": [27, 167, 261], "enumer": [27, 31, 32, 37, 39, 41, 46, 49, 52, 53, 57, 64, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 100, 103, 107, 109, 114, 116, 117, 118, 119, 122, 123, 125, 127, 131, 135, 137, 154, 156, 167, 168, 185, 187, 189, 191, 219, 222, 228, 230, 234, 237, 238, 244, 248, 251, 252, 254, 258, 264, 265, 266, 269, 285, 289, 295, 299, 300, 305, 306, 308, 310, 313, 316, 334], "_w": [27, 34, 45, 88, 89, 91, 97, 100, 101, 102], "extend": [27, 35, 37, 64, 67, 84, 96, 104, 113, 115, 116, 121, 122, 123, 124, 142, 151, 204, 208, 209, 212, 219, 221, 225, 227, 231, 241, 248, 355], "scatter3d": [27, 28, 32], "rgba": [27, 28, 52, 70, 74, 78, 87, 90, 91, 96, 98, 103, 105, 113, 116, 117, 119, 120, 122, 123, 124, 125, 127, 129, 131, 189, 230, 246, 247, 250, 254, 260, 261, 262, 265, 266, 267, 268, 269, 270, 299, 305, 310], "hoverinfo": [27, 45, 49, 56, 74, 78, 83, 90, 103, 109, 116, 117, 123, 230, 254, 267, 268, 270], "skip": [27, 28, 32, 35, 45, 49, 56, 57, 65, 74, 78, 83, 90, 103, 109, 113, 116, 117, 123, 244, 251, 253, 254, 258, 260, 262, 267, 268, 269, 285, 301, 303, 306], "neighborhood": [27, 29, 31, 175, 179, 183], "neg": [27, 29, 32, 33, 34, 35, 36, 37, 38, 39, 45, 46, 47, 49, 51, 57, 59, 64, 65, 67, 69, 70, 75, 78, 87, 88, 91, 92, 94, 95, 96, 97, 100, 101, 102, 107, 108, 109, 111, 112, 114, 134, 136, 142, 143, 144, 145, 146, 156, 157, 158, 160, 161, 162, 165, 167, 169, 170, 173, 175, 177, 179, 180, 181, 183, 186, 187, 188, 191, 198, 199, 200, 201, 204, 206, 207, 208, 211, 212, 214, 215, 219, 221, 223, 226, 227, 228, 229, 230, 233, 235, 236, 239, 240, 241, 246, 247, 248, 249, 251, 254, 263, 264, 268, 270], "Or": [27, 94, 180], "These": [27, 41, 46, 73, 112, 118, 150, 164, 182, 185, 188, 191, 198, 206, 211, 221, 230, 234, 243, 252, 280, 284, 285, 295, 304, 307, 327, 328, 337], "dijkstra_dist": 27, "heap": 27, "d_u": 27, "heappop": 27, "w_uv": 27, "nd": [27, 107], "heappush": 27, "dijkstra_with_prev": 27, "prev": [27, 29, 132], "all_pairs_shortest_path": 27, "adjacency_matrix": 27, "fill_diagon": [27, 28, 29, 31, 41, 74, 75, 81, 159, 228, 249, 255], "floyd_warshal": 27, "d_geo": [27, 29], "d_euc": 27, "isfinit": [27, 29, 32, 39, 64, 65, 95, 150, 153, 161, 163, 167, 168, 170, 172, 173, 174, 176, 179, 184, 186, 188, 191, 192, 194, 197, 202, 204, 206, 208, 209, 210, 211, 212, 214, 216, 225, 227, 228, 229, 230, 232, 233, 234, 235, 237, 238, 239, 240, 241, 242, 247, 248, 253, 254, 255, 258, 259, 264, 265, 267, 270], "quick": [27, 29, 34, 35, 36, 38, 39, 45, 57, 69, 78, 86, 89, 90, 91, 94, 97, 98, 103, 104, 110, 140, 144, 145, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 172, 174, 175, 176, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 210, 211, 212, 215, 217, 218, 220, 221, 222, 224, 225, 227, 228, 229, 230, 232, 234, 235, 240, 241, 254, 262, 265, 285, 287, 316, 393], "idx_smal": 27, "x_small": [27, 35, 168, 185, 211, 255, 260], "neighbors_smal": 27, "k_small": [27, 240], "d_dij": 27, "w_small": 27, "d_fw": 27, "clear": [27, 32, 51, 67, 73, 96, 98, 99, 101, 102, 116, 148, 153, 182, 193, 195, 265, 331, 350], "respect": [27, 34, 36, 41, 57, 69, 77, 95, 96, 104, 116, 144, 148, 160, 172, 176, 180, 185, 209, 210, 211, 229, 231, 265, 310], "idx_h": 27, "ix_": [27, 83], "Then": [27, 30, 31, 32, 34, 35, 36, 39, 45, 50, 51, 53, 57, 59, 67, 69, 75, 81, 83, 86, 87, 89, 90, 91, 92, 93, 94, 97, 98, 99, 100, 102, 106, 107, 108, 112, 114, 117, 118, 122, 123, 127, 131, 132, 139, 141, 150, 151, 152, 153, 154, 157, 158, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 199, 200, 202, 203, 205, 206, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 226, 227, 229, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 245, 249, 258, 260, 264, 266, 283, 288], "chord": 27, "find_cross_layer_pair": 27, "min_delta_t": 27, "thr": [27, 35, 39, 64, 69, 166, 262, 268], "cand": [27, 99, 114], "unravel_index": [27, 69, 78, 103, 154, 157, 168, 187, 219], "argmin": [27, 39, 51, 56, 67, 70, 72, 73, 74, 77, 81, 83, 84, 86, 87, 91, 94, 99, 107, 110, 112, 177, 287, 292, 301, 393], "No": [27, 28, 31, 32, 39, 41, 47, 74, 83, 99, 110, 115, 116, 122, 138, 139, 140, 141, 142, 200, 253, 261, 262, 265, 268, 269, 271, 275, 281, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 297, 298, 300, 301, 302, 303, 304, 306, 307, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 323, 324, 325, 326, 338, 368, 369, 381], "suitabl": [27, 51, 67, 81, 102, 216, 250], "pair": [27, 29, 32, 33, 35, 45, 49, 59, 60, 64, 68, 69, 73, 77, 78, 80, 83, 87, 89, 91, 112, 127, 132, 138, 140, 175, 185, 194, 209, 242, 245, 248, 249, 250, 253, 254, 257, 260, 262, 265, 267, 284, 295, 300, 305, 313, 314, 316, 320, 327, 331, 342, 353, 358, 365, 383], "dist_i": 27, "prev_i": 27, "cur": [27, 165, 353], "\u03b4t": 27, "path_xyz": 27, "55": [27, 64, 67, 81, 83, 87, 89, 91, 92, 93, 95, 98, 113, 117, 118, 123, 125, 135, 136, 137, 149, 152, 154, 160, 164, 166, 169, 170, 172, 173, 174, 178, 180, 181, 184, 187, 190, 192, 193, 197, 199, 202, 204, 205, 206, 208, 210, 211, 213, 216, 219, 221, 223, 237, 252, 253, 254, 260, 266, 280, 288], "red": [27, 41, 49, 53, 78, 86, 91, 103, 105, 108, 148, 149, 156, 164, 177, 193, 220, 223, 229, 230, 233, 234, 235, 238, 242, 243, 246, 247, 249, 251, 255, 269, 270, 287, 292, 393], "whose": [27, 28, 32, 108, 122, 150, 151, 158, 161, 174, 181, 182, 185, 186, 189, 195, 198, 199, 200, 201, 203, 206, 207, 211, 221, 242, 245, 251], "pairwis": [27, 28, 35, 36, 47, 64, 74, 75, 83, 105, 125, 132, 209, 249, 252, 253, 255, 257, 259, 260, 263, 267, 288], "d_": [27, 29, 35, 83, 135, 140, 146, 211, 256, 287], "ij": [27, 28, 29, 30, 31, 32, 35, 41, 56, 57, 69, 70, 75, 78, 81, 83, 96, 99, 101, 103, 185, 221, 243, 252, 255, 259, 393], "doubl": [27, 29, 35, 86, 91, 96, 164, 177, 182, 204, 216], "gram": [27, 28, 29], "simpli": [27, 38, 56, 73, 158, 164, 197, 199, 216, 225, 264, 268, 328], "wrap": [27, 115, 149, 156, 205, 352], "pipelin": [27, 32, 35, 73, 103, 105, 107, 108, 109, 110, 149, 153, 164, 165, 176, 201, 204, 209, 212, 216, 233, 236, 286, 291, 301, 312, 313, 315, 320, 324, 325, 327, 328, 329, 333, 336, 338, 343, 344, 346, 347, 348, 349, 350, 353, 355, 356, 381, 385, 403, 405], "scratchisomap": 27, "classical_md": [27, 29], "d2": [27, 29, 45, 46, 70, 72, 73, 77, 81, 83, 84, 86, 87, 88, 105, 125, 250, 265, 389], "shortest_path": [27, 32], "ensure_connect": 27, "ndim": [27, 28, 29, 34, 35, 36, 46, 47, 51, 52, 53, 56, 59, 65, 67, 72, 74, 84, 86, 87, 89, 90, 91, 92, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 112, 113, 117, 118, 123, 125, 127, 129, 131, 132, 139, 146, 153, 159, 176, 179, 181, 184, 185, 189, 209, 212, 221, 224, 228, 229, 230, 235, 237, 241, 244, 246, 247, 249, 250, 252, 253, 265, 266, 270], "k_use": 27, "neighbors_": [27, 28], "n_neighbors_": 27, "geodesic_distances_": 27, "embedding_": [27, 28, 29], "eigvals_": 27, "scratch_iso": 27, "downstream": [27, 30, 32, 73, 172, 178, 198, 324, 352, 354], "feel": [27, 110, 216, 252], "concret": [27, 59, 109, 110, 143, 153, 157, 186, 192, 207, 253, 255, 285, 296], "onto": [27, 30, 32, 206, 333], "plane": [27, 29, 30, 39, 105, 201, 248, 344], "part": [27, 31, 32, 38, 52, 72, 77, 84, 93, 98, 102, 107, 110, 113, 114, 116, 117, 119, 122, 123, 149, 151, 156, 157, 159, 162, 163, 174, 194, 196, 204, 207, 209, 212, 213, 214, 215, 216, 218, 269, 270, 275, 280, 284, 294, 303, 333, 339, 340], "zscore": [27, 125, 254], "nicer": [27, 45, 46, 93], "t_true": [27, 102], "y0": [27, 31, 64, 74, 91, 94, 98, 117, 123, 135, 137, 155, 176, 262, 267, 269, 312], "t0": [27, 117, 123, 134, 138, 141, 144, 145, 146, 157, 210, 217, 234, 249, 266, 308], "y_align": 27, "alpha": [27, 30, 49, 75, 86, 88, 90, 93, 94, 95, 98, 103, 104, 108, 109, 111, 120, 121, 124, 131, 135, 136, 139, 141, 144, 146, 151, 152, 155, 159, 160, 161, 163, 165, 166, 167, 168, 171, 175, 176, 178, 179, 180, 182, 185, 186, 188, 190, 191, 192, 193, 194, 197, 201, 209, 210, 214, 223, 226, 228, 230, 231, 234, 235, 236, 239, 240, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 291, 303, 394], "31": [27, 28, 41, 53, 69, 75, 89, 90, 91, 92, 103, 107, 113, 116, 119, 122, 125, 134, 135, 142, 143, 156, 201, 230, 240, 254, 257, 270, 292], "frame_point": 27, "p0": [27, 113, 176, 223, 226, 230, 236, 237, 247, 261], "trace0": 27, "cmin": [27, 56, 185], "cmax": [27, 56, 185], "frame": [27, 30, 31, 115, 224], "arg": [27, 29, 30, 31, 45, 46, 49, 67, 78, 83, 87, 99, 105, 106, 112, 119, 123, 127, 131, 132, 134, 135, 136, 137, 139, 151, 156, 158, 161, 169, 179, 188, 189, 192, 199, 204, 205, 206, 209, 210, 215, 220, 225, 242, 269, 288, 346, 366], "fr": [27, 108], "durat": [27, 30, 31, 98, 139, 148, 163, 167, 169, 173, 178, 183, 212, 213, 220, 340, 356, 391], "redraw": [27, 30, 31], "immedi": [27, 30, 31, 69, 134, 161, 164, 166, 173, 187, 192, 198, 199, 234, 239], "xaxi": [27, 31, 36, 38, 39, 49, 53, 64, 65, 74, 81, 83, 93, 140, 228, 230, 260, 268, 270], "zaxi": 27, "updatemenu": [27, 30, 31], "button": [27, 30, 31], "showact": [27, 30, 31], "plai": [27, 30, 31, 110, 140, 148, 241, 359], "fromcurr": [27, 30, 31], "paus": [27, 30, 31, 356], "slider": [27, 30, 31, 107, 269], "currentvalu": [27, 30, 31, 269], "prefix": [27, 30, 31, 269, 343, 350, 352, 369], "\u03b1": [27, 94, 144, 152, 160, 161, 169, 191, 195, 240, 242, 243, 244, 246, 247, 248, 249, 252, 254, 258, 259, 266, 269, 270], "45": [27, 35, 38, 41, 57, 67, 81, 94, 96, 107, 109, 113, 118, 123, 125, 127, 131, 132, 135, 137, 142, 145, 146, 164, 167, 171, 172, 177, 179, 181, 186, 211, 213, 230, 240, 245, 246, 248, 254, 267, 268], "corrupt": [27, 69, 70, 75], "unreli": [27, 32, 178, 179, 228, 251, 368], "infinit": [27, 39, 56, 117, 148, 155, 157, 158, 160, 161, 165, 166, 168, 179, 182, 183, 191, 192, 195, 196, 199, 204, 207, 210, 215, 216, 225, 236, 240, 241, 251], "tn": [27, 34, 35, 37, 39, 41, 49, 50, 51, 53, 57, 64, 65, 75, 78, 81, 238], "hn": 27, "neighbors_n": 27, "k_n": [27, 235, 240], "d_geo_n": 27, "yn": 27, "clean": [27, 30, 31, 32, 65, 67, 77, 96, 105, 107, 108, 122, 138, 148, 149, 150, 151, 153, 154, 158, 160, 161, 164, 165, 167, 170, 172, 176, 180, 183, 185, 186, 188, 191, 192, 195, 196, 199, 203, 206, 207, 209, 211, 219, 220, 224, 225, 226, 227, 228, 230, 232, 234, 240, 245, 252, 255, 268, 338, 342, 346, 348, 349, 351, 352, 371], "distort": [27, 28, 32, 38, 249, 265], "neighbors_bad": 27, "comp_bad": 27, "n_comp_bad": 27, "bincount": [27, 46, 49, 73, 74, 78, 106, 108, 110, 224, 226, 227, 230, 231, 232, 233, 234, 235, 236, 237, 239, 241], "d_geo_bad": 27, "finite_fract": 27, "fraction": [27, 30, 33, 34, 51, 67, 69, 70, 72, 75, 77, 78, 81, 85, 87, 89, 94, 98, 100, 101, 110, 142, 143, 150, 152, 153, 155, 159, 175, 196, 198, 212, 226, 232, 233, 234, 240, 243, 244, 245, 246, 250, 255, 256, 257, 262, 265], "conceptu": [27, 32, 36, 45, 113, 135, 137, 142, 182, 193, 214, 221, 232, 235, 237, 247, 257, 262, 270, 271, 339, 342, 344, 359], "iso": [27, 29, 49, 105], "y_sklearn": [27, 28], "circuit": [4, 7, 27, 28], "gradual": [27, 72, 112, 134, 367], "toler": [27, 29, 35, 52, 90, 99, 109, 141, 149, 171, 217, 221, 230, 322], "\u03b5": [27, 77, 89, 149, 176], "tenenbaum": [27, 32], "de": [27, 32, 89, 108, 188], "silva": [27, 32], "langford": [27, 32], "unfold": [28, 30, 32], "locallylinearembed": 28, "solv": [28, 29, 30, 87, 90, 94, 97, 103, 104, 107, 109, 112, 113, 115, 134, 135, 146, 148, 149, 150, 152, 153, 154, 158, 161, 162, 169, 171, 172, 180, 185, 187, 188, 189, 190, 196, 198, 200, 201, 202, 213, 215, 216, 220, 221, 227, 232, 233, 240, 266, 358, 368, 371], "knn": [28, 32, 287, 290, 319], "rebuild": [28, 365], "close": [28, 31, 32, 36, 38, 39, 45, 49, 51, 52, 57, 81, 83, 92, 93, 96, 97, 99, 100, 103, 105, 112, 116, 121, 134, 136, 138, 143, 145, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 244, 247, 249, 254, 257, 258, 261, 262, 265, 266, 268, 339, 353, 359, 371], "recip": [28, 143, 166, 184, 185, 358], "pictur": [28, 30, 103, 177, 207, 250, 265, 331, 332, 333, 334, 335], "n_curv": 28, "240": [28, 32, 46, 89, 118, 247], "theta": [28, 67, 86, 87, 90, 98, 100, 103, 104, 105, 108, 109, 114, 116, 119, 120, 122, 123, 124, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 146, 148, 149, 150, 151, 155, 157, 158, 159, 160, 163, 164, 165, 166, 168, 171, 174, 175, 176, 180, 181, 182, 184, 186, 188, 190, 191, 192, 194, 195, 197, 201, 202, 203, 205, 206, 210, 211, 212, 214, 215, 222, 223, 224, 229, 232, 248, 301], "endpoint": [28, 67, 70, 149, 150, 151, 152, 156, 165, 168, 170, 172, 174, 177, 179, 182, 202, 206, 207, 211, 212, 213, 215, 216, 217, 219, 222, 233, 236, 238, 334, 338, 339, 340, 344, 345, 349, 350, 351, 354, 357, 377, 381, 382, 386], "x_curv": 28, "i0": [28, 31, 74, 150, 205], "k0": [28, 163, 177, 187], "dist2": [28, 74, 103, 109], "nn0": 28, "1f77b4": [28, 30, 37, 39, 45, 52, 53, 56, 64, 81, 90, 94, 101, 103, 109, 110, 112, 113, 119, 125, 249, 263, 267, 268, 327, 328, 329], "14": [28, 47, 52, 53, 59, 70, 73, 74, 75, 81, 84, 90, 107, 109, 120, 122, 124, 135, 137, 141, 142, 154, 159, 185, 186, 188, 193, 201, 209, 213, 221, 230, 231, 233, 240, 242, 246, 247, 260, 280, 310, 317, 323], "light": [28, 164, 172, 180, 187, 207, 208, 245, 258, 262], "spoke": 28, "119": [28, 90, 103, 113, 119, 125, 145, 230, 254, 270], "180": [20, 28, 50, 73, 90, 99, 103, 113, 119, 122, 125, 136, 189, 222, 230, 254, 270, 306, 308, 317, 327], "x\u2081": 28, "x\u2082": 28, "520": [28, 31, 32, 35, 53, 56, 64, 86, 104, 105, 106, 108, 112, 113, 116, 117, 123, 125, 129, 167, 176, 193, 228], "x_1": [28, 78, 103, 105, 108, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 227, 228, 229, 230, 232, 233, 236, 237, 238, 239, 241, 245, 254, 256, 263, 266, 267], "x_n": [28, 74, 103, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 223, 227, 229, 236, 237, 239, 245, 254, 256, 266], "x_i": [28, 29, 30, 31, 32, 34, 35, 38, 41, 45, 46, 52, 53, 56, 64, 67, 83, 84, 86, 87, 88, 90, 93, 94, 95, 96, 97, 98, 99, 101, 103, 105, 107, 109, 110, 127, 129, 132, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 227, 228, 229, 230, 232, 233, 236, 237, 238, 239, 241, 250, 254, 255, 256, 262, 264, 265, 266, 267, 268, 270, 287], "\u211d": [28, 176, 216], "w_": [28, 29, 41, 67, 92, 136, 191, 221], "minim": [28, 31, 32, 35, 38, 39, 45, 46, 49, 51, 52, 56, 57, 64, 65, 67, 74, 75, 83, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 105, 107, 109, 112, 115, 117, 118, 119, 122, 136, 137, 138, 139, 141, 142, 143, 145, 153, 155, 159, 163, 165, 166, 168, 170, 175, 176, 181, 184, 188, 192, 199, 205, 210, 212, 214, 222, 224, 225, 228, 229, 237, 239, 291, 295, 303, 332, 333, 342, 343, 346, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 381, 385, 386, 393], "min_": [28, 64, 67, 83, 87, 90, 94, 104, 109, 112, 140, 287, 292, 293, 393], "x_j": [28, 29, 30, 31, 32, 35, 64, 83, 103, 105, 108, 109, 110, 159, 189, 228, 230, 237, 255], "_2": [28, 29, 83, 107, 112, 118, 193, 292, 293], "invari": [28, 29, 32, 36, 59, 70, 72, 73, 75, 77, 78, 84, 86, 92, 114, 119, 135, 151, 172, 182, 184, 194, 204, 213, 217, 222, 237, 238, 244, 255, 262, 341], "shift": [28, 29, 34, 41, 46, 49, 51, 53, 64, 72, 74, 75, 78, 81, 83, 86, 92, 94, 98, 100, 101, 108, 109, 119, 120, 122, 124, 125, 127, 132, 135, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 197, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 222, 224, 225, 226, 228, 229, 232, 233, 235, 236, 237, 238, 239, 240, 241, 245, 251, 252, 256, 257, 260, 262, 266, 270, 287, 306, 319, 322, 323, 328, 346], "z_i": [28, 38, 56, 73, 89, 90, 97, 114, 157, 160, 163, 164, 167, 172, 181, 188, 193, 197, 200, 208, 209, 259], "c_i": [28, 41, 74, 159, 252, 259], "especi": [28, 37, 39, 41, 49, 53, 57, 74, 77, 81, 91, 101, 104, 107, 108, 112, 113, 124, 151, 152, 156, 161, 168, 170, 171, 173, 174, 180, 181, 182, 184, 197, 202, 209, 218, 226, 231, 242, 246, 250, 251, 254, 262, 263, 268, 345, 349, 359, 386], "nearli": [28, 89, 97, 153, 163, 189, 197, 201, 213, 222, 237], "collinear": [28, 122, 123], "min_i": [28, 99, 120, 124, 144, 150, 162, 178, 184, 196, 199, 209, 217, 238], "y_j": [28, 29, 31, 32, 47, 59, 81, 109, 159, 249, 255, 267, 287], "nonzero": [28, 69, 78, 83, 84, 112, 115, 155, 161, 183, 184, 187, 192, 197, 201, 205, 207, 210, 230, 257], "phi": [28, 30, 57, 88, 98, 104, 109, 112, 116, 119, 120, 122, 124, 127, 129, 131, 132, 134, 136, 137, 138, 140, 141, 143, 144, 145, 146, 148, 151, 155, 157, 160, 163, 164, 165, 167, 175, 176, 178, 179, 180, 183, 190, 192, 194, 197, 198, 199, 200, 203, 204, 207, 208, 209, 212, 214, 218, 229, 231, 235, 240, 247, 252, 261, 300, 318], "_f": [28, 29, 127, 185, 221], "tr": [28, 37, 84, 95, 102, 185, 205, 221], "avoid": [7, 28, 30, 46, 49, 56, 69, 70, 73, 75, 88, 93, 95, 98, 101, 102, 103, 107, 108, 112, 113, 122, 135, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 161, 162, 165, 167, 168, 169, 170, 174, 175, 176, 177, 178, 179, 181, 182, 184, 185, 186, 187, 188, 189, 190, 192, 193, 194, 195, 197, 198, 199, 201, 202, 205, 207, 208, 211, 212, 214, 216, 219, 220, 222, 226, 228, 233, 234, 242, 245, 253, 255, 257, 260, 263, 280, 296, 303, 308, 310, 323, 331, 332, 333, 334, 335, 338, 340, 341, 342, 343, 348, 349, 351, 352, 353, 355, 358, 359, 365, 370, 371, 372, 375, 379], "solut": [28, 29, 47, 52, 72, 73, 90, 94, 96, 101, 107, 109, 146, 152, 153, 211, 227, 233], "constrain": [28, 65, 72, 77, 109, 143, 146, 152, 156, 169, 172, 180, 190, 191, 200, 202, 205, 206, 211, 213, 214], "mv": [28, 163, 165, 166, 175, 199, 200, 204, 225, 227, 234], "smallest": [28, 35, 109, 125, 199, 209, 226, 227, 232, 234, 236, 238, 241, 242, 253, 257, 260, 263, 270, 374], "select": [28, 35, 36, 41, 46, 57, 59, 65, 69, 73, 74, 75, 77, 78, 84, 86, 91, 92, 97, 98, 100, 107, 122, 145, 148, 214, 233, 283, 294, 297, 298, 301, 325, 334, 339, 347, 353, 377], "enforc": [28, 52, 94, 95, 97, 98, 102, 113, 117, 146, 159, 166, 168, 170, 172, 211, 214, 215, 220, 228, 234, 245, 334, 338, 339, 341, 357, 358, 359], "sum_j": [28, 31, 56, 57, 69, 70, 75, 78, 81, 90, 108, 109, 117, 123, 159, 193, 227, 228, 230, 243, 249, 257, 259], "pairwise_squared_dist": [28, 31], "diagon": [28, 29, 30, 35, 41, 64, 74, 75, 78, 81, 83, 103, 106, 113, 118, 143, 146, 185, 189, 221, 228, 249, 255, 268, 287, 328], "n_featur": [28, 30, 35, 36, 38, 39, 45, 46, 47, 49, 51, 56, 57, 59, 64, 67, 69, 73, 74, 75, 77, 78, 88, 89, 91, 92, 107, 108, 109, 110, 118], "x_norm": [28, 103, 109, 242, 250, 258], "knn_indices_from_dist2": 28, "satisfi": [28, 32, 52, 70, 88, 95, 109, 112, 117, 119, 123, 139, 146, 153, 154, 155, 158, 166, 167, 171, 174, 176, 178, 179, 182, 185, 187, 188, 196, 198, 202, 207, 215, 219, 228, 229, 230, 232, 233, 234, 243, 245], "got": [28, 34, 39, 46, 47, 51, 52, 65, 67, 73, 83, 86, 87, 88, 89, 91, 92, 96, 97, 98, 99, 100, 112, 127, 129, 131, 132, 153, 159, 161, 191, 221, 223, 226, 227, 230, 234, 235, 238, 240, 247, 248, 255, 258, 262, 265, 266, 268], "argpartit": [28, 105, 125, 260], "lle_local_weight": 28, "reg": [28, 35, 45, 69, 95, 97, 98, 104, 106, 110, 306, 319], "ni": [28, 35, 113, 244, 252], "linalgerror": [28, 118, 185], "lstsq": [28, 86, 90, 96, 97, 99, 100, 101, 107, 112, 117, 118, 119, 122, 123, 306, 327, 394], "rcond": [28, 86, 90, 96, 97, 99, 100, 101, 107, 112, 117, 118, 119, 122, 123, 306, 327, 394], "w_sum": [28, 56, 67, 86, 87, 95, 100, 105, 125], "isclos": [28, 35, 41, 45, 49, 50, 51, 69, 75, 81, 84, 90, 96, 102, 161, 172, 197, 202, 211, 213, 215, 217, 219, 220, 222, 224, 227, 229, 230, 246, 247], "scratchll": 28, "evec": 28, "weights_": 28, "eigenvalues_": 28, "lle_from_scratch": 28, "wrapper": [28, 81, 105, 109, 127, 131, 132, 141, 144, 172, 184, 300], "benchmark": [28, 70, 72, 73, 77, 81, 84, 136, 141, 144, 145, 146, 163, 280, 285, 299], "x_swiss": [28, 32], "scratch_ll": 28, "y_scratch": 28, "neighbors_swiss": 28, "weights_swiss": 28, "x_hat": 28, "recon_err": 28, "95th": 28, "percentil": [28, 86, 87, 91, 94, 146, 175, 177, 221, 239, 245, 246, 252, 255, 262, 265, 340], "95": [19, 28, 34, 36, 37, 39, 47, 51, 64, 69, 78, 94, 103, 108, 110, 116, 117, 119, 120, 123, 124, 125, 135, 136, 137, 140, 142, 143, 148, 150, 151, 159, 160, 161, 166, 170, 171, 172, 173, 174, 176, 178, 179, 182, 184, 186, 191, 194, 196, 197, 201, 203, 207, 208, 209, 211, 212, 215, 216, 218, 220, 222, 223, 226, 227, 233, 234, 236, 238, 241, 243, 245, 255, 256, 259, 261, 262, 265, 266, 267, 268, 269, 305, 317, 383, 386], "nbin": [28, 29, 34, 39, 69, 99, 101, 107, 134, 140, 148, 151, 153, 154, 156, 157, 158, 161, 162, 163, 174, 183, 184, 186, 187, 188, 194, 195, 203, 208, 209, 212, 213, 214, 216, 217, 218, 220, 221, 225, 228, 235, 242, 243, 251, 253, 255, 256, 258, 261, 265, 266, 270, 297, 298], "850": [28, 35, 108, 146, 155, 167, 171, 176, 178, 222, 225, 228, 229, 231, 254], "x\u2083": 28, "y\u2081": 28, "y\u2082": 28, "_i": [28, 34, 35, 36, 37, 51, 53, 59, 64, 65, 67, 75, 81, 86, 87, 88, 90, 91, 92, 94, 96, 97, 98, 99, 100, 107, 109, 125, 139, 159, 209, 236, 243, 252, 263, 266, 295, 316], "enough": [28, 46, 64, 67, 87, 105, 106, 107, 108, 113, 114, 117, 119, 123, 131, 132, 138, 139, 145, 146, 148, 155, 163, 170, 178, 191, 192, 197, 207, 212, 237, 250, 251, 252, 254, 256, 259, 260, 261, 263, 266, 267, 268, 269, 310], "plot_local_reconstruction_3d": 28, "wi": [28, 244], "err": [28, 36, 51, 59, 100, 122, 135, 137, 167, 170, 176, 186, 196, 199, 216], "140": [28, 34, 90, 92, 97, 98, 106, 110, 132, 136, 157, 160, 164, 168, 175, 176, 192, 204, 207, 210, 220, 233, 284, 308], "diamond": [28, 105], "d62728": [28, 30, 34, 37, 39, 45, 51, 52, 53, 56, 94, 103, 109, 110, 113, 244, 249, 263, 267, 270, 293, 329], "zaxis_titl": [28, 32, 389], "620": [28, 123], "i_demo": 28, "approx": [28, 35, 37, 38, 45, 73, 74, 83, 86, 90, 93, 95, 97, 98, 102, 106, 116, 120, 122, 124, 129, 134, 135, 136, 138, 143, 146, 148, 151, 153, 154, 155, 157, 161, 163, 164, 165, 167, 168, 170, 171, 172, 174, 175, 176, 177, 179, 180, 181, 182, 186, 187, 195, 197, 202, 203, 204, 205, 215, 218, 219, 220, 222, 226, 229, 230, 233, 235, 236, 237, 239, 242, 243, 244, 245, 246, 247, 249, 252, 258, 260, 263, 264, 393], "appli": [28, 29, 31, 45, 46, 47, 51, 67, 70, 78, 93, 97, 99, 112, 114, 116, 122, 123, 124, 131, 136, 137, 149, 152, 155, 156, 157, 161, 162, 166, 167, 168, 169, 175, 177, 179, 180, 190, 193, 195, 196, 197, 200, 204, 220, 223, 232, 233, 236, 242, 247, 248, 254, 257, 258, 260, 262, 266, 268, 285, 301, 323, 331, 334, 335, 338, 342, 369, 371, 372], "plot_weight_preserv": 28, "err_x": 28, "err_i": 28, "spec": [28, 32, 39, 47, 51, 56, 67, 69, 73, 115, 122, 214, 222, 331, 358, 359, 366, 367, 368, 369, 370, 372, 373, 374, 375, 377, 378, 379], "xy": [28, 32, 57, 159, 201], "\u0177": [28, 90, 91, 92, 93, 94, 96, 99], "22": [28, 38, 39, 75, 78, 91, 105, 107, 109, 115, 118, 135, 142, 166, 175, 201, 217, 221, 233, 237, 240, 247, 249, 250, 258, 270, 305], "1100": [28, 31, 32, 37, 88, 104, 149, 164, 171, 191, 264, 308], "update_scen": [28, 32], "captur": [28, 30, 51, 78, 89, 99, 111, 112, 114, 118, 119, 122, 127, 129, 131, 142, 157, 158, 191, 195, 215, 226, 228, 231, 233, 241, 285, 289, 291, 300, 310, 318, 327, 328], "smooth": [28, 32, 34, 36, 47, 50, 52, 57, 59, 64, 65, 67, 70, 72, 77, 83, 86, 87, 91, 94, 96, 97, 99, 103, 105, 109, 110, 112, 113, 114, 116, 120, 123, 124, 136, 138, 139, 149, 153, 156, 159, 161, 174, 177, 206, 211, 212, 213, 222, 228, 253, 255, 256, 295, 309, 316, 317, 322, 327, 355], "eigenproblem": 28, "poor": [28, 37, 49, 56, 67, 104, 113, 138, 192, 341], "critic": [7, 28, 50, 90, 107, 140, 141, 191, 209, 242, 244, 247, 249, 254, 256, 266, 267, 268, 269, 333, 344, 378, 383], "disconnect": [28, 29], "eigen": [28, 30, 136, 221], "expens": [28, 30, 50, 69, 83, 94, 103, 107, 155, 185, 189, 230, 280, 287, 292, 340, 341, 346, 381, 382, 386], "solver": [28, 29, 46, 86, 87, 94, 95, 104, 107], "24": [28, 75, 78, 91, 100, 107, 116, 119, 122, 131, 134, 142, 143, 145, 156, 182, 189, 201, 213, 231, 240, 246, 247, 248, 249, 253, 254, 258, 266, 271, 280, 281, 297, 298, 300, 301, 302, 304, 306, 307, 308, 309, 310, 318, 328, 334, 357, 358, 359], "break": [1, 28, 29, 31, 32, 47, 49, 59, 67, 70, 72, 73, 74, 75, 77, 81, 83, 84, 92, 93, 95, 104, 105, 107, 109, 112, 113, 121, 125, 138, 141, 144, 146, 155, 158, 162, 165, 178, 179, 183, 184, 185, 186, 189, 190, 202, 204, 213, 227, 231, 232, 243, 245, 246, 255, 256, 262, 263, 266, 268, 280, 310, 340, 344, 346, 348, 379], "brute": [28, 73, 75, 105, 125, 228, 230], "rowei": 28, "saul": 28, "document": [1, 28, 31, 47, 59, 75, 108, 110, 116, 122, 143, 148, 152, 159, 160, 165, 166, 169, 173, 181, 186, 190, 196, 197, 200, 201, 205, 209, 220, 228, 230, 231, 248, 252, 257, 259, 260, 262, 264, 338, 339, 341, 342, 352, 356, 382, 385], "techniqu": [29, 47, 59, 106, 183], "ve": [29, 35], "seen": [29, 90, 108, 111, 127, 129, 179, 197, 225, 234], "road": 29, "tabl": [29, 59, 72, 73, 78, 116, 118, 213, 247, 256, 257, 258, 265, 267, 311, 328, 341, 346, 348, 350, 351, 353, 357], "wonder": 29, "reflect": [29, 51, 122, 163, 181, 201, 207, 208, 219, 220, 222, 235, 246, 252, 280], "spearmanr": [29, 32, 265], "repres": [29, 30, 73, 90, 95, 103, 106, 108, 113, 114, 117, 124, 139, 154, 165, 199, 208, 218, 222, 231, 245, 292, 296, 300, 302, 331, 332], "subtleti": [29, 245], "uniqu": [29, 35, 37, 38, 39, 41, 46, 47, 49, 52, 53, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 105, 106, 108, 110, 114, 117, 123, 127, 182, 193, 227, 230, 233, 238, 253, 260, 270, 340, 352], "mirror": [29, 30, 46, 49, 75, 86, 87, 92, 94, 96, 97, 100, 151, 159, 170, 179, 185, 204, 221, 229, 267, 270], "helper": [29, 37, 98, 142, 143, 145, 169, 191, 216, 222, 235, 256, 359], "pairwise_euclidean_dist": [29, 83, 125], "sq_norm": [29, 83], "validate_distance_matrix": 29, "symmetri": [29, 81, 113, 149, 156, 158, 161, 166, 167, 176, 181, 182, 194, 202, 206, 207, 208, 210, 221, 226, 229, 239, 254, 264, 266, 270], "allclos": [29, 38, 45, 46, 51, 64, 70, 73, 91, 96, 97, 102, 148, 159, 160, 165, 166, 168, 173, 184, 186, 189, 208, 210, 218, 220, 221, 228], "atol": [29, 69, 84, 89, 97, 159, 189, 208, 210, 221, 230], "rtol": [29, 46, 69, 84, 89, 97, 189, 208, 209, 210, 230], "symmetr": [29, 30, 31, 32, 36, 53, 57, 69, 83, 84, 88, 92, 94, 96, 97, 101, 107, 110, 113, 149, 150, 152, 155, 156, 157, 158, 159, 161, 162, 163, 164, 167, 169, 175, 176, 177, 181, 185, 189, 190, 192, 193, 194, 195, 197, 201, 206, 207, 210, 212, 217, 221, 222, 224, 226, 229, 236, 238, 239, 248, 251, 254, 261, 262, 264, 265, 266, 270, 280, 299], "procrustes_align": 29, "allow_sc": 29, "being": [29, 30, 38, 56, 102, 154, 175, 191, 201, 209, 221, 256], "ref": [29, 38, 45, 148, 160, 230, 332], "tgt": 29, "ref0": 29, "tgt0": 29, "min_r": 29, "vt": 29, "full_matric": 29, "n_citi": 29, "cities_tru": 29, "city_label": 29, "reconstruct": [29, 109, 204, 228, 327], "mds_sklearn": 29, "precomput": [29, 106, 132, 267, 386], "500": [29, 30, 34, 37, 38, 39, 41, 46, 50, 57, 64, 74, 77, 78, 88, 89, 91, 92, 94, 96, 98, 102, 104, 105, 106, 117, 121, 122, 123, 131, 134, 139, 144, 148, 156, 162, 163, 165, 168, 169, 170, 173, 177, 182, 183, 194, 196, 198, 199, 200, 203, 208, 209, 211, 215, 216, 219, 220, 224, 228, 232, 234, 237, 238, 240, 241, 247, 254, 256, 261, 264, 305, 323, 365, 382, 384, 386], "cities_md": 29, "cities_mds_align": 29, "stress_": 29, "delta": [29, 47, 64, 90, 91, 113, 115, 119, 134, 135, 136, 139, 140, 142, 143, 146, 155, 159, 160, 167, 175, 178, 189, 191, 193, 196, 208, 211, 212, 220, 222, 233, 246, 248, 255, 260, 264, 267, 269, 270], "delta_": [29, 134, 136, 143], "ge": [29, 34, 35, 36, 37, 39, 46, 47, 49, 50, 51, 52, 53, 59, 64, 65, 67, 72, 75, 78, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 107, 108, 109, 111, 112, 114, 117, 121, 143, 148, 150, 152, 154, 157, 158, 159, 161, 162, 163, 164, 165, 166, 169, 170, 171, 176, 177, 178, 179, 180, 182, 184, 186, 187, 188, 190, 191, 193, 194, 196, 197, 198, 201, 202, 203, 204, 205, 206, 207, 209, 210, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 244, 245, 247, 248, 250, 254, 256, 257, 262, 263, 264, 266, 267, 288], "ii": [29, 41, 154, 165, 174, 185, 189, 196, 221, 232, 233], "ji": [29, 41], "induc": [29, 47, 59, 103, 140, 170, 175, 176, 192, 197, 214, 228, 239, 240, 249], "move": [29, 30, 31, 41, 46, 64, 65, 69, 72, 87, 89, 91, 96, 99, 105, 107, 111, 112, 113, 118, 121, 135, 138, 139, 140, 141, 142, 145, 146, 149, 152, 161, 173, 177, 178, 183, 185, 193, 197, 202, 204, 205, 212, 219, 221, 236, 238, 254, 262, 265, 267, 280, 297, 298, 299, 303, 308, 333, 345, 348, 353, 355, 359, 379, 382], "until": [29, 30, 67, 99, 107, 112, 119, 136, 148, 162, 169, 171, 204, 215, 223, 231, 233, 234, 236, 245, 334, 339, 342, 344, 346, 348, 350, 351, 355, 356, 370], "stori": [29, 30, 31, 32, 65, 100, 104, 106, 109, 111, 148, 158, 159, 163, 164, 165, 166, 169, 179, 188, 189, 191, 193, 199, 200, 201, 210, 214, 218, 219, 220, 221, 224, 225, 228, 231, 234, 258, 265, 280, 332], "typic": [29, 30, 31, 32, 34, 37, 46, 47, 49, 50, 53, 57, 59, 67, 69, 70, 72, 75, 78, 81, 83, 84, 86, 87, 88, 91, 93, 94, 95, 98, 101, 102, 103, 104, 107, 108, 110, 111, 113, 114, 115, 116, 121, 122, 123, 134, 137, 139, 142, 144, 145, 151, 152, 161, 200, 203, 208, 223, 224, 228, 238, 245, 247, 248, 249, 250, 251, 256, 257, 259, 261, 262, 263, 265, 267, 268, 269, 280, 284, 285, 286, 292, 296, 308, 322, 326, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 371, 375, 382, 384], "torgerson": 29, "gower": 29, "relat": [29, 32, 35, 37, 49, 69, 77, 81, 92, 98, 103, 110, 118, 119, 208, 228, 256, 263, 341, 343, 373], "sens": [29, 30, 32, 41, 47, 92, 110, 113, 150, 169, 177, 190, 192, 218, 222, 239, 250, 253, 257, 263], "mai": [29, 30, 34, 35, 37, 46, 47, 67, 69, 73, 90, 91, 94, 98, 107, 108, 113, 115, 117, 119, 122, 125, 132, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 151, 153, 156, 157, 159, 163, 165, 166, 170, 171, 172, 173, 174, 177, 182, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 200, 202, 205, 209, 213, 214, 216, 225, 226, 228, 235, 236, 240, 247, 253, 254, 257, 258, 263, 265, 266, 268, 300, 331, 332, 334, 338, 359, 373, 379, 385], "minima": [29, 52, 199, 200], "rank": [29, 31, 34, 37, 39, 45, 46, 47, 49, 54, 55, 56, 65, 88, 108, 227, 230, 233, 241, 243, 262, 266, 268, 269], "monoton": [29, 38, 47, 59, 64, 77, 94, 101, 102, 146, 153, 165, 171, 204, 220, 227, 232, 255], "human": [29, 41, 74, 101, 139, 356, 381, 384], "judgment": 29, "about": [29, 31, 32, 34, 36, 37, 39, 41, 45, 47, 49, 50, 52, 56, 64, 65, 67, 70, 74, 75, 77, 78, 81, 86, 87, 89, 91, 92, 96, 99, 101, 107, 108, 109, 110, 113, 122, 148, 156, 159, 161, 162, 163, 174, 175, 180, 182, 184, 186, 188, 189, 194, 198, 199, 200, 202, 213, 218, 219, 221, 222, 232, 236, 237, 238, 240, 242, 243, 244, 245, 249, 250, 252, 254, 256, 258, 259, 260, 262, 263, 265, 266, 267, 268, 269, 296, 305, 331, 338, 344, 355, 358, 359, 381], "farther": [29, 238, 252], "mathbf": [29, 30, 34, 51, 53, 67, 73, 93, 94, 105, 112, 113, 117, 118, 122, 123, 125, 148, 149, 177, 181, 184, 196, 197, 206, 207, 214, 217, 223, 237, 247, 256, 285, 286, 296, 306, 308, 393], "circ": [29, 35, 222], "elementwis": [29, 45, 50, 67, 92, 95, 221], "tfrac": [29, 35, 37, 64, 70, 97, 135, 136, 148, 149, 150, 151, 154, 155, 157, 160, 162, 163, 166, 167, 171, 172, 174, 175, 176, 178, 179, 183, 184, 185, 186, 187, 189, 191, 192, 194, 195, 197, 199, 201, 202, 206, 208, 210, 211, 221, 230, 236, 239, 252, 389], "truli": [29, 36, 67, 77, 106, 122, 156, 184, 211, 243, 258, 259, 261, 263, 268, 342], "eigendecompos": [29, 30], "v_p": 29, "lambda_p": 29, "posit": [29, 31, 32, 33, 34, 35, 37, 38, 39, 41, 45, 46, 49, 50, 53, 56, 57, 59, 64, 65, 67, 75, 78, 87, 88, 91, 92, 93, 95, 98, 107, 108, 112, 118, 120, 121, 124, 127, 131, 132, 134, 139, 140, 141, 143, 144, 146, 148, 149, 150, 152, 154, 156, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 198, 199, 200, 202, 203, 204, 206, 207, 208, 211, 212, 213, 218, 220, 221, 224, 226, 227, 228, 229, 230, 231, 232, 233, 237, 238, 239, 240, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 256, 257, 259, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 293, 303], "descend": [29, 30, 35, 36, 47, 64, 65, 253], "clamp": [29, 108, 140, 142, 143, 144, 145, 149], "due": [29, 59, 64, 134, 136, 138, 139, 141, 143, 144, 145, 146, 150, 151, 153, 160, 171, 174, 175, 188, 190, 192, 200, 204, 211, 213, 215, 237, 248, 264], "cities_class": 29, "eigvals_c": 29, "cities_classical_align": 29, "tell": [29, 30, 38, 39, 69, 77, 78, 81, 140, 242, 243, 244, 245, 246, 247, 248, 250, 251, 252, 257, 259, 260, 262, 264, 265, 266, 268, 381], "support": [29, 33, 35, 36, 37, 38, 39, 45, 46, 47, 49, 52, 53, 57, 61, 64, 86, 87, 88, 89, 90, 91, 92, 94, 96, 97, 98, 99, 100, 101, 102, 105, 106, 108, 113, 120, 125, 140, 143, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 251, 255, 256, 258, 264, 268, 312, 313, 314, 316, 322, 331, 333, 341, 342, 343, 346, 350, 351, 352, 353, 355, 359, 367, 373, 379, 382], "perfectli": [29, 32, 41, 45, 57, 65, 77, 89, 95, 98, 109, 110, 233, 248, 251, 255, 265, 287, 389], "add_hlin": [29, 34, 36, 46, 51, 59, 78, 86, 87, 88, 90, 97, 99, 100, 101, 112, 120, 124, 127, 131, 132, 146, 175, 217, 222, 223, 243, 244, 246, 247, 249, 250, 252, 256, 257, 258, 259, 263, 264, 266, 270], "workhors": [29, 110, 152, 166, 169, 173, 220, 223, 231, 236], "major": [29, 34, 41, 67, 73, 110, 132, 185], "complic": [29, 105, 245, 255], "At": [29, 46, 65, 86, 91, 94, 96, 101, 109, 110, 113, 139, 145, 158, 161, 203, 223, 234, 240, 333, 340, 353, 355, 357], "guess": [29, 37, 99, 119, 161, 163, 165, 205, 211, 212, 222, 236, 240], "current": [29, 36, 45, 70, 90, 110, 111, 113, 114, 118, 125, 134, 138, 140, 142, 143, 144, 172, 226, 237, 240, 247, 249, 368, 372, 382, 384, 385], "popular": [29, 78, 108, 155, 165, 184, 195, 212, 240, 241, 252, 255], "decreas": [29, 30, 32, 34, 35, 36, 39, 41, 47, 50, 64, 65, 69, 70, 74, 75, 77, 78, 87, 91, 134, 142, 148, 153, 156, 165, 168, 170, 173, 181, 184, 188, 198, 205, 206, 211, 215, 216, 220, 222, 227, 234, 238, 241, 245, 253, 255, 259, 265, 368], "raw_stress": 29, "d_ij": 29, "triu_indic": [29, 32, 255], "smacof_metr": 29, "300": [19, 29, 31, 32, 37, 49, 51, 53, 56, 57, 59, 64, 67, 87, 89, 97, 98, 99, 100, 106, 107, 108, 109, 110, 111, 112, 117, 119, 120, 124, 134, 136, 139, 140, 142, 154, 179, 182, 186, 187, 188, 191, 193, 195, 196, 198, 204, 205, 207, 210, 212, 217, 221, 222, 225, 228, 231, 236, 241, 246, 261, 262, 316, 317, 345], "b_ij": 29, "b_ii": 29, "stress_histori": 29, "ratio": [5, 29, 30, 33, 46, 50, 51, 65, 72, 74, 77, 78, 84, 86, 95, 105, 106, 140, 143, 146, 148, 151, 152, 154, 156, 157, 160, 162, 163, 165, 170, 172, 174, 176, 177, 181, 184, 187, 190, 191, 192, 193, 197, 198, 199, 200, 202, 203, 204, 205, 206, 208, 209, 210, 211, 213, 214, 216, 222, 224, 228, 229, 230, 231, 233, 238, 241, 245, 259, 267, 269, 383, 386, 393], "y_new": [29, 103, 231], "scratchmetricmd": 29, "stress_history_": 29, "scratch_md": 29, "cities_smacof": 29, "stress_hist": 29, "cities_smacof_align": 29, "eig": [29, 117], "sort_valu": [29, 36, 64, 74, 115, 253, 286, 287, 288, 289, 292, 300, 311, 312, 313, 314, 315, 316, 317, 318], "reset_index": [29, 64, 115, 243, 280, 285, 288, 296, 306, 311, 312, 313, 314, 315, 316, 317], "drop": [29, 30, 35, 47, 53, 59, 64, 72, 77, 115, 116, 122, 161, 168, 184, 203, 226, 229, 230, 236, 265, 270, 306, 311, 328, 347], "best": [29, 30, 31, 32, 34, 36, 37, 41, 45, 46, 47, 49, 50, 51, 52, 53, 57, 59, 65, 67, 69, 70, 72, 74, 75, 77, 78, 81, 83, 84, 86, 88, 90, 94, 95, 98, 99, 100, 102, 103, 105, 107, 112, 113, 118, 153, 158, 160, 167, 180, 182, 183, 188, 198, 199, 205, 210, 212, 214, 226, 227, 228, 230, 231, 244, 253, 259, 287, 292, 301, 310, 335, 341, 350, 354, 355, 381], "amount": [29, 93, 98, 169, 173, 187, 221, 247, 266, 269], "imperfect": [29, 67, 87, 100, 108, 119], "noise_level": [29, 103], "loc": [29, 34, 35, 37, 53, 64, 65, 70, 72, 73, 81, 83, 84, 86, 87, 91, 92, 94, 96, 104, 110, 112, 140, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 165, 166, 168, 169, 170, 171, 174, 176, 178, 179, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 214, 215, 217, 218, 222, 223, 225, 231, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 248, 249, 250, 256, 257, 259, 266, 267, 268, 269, 288, 300, 318], "d_noisi": 29, "cities_classical_noisi": 29, "eigvals_noisi": 29, "cities_smacof_noisi": 29, "stress_hist_noisi": 29, "mds_sklearn_noisi": 29, "cities_mds_noisi": 29, "methods_noisi": 29, "pairwise_distance_error": 29, "d_target": 29, "d_emb": 29, "d0": [29, 154, 211, 219], "d1": [29, 116, 119, 250, 389], "rel": [29, 38, 45, 46, 59, 86, 87, 88, 89, 92, 97, 100, 102, 104, 113, 119, 125, 134, 155, 158, 163, 170, 173, 176, 177, 185, 186, 200, 205, 214, 218, 219, 221, 224, 225, 230, 231, 232, 233, 237, 243, 255, 260, 264, 269, 312], "abs_rel": 29, "abs_rel_error": 29, "spearman_r": 29, "summari": [29, 36, 37, 39, 53, 57, 89, 94, 100, 116, 122, 127, 128, 129, 131, 138, 144, 228, 243, 252, 253, 256, 258, 267, 270, 275, 295, 312, 313, 314, 315, 316, 317, 318, 328, 386], "\u03b4d": 29, "median": [29, 75, 85, 92, 94, 96, 99, 101, 102, 115, 117, 119, 123, 125, 132, 148, 149, 155, 156, 160, 161, 162, 167, 168, 173, 175, 176, 177, 178, 179, 181, 182, 183, 184, 187, 188, 194, 196, 197, 201, 207, 210, 212, 215, 220, 221, 228, 229, 244, 245, 252, 256, 257, 266, 267, 270, 305], "df_err": 29, "ignore_index": [29, 102, 224], "df_summari": 29, "subspac": 29, "baselin": [29, 30, 31, 34, 36, 38, 41, 45, 56, 59, 69, 81, 88, 89, 91, 92, 95, 96, 97, 102, 105, 107, 108, 111, 112, 115, 119, 121, 122, 125, 131, 162, 163, 165, 166, 170, 171, 199, 200, 203, 212, 225, 232, 233, 236, 249, 253, 261, 266, 267, 269, 287, 291, 300, 304, 307, 309, 338, 342], "geodes": [29, 32], "reason": [29, 31, 32, 50, 67, 73, 74, 81, 96, 101, 113, 122, 148, 149, 158, 163, 180, 183, 184, 186, 193, 194, 199, 202, 205, 206, 214, 216, 217, 225, 226, 228, 238, 240, 247, 248, 249, 252, 255, 260, 261, 262, 267, 343, 351, 375], "rule": [29, 31, 33, 34, 39, 45, 50, 53, 56, 59, 65, 74, 88, 93, 97, 105, 109, 110, 119, 144, 157, 170, 172, 173, 174, 175, 182, 186, 194, 196, 216, 226, 228, 230, 233, 234, 245, 246, 247, 248, 251, 256, 258, 259, 261, 265, 266, 269, 270, 304, 307, 331, 332, 334, 339, 342, 347, 352, 357, 358, 369, 384], "thumb": [29, 31, 39, 74, 108, 110, 119, 173, 182, 226, 230, 247, 248, 258, 261, 266, 270], "essenti": [29, 81, 158, 172, 179, 188, 197, 205, 227, 241, 271, 343], "swiss": [29, 32], "x3": [29, 104, 106, 107, 125, 127, 129, 131, 132, 159, 264, 265], "y_pca": 29, "d_euclid": 29, "y_md": 29, "y_iso": 29, "dist_matrix_": 29, "df_emb": 29, "dim1": 29, "dim2": 29, "facet_col_spac": 29, "for_each_annot": 29, "relative_rms": 29, "rmse": [29, 89, 91, 92, 93, 96, 97, 99, 100, 104, 105, 113, 122, 125, 127, 129, 131, 132, 271, 280, 304, 307], "land": [29, 35, 65, 99, 148, 174, 178, 184, 190, 214, 224, 230, 250], "safer": [29, 118, 150, 163, 267, 338, 379], "wildli": [29, 252, 270], "interpret": [29, 30, 31, 32, 34, 35, 36, 37, 38, 45, 46, 47, 51, 52, 53, 56, 57, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 88, 89, 90, 91, 92, 93, 96, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 112, 116, 118, 119, 121, 123, 138, 143, 228, 292, 293, 300, 394], "spearman": [29, 32, 255, 262], "borg": 29, "groenen": 29, "1952": [29, 242, 257], "1966": [29, 181], "compress": [30, 36, 97, 154, 169, 181, 195, 208, 216, 287], "sometim": [30, 32, 35, 38, 50, 56, 70, 73, 74, 77, 93, 107, 108, 123, 153, 157, 160, 162, 167, 173, 179, 191, 208, 218, 237, 242, 245, 250, 258, 265, 335, 368, 372], "plain": [30, 72, 90, 91, 93, 97, 116, 117, 142, 162, 170, 225, 228, 256, 270, 334, 350], "languag": [30, 72, 231, 256, 260, 332, 335, 348, 349, 356, 371, 386], "x_c": [30, 220, 262], "mu": [30, 32, 36, 38, 46, 53, 57, 65, 84, 92, 93, 95, 98, 103, 104, 111, 112, 114, 117, 118, 121, 122, 125, 129, 137, 138, 144, 146, 149, 150, 151, 156, 158, 160, 163, 164, 165, 166, 168, 170, 173, 174, 175, 176, 178, 179, 181, 183, 185, 188, 189, 190, 191, 192, 193, 197, 199, 200, 203, 204, 205, 206, 210, 212, 214, 215, 216, 222, 223, 224, 225, 228, 229, 231, 233, 235, 236, 239, 242, 244, 245, 248, 254, 258, 260, 266, 270, 305, 389, 393], "wise": [7, 30, 36, 47, 51, 110, 136, 186, 209, 243, 249], "ax": [30, 56, 59, 73, 74, 106, 131, 135, 137, 140, 148, 158, 159, 160, 171, 175, 178, 186, 189, 194, 205, 215, 242, 250, 258, 261, 263, 264, 267, 271, 297, 298], "v_k": 30, "kernelpca": 30, "hand": [30, 36, 37, 57, 59, 86, 89, 140, 232, 233, 257, 266, 270], "floor": [30, 131, 176, 201, 224, 225, 226, 227, 229, 231, 232, 234, 235, 237, 238, 239, 240, 241, 247, 259], "spread": [30, 32, 74, 83, 84, 89, 107, 160, 164, 167, 172, 177, 180, 183, 184, 186, 189, 194, 199, 205, 206, 209, 212, 214, 218, 219, 221, 236, 238, 243, 244, 249, 250, 252, 253, 257, 259, 260, 341], "squish": 30, "hold": [30, 53, 100, 107, 122, 152, 193, 195, 210, 211, 227, 228, 234, 252, 254, 301], "front": [30, 339, 344], "lamp": 30, "cast": [30, 151], "semant": [4, 30, 73, 351, 355, 356, 370], "biggest": [30, 45, 256], "var": [30, 57, 87, 88, 89, 93, 95, 96, 98, 100, 104, 108, 109, 111, 113, 119, 121, 123, 134, 143, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 250, 252, 255, 258, 260, 267, 268, 271, 288, 335, 343, 358, 359, 365, 373, 376, 378, 395], "max_": [30, 49, 52, 64, 73, 74, 78, 87, 90, 109, 135, 139, 140, 144, 145, 146, 170, 249], "lagrang": [30, 230], "largest": [30, 45, 90, 102, 103, 118, 140, 172, 194, 209, 240, 242, 253, 256, 270], "orthonorm": [30, 189], "eigenbasi": 30, "perpendicular": 30, "pc1": 30, "pc2": 30, "subject": [30, 109, 150, 156, 172, 184, 196, 206, 229, 230, 253, 257, 267, 270, 354], "lambda_i": [30, 162, 193, 231, 236], "s_i": [30, 35, 36, 52, 64, 65, 86, 91, 139, 166, 193, 237, 244, 263], "decompos": [30, 38, 64, 84, 89, 115, 158, 211, 309], "v_i": [30, 78, 195, 228], "nice": [30, 36, 46, 65, 74, 77, 98, 110, 113, 151, 153, 159, 165, 167, 168, 183, 212, 235], "x2": [30, 34, 37, 46, 49, 52, 65, 70, 72, 73, 74, 75, 77, 78, 81, 84, 93, 103, 104, 105, 106, 107, 108, 109, 110, 159, 163, 164, 183, 189, 194, 196, 213, 226, 230, 264, 265, 269], "pcafit": 30, "mean_": [30, 39, 49, 83, 99, 157, 160, 164, 165, 170, 173, 176, 193, 215, 219, 229, 241], "explained_variance_": 30, "explained_variance_ratio_": [30, 106], "inverse_transform": [30, 74, 120, 124], "pca_fit": 30, "ascend": [30, 64, 138, 286], "total_var": 30, "explained_vari": [30, 134, 143], "explained_variance_ratio": 30, "pca2": 30, "sk_pca2": 30, "z_sklearn": 30, "live": [4, 30, 32, 57, 89, 114, 152, 153, 158, 170, 181, 185, 202, 206, 219, 222, 229, 246, 261, 284, 286, 289, 292, 311, 331, 332, 333, 338, 339, 341, 342, 344, 346, 347, 350, 358, 372], "unbend": 30, "langl": [30, 109, 132, 185], "rangl": [30, 109, 132, 185], "pretend": [30, 31, 67, 219], "explicitli": [30, 32, 35, 41, 46, 74, 103, 105, 107, 108, 109, 111, 113, 116, 118, 122, 146, 153, 158, 161, 185, 192, 199, 233, 243, 302, 310, 332, 346, 372, 373], "rbf": [30, 103, 130, 132], "gaussian": [30, 34, 73, 74, 83, 84, 88, 98, 101, 109, 111, 112, 114, 115, 121, 134, 136, 138, 140, 141, 142, 143, 144, 145, 146, 149, 155, 157, 158, 159, 161, 163, 166, 176, 177, 181, 186, 188, 189, 190, 191, 194, 201, 205, 207, 208, 209, 210, 214, 238, 244, 248, 254, 268], "gamma": [30, 85, 88, 95, 98, 107, 109, 114, 132, 134, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 148, 154, 155, 157, 159, 163, 164, 165, 166, 168, 170, 171, 172, 174, 176, 177, 178, 179, 181, 182, 183, 187, 188, 191, 192, 193, 195, 196, 197, 198, 201, 202, 204, 205, 209, 210, 213, 215, 216, 219, 220, 222, 224, 225, 227, 228, 230, 235, 239, 240, 241, 244, 246, 252, 267, 268, 303], "polynomi": [30, 96, 109, 112, 114, 116, 117, 118, 119, 123, 153, 154, 160, 166, 167, 168, 170, 171, 173, 178, 187, 191, 192, 196, 203, 204, 209, 210, 211, 213, 237], "k_": [30, 69, 81, 103, 109, 132, 192, 203, 209, 210, 225, 234, 235, 236, 251], "k_c": 30, "_n": [30, 34, 86, 88, 100, 209, 228], "z_m": 30, "alpha_": [30, 109, 131, 159, 228], "implicitli": [30, 235, 264, 294], "four": [30, 32, 57, 70, 100, 153, 166, 170, 171, 211, 234, 237, 265], "interact": [4, 30, 32, 51, 119, 134, 188, 243, 266, 346, 350, 382, 384], "1d": [30, 34, 35, 36, 46, 47, 49, 51, 52, 53, 59, 65, 67, 72, 74, 78, 84, 86, 87, 89, 91, 92, 96, 97, 98, 99, 100, 101, 102, 103, 107, 109, 112, 123, 125, 127, 129, 131, 138, 139, 146, 151, 158, 159, 160, 164, 174, 175, 176, 179, 180, 186, 189, 199, 212, 224, 227, 228, 229, 230, 233, 235, 237, 240, 241, 244, 246, 247, 249, 250, 253, 255, 257, 265, 266, 269, 270], "anim": 30, "arrow": [30, 74, 137], "p1a": 30, "p1b": 30, "p2a": 30, "p2b": 30, "white": [30, 31, 32, 34, 38, 83, 96, 97, 99, 103, 104, 105, 106, 108, 109, 112, 113, 114, 117, 119, 255, 297, 298], "slightli": [30, 41, 91, 108, 125, 142, 146, 149, 150, 151, 163, 195, 206, 212, 241, 247, 257, 260, 263, 266, 268, 269], "600": [30, 32, 35, 46, 50, 52, 74, 86, 87, 88, 92, 93, 94, 95, 97, 98, 102, 110, 111, 112, 123, 131, 134, 143, 148, 149, 150, 151, 152, 160, 161, 163, 165, 166, 167, 168, 169, 170, 171, 172, 174, 175, 179, 180, 183, 185, 186, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 201, 204, 205, 206, 207, 211, 212, 213, 214, 216, 217, 218, 220, 223, 226, 227, 233, 236, 238, 239, 246, 252, 254, 256, 259, 261], "x6": 30, "pca6": 30, "cum": [30, 196, 394], "cumsum": [30, 35, 36, 47, 64, 65, 67, 86, 87, 119, 125, 150, 151, 155, 161, 170, 173, 174, 175, 178, 179, 181, 184, 195, 196, 197, 208, 212, 216, 218, 223, 224, 226, 227, 228, 232, 233, 234, 236, 237, 238, 239, 241, 243, 251, 257, 263, 267], "cumul": [30, 33, 64, 65, 153, 162, 170, 179, 180, 191, 195, 199, 203, 223, 224, 226, 227, 232, 236, 237, 240, 256, 267, 287, 394], "tickformat": [30, 49], "x_proj": 30, "outer": [30, 41, 122, 159, 221, 228, 230, 246, 249, 251, 305], "pc1_dir": 30, "span": [30, 97, 102, 183, 212, 256, 381], "line_a": 30, "line_b": 30, "x_min": [30, 103, 104, 105, 106, 108, 109, 110, 172, 179, 183, 197, 199, 207, 215, 233, 238, 256], "x_max": [30, 103, 104, 105, 106, 108, 109, 110, 158, 160, 164, 165, 169, 171, 172, 174, 179, 183, 186, 190, 191, 193, 196, 197, 199, 204, 205, 207, 215, 218, 233, 238, 244, 250, 256, 266, 267], "y_min": [30, 103, 104, 105, 106, 108, 109, 110], "y_max": [30, 103, 104, 105, 106, 108, 109, 110, 215], "ts": [30, 151, 181, 185, 197, 200, 207, 212, 319, 321, 341, 381, 382], "down": [30, 32, 35, 47, 65, 72, 74, 77, 92, 107, 111, 113, 121, 134, 136, 140, 146, 148, 149, 150, 155, 158, 160, 164, 165, 166, 167, 171, 172, 176, 179, 180, 184, 191, 195, 199, 206, 208, 210, 211, 214, 216, 218, 219, 220, 226, 228, 229, 230, 233, 236, 239, 265, 267, 285, 342, 349, 358, 359, 367, 381, 384], "y_moon": [30, 110], "z_lin": 30, "z_k": [30, 209], "kpca1": 30, "kpca2": 30, "legend_title_text": [30, 88, 164, 182, 226, 231, 241, 247, 252], "believ": [30, 103, 108, 113, 211, 212, 238, 266], "hungri": [30, 106], "chase": [30, 113, 139], "noisiest": 30, "unitless": [30, 86, 89, 92], "dollar": [30, 91, 99], "cent": 30, "domin": [30, 34, 37, 52, 56, 59, 70, 73, 74, 75, 81, 91, 95, 96, 97, 100, 101, 102, 105, 151, 161, 163, 175, 179, 194, 196, 201, 210, 217, 240, 248, 258, 264, 266, 268, 269, 303, 323], "domain": [30, 39, 57, 65, 87, 88, 93, 95, 104, 107, 109, 112, 135, 137, 149, 153, 154, 156, 158, 163, 167, 176, 177, 180, 181, 188, 191, 194, 195, 197, 199, 200, 205, 212, 219, 221, 229, 236, 238, 241, 242, 256, 264, 295, 339, 354], "appropri": [30, 93, 96, 109, 116, 148, 153, 155, 159, 161, 162, 163, 165, 166, 173, 177, 178, 183, 184, 186, 188, 195, 203, 204, 207, 216, 226, 230, 233, 236, 238, 251, 252, 260, 262, 266, 268, 270, 285, 340], "won": [30, 108, 246, 262, 357], "ye": [30, 32, 70, 110, 140, 197, 223, 226, 251], "400": [30, 31, 34, 35, 37, 39, 41, 47, 49, 50, 51, 53, 69, 77, 86, 87, 88, 89, 90, 94, 96, 97, 99, 101, 102, 103, 104, 105, 106, 108, 109, 110, 134, 139, 149, 151, 153, 154, 157, 159, 161, 162, 163, 165, 170, 173, 174, 177, 178, 180, 181, 182, 186, 187, 191, 195, 196, 197, 198, 201, 203, 204, 212, 216, 217, 218, 219, 220, 221, 223, 226, 231, 244, 246, 248, 252, 254, 258, 264, 266], "underli": [30, 87, 89, 108, 136, 165, 181, 192, 193, 205, 214, 216, 219, 223, 258, 264, 346, 349], "50x": 30, "p_unscal": 30, "xs_scale": 30, "p_scale": 30, "implicit": [30, 253, 373], "independ": [30, 41, 51, 59, 64, 89, 94, 95, 107, 113, 143, 152, 154, 155, 159, 160, 161, 162, 163, 165, 166, 169, 174, 175, 177, 183, 185, 186, 189, 190, 191, 192, 193, 194, 195, 199, 201, 205, 206, 207, 208, 209, 210, 219, 221, 224, 226, 230, 231, 232, 233, 235, 236, 237, 239, 243, 244, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 259, 260, 261, 263, 264, 265, 266, 268, 269, 270, 353], "approach": [30, 35, 59, 64, 65, 90, 93, 103, 105, 107, 113, 118, 125, 126, 130, 149, 150, 151, 153, 157, 159, 160, 163, 167, 170, 171, 174, 177, 179, 184, 185, 190, 191, 192, 195, 197, 202, 203, 205, 208, 209, 210, 213, 214, 215, 221, 222, 224, 227, 228, 231, 232, 234, 235, 237, 241, 242, 243, 245, 247, 249, 255, 257, 260, 262, 266, 269, 270, 271], "highest": 30, "purpos": [30, 70, 193, 226, 236, 334, 335, 346], "esl": [30, 67, 107, 110], "hasti": [30, 67, 87, 88, 96, 101, 107, 110], "tibshirani": [30, 67, 87, 88, 96, 101, 107, 110, 263], "friedman": [30, 67, 96, 101, 107, 110, 257], "element": [30, 53, 67, 78, 96, 101, 105, 107, 111, 146, 153, 181, 189, 221, 237, 238], "bishop": [30, 46], "sch\u00f6lkopf": [30, 109], "smola": [30, 109], "m\u00fcller": 30, "fastica": 30, "stochast": [31, 32, 116, 117, 119, 134, 139, 144, 150, 165, 175, 192, 195, 242], "stand": [31, 120], "everyon": [31, 34, 36, 46, 106], "gp": [31, 113], "who": [2, 31, 32, 35, 75, 106, 110, 357, 373, 382], "recogn": [31, 150, 165, 168, 169, 170, 180, 187, 190, 201, 218, 223, 225, 226, 230, 233, 236, 237, 238, 239, 240, 296], "beauti": 31, "dishonest": 31, "p_": [31, 39, 46, 51, 56, 67, 69, 73, 108, 112, 113, 141, 151, 226, 231, 237, 240, 247, 251], "q_": [31, 99, 137, 138, 139, 141, 144, 145, 172, 193, 209, 253, 305], "tsne": [31, 32], "person": [31, 105, 266, 268], "music": 31, "tast": 31, "hobbi": 31, "polit": 31, "whom": 31, "ask": [31, 32, 46, 49, 89, 99, 114, 159, 195, 242, 258, 267], "convinc": 31, "throughout": [31, 35, 161, 168, 171, 184, 194, 201, 206, 207, 212, 218, 235, 241], "handwritten": [31, 32], "images_al": 31, "trick": [31, 35, 50, 53, 73, 102, 103, 105, 110, 141, 142, 144, 145, 150, 158, 160, 166, 168, 174, 196, 201, 219, 227, 259, 266, 381], "x_pca": 31, "mid": [31, 32, 34, 37, 38, 39, 45, 49, 50, 56, 65, 67, 72, 73, 77, 78, 84, 88, 91, 95, 96, 98, 103, 104, 106, 108, 111, 113, 121, 122, 123, 134, 135, 136, 137, 139, 140, 142, 143, 144, 146, 148, 150, 151, 152, 156, 159, 160, 161, 162, 165, 167, 168, 169, 170, 171, 174, 178, 179, 180, 181, 182, 183, 185, 186, 188, 189, 190, 191, 192, 193, 194, 196, 198, 199, 200, 202, 203, 204, 205, 206, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 239, 240, 241, 245, 247, 251, 263, 266, 267, 288, 308], "sigma_i": [31, 32, 96, 166, 214, 244, 267], "neq": [31, 51, 73, 83, 117, 192, 197, 198, 200, 212, 221, 258, 262, 268], "x_k": [31, 35, 159, 228, 230], "own": [31, 41, 73, 78, 106, 109, 112, 118, 123, 129, 148, 231, 242, 244, 333, 334, 335, 340, 341, 342, 343, 347, 358, 372, 378], "bandwidth": [31, 339], "2n": [31, 107, 109, 158, 161, 182, 193, 196, 201, 202, 206, 224, 234, 238, 255], "moder": [31, 32, 39, 69, 151, 167, 175, 178, 185, 189, 191, 193, 206, 211, 224, 226, 228, 230, 233, 234, 236, 237, 248, 249, 255, 262, 265, 267, 270, 297, 298], "distant": 31, "mass": [31, 32, 41, 59, 86, 88, 98, 141, 142, 146, 150, 151, 152, 153, 156, 157, 159, 160, 163, 164, 165, 167, 169, 170, 171, 173, 176, 179, 181, 182, 183, 184, 186, 189, 191, 193, 194, 195, 196, 198, 199, 201, 202, 203, 204, 205, 206, 207, 208, 211, 212, 214, 215, 216, 217, 219, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 238, 239, 240, 241, 256, 270], "caus": [31, 92, 112, 179, 248, 250, 259, 367, 383], "sit": [31, 160, 183, 230, 252, 255, 270, 339, 348], "heavi": [31, 35, 47, 50, 51, 69, 86, 87, 91, 96, 98, 99, 100, 101, 102, 112, 113, 121, 125, 148, 154, 155, 157, 160, 161, 165, 166, 168, 172, 173, 175, 176, 177, 178, 179, 181, 183, 186, 187, 188, 191, 192, 194, 195, 197, 198, 199, 203, 204, 207, 208, 209, 210, 215, 216, 219, 222, 225, 231, 240, 241, 243, 244, 245, 248, 252, 254, 255, 256, 257, 258, 259, 260, 263, 264, 266, 267, 268, 270, 290, 309, 325, 341, 349, 385], "tail": [31, 86, 87, 91, 94, 96, 97, 98, 99, 100, 101, 102, 111, 113, 116, 119, 121, 134, 155, 157, 158, 161, 162, 163, 164, 165, 166, 167, 168, 172, 173, 176, 177, 178, 179, 180, 183, 186, 188, 190, 191, 192, 193, 194, 195, 197, 198, 199, 200, 201, 203, 204, 205, 207, 208, 209, 210, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 225, 226, 227, 228, 230, 231, 239, 240, 241, 243, 244, 245, 246, 247, 248, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 266, 267, 268, 270, 340], "degre": [31, 32, 35, 69, 109, 119, 132, 155, 166, 170, 173, 176, 186, 188, 190, 193, 199, 201, 205, 207, 209, 210, 213, 222, 240, 243, 246, 248, 249, 250, 254, 257, 259, 262, 267, 268, 301], "freedom": [31, 32, 69, 155, 166, 170, 173, 176, 186, 188, 190, 193, 199, 201, 205, 207, 209, 210, 243, 246, 248, 249, 250, 254, 257, 259, 262, 267, 268], "y_k": [31, 35, 104, 159, 230], "y_l": 31, "pai": [31, 98, 107, 245, 341, 349, 381, 386], "penalti": [31, 38, 41, 46, 49, 51, 52, 67, 69, 75, 87, 94, 96, 98, 102, 103, 104, 107, 115, 140, 143, 158, 229], "asymmetri": [31, 87, 88, 94, 98, 157, 177, 185, 189, 192, 195, 197, 207, 208, 212, 248, 254, 264], "island": [31, 32], "p_i": [31, 34, 38, 45, 46, 50, 53, 56, 170, 223, 225, 228, 230, 237, 251], "wider": [31, 52, 109, 181, 199, 204, 220, 226, 239], "social": 31, "dure": [31, 35, 46, 59, 88, 89, 93, 98, 103, 138, 140, 144, 145, 153, 172, 174, 382, 384], "phase": [31, 89, 151, 175, 190, 222, 287, 295, 318, 319, 333], "temporarili": [31, 355], "attract": [31, 32, 233], "settl": [31, 155, 254], "sum_sq": 31, "_hbeta": 31, "dist_sq": 31, "shannon": [31, 77, 84, 224, 226, 227, 228, 229, 231, 232, 233, 235, 236, 239, 240], "sump": 31, "full_lik": [31, 45, 46, 50, 52, 53, 56, 57, 86, 87, 88, 89, 95, 98, 100, 112, 139, 148, 149, 150, 151, 154, 156, 160, 164, 165, 166, 167, 168, 169, 171, 172, 173, 174, 178, 179, 180, 181, 182, 183, 184, 186, 187, 190, 191, 193, 195, 197, 199, 201, 202, 203, 204, 205, 206, 215, 216, 217, 218, 219, 220, 225, 227, 228, 232, 235, 237, 238, 240, 251, 254], "conditional_prob": 31, "dist_sq_row": 31, "binari": [31, 33, 35, 36, 38, 39, 41, 43, 45, 47, 49, 52, 64, 65, 67, 75, 77, 78, 81, 104, 109, 110, 122, 223, 226, 227, 237, 261, 284, 322, 333, 342, 382], "logu": 31, "beta_min": 31, "beta_max": 31, "hdiff": 31, "isinf": [31, 64, 157, 216], "perplexity_of": 31, "demonstr": [31, 50, 59, 77, 107, 110, 127, 136, 149, 151, 153, 155, 157, 164, 166, 167, 171, 175, 176, 178, 179, 186, 196, 198, 200, 203, 205, 209, 213, 217, 218, 224, 237, 238, 270], "ONE": 31, "x_demo": [31, 32, 168, 191, 206, 208, 223, 238, 258, 265], "y_demo": 31, "d_demo": 31, "dist_row": 31, "perp": [31, 32, 160, 163, 177, 192, 209, 210], "p_row": 31, "p_sort": 31, "actual": [31, 36, 38, 47, 49, 50, 65, 83, 90, 119, 125, 127, 129, 131, 132, 141, 197, 214, 216, 243, 255, 260, 280, 281, 297, 298, 302, 304, 306, 307, 309, 331, 333, 345, 373, 379], "1f": [31, 87, 92, 94, 99, 134, 136, 138, 141, 144, 145, 151, 186, 193, 196, 207, 210, 217, 224, 228, 236, 246, 260, 270], "learning_r": [31, 32, 107, 110, 134, 136, 139, 142, 143, 144, 145], "turbo": [31, 32], "hovertempl": [31, 32, 47, 53, 65, 78, 81, 83, 84, 90, 228, 251, 253, 254, 261], "br": [31, 32, 45, 47, 53, 64, 65, 69, 70, 74, 78, 81, 84, 90, 96, 100, 123, 228, 243, 250, 251, 253, 254, 255, 256, 261, 263, 264, 265, 267, 270], "370": [31, 124], "compute_joint_prob": 31, "kl_diverg": [31, 136], "optimize_embed": 31, "y_init": 31, "n_iter": [31, 32, 34, 38, 41, 53, 57, 65, 70, 73, 77, 78, 88, 91, 92, 93, 94, 107], "momentum_earli": 31, "momentum_l": 31, "momentum_switch_it": 31, "early_exagger": 31, "exaggeration_it": 31, "save_everi": 31, "student_t": 31, "either": [31, 34, 53, 72, 75, 101, 110, 111, 122, 158, 171, 191, 227, 247, 248, 250, 255, 260, 262, 332], "local_rng": [31, 99], "iy": 31, "gain": [31, 33, 110, 113, 142], "ones_lik": [31, 37, 39, 67, 73, 78, 81, 86, 90, 96, 97, 99, 100, 101, 105, 140, 150, 160, 167, 168, 196, 197, 202, 219, 220, 234, 246, 254], "min_gain": 31, "01": [21, 22, 31, 34, 35, 38, 39, 41, 49, 50, 52, 53, 56, 59, 67, 75, 78, 93, 94, 101, 102, 107, 108, 112, 115, 116, 119, 120, 122, 123, 124, 125, 127, 129, 131, 132, 134, 136, 139, 140, 142, 143, 146, 148, 153, 157, 165, 168, 172, 175, 176, 180, 181, 184, 195, 199, 200, 207, 210, 220, 237, 242, 247, 248, 251, 252, 254, 261, 280, 296, 300, 301, 303, 306, 341, 348, 381, 382], "p_use": 31, "pq": [31, 138, 223], "n_anim": 31, "idx_anim": 31, "x_anim": 31, "y_anim": 31, "perplexity_anim": 31, "p_anim": 31, "history_tsn": 31, "kl_tsne": 31, "360": [31, 73, 87, 100, 118, 181, 189, 222, 259, 261, 280, 329], "annotation_text": [31, 34, 36, 38, 51, 57, 59, 77, 78, 86, 90, 91, 99, 100, 110, 148, 149, 151, 155, 160, 161, 164, 169, 173, 174, 175, 176, 177, 178, 179, 181, 184, 186, 193, 197, 198, 200, 206, 215, 216, 217, 220, 222, 223, 226, 227, 229, 231, 232, 233, 234, 235, 236, 238, 240, 243, 244, 245, 247, 249, 253, 255, 256, 257, 259, 260, 265, 266, 268, 270, 284], "progress": [31, 90, 135, 136, 141, 142, 143, 218, 241, 331, 355, 367], "it0": 31, "y_first": 31, "y1": [31, 36, 64, 74, 89, 91, 117, 123, 135, 137, 160, 164, 192, 221, 239, 262, 265, 267, 269, 312], "zerolin": [31, 230], "y2": [31, 36, 78, 89, 91, 92, 93, 109, 140, 153, 160, 164, 192, 221, 239, 265, 296], "720": [31, 64, 104, 108, 113, 256], "push": [31, 38, 45, 47, 74, 77, 84, 94, 113, 121, 134, 143, 149, 157, 165, 166, 170, 171, 179, 184, 193, 199, 203, 216, 224, 225, 228, 241, 250, 331, 332, 333, 353, 358, 359, 386], "further": [31, 52, 117, 157, 164, 179, 227], "apart": [31, 32, 74, 75, 105, 140, 209, 243], "unnorm": [31, 67, 193], "influenc": [31, 52, 89, 96, 101, 109, 122, 123, 158, 210, 245], "history_gauss": 31, "kl_gauss": 31, "y_gauss": [31, 161, 203], "y_tsne": 31, "1000": [31, 32, 38, 39, 46, 88, 93, 95, 102, 104, 114, 134, 140, 141, 145, 149, 150, 152, 154, 155, 166, 167, 172, 176, 187, 210, 213, 222, 247, 254, 264, 265, 267], "explor": [31, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 173, 197, 295, 311, 322, 383, 384], "subclust": 31, "reveal": [31, 78, 89, 97, 160, 315, 328], "lie": [31, 32, 87, 99, 109, 114, 118, 149, 179, 196, 202, 203, 206, 211, 212, 213, 214, 215, 216, 226, 230, 237, 262], "trustworthi": [31, 32, 243, 258, 271], "parametr": [31, 125, 149, 151, 153, 160, 163, 164, 165, 167, 171, 195, 197, 204, 206, 212, 214, 215, 219, 220, 224, 228, 240, 241, 243, 245, 248, 252, 255, 256, 263, 264, 268], "rerun": [31, 269], "diagnost": [31, 39, 45, 70, 72, 86, 87, 88, 100, 119, 120, 124, 127, 131, 132, 136, 137, 143, 146, 148, 154, 158, 160, 161, 166, 168, 177, 186, 187, 188, 190, 195, 198, 199, 206, 208, 215, 217, 231, 241, 246, 247, 252, 254, 262, 264, 305], "metadata": [31, 141, 331, 334, 341, 342, 348, 351, 352, 353, 358, 359, 365, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379], "excel": [31, 37, 105, 110, 236, 239, 255, 302, 304, 307], "slow": [4, 8, 31, 38, 65, 70, 111, 116, 121, 139, 142, 159, 170, 171, 185, 204, 209, 214, 221, 234, 236, 240, 303, 346], "hyperparamet": [31, 36, 37, 49, 57, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 98, 183, 184, 205, 210], "cleanest": [31, 52, 150, 159, 226], "z_pca2": 31, "z_tsne30": 31, "z_umap": 31, "min_dist": 31, "100": [31, 32, 37, 50, 53, 72, 81, 83, 84, 86, 87, 92, 99, 102, 103, 117, 119, 123, 134, 136, 139, 140, 141, 144, 145, 152, 153, 157, 158, 169, 172, 184, 190, 204, 214, 224, 226, 241, 242, 244, 246, 247, 252, 255, 263, 264, 266, 267, 269, 280, 292, 293, 299, 305, 318, 389], "conclus": [31, 258, 264], "van": [31, 32, 50, 145], "der": [31, 32], "maaten": [31, 32], "hinton": [31, 32], "2008": [31, 32], "acceler": [31, 113, 141, 144, 146, 168, 339], "barn": 31, "hut": 31, "mcinn": [31, 32], "2018": [31, 32, 115, 124, 145, 296], "tune": [32, 37, 49, 50, 53, 67, 69, 70, 72, 73, 81, 84, 94, 95, 103, 107, 110, 113, 143, 146, 161, 254, 283, 286, 288, 291, 299, 301, 346, 349, 368], "strength": [32, 36, 39, 49, 65, 69, 78, 104, 107, 108, 109, 148, 170, 172, 184, 191, 193, 200, 205, 219, 220, 223, 246, 265, 333], "weak": [32, 70, 112, 119, 134, 140, 151, 196, 246], "csr_matrix": [32, 73], "csgraph": 32, "pdist": 32, "modulenotfounderror": [32, 110, 115, 271, 275, 281, 290, 291, 293, 294, 297, 298, 302, 304, 307, 309, 310, 311, 319, 320, 321, 323, 324, 325, 326], "easiest": [32, 74, 184, 190, 222], "wrinkl": 32, "could": [32, 103, 220, 262, 264, 265], "grab": 32, "tear": 32, "inevit": 32, "friend": 32, "strongli": [32, 52, 67, 74, 78, 87, 93, 96, 100, 101, 103, 107, 111, 121, 151, 153, 164, 165, 174, 175, 180, 188, 221, 224, 233, 235, 236, 242, 243, 249, 262, 269, 341], "friendship": 32, "emerg": 32, "compromis": 32, "t_swiss": 32, "1400": [19, 32, 35, 197, 267], "disguis": 32, "460": [32, 106, 209, 261], "paper": [17, 18, 23, 24, 32, 39, 74, 133, 135, 137, 139, 140, 141, 144, 147, 240, 255, 263, 266, 267, 269, 272, 273, 274, 276, 277, 278, 279, 282], "piec": [32, 74, 211, 221, 228, 230, 242, 243, 247, 358, 373], "stitch": [32, 123], "sai": [32, 38, 46, 69, 70, 94, 102, 103, 107, 108, 112, 113, 114, 143, 149, 150, 188, 197, 215, 221, 224, 246, 251, 252, 254, 256, 259, 266, 269, 270, 331], "membership": [32, 69, 81, 243, 251], "confid": [32, 38, 45, 46, 52, 56, 67, 119, 134, 178, 182, 201, 209, 210, 228, 236, 249, 250, 251, 259, 261, 267, 268, 269], "mu_": [32, 103, 107, 108, 137, 138, 141, 146, 167, 185, 188, 199, 239, 245, 295, 316], "rho_i": 32, "offset": [32, 89, 91, 95, 117, 122, 123, 149, 212, 217, 220, 236], "OR": [32, 134, 251], "topolog": 32, "encourag": [32, 38, 52, 59, 64, 134, 136, 140, 146, 229], "written": [32, 35, 64, 93, 98, 104, 107, 119, 122, 123, 152, 157, 158, 159, 167, 169, 175, 177, 178, 180, 182, 186, 191, 192, 193, 194, 200, 202, 203, 205, 206, 207, 208, 210, 211, 215, 216, 220, 223, 224, 227, 228, 234, 236, 237, 264, 300], "nu_": 32, "lvert": [32, 38, 52, 74, 91, 96, 101, 104, 109, 185, 186, 237], "rvert": [32, 52, 109, 186, 237], "2b": [32, 176, 202, 211, 212, 213, 239], "nu": [32, 103, 136, 155, 166, 169, 173, 190, 191, 193, 195, 202, 205, 207, 209, 210, 218, 238, 239, 247], "simplifi": [32, 45, 106, 110, 151, 153, 154, 162, 165, 168, 174, 179, 182, 187, 203, 205, 213, 218, 220, 225, 332, 333, 339], "_binary_search_sigma": 32, "rho": [32, 57, 87, 107, 114, 118, 185, 189, 202, 204, 206, 224, 255, 262, 265, 288], "lo": [32, 50, 90, 94, 120, 124, 127, 156, 163, 171, 173, 178, 179, 180, 181, 190, 199, 200, 204, 205, 215, 227, 232, 233, 238, 239, 248, 249, 255, 260, 262, 263, 265, 266, 268], "hi": [32, 50, 90, 94, 120, 124, 127, 156, 163, 171, 173, 178, 179, 180, 181, 190, 199, 200, 204, 215, 227, 232, 233, 238, 239, 248, 249, 255, 260, 262, 263, 265, 266, 268], "simplified_fuzzy_graph": 32, "log2": [32, 59, 78, 110, 131], "adjac": 32, "sym": 32, "demo_idx": 32, "knn_idx": 32, "knn_dist": 32, "weights_i": 32, "aspect": [32, 49, 53, 57, 73, 74, 78, 99, 103, 139, 157, 219, 221, 222, 251, 253], "\u03bc_ij": 32, "440": [32, 229, 262], "emphas": [32, 49, 59, 84, 91, 96, 129, 196, 245], "tight": [32, 83, 90, 231, 328, 332, 343, 344], "coher": 32, "spideri": 32, "tightli": [32, 110, 181, 182, 222, 332, 374], "clump": 32, "mostli": [32, 37, 41, 50, 72, 77, 78, 97, 107, 108, 112, 113, 119, 143, 157, 175, 183, 188, 190, 201, 235, 255, 260, 371], "densiti": [32, 65, 83, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 227, 232, 233, 236, 240, 241, 244, 246, 248, 250, 252, 254, 258, 259, 261, 262, 264, 266, 267, 268, 269, 284], "cosin": [32, 83, 149, 202, 207, 300, 327], "manhattan": [32, 83, 105], "save": [32, 139, 140, 143, 384], "64d": 32, "x_digit": 32, "y_digit": 32, "n_digit": 32, "sub_idx": [32, 35], "x_d": [32, 108, 189], "y_d": 32, "fit_umap": 32, "fit_tsn": 32, "perplex": 32, "fit_isomap": 32, "_digit_colorbar": 32, "ticktext": [32, 53, 75, 139, 249, 268, 270], "scatter_digit": 32, "show_scal": 32, "n_neighbors_grid": 32, "min_dist_grid": 32, "md": 32, "760": [32, 36, 64, 104, 106, 108, 260], "takeawai": [32, 35, 78, 89, 102, 109, 114], "avg_knn_overlap": 32, "nn_a": 32, "nn_b": 32, "na": [32, 286, 287, 288, 289, 292, 300, 318], "return_dist": 32, "nb": [32, 108, 231], "overlap": [32, 34, 35, 37, 50, 53, 64, 65, 73, 74, 78, 84, 114, 322, 357, 366], "ra": [32, 143], "rb": 32, "umap_emb": 32, "tsne_emb": 32, "row_titl": [32, 114], "tsne_row": 32, "averag": [32, 33, 35, 37, 38, 45, 46, 49, 50, 51, 52, 53, 54, 56, 57, 59, 64, 65, 74, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 110, 113, 118, 125, 127, 129, 134, 135, 140, 141, 143, 144, 145, 146, 154, 155, 156, 162, 166, 175, 185, 187, 190, 191, 194, 196, 212, 217, 221, 230, 236, 237, 250, 252, 253, 257, 260, 263, 265, 266, 267, 268, 269, 270, 280, 288, 297, 298, 299, 301, 303, 308, 319, 340], "avg_knn_overlap_vs_seed0": 32, "df_stabil": 32, "heavili": [32, 36, 38, 52, 53, 56, 103, 184, 190, 194, 242], "weaker": 32, "x_sr": 32, "t_sr": 32, "geodesic_spearman": 32, "geo": [32, 339], "iu": [32, 195], "geo_vec": 32, "emb_vec": 32, "n_metric": 32, "metric_idx": 32, "x_m": [32, 232, 233, 237, 238, 241], "emb_m": 32, "df_metric": 32, "tickangl": [32, 81, 100], "x_new": [32, 103, 226, 236], "flexibl": [5, 32, 73, 103, 106, 110, 118, 125, 152, 153, 154, 158, 161, 164, 165, 166, 169, 170, 171, 173, 174, 180, 187, 190, 191, 195, 198, 199, 208, 211, 220, 245, 247, 287, 333], "dramat": [32, 183], "smear": 32, "decent": [32, 188, 211, 243, 248, 258], "kl": [32, 95, 136, 140, 142, 143, 184], "diverg": [32, 95, 113, 135, 138, 139, 150, 152, 154, 155, 158, 159, 160, 161, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 182, 183, 187, 196, 198, 199, 202, 204, 207, 209, 216, 219, 220, 240, 244], "nativ": [32, 331, 332, 353, 359, 366, 386], "Not": [32, 35, 36, 37, 41, 46, 47, 49, 50, 51, 52, 56, 64, 65, 69, 70, 72, 73, 74, 75, 77, 81, 83, 84, 86, 87, 88, 89, 91, 93, 94, 100, 103, 139, 145, 213, 217, 243, 249, 260, 264, 335, 346, 350, 351, 352, 353, 358, 379], "shortest": [32, 99, 129], "hole": 32, "header": [1, 2, 32, 59, 249, 258, 339, 350], "fill_color": [32, 266], "f2f2f2": 32, "font": [32, 39, 72, 101, 135, 137, 269], "28": [32, 75, 81, 107, 142, 188, 213, 221, 224, 230, 247, 260, 267, 300, 389], "sever": [32, 41, 75, 78, 87, 88, 93, 95, 98, 108, 112, 114, 142, 166, 169, 170, 173, 181, 190, 193, 197, 199, 200, 207, 209, 216, 223, 236, 238, 239, 242, 244, 249, 253, 257, 258, 267, 285, 386], "heali": 32, "melvil": 32, "auc": [33, 34, 36, 37, 39, 45, 56, 67, 75], "area": [33, 36, 65, 110, 152, 153, 154, 157, 184, 187, 196, 198, 204, 206, 211, 212, 236, 246, 254, 266, 267], "trapezoid": [33, 36, 64, 65, 164, 170, 174, 266, 267], "average_precision_scor": [33, 64], "ap": [33, 92, 246], "balanced_accuracy_scor": [33, 34], "brier_score_loss": [33, 45], "brier": [33, 34, 49, 50, 56, 64, 67], "class_likelihood_ratio": 33, "likelihood": [33, 45, 46, 52, 91, 95, 96, 101, 104, 108, 112, 113, 114, 116, 117, 119, 122, 136, 228, 295], "classification_report": [33, 106, 108, 287, 289, 290, 291, 293, 294, 324, 325], "report": [33, 37, 38, 39, 40, 46, 59, 67, 72, 96, 100, 101, 102, 106, 108, 114, 122, 197, 204, 216, 227, 243, 245, 246, 248, 249, 251, 255, 260, 261, 263, 268, 269, 270, 280, 331, 332, 333, 340, 350, 353, 355, 366], "cohen_kappa_scor": 33, "cohen": [33, 267, 268, 269], "inter": [33, 41, 53, 162, 213, 236, 303], "confusion_matrix_at_threshold": 33, "calcul": [33, 43, 85, 122, 154, 155, 165, 174, 193, 208, 216, 237, 319, 335], "d2_brier_scor": 33, "d2_log_loss_scor": 33, "dcg_score": 33, "discount": [33, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 396], "det_curv": 33, "detect": [12, 33, 34, 36, 48, 49, 50, 53, 74, 75, 99, 112, 153, 191, 193, 201, 205, 216, 242, 247, 250, 254, 255, 256, 257, 259, 260, 261, 264, 266, 270, 271, 283, 317, 322, 331, 335, 338, 381], "f1_score": 33, "f1": [33, 34, 39, 50, 51, 57, 67, 75, 106, 108, 154, 225, 228, 322], "known": [33, 39, 45, 57, 70, 72, 73, 77, 81, 84, 113, 117, 122, 148, 149, 151, 154, 155, 156, 157, 158, 160, 161, 163, 164, 167, 168, 171, 173, 174, 175, 179, 181, 184, 185, 187, 188, 189, 190, 195, 196, 198, 200, 202, 204, 206, 207, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 224, 225, 226, 227, 229, 231, 233, 234, 237, 238, 241, 242, 256, 262, 266, 269, 334], "fbeta_scor": [33, 49], "hamming_loss": 33, "ham": [33, 34, 67], "hinge_loss": 33, "hing": [33, 35, 52, 109, 115], "jaccard_scor": [33, 53], "jaccard": [33, 51, 67], "coeffici": [33, 41, 45, 49, 68, 82, 85, 100, 104, 107, 109, 112, 113, 114, 115, 116, 118, 134, 139, 140, 142, 143, 144, 145, 146, 158, 185, 190, 199, 200, 202, 213, 218, 225, 228, 230, 231, 234, 237, 252, 253, 261, 262], "aka": 33, "logist": [33, 35, 39, 41, 49, 50, 52, 53, 64, 74, 104, 106, 115, 154, 187, 223, 237, 261], "matthews_corrcoef": 33, "matthew": 33, "mcc": 33, "multilabel_confusion_matrix": 33, "ndcg_score": [33, 47], "precision_recall_curv": [33, 36], "recal": [33, 34, 37, 39, 51, 57, 60, 61, 63, 64, 65, 75, 106, 108, 158, 183, 188, 203, 322], "precision_recall_fscore_support": 33, "precision_scor": [33, 49], "recall_scor": [33, 49], "roc_auc_scor": [33, 35, 65], "receiv": [33, 64, 135, 137, 190, 201, 257, 333, 354, 355, 385], "characterist": [33, 64, 112, 118, 169, 180, 188, 201, 208, 228], "roc": [33, 34, 36, 75], "roc_curv": [33, 35, 39, 64, 65], "top_k_accuracy_scor": 33, "zero_one_loss": [33, 51], "coverage_error": 33, "coverag": [33, 44, 53, 87, 94, 280, 285], "label_ranking_average_precision_scor": 33, "label_ranking_loss": 33, "user": [1, 33, 34, 37, 46, 47, 49, 59, 64, 68, 85, 86, 93, 98, 99, 101, 224, 225, 226, 230, 237, 238, 263, 266, 270, 333, 339, 341, 351, 353, 358, 359, 383, 385], "guid": [33, 34, 46, 49, 64, 68, 74, 85, 86, 93, 98, 101, 172, 264, 332, 382, 384, 385], "model_evalu": [33, 34, 35, 37, 38, 49, 50, 64, 68, 74, 85, 86, 89, 96, 99, 101, 271], "sk_accuracy_scor": 34, "4": [34, 50, 52, 84, 95, 111, 114, 115, 119, 120, 121, 124, 127, 129, 131, 132, 141, 145, 228, 244, 246, 254, 256, 259, 269, 275, 281, 286, 289, 290, 291, 292, 294, 296, 297, 298, 299, 302, 303, 304, 305, 306, 307, 309, 310, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 338, 340, 341, 342, 343, 344, 347, 348, 350, 351, 352, 354, 355, 356, 357, 389, 394], "comfort": [34, 93, 96, 97, 139, 143, 157, 158, 162, 163, 183, 191, 194, 195, 198, 201, 209, 211, 212, 213, 216, 218, 223, 224, 228, 229, 230, 235, 237, 238, 240, 246, 267, 334, 335, 356], "y_1": [34, 86, 88, 100, 112, 125, 159, 160, 166, 199, 230, 239, 245, 263, 267], "y_n": [34, 86, 88, 100], "_1": [34, 86, 88, 100, 107, 118, 209, 215, 261], "statement": [34, 186, 196, 258, 266, 270], "equal": [34, 36, 37, 38, 41, 46, 47, 49, 50, 51, 53, 59, 64, 67, 70, 77, 78, 81, 84, 86, 87, 88, 89, 93, 105, 106, 109, 112, 125, 134, 154, 159, 166, 167, 168, 181, 184, 187, 189, 192, 193, 194, 196, 197, 198, 199, 200, 201, 206, 209, 211, 217, 218, 221, 222, 223, 226, 227, 229, 230, 234, 235, 236, 237, 238, 239, 243, 244, 245, 249, 253, 256, 257, 258, 259, 260, 261, 263, 266, 269, 270, 295], "operatornam": [34, 39, 46, 51, 56, 99, 111, 121, 142, 151, 153, 156, 158, 161, 166, 175, 178, 179, 181, 186, 188, 194, 201, 223, 229, 255, 262, 264], "tp": [34, 35, 36, 37, 39, 41, 49, 50, 51, 57, 64, 65, 75, 78, 81, 141], "fp": [34, 35, 36, 37, 39, 41, 49, 50, 51, 57, 64, 65, 75, 78, 81, 158], "fn": [34, 35, 36, 37, 39, 41, 49, 50, 51, 57, 64, 65, 75, 78, 81], "ell_": [34, 46, 90, 94, 139, 300], "ne": [34, 52, 67, 74, 98, 120, 153, 154, 159, 161, 165, 172, 173, 181, 184, 190, 199, 202, 207, 208, 213, 215, 216, 218, 226, 228, 230, 233, 238, 249], "contribut": [34, 37, 47, 51, 52, 59, 69, 78, 91, 93, 96, 97, 98, 101, 102, 114, 122, 157, 165, 183, 193, 211, 237, 242, 246, 247, 251, 254, 255], "incorrect": [34, 67], "y_true": [34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 75, 77, 78, 81, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 117, 122, 123, 125, 131, 132, 134, 143, 161, 280, 301], "y_pred": [34, 35, 37, 39, 41, 49, 50, 51, 52, 53, 57, 64, 65, 67, 69, 70, 72, 77, 78, 81, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 107, 108, 122, 125, 127, 129, 131, 132, 134, 143, 280, 299, 301, 303, 306], "marker_color": [34, 45, 64, 77, 81, 83, 86, 87, 90, 92, 100, 120, 122, 124, 127, 131, 132, 245, 247, 249, 251, 261, 263, 267, 268, 270], "2ca02c": [34, 39, 53, 64, 81, 94, 113, 244, 270, 328, 329], "annotation_posit": [34, 100, 169, 243, 244, 245, 247, 249, 253, 255, 256, 257, 259, 260, 265, 268, 284], "accuracy_score_np": [34, 37], "sample_weight": [34, 37, 38, 39, 45, 46, 47, 51, 52, 56, 67, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102], "n_label": [34, 47, 51, 53, 78], "2": [34, 50, 52, 84, 95, 111, 115, 120, 121, 124, 127, 129, 131, 132, 141, 228, 244, 269, 275, 281, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 332, 334, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 350, 351, 352, 353, 354, 355, 356, 357, 366, 368, 378, 381, 389, 393, 394], "expect": [34, 35, 38, 39, 45, 46, 47, 52, 53, 56, 57, 59, 67, 70, 72, 74, 75, 81, 86, 89, 94, 97, 100, 103, 107, 108, 111, 113, 114, 121, 125, 134, 140, 141, 144, 151, 154, 228, 242, 246, 250, 251, 252, 253, 255, 258, 265, 270, 271, 293, 296, 349, 393], "correct_f": 34, "predict_labels_from_proba": [34, 67], "5": [34, 50, 52, 65, 67, 72, 84, 95, 106, 114, 115, 119, 120, 124, 127, 129, 131, 132, 135, 141, 145, 228, 244, 246, 256, 259, 269, 275, 281, 289, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 310, 312, 317, 319, 322, 323, 326, 327, 328, 329, 335, 338, 341, 343, 344, 347, 348, 351, 352, 356, 374, 381, 382, 383, 386, 389, 393], "3": [34, 50, 52, 84, 95, 114, 115, 119, 120, 124, 127, 129, 131, 132, 141, 228, 244, 246, 259, 269, 275, 281, 284, 285, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 307, 308, 309, 310, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 350, 351, 352, 353, 354, 355, 356, 357, 359, 365, 366, 367, 370, 375, 378, 383, 389, 394], "theirs": [34, 189, 258], "y_true_ml": [34, 53, 67], "y_pred_ml": [34, 53, 67], "401": [34, 37, 38, 45, 49, 57, 91, 175, 176, 207], "best_idx": [34, 41, 49, 51, 53, 57, 69, 70, 75, 78, 301], "best_t": [34, 37, 41, 51, 53, 57, 75], "achiev": [34, 37, 46, 51, 57, 65, 67, 141, 153, 208, 225, 231, 291, 297, 298], "complet": [34, 68, 69, 76, 93, 140, 198, 211, 251, 264, 266, 268, 311, 338, 370], "n_po": [34, 35, 36, 37, 50, 64, 65], "y_pred_all0": 34, "texttempl": [34, 37, 39, 49, 69, 73, 78, 246, 259, 261], "imbal": [34, 35, 37, 41, 46, 49, 50, 51, 52, 65, 67, 73, 108, 109, 241], "surrog": [34, 36, 37, 47, 51, 52, 53, 59, 64, 67, 143, 146], "monitor": [34, 37, 45, 50, 51, 90, 113, 138, 140, 318, 340, 345, 346, 347, 351, 386], "improv": [34, 36, 37, 45, 46, 47, 84, 88, 90, 91, 100, 108, 122, 123, 134, 137, 139, 142, 143, 144, 145, 146, 166, 251, 266, 301, 310, 323, 359, 372, 381, 385], "n0": [34, 37, 41, 53, 67, 72, 219, 234], "n1": [34, 37, 41, 53, 72, 74, 107, 163, 166, 250, 256, 260, 266, 267], "260": [34, 97, 103, 106, 109, 110, 119, 260], "unavoid": 34, "add_intercept": [34, 35, 37, 41, 45, 49, 50, 57, 65, 69, 75, 95, 104, 117, 122, 123], "log_loss_np": 34, "fit_logreg_gd": [34, 36, 37, 39, 46, 53, 65], "l2": [34, 36, 37, 38, 39, 41, 45, 46, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 69, 75, 78, 86, 91, 94, 95, 98, 104, 110, 115, 358], "verbos": [34, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 339], "exclud": [34, 41, 69, 83, 238, 242, 249, 261, 266, 267], "intercept": [34, 41, 45, 46, 57, 65, 69, 78, 87, 89, 93, 95, 96, 98, 99, 100, 104, 107, 109, 112, 115, 116, 117, 118, 183], "hist": [34, 36, 37, 46, 47, 51, 52, 56, 64, 67, 88, 90, 91, 92, 96, 97, 98, 99, 101, 102, 120, 122, 124, 127, 131, 132, 149, 150, 151, 153, 161, 164, 170, 171, 178, 185, 186, 191, 202, 217, 222, 236, 248, 254], "p_val": [34, 37, 39, 45, 49, 51, 56, 57, 67, 69, 75, 78, 246, 263, 267], "acc_val_05": 34, "smoothli": [34, 47, 69, 70, 107, 138, 149, 156, 157, 171, 206], "maxim": [34, 37, 39, 41, 45, 46, 47, 49, 50, 53, 56, 57, 65, 69, 70, 72, 73, 75, 78, 81, 83, 84, 86, 87, 88, 89, 95, 100, 103, 104, 106, 109, 134, 137, 138, 143, 152, 158, 164, 165, 168, 175, 176, 177, 179, 184, 185, 187, 188, 190, 203, 206, 207, 211, 217, 223, 224, 229, 237, 238, 244, 249, 393], "accs_val": 34, "boundari": [34, 37, 38, 49, 52, 53, 56, 67, 75, 78, 81, 103, 106, 109, 110, 134, 149, 150, 151, 152, 159, 163, 168, 170, 178, 181, 190, 194, 195, 197, 198, 202, 206, 211, 214, 215, 220, 223, 224, 227, 228, 231, 232, 238, 239, 241, 252, 254, 291, 331, 357, 358, 372], "x2_min": [34, 37, 52], "x2_max": [34, 37, 52], "x1_grid": [34, 75, 78], "x2_grid": 34, "p_grid": [34, 38, 50, 153, 226, 231, 264], "background": [4, 34, 51, 53, 103, 151, 342, 354, 355, 358], "showlin": [34, 104, 105, 106, 108, 109, 110, 185], "clf": [34, 35, 38, 46, 52, 64, 287, 289, 290, 291, 293, 294], "y_pred_val": 34, "percent": [34, 92, 122, 149, 150, 165, 171, 201, 211, 212, 230, 255], "hide": [34, 49, 50, 65, 67, 77, 81, 89, 91, 97, 99, 101, 178, 305, 334], "strict": [34, 51, 64, 67, 123, 141, 144, 212, 213, 296, 332], "pr": [34, 35, 36, 37, 45, 46, 49, 50, 65, 67, 154, 163, 181, 187, 196, 224, 225, 228, 230, 232, 234, 236, 241, 243, 247, 250, 251, 256, 332, 333, 335], "deploi": [34, 271, 331, 332, 333, 339, 340, 344, 345, 346, 349, 356, 367, 381, 382, 383], "medic": [34, 39, 46, 50, 108, 257], "screen": [34, 39, 50, 64, 65, 234, 262], "answer": [2, 17, 18, 23, 24, 35, 36, 53, 59, 70, 72, 73, 87, 90, 91, 94, 100, 105, 112, 118, 133, 147, 231, 243, 244, 245, 247, 250, 251, 253, 255, 257, 259, 261, 262, 263, 265, 266, 268, 269, 270, 272, 273, 274, 276, 277, 278, 279, 282, 310, 340], "randomli": [35, 69, 70, 75, 99, 138, 141, 184, 195, 255, 260, 263, 265, 268, 289], "focus": [7, 35, 36, 47, 50, 64, 65, 67, 75, 102, 103, 107, 110, 116, 122, 126, 128, 130, 135, 153, 188, 245, 250, 254, 261, 263, 280, 311, 312, 313, 317, 359], "free": [35, 36, 37, 64, 65, 87, 99, 100, 109, 110, 117, 151, 154, 159, 162, 165, 168, 169, 170, 172, 173, 174, 176, 177, 180, 183, 187, 188, 190, 196, 198, 199, 200, 203, 206, 211, 212, 213, 216, 218, 219, 222, 227, 229, 233, 244, 252, 256, 265, 280, 381, 384, 385, 389], "inspir": [35, 127, 130, 131, 132, 159], "make_classif": [35, 36, 38, 39, 45, 46, 49, 57, 64, 69, 75, 78], "make_pipelin": [35, 103, 107, 109, 110, 291, 320, 324, 325], "tau": [35, 36, 64, 78, 134, 139, 141, 143, 144, 145, 155, 160, 163, 172, 175, 176, 177, 183, 192, 194, 203, 222, 284], "infti": [35, 56, 64, 65, 90, 92, 95, 100, 114, 117, 118, 134, 136, 137, 139, 143, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 212, 213, 214, 215, 216, 218, 219, 220, 224, 225, 227, 228, 229, 231, 232, 233, 234, 235, 236, 239, 240, 241, 242, 254, 261], "summar": [35, 36, 49, 50, 64, 73, 74, 77, 81, 89, 91, 93, 99, 101, 102, 131, 132, 145, 252, 253, 257, 261, 329, 340], "n_neg": [35, 37, 50, 64, 65], "pos_scor": [35, 64], "neg_scor": [35, 64], "r_": [35, 36, 41, 45, 50, 64, 65, 74, 77, 78, 89, 93, 103, 104, 114, 134, 137, 139, 140, 143, 233, 237, 252, 254, 256, 257, 267], "y_score": [35, 36, 47, 49, 50, 64, 65], "toy_auc": 35, "convert": [35, 39, 47, 50, 51, 59, 67, 91, 92, 97, 107, 140, 141, 148, 169, 172, 175, 191, 192, 207, 209, 211, 221, 222, 225, 230, 242, 247, 259, 264, 306, 318, 333, 385], "qquad": [35, 37, 38, 39, 41, 46, 49, 50, 52, 59, 64, 65, 67, 69, 73, 75, 77, 78, 81, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 107, 109, 111, 114, 116, 117, 119, 120, 121, 122, 125, 136, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 208, 210, 211, 212, 214, 215, 216, 217, 218, 219, 220, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 249, 253, 254, 256, 261, 264, 267, 268], "confusion_counts_at_threshold": 35, "roc_auc": 35, "integr": [8, 35, 36, 64, 228, 266, 267, 332, 333, 334, 335, 338, 343, 344, 345, 346, 348, 350, 352, 356, 359, 402], "auc_trapezoid": 35, "10f": 35, "whenev": [35, 134, 186, 193, 196, 198, 201, 202, 212, 214, 216, 220, 221, 226, 227, 230, 355], "roc_curve_numpi": [35, 65], "issubset": [35, 52], "undefin": [35, 39, 45, 49, 53, 57, 64, 74, 83, 87, 90, 92, 100, 101, 112, 148, 155, 160, 168, 175, 178, 179, 194, 207, 210, 223, 224, 242, 262, 265], "present": [35, 46, 64, 108, 112, 113, 123, 131, 146, 165, 191, 213, 239, 257, 328, 381], "ti": [35, 47, 64, 67, 90, 101, 177, 181, 242, 248, 252, 253, 256, 257, 260, 265, 270, 314, 379], "kind": [35, 36, 57, 59, 64, 65, 103, 104, 123, 150, 151, 193, 195, 202, 205, 225, 239, 242, 252, 253, 257, 260, 265, 270, 295, 331, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 382], "mergesort": [35, 36, 59, 64, 65, 252, 253, 257, 260, 265, 270], "y_true_sort": [35, 59, 65], "y_score_sort": [35, 59, 64, 65], "distinct": [35, 47, 65, 74, 148, 197, 212, 214, 224, 252], "threshold_idx": [35, 64], "prepend": [35, 64, 173], "roc_auc_score_numpi": 35, "fpr_np": [35, 64], "tpr_np": [35, 64], "thr_np": [35, 64], "auc_np": [35, 64], "pn": 35, "s_j": [35, 47, 52, 64, 74, 115, 139, 284, 322], "There": [35, 81, 102, 107, 151, 154, 156, 157, 158, 160, 162, 163, 165, 166, 168, 169, 173, 175, 179, 181, 187, 188, 191, 192, 194, 195, 199, 200, 205, 206, 208, 209, 213, 219, 220, 222, 224, 225, 226, 228, 230, 231, 232, 233, 234, 236, 237, 239, 256], "r_i": [35, 41, 89, 90, 91, 92, 93, 96, 97, 101, 107, 139, 205, 247, 257], "among": [35, 36, 37, 59, 83, 84, 87, 91, 97, 100, 113, 189, 194, 199, 209, 217, 235, 238, 249, 255, 301], "rankdata_average_ti": [35, 64], "x_sort": [35, 64, 110, 148, 153, 154, 170, 177, 186, 187, 220, 242, 253, 256, 259], "ranks_sort": [35, 64, 252, 253, 257, 260, 270], "avg_rank": [35, 64, 257, 260, 265, 270], "empty_lik": [35, 36, 37, 38, 39, 41, 45, 46, 49, 57, 64, 65, 75, 77, 78, 81, 95, 116, 151, 153, 156, 157, 158, 160, 161, 164, 165, 168, 171, 172, 174, 175, 180, 181, 185, 199, 200, 204, 210, 211, 212, 213, 217, 238, 248, 252, 253, 260, 261, 267], "roc_auc_score_rank_numpi": 35, "sum_pos_rank": 35, "auc_rank": 35, "formula": [35, 36, 49, 50, 51, 56, 57, 64, 67, 70, 72, 75, 88, 93, 98, 101, 105, 110, 148, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 179, 181, 185, 186, 187, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 204, 206, 208, 211, 212, 213, 216, 220, 221, 222, 226, 227, 228, 229, 231, 234, 235, 236, 237, 238, 239, 246, 247, 255, 260], "trapz": [35, 64, 65, 148, 149, 151, 152, 153, 155, 156, 161, 164, 170, 171, 173, 174, 175, 176, 177, 184, 193, 197, 198, 200, 202, 204, 206, 208, 211, 212, 213, 216, 227, 232, 233, 240, 266], "feasibl": [35, 65, 69, 109, 149, 174, 184, 185, 197, 215, 228, 230, 232, 233, 234, 238, 251], "pos_idx": [35, 64], "neg_idx": [35, 64], "y_sub": 35, "s_sub": 35, "po": [35, 36, 38, 39, 41, 45, 46, 49, 50, 57, 64, 65, 67, 75, 113, 120, 139, 140, 144, 158, 161, 168, 181, 190, 234], "auc_pairwis": [35, 64], "softplu": [35, 51, 56, 93, 97, 140], "s_transform": 35, "3s": [35, 134, 136, 141, 145], "explicit": [1, 35, 36, 39, 49, 50, 52, 67, 90, 102, 103, 107, 113, 120, 122, 124, 138, 141, 143, 149, 153, 155, 157, 161, 163, 171, 172, 185, 188, 189, 192, 197, 201, 202, 205, 221, 244, 259, 264, 268, 270, 328, 331, 338, 344, 358, 359, 379], "thr_plot": 35, "tpr_plot": 35, "fpr_plot": 35, "\u03c4": [35, 64, 155, 163, 265], "stricter": [35, 65, 67, 111], "read": [3, 5, 35, 45, 46, 78, 83, 87, 112, 114, 224, 228, 245, 251, 259, 261, 263, 332, 334, 335, 338, 341, 345, 348, 349, 350, 351, 352, 358, 373, 376, 382], "autorang": [35, 41, 53, 64, 65, 310], "decision_funct": [35, 52, 64, 106, 109], "n_inform": [35, 36, 38, 39, 45, 46, 49, 57, 64, 69, 75, 78], "n_redund": [35, 36, 38, 39, 45, 46, 49, 57, 64, 69, 75, 78], "class_sep": [35, 36, 38, 39, 45, 46, 49, 57, 64, 69, 75, 78], "y_score_test": 35, "auc_test": 35, "fpr_test": 35, "tpr_test": 35, "held": [35, 39, 160, 179, 196, 224], "max_w": 35, "s_w": [35, 216], "nabla_w": [35, 38, 45, 52, 56, 86, 89, 91, 92, 93, 94, 135], "exp_z": [35, 36, 38, 41, 45, 46, 65], "standardize_fit": [35, 37, 41, 57, 69, 107], "standardize_transform": [35, 37, 41, 51, 56, 67, 69], "prepar": [35, 295, 326], "y_small": [35, 255, 260], "flip_i": [35, 38, 39, 45, 46, 57, 75], "x_tr": [35, 88, 95, 96, 101, 102, 104, 105, 106, 107, 110], "x_va": 35, "y_tr": [35, 88, 95, 96, 101, 102, 104, 105, 106, 107, 110], "y_va": 35, "train_logistic_c": 35, "auc_hist": 35, "train_auc_pairwis": 35, "steps_per_epoch": 35, "batch_pair": [35, 64], "d_score": 35, "w_ce": [35, 50, 64], "auc_c": 35, "w_auc": [35, 64], "auc_auc": 35, "150": [35, 41, 50, 70, 78, 83, 96, 99, 103, 127, 134, 136, 139, 141, 146, 233, 242, 261, 322, 389], "ce": 35, "insensit": [35, 67, 89], "terribl": [35, 51], "busi": [35, 65, 91, 92, 94, 119, 246, 280], "As": [35, 36, 45, 50, 52, 67, 72, 73, 77, 87, 90, 96, 98, 99, 105, 124, 142, 148, 150, 151, 153, 154, 155, 156, 157, 158, 160, 163, 166, 167, 169, 171, 174, 177, 180, 186, 187, 188, 191, 192, 195, 197, 203, 206, 207, 208, 210, 211, 213, 214, 216, 221, 222, 223, 224, 225, 229, 230, 232, 235, 262, 265, 269, 365, 376, 389], "usabl": [35, 70, 72, 77, 118, 222, 224, 228, 231, 348], "highli": [35, 46, 47, 49, 50, 59, 67, 78, 107, 108, 123, 139, 155, 169, 175, 214, 228, 254, 270, 292, 332, 333], "imbalanc": [35, 36, 37, 38, 41, 45, 46, 49, 50, 53, 56, 57, 64, 65, 70, 77, 78, 83, 84], "tom": [35, 65], "fawcett": [35, 64, 65], "2006": [35, 46, 64, 65, 103, 253], "analysi": [35, 64, 65, 83, 116, 117, 119, 122, 123, 162, 167, 171, 173, 189, 191, 192, 197, 200, 212, 216, 218, 220, 251, 252, 253, 257, 261, 340, 353, 381, 386], "reach": [36, 73, 87, 139, 141, 146, 218, 226, 335, 350, 357, 358], "fraud": [36, 45, 49, 50, 57, 223], "diseas": [36, 108], "anomali": [36, 57, 112, 161, 271, 283, 285, 317, 381], "retriev": [36, 47, 49, 50, 53, 59, 65, 341], "recommend": [36, 47, 50, 59, 143, 218, 233, 246, 262, 266, 308, 340, 358], "sk_average_precision_scor": 36, "sk_precision_recall_curv": 36, "healthi": [36, 340], "defect": [36, 49, 98, 152, 223, 224, 226, 230, 231, 234, 236], "99": [36, 37, 39, 41, 46, 49, 53, 56, 57, 65, 67, 75, 78, 94, 114, 119, 134, 136, 138, 139, 140, 142, 143, 144, 145, 146, 148, 154, 160, 165, 168, 172, 175, 176, 177, 180, 181, 183, 184, 187, 194, 195, 196, 197, 200, 202, 203, 207, 209, 220, 221, 225, 235, 237, 239, 246, 248, 252, 260, 293, 299], "useless": [36, 57, 81, 100], "Of": 36, "flag": [36, 118, 134, 209, 242, 284, 322, 341, 359], "skill": 36, "preval": [36, 39, 57, 108, 232], "y_true_toi": [36, 77], "y_score_toi": 36, "90": [36, 47, 57, 59, 64, 67, 69, 87, 88, 105, 109, 117, 119, 121, 123, 124, 125, 136, 142, 146, 151, 154, 159, 163, 173, 179, 181, 183, 184, 187, 191, 195, 197, 202, 220, 233, 234, 241, 250, 256, 261, 315], "70": [36, 47, 57, 59, 72, 73, 100, 108, 110, 134, 135, 137, 142, 151, 156, 161, 164, 169, 171, 173, 174, 181, 183, 184, 185, 186, 190, 193, 194, 203, 204, 206, 213, 221, 226, 229, 230, 237, 244, 245, 246, 248, 252, 258, 261, 264, 316, 318, 368], "y_sort": [36, 59, 99], "s_sort": [36, 185, 188, 191, 215], "precision_at_k": 36, "recall_at_k": 36, "encount": [31, 36, 57, 89, 158, 160, 206, 235, 240], "ap_toi": 36, "prevalence_toi": 36, "df_toi": 36, "tp_cum": 36, "fp_cum": 36, "contributes_to_ap": 36, "pos_mask": 36, "crimson": [36, 64, 67, 78, 90, 91, 99, 114, 245, 247, 253, 255, 256, 257, 259, 261, 265, 284, 317, 322], "precision_curv": [36, 50], "recall_curv": [36, 50], "ap_area": 36, "line_shap": [36, 67, 223, 226, 229, 231, 232, 233, 234, 236, 238, 239, 242, 256], "hv": [36, 67, 223, 226, 229, 231, 232, 233, 234, 236, 238, 239, 242, 256], "fill": [36, 69, 70, 78, 90, 103, 109, 113, 116, 117, 119, 120, 122, 123, 124, 125, 132, 138, 146, 148, 152, 156, 158, 166, 169, 170, 180, 185, 190, 193, 197, 214, 232, 236, 246, 250, 254, 258, 261, 266, 267, 268, 269, 305, 340, 341, 347, 355], "tozeroi": [36, 250, 258, 261, 268, 269], "r_n": [36, 205], "p_n": [36, 237], "shown": [36, 115, 153, 160, 174, 270, 280, 348, 349, 354], "earlier": [36, 122, 165, 171, 199, 211, 213], "mapsto": [36, 159, 173, 177, 181, 203, 205, 218, 221, 232, 233, 236], "auprc": 36, "precision_recall_curve_np": 36, "average_precision_score_np": 36, "y_check": 36, "s_check": 36, "ap_np": 36, "ap_sk": 36, "ap_np_affin": 36, "ap_np_cub": 36, "upward": [36, 69, 94, 174, 178, 239, 257], "3000": [36, 38, 49, 64, 75, 88, 90, 91, 94, 107, 108, 145, 153, 154, 161, 164, 172, 173, 176, 177, 178, 179, 187, 190, 202, 207, 211, 212, 214, 216, 218, 231, 242, 255, 265, 266], "y_sim": 36, "scores_random": 36, "scores_some_sign": 36, "scores_almost_perfect": 36, "001": [36, 39, 49, 57, 107, 136, 138, 141, 142, 144, 145, 146, 161, 163, 166, 178, 179, 180, 181, 182, 183, 188, 191, 195, 197, 198, 199, 200, 213, 219, 239, 246, 261, 351, 352, 356, 394], "prec": [36, 49, 221], "rec": [36, 49, 127, 131], "multilabel": [36, 47, 50], "micro": [36, 50, 53, 342, 351, 357], "macro": [36, 37, 50, 53, 64, 106, 108, 122], "prec_sk": 36, "rec_sk": 36, "thr_sk": [36, 65], "prec_sk_inc": 36, "rec_sk_inc": 36, "ell_2": 36, "5000": [36, 37, 87, 93, 98, 104, 107, 141, 145, 149, 153, 155, 168, 169, 170, 171, 175, 177, 178, 179, 190, 196, 201, 203, 205, 208, 212, 214, 215, 216, 218, 219, 240, 243, 247, 254, 256, 257, 265, 266, 393], "n_clusters_per_class": [36, 38, 39, 45, 46, 49, 57, 69, 75, 78], "x_tmp": [36, 41, 49, 57], "y_tmp": [36, 41, 49, 57], "x_train_": [36, 37, 38, 39, 41, 46, 49, 51, 53, 56, 57, 65, 67, 69, 78, 92, 125, 132], "x_val_": [36, 37, 39, 41, 49, 51, 56, 57, 65, 67, 69, 78], "x_test_": [36, 38, 39, 41, 46, 49, 53, 57, 92], "predict_proba_logreg": [36, 37, 41, 49, 69, 75], "y_prob": [36, 38, 45, 56], "n_epoch": [36, 37, 45, 46, 52, 143], "eval_everi": [36, 140], "val_ap": 36, "grad_w": [36, 38, 39, 50, 51, 52, 56, 67, 87, 89, 91, 92, 94, 101, 102, 136], "grad_b": [36, 38, 39, 51, 52, 56, 67, 89, 91, 92, 94, 101, 102, 136], "val_scor": 36, "best_run": 36, "yaxis2": [36, 78, 91, 92, 93, 140, 153, 296], "side": [36, 67, 78, 86, 91, 92, 93, 99, 122, 140, 148, 152, 153, 155, 157, 158, 161, 162, 163, 166, 175, 177, 178, 179, 182, 185, 192, 194, 196, 197, 201, 207, 208, 210, 212, 214, 219, 223, 225, 226, 227, 230, 232, 233, 234, 236, 239, 240, 241, 245, 246, 247, 249, 255, 258, 260, 261, 262, 263, 265, 266, 267, 268, 269, 270, 296, 305, 382], "test_ap": 36, "l2_grid": [36, 65], "logspac": [36, 65, 84, 92, 93, 95, 98, 102, 107, 108, 131, 148, 153, 154, 155, 160, 165, 166, 168, 173, 175, 178, 182, 187, 203, 207, 215, 220, 232, 233, 291], "best_overal": 36, "_hist": 36, "best_val_ap": 36, "best_epoch": 36, "df_grid": 36, "log_x": [36, 84, 93, 97, 102, 154, 159, 187], "best_l2": [36, 65], "w_star": [36, 59], "b_star": 36, "test_ap_star": 36, "swing": [36, 107], "swap": [36, 57, 72, 73, 77, 81, 134, 139, 144, 165, 177, 234, 250, 255, 261, 263, 371], "silent": [36, 347], "sum_n": 36, "minor": [37, 49, 67], "tpr": [37, 39, 65], "tnr": [37, 39], "special": [37, 69, 86, 87, 88, 95, 98, 103, 104, 108, 112, 117, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 175, 178, 179, 180, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 205, 206, 207, 208, 209, 210, 214, 216, 217, 219, 220, 223, 224, 225, 226, 227, 228, 231, 232, 233, 234, 236, 237, 238, 239, 240, 265, 269, 303, 314, 342], "expit": [37, 103, 104, 237], "sk_balanced_accuracy_scor": 37, "ba": 37, "ber": [37, 223], "fnr": [37, 39], "fpr": [37, 39, 65], "_k": [37, 38, 104, 105, 118, 125, 152, 209, 228, 289, 319], "texttt": [37, 158, 161, 169, 177, 179, 180, 183, 198, 199, 201, 203, 205, 214, 219, 235, 238], "_score": 37, "offer": [37, 142, 161, 350, 379], "chanc": [37, 41, 68, 75, 228, 243, 249, 263, 265, 267], "adj": [37, 86], "toward": [37, 41, 45, 69, 70, 77, 84, 88, 92, 111, 113, 140, 141, 159, 164, 167, 170, 171, 174, 194, 198, 199, 203, 211, 214, 216, 225, 228, 232, 235, 262], "per_class_recall_np": 37, "zero_divis": [37, 49, 50, 53], "recall_k": 37, "cl": [37, 52, 74, 127, 131, 132, 153, 311, 312, 313, 314, 315, 316, 317], "balanced_accuracy_score_np": 37, "labels_us": [37, 41], "n_class": [37, 41, 52, 56, 77, 84, 105, 108], "confusion_matrix_np": [37, 57], "mainli": [37, 72, 73, 87, 97, 110, 193, 195, 262, 356, 385], "label_to_index": [37, 41, 57], "true_idx": [37, 41, 57, 77], "pred_idx": [37, 41, 57, 77], "_y_tru": 37, "_y_pr": 37, "990": [22, 37], "bal": 37, "bal_adj": 37, "cm_label": 37, "henc": [37, 105, 163, 176, 192, 194, 202, 207, 231, 234, 241], "p_neg": [37, 39], "p_po": [37, 39, 46, 108, 113], "proba": [37, 38, 41, 46, 103, 104, 105, 106, 108, 110], "discret": [37, 41, 53, 57, 69, 75, 77, 83, 84, 113, 118, 119, 134, 136, 140, 142, 143, 154, 162, 181, 185, 187, 217, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 248, 255, 256, 257, 259, 260, 265, 285, 286, 381], "unweight": [37, 41, 67, 87, 89, 93, 94, 95], "mild": [37, 116, 118, 268], "1200": [37, 46, 50, 65, 106, 158, 171, 172, 174, 178, 192, 204, 206, 207, 226, 261, 268], "log_loss_binari": [37, 56, 67], "per_sampl": [37, 51, 67, 93], "sw_sum": 37, "val_bal_acc": 37, "p_train": [37, 45, 46, 67], "y_val_hat": 37, "gd": [37, 41, 45, 57, 64, 67, 87, 88, 93, 95, 96, 97, 98, 100, 107], "w_unw": 37, "hist_unw": 37, "best_unw": 37, "n_train": [37, 50, 59, 64, 65, 103, 106, 119, 125], "w_po": [37, 67], "w_neg": [37, 67], "sw_bal": 37, "w_wt": 37, "hist_wt": 37, "best_wt": 37, "best_threshold_for_balanced_accuraci": 37, "p_unw": 37, "p_wt": 37, "best_t_unw": 37, "best_t_wt": 37, "ba_unw": 37, "ba_wt": 37, "ff7f0e": [37, 53, 64, 81, 101, 113, 125, 263, 327, 328, 329], "summarize_threshold": 37, "2x2": [37, 221, 232, 251], "grid_": 37, "fig1": [37, 51, 84, 104, 105, 106, 108, 110, 173, 214, 216, 248, 280], "fig2": [37, 51, 74, 84, 104, 105, 106, 108, 110, 136, 151, 168, 173, 202, 214, 216, 235, 248, 266, 267, 280], "1050": [37, 39, 45, 88, 149, 164, 175], "gridsearchcv": [37, 105], "cross_val_scor": [37, 91, 92], "balanced_accuraci": [37, 57], "class_weight": [37, 109], "clf_unw": 37, "clf_wt": 37, "pred_unw": 37, "pred_wt": 37, "natur": [37, 39, 41, 46, 47, 51, 52, 53, 56, 57, 65, 69, 72, 74, 77, 78, 84, 88, 89, 92, 97, 98, 102, 104, 113, 120, 125, 136, 149, 150, 153, 154, 158, 163, 169, 170, 172, 174, 176, 177, 178, 179, 180, 181, 183, 184, 189, 191, 192, 195, 198, 199, 201, 202, 203, 204, 205, 206, 207, 212, 213, 214, 215, 218, 219, 221, 222, 223, 225, 228, 232, 235, 237, 238, 239, 251, 253, 254, 255, 257, 280], "rather": [37, 49, 67, 87, 91, 100, 108, 114, 121, 145, 151, 158, 164, 182, 183, 185, 186, 209, 215, 228, 251, 259, 352, 383], "auroc": 37, "outcom": [38, 45, 57, 67, 88, 155, 168, 175, 183, 192, 199, 214, 215, 216, 219, 223, 225, 226, 230, 231, 233, 238, 241, 243, 249, 251, 256, 257, 259, 260, 261, 263, 267, 334], "calibrate_logit_scal": 38, "calibration_bin": 38, "n_bin": [38, 45, 286], "bin": [38, 89, 151, 167, 178, 213, 222, 226, 230, 235, 236, 239, 240, 246, 247, 286, 393], "bin_id": 38, "mean_pr": [38, 100, 209], "nan": [38, 39, 46, 64, 67, 73, 74, 86, 87, 88, 89, 100, 112, 113, 115, 134, 136, 139, 142, 143, 144, 146, 148, 150, 151, 152, 154, 157, 158, 160, 163, 166, 168, 172, 173, 174, 175, 176, 179, 180, 181, 182, 187, 191, 192, 195, 196, 197, 204, 205, 207, 209, 210, 214, 218, 219, 220, 221, 223, 224, 225, 226, 228, 234, 235, 236, 237, 238, 239, 240, 241, 246, 248, 251, 252, 254, 255, 257, 258, 259, 263, 264, 265, 268, 269, 270, 280, 299, 323, 328, 329], "frac_po": 38, "brier_decomposit": 38, "1973": [38, 248], "bs": [38, 45, 146, 164, 167], "y_bar": [38, 100, 183, 210], "unc": 38, "event": [4, 6, 38, 88, 95, 98, 108, 111, 114, 115, 122, 125, 129, 148, 152, 157, 162, 164, 168, 169, 171, 175, 188, 195, 196, 199, 200, 204, 207, 213, 215, 217, 223, 230, 231, 236, 237, 239, 245, 258, 261, 322, 332, 333, 341, 347, 348, 349, 352, 354, 355, 356, 358, 381, 385, 403, 410], "pos_label": [38, 39, 49, 50, 64], "e_": [38, 41, 117, 123], "rvert_2": [38, 74, 96, 101, 104, 186], "501": [38, 50, 53, 210, 264], "sim": [38, 69, 95, 96, 103, 104, 106, 108, 113, 114, 117, 119, 120, 122, 134, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 247, 249, 250, 252, 264, 266, 267, 322], "bernoulli": [38, 46, 56, 104, 224, 225, 231, 237, 238], "irreduc": 38, "uncertainti": [38, 46, 52, 87, 94, 103, 110, 111, 115, 119, 121, 125, 148, 152, 159, 172, 184, 189, 204, 212, 216, 217, 221, 225, 228, 261, 263, 266, 267, 269, 305], "miscalibr": [38, 46, 305], "50_000": [38, 41, 107, 139, 144, 148, 149, 151, 153, 154, 155, 158, 159, 160, 162, 165, 169, 172, 174, 180, 182, 183, 186, 187, 189, 190, 191, 193, 195, 196, 197, 198, 201, 203, 204, 211, 214, 215, 220, 224, 225, 226, 227, 228, 230, 233, 234, 236, 238, 239, 240, 246, 247, 250, 258, 268, 269, 270], "binomi": [38, 45, 46, 50, 53, 65, 67, 95, 153, 165, 169, 170, 207, 223, 228, 232, 233, 235, 236, 239, 240, 261], "empir": [38, 45, 67, 69, 73, 78, 86, 93, 94, 106, 125, 132, 148, 152, 153, 154, 155, 156, 158, 159, 160, 162, 163, 165, 166, 167, 168, 169, 170, 172, 173, 174, 175, 176, 177, 178, 180, 181, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 208, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 227, 229, 230, 231, 235, 237, 238, 240, 241, 242, 244, 245, 248, 249, 250, 251, 252, 254, 256, 267, 269], "analyt": [38, 93, 95, 149, 157, 161, 164, 171, 175, 188, 197, 211, 216, 217, 222, 237, 238, 240, 245, 246, 250, 259, 341, 348, 352, 353, 382], "min_p": 38, "bss": 38, "p_star": 38, "201": [38, 49, 53, 105, 205, 229], "overconfid": [38, 45, 46, 194], "underconfid": [38, 45], "underbrac": [38, 89, 111, 120, 121, 157, 170, 192, 197, 205, 254], "resolut": [38, 157, 263, 266, 270, 359], "p_k": [38, 57, 67, 110, 198, 213, 230, 241, 288, 322], "o_k": [38, 247], "frequenc": [38, 41, 78, 108, 111, 115, 136, 159, 163, 184, 197, 224, 230, 235, 240, 241, 247, 269, 275, 286, 295, 296, 353], "n_k": [38, 72, 77, 84, 244], "sum_k": [38, 46, 57, 72, 77, 84, 104, 225, 227, 228, 229, 238, 288], "reward": [38, 46, 47, 50, 56, 57, 78, 81, 100, 103, 134, 135, 136, 138, 139, 143, 144, 145, 146, 270], "10_000": [38, 109, 139, 144, 145, 152, 162, 167, 168, 170, 174, 181, 182, 184, 191, 193, 211, 217, 218, 223, 225, 226, 237, 239, 246, 256, 262, 263, 264, 291, 320, 324], "p_true": [38, 45, 46, 51, 67, 223, 226, 230, 237, 247], "p_calibr": 38, "p_overconf": 38, "p_underconf": 38, "diagram": [38, 45, 46, 137], "specifi": [38, 111, 112, 113, 122, 135, 137, 148, 160, 173, 179, 212, 219, 220, 222, 247, 251, 256, 297, 298, 375], "brier_score_loss_np": [38, 45], "isin": [38, 53, 86, 312, 313, 314, 315, 316, 317], "y01": [38, 52, 109], "cannot": [38, 84, 97, 105, 113, 127, 129, 139, 149, 151, 155, 168, 174, 201, 204, 208, 212, 214, 219, 233, 262, 271, 280, 359], "y_pm": 38, "penal": [38, 46, 52, 57, 59, 72, 78, 84, 87, 88, 91, 93, 96, 97, 101, 103, 104, 107, 112, 146, 184, 194, 210], "bound": [38, 52, 75, 84, 92, 103, 109, 119, 120, 124, 127, 131, 132, 135, 137, 138, 141, 144, 146, 149, 150, 151, 152, 153, 154, 156, 158, 159, 160, 171, 172, 176, 178, 179, 182, 184, 187, 191, 192, 193, 196, 197, 198, 202, 204, 205, 208, 209, 211, 212, 213, 214, 216, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 239, 240, 241, 258, 264, 349, 382], "unbound": [38, 46, 56, 78, 86, 150, 153, 238, 261], "punish": [38, 46, 49, 56, 93, 98, 280], "forgiv": [38, 51], "brier_y1": 38, "brier_y0": 38, "logloss_y1": 38, "logloss_y0": 38, "le": [38, 39, 52, 83, 86, 88, 89, 90, 93, 98, 99, 109, 110, 117, 123, 127, 129, 135, 139, 146, 148, 149, 150, 151, 152, 153, 154, 156, 157, 159, 160, 161, 162, 165, 166, 168, 169, 171, 173, 174, 176, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 206, 207, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 249, 250, 256, 263, 305, 322, 383, 386], "train_logreg_brier_gd": 38, "dl_dz": 38, "p_test": [38, 39, 46, 49, 57], "grid_x0": 38, "220": [38, 52, 53, 56, 67, 90, 91, 103, 104, 105, 106, 108, 109, 219, 232, 254, 262, 322], "grid_x1": 38, "portland": 38, "p_sklearn": 38, "nscikit": [38, 50], "weather": [38, 107, 108, 169], "extens": [38, 57, 111, 112, 139, 142, 199, 214, 256, 257, 333], "rare": [38, 47, 49, 53, 57, 59, 67, 74, 78, 86, 90, 99, 101, 108, 139, 141, 148, 160, 166, 175, 178, 179, 185, 187, 188, 190, 192, 196, 200, 215, 230, 233, 235, 236, 240, 241, 245, 246, 247, 251, 256, 257, 260, 261, 265, 269, 322, 382], "decept": [38, 51], "deliber": [38, 59, 98, 113, 116, 253], "glenn": 38, "1950": 38, "verif": [38, 78, 156, 257], "allan": 38, "partit": [4, 38, 69, 70, 78, 81, 211, 212, 232, 341, 348, 372, 382], "odd": [39, 99, 149, 155, 156, 158, 161, 167, 176, 181, 189, 194, 202, 206, 223, 239], "post": [12, 39, 89, 110, 148, 149, 151, 152, 154, 155, 157, 159, 160, 161, 164, 165, 167, 168, 170, 173, 174, 175, 176, 178, 179, 181, 184, 187, 193, 194, 196, 197, 198, 200, 202, 204, 208, 211, 212, 213, 215, 216, 218, 219, 221, 222, 227, 229, 232, 234, 238, 240, 241, 243, 253, 260, 270, 333, 363, 381, 386], "confirm": [39, 70, 122, 186, 231, 234, 248, 252, 265, 285, 300, 317, 381], "bay": [39, 106, 158, 211, 213, 218, 223, 224, 227, 230, 233], "iff": [39, 93, 95, 112, 154, 160, 166, 168, 172, 179, 182, 185, 187, 192, 196, 203, 204, 207, 210, 240], "cdot": [39, 47, 69, 75, 81, 92, 93, 98, 101, 114, 116, 117, 118, 119, 122, 123, 134, 135, 136, 139, 141, 143, 144, 146, 148, 150, 151, 152, 153, 154, 156, 158, 159, 161, 162, 163, 166, 167, 178, 179, 182, 184, 186, 187, 189, 190, 192, 193, 195, 200, 201, 202, 205, 206, 208, 209, 210, 213, 218, 220, 222, 223, 224, 225, 226, 227, 231, 232, 233, 234, 236, 238, 239, 240, 243, 244, 250, 261, 280, 303], "prior": [39, 46, 106, 108, 113, 115, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241], "begin": [39, 65, 72, 87, 91, 94, 103, 107, 114, 117, 118, 120, 139, 141, 145, 148, 149, 150, 157, 158, 161, 164, 165, 166, 172, 173, 176, 177, 179, 181, 182, 184, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 211, 212, 213, 214, 215, 216, 219, 222, 223, 225, 227, 229, 235, 237, 238, 241, 252], "cc": [39, 180, 260], "hline": 39, "dor": 39, "_infer_binary_label": 39, "negative_class": 39, "positive_class": 39, "neg_label": 39, "confusion_counts_binari": [39, 49, 50, 53, 57], "is_pos_tru": 39, "is_pos_pr": 39, "class_likelihood_ratios_numpi": 39, "raise_warn": 39, "pos_tot": 39, "neg_tot": 39, "lr_plu": 39, "lr_minu": 39, "cat": [39, 53, 73, 81, 136, 138, 140, 141, 144, 145, 146, 230], "bare": [39, 89, 99, 105], "evid": [39, 108, 211, 234, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 269, 270], "prob_from_odd": 39, "update_prob": 39, "p_pre": 39, "lr_plus_valu": 39, "lr_minus_valu": 39, "particular": [39, 161, 166, 170, 171, 178, 182, 183, 184, 185, 190, 202, 205, 209, 215, 221, 222, 234, 240, 241], "slope": [39, 92, 94, 95, 96, 98, 99, 107, 115, 127, 129, 160, 178, 183, 196, 212, 241, 289, 294, 318], "steep": [39, 92, 168, 181, 193, 195], "2200": 39, "x_train_val": 39, "y_train_val": 39, "std_": [39, 49], "ez": [39, 49, 57, 75, 181], "n_step": [39, 51, 56, 67, 69, 86, 87, 89, 90, 96, 97, 98, 99, 100, 107, 118, 134, 136, 140, 143, 144, 145, 150, 165, 178, 179, 188], "checkpoint": [39, 108], "p_hat": [39, 46, 67, 118, 223, 224, 226, 228, 230, 237], "histnorm": [39, 65, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 225, 228, 244, 246, 248, 250, 254, 258, 259, 261, 262, 264, 267, 269], "sweep_threshold": [39, 41], "y_proba": [39, 46], "arr": [39, 267], "pick_operating_point": 39, "min_sensit": 39, "min_specif": 39, "sen": 39, "fallback": [39, 52, 115, 143, 225, 267, 270, 299], "youden": 39, "youden_j": 39, "t_best": [39, 49, 67], "nanargmax": [39, 50], "best_label": [39, 70, 72, 73, 74, 81, 83, 84], "priorit": [39, 139, 409], "mask_screen": 39, "t_screen": 39, "nanargmin": 39, "IN": 39, "mask_confirm": 39, "t_confirm": 39, "_vline": 39, "line_width": [39, 49, 50, 56, 65, 87, 112, 115, 117, 123, 125, 127, 129, 151, 173, 174, 181, 184, 204, 211, 241, 242, 243, 245, 247, 253, 254, 255, 257, 258, 259, 260, 262, 263, 265, 268, 284, 289, 299, 318], "add_annot": [39, 56, 72, 74, 83, 96, 101, 135, 137, 230, 242, 250, 255, 260, 263, 265, 267, 268, 269], "xref": [39, 74, 135, 137, 255, 263, 269], "yref": [39, 74, 135, 137, 255, 263, 267, 269], "showarrow": [39, 56, 72, 74, 83, 96, 101, 135, 137, 230, 242, 250, 255, 260, 263, 265, 267, 268, 269], "x_pt": [39, 170], "y_pt": 39, "metrics_at_threshold": [39, 57], "lr_p": 39, "lr_m": 39, "m_best": [39, 41, 57], "m_screen": 39, "m_confirm": 39, "textfont": 39, "max_dor": 39, "9s": [39, 134, 136, 145], "therefor": [39, 49, 86, 88, 89, 93, 96, 97, 150, 155, 156, 158, 160, 162, 164, 166, 171, 173, 181, 183, 186, 192, 199, 201, 202, 204, 205, 207, 222, 225, 229, 230, 234, 255, 267], "strategi": [39, 45, 64, 121, 122, 141, 151, 226, 230, 245, 271, 281, 301, 304, 307, 310, 323, 328, 332, 345, 367, 378, 381, 401, 408], "confirmatori": 39, "y_pred_test": 39, "posterior": [39, 67, 103, 106, 113, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 172, 173, 174, 175, 176, 178, 179, 181, 182, 183, 184, 186, 187, 188, 189, 193, 194, 196, 197, 198, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 224, 226, 228, 229, 230, 231, 235, 236, 237, 238, 239, 240, 241], "npv": [39, 98, 396], "explan": [39, 136, 138, 139, 244], "wikipedia": [39, 45, 51, 53, 56, 65, 99, 100, 163, 165, 177, 201, 225, 234, 256], "en": [39, 45, 51, 53, 56, 65, 99, 100, 134, 138, 139, 140, 144, 145, 256, 285, 301, 382, 384, 385], "wiki": [39, 45, 51, 53, 56, 65, 99, 100, 256], "likelihood_ratios_in_diagnostic_test": 39, "todo": [40, 42, 43, 44, 48, 54, 55, 58, 60, 61, 62, 63, 66, 71, 76, 79, 80, 82], "beyond": [41, 114, 122, 157, 166, 170, 197, 212, 226, 230, 231, 236, 261], "p_o": 41, "p_e": 41, "adjust": [41, 50, 67, 68, 72, 75, 84, 87, 100, 113, 143, 146, 173, 216, 232, 242, 244, 247, 249, 251, 265, 266, 268], "950": [21, 41, 64, 69, 88, 108, 114, 149, 151, 155, 164, 171, 175, 176, 178, 181, 193, 196, 244, 245, 248], "proport": [41, 46, 77, 87, 92, 94, 95, 101, 131, 148, 150, 151, 153, 156, 159, 160, 167, 170, 176, 177, 182, 184, 191, 193, 197, 198, 202, 203, 205, 206, 227, 228, 229, 232, 235, 238, 240, 243, 247, 259, 260], "were": [41, 78, 141, 225, 228, 242, 245, 246, 247, 250, 256, 258, 260, 261, 263, 265, 266, 267, 270, 331, 338], "confusion_matrix_numpi": 41, "kappa_components_from_cm": 41, "kappa_weight_matrix": 41, "disagr": [41, 57, 81], "isinst": [41, 86, 87, 92, 96, 97, 99, 101, 110, 115, 120, 124, 127, 129, 134, 136, 138, 139, 142, 143, 144, 145, 169, 190, 197, 201, 208, 214, 226, 230, 231, 232, 233, 236, 237, 238, 241, 242, 263, 285, 312, 313, 314, 315, 316, 317], "quadrat": [41, 91, 97, 98, 103, 104, 109, 135, 144, 146, 176, 185, 189, 201, 203, 206, 212], "cohen_kappa_score_numpi": 41, "degener": [41, 69, 72, 81, 89, 131, 172, 176, 182, 211, 212, 217, 223, 224, 229, 231, 232, 233, 234, 235, 236, 237, 238, 239], "concentr": [41, 83, 90, 108, 142, 151, 153, 158, 159, 161, 164, 166, 167, 169, 174, 180, 181, 182, 183, 184, 190, 197, 198, 202, 205, 209, 211, 214, 216, 218, 221, 222, 224, 225, 227, 228, 229, 230, 232, 233, 234, 237, 241, 250, 256], "1_000": [41, 93, 138, 139, 144, 145, 186], "k_np": 41, "k_sk": 41, "k_np_lin": 41, "k_sk_lin": 41, "k_np_quad": 41, "k_sk_quad": 41, "plot_confusion_matrix": 41, "plot_true_vs_pred_margin": 41, "true_marg": 41, "pred_marg": 41, "flip_idx": [41, 69], "simulate_symmetric_nois": 41, "98": [41, 46, 93, 120, 124, 141, 146, 222, 255, 263, 269], "\u03c0": [41, 57, 144, 151, 155, 175, 222, 246], "predictor": [41, 45, 86, 88, 89, 91, 92, 93, 94, 96, 100, 104, 166, 261, 262, 319, 328], "o_": 41, "c_j": 41, "kappa_w": 41, "plot_weight_matrix": 41, "2_000": [41, 138, 141, 148, 150, 160, 165, 170, 184, 185, 186, 188, 189, 191, 195, 198, 200, 213, 220, 222, 223, 224, 225, 226, 229, 233, 234, 237, 238, 239, 241], "k_unw": 41, "k_lin": 41, "k_quad": 41, "w_lin": 41, "w_quad": 41, "log_loss_from_logit": 41, "fit_logistic_regression_gd": [41, 49, 56, 57, 67, 75, 78], "record_everi": [41, 53, 88], "mean0": [41, 108, 177], "mean1": [41, 108, 267], "multivariate_norm": [41, 64, 103, 106, 108, 113, 185, 221], "proba_v": 41, "eval_at_threshold": 41, "proba_test": 41, "m_default": 41, "cm_default": 41, "cm_best": 41, "unlik": [41, 49, 52, 57, 69, 90, 99, 101, 175, 178, 193, 200, 227, 229, 242, 247, 250, 253, 255, 256, 266, 271, 302, 370], "caveat": [41, 50, 72, 77, 78, 92, 119, 148, 151, 158, 160, 167, 173, 179, 180, 184, 186, 220, 256, 265], "paradox": 41, "hint": [41, 73, 92, 254, 255], "asymmetr": [41, 57, 64, 67, 87, 91, 93, 94, 99, 157, 159, 160, 195, 207, 208, 218, 264, 270], "1960": [41, 113, 190, 209, 259], "nomin": 41, "clinic": [41, 224, 251], "latex": [45, 134, 139, 142, 144, 145, 146, 158, 162, 183, 201, 203, 211, 224], "calibration_curv": 45, "r2_score": [45, 85, 86, 89, 107, 109, 127, 129, 131, 132], "Be": [45, 50, 105, 122, 154, 187, 270, 331, 338, 341, 344, 359], "proper": [45, 46, 49, 50, 56, 87, 89, 95, 100, 184, 221, 271, 378], "2_": [45, 46, 86, 87, 108, 166, 169, 178, 182, 185, 191, 192, 193, 196, 201, 209, 210, 221, 231, 244, 247, 249, 250, 252], "force_finit": [45, 100], "otherwis": [45, 73, 86, 87, 89, 98, 113, 114, 138, 139, 141, 148, 149, 156, 158, 160, 161, 164, 165, 166, 169, 170, 173, 190, 191, 197, 199, 203, 210, 212, 213, 214, 215, 216, 217, 220, 223, 226, 229, 235, 238, 240, 256, 366], "determin": [45, 77, 85, 98, 100, 103, 113, 136, 157, 160, 185, 192, 209, 211, 221, 230, 251, 308, 341], "d2_brier": 45, "ship": [45, 140, 200, 285, 346, 385], "p_ref": 45, "discuss": [45, 50, 87, 102, 105, 121, 153], "err2": 45, "d2_brier_score_np": 45, "y_ref": [45, 70], "bs_ref": 45, "plot_reliability_diagram": 45, "probas_by_nam": 45, "prob_tru": 45, "prob_pr": 45, "legend_titl": [45, 52, 89, 109, 118, 184, 186, 216, 235, 237, 250], "bs_np": 45, "bs_sklearn": 45, "d2_np": 45, "d2_r2": 45, "p_base": 45, "oracl": [45, 351], "6000": [45, 50, 108, 134, 138, 145, 199, 228, 258], "logit_tru": 45, "p_oracl": 45, "p_under": 45, "p_over": 45, "worst": [45, 59, 90, 99, 172, 200, 355], "poorli": [45, 65, 89, 103, 109, 113, 148, 199], "contrib": [45, 47, 78, 93, 122, 242, 246], "hover": 45, "hovertext": [45, 135, 137, 270], "3500": 45, "x_train_i": [45, 46, 57], "x_val_i": [45, 57], "fit_logistic_gd": 45, "brier_train": 45, "d2_train": 45, "brier_val": 45, "d2_val": [45, 46, 87, 88], "w_brier": 45, "hist_brier": 45, "w_log": [45, 53], "hist_log": [45, 53], "p_val_brier": 45, "p_val_log": 45, "p_val_bas": 45, "incentiv": 45, "feed": [45, 112, 135, 296, 308, 324, 405], "throw": [45, 141], "awai": [45, 46, 93, 103, 141, 151, 155, 161, 165, 166, 168, 173, 174, 175, 176, 181, 182, 190, 194, 205, 207, 212, 213, 242, 250, 252, 254, 266, 268], "denomin": [45, 46, 49, 53, 57, 69, 87, 88, 89, 92, 100, 107, 112, 166, 209, 210, 212, 229, 243, 250, 258, 269], "medicin": [45, 269], "discrimin": [45, 289, 292, 293], "alongsid": [45, 56, 77, 90, 99, 100, 153, 242, 270, 344], "badli": [45, 64, 174, 214, 267], "aggress": [45, 142, 155, 198, 233, 269], "temperatur": [45, 46, 172, 186, 227], "platt": [45, 46, 109], "isoton": [45, 46], "brier_scor": 45, "r\u00b2": [46, 91, 96, 246], "accur": [46, 110, 122, 163, 175, 188, 189, 200, 214, 236, 239, 244, 255, 269, 288, 291], "my": [46, 59, 88, 94, 99, 100, 195, 230, 240, 338, 339, 342, 345, 348, 350, 351, 352, 374], "harshli": 46, "sse": [0, 4, 46, 70, 73, 100, 119, 249, 352], "sst": [46, 100, 243], "bigl": [46, 49, 67, 86, 94, 104, 148, 149, 155, 157, 160, 164, 165, 168, 171, 172, 175, 177, 178, 181, 182, 183, 187, 191, 192, 197, 202, 207, 210, 211, 214, 215, 216, 220, 222, 229, 230, 232, 233, 295, 316], "bigr": [46, 49, 67, 86, 94, 104, 148, 149, 155, 157, 160, 164, 165, 168, 171, 172, 175, 177, 178, 181, 182, 183, 187, 191, 192, 197, 202, 207, 210, 211, 214, 215, 216, 220, 222, 229, 230, 232, 233, 295, 316], "logarithm": [46, 47, 84, 85, 148, 153, 175, 180, 182, 183, 184, 223], "nat": [46, 56, 69, 78, 135, 149, 156, 158, 159, 168, 172, 184, 189, 198, 201, 212, 223, 224, 229, 231, 233, 234, 236, 237, 238, 344, 350, 357, 358], "pi_k": [46, 106], "blow": [46, 74, 92, 98, 108, 138, 165, 169, 185, 202, 207, 219, 220, 229, 235, 242, 381], "equiv": [46, 92, 157, 166, 185, 193, 198, 231], "log_loss_numpi": 46, "d2_log_loss_score_numpi": 46, "_as_float_arrai": [46, 208], "_check_sample_weight": [46, 89], "_infer_class": 46, "pleas": [46, 238], "provid": [3, 8, 46, 67, 86, 88, 97, 98, 99, 102, 103, 104, 105, 110, 123, 125, 128, 129, 135, 137, 143, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 202, 205, 206, 207, 208, 209, 210, 211, 212, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 244, 246, 247, 252, 257, 262, 310, 314, 316, 322, 323, 327, 328, 333, 334, 335, 338, 344, 345, 347, 350, 351, 353, 356, 358, 359, 367, 373, 377, 378, 381], "argument": [46, 73, 88, 91, 127, 131, 132, 135, 136, 137, 144, 146, 151, 158, 182, 183, 192, 209, 220, 222, 233, 348], "_label_to_index": 46, "label_to_idx": 46, "y_idx": [46, 77], "keyerror": [46, 249], "finfo": [46, 69, 92, 161, 164, 165, 168, 182, 188, 198, 200, 222, 240, 252], "row_sum": [46, 69, 73, 78, 159, 228, 230, 246], "sure": [46, 47, 73, 113, 135, 137, 205, 206, 211, 230, 239, 247, 383], "per_sample_loss": 46, "loss_sum": 46, "runtimewarn": [31, 46, 57, 89, 98, 158, 160, 174, 206, 235, 240], "minlength": [46, 74, 78, 106, 108, 110, 224, 226, 227, 230, 231, 232, 233, 234, 235, 236, 237, 239, 241], "y_proba_nul": 46, "tile": [46, 86, 87, 268, 280, 296], "y_true_bin": 46, "y_true_mc": [46, 49, 51, 52, 53, 56, 57], "catastroph": [46, 99, 162, 163, 196, 226, 237], "loss_y1": [46, 56], "loss_y0": [46, 56], "Its": [46, 69, 148, 149, 150, 151, 161, 173, 178, 184, 188, 189, 195, 199, 216, 220], "determinist": [46, 59, 65, 116, 122, 136, 141, 143, 145, 167, 205, 211, 232, 235, 333, 334], "logloss_v": 46, "qi": [46, 59], "430": [46, 64, 69, 192, 200, 229, 231, 245], "rescal": [46, 100, 149, 150, 153, 156, 158, 164, 165, 168, 174, 181, 183, 184, 186, 190, 197, 199, 217, 247, 255], "eta_i": [46, 88, 93, 95, 98, 223], "nabla": [46, 96, 116, 119, 323], "x_test_i": [46, 57], "train_log_loss": [46, 67], "train_d2": 46, "w_hat": [46, 116], "lbfg": [46, 104, 120, 122, 124], "p_test_sklearn": 46, "fold": 46, "churn": [46, 49, 171], "audienc": 46, "familiar": [46, 81, 98, 139, 150, 157, 158, 159, 175, 181, 191, 194, 195, 205, 209, 213, 216, 218, 228, 229, 234, 235, 238, 240, 270, 332, 334, 342, 346, 348, 350, 352, 353], "hurt": [46, 72], "bad": [46, 47, 70, 74, 83, 84, 88, 99, 100, 103, 113, 184, 258, 367], "didn": [46, 242, 243], "beat": [46, 99, 152, 168, 271, 280, 304, 307, 385], "put": [47, 69, 70, 72, 91, 122, 148, 170, 176, 177, 180, 181, 184, 191, 192, 215, 219, 224, 229, 231, 233, 239, 242, 253, 256, 338, 339, 341, 347, 352, 374, 381, 389], "sk_dcg_score": 47, "sk_ndcg_score": 47, "s_": [47, 59, 81, 116, 134, 136, 143, 192, 195, 228, 300], "pi_1": 47, "pi_2": 47, "pi_m": 47, "d_r": 47, "log_b": [47, 159, 184, 204, 214, 225], "log_bas": 47, "d_1": [47, 88, 98, 166, 191, 268, 270, 389], "cutoff": [47, 59, 112, 114, 157, 160, 184, 196, 197, 215, 216, 225, 227, 241, 312], "pi_r": 47, "late": [47, 154, 187], "exponenti": [47, 59, 87, 88, 91, 98, 120, 124, 134, 135, 146, 151, 153, 158, 160, 161, 168, 169, 170, 173, 175, 179, 180, 181, 182, 183, 184, 188, 193, 198, 199, 201, 205, 211, 215, 216, 219, 220, 224, 227, 229, 232, 234, 235, 236, 239, 242, 245, 254, 256, 257, 260, 261, 264, 265, 267], "occupi": 47, "d_t": [47, 134, 136, 300], "uniformli": [47, 74, 86, 105, 139, 141, 158, 184, 186, 202, 206, 217, 234, 238, 240], "ignore_ti": [47, 59], "idcg": 47, "ideal": [47, 49, 52, 59, 89, 93, 96, 112, 119, 152, 186, 204, 255, 263, 266, 319, 331, 332, 333, 335], "doc_id": [47, 59], "doc_": 47, "y_true_1q": 47, "y_score_good": 47, "y_score_bad": 47, "dcg_rank_contribut": 47, "y_true_1d": [47, 51, 96], "y_score_1d": 47, "cum_dcg": 47, "plot_dcg_breakdown": 47, "breakdown": [47, 99, 382], "secondary_i": [47, 51, 56, 67, 69, 73, 122, 135, 137], "customdata": [47, 81, 90, 251], "cumulative_dcg_curv": 47, "dcg_good": 47, "dcg_bad": 47, "dcg_ideal": 47, "ks": [47, 70, 72, 73, 83, 105, 148, 149, 150, 151, 152, 154, 156, 158, 160, 161, 162, 163, 164, 165, 167, 168, 169, 171, 173, 174, 179, 180, 184, 186, 187, 188, 193, 195, 198, 203, 206, 209, 211, 212, 213, 215, 217, 218, 219, 220, 224, 225, 226, 227, 231, 234, 235, 236, 237, 239, 241, 247, 258, 263], "dcg_good_k": 47, "dcg_bad_k": 47, "idcg_k": [47, 59], "ndcg_good_k": 47, "ndcg_bad_k": 47, "_as_2d": [47, 87, 94, 99, 101, 102, 103, 189], "_discount_vector": 47, "ranks0": 47, "_tie_averaged_dcg_1d": 47, "discount_cumsum": 47, "_rank": 47, "_tie_averaged_dcg": 47, "inv": [47, 74, 81, 83, 84, 106, 136, 166, 176, 183, 189, 221], "return_invers": [47, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 105, 106, 108, 110], "return_count": [47, 110, 253, 260, 270], "mean_gain_per_group": 47, "groups_end": 47, "discount_sum": 47, "_dcg_sample_scores_numpi": 47, "ranked_tru": 47, "dcg_score_numpi": 47, "return_per_sampl": 47, "ndcg_score_numpi": 47, "yt": [47, 49, 70, 90, 117, 123], "sk": [47, 49, 59, 89, 91, 95, 97, 98, 101, 102, 104, 106, 110], "np_": 47, "12f": [47, 207, 223, 225, 229, 235], "round": [47, 51, 59, 69, 70, 72, 75, 105, 110, 112, 150, 151, 158, 159, 161, 164, 174, 176, 190, 206, 212, 221, 224, 227, 228, 229, 230, 237, 238, 240, 242, 243, 244, 247, 248, 253, 257, 259, 260, 265, 267, 270, 280, 288], "ys_ti": 47, "ntie": 47, "true_relev": 47, "nti": [47, 257], "pointwis": [47, 91, 317], "listwis": [47, 59], "ascent": [47, 50], "make_synthetic_ranking_data": 47, "n_queri": [47, 59, 105, 125], "n_doc": [47, 59, 108, 228], "w_true": [47, 51, 65, 89, 93], "grade": [47, 59, 99, 107, 116, 200, 267, 269, 344], "quantil": [47, 59, 64, 69, 85, 86, 91, 96, 99, 101, 115, 117, 119, 123, 125, 151, 152, 153, 158, 162, 163, 164, 166, 167, 169, 171, 172, 173, 175, 177, 180, 183, 184, 186, 189, 190, 191, 194, 195, 196, 197, 200, 203, 205, 207, 208, 209, 216, 225, 236, 242, 244, 245, 247, 248, 249, 250, 252, 254, 255, 256, 262, 265, 266, 267, 268, 269, 286, 318, 328], "q50": [47, 59, 119, 125, 197], "q75": [47, 59, 155, 168, 175, 252], "q90": [47, 59, 197], "mean_ndcg_at_k": 47, "coordinate_ascent_ndcg": 47, "n_pass": 47, "step_decai": 47, "init_scal": 47, "w0": [47, 52, 59, 75, 78, 89, 100, 221], "train_ndcg": [47, 59], "val_ndcg": [47, 59], "best_val": 47, "best_w": [47, 65], "base_train": 47, "best_loc": 47, "best_delta": 47, "w_try": 47, "w_best": [47, 69], "yq": [47, 87, 105], "s0": [47, 168, 177, 181, 187, 195, 199, 203, 221, 266], "comp0": 47, "comp1": 47, "shared_yax": [47, 70, 117, 118, 123, 295, 308, 316], "ux": [47, 331], "scroll": [47, 59], "unrel": [47, 69, 87], "meaningless": [47, 155, 204, 222], "yourself": [47, 87, 222, 225, 228, 230, 269, 350, 351], "modifi": [47, 69, 72, 77, 91, 97, 98, 113, 150, 151, 193, 195, 202, 203, 205, 206, 210, 239, 244, 255, 256, 258, 259], "accept": [47, 52, 99, 112, 125, 127, 129, 131, 132, 146, 148, 151, 152, 158, 165, 166, 169, 170, 180, 188, 190, 193, 197, 202, 238, 239, 244, 248, 296], "gain_fn": 47, "u00e4rvelin": 47, "kek": 47, "u00e4l": 47, "u00e4inen": 47, "2002": [47, 59], "ir": [47, 59], "sk_f1_score": 49, "sk_precision_scor": 49, "sk_recall_scor": 49, "harmon": [49, 50, 72, 77, 84, 124, 222, 235, 241], "f_1": [49, 53, 127], "substitut": [49, 151, 154, 161, 164, 165, 168, 169, 177, 181, 183, 186, 187, 199, 200, 201, 202, 203, 204, 216, 218, 219, 220, 235], "definit": [49, 52, 53, 59, 75, 77, 78, 87, 107, 113, 118, 146, 228, 250, 252, 259, 269, 331, 333, 343, 346, 350, 351, 356, 359], "vice": [49, 87, 185, 207, 270], "versa": [49, 87, 185, 207, 270], "abund": 49, "f_": [49, 50, 103, 136, 140, 189, 191, 192, 193, 197, 201, 205, 206, 209, 210, 221, 242, 250], "arithmet": [49, 69, 84, 204], "ps": [49, 78, 112, 116, 122, 138, 192, 195, 214, 224, 228, 237, 252, 358, 359], "r_fix": 49, "am": [49, 69, 91, 92, 212], "precision_grid": 49, "recall_grid": 49, "den": [49, 53, 75, 86, 159, 166, 170, 182, 191, 199, 200, 211, 212, 215, 216, 227, 234, 248, 250, 251, 254, 262], "coloraxis_colorbar": [49, 57, 255], "safe": [1, 4, 49, 64, 70, 92, 163, 172, 181, 196, 210, 219, 228, 331, 334, 335, 367], "_as_1d": 49, "_safe_divid": [49, 53], "broadcast": [49, 81, 96, 191, 209, 234, 354], "yp": [49, 70, 90, 102, 104], "precision_recall_f1_from_count": 49, "f1_score_binari": 49, "f1_score_multiclass": 49, "lab": [49, 53, 70, 78, 83], "per_class_f1": 49, "y_pred_mc": [49, 51, 53, 57], "8s": [49, 134, 136, 145], "log_loss_from_proba": [49, 75], "w_new": [49, 75], "loss_hist": [49, 65, 87], "precision_recall_f1_at_threshold": 49, "y_true_po": [49, 50, 98], "pred_po": [49, 50, 57, 64], "prec_t": 49, "rec_t": 49, "f1_t": 49, "tp_t": 49, "fp_t": 49, "fn_t": 49, "confusion_matrix_from_threshold": 49, "mat": [49, 221], "mat_05": 49, "counts_05": 49, "mat_best": 49, "counts_best": 49, "f_level": 49, "p_line": 49, "boundary_lin": [49, 52], "z_thr": 49, "x2_05": [49, 75], "x2_best": [49, 75, 78], "report_binari": 49, "rep_05": 49, "rep_best": 49, "w_a": 49, "p_val_a": 49, "f1_a": 49, "best_idx_a": 49, "f1_val_best": 49, "alpha_v": 49, "f1_val": 49, "per_class": 49, "dice": [49, 53], "polici": [11, 49, 50, 67, 98, 118, 122, 123, 136, 139, 141, 144, 215, 236, 331, 334, 339, 340, 343, 347, 352, 353, 372, 373, 379, 382, 383, 400], "overal": [49, 50, 90, 103, 107, 110, 156, 166, 173, 187, 189, 200, 221, 233, 243, 246, 252, 257, 258], "magic": 49, "disappear": [49, 170, 190, 211, 233], "ranker": 49, "prefer": [49, 51, 52, 64, 67, 70, 78, 81, 84, 107, 109, 113, 118, 122, 143, 148, 150, 153, 154, 155, 158, 160, 161, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 199, 200, 201, 204, 205, 208, 210, 213, 215, 216, 217, 218, 219, 221, 222, 224, 226, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 242, 244, 245, 255, 256, 261, 264, 265, 266, 267, 271, 310, 322, 332, 333, 334, 335, 338, 340, 341, 342, 343, 344, 346, 348, 349, 350, 352, 357, 358, 359, 371, 375, 376, 381, 384, 385], "\u03b2": [50, 152, 160, 161, 167, 169, 195], "1": [7, 50, 52, 84, 95, 111, 115, 120, 124, 127, 129, 131, 132, 141, 228, 244, 269, 275, 281, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 334, 335, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 359, 366, 367, 370, 374, 375, 378, 381, 383, 389, 393, 394], "librari": [50, 52, 59, 102, 115, 134, 138, 140, 141, 142, 143, 145, 153, 159, 166, 167, 169, 190, 192, 209, 217, 224, 231, 233, 240, 249, 252, 255, 256, 260, 261, 262, 266, 269, 270, 325, 333, 334, 344, 345, 346, 359, 386], "safe_divid": 50, "fill_valu": [50, 160, 167, 168, 179, 184, 216, 225, 228, 240], "y_pred_po": [50, 98], "precision_recall_fbeta_from_count": 50, "fbeta": 50, "precision_recall_fbeta": 50, "fbeta_score_numpi": 50, "trade": [0, 10, 50, 52, 53, 65, 74, 90, 111, 112, 118, 134, 136, 144, 160, 173, 288, 308, 330, 387, 397, 404], "favor": [50, 53, 72, 74, 83, 151, 206, 230, 232, 233], "upweight": 50, "skl_fbeta_scor": 50, "repr": [50, 65, 135, 137, 243, 246, 264, 267], "sinc": [50, 72, 78, 93, 95, 111, 139, 148, 149, 151, 154, 156, 158, 159, 163, 168, 173, 177, 179, 182, 183, 184, 187, 192, 193, 194, 195, 196, 197, 200, 205, 206, 208, 209, 214, 215, 218, 219, 221, 222, 225, 234, 236, 239, 240], "f2": [50, 225, 228], "pr_fbeta_curv": 50, "301": [35, 50, 64, 155], "y_po": [50, 88, 98, 120, 124, 190, 204, 265], "best_threshold_for_fbeta": 50, "fbeta_curv": 50, "820": 50, "best_05": 50, "best_1": 50, "best_2": 50, "700": [50, 52, 53, 87, 98, 104, 105, 108, 112, 123, 127, 129, 134, 158, 160, 163, 164, 169, 173, 176, 180, 181, 183, 190, 191, 193, 195, 196, 197, 200, 203, 206, 208, 212, 219, 238, 250, 256, 259], "legend_orient": 50, "beta_iso": 50, "find_bias_for_target_r": 50, "target_r": 50, "make_synthetic_logistic_data": 50, "target_pos_r": 50, "true_w": [50, 101], "base_logit": 50, "true_b": [50, 101, 212, 216, 217], "train_val_test_split": 50, "n_val": [50, 193, 234], "log_loss_and_grad": 50, "fit_logistic_regression_c": 50, "1500": [50, 77, 104, 105, 140, 154, 157, 161, 168, 174, 176, 178, 179, 184, 187, 188, 192, 202, 207, 208, 235, 240, 252], "hist_c": [50, 64], "evaluate_threshold": 50, "val_scores_c": 50, "test_scores_c": 50, "test_ev": 50, "best_val_threshold": 50, "val_fbeta": 50, "test_precis": 50, "test_recal": 50, "test_fbeta": 50, "widetild": 50, "plug": [50, 57, 78, 109, 139, 150, 154, 158, 171, 173, 174, 179, 187, 190, 196, 197, 210, 220, 233, 234, 246], "soft_fbeta_and_grad": 50, "soft_fbeta": 50, "sp": [50, 73, 209, 248, 298, 302, 307, 309, 323], "dp_i": 50, "df_dp": 50, "df_dz": 50, "fit_logistic_regression_soft_fbeta": 50, "beta_opt": 50, "w_soft": 50, "hist_soft": 50, "val_scores_soft": 50, "test_scores_soft": 50, "best_c": 50, "best_soft": 50, "test_c": 50, "test_soft": 50, "val_best_threshold": 50, "safeti": [50, 52, 77, 90, 107, 109, 143, 331, 334, 335], "abus": 50, "rijsbergen": 50, "sk_hamming_loss": 51, "hl": 51, "1s": [51, 81, 134, 136, 138, 141, 144, 145], "nl": 51, "hl_manual": 51, "hl_sklearn": 51, "subset_acc": 51, "x_label": [51, 246], "label_": 51, "y_label": [51, 246], "sample_": 51, "green": [51, 53, 91, 92, 108, 148, 177, 193, 220, 247, 251, 262, 270, 331, 336], "ffffff": [51, 53, 75, 81], "per_label": 51, "hl_int": 51, "y_true_oh": 51, "y_pred_oh": 51, "hl_onehot": 51, "straightforward": [51, 83, 113, 148, 154, 155, 157, 158, 159, 160, 165, 166, 168, 171, 185, 186, 187, 192, 195, 197, 198, 199, 207, 209, 211, 215, 216, 219, 225, 227, 233, 237, 241, 255], "hamming_loss_np": 51, "y_pred_1d": [51, 96], "y_true_2d": [51, 86, 91, 96, 97, 99, 100, 101, 102], "y_pred_2d": [51, 86, 91, 96, 97, 99, 100, 101, 102], "hl_np_w": 51, "hl_sk_w": 51, "z_": [51, 56, 193, 194, 230, 248, 252, 259, 261], "log1p": [51, 64, 97, 98, 102, 151, 152, 153, 155, 156, 160, 162, 164, 165, 166, 168, 170, 171, 174, 176, 181, 191, 196, 201, 202, 206, 210, 213, 214, 215, 216, 220, 222, 223, 226, 231, 235, 236, 237, 240, 242, 250, 263], "bce_from_logit": 51, "standardize_fit_transform": [51, 56, 67], "fit_multilabel_logreg_gd": 51, "train_bc": 51, "train_hl": 51, "val_bc": 51, "val_hl": 51, "dj": [51, 96], "z_val": [51, 67, 73], "1600": [51, 78], "rarer": [51, 164, 229, 234, 241], "b_true": [51, 65, 89, 164, 176, 195, 205, 213, 215, 224, 225], "z_true": [51, 97], "bce": [51, 140], "480": [51, 69], "91": [34, 51, 65, 103, 110, 204], "hl_val": 51, "y_hat_val": 51, "t05_idx": 51, "hl_at_05": 51, "hl_best": 51, "per_label_threshold": 51, "pred_j": 51, "y_hat_per_label": 51, "hl_per_label": 51, "alon": [51, 72, 77, 83, 91, 233], "complement": [51, 226], "tag": [51, 53, 295, 311, 312, 313, 314, 315, 316, 317, 322, 331, 332, 334, 335, 338, 342, 358, 371], "attribut": [2, 51, 213, 335, 341, 354, 355, 389], "hamming_dist": 51, "soft": [52, 67, 107, 137, 138, 139, 141, 176], "svm": [52, 106, 132], "notat": [52, 73, 86, 87, 88, 92, 99, 100, 113, 116, 122, 139, 165, 188, 191, 193, 203, 205, 219, 221, 223, 233, 234, 235, 237, 240], "subgradi": [52, 86, 92], "primal": 52, "skl_hinge_loss": 52, "linearsvc": [52, 109], "quantiti": [52, 73, 93, 95, 104, 113, 148, 151, 152, 154, 156, 159, 160, 164, 165, 166, 168, 169, 173, 174, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 193, 195, 196, 197, 200, 201, 202, 203, 206, 207, 208, 211, 213, 214, 217, 218, 219, 221, 223, 228, 233, 235, 243, 254, 258, 339], "correctli": [52, 53, 122, 211, 247, 254, 269, 331], "upper": [52, 70, 81, 94, 99, 103, 109, 116, 120, 124, 135, 146, 151, 152, 157, 160, 171, 172, 173, 174, 178, 179, 184, 196, 197, 199, 200, 206, 212, 213, 214, 215, 216, 217, 219, 227, 230, 236, 237, 238, 244, 246, 247, 248, 252, 253, 255, 258, 261, 305], "loss_01": 52, "loss_hing": 52, "loss_sq_hing": 52, "\ud835\udfd9": 52, "call": [52, 75, 90, 98, 104, 107, 108, 112, 115, 119, 120, 124, 127, 131, 132, 135, 136, 137, 143, 148, 153, 154, 158, 167, 173, 177, 179, 184, 186, 187, 190, 192, 198, 201, 205, 207, 209, 213, 214, 216, 217, 218, 219, 220, 222, 229, 230, 232, 234, 236, 249, 250, 256, 259, 260, 261, 268, 271, 275, 281, 290, 291, 293, 294, 295, 297, 298, 302, 304, 307, 309, 310, 319, 320, 321, 323, 324, 325, 326, 332, 333, 334, 335, 340, 342, 343, 346, 349, 350, 351, 352, 353, 354, 356, 357, 358, 363, 383, 389], "m_sampl": 52, "loss_sampl": 52, "crammer": 52, "singer": 52, "s_k": [52, 115, 127, 129, 289], "s_y": [52, 81, 166, 267], "compet": [52, 183, 199, 204], "formul": [52, 120, 253], "pred_decis": 52, "_as_1d_float": [52, 267], "binary_hinge_loss": 52, "mean_i": [52, 120, 124, 218, 236], "score_i": 52, "multiclass_hinge_loss": 52, "s_ij": 52, "true_scor": 52, "s_other": 52, "max_oth": 52, "y_true_01": 52, "skl": [52, 69], "scores_mc": 52, "skl_mc": 52, "ours_mc": 52, "tfrac12": [52, 87, 106, 146, 149, 150, 158, 161, 167, 174, 179, 182, 185, 188, 190, 194, 195, 202, 206, 210, 214, 218, 230, 260], "m_i": [52, 103, 159, 237], "violat": [52, 108, 109, 123, 172, 178, 206, 209, 215, 226, 242, 243, 250, 252, 257], "nabla_b": [52, 94], "linearsvmhistori": 52, "mean_hing": 52, "linear_svm_object": 52, "obj": [52, 90, 135, 137, 151, 228, 352], "linear_svm_subgrad": 52, "viol": 52, "train_linear_svm_subgradient_desc": 52, "cluster_std": [52, 56, 67, 69, 74, 75, 77, 81, 84, 104, 106, 108, 109], "y_pm1": 52, "band": [52, 69, 87, 90, 94, 113, 116, 119, 125, 146, 184, 217, 331, 335], "highlight": [52, 67, 100, 105, 142, 148, 158, 256, 258, 268, 270], "role": [2, 52, 72, 137, 140, 148, 173, 177, 191, 209, 210, 338, 342, 343, 344, 346, 348, 349, 350, 352, 353, 356], "narrow": [52, 109, 138, 151, 214, 258, 285, 384], "cs": [52, 109, 182, 199, 200, 202, 222], "w_c": 52, "b_c": 52, "dual": 52, "dec": 52, "pro": 52, "con": [52, 109], "awar": [52, 59, 87, 88, 122, 127, 129, 256, 283, 295, 299, 303, 305, 308], "bag": [52, 108, 228, 230, 247, 286], "word": [52, 92, 103, 108, 109, 114, 209, 228, 230, 231, 240, 241, 286], "tf": [52, 138, 143], "idf": 52, "uncalibr": 52, "territori": 52, "smoother": [52, 103, 110, 113, 136, 138, 141, 146, 204, 212, 329], "l1": [52, 92, 110, 122, 139, 158, 176], "sparsiti": [52, 87, 88, 107, 158, 176, 229], "vapnik": [52, 109], "cort": [52, 109], "1995": [52, 109, 166], "cap": [53, 69, 70, 142, 161, 174, 215, 219, 225, 406], "cup": 53, "displaystyl": [53, 188, 211], "__import__": [53, 110, 144, 170, 195, 259], "agre": [53, 70, 99, 143, 155, 196, 207, 225, 230, 232, 255], "bloat": 53, "univers": [53, 94, 99, 172], "a_mask": 53, "b_mask": 53, "00": [36, 53, 75, 88, 93, 94, 98, 99, 100, 110, 117, 118, 123, 136, 140, 141, 142, 172, 186, 228, 235, 237, 247, 249, 251, 253, 267, 341, 366], "249999": 53, "499999": 53, "749999": 53, "newaxi": 53, "ton": 53, "logical_and": 53, "jaccard_score_binari": 53, "accuracy_score_binari": 53, "mgrid": 53, "circle_mask": 53, "true_mask": 53, "pred_mask": 53, "goe": [53, 56, 72, 77, 149, 174, 187, 198, 202, 206, 219, 265], "y_true_cor": 53, "y_pred_cor": 53, "tn_size": 53, "2001": [53, 67, 176, 206, 207, 269], "jacc": 53, "y_true_ful": 53, "y_pred_ful": 53, "fp_val": 53, "fn_val": 53, "2tp": 53, "ingredi": [53, 205, 268], "longleftrightarrow": [53, 89, 149, 150, 158, 169, 175, 180, 182, 186, 187, 198, 202, 203, 205, 209, 217, 221, 232, 233, 240], "2j": [53, 178, 193], "j_from_f1": 53, "mutual": [53, 68, 72, 73, 77, 79, 230, 246, 247], "exclus": [53, 230, 238, 246, 247], "jaccard_score_multilabel": 53, "uni": 53, "logical_or": [53, 134], "inter_l": 53, "uni_l": 53, "label_scor": 53, "inter_": 53, "uni_": 53, "sample_scor": 53, "jaccard_score_multiclass": 53, "multiclass_macro": 53, "multiclass_micro": 53, "multiclass_per_class": 53, "sk_jaccard_scor": 53, "y_true_thr": 53, "p_thr": 53, "j_score": 53, "best_j": [53, 67], "j_": [53, 202], "varepsilon": [53, 56, 73, 77, 90, 91, 92, 93, 97, 101, 103, 105, 112, 117, 123, 125, 132, 166, 168, 181, 183, 189, 198, 219, 220, 222, 229, 257], "n_test": 53, "xb_train": [53, 65], "xb_test": 53, "soft_jaccard_loss": 53, "soft_jaccard_grad_p": 53, "iep": 53, "uep": 53, "djdp": 53, "soft_jaccard": 53, "dldp": 53, "dldz": 53, "best_threshold_for_jaccard": 53, "w_iou": 53, "hist_iou": 53, "p_test_log": 53, "p_test_iou": 53, "j05_log": 53, "j05_iou": 53, "best_t_log": 53, "best_j_log": 53, "curve_log": 53, "best_t_iou": 53, "best_j_iou": 53, "curve_i": 53, "overwhelm": [53, 386], "frequent": [53, 73, 111, 122, 139, 151, 160, 162, 187, 207, 240, 241, 335], "impli": [53, 97, 111, 121, 122, 148, 160, 161, 163, 164, 166, 174, 178, 180, 189, 191, 196, 197, 202, 204, 207, 218, 219, 234, 241, 255, 261, 264, 328, 389], "jaccard_index": 53, "sk_log_loss": 56, "ik": [56, 163, 185, 221, 222, 393], "prod_": [56, 108, 148, 150, 152, 159, 161, 162, 163, 165, 173, 176, 181, 183, 184, 188, 191, 192, 194, 195, 196, 198, 199, 202, 206, 209, 211, 215, 217, 220, 221, 223, 225, 228, 230, 234, 236, 237, 238, 239], "logsumexp": [56, 108, 154, 160, 187, 216, 218, 228, 234, 238], "a_max": [56, 227, 251, 261], "squeez": [56, 134, 136, 138, 139, 140, 142, 143, 144, 146, 169, 180, 190, 264], "log_softmax": [56, 134], "_weighted_mean": [56, 89], "log_loss_multiclass": 56, "log_loss_binary_from_logit": 56, "log_loss_multiclass_from_logit": 56, "true_class": 56, "log_prob": [56, 108, 134, 136, 140, 142, 143, 144, 146, 230], "expected_loss": 56, "arrowhead": [56, 74, 135, 137, 242, 250, 263, 267], "ay": [56, 74, 135, 137, 140, 186, 250, 263, 267], "p_good": 56, "p_one_confident_mistak": 56, "losses_good": 56, "losses_bad": 56, "p_baselin": 56, "probability_assigned_to_the_true_class": 56, "logits_v": 56, "xx0": [56, 67], "xx1": [56, 67], "prob_grid": [56, 67], "net": [56, 96, 136, 138, 139, 140, 141, 144, 145, 146, 223, 229, 239, 285, 339, 349], "mislabel": [56, 83], "triag": [56, 65, 332], "nll": [56, 104, 153, 155, 159, 163, 165, 168, 174, 175, 177, 181, 212, 213, 214, 216, 222, 224, 226, 232, 233, 239, 241], "scoring_rul": 56, "systemat": [57, 89, 101, 116, 219, 250, 252, 253, 254, 257, 263, 268, 270, 394], "invers": [57, 88, 97, 98, 102, 107, 113, 114, 118, 125, 135, 136, 148, 149, 152, 153, 157, 166, 172, 179, 183, 185, 189, 205, 209, 210, 211, 214, 215, 216, 221, 223, 234, 240, 241, 245, 252, 254, 255, 266, 267], "sk_matthews_corrcoef": 57, "mathemat": [57, 108, 150, 154, 158, 169, 173, 209, 210, 219, 223, 225, 235, 244, 262], "conting": [57, 68, 72, 232, 247, 251], "And": [57, 103, 162, 183, 197, 207, 211, 238, 241, 255, 260], "kk": [57, 59, 225, 240], "t_k": 57, "builder": [57, 73, 77, 268, 326], "fromit": 57, "mcc_from_count": 57, "matthews_corrcoef_np": 57, "t_sum": 57, "p_sum": 57, "positive_label": 57, "true_po": 57, "kxk": 57, "mcc_mc": 57, "cm_mc": 57, "labels_mc": 57, "plot_mcc_surfac": 57, "grid_step": [57, 104, 105, 106, 108, 110], "101": [57, 86, 89, 99, 146, 242, 247, 258], "cancel": [57, 72, 77, 84, 91, 106, 117, 123, 162, 163, 165, 172, 183, 187, 211, 212, 216, 220, 226, 227, 229, 235, 237], "acc_always_neg": 57, "mcc_always_neg": 57, "balanced_acc_always_neg": 57, "binary_log_loss": 57, "standardize_appli": [57, 107], "safe_div": 57, "binary_metrics_from_count": 57, "bal_acc": 57, "y_val_bool": 57, "best_acc_idx": 57, "best_acc_t": 57, "y_test_pr": [57, 91], "cm_test": 57, "bioinformat": 57, "perturb": [57, 90, 114, 160, 172, 181, 183, 229], "1975": 57, "secondari": [57, 341], "t4": [57, 160], "phage": 57, "lysozym": 57, "q1": [59, 144, 145, 196], "qn": 59, "pi_q": 59, "irrelev": [59, 107, 248, 254], "amplifi": [59, 138, 160, 242], "log_2": [59, 69, 110, 184, 238], "abcdefgh": 59, "order_pr": 59, "order_id": [59, 354, 355], "gain_exp": 59, "rel_pr": 59, "gain_pr": 59, "contrib_pr": 59, "dcg_k": 59, "rel_id": 59, "gain_id": 59, "contrib_id": 59, "ndcg_k": 59, "join": [5, 59, 122, 157, 267, 286, 311, 312, 313, 314, 315, 316, 317, 341, 346, 351], "sk_ndcg": 59, "y_score_sc": 59, "sk_scale": 59, "docs_pr": 59, "scores_pr": 59, "rels_pr": 59, "gains_pr": 59, "contribs_pr": 59, "docs_id": 59, "rels_id": 59, "gains_id": 59, "contribs_id": 59, "slice": [59, 90, 103, 117, 123, 230, 340, 386], "k_list": [59, 187], "dcg_at_k_numpi": 59, "ndcg_at_k_numpi": 59, "mean_ndcg_at_k_numpi": 59, "_as_2d_same_shap": 59, "_gain": 59, "scheme": [59, 139, 224, 228, 245, 263], "gain_schem": 59, "take_along_axi": [59, 86, 87, 253], "idcg_at_k_numpi": 59, "ideal_ord": 59, "y_ideal": 59, "dcg_at_k_expected_ties_1d": 59, "tie": [59, 64, 65, 105, 226, 252, 255, 260, 265, 270], "gains_sort": 59, "group_siz": [59, 243, 257], "sum_discounts_in_top_k": 59, "y_true_rand": [59, 101, 102], "y_score_rand": 59, "np_impl": 59, "y_true_ti": 59, "y_score_ti": 59, "ndcg_simpl": 59, "primari": [59, 340, 341, 345, 346], "order_best": 59, "lexsort": 59, "order_worst": 59, "ndcg_from_ord": 59, "rel_sort": 59, "ndcg_best": 59, "ndcg_worst": 59, "dcg_expect": 59, "ndcg_expect": 59, "sk_tie_awar": 59, "sk_ignore_ti": 59, "min_w": 59, "qj": 59, "y_rel": 59, "train_idx": [59, 64, 65, 101, 105, 308, 310], "val_idx": [59, 65], "k_eval": 59, "score_linear": 59, "tensordot": [59, 131], "baseline_v": 59, "train_pointwise_ms": 59, "x_flat": [59, 132], "y_flat": 59, "w_mse": [59, 89, 101], "hist_ms": [59, 89, 101], "_sigmoid": 59, "_sample_pair": 59, "y_queri": 59, "max_pair": 59, "i_idx": [59, 78, 84], "j_idx": [59, 78, 84], "sel": 59, "make_pair_dataset": 59, "max_pairs_per_queri": 59, "qs": [59, 115, 116, 122, 125, 148, 154, 165, 172, 173, 175, 178, 181, 187, 195, 196, 200, 203, 207, 209], "is_": 59, "js": [59, 174, 338, 339, 341, 347, 355], "pair_q": 59, "pair_i": 59, "pair_j": 59, "train_pairwise_logist": 59, "x_diff": [59, 176], "n_pair": [59, 64, 70, 255], "w_rank": 59, "hist_rank": 59, "mse_train": 59, "mse_val": 59, "rank_train": 59, "rank_val": 59, "slate": 59, "j\u00e4rvelin": 59, "kek\u00e4l\u00e4inen": 59, "acm": 59, "burg": 59, "2005": [59, 65, 94, 196, 245, 262], "mann": [64, 257, 266, 267, 270], "whitnei": [64, 257, 266, 267, 270], "calculu": [64, 98, 150, 157, 159, 162, 163, 183, 194, 195, 198, 201, 204, 209, 211, 212, 213, 216, 218, 221, 235, 240], "skl_roc_auc_scor": 64, "skl_roc_curv": 64, "confusion_at_threshold": 64, "tpr_fpr_from_confus": 64, "y_true_smal": 64, "y_score_smal": 64, "52": [39, 64, 67, 93, 116, 134, 142, 253], "df_small": 64, "u2265": [64, 253], "lenient": 64, "noth": [64, 77, 78, 100, 122, 369], "roc_curve_bruteforc": 64, "tpr_i": 64, "fpr_i": 64, "fpr_b": 64, "tpr_b": 64, "thr_b": 64, "auc_b": 64, "df_roc_smal": 64, "point_label": 64, "int_0": [64, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 161, 162, 164, 165, 166, 168, 169, 170, 171, 172, 173, 174, 175, 176, 178, 180, 181, 182, 183, 187, 190, 192, 198, 199, 200, 201, 202, 203, 204, 205, 207, 208, 209, 213, 218, 219, 220, 222, 225, 233, 240], "du": [64, 161, 162, 164, 169, 175, 179, 181, 189, 200, 201, 202, 204, 213, 219, 220], "pos_": 64, "df_pair": [64, 250], "add_shap": [64, 91, 135, 137, 267, 269, 312], "scan": [16, 64, 74, 153, 312, 332, 333, 341, 348, 360], "roc_curve_np": 64, "anyth": [64, 333, 342, 343], "y_pos_sort": 64, "distinct_value_indic": 64, "roc_auc_score_np": 64, "roc_auc_score_mann_whitney_np": 64, "wilcoxon": [64, 253, 266, 268, 269], "sum_ranks_po": 64, "auc_mw": 64, "auc_skl": 64, "drop_intermedi": 64, "fpr_skl": 64, "tpr_skl": 64, "thr_skl": 64, "auc_logit": 64, "auc_prob": 64, "scores_po": [64, 65], "scores_neg": [64, 65], "y_true_big": 64, "y_score_big": 64, "auc_val": 64, "thresholds_demo": 64, "tpr_thr": 64, "fpr_thr": 64, "duplic": [64, 334, 355, 383], "10x": 64, "y_true_imb": 64, "y_score_imb": 64, "auc_orig": 64, "auc_imb": 64, "ap_orig": 64, "ap_imb": 64, "fpr_o": 64, "tpr_o": 64, "multi_class": 64, "ovr": 64, "ovo": 64, "score_logit": 64, "score_proba": 64, "score_label": 64, "workaround": [64, 149, 159, 164, 185, 221], "add_bia": 64, "make_gaussian_binari": 64, "1250": [64, 70, 141], "mean_po": 64, "mean_neg": 64, "x_po": [64, 113, 168, 234], "x_neg": 64, "train_logistic_logloss_gd": 64, "log_everi": [64, 94, 139], "reg_grad": 64, "train_auc": 64, "train_auc_pairwise_sgd": 64, "dloss": [64, 140], "dd": [64, 385], "pair_loss": 64, "test_idx": [64, 101, 105, 310], "hist_auc": 64, "1024": [64, 140, 142, 143, 146], "scores_ce_test": 64, "scores_auc_test": 64, "auc_ce_test": 64, "auc_auc_test": 64, "fpr_ce": 64, "tpr_ce": 64, "fpr_auc": 64, "tpr_auc": 64, "hanlei": 64, "mcneil": 64, "1982": [64, 95, 220], "knowledg": [65, 112, 149, 191, 200, 212, 240, 241, 264, 343, 353], "threshold_exampl": 65, "add_histogram": [65, 160, 247], "confusion_count": [65, 78], "tpr_exampl": 65, "fpr_exampl": 65, "recomput": [65, 141, 195, 243, 245, 255, 256, 257, 262, 263, 265, 268], "array_equ": [65, 73, 77, 84], "distinct_score_indic": 65, "threshold_indic": 65, "auc_trapz": 65, "auc_roc": 65, "sk_roc_auc_scor": 65, "sk_roc_curv": 65, "fpr_sk": 65, "tpr_sk": 65, "auc_sk": 65, "auc_sk_trapz": 65, "hover_text": 65, "add_scatt": [65, 78], "evolv": [65, 113, 153, 285, 311], "nuanc": [65, 111, 143, 207, 252, 255, 257, 260], "xb_val": 65, "data_loss": 65, "reg_loss": 65, "weights_by_l2": 65, "auc_by_l2": 65, "scores_v": 65, "fpr_v": 65, "tpr_v": 65, "auc_v": 65, "best_i": [65, 78], "best_auc": 65, "\u03bb": [65, 69, 162, 163, 169, 193, 213, 218, 236, 242], "refit": [65, 112, 132, 195, 256, 271], "thr_v": 65, "target_fpr": 65, "chosen_i": 65, "chosen_thr": 65, "default_thr": 65, "tp2": 65, "fp2": 65, "tn2": 65, "fn2": 65, "tpr2": 65, "fpr2": 65, "commit": [65, 331, 333, 376], "overli": [65, 103, 110, 211, 258, 265], "optimist": [65, 145, 206, 241], "absolut": [65, 85, 87, 88, 90, 92, 96, 97, 99, 100, 102, 114, 118, 155, 158, 172, 176, 177, 188, 204, 207, 209, 214, 247, 256, 259, 280, 299], "zoom": [65, 105], "coupl": [65, 90, 103, 114, 117, 118, 123, 184, 201, 210, 270, 335, 374], "doi": [65, 86, 87], "1016": 65, "patrec": 65, "010": [65, 94, 108, 142, 242], "receiver_operating_characterist": 65, "discontinu": 67, "sk_zero_one_loss": 67, "l_": [67, 87, 145], "l_w": 67, "multioutput": [67, 86, 87, 90, 91, 92, 94, 99, 102, 306], "max_k": [67, 106, 169, 213, 225, 231, 236], "eta": [67, 88, 93, 95, 96, 98, 99, 104, 109, 110, 152, 160, 181, 220, 231, 243], "zero_one_loss_np": 67, "zero_one_loss_from_proba": 67, "best_threshold_zero_on": 67, "plu": [67, 74, 88, 93, 104, 112, 114, 117, 118, 124, 136, 143, 146, 149, 150, 153, 158, 163, 164, 171, 173, 174, 183, 188, 191, 193, 197, 205, 209, 214, 215, 227, 229, 240, 245, 253, 260, 262, 280, 353], "optimum": [67, 86, 87, 91, 93, 94, 96, 97, 101, 109, 190], "cum_po": 67, "cum_neg": 67, "total_neg": 67, "uniq": [67, 75, 110], "searchsort": [67, 86, 87, 162, 181, 207, 212, 218, 226, 227, 232, 234, 236, 238, 240, 241, 256], "pos_below": 67, "neg_below": 67, "train_zero_on": 67, "val_log_loss": 67, "val_zero_on": 67, "z_train": 67, "601": [41, 57, 67, 169], "51": [51, 53, 67, 77, 105, 116, 122, 145, 205, 231, 267, 288], "nweight": [67, 99], "nmultilabel": 67, "p_soft": 67, "49": [49, 67, 142, 253, 267], "p_confid": 67, "losses_grid": 67, "min_loss_grid": 67, "min_idx": [67, 292], "t_grid": [67, 75, 162, 173, 210, 212], "t_grid_low": 67, "t_grid_high": 67, "t_exact": 67, "loss_exact": 67, "3x": [67, 151], "costli": [67, 88, 91, 96, 101, 340], "t_w": 67, "loss_w": 67, "losses_unweight": 67, "losses_weight": 67, "plateau": [67, 99, 211], "landscap": [67, 78, 96, 97, 98, 107], "w_grid": 67, "151": [67, 176], "b_grid": 67, "loss01": 67, "p_clip": 67, "losslog": 67, "w_path": 67, "b_path": 67, "val_loss_05": 67, "val_loss_best": 67, "machineri": 67, "harsh": [67, 98], "prove": [67, 91, 242, 244, 245, 246, 248, 249, 250, 256, 263, 266, 268, 269], "adjusted_mutual_info_scor": [68, 77, 78], "rand": [68, 72, 73, 84], "calinski_harabasz_scor": 68, "calinski": [68, 71], "harabasz": [68, 71], "contingency_matrix": 68, "pair_confusion_matrix": [68, 81], "aris": [68, 80, 160, 166, 170, 172, 179, 183, 186, 191, 194, 204, 205, 210, 224, 234], "completeness_scor": [68, 72, 77, 84], "davies_bouldin_scor": [68, 75], "davi": [68, 70], "bouldin": [68, 70], "fowlkes_mallows_scor": 68, "homogeneity_completeness_v_measur": 68, "homogen": [68, 72, 76, 246, 252], "homogeneity_scor": [68, 72, 84], "mutual_info_scor": 68, "normalized_mutual_info_scor": [68, 69, 78, 84], "rand_scor": [68, 81], "silhouette_sampl": [68, 83], "silhouett": [68, 70, 74, 81, 82, 84], "silhouette_scor": [68, 75, 83], "v_measure_scor": [68, 72, 77], "extern": [69, 70, 72, 75, 77, 78, 81, 84, 119, 122, 139, 144, 167, 331, 348, 356, 366], "gammaln": [69, 154, 158, 159, 169, 171, 173, 180, 187, 190, 193, 197, 209, 210, 224, 225, 228, 234, 240], "skl_adjusted_mutual_info_scor": 69, "u_1": [69, 70, 168, 193, 194, 198, 202, 212, 260], "u_r": [69, 70, 216], "v_1": [69, 70, 84, 160], "v_c": 69, "n_": [69, 70, 72, 73, 75, 77, 78, 81, 84, 108, 134, 143, 211, 225, 226, 231, 233, 234, 241, 249, 251], "u_i": [69, 70, 78, 87, 167, 171, 193, 197, 198, 237], "v_j": [69, 70], "a_i": [69, 70, 75, 81, 99, 117, 118, 123, 139], "b_j": [69, 70, 75], "_relabel_to_integ": 69, "contingency_matrix_np": [69, 72, 73, 77, 81, 84], "labels_tru": [69, 70, 73, 75, 78, 84], "labels_pr": [69, 70, 73, 75, 78, 84], "n_ij": [69, 84], "true_int": 69, "pred_int": 69, "n_true": [69, 73, 75, 78, 81, 224, 225, 226, 234, 238], "n_pred": [69, 73, 75, 78, 81, 231], "entropy_from_count": [69, 72, 77, 84], "mutual_info_from_conting": [69, 84], "col_sum": [69, 73, 78, 246], "row_idx": 69, "col_idx": 69, "nij": [69, 78, 185], "ai": [69, 109, 132], "bj": 69, "null": [69, 135, 137, 161, 162, 165, 166, 169, 170, 174, 184, 189, 190, 191, 192, 195, 198, 201, 203, 204, 209, 210, 211, 212, 214, 217, 219, 221, 222, 224, 230, 232, 236, 237, 242, 243, 246, 249, 253, 255, 256, 257, 258, 259, 261, 264, 266, 267, 269, 271], "hypergeometr": [69, 70, 152, 159, 166, 190, 198, 205, 224, 226, 228, 240, 251, 261], "intersect": [69, 238], "binom": [69, 70, 75, 119, 165, 174, 206, 224, 225, 228, 230, 232, 233, 234, 251, 255], "expected_mutual_info_from_margin": 69, "factori": [69, 152, 171, 191, 213, 224, 228, 230, 231, 232, 234, 236], "combinator": [69, 70, 81, 234], "log_factori": 69, "log_comb": 69, "k_arr": [69, 226, 231, 232, 236, 237, 239, 241], "expected_mi": 69, "k_min": [69, 239], "pmf": [69, 78, 104, 228, 261, 270], "log_p": [69, 230, 235, 251, 261], "overflow": [69, 95, 98, 148, 154, 157, 160, 164, 165, 168, 169, 170, 172, 173, 175, 180, 181, 183, 184, 187, 188, 193, 196, 205, 207, 218, 219, 221, 222, 224, 225, 231, 232, 234, 235, 236, 238, 239, 241], "k_po": [69, 207], "adjusted_mutual_info_score_np": 69, "average_method": [69, 84], "h_true": 69, "h_pred": 69, "renam": [69, 75, 78, 115, 200, 280, 311, 312, 313, 314, 315, 316, 317, 385], "_assert_matches_sklearn": 69, "n_trial": [69, 70, 84, 89], "assertionerror": 69, "y_pred_permut": [69, 70, 72], "y_pred_noisi": [69, 70], "y_pred_random": [69, 70], "cont": [69, 70, 81, 84], "k_true": [69, 78, 81, 163, 187, 209], "noise_grid": [69, 75], "19": [41, 69, 75, 81, 115, 131, 134, 135, 141, 142, 143, 153, 160, 182, 217, 224, 227, 244, 246, 250, 252, 269], "n_flip": 69, "reassign": [69, 70, 75], "coincident": 69, "fulli": [69, 84, 109, 117, 143, 179, 190, 219, 222, 247, 256, 339, 341, 345, 354, 355], "ami_random": 69, "tonexti": [69, 103, 113, 117, 119, 120, 122, 123, 124, 125, 146], "regardless": [69, 70], "k_grid": [69, 70, 74, 187], "mi_by_k": 69, "ami_by_k": 69, "fluctuat": [69, 89, 195, 204, 221, 246, 247, 250, 268], "ami_sampl": 69, "train_logistic_regression_gd": 69, "reg_strength": 69, "x_train_std": 69, "x_val_std": 69, "reg_grid": 69, "threshold_grid": 69, "37": [69, 75, 115, 127, 132, 134, 142, 152, 207, 232, 285], "ami_grid": 69, "acc_grid": 69, "best_reg": 69, "best_thr": 69, "best_ami": 69, "ami_curv": 69, "acc_curv": 69, "thr_acc": 69, "indistinguish": 69, "experi": [69, 70, 92, 134, 137, 138, 157, 191, 192, 194, 204, 209, 217, 224, 226, 230, 243, 245, 247, 249, 263, 267, 280, 338, 351, 352], "vinh": 69, "epp": 69, "bailei": 69, "2010": [69, 116, 122, 306], "theoret": [69, 73, 77, 114, 120, 124, 127, 131, 132, 148, 150, 151, 152, 153, 154, 156, 158, 161, 163, 165, 166, 167, 168, 169, 172, 173, 174, 176, 177, 178, 180, 181, 182, 183, 186, 187, 188, 190, 192, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 210, 212, 213, 214, 215, 218, 219, 220, 223, 227, 229, 230, 231, 235, 236, 238, 240, 241, 242, 248, 254, 256, 263, 267], "vocabulari": [70, 108, 113, 241, 333, 381], "unord": [70, 75, 81], "bucket": [70, 77, 334, 335, 338, 339, 346, 348, 350, 352], "pair_confusion_count": 70, "same_tru": [70, 75, 81], "same_pr": [70, 75, 81], "triu": [70, 81, 206, 255], "a_same_sam": 70, "b_diff_diff": 70, "c_same_diff": 70, "d_diff_sam": 70, "meaningfulli": [70, 114, 267], "maxindex": 70, "v_": [70, 84, 134, 136, 140, 143, 144, 146, 185, 192, 222], "similarli": [70, 97, 152, 155, 159, 160, 169, 175, 177, 178, 179, 180, 183, 191, 192, 200, 201, 211, 213, 219, 228, 232], "hubert": [70, 81], "arabi": [70, 81], "1985": [70, 81, 148, 157], "rs": [70, 367, 375], "comb2": [70, 75, 81], "x_arr": [70, 226, 232, 237, 241], "contingency_matrix_numpi": [70, 75, 78], "true_label": [70, 73, 77], "true_inv": [70, 78, 81], "pred_label": [70, 73, 77], "pred_inv": [70, 78, 81], "rand_index_numpi": 70, "sum_nij": 70, "sum_ai": 70, "sum_bj": 70, "adjusted_rand_index_numpi": 70, "max_index": 70, "ri_pair": 70, "ri_cont": 70, "pariti": [70, 89, 111, 389], "singleton": [70, 75, 81, 83], "ari_np": 70, "ri_np": [70, 81], "ari_sk": 70, "ri_by_k": 70, "ari_by_k": 70, "y_rand": 70, "boxmean": [70, 81], "n_per": [70, 81, 83], "y_true_vi": 70, "illustr": [1, 70, 150, 157, 167, 172, 178, 191, 217, 219, 223, 236, 240, 243, 299, 303, 306, 333, 334, 335, 338, 339, 340, 341, 344, 347, 355, 393, 394], "corrupt_label": [70, 75], "y_pred_perfect": 70, "palett": [70, 75, 305], "t_label": 70, "p_label": 70, "toself": [70, 78, 90, 116, 246, 254, 266, 267, 305], "fillcolor": [70, 78, 90, 103, 113, 116, 117, 119, 120, 122, 123, 124, 125, 127, 129, 151, 174, 181, 184, 241, 246, 250, 254, 260, 261, 266, 267, 268, 269, 284, 289, 299, 305, 318], "semi": [70, 73, 81, 84, 189, 206, 353, 382], "kmeans_single_run": [70, 73], "init_idx": [70, 73, 84], "new_cent": [70, 73], "inertia": [70, 72, 73, 74, 81, 84, 112, 118], "kmeans_from_scratch": 70, "best_cent": [70, 73], "best_inertia": [70, 72, 73, 74, 81, 84], "labels_k": [70, 73, 74], "centers_k": [70, 73], "inertia_k": [70, 73, 74], "ari_k": 70, "best_k": [70, 81, 105], "best_ari": 70, "selector": [70, 367, 372, 375, 377, 378], "intern": [70, 72, 73, 74, 75, 81, 83, 84, 93, 96, 103, 107, 134, 136, 138, 139, 141, 143, 144, 145, 146, 148, 160, 174, 197, 205, 237, 306, 343, 344, 351, 357], "unadjust": [70, 81], "again": [70, 109, 162, 163, 174, 176, 189, 193, 195, 196, 203, 206, 214, 218, 225, 228, 232, 240, 355], "1971": [70, 81, 223, 248], "criteria": [70, 81, 112, 118, 156, 165, 240, 242, 370], "journal": [70, 75, 81, 170], "american": [70, 75, 81], "associ": [70, 75, 81, 122, 232, 246, 251, 261, 262, 263, 265], "ck": [72, 84, 171, 174], "skl_completeness_scor": 72, "skl_homogeneity_scor": 72, "skl_v_measure_scor": 72, "complementari": [72, 84, 109, 116, 163, 188, 210, 288], "n_c": [72, 77, 84, 249], "sum_c": [72, 77, 84], "class_idx": [72, 84], "cluster_idx": [72, 84], "conditional_entropy_from_conting": 72, "completeness_score_np": 72, "h_k": [72, 84], "h_k_given_c": 72, "homogeneity_score_np": [72, 77], "h_c": [72, 77, 84], "h_c_given_k": [72, 77], "v_measure_score_np": [72, 84], "y_pred_split": 72, "y_pred_one_clust": 72, "c_np": [72, 84], "c_skl": 72, "h_np": [72, 77, 84], "h_skl": 72, "v_np": [72, 84], "v_skl": 72, "plot_contingency_heatmap": 72, "react": [72, 75, 89, 111, 113, 131, 258, 347, 349, 356, 401], "y_true_2": [72, 101], "base_pr": 72, "41": [49, 72, 75, 78, 122, 132, 163, 207, 229, 232, 261, 289, 301], "v_measur": [72, 77, 84], "collaps": [72, 83, 134, 135, 142, 163, 167, 231, 234, 235], "blindli": [72, 334, 335], "sensibl": [72, 105, 165, 240, 263, 382], "n_per_class": [72, 73, 77, 84], "y_true_blob": 72, "kmeans_fit_predict_np": [72, 77], "lloyd": [72, 73, 74, 77, 83, 84], "centroid": [72, 74, 77, 81, 83, 84, 211, 212], "best_centroid": [72, 74, 81, 83, 84], "new_centroid": [72, 74, 81, 83, 84], "k_val": 72, "c_val": [72, 174, 219], "v_val": 72, "inertia_v": 72, "best_k_unconstrain": 72, "best_k_k_ge_2": 72, "best_k_by_v_measur": 72, "unconstrain": [72, 110, 125, 132, 150, 165, 171, 172, 174, 180, 182, 190, 191, 199, 202, 224, 230, 237], "k_star": 72, "labels_star": 72, "centroids_star": 72, "c_star": [72, 87, 94, 99], "h_star": 72, "v_star": 72, "nmi": [72, 73, 84], "rosenberg": [72, 77, 84], "hirschberg": [72, 77, 84], "2007": [72, 77, 84, 102], "linear_sum_assign": 73, "c_1": [73, 74, 175, 251, 286], "c_c": [73, 83], "k_1": [73, 195, 224, 225, 231, 234, 235, 240], "k_k": 73, "c_a": 73, "wedg": 73, "k_b": [73, 163, 186, 227], "n_a": [73, 245, 250, 260, 266], "m_b": 73, "csr": [73, 398], "y_inv": 73, "z_inv": 73, "coo_matrix": 73, "tocsr": 73, "dog": [73, 230], "fish": [73, 230], "cm_np": 73, "cm_sk": 73, "nconting": 73, "nallclos": 73, "cm_spars": 73, "nspars": 73, "toarrai": 73, "composit": [73, 159, 212, 228, 230, 232, 234, 313, 332], "row_norm": 73, "col_norm": 73, "labels_pred_perm": 73, "cm_perm": 73, "z_vals_perm": 73, "inv_perm": 73, "perm_idx": 73, "new_label": [73, 77, 84], "kmeans_np": [73, 74, 81, 84], "labels_km": 73, "centers_km": 73, "inertia_km": 73, "cm_col_norm": 73, "vote": [73, 105, 110], "purity_from_conting": 73, "majority_vote_map": 73, "best_true_idx_per_clust": 73, "mv_map": 73, "y_pred_mv": 73, "acc_mv": 73, "hungarian": 73, "row_ind": 73, "col_ind": 73, "hungarian_map": 73, "y_pred_h": 73, "acc_h": 73, "purity_score_np": 73, "z_pred": 73, "restart": [73, 103, 365, 373, 376], "1_000_000": [73, 139, 142, 144, 145], "purity_list": 73, "inertia_list": 73, "labels_": [73, 74], "centers_": 73, "inertia_": 73, "hashabl": [73, 75], "never": [2, 73, 89, 91, 113, 150, 181, 196, 216, 310, 332, 340, 346, 366, 370], "occur": [73, 95, 125, 148, 154, 157, 187, 188, 196, 204, 211, 225, 227, 230, 231, 236, 241, 251, 256, 303, 355], "game": [73, 234, 239], "leak": [73, 107, 332, 371], "leq": 73, "compact": [74, 83, 89, 107, 122, 129, 152, 153, 156, 182, 190, 195, 198, 205, 206, 212, 214, 223, 224, 225, 241, 300, 327], "sk_davies_bouldin_scor": 74, "cluster_centers_": 74, "c_k": [74, 241], "mu_i": [74, 88, 93, 95, 104, 218, 245, 249], "mu_j": 74, "d_i": [74, 92, 93, 125, 139, 163, 263, 265, 266, 268, 270], "davies_bouldin_index_np": 74, "m_ij": 74, "centroid_dist": 74, "r_ij": [74, 253], "errstat": [74, 77, 88, 89, 100, 156, 159, 164, 168, 173, 205, 220, 246, 250], "invalid": [31, 57, 74, 77, 83, 88, 89, 93, 100, 102, 135, 137, 138, 143, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 185, 187, 188, 189, 191, 193, 194, 196, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 210, 211, 212, 213, 215, 217, 218, 220, 223, 228, 229, 232, 234, 235, 237, 238, 239, 240, 241, 248, 257, 265, 339, 345], "dbi_np": 74, "dbi_sk": 74, "labels_random": [74, 78], "dbi_random": 74, "dbi_components_np": 74, "unique_label": [74, 83], "worst_neighbor": 74, "r_show": 74, "isol": [8, 74, 271, 332, 333, 357, 358], "mont": [74, 123, 143, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 200, 201, 202, 204, 205, 206, 207, 208, 210, 211, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 246, 247, 250, 253, 256, 257, 259, 263, 264, 268, 269, 270], "carlo": [74, 123, 143, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 200, 201, 202, 204, 205, 206, 207, 208, 210, 211, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 246, 247, 250, 253, 256, 257, 259, 263, 264, 268, 269, 270], "rng_demo": [74, 245], "123": [74, 84, 89, 99, 108, 114, 117, 121, 140, 142, 148, 166, 181, 186, 195, 210, 217, 218, 220, 224, 228, 241, 242, 245, 247, 249, 250, 252, 253, 259, 263, 269, 306, 319, 340, 344, 347], "n2": [74, 107, 163, 166, 250, 256, 260, 266, 267], "z2": [74, 155, 186, 194, 218, 262], "labels_true_2": 74, "make_two_blobs_np": 74, "sep": 74, "x_sep": 74, "df_sep": 74, "x_std": [74, 91, 92, 95, 258], "df_std": 74, "diffus": [74, 178, 186, 189, 218], "x_bad": [74, 105], "k_bad": 74, "labels_bad": 74, "dbi_bad": 74, "x_bad_std": 74, "k_std": 74, "labels_std": 74, "dbi_std": 74, "invert": [74, 97, 102, 103, 107, 112, 113, 116, 117, 119, 123, 135, 157, 163, 171, 181, 196, 233, 261, 266, 382], "centroids_std_origin": 74, "kmeans_pp_init_np": 74, "closest_dist2": 74, "dist2_new": 74, "_it": 74, "xk": [74, 81, 103, 106, 109], "centroids_k": [74, 84], "dbi_k": 74, "df_k": 74, "dtick": 74, "k_wrong": 74, "labels_wrong": 74, "centroids_wrong": 74, "dbi_wrong": 74, "labels_best": [74, 81, 83, 84], "dbi_best": 74, "df_scan": 74, "setup": [74, 93, 101, 102, 109, 113, 115, 136, 141, 192, 247, 257, 269, 332, 334, 341, 344, 346, 350, 355, 357], "altern": [74, 91, 96, 112, 116, 141, 149, 150, 153, 156, 157, 165, 166, 169, 170, 171, 172, 177, 181, 183, 185, 188, 190, 191, 192, 193, 194, 197, 199, 200, 206, 207, 208, 210, 211, 212, 215, 221, 222, 223, 226, 227, 230, 232, 235, 239, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 262, 263, 265, 268, 269, 270, 280, 300, 309, 331, 341], "rm": [74, 139, 141, 144, 196, 358, 359], "1979": [74, 245], "sk_fowlkes_mallows_scor": 75, "_j": [75, 81, 96, 99, 101, 117, 139, 209, 225], "pair_confusion_counts_bruteforc": 75, "fowlkes_mallows_from_pair_count": 75, "precision_pair": 75, "recall_pair": 75, "pairs_tot": 75, "same_cluster_matrix": 75, "pair_typ": 75, "colorscale_pair": 75, "e0e0e0": 75, "125": [51, 75, 81, 86, 92, 113, 136, 141, 150, 218, 269], "375": [75, 81, 92, 152, 203, 239], "d73027": 75, "625": [69, 75, 81, 135, 137], "4575b4": 75, "875": [75, 81], "1a9850": 75, "grei": 75, "tp_fast": 75, "pred_pair": 75, "true_pair": 75, "fmi_fast": 75, "fowlkes_mallows_score_numpi": 75, "check_cas": 75, "y_t": [75, 102, 112, 113, 114, 116, 117, 118, 119, 120, 122, 123, 124, 132, 250, 265, 271, 280, 284, 285, 296, 297, 298, 300, 303, 304, 306, 307, 308, 322, 323, 327, 328, 329], "y_p": [75, 102, 104, 112], "ok": [75, 84, 90, 181, 210, 244, 261, 333], "ok_al": 75, "trial": [75, 89, 104, 150, 159, 162, 223, 225, 228, 230, 231, 237], "y_perfect": 75, "y_permut": 75, "y_merg": 75, "mask0": [75, 153, 175, 204, 210, 238], "cut": [75, 102, 117, 119, 171, 214, 222, 266], "y_split": 75, "y_noisi": 75, "noisy_kei": 75, "label_color": 75, "color_map": 75, "panel": [75, 100, 110, 128, 129, 167, 191, 256, 291, 320, 324, 325, 351, 383, 386], "y_corrupt": 75, "199": [75, 269], "fmi_grid": 75, "best_fmi": 75, "decision_line_xi": 75, "logit_t": 75, "desir": [75, 78, 141, 149, 153, 171, 212, 235, 242, 331, 334, 335, 338, 343, 367], "unintuit": [75, 220], "refin": [75, 119], "1983": [75, 248, 258], "open": [77, 105, 109, 122, 167, 238, 333, 338, 346, 377, 381, 386], "sk_completeness_scor": 77, "sk_homogeneity_scor": 77, "sk_v_measure_scor": 77, "impur": 77, "complain": 77, "member": [77, 84, 200], "occurr": [77, 223, 292, 303], "encode_label": 77, "conditional_entropy_c_given_k_from_conting": 77, "p_ck": 77, "p_c_given_k": 77, "h_sk": [77, 84], "somewhat": 77, "y_pred_toi": 77, "n_toi": 77, "classes_toi": 77, "clusters_toi": 77, "h_toi": 77, "cluster_s": 77, "cluster_entropi": 77, "flip_fract": 77, "true_bin": 77, "eps_grid": 77, "h_valu": 77, "pred_bin": 77, "yaxis_rang": [77, 157, 193, 250], "split_each_class_into_m_clust": 77, "m_grid": 77, "h_list": 77, "comp_list": 77, "v_list": 77, "plot_clust": 77, "km": [77, 352], "k_valu": [77, 81], "13": [75, 77, 89, 92, 93, 100, 107, 109, 112, 116, 131, 135, 137, 141, 142, 153, 159, 161, 170, 175, 178, 184, 201, 209, 213, 217, 221, 227, 230, 231, 238, 239, 240, 242, 247, 250, 254, 280, 310, 323, 381, 382, 389], "best_by_k": 77, "best_row": 77, "best_k_by_h": 77, "watch": [77, 98, 106, 142, 169, 247, 265, 357, 369, 385], "artifici": [77, 222], "gold": [77, 352], "situat": [77, 97, 211, 250, 257, 260, 265], "harm": [77, 119], "ami": [77, 84, 335, 342, 343, 357], "sum_u": 78, "widehat": [78, 165, 179, 190, 221, 235, 261], "true_valu": 78, "pred_valu": 78, "mutual_info_score_numpi": 78, "k_pred": 78, "labels_true_rand": 78, "labels_pred_rand": 78, "mi_sklearn": 78, "mi_numpi": 78, "n_per_clust": 78, "labels_perm": 78, "add_label_nois": 78, "p_nois": 78, "labels_noisi": 78, "contingency_heatmap_trac": 78, "true_val": 78, "pred_val": 78, "cont_perm": 78, "pred_perm_v": 78, "cont_rand": 78, "pred_rand_v": 78, "cont_noisi": 78, "pred_noisy_v": 78, "n_repeat": 78, "mi_mean": 78, "mi_std": 78, "max_mi": 78, "mi_contribution_matrix": 78, "contrib_noisi": 78, "color_continuous_midpoint": 78, "x_train_b": 78, "x_val_b": 78, "mi_val": 78, "acc_val": 78, "y_pred_tau": 78, "best_tau": 78, "y_pred_best": 78, "y_pred_05": 78, "decision_boundary_x2": 78, "x2_tau05": 78, "w_0": [78, 100], "w_1": [78, 100, 165, 211, 221], "y_bin": 78, "w0_grid": 78, "81": [78, 240], "w1_grid": 78, "mi_grid": 78, "w0_best": 78, "w1_best": 78, "labels_true_smal": 78, "labels_uniqu": 78, "thoma": 78, "inflat": [81, 113, 116, 118, 122, 152, 159, 183, 210, 236, 237, 242, 243, 244, 249, 250, 252, 269], "inom": [81, 231], "formal": [81, 228, 252], "ri": 81, "pcm_ord": 81, "im": [81, 155, 164, 173, 175, 176, 178, 204, 207, 216, 271], "a_": [81, 99, 118, 134, 135, 136, 137, 141, 145, 146, 165, 184, 186, 221, 241, 251, 252], "pair_category_matrix": 81, "upper_mask": 81, "axis_label": 81, "name_map": 81, "cat_nam": 81, "c_diag": 81, "c_tn": 81, "d9d9d9": 81, "c_fp": 81, "c_fn": 81, "c_tp": 81, "1249": [21, 81], "3749": 81, "6249": [81, 189], "8749": [81, 123], "column_width": [81, 125], "72": [81, 169, 212, 229], "triangl": [81, 159, 206, 211, 212, 228, 230, 255], "k_y": [81, 103], "pairs_ord": 81, "_labels_to_integ": 81, "pair_confusion_matrix_np": 81, "total_pair": 81, "rand_score_np": 81, "ri_sk": 81, "pcm_np": 81, "pcm_sk": 81, "pair_confus": 81, "y_pred_perm": 81, "surprisingli": [81, 108, 131, 240, 304, 307, 309], "all_in_on": 81, "all_singleton": 81, "y_all1": 81, "y_singl": 81, "practition": [81, 209], "k_pred_valu": 81, "rep": [81, 252, 258, 280], "adj_rand_scor": 81, "x_list": 81, "liter": [75, 81, 100, 105, 109, 116, 117, 153, 165, 169, 190, 197, 199, 200, 207, 217, 221, 231, 247, 249, 255, 258, 261, 267, 270], "ablat": 81, "thin": [81, 105, 175, 188, 236, 258], "insight": [81, 266, 340], "versu": [83, 197, 198, 205], "skl_silhouette_scor": 83, "skl_silhouette_sampl": 83, "border": 83, "misclust": 83, "subsampl": [83, 110, 152, 168, 169, 173, 174, 181, 190, 193, 197, 200, 205, 208, 209], "chunk": 83, "ddof": [83, 89, 96, 107, 120, 124, 127, 129, 131, 132, 152, 157, 159, 163, 166, 168, 181, 183, 184, 194, 195, 197, 198, 199, 200, 202, 203, 208, 210, 214, 218, 219, 221, 223, 224, 225, 226, 228, 230, 231, 232, 233, 236, 237, 239, 241, 242, 243, 244, 245, 246, 247, 248, 250, 252, 254, 258, 264, 266, 267, 268, 269, 286, 289, 305], "guard": [83, 92, 184, 194, 237, 241], "silhouette_samples_from_distance_matrix": 83, "cluster_indic": 83, "singleton_mask": 83, "mean_dist": 83, "silhouette_score_from_distance_matrix": 83, "silhouette_score_numpi": 83, "silhouette_point_detail": 83, "i_clust": 83, "idx_self": 83, "mean_to_clust": 83, "tmp": [31, 57, 83, 143, 146, 153, 158, 181, 189, 206, 230, 235, 285], "b_cluster": 83, "cluster_label": 83, "i_cluster_label": 83, "b_cluster_label": 83, "misassign": 83, "x_toi": 83, "labels_toi": 83, "d_toi": 83, "s_toi": 83, "score_toi": 83, "skl_s_toi": 83, "skl_score_toi": 83, "nselect": [83, 148], "mean_to": 83, "x_name": 83, "royalblu": [83, 99, 161], "firebrick": [83, 197, 246, 254, 261], "borderlin": 83, "plot_silhouett": 83, "y_offset": 83, "yshift": [83, 96, 101, 135, 137, 230, 260, 268, 269], "kmeans_lloyd": 83, "reiniti": 83, "best_kmeans_by_silhouett": 83, "unlabel": 83, "k_best": 83, "centroids_best": [83, 84], "s_best": 83, "labels_skl": 83, "score_skl": 83, "score_np": 83, "globular": 83, "rousseeuw": [83, 99], "1987": [83, 254], "graphic": [83, 271, 297, 298], "aid": 83, "perm_map": 84, "labels_pred_perfect": 84, "labels_pred_one_clust": 84, "split_bit": 84, "labels_pred_split_each_class": 84, "labels_pred_random": 84, "_encode_label": 84, "pj": 84, "homogeneity_completeness_v_measure_np": 84, "_check_against_sklearn": 84, "c_sk": 84, "v_sk": 84, "beta_row": 84, "n_per_cent": 84, "x_part": [84, 118], "y_part": 84, "results_summari": 84, "giant": [84, 228], "d2_absolute_error_scor": [85, 87], "d2_pinball_scor": [85, 86], "pinbal": [85, 91, 96, 280], "d2_tweedie_scor": [85, 98], "tweedi": [85, 93, 95], "devianc": [85, 87, 95], "explained_variance_scor": 85, "max_error": 85, "residu": [85, 86, 87, 89, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 102, 111, 113, 114, 116, 117, 118, 120, 122, 123, 124, 127, 131, 132, 134, 157, 158, 161, 176, 177, 185, 191, 194, 195, 197, 204, 207, 208, 229, 241, 242, 243, 245, 247, 248, 249, 250, 254, 257, 258, 259, 262, 271, 284, 297, 298, 305, 323], "mean_absolute_error": [85, 86, 90, 92, 99, 101, 125, 127, 129, 131, 132, 271, 297, 298, 304, 307, 310, 320, 321], "mean_absolute_percentage_error": 85, "percentag": [85, 92, 101, 102, 247, 255, 256, 280, 299], "mape": [85, 271, 280, 303], "mean_gamma_devi": 85, "mean_pinball_loss": [85, 87], "mean_poisson_devi": 85, "poisson": [85, 88, 93, 98, 108, 169, 180, 222, 225, 226, 230, 247, 256], "mean_squared_error": [85, 89, 90, 91, 92, 97, 99, 101, 102, 104, 105, 107, 109, 110, 125, 127, 129, 131, 132, 271, 304, 307], "mean_squared_log_error": [85, 97, 102], "mean_tweedie_devi": [85, 88, 93], "median_absolute_error": 85, "root_mean_squared_error": [85, 101, 102], "root": [85, 97, 112, 114, 116, 117, 118, 121, 164, 169, 174, 179, 180, 190, 209, 211, 220, 331, 358], "root_mean_squared_log_error": [85, 102], "d\u00b2_absolut": 86, "arbitrarili": [86, 87, 100, 107, 179, 208, 219], "sk_d2_absolute_error_scor": 86, "sk_mean_absolute_error": 86, "tild": [86, 87, 90, 113, 145, 155, 175, 181], "ae": 86, "mae_model": 86, "mae_baselin": 86, "d\u00b2_ae": 86, "min_c": 86, "half": [86, 90, 99, 155, 171, 177, 178, 186, 190, 203, 206, 207, 208, 214, 237, 238, 260], "c_grid": [86, 87, 91, 94, 99, 100, 101, 153, 154, 161, 168, 174, 180, 200, 202, 216, 219, 220, 222], "mae_c": [86, 91], "e45756": [86, 87, 92, 100, 245], "twice": [86, 101, 233, 266, 267, 268, 270], "anti": [86, 100], "mae_bas": 86, "4c78a8": [86, 87, 100, 245], "f58518": [86, 100], "54a24b": 86, "aggreg": [86, 87, 91, 92, 96, 97, 99, 100, 101, 110, 114, 117, 122, 157, 194, 280, 288, 296, 346, 356, 381, 384, 386], "raw_valu": [86, 87, 89, 91, 92, 94, 96, 97, 99, 100, 101, 102], "uniform_averag": [86, 87, 89, 91, 92, 94, 96, 97, 99, 100, 101, 102], "n_output": [86, 87, 89, 91, 94, 96, 97, 99, 100, 101, 102], "_to_2d": [86, 89], "weighted_percentile_low": 86, "_weighted_percentil": [86, 87], "n_dim": [86, 87, 129], "sorted_idx": [86, 87], "sorted_arrai": [86, 87], "sorted_w": 86, "cdf": [86, 87, 125, 149, 153, 164, 196, 216, 228, 242, 246, 249, 252, 254, 260, 261, 262, 264, 266, 267, 268, 269, 270], "gh20528": 86, "nextaft": [86, 87, 157, 174, 194, 199, 235], "mae_raw_valu": 86, "abs_err": [86, 91, 92], "d2_absolute_error_score_numpi": 86, "med": [86, 99, 132, 155, 175, 183, 207], "nonzero_num": 86, "nonzero_den": 86, "ol": [86, 87, 90, 91, 92, 96, 97, 99, 100, 112, 119, 122, 123, 262], "out_idx": [86, 99, 265], "y_baselin": [86, 87], "w_ol": [86, 100], "y_hat_ol": [86, 96], "fit_l1_linear_subgradi": 86, "lr0": [86, 91, 92, 176], "mae_hist": 86, "d2_hist": [86, 87], "diminish": [86, 94, 153], "w_l1": 86, "y_hat_l1": 86, "x_line": [86, 87, 90, 91, 92, 96, 97, 98, 99, 100, 101, 107, 216, 267], "y_line_ol": [86, 87, 90, 91, 92], "y_line_l1": 86, "y_line_baselin": 86, "linearli": [86, 87, 91, 92, 93, 95, 96, 105, 109, 142, 153, 155, 169, 175, 177, 178, 186, 201, 207, 211, 212, 234, 262, 265], "thu": [86, 207, 210, 219, 228], "huber": [86, 91, 96, 100, 101, 139], "misread": 86, "magnitud": [86, 87, 91, 96, 97, 98, 99, 101, 102, 111, 158, 161, 164, 168, 173, 174, 175, 178, 179, 182, 183, 184, 186, 190, 193, 201, 205, 207, 245, 262, 265], "drastic": 86, "koenker": [86, 87, 94], "machado": [86, 87], "1999": [86, 87, 139, 257], "1080": [86, 87], "01621459": [86, 87], "10473882": [86, 87], "analogu": [87, 162, 185, 186, 191, 225, 228, 229, 230, 238, 241, 253, 257], "linearregress": [87, 89, 91, 92, 96, 97, 101, 102], "quantileregressor": 87, "minu": [87, 116, 150, 152, 159, 200, 203, 206, 223, 234, 239, 394], "rho_": [87, 177], "9x": 87, "pinball_loss_residu": 87, "tilt": [87, 151, 170, 189, 198, 208, 232], "rho_alpha": 87, "partial_c": [87, 94], "loss_grid": 87, "loss_star": 87, "standard_t": [87, 242, 244, 248, 250, 252, 254, 258, 259, 269, 270], "_weighted_percentile_low": 87, "sorted_weight": 87, "weight_cdf": 87, "total_weight": 87, "mean_pinball_loss_numpi": 87, "d2_pinball_score_numpi": 87, "y_quantil": 87, "nonzero_numer": 87, "nonzero_denomin": 87, "valid_scor": 87, "output_scor": [87, 89, 100], "y_const": [87, 89, 100, 101], "Their": [87, 245], "nabla_": [87, 95, 100, 107, 109, 116, 134, 135, 136, 138, 143, 146, 323], "skew": [87, 88, 94, 98, 101, 122, 150, 157, 162, 164, 165, 168, 169, 171, 173, 176, 180, 186, 188, 189, 193, 194, 197, 199, 201, 209, 214, 217, 218, 221, 223, 228, 229, 237, 241, 242, 244, 245, 252, 256, 257, 258, 261, 266, 267, 269, 270], "heteroscedast": [87, 88, 89, 93, 94, 98, 101, 102, 243, 249, 252, 259], "fit_linear_quantile_regression_sgd": 87, "x_design": [87, 107, 327], "baseline_pr": 87, "baseline_loss": 87, "grad_pr": 87, "w_qr": 87, "l_alpha": 87, "x_train_design": 87, "x_test_design": 87, "regressor": [87, 94, 97, 100, 102, 104, 116, 122, 123, 127, 129, 131, 285, 306, 311, 315, 319, 320, 324, 328], "y_test_pred_qr": 87, "y_test_pred_ol": 87, "x_line_design": 87, "y_line_qr": 87, "intercept_": [87, 89, 91, 92, 93, 94, 98, 101, 104, 109], "coef_": [87, 89, 91, 92, 93, 94, 95, 98, 101, 104, 109, 115], "interv": [87, 94, 99, 103, 113, 115, 117, 119, 120, 124, 125, 127, 128, 144, 149, 150, 151, 153, 156, 161, 166, 169, 170, 171, 173, 174, 176, 178, 182, 184, 191, 195, 198, 201, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 222, 227, 233, 234, 236, 238, 249, 250, 251, 259, 261, 267, 268, 269, 280, 284, 288, 294, 303, 308, 313, 317, 321, 322], "10th": 87, "90th": [87, 94], "scorer": [87, 97, 101], "make_scor": 87, "greater_is_bett": 87, "alpha_level": [87, 152, 254], "y_test_pred_qr_sklearn": 87, "involv": [87, 98, 116, 152, 166, 170, 174, 176, 178, 179, 184, 191, 193, 195, 197, 203, 205, 209, 211, 221, 228, 239, 267], "lp": [87, 158, 197, 205, 216, 219], "demand": [87, 92, 93, 94, 97, 102, 119, 122, 212, 241, 339, 341, 342, 346, 349], "energi": [87, 94, 119, 151, 157, 166, 175, 193, 204, 215, 235], "latenc": [3, 4, 5, 7, 87, 112, 163, 172, 178, 260, 263, 269, 270, 339, 340, 341, 345, 349, 351, 353, 368, 381, 383, 386, 409], "alloc": [87, 333, 342], "eq": [87, 88, 109, 260, 270], "wainwright": [87, 88], "su": 87, "statlearnspars": 87, "incl": [88, 95, 98], "glm": [88, 93, 95, 98, 223, 236, 237], "sk_d2_tweedie_scor": 88, "sk_mean_tweedie_devi": 88, "_p": [88, 90, 118, 221], "2_p": 88, "2_0": 88, "dispers": [88, 93, 95, 98, 104, 125, 183, 190, 193, 194, 201, 217, 218, 224, 226, 228, 231, 236, 239, 295], "compound": [88, 93, 98, 224, 228, 306, 308], "d_0": [88, 98], "d_2": [88, 98, 166, 191, 389], "notin": [88, 98, 150, 223, 226, 230, 237], "curvatur": [88, 136, 170, 248, 254, 309], "_xlogi": [88, 98], "bx": 88, "broadcast_arrai": [88, 98, 234], "_validate_pow": 88, "_check_1d_target": 88, "tweedie_unit_deviance_numpi": 88, "\u03bc": [88, 93, 95, 98, 104, 122, 146, 160, 163, 172, 175, 176, 178, 181, 183, 193, 194, 195, 203, 206, 210, 218, 222, 231, 269], "prevent": [88, 107, 108, 110, 138, 145, 150, 281, 341, 371], "dev": [88, 93, 95, 98, 194, 197, 225, 236, 252, 258, 331, 333, 334, 335, 338, 344, 352, 353, 357, 358, 359, 365, 371, 372], "mean_tweedie_deviance_numpi": 88, "d2_tweedie_score_numpi": 88, "y_avg": 88, "sk_loss": 88, "np_loss": 88, "sk_d2": 88, "np_d2": 88, "underpredict": [88, 93, 102], "downweight": [88, 89, 96, 155], "mu_po": [88, 104], "y_fix": [88, 98], "powers_main": 88, "mu_zero": 88, "y_zero": 88, "powers_zero": 88, "beta_tru": [88, 95, 104, 107, 157], "mu_tru": [88, 93, 95, 98, 104, 160, 172, 176, 181, 183, 188, 189, 203, 214, 218, 222], "\u03bc_pred": 88, "\u03bc_true": 88, "fit_tweedie_glm_gd": [88, 98], "x\u03b2": [88, 104, 122], "\u03b7": [88, 95, 98, 104], "g_eta": 88, "beta_hat": [88, 95, 104, 118, 122, 157], "mu_hat": [88, 98, 114, 163, 168, 172, 176, 181, 183, 189, 194, 203, 208, 214, 217, 218, 222, 223], "mu_true_": 88, "mu_hat_": 88, "mu_baselin": [88, 95], "poissonregressor": [88, 95, 104], "gammaregressor": [88, 93, 104], "tweedieregressor": [88, 98, 104], "x_feat": [88, 168], "x_te": [88, 95, 96, 101, 102, 104, 105, 106, 110], "y_te": [88, 95, 96, 101, 102, 104, 105, 106, 110], "mu_t": 88, "x_tr_i": [88, 104, 108], "x_te_i": [88, 104, 108], "beta_hat_tr": 88, "mu_te_gd": 88, "insur": [88, 93, 98, 104, 154, 169, 172, 187, 196, 197, 231, 236], "claim": [88, 93, 98, 104, 154, 169, 172, 182, 187, 196, 215, 231, 234, 236, 246, 247, 249, 250], "unexplain": [89, 123, 166, 394], "twist": 89, "popul": [89, 95, 96, 100, 163, 196, 213, 214, 232, 234, 239, 243, 244, 245, 250, 258, 259, 262, 264, 265, 266, 267, 269, 311, 312, 313, 314, 315, 316, 317, 345, 348], "ill": [89, 150, 189, 205, 229, 235, 237], "y_signal": 89, "r2": [89, 107, 109, 127, 129, 131, 132, 164, 251, 261], "residual_mean": 89, "residual_var": 89, "xbin": [89, 155, 169, 175], "evs_val": 89, "r2_val": [89, 100], "var_i": [89, 134, 143, 236], "evs_theori": 89, "rng_sim": [89, 269], "evs_sim": 89, "\u03c3\u00b2": [89, 194, 250], "proportion": [89, 153, 213], "\u03c3": [89, 160, 163, 172, 181, 183, 184, 194, 201, 205, 210, 244, 246, 250, 269], "variance_weight": [89, 100], "_weighted_vari": 89, "explained_variance_score_np": 89, "zero_den": 89, "mo": 89, "mean_squared_error_np": [89, 96], "r2_score_np": 89, "assert_allclos": 89, "y_const_pred_const": 89, "y_const_pred_vari": 89, "equal_nan": 89, "y_true_mo": 89, "y_pred_mo": 89, "var_w": 89, "y_clean": [89, 92, 99], "mask_noisi": 89, "y_true_w": 89, "y_pred_w": 89, "score_unweight": 89, "score_weight": 89, "primarili": [89, 158, 162, 346, 349, 353, 359], "instruct": [89, 125], "r_c": 89, "fit_linear_gd": [89, 101], "resid_var": 89, "b_mse": [89, 101], "w_ev": 89, "b_ev": 89, "hist_ev": 89, "b_evs_post": 89, "hoc": [89, 243, 253, 260, 341, 353, 357, 370], "trained_on_ms": 89, "trained_on_ev": 89, "evs_posthoc_intercept": 89, "resid": [89, 112, 116, 117, 120, 123, 124, 127, 131, 132, 208, 246, 271, 297, 298, 394], "y_pred_test_ms": 89, "y_pred_test_ev": 89, "y_pred_test_evs_post": 89, "lin": 89, "coef": [89, 93, 104, 116, 118, 122, 151, 306, 308, 318, 394], "detrend": [89, 112, 281, 284, 301, 317, 322, 323], "maxerror": 90, "ldot": [90, 115, 141, 152, 160, 181, 189, 238, 244, 260, 310], "e_i": [90, 95, 97, 100, 159, 227, 230, 247], "max_i": [90, 150, 172, 174, 179, 184, 198, 206, 209, 215, 217, 238, 241, 249, 256, 288], "abs_error": [90, 91, 99, 101], "max_err_np": 90, "max_err_skl": 90, "max_idx": 90, "y_pred_bas": [90, 99], "max_val": [90, 131], "mae_val": [90, 92, 99, 101], "rmse_val": [90, 99, 101], "max_error_np": 90, "inject": [14, 90, 91, 99, 123, 258, 266, 293, 332, 333, 358, 365, 371, 376], "mx": [90, 100, 180, 230], "b_0": [90, 96, 97, 98, 99, 123, 172, 178, 186, 190, 196, 233], "chebyshev": 90, "slack": [90, 109, 347, 386], "foral": [90, 109, 221, 228], "awkward": [90, 92, 99], "z_j": [90, 247], "b0_true": [90, 96, 97, 98, 99], "b1_true": [90, 96, 97, 98, 99], "outlier_idx": [90, 91], "smooth_ab": 90, "smooth_max": 90, "z_scale": 90, "z_max": 90, "smooth_max_weight": 90, "smooth_max_error_for_lin": 90, "smooth_max_error_gradients_for_lin": 90, "d_obj_dr": 90, "db0": [90, 96, 98], "fit_line_minimax_gd": 90, "smooth_obj": 90, "b0_ol": [90, 96, 97, 99], "b1_ol": [90, 96, 97, 99], "b0_mm": 90, "b1_mm": 90, "summarize_fit": 90, "yhat_lin": 90, "mx_ol": 90, "mx_mm": 90, "y_line_mm": 90, "weights_for_param": 90, "sla": [90, 94, 266, 269], "dictat": 90, "manufactur": [90, 165, 236, 250], "disastr": 90, "rvert_1": 91, "minut": [91, 236, 340, 356, 381, 383, 386], "mae_manu": 91, "mae_sklearn": 91, "middl": [91, 99, 148, 150, 156, 160, 203, 206, 211, 348], "mae_on": 91, "mse_on": 91, "c_argmin": 91, "y_median": 91, "y_mean": [91, 103, 107, 138, 214, 262], "mean_absolute_error_np": 91, "output_error": [91, 92, 94], "laplac": [91, 148, 158, 160, 161, 165, 166, 183, 191, 196, 219, 258], "beta0_tru": [91, 107, 122], "beta1_tru": [91, 107], "ordinari": [91, 92, 96, 100, 107, 178, 208, 214, 233], "y_pred_ol": [91, 92], "mae_ol": [91, 92], "mse_ol": [91, 92], "fit_linear_regression_mae_subgradi": 91, "x_mean": [91, 92, 95, 107, 129, 262], "w_scale": 91, "b_scale": 91, "w_mae": 91, "b_mae": 91, "y_pred_ma": 91, "mae_ma": 91, "mse_ma": 91, "y_line_tru": [91, 92], "y_line_ma": 91, "neg_mean_absolute_error": 91, "test_ma": 91, "cv": [91, 92, 105, 107, 218, 271, 283], "mae_scor": 91, "commun": [0, 91, 92, 160, 190, 193, 201, 205, 270, 335, 355], "23": [75, 92, 103, 107, 109, 110, 115, 135, 142, 143, 146, 217, 235, 240, 241, 246, 286], "102": [92, 99, 116, 138], "ape_pct": 92, "rewrit": [92, 151, 164, 168, 241, 369], "lognorm": [92, 93, 94, 102, 154, 163, 167, 168, 182, 187, 188, 194, 215, 218, 244, 248, 252, 260, 263, 264, 389], "mape_v": 92, "rangemod": 92, "tozero": 92, "showgrid": 92, "shallow": [92, 110], "y_valu": 92, "Near": [92, 102, 154, 156, 161, 164, 172, 187, 189, 195, 197, 203, 229], "wape": [92, 280], "smape": [92, 271, 280, 299], "quirk": [92, 153], "rmsle": [92, 97, 101], "ape_no_guard": 92, "ape_with_ep": 92, "mean_absolute_percentage_error_np": 92, "w_out": 92, "nmultioutput": [92, 100], "1020": 92, "mult": 92, "mape_ol": 92, "fit_linear_regression_mape_subgradi": 92, "wrt": [92, 94, 95, 98, 228], "y_hat2": 92, "w_mape": 92, "b_mape": 92, "b_": [92, 109, 117, 123, 184, 207, 233, 300], "slope_map": 92, "intercept_map": 92, "y_pred_map": 92, "mape_map": 92, "mae_map": 92, "mse_map": 92, "y_line_map": 92, "ape_ol": 92, "ape_map": 92, "boxpoint": 92, "neg_mean_absolute_percentage_error": 92, "mape_cv": 92, "sale": [92, 97, 102, 119, 160, 240, 296], "traffic": [92, 97, 102, 107, 119, 160, 172, 196, 247, 341, 342, 355, 357, 358, 367, 374, 377, 381, 386], "kwh": 92, "hyndman": [92, 116, 119], "athanasopoulo": [92, 116, 119], "otext": 92, "com": [92, 138, 139, 140, 141, 142, 144, 146, 331, 332, 333, 334, 335, 337, 339, 341, 343, 357, 358, 369, 381, 383], "fpp3": 92, "mgd": 93, "const": [93, 98, 106, 108, 116, 122, 148, 158, 178, 184, 185, 203, 221, 228, 229, 232, 233], "overpredict": [93, 98, 102], "2y": [93, 95, 151, 178, 179, 202], "inequ": [93, 160, 230], "rearrang": 93, "format": [93, 127, 131, 132, 135, 137, 145, 246, 296, 332, 335, 382, 385, 389], "mgd_np": 93, "mgd_sklearn": 93, "mean_gamma_deviance_np": 93, "div": [93, 102], "per_sample_gamma": 93, "per_sample_sq": 93, "grad_mean_gamma_deviance_wrt_mu": 93, "mu_pr": [93, 183], "finite_diff_grad": 93, "mu_vec": [93, 194], "g_analyt": [93, 95], "g_numer": [93, 95], "eta_tru": [93, 95], "shape_k": 93, "log10": [93, 95, 160, 178, 184, 197, 215, 228], "mu_train": 93, "mu_test": [93, 218], "fit_gamma_regression_gd": 93, "clip_eta": 93, "w_gd": 93, "mu_pred_test": 93, "gr": 93, "mu_pred_sk": 93, "propto": [93, 95, 96, 104, 106, 108, 112, 135, 148, 151, 153, 156, 158, 160, 161, 165, 166, 167, 170, 176, 178, 179, 182, 184, 198, 201, 202, 210, 212, 215, 227, 228, 229, 232, 234, 241], "price": [93, 98, 102, 118, 122, 123, 183, 214, 296, 306, 349, 388, 391], "rainfal": [93, 98, 169, 172, 173, 187, 216], "mpl": 94, "pred_und": 94, "pred_ov": 94, "loss_und": 94, "loss_ov": 94, "cheap": [94, 135, 152, 153, 166, 168, 169, 185, 190, 193, 353, 379], "downward": [94, 179, 239], "yhat_grid": 94, "\u2113\u03b1": 94, "mean_pinball_loss_np": 94, "g_i": [94, 228, 231], "fit_linear_quantile_regression_subgd": 94, "kink": [94, 177], "beta0": [94, 107, 152, 160, 162, 168, 169, 179, 183, 198, 210, 213, 226, 235, 236, 241], "sigma0": [94, 106, 160, 188, 189, 197, 201, 205, 214, 221], "sigma1": [94, 106, 166], "x_grid": [94, 103, 105, 109, 110, 146, 148, 149, 150, 153, 154, 156, 160, 161, 162, 163, 164, 167, 168, 169, 171, 172, 173, 177, 180, 181, 183, 186, 187, 190, 191, 192, 194, 196, 197, 198, 199, 201, 202, 203, 205, 206, 207, 208, 214, 215, 219, 220, 223, 238, 244, 246, 250, 252, 254, 256, 262, 264], "ppf": [94, 120, 124, 127, 131, 132, 150, 152, 153, 155, 157, 163, 164, 166, 168, 170, 171, 172, 175, 176, 178, 180, 181, 182, 183, 184, 185, 186, 187, 189, 191, 192, 193, 194, 195, 196, 198, 200, 201, 204, 205, 207, 209, 212, 213, 216, 218, 222, 225, 226, 231, 233, 236, 239, 252, 261, 268, 269], "y_true_q": 94, "program": [94, 109, 134, 136, 138, 139, 141, 143, 144, 145, 146, 153, 163, 237, 334, 348, 359], "sk_fit": 94, "w_subgd": 94, "b_subgd": 94, "w_sk": [94, 101], "b_sk": [94, 101], "subgd": 94, "y_hat_subgd": 94, "y_hat_sklearn": 94, "score_subgd": 94, "score_sklearn": 94, "stockout": 94, "overstock": 94, "breach": 94, "slower": [94, 109, 125, 129, 138, 141, 161, 209, 221, 229, 232, 244, 319, 359], "deliveri": [4, 94, 266, 333, 339, 354, 355], "plan": [5, 94, 141, 203, 212, 243, 335, 342, 343, 344, 349, 350, 351, 357, 373, 376, 381, 385], "conserv": [94, 118, 145, 249, 251, 256], "cambridg": 94, "press": 94, "ensur": [95, 98, 138, 139, 146, 150, 153, 181, 189, 195, 209, 227, 268, 296, 310, 314, 348, 367, 375, 377], "beta_0": [95, 107, 120, 122, 162, 224, 241], "mpd": 95, "_to_1d_float": 95, "poisson_deviance_per_sampl": 95, "2\u03bc": 95, "mean_poisson_deviance_np": 95, "mean_poisson_deviance_grad_mu": 95, "lam": [95, 98, 104, 108, 136, 140, 142, 143, 146, 163, 169, 171, 191, 193, 195, 213, 218, 227, 231, 235, 236, 239, 256], "y_true_": 95, "y_pred_": 95, "y_pred_ep": 95, "y_vec": 95, "d_over_i": 95, "poisson_mean_from_eta": 95, "eta_clip": 95, "underflow": [95, 108, 154, 155, 157, 158, 160, 161, 162, 164, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 182, 183, 186, 188, 189, 194, 195, 199, 200, 201, 207, 208, 210, 214, 218, 220, 221, 224, 226, 228, 229, 230, 236, 241], "poisson_regression_loss_and_grad_beta": 95, "incompat": [95, 268], "ridg": [95, 104, 115, 131, 320], "fit_poisson_regression_gd": 95, "beta_next": 95, "te": [95, 102, 160], "baseline_dev": 95, "mu_hat_t": 95, "dev_t": 95, "fit_intercept": [95, 104, 107], "mu_sk_t": 95, "mu_true_t": 95, "dev_baseline_p": 95, "dev_model_p": 95, "max_axi": 95, "tip": [95, 138, 142, 143, 171, 200, 204, 244, 267, 296], "exposur": [14, 95, 183, 236, 239, 261, 394], "leftrightarrow": [95, 100, 203], "mccullagh": [95, 104], "nelder": [95, 104, 155, 163, 165, 166, 168, 175, 199, 210, 212, 225], "wmse": 96, "meter": [96, 236], "meters\u00b2": 96, "sq_error": [96, 101, 102], "\u00b2": [96, 246], "2r": [96, 191, 205, 206], "varepsilon_i": [96, 229], "heteroskedast": [96, 112, 122, 209, 242], "y_true_arr": [96, 97], "y_pred_arr": [96, 97], "mse_per_output": [96, 101], "output_weight": [96, 97, 101], "weight_sum": [96, 97, 193], "mse_raw_np": 96, "mse_raw_sk": 96, "mse_w_np": 96, "mse_w_sk": 96, "mse_wo_np": 96, "mse_wo_sk": 96, "da": [96, 132, 148, 158, 186, 233], "j_w": 96, "y_outlier": 96, "a_grid": [96, 148, 198, 207, 241], "mse_clean": 96, "mse_out": 96, "mu_clean": 96, "mu_out": 96, "mse_at_mu_clean": 96, "mse_at_mu_out": 96, "w_down": 96, "wmse_down": 96, "mu_w": 96, "wmse_at_mu_w": 96, "b_1x_i": 96, "mse_for_lin": 96, "mse_gradients_for_lin": 96, "fit_line_gd": 96, "b0_gd": [96, 97], "b1_gd": [96, 97], "y_hat_gd": 96, "b0_grid": [96, 97, 98, 99], "b1_grid": [96, 97, 98, 99], "b0_path": [96, 97, 98, 99], "b1_path": [96, 97, 98, 99], "contours_color": [96, 97, 98, 99, 107, 154, 187], "bowl": [96, 97, 98], "trajectori": [96, 97, 98, 139, 141, 143, 178, 285], "y_pred_t": [96, 102, 105], "mse_t": 96, "rmse_t": 96, "w_te": 96, "mse_te_w": 96, "min_v": [96, 102], "max_v": [96, 102], "particularli": [96, 149, 151, 160, 164, 186, 190, 202], "root_mean_squared_error_np": 96, "shorthand": [97, 114, 159, 185, 230], "dimensionless": [97, 163, 205, 213], "consequ": [97, 108, 117, 148, 153, 160, 167, 168, 176, 219, 237], "taylor": [97, 212], "closer": [97, 102, 105, 138, 139, 140, 142, 143, 145, 171, 180, 195, 224, 237, 241, 253, 262, 269], "y_grid": [97, 105, 168], "z_grid": [97, 264], "expm1": [97, 102, 153, 154, 160, 161, 164, 165, 171, 172, 187, 196, 199, 200, 201, 213, 215, 216, 217, 220, 227, 235, 238], "rewritten": [97, 103, 113], "geomspac": [97, 184, 196, 199], "sq_log_error": [97, 102], "r0": [97, 220, 262], "driven": [97, 122, 123, 164, 201, 209, 224, 245, 257, 347, 349, 355], "sq_err_ms": 97, "sq_err_msl": 97, "target_log_ratio_sq": 97, "mean_squared_log_error_np": [97, 102], "log_tru": 97, "log_pr": 97, "msle_per_output": [97, 102], "msle_grad_y_pr": 97, "g_ana": 97, "g_num": 97, "y_pred_p": 97, "y_pred_m": 97, "f_p": 97, "f_m": [97, 110], "z_ob": [97, 194], "fit_line_msle_gd": 97, "z_hat": [97, 170], "msle_t": 97, "grad_b0": 97, "grad_b1": 97, "b0_mse": 97, "b1_mse": 97, "y_pred_msl": 97, "y_line_msl": 97, "y_pred_ms": 97, "y_line_ms": 97, "y_pred_mse_clip": 97, "negat": 97, "neg_mean_squared_log_error": 97, "transformedtargetregressor": [97, 102], "neatli": 97, "compos": [97, 102, 183, 281, 301, 306, 323, 334, 335, 371, 384], "x_1d": [97, 110], "func": [97, 102, 127, 131, 132, 167, 209, 237], "inverse_func": [97, 102], "thank": 97, "inventori": [97, 239, 303, 348, 351], "unrealist": [98, 145, 226], "d_p": [98, 105], "wow": 98, "_tweedi": 98, "_devianc": 98, "tweedie_deviance_per_sample_np": 98, "mean_tweedie_deviance_np": 98, "_check_1d_float": 98, "msg": [98, 230, 355, 381, 382], "sk_w": 98, "np_w": 98, "mu_grid": [98, 160, 181, 194, 203, 218, 222, 235], "grad_mu": 98, "severity_j": 98, "severity_shap": 98, "severity_scal": 98, "sev_mean": 98, "exp_clip": 98, "tweedie_glm_loss_and_grad": 98, "grad_eta": 98, "b0_hat": [98, 123, 176], "b1_hat": [98, 123], "mu_line_tru": 98, "mu_line_hat": 98, "mu_sk": [98, 103], "tunabl": [98, 158, 164, 173, 199, 219, 406], "hour": [98, 115, 236, 300, 366], "click": [98, 152, 223, 224, 226, 230, 236, 245], "spent": [98, 150, 152, 246, 381], "spot": [98, 170, 189, 198, 227, 232, 235, 240, 256, 258, 313, 346], "j\u00f8rgensen": 98, "a_n": [99, 172], "medae_np": 99, "medae_sklearn": 99, "mean_ab": 99, "outlier_frac": 99, "medae_v": 99, "medae_with_fraction_outli": 99, "seed_offset": 99, "medae_10": 99, "medae_60": 99, "median_absolute_error_np": 99, "compat": [99, 108, 141, 172, 216, 244, 246, 261, 262, 296, 333, 343, 344, 351, 354, 358, 359], "med_per_output": 99, "nraw_valu": 99, "lceil": 99, "rceil": 99, "tightest": [99, 238], "densest": 99, "best_constant_meda": 99, "ceil": [99, 110, 143, 225, 236, 239, 266, 280], "medae_star": 99, "103": 99, "104": [39, 99, 136, 141], "c_median": [99, 101], "hill": [99, 138, 140, 142, 146], "climb": 99, "warm": [99, 138, 247, 368, 382], "propos": [99, 151, 152, 156, 158, 170, 197, 214], "slowli": [99, 121, 137, 138, 166, 200], "n_out": 99, "is_outli": 99, "medae_for_lin": 99, "fit_line_medae_hillclimb": 99, "b0_init": 99, "b1_init": 99, "8000": [99, 134, 138, 145, 180, 257, 267, 358, 359], "step0": 99, "9995": [99, 179, 193], "step_b0": 99, "step_b1": 99, "cand_b0": 99, "cand_b1": 99, "b0_meda": 99, "b1_meda": 99, "seagreen": [99, 256], "downsampl": [99, 290], "lime": 99, "face": [99, 230, 246, 247], "cleanli": [99, 113, 163, 175, 199, 219, 335], "occasion": [99, 138, 148, 153, 154, 155, 157, 160, 163, 166, 175, 176, 178, 182, 188, 210, 222, 229, 303], "gross": 99, "glitch": 99, "messi": [99, 110, 225], "robust_statist": 99, "leroi": 99, "sk_r2_score": 100, "nmodel": 100, "r2_manual": 100, "r2_sklearn": 100, "sse_val": 100, "sse_over_sst": 100, "mn": [100, 180, 185, 189], "smarter": 100, "sse_grid": 100, "ssr": [100, 398], "someth": [100, 119, 134, 141, 188, 247, 255, 257, 265, 340, 381], "2_w": 100, "r2_score_numpi": 100, "denom_sum": 100, "w_out_sum": 100, "nconstant": 100, "w_close": 100, "r2_hist": 100, "mse_hist": 100, "w_hist": 100, "y_line_gd": 100, "y_line_clos": 100, "accordingli": [100, 203, 369], "stationari": [100, 112, 114, 116, 118, 119, 122, 240, 271], "coefficient_of_determin": 100, "rmse_sklearn": [101, 104], "mae_weight": 101, "mse_weight": 101, "base_residu": 101, "outlier_valu": [101, 267], "df_sweep": 101, "rmse_curv": 101, "mae_curv": [101, 301], "c_mean": [101, 161, 165, 167, 168, 216, 219, 222], "y_top": [101, 267], "signatur": [2, 101, 112, 127, 131, 132, 136, 142, 143, 145, 146, 167, 170, 174, 203, 263], "mse_np": 101, "rmse_np": 101, "rmse_per_output": 101, "y_pred_rand": [101, 102], "sample_w": [101, 102], "train_siz": [101, 106], "df_data": 101, "predict_linear": [101, 102, 107], "w_rmse": 101, "b_rmse": 101, "hist_rms": 101, "train_rms": 101, "test_rms": 101, "df_hist": [101, 102], "w_l": 101, "b_l": [101, 123], "rmse_train_l": 101, "rmse_test_l": 101, "least_squar": 101, "sk_model": 101, "rmse_train_sk": 101, "rmse_test_sk": 101, "neg_root_mean_squared_error": 101, "y_pred_2": 101, "y_hat_t": 101, "resid_t": 101, "msle": 102, "t_i": [102, 192, 228, 230, 249, 295], "neglig": [102, 165, 205, 225, 233, 236, 240], "df_ratio": [102, 142], "t_pred": [102, 192], "df_exampl": 102, "hover_data": 102, "y_true_scal": 102, "scenario": [102, 114, 122, 123, 172, 185, 244, 266], "y_pred_rel": 102, "y_pred_ab": 102, "df_scale": 102, "df_long": [102, 253], "melt": [102, 253, 280, 288], "id_var": [102, 253, 280, 288], "value_var": [102, 280], "var_nam": [102, 253], "value_nam": [102, 253], "log_i": 102, "_check_non_neg": 102, "root_mean_squared_log_error_np": 102, "rmsle_per_output": 102, "caught": 102, "delta_i": 102, "fit_linear_mse_gd": 102, "5e": [102, 143, 258, 262], "y_hat_clip": 102, "fit_log1p_mse_gd": 102, "mse_log": 102, "mse_i": 102, "t_hat": 102, "hist_i": [102, 167, 213], "w_t": [102, 113, 116, 221, 389], "b_t": [102, 178, 218], "hist_t": 102, "y_hat_te_ms": 102, "y_hat_te_log": 102, "df_hist_long": 102, "df_pred": [102, 210], "overweight": 102, "kaggl": 102, "nonparametr": [103, 246, 249, 256, 257, 259, 260, 263, 265, 266, 269], "thought": [103, 166, 183, 231, 234], "plausibl": [103, 125, 148, 149, 160, 161, 164, 169, 172, 173, 183, 184, 191, 199, 211, 212, 217, 219, 220, 222, 242, 244, 248, 250, 253, 254, 255, 256, 261, 262, 263, 264, 265, 266, 267, 269, 270], "advantag": [103, 105, 135, 136, 140, 142, 146, 190, 239, 240], "versatil": 103, "rough": [103, 134, 172, 228, 243, 248, 250, 254, 265], "disadvantag": 103, "multivari": [103, 113, 127, 159, 177, 185, 194, 224, 228, 230, 249, 285, 296, 311, 312, 313, 314, 316, 322], "choleski": [103, 117, 118, 123, 185, 194, 221, 249], "gaussianprocessregressor": 103, "gaussianprocessclassifi": 103, "gaussian_process": 103, "matern": 103, "expsinesquar": 103, "rationalquadrat": 103, "whitekernel": 103, "constantkernel": 103, "neutral": [103, 389], "rbf_kernel": [103, 109], "length_scal": 103, "z_norm": [103, 109], "periodic_kernel": 103, "sample_gp_prior_1d": 103, "kernel_fn": 103, "jitter": [103, 110, 118, 149, 158, 163, 185, 189, 190, 195, 211, 217, 245, 255, 257, 260, 263, 269], "plot_gp_samples_1d": 103, "y_std": 103, "96": [65, 103, 114, 116, 120, 124, 127, 131, 132, 142, 186, 204, 209, 240, 243], "kfn": 103, "k_slice": 103, "samples_rbf_short": 103, "samples_rbf_long": 103, "samples_p": 103, "job": [4, 103, 122, 213, 332, 333, 340, 342, 343, 344, 346, 347, 348, 349, 350, 351, 353, 355, 356, 366, 374, 386], "wiggli": [103, 105, 113], "weakli": [103, 113, 114, 121, 155, 165, 171, 183, 194, 204, 210], "rougher": 103, "k_short": 103, "k_long": 103, "bmatrix": [103, 107, 118, 205], "sigma_": [103, 107, 146, 167, 185, 188, 189, 199, 221], "gp_posterior_regress": 103, "noise_vari": 103, "triangular": [103, 185, 206, 211, 221], "k_ss": 103, "log_marginal_likelihood_zero_mean": 103, "log_det": [103, 144, 189], "f_true": 103, "posterior_sampl": 103, "noiseless": 103, "nv": 103, "mu_c": [103, 167, 199, 249], "cov_c": 103, "std_c": 103, "account": [103, 122, 209, 225, 249, 343, 344, 347, 349, 350, 351, 353, 354], "redund": 103, "bottleneck": [103, 407], "lml": 103, "ns": [103, 221, 257, 258], "ls": [103, 149, 358, 359], "k_ij": 103, "best_nois": 103, "best_l": 103, "adapt": [103, 113, 143, 263, 266, 303], "gp_std_on_grid": 103, "cov_": [103, 106], "x_train_a": 103, "y_train_a": 103, "std_befor": 103, "std_after": 103, "uncertain": [103, 113, 225, 228], "gpr": 103, "normalize_i": 103, "n_restarts_optim": 103, "optima": [103, 155, 192, 195], "1e2": [103, 168, 178, 184], "length_scale_bound": 103, "noise_level_bound": 103, "1e0": [103, 184], "kernel_": 103, "log_marginal_likelihood": 103, "std_sk": 103, "return_std": [103, 140], "136": [103, 168], "rgb": 103, "anymor": 103, "kernel_rbf": 103, "gpc_rbf": 103, "max_iter_predict": 103, "named_step": 103, "gpc_matern": 103, "proba_rbf": 103, "proba_mat": 103, "ard": 103, "fourier": [103, 115, 116, 122, 124, 222, 323], "realist": [103, 160, 165, 184, 202, 215, 241, 258, 331, 332, 333, 378, 385, 386], "rasmussen": 103, "william": 103, "reweight": [104, 170], "pdf": [104, 149, 153, 164, 172, 177, 184, 196, 204, 206, 216, 223, 226, 228, 236, 246, 248, 250, 252, 254, 256, 258, 261, 264, 267, 268, 269, 389], "newton": [104, 135, 158], "gamma_dist": [104, 148, 220], "invgauss": 104, "anecdot": [104, 106, 108], "thermostat": 104, "freeli": [104, 153, 203, 218, 247, 359], "physic": [104, 112, 113, 151, 157, 174, 175, 184, 186, 188, 194, 197, 204, 206, 213, 214, 215, 216, 219, 220, 227, 235], "\u00b9": [104, 252], "mu_ident": 104, "mu_sigmoid": 104, "mu_exp": 104, "multinomi": [104, 134, 159, 224, 246, 247], "mu_k": [104, 106, 156, 174, 199, 243, 289, 295], "9999": [30, 104, 134, 163, 171, 193, 202, 225, 252], "bern_y1": 104, "bern_y0": 104, "pois_dev": 104, "tailor": 104, "galleri": 104, "xg": [104, 185, 192, 195, 197], "mu_param": 104, "scale_param": 104, "fisher": [104, 136, 140, 146, 159, 166, 172, 177, 180, 181, 184, 198, 206, 214, 221, 233, 238, 246, 258, 262, 263], "irls_logistic_regress": 104, "sqrt_w": 104, "zw": 104, "beta_new": 104, "470": [104, 108], "pred_scratch": [104, 108], "pred_sklearn": [104, 108], "plot_probability_surface_2d": 104, "model_proba_fn": 104, "irls_poisson_regress": 104, "xp": [104, 220], "xp_i": 104, "xp_tr": 104, "xp_te": 104, "yp_tr": 104, "yp_te": 104, "xp_tr_i": 104, "xp_te_i": 104, "beta_p": 104, "losses_p": 104, "sk_p": 104, "mu_hat_scratch": 104, "mu_hat_sklearn": 104, "rmse_scratch": 104, "heavier": [104, 150, 154, 157, 158, 160, 161, 167, 168, 173, 176, 177, 181, 182, 183, 192, 195, 196, 199, 203, 207, 209, 210, 215, 218, 219, 220, 222, 225, 229, 235, 240, 242, 248, 258, 266, 269], "growth": [104, 115, 155, 160, 168, 386], "unif": [104, 150, 155, 156, 161, 175, 180, 181, 182, 196, 197, 199, 206, 207, 212, 213, 216, 218, 227, 235, 252], "1800": [104, 108], "xg_i": 104, "k_shape": 104, "y_gamma": 104, "xg_tr": 104, "xg_te": 104, "yg_tr": 104, "yg_te": 104, "m_gamma": 104, "m_ig": 104, "pred_gamma": 104, "pred_ig": 104, "eta_k": 104, "beta_k": 104, "capabl": [104, 285, 311, 312, 338], "y3": [104, 106, 132, 192, 265], "x3_tr": [104, 106], "x3_te": [104, 106], "y3_tr": [104, 106], "y3_te": [104, 106], "m_multi": 104, "educ": [104, 105, 110, 129, 193, 219, 237, 270], "shrinkag": [104, 107, 158, 176], "lazi": [105, 345, 399], "kneighborsclassifi": 105, "kneighborsregressor": 105, "rent": 105, "organ": [105, 205, 283, 296, 346], "weird": 105, "minkowski": 105, "max_c": 105, "kilomet": 105, "millimet": 105, "x_circl": 105, "y_circl": 105, "x_diamond": 105, "y_diamond": 105, "y\u00b2": 105, "lookup": [105, 123, 267, 288, 300, 318, 385], "pairwise_minkowski_dist": 105, "x_queri": [105, 125], "2ab": [105, 167], "q_sq": [105, 125], "t_sq": [105, 125], "kneighbors_indices_and_dist": 105, "exce": [105, 127, 129, 142, 149, 151, 174, 209, 219, 224, 260], "unsort": 105, "d_k": [105, 169], "idx_sort": [105, 125], "d_sort": 105, "scratchknnclassifi": 105, "classes_": [105, 106, 108, 110], "y_encoded_": 105, "_weight": 105, "neighbor_label": 105, "scratchknnregressor": 105, "y_neighbor": 105, "scratch_knn": 105, "xq": [105, 125], "pt": [105, 159, 185, 189, 254], "plot_knn_boundary_2d": 105, "hasattr": [105, 109, 115, 136, 139, 221, 228, 310, 311, 312, 313, 314, 315, 316, 317], "z_titl": 105, "advic": 105, "opinion": [105, 334], "hundr": [105, 318], "nich": 105, "accuracy_for_k": 105, "acc_uniform": 105, "acc_dist": 105, "n_reg": 105, "x_reg": [105, 110], "noise_reg": 105, "y_reg": [105, 110, 119], "x1_tr": 105, "y_tr_reg": 105, "x1_te": 105, "y_te_reg": 105, "m_uniform": 105, "m_distanc": 105, "x_2": [105, 159, 189, 193, 195, 228, 230, 239], "NOT": [105, 115], "ptp": 105, "xb_tr": 105, "xb_te": 105, "yb_tr": 105, "yb_te": 105, "m_raw": 105, "acc_raw": 105, "pipe": [105, 281, 323, 324, 325], "acc_scal": 105, "NO": 105, "_sklearnwrapp": 105, "farthest": 105, "nearer": 105, "lose": [105, 167, 188, 212, 227, 235, 236, 374], "nn_distance_ratio": 105, "n_point": [105, 106], "xd": [105, 127], "interfac": [105, 115, 124, 141, 177, 357], "ball_tre": 105, "kd_tree": 105, "leaf_siz": 105, "sk_knn": 105, "grown": 105, "param_grid": [105, 310], "knn__n_neighbor": 105, "knn__weight": 105, "knn__p": 105, "gs": 105, "best_params_": [105, 310], "best_score_": 105, "best_estimator_": 105, "valuabl": [8, 105], "weigh": 105, "lineardiscriminantanalysi": 106, "quadraticdiscriminantanalysi": 106, "discriminant_analysi": 106, "worldview": 106, "judg": 106, "novelist": 106, "sigma_k": [106, 156, 244, 252, 259, 289], "mu0": [106, 157, 160, 168, 176, 181, 183, 188, 189, 192, 194, 197, 203, 210, 214, 218, 222, 239, 266, 268, 269, 270], "mu1": [106, 175, 183, 225, 239, 267], "covariance_ellipse_point": 106, "n_std": 106, "ellips": [106, 254], "vec": [106, 185], "radii": [106, 205], "mu0_hat": 106, "mu1_hat": [106, 239], "s0_hat": 106, "s1_hat": 106, "x0e": 106, "y0e": 106, "x1e": 106, "y1e": 106, "2\u03c3": [106, 113, 201], "delta_k": 106, "hyperplan": [106, 109], "scratchlda": 106, "y_enc": [106, 108, 110], "priors_": 106, "means_": 106, "unbias": [106, 183, 189, 194, 221, 232, 233, 244, 250, 267], "precision_": 106, "_w_": 106, "_b_": 106, "scratchqda": 106, "covs_": 106, "precisions_": 106, "logdets_": 106, "slogdet": [106, 118, 221], "maha": 106, "scratch_lda": 106, "scratch_qda": 106, "sk_lda": 106, "sk_qda": 106, "reg_param": 106, "pred_lda_": 106, "pred_qda_": 106, "pred_lda": 106, "pred_qda": 106, "nclassif": 106, "plot_boundari": 106, "780": 106, "540": 106, "fig3": [106, 136, 173], "fig4": [106, 136], "sample_gaussian_dataset": 106, "acc_lda": 106, "acc_qda": 106, "m_lda": 106, "m_qda": 106, "lda_proj": 106, "ld1": 106, "ld2": 106, "getattr": [106, 109, 110, 115, 127, 138, 139], "hello": [107, 349, 356], "rich": [107, 131, 240], "teach": 107, "analog": [107, 118, 119, 140, 176, 182, 227, 235], "someon": [107, 384], "commut": 107, "board": 107, "clever": [107, 197], "beta_1": [107, 120], "n_samples_simpl": 107, "x_simpl": 107, "y_simpl": 107, "beta1_hat": 107, "beta0_hat": 107, "y_line": 107, "y_pred_simpl": 107, "compactli": [107, 119, 158], "vdot": [107, 118], "ddot": [107, 118], "beta_d": 107, "cowork": 107, "credit": [107, 138, 141], "n_samples_multi": 107, "feature_nam": [107, 110], "true_intercept": 107, "true_beta": [107, 394], "y_multi": 107, "rowvar": [107, 159, 185, 189], "add_intercept_column": 107, "ols_via_lstsq": 107, "ols_via_normal_equation_solv": 107, "xtx": 107, "xty": 107, "ols_via_choleski": 107, "spd": [107, 185, 189, 221], "beta_lstsq": 107, "beta_solv": 107, "beta_chol": 107, "downhil": 107, "beta_gd": 107, "gd_step": 107, "gd_loss": 107, "gd_beta": 107, "gradient_descent_linear_regress": 107, "beta0_grid": 107, "beta1_grid": 107, "y_pred_grid": 107, "mse_grid": 107, "belt": 107, "damp": [107, 120, 135, 136, 140, 146], "budget": [107, 121, 134, 152, 159, 409], "spend": [107, 122, 263], "unscale_coeffici": 107, "beta_sc": 107, "feature_mean": 107, "feature_std": 107, "target_mean": 107, "y_center": 107, "beta_origin": 107, "intercept_origin": 107, "x_train_scal": 107, "y_train_mean": 107, "y_train_cent": 107, "x_test_scal": 107, "ridge_closed_form": 107, "ridge_coefs_sc": 107, "xaxis_typ": [107, 153, 196, 215, 233], "fit_ridge_and_scor": 107, "lz": [107, 189], "ridge_via_choleski": 107, "alpha_demo": 107, "alphas_ridg": 107, "val_ms": 107, "best_alpha": 107, "4g": [107, 165, 258, 262], "soft_threshold": [107, 176], "lasso_coordinate_desc": 107, "warm_start": 107, "feature_norm": 107, "beta_prev": 107, "lasso_coefs_sc": 107, "beta_w": 107, "fit_lasso_and_scor": 107, "num_nonzero": 107, "l1_ratio": 107, "elastic_net_coordinate_desc": 107, "enet_coefs_sc": 107, "squared_error": [107, 110], "invscal": 107, "eta0": 107, "cyclic": [107, 167], "islr": [107, 110], "jame": [107, 110], "witten": [107, 110], "stream": [4, 108, 113, 160, 239, 339, 340, 343, 349, 382, 383], "naive_bay": 108, "bernoullinb": [108, 223], "p_d": 108, "false_positive_r": 108, "p_d_given_po": 108, "condition": [108, 111, 121, 224, 226, 263], "crazi": 108, "sound": 108, "computation": [108, 191, 211, 290], "x_corr": 108, "y_corr": 108, "corr0": 108, "corr1": 108, "pi_c": 108, "wiggl": [108, 110], "scratchgaussiannb": 108, "var_smooth": 108, "class_count_": 108, "class_prior_": 108, "theta_": [108, 114, 123, 135, 140, 142, 143, 146, 222], "var_": [108, 157, 160, 164, 165, 170, 173, 176, 185, 193, 215, 219, 229, 241, 255], "overall_var": 108, "epsilon_": [108, 297, 298], "_joint_log_likelihood": 108, "log_prior": [108, 148, 151, 155, 160, 161, 165, 167, 174, 175, 176, 181, 184, 188, 193, 197, 200, 204, 213, 216, 218, 227, 233, 234, 240, 241], "jll": 108, "2\u03c0": [108, 178, 184, 222], "var_j": 108, "mean_j": 108, "log_norm": [108, 158, 159, 177, 189, 210, 221, 227, 228, 269], "x_g": 108, "y_g": 108, "x_tr_g": 108, "x_te_g": 108, "y_tr_g": 108, "y_te_g": 108, "scratch_gnb": 108, "sk_gnb": 108, "plot_proba_boundary_2d": 108, "deploy": [108, 331, 332, 333, 334, 336, 338, 343, 344, 345, 346, 351, 364, 368, 370, 371, 372, 374, 375, 383], "oversmooth": 108, "wash": 108, "theta_c": 108, "unseen": 108, "kill": 108, "haven": 108, "unicorn": 108, "spam": 108, "imposs": [108, 214, 215], "make_synthetic_text_dataset": 108, "vocab_s": 108, "avg_len": 108, "base0": 108, "base1": 108, "sharpen": 108, "theta0": [108, 119, 163, 165, 166, 210, 212, 224], "theta1": [108, 116, 224], "pval": [108, 176, 212, 217, 248, 266], "vocab": [108, 230], "x_count": 108, "y_text": 108, "x_tr_t": 108, "x_te_t": 108, "y_tr_t": 108, "y_te_t": 108, "idx0": 108, "idx1": [108, 125], "scratchmultinomialnb": 108, "fit_prior": 108, "class_count": [108, 110], "class_log_prior_": 108, "feature_count": 108, "smoothed_fc": 108, "smoothed_cc": 108, "feature_log_prob_": 108, "scratch_mnb": 108, "sk_mnb": 108, "force_alpha": 108, "class_prior": 108, "overrid": 108, "presenc": [108, 131, 193, 204], "absenc": 108, "binar": 108, "x_tr_bin": 108, "x_te_bin": 108, "m_mnb": 108, "m_bnb": 108, "acc_mnb": 108, "acc_bnb": 108, "wa": [108, 114, 122, 134, 143, 167, 240, 263, 389], "x_counts_imb": 108, "y_imb": 108, "y_tr_i": 108, "y_te_i": 108, "m_mnb_i": 108, "m_cnb_i": 108, "pred_mnb": 108, "pred_cnb": 108, "browser": [108, 403], "chrome": 108, "safari": 108, "firefox": 108, "countri": [108, 266, 385], "transport": [108, 218], "sunni": 108, "raini": 108, "overcast": 108, "car": [108, 230], "bu": [108, 207, 347], "bike": 108, "go_out": 108, "stay_in": 108, "p_go_out": 108, "y_cat": 108, "x_cat": 108, "x_tr_c": 108, "x_te_c": 108, "y_tr_c": 108, "y_te_c": 108, "m_cat": 108, "acc_cat": 108, "combo": [108, 189], "labels_weath": 108, "labels_transport": 108, "min_categori": 108, "increment": [108, 119, 186, 195, 236, 239], "suffici": [108, 112, 118, 151, 157, 167, 172, 173, 192, 244, 257, 266], "stream_synthetic_text_batch": 108, "n_batch": [108, 143], "x_test_stream": 108, "y_test_stream": 108, "12000": [108, 134, 144, 248], "m_stream": 108, "x_batch": 108, "y_batch": 108, "widest": 109, "qp": 109, "make_circl": 109, "plot_svm_decision_2d": 109, "show_margin": 109, "grid_r": 109, "zz": [109, 164, 171], "444": [109, 119, 125], "support_vectors_": 109, "sv": 109, "clf_linear": 109, "stationar": [109, 113, 114, 116, 117, 121, 122, 125, 139, 172, 297, 298, 323, 390], "inact": 109, "heart": [109, 143], "alpha_i": [109, 111, 132, 159, 169, 228], "alpha_j": [109, 159, 228], "clf_almost_hard": 109, "1e6": [109, 159, 163, 175, 178, 190, 215, 224, 227, 266], "w_sklearn": 109, "b_sklearn": 109, "y_alpha": 109, "dual_coef_": 109, "n_support": 109, "w_from_dual": 109, "04260136446471105": 109, "y2_01": 109, "130": [109, 139, 145], "xs2": [109, 198], "widen": [109, 119, 184, 212], "838": 109, "67": [93, 109, 110, 134, 146, 193, 240], "831": 109, "56": [109, 116, 122, 136, 141], "c_0": [109, 153, 174, 178], "coef0": [109, 132], "kernelnam": 109, "_gamma_scal": 109, "linear_kernel": 109, "polynomial_kernel": 109, "yc01": 109, "yc": [109, 265], "config": [109, 139, 144, 211, 333, 334, 335, 339, 358, 359, 365, 371, 372, 374, 385], "deg": 109, "kernelsvmclassifiersmo": 109, "max_pass": 109, "_kernel_matrix": 109, "alphas_": 109, "f_i": [109, 242], "num_chang": 109, "ei": [109, 153, 184], "ej": 109, "aj": 109, "ai_old": 109, "aj_old": 109, "aj_new": 109, "ai_new": 109, "b_new": [109, 232], "support_": 109, "svm_scratch": 109, "svm_sklearn": 109, "acc_scratch": [109, 110], "acc_sklearn": [109, 110], "000": [22, 25, 41, 75, 81, 96, 99, 100, 108, 109, 122, 125, 142, 146, 228], "sibl": 109, "kernelsvrqp": 109, "alpha_star": 109, "g_beta": 109, "g_alpha": 109, "g_alpha_star": 109, "jac": [109, 159, 167, 228], "slsqp": 109, "ftol": 109, "maxit": [109, 120, 122, 124, 155, 168, 175, 209, 212], "disp": [109, 116, 120, 122, 124, 209], "alpha_star_": 109, "beta_": [109, 189, 394], "f_no_b": 109, "mask_up": 109, "mask_lo": 109, "b_val": 109, "xr": [109, 267], "yr": [109, 267], "x_scaler": 109, "x_grid_": [109, 199], "svr_qp": 109, "svr_sk": 109, "pred_qp": 109, "pred_sk": 109, "train_pred_qp": 109, "train_pred_sk": 109, "sv_idx": 109, "01262595102773146": [], "977980144024106": [], "012624597718471414": 109, "977982504216612": 109, "linearsvr": 109, "tighter": [109, 152], "enabl": [109, 139, 143, 149, 153, 172, 174, 211, 216, 281, 305, 331, 332, 334, 335, 339, 341, 347, 350, 352, 359, 376, 382], "2004": [109, 160, 263], "tutori": 109, "quickli": [110, 118, 132, 151, 158, 164, 165, 169, 170, 171, 188, 210, 218, 224, 228, 229, 230, 231, 234, 235, 250, 254, 264, 329, 371], "cart": [110, 341], "decisiontreeclassifi": 110, "decisiontreeregressor": [110, 127, 129], "export_text": 110, "randomforestclassifi": 110, "randomforestregressor": [110, 306], "histgradientboostingclassifi": 110, "Is": [110, 112, 247, 250, 262, 266, 269, 340], "m\u00b2": 110, "220k": 110, "310k": 110, "420k": 110, "children": 110, "purer": 110, "parent": [110, 209], "n_l": 110, "n_r": 110, "gini_impur": 110, "information_gain": 110, "y_left": 110, "y_right": 110, "impurity_fn": 110, "n_left": [110, 212], "n_right": [110, 212], "child": [110, 331], "y_1d": 110, "midpoint": [110, 176, 217], "ig_gini": 110, "ig_entropi": 110, "best_t_gini": 110, "best_t_entropi": 110, "orang": [110, 142, 159, 247, 284, 289, 299], "abstract": [110, 114, 134, 186, 223, 334], "g_parent": 110, "g_left": 110, "g_right": 110, "counts_par": 110, "counts_left": 110, "counts_right": 110, "greedi": [110, 134, 139, 140], "prune": [110, 331, 358], "max_depth": [110, 127, 129], "min_samples_split": 110, "min_samples_leaf": [110, 127, 129], "max_featur": 110, "feature_index": 110, "_resolve_max_featur": 110, "unsupport": [110, 143], "decisiontreeclassifierscratch": 110, "root_": 110, "_rng": [110, 139, 141], "_impur": 110, "_best_split": 110, "parent_impur": 110, "feature_indic": 110, "best_gain": 110, "best_featur": 110, "best_threshold": 110, "x_col": 110, "_build": 110, "predicted_class": 110, "left_mask": 110, "y_raw": 110, "_predict_on": 110, "x_row": 110, "readi": [110, 153, 154, 156, 182, 197, 208, 252, 255, 303, 327, 331, 348, 350, 351, 352, 367, 374, 377], "plot_decision_boundari": 110, "7aa6ff": 110, "ff8c7a": 110, "scratch_tre": 110, "sk_tree": 110, "print_scratch_tre": 110, "indent": [110, 228], "array2str": 110, "floatmod": 110, "puriti": 110, "leaf": 110, "decisiontreeregressorscratch": 110, "parent_var": 110, "best_reduct": 110, "child_var": 110, "blocki": 110, "xr_tr": 110, "xr_te": 110, "yr_tr": 110, "yr_te": 110, "single_reg": 110, "rf_reg": 110, "n_estim": [110, 127, 129, 289, 294, 306, 321], "mse_singl": 110, "mse_rf": 110, "newer": [110, 139, 143], "ccp_alpha": 110, "sk_tree_smal": 110, "learner": [110, 288], "bootstrap": [110, 127, 136, 138, 139, 141, 142, 143, 145, 146, 148, 149, 160, 163, 164, 167, 171, 172, 173, 179, 180, 195, 197, 206, 212, 213, 214, 215, 218, 219, 220, 224, 228, 240, 241, 256, 259, 262, 263, 266, 267, 268, 269, 331], "decorrel": [110, 139], "expert": [110, 211, 212], "inconsist": [110, 162, 206, 246, 248, 250, 258, 266], "randomforestclassifierscratch": 110, "trees_": 110, "1_000_000_000": 110, "acc_singl": 110, "acc_forest": 110, "spiki": [110, 158, 164, 182, 191, 341], "oob_scor": 110, "rf": [110, 394], "acc_rf": 110, "oob_score_": 110, "feature_importances_": 110, "randomforest": 110, "student": [110, 121, 155, 157, 192, 194, 207, 250, 252, 262, 263, 264, 268], "x_tr2": 110, "x_val2": 110, "y_tr2": 110, "y_val2": 110, "gb": [110, 252], "staged_predict_proba": 110, "best_it": 110, "gbdt": 110, "oblivi": 110, "num_boost_round": 110, "num_iter": 110, "min_child_weight": 110, "num_leav": 110, "min_data_in_leaf": 110, "bagging_fract": 110, "colsample_bytre": 110, "feature_fract": 110, "rsm": 110, "reg_lambda": 110, "lambda_l2": 110, "l2_leaf_reg": 110, "reg_alpha": 110, "lambda_l1": 110, "counterbal": 110, "lib": [89, 110, 115, 127, 131, 132, 134, 135, 136, 137, 138, 139, 141, 143, 144, 145, 146, 151, 160, 201, 209, 230, 240, 358, 359, 373, 378, 389], "mod": [110, 120, 222], "ver": 110, "__name__": [110, 127, 237, 238, 286, 287, 289, 292, 311, 312, 313, 314, 315, 316, 317, 389], "decisiontre": 110, "histgradientboost": 110, "offici": [110, 115, 337], "varepsilon_t": [111, 112, 114, 115, 116, 117, 119, 120, 121, 122, 123, 195], "homoskedast": 111, "past": [111, 112, 114, 116, 117, 118, 121, 123, 125, 129, 271, 285, 328, 334, 371], "garch": [111, 390], "liquid": 111, "daili": [111, 115, 120, 124, 129, 172, 226, 271, 300, 366], "persist": [111, 114, 117, 121, 123, 304, 307, 345, 385], "shortfal": [111, 121], "stress": [111, 121, 148, 165, 167, 171, 172, 209, 216, 255, 395], "leverag": [111, 121, 249, 262], "execut": [111, 146, 332, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357], "placement": [111, 234], "impact": [111, 112, 121, 122, 379, 383], "hit": [111, 117, 140, 156, 178, 179, 189, 199, 211, 217, 218, 219, 231, 232, 367, 371], "innov": [111, 113, 116, 117, 118, 121, 122, 123, 195, 240], "varepsilon_": [111, 114, 119, 120, 121, 249], "recent": [75, 107, 111, 112, 114, 127, 131, 132, 135, 136, 137, 142, 153, 201, 207, 209, 213, 217, 230, 232, 250, 261, 271, 275, 281, 290, 291, 293, 294, 297, 298, 302, 304, 305, 307, 309, 310, 319, 320, 321, 323, 324, 325, 326, 340, 382, 389], "omega": [111, 121, 151, 153, 156, 157, 158, 164, 167, 171, 182, 183, 186, 192, 198, 200, 201, 202, 211, 212, 213, 214, 215, 219, 227, 228, 229, 230, 232, 235, 237, 238], "pin": [111, 195, 333, 335, 346, 358], "simulate_arch": 111, "burn": [111, 121, 165, 188], "eps_t": [111, 112, 116, 119, 122], "eps_": [111, 119], "alpha_sum": 111, "h_bar": [111, 121], "lagged_eps_sq": 111, "arch_conditional_vari": 111, "initial_vari": [111, 121], "arch_forecast_vari": 111, "horizon": [111, 112, 117, 118, 121, 122, 123, 125, 127, 131, 134, 138, 140, 141, 143, 275, 280, 285, 299, 305, 308, 328], "eps_sq_lag": 111, "eps_sq": [111, 121], "h_fore": [111, 121], "lookback": [111, 121], "hist_x": [111, 121, 167, 213], "fore_x": [111, 121], "histor": [111, 119, 121, 143, 237, 271, 333], "lag": [111, 113, 114, 116, 119, 120, 121, 122, 123, 124, 127, 129, 131, 132, 271, 297, 298, 323, 329], "statsmodel": [112, 116, 119, 120, 122, 124, 271, 297, 298], "jupyt": 112, "todai": [112, 114, 118, 119, 125, 347, 389], "univari": [112, 113, 118, 119, 125, 127, 129, 148, 155, 159, 166, 173, 185, 189, 220, 228, 230, 285, 297, 298, 309, 323], "y_0": [112, 125], "varphi_1": [112, 122], "varphi_p": 112, "autocorrel": [112, 113, 116, 117, 119, 122, 123, 129, 242, 248, 297, 298, 302, 325], "acf": [112, 116, 119, 120, 122, 124, 127, 131, 132], "differenc": [112, 113, 122, 271, 297, 298, 315], "varphi_i": [112, 120, 207, 222], "uncondit": [112, 121, 122], "uncorrel": [112, 114, 119, 189], "autocovari": [112, 117, 119], "govern": [112, 113, 221, 347, 353], "varphi_2": 112, "shock": [112, 113, 114, 116, 118, 119, 125, 179, 207, 210], "oscil": [112, 235], "underdamp": 112, "arima": [112, 114, 254, 271, 298, 302], "holdout": [112, 122], "pacf": [112, 119, 122], "suggest": [112, 119, 122, 171, 200, 209, 246, 248, 251, 260, 264], "2k": [112, 124, 163, 166, 188, 191], "rss": 112, "sum_t": [112, 119, 129], "simulate_ar": 112, "burn_in": [112, 118, 119], "phi_i": [112, 119, 297, 298], "make_lagged_matrix": 112, "include_intercept": 112, "y_target": [112, 125, 306], "lag_col": 112, "fit_ar_ol": 112, "y_hat_target": 112, "n_eff": [112, 256], "sigma2": [112, 119, 122, 166, 185, 189, 270, 288], "forecast_ar": 112, "y_histori": 112, "y_hist": [112, 117, 123, 125], "y_next": [112, 125, 127, 129, 131, 132], "aic_bic_from_rss": 112, "ar_stationari": 112, "coeff": [112, 114, 119, 165, 174, 244], "phi1": [112, 116, 122], "phip": 112, "nlag": [112, 119, 271], "examin": [112, 122], "phi_tru": [112, 119], "c_true": [112, 153, 154, 161, 172, 173, 174, 180, 199, 200, 202, 211, 215, 219, 220, 222], "sigma_tru": [112, 172, 183, 184, 185, 188, 189, 201, 205, 214, 221], "is_stat": 112, "train_n": 112, "unnecessari": [112, 116], "p_max": [112, 118], "rss_list": 112, "mse_dyn": 112, "y_fc": 112, "p_best_aic": 112, "p_best_bic": 112, "p_show": 112, "fairli": [112, 243, 255, 267, 268, 280], "p_best": 112, "fit_best": 112, "x_full": 112, "y_target_ful": 112, "y_hat_target_ful": 112, "y_hat_ful": 112, "spike": [112, 116, 127, 129, 150, 158, 161, 164, 172, 174, 206, 229, 242, 251, 340, 355, 381], "res_acf": 112, "y_stat": 112, "y_nonstat": 112, "\u03c6": [112, 151, 155, 160, 163, 164, 173, 175, 176, 178, 184, 200, 207, 210, 211, 212, 216, 236, 252, 261, 264], "done": [112, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 157, 169, 171, 172, 184, 191, 193, 195, 196, 204, 220, 231, 234, 245, 333, 338, 342, 344], "crucial": [112, 125, 145, 150, 175, 245, 257, 260, 269], "u2192": [113, 229, 253], "cycl": [113, 116, 167, 172, 305], "platform": [113, 135, 137, 138, 155, 168, 175, 177, 178, 181, 182, 185, 192, 204, 207, 210, 222, 261, 267, 269, 331, 332, 334, 335, 344, 346, 348, 358], "python_vers": [113, 135, 137, 138, 155, 168, 175, 177, 178, 181, 182, 185, 192, 204, 207, 210, 222, 267, 269], "onlin": [113, 139, 141, 145, 351], "arriv": [113, 151, 162, 169, 213, 228, 231, 236, 239, 303, 347], "markov": [113, 139], "veloc": [113, 134, 141, 144, 146, 186], "kf": [113, 240], "ekf": 113, "unscent": 113, "ukf": 113, "particl": [113, 151, 157, 175, 186, 188, 204], "_0": [113, 162, 165, 170, 171, 198, 207, 213, 230, 247, 261], "action": [113, 136, 137, 140, 141, 142, 143, 145, 146, 196, 333, 335, 340, 344, 384], "unmodel": 113, "disturb": [113, 114, 123], "incorpor": 113, "v_t": [113, 146], "k_t": [113, 234], "lean": [113, 175, 198], "ma": [113, 116, 119, 120, 122, 124, 138, 139, 140, 142, 144, 145, 308], "arma": [113, 114, 116, 117, 123, 124, 271, 297, 298, 300], "sarima": [113, 114, 119], "irregular": [113, 271], "fusion": 113, "imu": 113, "radar": [113, 190, 193, 201, 205], "sonar": [113, 190, 201, 205], "robot": [113, 222], "feedback": [113, 117, 118, 122, 123], "lqg": 113, "lqr": 113, "industri": 113, "aircraft": 113, "spacecraft": 113, "nowcast": 113, "semidefinit": [113, 189, 221], "gate": [113, 333, 336], "overreact": 113, "p_t": [113, 303], "make_constant_velocity_model": 113, "dt": [113, 115, 141, 144, 146, 148, 152, 154, 157, 160, 168, 170, 171, 173, 175, 192, 195, 199, 202, 203, 204, 208, 210, 214, 216, 225, 233, 296], "sigma_a": 113, "sigma_z": 113, "simulate_lgssm": 113, "sigma_a_tru": 113, "sigma_z_tru": 113, "q_true": 113, "r_true": [113, 234], "x0_true": 113, "x_true": 113, "y_ob": [113, 202, 211], "joseph": 113, "kalman_filt": 113, "x_pred": 113, "p_pred": [113, 228, 231], "x_filt": 113, "p_filt": 113, "x_prev": 113, "p_prev": 113, "u_t": [113, 118, 119, 120, 122], "x_pr": 113, "p_pr": 113, "isnan": [113, 209, 252, 255, 263, 268, 269], "s_t": [113, 116, 124, 134, 136, 137, 139, 140, 141, 142, 143, 144, 150, 195, 271, 329, 389], "pht": 113, "x0_guess": 113, "p0_guess": 113, "rmse_po": 113, "rmse_vel": 113, "u00b12": 113, "u03c3": 113, "pos_tru": 113, "pos_ob": 113, "pos_est": 113, "pos_std": 113, "pos_var_pr": 113, "pos_var_filt": 113, "vel_var_pr": 113, "vel_var_filt": 113, "filt": 113, "vel": [113, 144], "xaxis2_titl": 113, "yaxis2_titl": 113, "sigma_a_grid": 113, "sigma_z_grid": 113, "colors_a": 113, "colors_z": 113, "9467bd": 113, "8c564b": 113, "e377c2": 113, "runs_a": 113, "q_assum": 113, "r_assum": 113, "runs_z": 113, "\u03c3_a": 113, "\u03c3_z": 113, "dup": 113, "x_f": 113, "p_f": [113, 252, 253, 259], "compens": [113, 356], "destabil": [113, 138, 139], "psd": [113, 132, 221], "v_x": [113, 186], "v_y": [113, 186], "command": [113, 332, 333, 334, 335, 346, 348, 370], "dan": 113, "simon": [113, 190, 205], "kevin": 113, "murphi": 113, "perspect": [113, 236, 243, 263], "filter": [114, 117, 122, 123, 189, 194, 267, 287, 288, 312, 313, 314, 316, 347, 354, 357, 381, 382, 384, 385], "theta_1": [114, 116, 119, 122, 144, 145, 222], "theta_q": [114, 116, 119, 122], "wn": [114, 119, 120], "theta_0": [114, 123], "theta_i": [114, 144, 145, 222], "fir": 114, "sharp": [114, 129, 145, 151, 161, 174, 176, 188, 219, 222, 393], "theta_j": [114, 116, 119, 297, 298], "theta_h": [114, 123], "thereaft": 114, "carryov": 114, "ring": 114, "subsequ": [114, 286, 287, 292, 293], "temporari": [114, 122, 338, 345, 346, 352, 374], "outag": [114, 122], "microstructur": [114, 117], "bid": 114, "bounc": [114, 265], "standalon": 114, "mle": [114, 117, 120, 122, 124, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 165, 166, 168, 169, 170, 171, 172, 173, 174, 175, 177, 180, 181, 185, 187, 188, 189, 191, 192, 193, 195, 197, 199, 200, 202, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 231, 232, 233, 236, 237, 238, 239, 240, 241, 256], "quasi": [114, 236], "moment": [114, 228, 248, 254, 258, 264], "impos": [114, 185, 213, 237], "expans": [114, 165, 171, 212, 219, 379], "summabl": 114, "alias": 114, "echo": [114, 117, 332, 333], "spill": 114, "ma_filt": 114, "simulate_ma": 114, "burnin": [114, 117, 123], "innovations_from_ma": 114, "sample_acf": 114, "max_lag": [114, 117, 120, 122, 123, 124, 127, 131, 132], "theoretical_acf_ma": 114, "theta_ful": 114, "is_invert": 114, "fit_ma1_via_acf": 114, "r1": [114, 164, 251, 260, 261, 262], "499": 114, "theta_hat": 114, "disc": [114, 140], "theta_a": 114, "theta_b": 114, "var_hat": [114, 173, 217, 223], "sigma2_hat": 114, "sigma_hat": [114, 117, 123, 163, 172, 183, 185, 189, 194, 201, 208, 214], "fit_ma_via_acf_random_search": 114, "n_candid": 114, "best_theta": 114, "best_loss": 114, "theo": [114, 196, 223, 238], "1150": [114, 222], "\u03b8_h": 114, "\u03b8_0": 114, "theta_tru": [114, 119, 169, 206, 214, 215, 229], "_eps_tru": 114, "mu_1": [114, 175, 188, 193, 195, 199, 239, 243, 266, 267], "sigma_1": [114, 166, 188, 244, 252, 259], "mu_2": [114, 170, 172, 175, 184, 188, 190, 195, 199, 205, 211, 239, 243, 266, 267], "theta_2": [114, 144, 145], "sigma_2": [114, 166, 188, 244, 252, 259], "25000": [114, 143, 221], "resid_1": 114, "resid_2": 114, "acf_resid_1": 114, "acf_resid_2": 114, "conf": 114, "acf_resid": 114, "identif": [114, 118, 122], "ljung": [114, 116, 119, 122], "packag": [89, 115, 127, 131, 132, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 151, 160, 201, 209, 230, 240, 249, 332, 333, 334, 335, 337, 346, 349, 358, 371, 389], "meta": [115, 288], "facebook": 115, "lightweight": [115, 151, 156, 185, 208, 339, 345, 349, 351, 358], "changepoint": 115, "compil": [115, 333], "stan": [115, 163, 172, 218], "weekli": [115, 116, 120, 127, 129, 131, 132, 300], "yearli": [115, 116, 172, 300], "_as_prophet_df": 115, "y_col": 115, "coerc": 115, "ds": [115, 149, 164, 209, 256, 344, 355], "datetim": [115, 340], "datetimeindex": [115, 271], "to_datetim": 115, "to_numpi": [115, 120, 122, 124, 127, 129, 131, 132, 134], "dropna": [115, 297, 298, 306, 312, 313, 314, 315, 316, 317, 328], "_infer_freq": 115, "infer_freq": [115, 116], "coars": 115, "timedelta": [115, 125, 340], "_future_d": 115, "last_d": 115, "timestamp": [115, 116, 122, 271, 284, 296, 322, 333, 340, 384, 385], "freq": [115, 116, 119, 120, 122, 124, 125, 127, 129, 131, 132, 241, 271, 275, 280, 296, 300, 301, 303, 306], "tseri": 115, "to_offset": 115, "date_rang": [115, 116, 119, 120, 122, 124, 125, 127, 129, 131, 132, 300], "fourier_featur": 115, "t_dai": 115, "period_dai": 115, "fourier_ord": 115, "2\u03c0nt": 115, "changepoint_featur": 115, "t_scale": 115, "changepoints_sc": 115, "basi": [115, 159, 199, 263, 300], "ridge_fit": 115, "prophetlik": 115, "n_changepoint": 115, "changepoint_rang": 115, "yearly_season": 115, "weekly_season": 115, "daily_season": 115, "add_season": 115, "lambda_changepoint": 115, "lambda_season": 115, "staticmethod": 115, "_seasonality_ord": 115, "default_if_tru": 115, "_build_matrix": 115, "ds0_": 115, "total_second": 115, "86400": 115, "t_scale_": 115, "x_trend": 115, "x_season_part": 115, "season_nam": 115, "yearly_ord": 115, "weekly_ord": 115, "daily_ord": 115, "365": [115, 124], "x_season": 115, "freq_": 115, "iloc": [115, 116, 120, 122, 124, 280, 301, 306, 319], "portion": 115, "cp_max": 115, "cp_count": 115, "changepoints_scaled_": 115, "season_names_": 115, "x_trend_cols_": 115, "train_": 115, "fitted_": 115, "_predict_df": 115, "include_compon": 115, "coef_trend": 115, "coef_season": 115, "from_scratch": 115, "kwarg": [115, 127, 131, 132, 134, 135, 137, 143, 144, 145, 209], "prophet_kwarg": 115, "add_country_holidai": 115, "_prophet_avail": 115, "noqa": [115, 230, 311, 312, 313, 314, 315, 316, 317], "f401": [115, 311, 312, 313, 314, 315, 316, 317], "prophetmodel": 115, "country_nam": 115, "_impl": 115, "_train_df": 115, "_backend_": 115, "fcst": [115, 120, 124], "yhat_low": 115, "yhat_upp": 115, "cp": [115, 317, 322], "04": [21, 22, 96, 115, 116, 122, 159, 172, 186, 251, 253, 329, 358, 359, 393, 394], "y_seri": 115, "pred_futur": 115, "train_df": 115, "cp_scale": 115, "cp_dai": 115, "cp_date": 115, "to_timedelta": 115, "date": [115, 116, 119, 120, 122, 124, 125, 127, 129, 131, 132, 280, 382, 385], "550": [115, 119, 134, 268], "mcmc": [115, 154, 165, 167, 168, 172, 173, 175, 187, 188, 190, 197, 205, 208, 211, 213, 240], "s_1": [115, 143, 166, 250], "monthli": [116, 120, 122, 127, 129, 131, 132, 271, 280, 310], "quarterli": 116, "decemb": 116, "2s": [116, 134, 136, 138, 141, 181], "dummi": [116, 120, 122, 124], "month": [116, 172, 271, 381, 394], "year": [116, 172, 236, 356], "remaind": [116, 247], "phi_p": [116, 119, 122], "phi_1": [116, 119, 122], "tsa": [116, 119, 120, 122, 124, 271], "seasonal_decompos": 116, "statespac": [116, 122], "sarimax": [116, 120, 124], "purposefulli": 116, "motiv": [116, 143, 228, 244], "season_length": [116, 280], "n_year": 116, "n_ob": [116, 120, 124, 169, 224, 225, 238, 275], "ms": [116, 122, 151, 157, 190, 259], "det_season": 116, "seasonal_nois": 116, "short_nois": 116, "eps_season": 116, "eps_short": 116, "t_t": [116, 271], "to_fram": 116, "month_num": 116, "strftime": 116, "month_ord": 116, "decomp": 116, "ago": 116, "ds1": 116, "d1_ds1": 116, "idx_d1": 116, "idx_ds1": 116, "idx_d1_ds1": 116, "recur": 116, "peak": [116, 145, 149, 151, 152, 156, 161, 163, 166, 172, 176, 178, 181, 182, 188, 190, 194, 197, 202, 204, 206, 211, 212, 218, 222, 229], "trough": 116, "ar_n": 116, "ar_": 116, "convolv": [116, 138, 139, 143, 144], "nonzero_lag": 116, "convolut": [116, 130, 131, 195, 291], "ahead": [116, 117, 119, 121, 122, 123, 125, 127, 129, 131, 132, 271, 328], "undo": 116, "_ar_poli": 116, "phi_j": 116, "_ma_poli": 116, "ma_n": 116, "ma_": 116, "difference_with_forecast_histori": 116, "last_values_nonseason": 116, "last_values_season": 116, "invert_forecast_differ": 116, "x_futur": [116, 120, 123, 124, 228], "next_val": 116, "arma_innov": 116, "ar_poli": 116, "ma_poli": 116, "ar_term": 116, "ma_term": 116, "arma_forecast": 116, "w_ext": 116, "eps_ext": 116, "w_next": 116, "replic": [116, 228, 230, 233, 345, 351, 382, 389, 410], "seasonal_ord": [116, 122], "enforce_stationar": [116, 120, 122, 124], "enforce_invert": [116, 120, 122, 124], "fc_sm": 116, "get_forecast": [116, 120, 122, 124], "fc_sm_mean": 116, "predicted_mean": [116, 120, 122, 124], "fc_sm_ci": 116, "conf_int": [116, 120, 122, 124], "ourselv": [116, 159, 252], "w_train": 116, "last_non": 116, "last_sea": 116, "w_futur": 116, "y_future_numpi": 116, "forecast_index": 116, "fc_np": 116, "forecast_numpi": 116, "x_ci": 116, "y_ci": 116, "204": [116, 148], "recreat": [116, 331, 374], "necessarili": [116, 122, 145, 153, 237, 255, 265], "regener": 116, "jenkin": [116, 119, 122], "reinsel": [116, 119, 122], "variat": [117, 151, 165, 170, 173, 174, 177, 185, 189, 190, 191, 211, 212, 218, 240, 243, 318, 371, 394], "boldsymbol": [117, 122, 123], "serial": [117, 237, 238, 254], "m_j": [117, 123, 184], "vma": 117, "a_p": [117, 123], "m_1": [117, 120, 123, 124, 164, 170, 174, 184, 205, 215, 216, 222], "m_q": [117, 123, 209], "realiti": [117, 266], "friction": 117, "wold": 117, "psi_h": [117, 118, 123], "psi_0": [117, 123], "m_h": 117, "psi_": [117, 180], "kalman": [117, 122, 189, 194], "parsimoni": 117, "recover": [117, 352], "echelon": 117, "realiz": [117, 121], "var_companion": 117, "a_list": [117, 118, 123], "companion": [117, 245, 250, 269], "e_t": [117, 122, 123, 271], "is_var_st": 117, "simulate_varma": 117, "m_list": [117, 123], "var_ols_fit": 117, "x_block": [117, 123], "b_hat": [117, 123, 152, 160, 164, 170, 171, 176, 184, 195, 196, 205, 212, 214, 215, 217, 224, 225], "c_hat": [117, 123, 153, 154, 161, 165, 167, 168, 170, 171, 172, 173, 174, 178, 180, 182, 199, 200, 202, 211, 212, 215, 216, 219, 220, 222], "a_hat": [117, 123, 148, 152, 158, 160, 165, 169, 170, 171, 173, 184, 186, 195, 198, 207, 208, 212, 214, 217, 224, 225, 229, 241], "varma_irf": [117, 123], "psi_step": [117, 123], "psi": [117, 118, 123, 151, 152, 154, 158, 159, 166, 169, 173, 174, 178, 180, 187, 188, 190, 197, 202, 210, 221, 240], "mh": [117, 123], "varma_forecast_path": 117, "e_hist": 117, "n_path": [117, 119, 123, 150], "y_ext": [117, 123], "e_ext": 117, "a2": [117, 123, 141, 209, 216, 242, 258, 264], "m1": [117, 123, 124, 157, 160, 164, 165, 168, 170, 171, 173, 174, 183, 184, 190, 191, 192, 199, 205, 211, 213, 214, 215, 216, 222, 228, 239, 241, 248, 266, 267], "warrant": [117, 197], "a1_hat": 117, "a2_hat": 117, "t_0": [117, 245, 308], "q_lo": [117, 123, 166, 179, 201, 208], "q_med": [117, 123], "q_hi": [117, 123, 166, 179, 201, 208], "x_past": [117, 123], "x_fut": [117, 123], "respond": [117, 118, 252, 268, 329, 356], "h_irf": [117, 123], "shock_std": [117, 123], "e0": [117, 123], "e1": [117, 123, 159, 160, 176, 225], "shock_j": [117, 123], "resp": [117, 123, 338, 339, 340, 341, 342, 345, 346, 349, 350, 351, 352, 355, 356, 381, 386], "l\u00fctkepohl": [117, 123], "hamilton": [117, 123], "tsai": [117, 123], "jointli": [118, 122, 169, 185, 189, 213, 220, 221], "sigma_u": [118, 260], "c_x": 118, "c_y": 118, "u_": [118, 119, 120, 122, 152, 185, 216], "economi": 118, "suppli": [118, 212, 236], "spectral": 118, "kp": 118, "companion_matrix": 118, "check_stationar": 118, "spectral_radiu": 118, "is_stationari": 118, "build_var_matric": 118, "include_const": 118, "fit_var_ol": 118, "effective_t": 118, "lag_index": 118, "_u": [118, 138], "aic": [116, 118, 119, 120, 122, 124, 158, 160, 168, 171, 188, 224], "2m": [118, 190, 212], "t_p": [118, 183], "bic": [116, 118, 119, 122, 158, 224], "_slogdet_psd": 118, "max_tri": [118, 185], "jitter_valu": 118, "logdet": [118, 221], "information_criteria_var": 118, "n_param": 118, "select_lag": 118, "from_record": 118, "set_index": [118, 296], "sort_index": 118, "idxmin": 118, "cholesky_with_jitt": 118, "simulate_var": 118, "chol": 118, "ar_part": 118, "policyr": 118, "a1_tru": 118, "a2_tru": 118, "sigma_u_tru": 118, "stationarity_tru": 118, "ic_tabl": 118, "stationarity_hat": 118, "plot_var_coeffici": 118, "irf_matric": 118, "f_power": 118, "orthogonalize_irf": 118, "plot_irf_grid": 118, "psi_orth": 118, "stattool": [119, 271], "adful": [119, 271], "terminolog": [119, 198, 346], "2y_": 119, "speak": [119, 200, 348], "bt": [119, 129], "simulate_arma": 119, "2020": [115, 119, 120, 125], "raw_p": 119, "diff_p": 119, "adf": [119, 271], "3g": [119, 201, 248, 251, 264, 267], "\u03b4y": [119, 122], "kpss": [119, 271], "acf_np": 119, "pacf_ol": 119, "x_lag": 119, "acf_val": [119, 120, 124, 127, 131, 132], "pacf_val": 119, "css": [119, 339], "difference_level": 119, "\u03b4": [119, 155, 178, 195, 263, 269], "last_valu": [119, 134, 136, 140, 142, 308], "undifference_forecast": 119, "diff_forecast": 119, "delta_d": 119, "arma_residu": 119, "_arma_css_ss": 119, "fit_arma_css": 119, "c0": [119, 148, 153, 154, 165, 167, 168, 170, 171, 173, 174, 182, 187, 199, 200, 202, 211, 212, 215, 216, 219, 222], "phi0": 119, "bfg": [119, 153, 159, 181, 188, 205, 214, 222, 224, 228, 237, 239], "nob": [119, 120, 124], "arma_forecast_mean": 119, "x_hist": [119, 123], "eps_hist": 119, "arma_simulate_futur": 119, "n_sim": [119, 242, 244, 246, 247, 249, 250, 251, 252, 256, 261, 262, 264, 266, 267, 270], "base_len": 119, "x_fc_mean": 119, "y_fc_mean": 119, "x_fc_sim": 119, "y_fc_sim": 119, "q05": [119, 125, 184], "q95": [119, 125, 160, 184], "x_train_dat": 119, "x_test_dat": 119, "path_idx": 119, "fan": [4, 119, 125, 305, 354, 355, 356], "volum": [119, 148, 160, 166, 220, 236, 269, 308, 342, 365, 374, 376, 378, 379, 382], "ticket": [119, 333], "websit": [119, 247, 339, 352], "macroeconom": 119, "arimax": [119, 122], "richer": [119, 212, 226, 240, 318], "ox": 120, "rma": 120, "rend": 120, "eason": 120, "use_box_cox": [120, 124], "box_cox_bound": [120, 124], "use_trend": [120, 124], "use_damped_trend": [120, 124], "seasonal_period": [120, 124, 299], "use_arma_error": [120, 124], "g_": [120, 124, 136, 234], "dfrac": [120, 149, 153, 171, 172, 177, 180, 181, 184, 186, 187, 190, 192, 193, 195, 197, 200, 204, 207, 208, 210, 212, 213, 214, 215, 216, 218, 219, 222, 227, 229, 235], "m_k": [120, 154, 164, 173, 211, 216, 222, 231, 254, 264], "vartheta_j": 120, "sm": [120, 122, 124, 354], "boxcoxtransform": [120, 124, 323], "shift_": [120, 124], "lambda_": [120, 124, 218, 227, 230, 235, 236, 349], "boxcox_normmax": [120, 124], "brack": [120, 124], "lmbda": [120, 124], "_acf": [120, 124, 127, 131, 132], "seasonal_dummi": 120, "drop_first": 120, "trend_featur": [120, 124], "use_damp": [120, 124], "damped_phi": [120, 124], "bats_design_matrix": 120, "damped_trend_phi": [120, 124], "batsmodel": 120, "y_index": [120, 124], "fitted_valu": [120, 124], "fitted_x": [120, 124], "fittedvalu": [120, 124], "t_futur": [120, 124], "exog": [120, 122, 124], "mean_x": [120, 124], "ci_np": [120, 124], "lower_x": [120, 122, 124], "upper_x": [120, 122, 124], "lower_i": [120, 124], "upper_i": [120, 124], "arma_ord": [120, 124], "max_arma_ord": [120, 124], "show_warn": [120, 124], "_fit_sarimax": [120, 124], "y_x": [120, 124], "_select_arma_ord": [120, 124], "best_ord": [120, 124], "best_aic": [120, 124], "y_np": [120, 124], "chosen_ord": [120, 124], "m_2": [120, 124, 164, 170, 174, 184, 205, 215, 216, 222, 254, 264], "simulate_arma11": [120, 124], "pred_mean": [120, 124], "pred_low": [120, 124], "pred_upp": [120, 124], "4e79a7": [120, 122, 127, 129, 132], "78": [120, 122, 127, 129, 139, 142, 145, 262], "121": [105, 120, 122, 127, 129, 136, 191, 240], "167": [74, 120, 122, 127, 129], "e15759": [120, 122, 124, 127, 131, 132], "warmup": [120, 124, 144], "resid_us": [120, 124], "jarqu": [120, 122, 124, 127, 131, 132], "bera": [120, 122, 124, 127, 131, 132], "jarque_bera": [120, 124, 127, 131, 132], "qq": [120, 124, 127, 131, 132, 148, 154, 165, 168, 173, 177, 183, 186, 187, 190, 194, 195, 199, 215, 250, 252, 254, 264], "nq": [120, 124, 127, 131, 132, 231], "sample_q": [120, 124, 127, 131, 132], "financi": [121, 195], "arch": [121, 390], "yesterdai": 121, "elev": [121, 340, 359], "simulate_garch11": 121, "garch11_conditional_vari": 121, "garch11_forecast_vari": 121, "eps_last": 121, "shock_multipli": 121, "eps_last_shock": 121, "h_fore_shock": 121, "igarch": 121, "enter": [122, 140, 170], "counterfactu": 122, "stage": [122, 331, 332, 333, 334, 335, 338, 344, 353, 357, 358, 365, 371, 372, 381], "backshift": 122, "_s": [122, 123], "contemporan": [122, 123], "intervent": [122, 123, 266, 268], "promot": [122, 306, 331, 332, 333, 350], "beta_j": 122, "endogen": 122, "interven": 122, "omit": [122, 123, 161, 228, 236, 373, 379], "confound": [122, 261, 262, 263], "unobserv": [122, 216], "vix": 122, "announc": 122, "fund": 122, "cautiou": 122, "econom": [122, 154, 160, 168, 173, 177, 187], "oil": 122, "unemploy": 122, "iv": [122, 151, 193, 202, 239], "svar": 122, "granular": [122, 143, 224, 226], "resampl": [122, 134, 144, 178, 245, 248, 253, 255, 262, 263, 264, 265, 271], "unexpect": [122, 127, 131, 132, 139, 145, 161, 228], "gap": [122, 162, 179, 256, 296, 333], "scenar": 122, "publish": [122, 333, 338, 340, 347, 349, 354, 358, 359, 369], "cointegr": [122, 390], "spuriou": [122, 152, 188], "joblib": 122, "stimulu": 122, "132": [122, 182, 221], "ar1": 122, "sar1": 122, "beta_rate_tru": 122, "beta_stimulus_tru": 122, "exog_col": 122, "res_x": 122, "res_0": 122, "fcst_x": 122, "fcst_0": 122, "pred_x": 122, "pred_0": 122, "ci_x": 122, "f28e2b": 122, "reindex": [122, 243], "l12": 122, "phi_at_1": 122, "total_contrib": 122, "mean_part": 122, "07": [21, 22, 122, 157, 172, 188, 382, 393], "exog_bas": 122, "exog_cf": 122, "pred_bas": 122, "pred_cf": 122, "transpar": [122, 158, 249, 264, 266], "fit_ol": 122, "fit_seasonal_ar": 122, "forecast_seasonal_ar": 122, "residuals_histori": 122, "ar_param": 122, "r_hat": 122, "beta_ol": 122, "resid_train": 122, "resid_fcst": 122, "pred_numpi": 122, "59a14f": [122, 124, 131], "subtli": 122, "overestim": [122, 138, 144, 145], "econ": 122, "caution": [122, 149, 150, 158, 161, 195, 217], "backtest": [122, 285, 305, 308], "mimo": 123, "simultan": [123, 176, 209, 233, 249], "riski": [123, 331], "substanti": 123, "briefli": 123, "impuls": [123, 195], "puls": 123, "simulate_varmax": 123, "b_list": [123, 213], "sum_l": 123, "mq": 123, "t_x": [123, 255], "varx_ols_fit": 123, "b_ell": 123, "tx": [123, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 160, 162, 163, 164, 165, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 187, 190, 191, 194, 195, 196, 198, 199, 200, 201, 202, 203, 204, 206, 207, 211, 212, 213, 215, 216, 217, 218, 219, 220, 223, 224, 226, 227, 232, 233, 234, 236, 237, 238, 239, 241], "offset2": 123, "varx_forecast_path": 123, "m2": [123, 124, 154, 160, 161, 164, 165, 168, 170, 171, 173, 174, 183, 184, 187, 190, 191, 192, 199, 205, 211, 213, 214, 215, 216, 225, 228, 233, 239, 241, 248, 254, 258, 264, 266, 267], "x_ext": 123, "e_fut": 123, "varx_dynamic_multipli": 123, "theta_step": 123, "sum_el": 123, "bh": [123, 256], "instant": 123, "t_eff": 123, "h_mul": 123, "bat": 124, "rigonometr": 124, "seasonal_harmon": 124, "cox": [124, 248, 264, 300, 301, 323], "trigonometr": 124, "a_k": [124, 232], "b_k": 124, "fourier_term": [124, 300], "ang": 124, "tbats_design_matrix": 124, "tbatsmodel": 124, "003": [124, 142, 159, 262, 265], "bats_seasonal_param": 124, "k_weekli": 124, "k_yearli": 124, "tbats_seasonal_param": 124, "89": [19, 124, 142, 144], "161": [108, 124, 254], "79": [124, 134, 243], "kneighborstimeseriesregressor": [125, 126], "dtw": [125, 130, 132, 287, 290, 295, 316, 319], "warp": [125, 287, 290], "season_30": 125, "season_7": 125, "shock_idx": 125, "make_supervised_window": 125, "window_length": [125, 127, 129, 131, 132, 271, 306, 310], "t_target": 125, "last_start": 125, "t_next": 125, "h_test": 125, "zscore_per_seri": 125, "sd": [125, 169, 176, 178, 180, 181, 209, 239, 262, 266, 267, 268], "dtw_distance_1d": 125, "dp": [125, 240, 270], "j_start": [125, 132], "pairwise_dtw_dist": 125, "weighted_quantile_1d": 125, "sorter": [125, 252, 270], "interp": [125, 151, 155, 161, 173, 174, 175, 184, 197, 208, 216, 227, 233, 250, 267], "_as_3d_panel": [125, 127, 129, 131, 132], "dtw_window": [125, 132], "sako": [125, 132], "chiba": [125, 132], "n_train_": 125, "n_dims_": [125, 127, 129, 131, 132], "n_timepoints_": [125, 127, 129, 131, 132], "x_train_raw_": 125, "y_train_": 125, "_mu_": 125, "_sd_": 125, "_transform": 125, "_pairwise_dist": 125, "q3": 125, "t3": [125, 160, 342, 351, 357], "q2": [125, 144, 145, 196], "t2": [125, 160, 164, 184, 189, 211], "dist_k": 125, "dist_sort": 125, "yk": 125, "neighbor_target": 125, "y_nei": 125, "q_mat": 125, "test_dat": 125, "dist1": 125, "rel_t": 125, "xval": 125, "nei": 125, "model_ful": 125, "t_all": 125, "recursive_forecast_with_band": 125, "buf": [125, 138], "n_futur": [125, 159, 225], "fc_med": 125, "fc_lo": 125, "fc_hi": 125, "future_d": 125, "repetit": 125, "curs": 125, "k_neighbors_time_series_regressor": 126, "forest": [127, 129, 294, 306, 318, 321], "ensembl": [127, 286, 289, 294, 306, 321], "timeseriesforestregressor": [127, 128], "e_k": [127, 129, 230, 289], "f_f": [127, 191], "phi_b": [127, 129, 214], "t_b": [127, 245, 263], "_feature_mean": 127, "seg2d": [127, 129], "_feature_std": 127, "_feature_min": 127, "_feature_max": 127, "_feature_slop": 127, "_builtin_featur": 127, "callabl": [127, 141, 184, 209, 237, 263], "_resolve_feature_funct": 127, "feature_funct": 127, "resolv": [127, 182, 334, 358], "ff": 127, "feature_": 127, "_wrap": 127, "apply_along_axi": 127, "typeerror": [127, 131, 132, 143, 207, 226, 230, 231, 232, 233, 236, 238, 241, 268, 286, 287, 289, 292], "_random_interv": [127, 129], "n_timepoint": [127, 129], "n_interv": [127, 129, 289], "min_length": [127, 129], "max_length": [127, 129], "_transform_interv": [127, 129], "_m": [127, 196, 225, 228], "seg": [127, 129, 131], "_name": 127, "min_interval_length": 127, "max_interval_length": 127, "tree_param": 127, "feature_functions_": 127, "intervals_": [127, 129], "estimators_": [127, 129], "phi_fit": 127, "y_fit": 127, "simulate_ar1_nois": [127, 129, 131, 132], "2022": [122, 127, 129, 132], "make_sliding_window": [127, 129, 131, 132], "recursive_forecast": [127, 131], "shorter": [127, 162, 171, 220], "h2": [127, 131, 134], "t_h2": [127, 131], "tree_idx": [127, 129], "x_axi": [127, 129], "add_vrect": [127, 129, 151, 174, 181, 184, 216, 241, 260, 284, 289, 299, 318], "time_series_forest_regressor": 128, "min_interv": [128, 129], "tsf": 128, "composable_time_series_forest_regressor": [128, 129], "i_k": [129, 193], "3k": 129, "f_b": 129, "_f_mean": 129, "_f_std": 129, "_f_slope": 129, "t_mean": 129, "feat": 129, "max_interv": 129, "_resolve_n_interv": 129, "tree_rng": 129, "time_series_svr_tslearn": 130, "timeseriessvrtslearn": 130, "tslearn": 130, "rocket_regressor": 130, "rocketregressor": 130, "ridgecv": 130, "andom": 131, "onvolut": 131, "ernel": 131, "ppv": 131, "num_kernel": [131, 291, 320, 324], "divers": [131, 138, 165, 288, 318], "dilat": 131, "rockettransform": 131, "kernels_": 131, "max_d": 131, "max_pow": 131, "kinfo": 131, "m_pad": 131, "out_len": 131, "transformer_": 131, "regressor_": 131, "2021": 131, "015": [131, 142, 257], "pred_rocket": 131, "pred_ridg": 131, "poli": [132, 157, 234, 242, 258, 261, 264], "dtw_rbf": 132, "tube": 132, "misalign": 132, "_flatten_panel": 132, "dtw_cost": 132, "curr": 132, "pairwise_dtw_cost": 132, "dtw_rbf_kernel": 132, "dtw_gamma": 132, "model_": 132, "dtw_gamma_": 132, "triu_indices_from": 132, "n_train_max": 132, "x_train_smal": 132, "y_train_smal": 132, "svr_dtw": 132, "pred_dtw": 132, "svr_rbf": 132, "pred_rbf": 132, "dqn": 141, "ppo": [], "trpo": [135, 140], "actor": [140, 141, 332], "a2c": [], "a3c": 134, "sac": [137, 140, 141], "td3": [137, 138, 141], "pi_": [134, 135, 136, 140, 142, 143, 144, 145, 146], "rl": [134, 136, 138, 139, 140, 142, 145], "gymnasium": [134, 135, 136, 137, 138, 142, 143, 144, 145], "synchron": [4, 134, 349], "agent": [134, 138, 142, 143, 144, 145, 333, 381, 382, 385], "gym": [134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146], "gymnasium_avail": [134, 135, 137], "_gym_import_error": [134, 145], "env_id": [134, 136, 138, 142, 143, 145], "env": [134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 331, 333, 334, 335, 338, 343, 350, 358, 365, 371, 372, 376, 381, 382, 383, 384, 385], "n_env": [134, 140, 143], "total_timestep": [134, 136, 138, 139, 140, 142, 143, 144, 145, 146], "30_000": [134, 150, 153, 154, 159, 168, 183, 187, 195, 196, 198, 203, 204, 212, 221, 233, 241, 245, 261], "200_000": [134, 136, 138, 144, 145, 146, 150, 151, 152, 153, 155, 156, 158, 160, 162, 163, 164, 166, 168, 173, 175, 176, 178, 179, 181, 183, 184, 186, 188, 191, 193, 195, 196, 198, 199, 200, 201, 202, 203, 205, 207, 208, 209, 210, 211, 212, 214, 217, 219, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 235, 236, 237, 238, 239, 240, 247, 249, 250, 259], "gae_lambda": [134, 136, 142, 143], "ent_coef": [134, 136, 140, 142, 143, 144], "vf_coef": [134, 136, 140, 142, 143], "7e": 134, "rmsprop_ep": 134, "normalize_advantag": 134, "log_every_upd": [134, 142], "return_smoothing_window": 134, "a_t": [134, 136, 137, 139, 140, 141, 142, 143, 144, 146, 284, 317, 322], "worker": [134, 333, 342, 344, 350, 355, 356, 358, 359, 367], "asynchron": [4, 134, 136, 347, 350, 355], "mdp": [134, 141], "td": [134, 137, 138, 139, 143], "delta_t": [134, 136, 143], "bonu": [134, 135, 136, 140, 142, 143, 146], "c_v": [134, 143, 286], "c_e": [134, 143], "make_vec_env": [134, 143], "syncvectorenv": 134, "env_fn": 134, "autoreset_mod": 134, "autoresetmod": 134, "same_step": 134, "obs_spac": [134, 141], "single_observation_spac": 134, "act_spac": 134, "single_action_spac": 134, "obs_dim": [134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146], "prod": [134, 138, 142, 143, 145, 148, 151, 169, 180, 183, 190, 197, 214, 237, 241, 255, 331, 332, 333, 334, 335, 338, 344, 357, 365, 371, 372, 384, 385], "n_action": [134, 138, 139, 140, 143, 145], "trunk": 134, "actorcrit": [134, 140, 142, 143], "h1": [134, 151, 154, 155, 170, 172, 175, 176, 177, 187, 190, 191, 198, 199, 200, 202, 204, 205, 216, 222, 228, 229, 233, 242, 246, 253, 255, 266, 269], "fc1": 134, "fc2": 134, "ob": [134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 163, 184, 194, 212, 219, 222, 225, 231, 233, 234, 236, 240, 241, 245, 247, 248, 249, 250, 251, 256, 257, 263, 266, 267, 268], "sample_actions_and_logp": 134, "logp": [134, 136, 140, 142, 146, 165, 224, 226, 228, 232, 234, 239, 241], "num_sampl": 134, "gather": [134, 139], "unsqueez": [134, 136, 138, 139, 141, 142, 143, 144, 146], "policy_action_prob": 134, "compute_ga": [134, 136, 140, 142, 143], "last_adv": [134, 140], "next_valu": [134, 136, 140, 142, 143, 146], "replai": [4, 134, 138, 145, 347, 355], "finish": [134, 144, 211, 348], "train_a2c": 134, "rmsprop": 134, "obs_buf": [134, 136, 138, 139, 140, 144, 145, 146], "act_buf": [134, 136, 138, 140, 144, 145, 146], "rew_buf": [134, 136, 138, 144, 145, 146], "done_buf": [134, 136, 138, 140, 144, 145, 146], "val_buf": [134, 136, 140, 146], "ep_returns_run": 134, "ep_lengths_run": 134, "int32": [134, 140], "ep_return": [134, 138, 140, 141, 142, 143, 144, 145, 146], "ep_length": 134, "history_upd": 134, "last_adv_flat": 134, "global_step": [134, 138, 139, 143], "obs_t": [134, 136, 138, 139, 140, 143, 144, 145, 146], "as_tensor": [134, 138, 139, 141, 144, 145, 146], "next_ob": [134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146], "termin": [134, 136, 138, 139, 141, 142, 143, 144, 145, 146, 165, 181, 191, 212, 223, 227, 231, 234, 238, 241, 339, 342, 346, 369], "truncat": [134, 136, 138, 139, 141, 142, 143, 144, 145, 148, 149, 153, 155, 162, 165, 172, 179, 183, 184, 191, 193, 203, 205, 207, 208, 211, 225, 227, 231, 235, 239, 240, 241], "bookkeep": 134, "obs_last": [134, 143], "b_ob": [134, 143, 261], "b_act": 134, "b_adv": [134, 143], "b_ret": 134, "values_pr": 134, "b_logp": 134, "actor_loss": [134, 136, 138, 141, 144, 145], "critic_loss": [134, 136, 138, 141, 144, 145], "mean_ep_return": 134, "mean_return_window": 134, "4d": [134, 136, 138, 139, 141, 145], "7d": [134, 139, 382], "5d": 134, "mean_return": [134, 393], "hist_df": [134, 286], "roll_mean": 134, "littl": [134, 138, 210, 224, 253, 255, 265, 269], "pole": [134, 246], "angl": [134, 149, 150, 156, 178, 201, 202, 205, 222], "angular": [134, 149, 222], "policy_value_slic": 134, "ang_vel": 134, "theta_dot": 134, "p_right": [134, 166, 207, 250], "xdot": 134, "\u03b8": [134, 149, 162, 169, 206, 222], "\u03b8dot": 134, "max_a": [134, 148], "n_episod": [134, 140, 141], "ret": [134, 140, 142, 146], "eval_return": [134, 144], "instantli": [134, 332], "pendulum": [134, 138, 140, 142, 144, 145], "readthedoc": [134, 138, 139, 140, 145, 331], "master": [134, 139, 140, 141, 142, 145, 146, 333, 346], "stable_baselines3": [134, 138, 139, 141, 144, 145], "mlppolici": [134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146], "rms_prop_ep": 134, "use_rms_prop": 134, "constructor": [134, 136, 139, 142, 143, 144, 145, 146], "0007": [78, 134, 142], "use_sd": [134, 144], "sde_sample_freq": [134, 144], "rollout_buffer_class": 134, "rollout_buffer_kwarg": 134, "stats_window_s": [134, 144, 145], "tensorboard_log": [134, 139, 142, 143, 144, 145, 146], "policy_kwarg": [134, 136, 139, 142, 143, 144, 145, 146], "_init_setup_model": [134, 142, 143, 145], "cnnpolici": [134, 136, 139, 142, 143, 144, 145], "vecenv": 134, "gsde": [134, 144], "tensorboard": [134, 143, 144, 145], "dir": [134, 228], "mnih": [134, 139], "2016": [134, 140], "schulman": [134, 142], "gauss": [135, 167, 224, 234, 240], "cheapli": 135, "01_acktr_from_scratch": 135, "cheaper": [135, 382], "destruct": [135, 338], "infeas": [135, 184, 237], "million": 135, "exploit": [135, 145, 154, 173, 175, 268], "nabla_h": 135, "f_w": [135, 165, 188, 216], "otim": [135, 136, 185], "precondition": [135, 136], "rect": [135, 137], "axref": [135, 137], "ayref": [135, 137], "arrows": [135, 137], "ncontrol": 135, "310": [135, 137], "episod": [135, 136, 137, 138, 139, 140, 143, 144, 145, 146], "prereq": 136, "40_000": [136, 151, 159, 165, 215, 221, 229], "rollout_step": [136, 142], "critic_lr": [136, 138, 141, 144, 145], "actor_lr": [136, 138, 141, 144, 145], "kfac_damp": 136, "kfac_stats_decai": 136, "kfac_clip": 136, "inverse_update_interv": 136, "observation_spac": [136, 138, 141, 142, 143, 144, 145], "act_dim": [136, 138, 141, 143, 144, 145, 146], "action_spac": [136, 138, 139, 141, 142, 143, 144, 145], "_v": 136, "critic_optim": [136, 145], "numel": [136, 146], "next_nontermin": [136, 142, 143, 146], "precondit": 136, "kroneck": [136, 185], "kfacoptim": 136, "hook": 136, "stats_decai": 136, "_collect_stat": 136, "_step": 136, "a_inv": 136, "g_inv": 136, "register_forward_hook": 136, "_forward_hook": 136, "register_full_backward_hook": 136, "_backward_hook": 136, "set_collect_stat": 136, "_kfac_input": 136, "grad_input": 136, "grad_output": 136, "_kfac_grad_output": 136, "update_stat": 136, "a_aug": 136, "a_new": [136, 158, 232], "g_new": 136, "st": [136, 181, 236], "_update_invers": 136, "sh": [136, 146, 332, 333, 358, 359], "grad_wb": 136, "nat_wb": 136, "nat_w": 136, "nat_b": 136, "predicted_kl": 136, "nat_grad": 136, "add_": [136, 138, 139, 141, 144, 145], "actor_kfac": 136, "num_upd": [136, 143], "episode_return": [136, 138, 140, 141, 142, 143, 145], "episode_len": 136, "episode_length": [136, 138, 139, 145], "last_obs_t": 136, "obs_batch": [136, 141], "act_batch": [136, 141], "adv_batch": 136, "ret_batch": 136, "v_pred": [136, 146], "pow": [136, 143, 144], "logits_old": 136, "dist_old": 136, "fisher_loss": 136, "retain_graph": [136, 146], "step_info": 136, "logits_new": 136, "dist_new": 136, "approx_kl": [136, 140, 142, 143], "mean_20": 136, "mean_return_20": 136, "df_log": [136, 142], "df_ep": [136, 138, 140, 141, 142], "return_smooth": 136, "min_period": [136, 141, 145, 315], "tensorflow": [136, 140, 142, 143, 146], "deliver": 136, "stable_baselin": [136, 138, 140, 141, 142, 143, 146], "vf_fisher_coef": 136, "lr_schedul": 136, "kfac_upd": 136, "v2": [136, 267], "py": [31, 57, 89, 115, 127, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 151, 153, 158, 160, 181, 189, 201, 206, 209, 230, 235, 240, 346, 348, 349, 350, 389], "async_eigen_decomp": 136, "n_cpu_tf_sess": [136, 142, 143, 146], "boilerpl": 136, "safeguard": 136, "clip_kl": 136, "double_linear_con": 136, "middle_drop": 136, "double_middle_drop": 136, "throughput": [136, 341, 355, 356, 382, 409], "cnnlstmpolici": 136, "instanc": [136, 142, 143, 144, 145, 237, 296, 334, 335, 338, 342, 343, 346, 351, 358, 359, 385], "thread": [136, 143, 146], "kfac": 136, "cold_it": 136, "01_ddpg_from_scratch": 137, "pprox": [137, 156, 204, 231, 264, 267], "s_0": [137, 143, 163, 172, 200, 221, 389], "a_0": [137, 143, 172, 178, 190, 196], "ight": [137, 156, 160, 193, 217, 231, 261, 264, 267, 305], "maintain": [137, 138, 142, 171, 234, 285, 331], "au": 137, "minibatch": [137, 138, 142, 143], "epsilon_t": [137, 297, 298, 394], "ig": [137, 152, 193, 195, 203, 218, 261], "abla_": [137, 271], "abla_a": 137, "vert_": 137, "evolut": [137, 138], "probe": [137, 138, 139, 367, 374, 377], "280": [21, 47, 137, 240], "v1": [1, 138, 139, 142, 144, 145, 146, 237, 267, 334, 340, 365, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379], "bellman": [138, 144, 145], "instabl": [138, 141, 171, 172, 175], "nabla_a": 138, "rvert_": [138, 146], "gym_backend": 138, "num_episod": [138, 139], "max_steps_per_episod": [138, 139], "005": [36, 138, 141, 144, 145, 146], "probe_n": 138, "probe_every_episod": 138, "set_global_se": [138, 145], "env_reset": [138, 143, 145], "info": [138, 139, 140, 141, 143, 144, 145, 153, 185, 308, 335, 344, 350, 365, 381, 382], "env_step": [138, 143, 145], "make_env": [138, 144], "action_scale_and_bia": 138, "replaybuff": [138, 139, 144, 145], "next_obs_buf": [138, 139, 144, 145], "max_siz": [138, 144, 145], "ptr": [138, 139, 144, 145], "rew": [138, 144, 145, 146], "output_activ": [138, 141, 144, 145, 146], "action_scal": [138, 141, 144, 145], "action_bia": [138, 144, 145], "register_buff": [138, 144, 145], "ddpgconfig": [138, 141], "ddpgagent": [138, 141], "cfg": [138, 141, 144], "target_actor": 138, "target_crit": 138, "load_state_dict": [138, 139, 141, 144, 145], "state_dict": [138, 139, 141, 144, 145], "actor_opt": [138, 141, 144], "critic_opt": [138, 141], "next_act": [138, 145], "target_q_next": 138, "actor_act": 138, "p_targ": [138, 139, 144, 145], "mul_": [138, 139, 141, 144, 145], "q_mean": [138, 141], "moving_averag": [138, 139, 144], "train_ddpg": 138, "act_scal": 138, "act_bia": 138, "max_step": [138, 139, 140, 141, 144, 146], "_max_episode_step": 138, "global_step_end": 138, "update_step": 138, "snapshot": [138, 142, 146, 351, 352, 373], "probe_episod": 138, "probe_action_stat": 138, "probe_q": 138, "probe_st": 138, "ep_len": [138, 145], "pa": 138, "policy_stat": 138, "6d": [138, 139, 141, 145], "quietli": 138, "ma_window": [138, 144], "ma_x": 138, "df_up": [138, 141], "probe_ep": 138, "z_action": 138, "z_q": 138, "repositori": [138, 332], "normalactionnois": [138, 145], "action_nois": [138, 144, 145], "address": [138, 141, 145, 160, 345, 351, 357, 374], "twin": [138, 268], "myopic": 138, "potenti": 138, "ornstein": 138, "uhlenbeck": 138, "layernorm": 138, "lillicrap": 138, "arxiv": [138, 140, 141, 142, 144], "1509": 138, "02971": 138, "openai": [138, 142, 144], "spin": [138, 144, 338], "spinningup": [138, 144], "latest": [138, 144, 332, 343, 358, 381, 383, 386], "frac12": [139, 149, 158, 179, 188, 193, 202, 212, 214], "a_j": 139, "r_j": [139, 253], "d_j": 139, "older": [139, 142, 143, 218, 268, 382], "polyak": [139, 141, 144, 145], "frozen": [139, 148, 159, 160, 165, 177, 199, 207, 208, 211, 212, 216, 221, 227, 231, 235, 238, 241, 258, 267], "dqnconfig": 139, "buffer_s": [139, 144, 145], "learning_start": [139, 144, 145], "train_freq": [139, 144, 145], "gradient_step": [139, 144, 145], "target_update_interv": [139, 144], "eps_start": 139, "eps_end": 139, "eps_fract": 139, "linear_schedul": 139, "reset_env": [139, 144], "step_env": [139, 144], "polyak_upd": [139, 144], "target_net": 139, "online_net": 139, "infer_n_act": 139, "select_act": [139, 145], "q_net": 139, "lineworldenv": 139, "n_state": 139, "step_penalti": 139, "goal_reward": 139, "slip_prob": 139, "_po": [139, 141], "_ob": 139, "slip": 139, "obs_shap": 139, "actions_buf": 139, "rewards_buf": 139, "dones_buf": 139, "qnetwork": [139, 144, 145], "dqn_updat": 139, "q_valu": 139, "q_sa": 139, "next_q": 139, "max_next_q": 139, "smooth_l1_loss": 139, "train_dqn": 139, "obs0": [139, 143], "eps_decay_step": 139, "episode_reward": [139, 142], "loss_step": 139, "loss_valu": 139, "q_probe_histori": 139, "probe_ob": 139, "total_reward": 139, "done_for_bootstrap": 139, "q_probe": 139, "25_000": [139, 194, 221, 230, 244], "lineworld": 139, "q_all": 139, "cartpol": [139, 146], "sb3": [139, 145], "log_interv": 139, "dqn_cartpol": 139, "dlr": [139, 141, 144], "multiinputpolici": [139, 141], "exploration_initial_ep": 139, "exploration_final_ep": 139, "exploration_fract": 139, "net_arch": [139, 144], "replay_buffer_class": [139, 141, 144, 145], "replay_buffer_kwarg": [139, 141, 144, 145], "her": [139, 144], "optimize_memory_usag": [139, 144, 145], "fool": 140, "gan": 140, "emit": [140, 174, 200, 205, 209, 347, 354, 356], "set_num_thread": 140, "step_siz": [140, 146], "noise_std": [140, 141], "goal_radiu": 140, "n_expert_episod": 140, "steps_per_it": 140, "lambda_ga": 140, "d_lr": 140, "d_epoch": 140, "d_batch_siz": 140, "pi_lr": 140, "ppo_epoch": 140, "ppo_batch_s": 140, "clip_ep": [140, 142], "eval_episod": 140, "pi_e": 140, "occup": [140, 235], "came": [140, 212, 247, 256], "vectorpointnav2d": 140, "reset_don": 140, "done_mask": 140, "bool_": [140, 142], "expert_polici": 140, "choose_x": 140, "env_on": 140, "traj": 140, "collect_expert_pair": 140, "obs_list": [140, 142], "act_list": 140, "expert_ob": 140, "expert_act": 140, "one_hot": 140, "num_class": 140, "get_action_and_valu": 140, "pi_opt": 140, "d_opt": 140, "logp_buf": [140, 146], "true_r_buf": 140, "completed_return": 140, "completed_success": 140, "act_np": 140, "true_r": 140, "true_reward": 140, "adv": [140, 142, 146], "train_discrimin": 140, "gen_ob": 140, "gen_act": 140, "n_gen": [140, 168], "n_exp": [140, 249], "idx_g": 140, "randint": [140, 289], "idx_": 140, "g_ob": 140, "g_act": 140, "e_ob": 140, "e_act": 140, "randperm": 140, "mb": 140, "logits_g": 140, "logits_": 140, "loss_g": 140, "binary_cross_entropy_with_logit": 140, "loss_": 140, "ppo_upd": [140, 142], "old_logp": 140, "act_t": 140, "old_logp_t": 140, "adv_t": 140, "ret_t": 140, "policy_loss": [140, 142, 143], "value_loss": [140, 142, 143], "pg1": 140, "pg2": [140, 180], "entropy_bonu": 140, "gail_reward_from_logit": 140, "evaluate_polici": 140, "ep_step": 140, "ep_success": [140, 141], "return_mean": 140, "success_r": 140, "steps_mean": 140, "evaluate_expert": 140, "expert_ev": 140, "disc_loss_hist": 140, "ppo_loss_hist": 140, "ppo_policy_loss_hist": 140, "ppo_value_loss_hist": 140, "ppo_entropy_hist": 140, "ppo_kl_hist": 140, "train_ep_return": 140, "train_ep_success": 140, "train_ep_it": 140, "eval_it": 140, "eval_return_mean": 140, "eval_success_r": 140, "gail_reward": 140, "ppo_stat": 140, "df_disc": 140, "disc_loss": 140, "df_eval": 140, "rollout_singl": 140, "use_expert": 140, "2025": [140, 300], "expert_rol": 140, "learned_rol": 140, "upstream": [140, 146, 344], "inherit": [140, 197], "expertdataset": 140, "openmpi": 140, "mpi": [140, 142, 143], "generate_expert_traj": 140, "v0": [140, 189, 285], "expert_pendulum": 140, "n_timestep": 140, "expert_path": 140, "npz": 140, "traj_limit": 140, "gail_pendulum": 140, "docstr": [140, 144, 163, 170, 173, 225, 234], "timesteps_per_batch": [140, 146], "max_kl": [140, 146], "cg_iter": [140, 146], "conjug": [140, 146, 152, 154, 162, 168, 169, 170, 173, 179, 182, 183, 185, 187, 188, 189, 190, 193, 196, 197, 198, 201, 205, 211, 213, 220, 221, 223, 224, 235], "entcoeff": [140, 142, 146], "cg_damp": [140, 146], "vf_stepsiz": [140, 146], "vf_iter": [140, 146], "player": 140, "g_step": 140, "d_step": 140, "d_stepsiz": 140, "giver": 140, "hidden_size_adversari": 140, "adversary_entcoeff": 140, "stale": 140, "baselines3": [140, 142], "humancompatibleai": 140, "switch": [5, 140, 142, 197, 203, 227, 249, 260, 265, 339, 358], "ho": [140, 262], "ermon": 140, "1606": 140, "03476": 140, "reinterpret": 141, "achieved_go": 141, "desired_go": 141, "succe": [141, 226, 231, 237, 356], "effector": 141, "n_sampled_go": 141, "asdict": 141, "pointreachgoalenv": 141, "pos_x": 141, "pos_i": 141, "vel_x": 141, "vel_i": 141, "goal_x": [141, 146], "goal_i": 141, "render_mod": 141, "goal_rang": 141, "max_spe": 141, "distance_threshold": 141, "goal_spac": 141, "_vel": 141, "_goal": 141, "_sample_go": 141, "_get_ob": 141, "compute_reward": 141, "compute_success": 141, "is_success": 141, "accel": 141, "obs2": 141, "info2": 141, "state_dim": 141, "action_dim": [141, 142, 143], "soft_upd": 141, "herconfig": 141, "buffer_capacity_transit": 141, "100_000": [141, 144, 145, 161, 189, 196, 224, 230, 237, 241], "goal_selection_strategi": 141, "hindsightreplaybuff": 141, "compute_reward_fn": 141, "n_transit": 141, "her_prob": 141, "add_episod": 141, "next_achieved_go": 141, "ep_indic": 141, "next_obs_batch": 141, "done_batch": 141, "goal_batch": 141, "next_achieved_batch": 141, "achieved_batch": 141, "t_batch": 141, "t_idx": 141, "her_mask": 141, "future_t": 141, "unreach": 141, "g_her": 141, "next_stat": 141, "start_learning_aft": 141, "exploration_noise_std": 141, "grad_clip_norm": 141, "actor_targ": 141, "critic_targ": 141, "state_t": 141, "q_targ": 141, "a_pi": [141, 144], "trainconfig": 141, "updates_per_episod": 141, "env_max_step": 141, "env_distance_threshold": 141, "env_dt": 141, "env_goal_rang": 141, "env_max_spe": 141, "env_action_scal": 141, "default_factori": 141, "goal_dim": 141, "ag": [141, 164, 171, 220], "episode_success": 141, "episode_final_dist": 141, "update_log": 141, "ep_ob": 141, "ep_next_ob": 141, "ep_act": 141, "ep_achiev": 141, "ep_next_achiev": 141, "ep_desir": 141, "ep_don": 141, "ep_reward": 141, "final_dist": 141, "sr": 141, "avg_success": 141, "last25": 141, "success_ma_10": 141, "return_ma_10": 141, "ma10": 141, "ran": 141, "critic_loss_ma_200": 141, "actor_loss_ma_200": 141, "q_mean_ma_200": 141, "ma200": 141, "herreplaybuff": 141, "1707": [141, 142], "01495": 141, "team": [141, 239, 334, 335, 344, 350, 352, 353, 371, 372, 383, 384, 385], "rst": 141, "bitflippingenv": 141, "model_class": 141, "n_bit": 141, "bit_flipping_env": 141, "sparser": 141, "proxim": [142, 148, 288], "codebas": [142, 143], "2048": [142, 143], "n_updat": 142, "update_epoch": 142, "minibatch_s": [142, 143], "adam_ep": 142, "logic": [142, 214, 238, 270, 333, 339, 340, 343, 353, 356, 357, 370, 372], "backbon": [142, 143, 209, 328], "policy_head": 142, "value_head": 142, "orthogonal_": 142, "constant_": 142, "evaluate_act": 142, "collect_rollout": 142, "action_list": 142, "logp_list": 142, "value_list": 142, "reward_list": 142, "done_list": 142, "obs_tensor": 142, "action_item": 142, "obs_arr": 142, "actions_arr": 142, "logp_arr": 142, "values_arr": 142, "rewards_arr": 142, "dones_arr": 142, "adv_arr": 142, "ret_arr": 142, "b_ind": 142, "clip_frac": 142, "mb_ind": 142, "obs_b": 142, "actions_b": 142, "old_logp_b": 142, "adv_b": 142, "ret_b": 142, "new_logp": 142, "log_ratio": [142, 143, 187, 228, 239], "unclip": [142, 143, 175], "entropy_mean": 142, "last_ratio_snapshot": 142, "last_adv_snapshot": 142, "last_clip_active_snapshot": 142, "clip_act": 142, "recent_mean": 142, "recent_reward_mean": 142, "reward_ma": 142, "discourag": [142, 233], "pi_new": 142, "pi_old": 142, "legaci": [142, 143, 342], "repo": [142, 159, 185, 221, 331, 332, 333, 334], "file": [127, 131, 132, 135, 137, 142, 160, 182, 196, 209, 215, 332, 335, 337, 339, 346, 348, 349, 352, 356, 359, 365, 376, 381, 382, 383, 389], "clip_param": 142, "timesteps_per_actorbatch": [142, 143], "archiv": [142, 333, 347, 352, 385], "tf1": 142, "ppo2": 142, "pposgd_simpl": 142, "optim_epoch": 142, "optim_steps": [142, 143], "optim_batchs": [142, 143], "adam_epsilon": 142, "full_tensorboard_log": [142, 143, 146], "pressur": [142, 143, 243, 270], "sb": [142, 216], "sustain": 142, "2017": [116, 142, 181], "06347": 142, "pragma": [143, 268], "r_0": [143, 233], "cpi": 143, "klpen": 143, "bake": [143, 204, 358], "blog": 143, "mpi4pi": [143, 146], "plumb": 143, "cliprange_vf": 143, "nminibatch": 143, "noptepoch": 143, "epsilon_v": 143, "a_po": 143, "a_neg": 143, "clipped_surrog": 143, "r_clip": 143, "_info": [143, 144, 145], "set_seed_everywher": 143, "is_discret": 143, "log_std": [143, 144, 146], "actor_mean": 143, "_dist": 143, "expand_a": [143, 146], "make_rollout_storag": 143, "last_ga": [143, 146], "next_v": 143, "ppo2_upd": 143, "old_log_prob": 143, "old_valu": 143, "clip_coef": 143, "vf_clip_coef": 143, "v_clip": 143, "v_loss1": 143, "v_loss2": 143, "entropy_loss": 143, "clipfrac": 143, "textbook": [0, 10, 143, 196, 200, 270, 330, 387, 397, 404], "train_ppo2": 143, "150_000": [143, 151, 221, 234, 259], "target_kl": 143, "lr_now": 143, "clip_now": 143, "pg": 143, "param_group": 143, "action_t": 143, "logp_t": [143, 146], "_ent_t": 143, "value_t": 143, "adv_np": 143, "ret_np": 143, "b_action": 143, "b_old_logp": 143, "b_old_valu": 143, "b_return": 143, "batch_indic": 143, "metrics_accum": 143, "mb_idx": 143, "valv": 143, "120_000": [143, 164, 165, 166, 176, 177, 180, 183, 185, 189, 192, 193, 197, 199, 200, 201, 202, 233, 241, 269], "disabl": [143, 343], "rolling_x": 143, "add_lin": 143, "560": 143, "mainten": [143, 332, 333, 343, 350, 351, 366, 370], "ppo2_cartpol": 143, "cliprang": 143, "mlplstmpolici": 143, "directori": [143, 144, 145, 333, 358, 359], "disk": [143, 222, 340, 342, 352, 358, 373, 385], "squash": 144, "backup": [144, 333, 351, 352, 373, 378, 408], "cudnn": [144, 145], "broader": [144, 207, 258], "_q": 144, "reparameter": [144, 159, 179, 190, 203, 212, 213, 214, 217, 223, 224, 229, 235], "continuouspointmass1denv": 144, "dep": [116, 122, 144, 350], "action_limit": 144, "_action_limit": 144, "action_low": [144, 145], "action_high": [144, 145], "prefer_gym_pendulum": 144, "pkg": 144, "env_nam": [144, 350], "act_low": 144, "act_high": 144, "sample_batch": 144, "squashedgaussianactor": 144, "log_std_min": 144, "log_std_max": 144, "mu_lay": 144, "log_std_lay": 144, "rsampl": 144, "log_prob_u": 144, "mu_act": 144, "_std": 144, "_logp": 144, "_mu_a": 144, "sacconfig": 144, "alpha_lr": 144, "replay_s": 144, "updates_per_step": 144, "start_step": [144, 145], "auto_alpha": 144, "init_alpha": 144, "sacag": 144, "q1_targ": 144, "q2_targ": 144, "q_opt": 144, "target_entropi": 144, "log_alpha": [144, 228], "requires_grad": 144, "alpha_opt": 144, "next_a": 144, "next_logp": 144, "_next_mu_a": 144, "q1_next": 144, "q2_next": 144, "q_next": 144, "logp_pi": 144, "q1_pi": 144, "q2_pi": 144, "q_pi": 144, "alpha_loss": 144, "mean_logp": 144, "mean_q": 144, "q_1": [144, 205, 209], "q_2": 144, "taken": [144, 233, 268], "total_episod": 144, "max_steps_per_ep": 144, "ep_entropi": 144, "ep_q_valu": 144, "ep_alpha": 144, "total_step": 144, "ep_ret": [144, 146], "ent_sum": 144, "q_sum": 144, "anywai": 144, "_a_pi": 144, "entropy_est": 144, "q_est": 144, "_metric": 144, "log\u03c0": 144, "eval_polici": 144, "haarnoja": 144, "1801": 144, "01290": 144, "unus": [144, 342], "auto_0": 144, "use_sde_at_warmup": 144, "fujimoto": 145, "hoof": 145, "meger": 145, "modif": 145, "gym_avail": 145, "update_aft": 145, "policy_delai": 145, "target_policy_nois": 145, "target_noise_clip": 145, "exploration_nois": 145, "layer_s": 145, "action_low_t": 145, "action_high_t": 145, "twincrit": 145, "q1_onli": 145, "td3agent": 145, "actor_target": 145, "deepcopi": 145, "critic_target": 145, "actor_optim": 145, "total_it": [145, 146], "noise_scal": 145, "_soft_update_": 145, "train_step": 145, "replay_buff": 145, "randn_lik": 145, "target_q1": 145, "target_q2": 145, "target_q": [145, 196], "current_q1": 145, "current_q2": 145, "train_info": 145, "return_ma": 145, "script": [145, 333, 348, 353, 356], "research": 145, "1000000": 145, "ou": 145, "backtrack": [146, 287], "gae": 146, "hessian": 146, "max_p": 146, "pointmass1denv": 146, "x_init_rang": 146, "v_init_rang": 146, "action_max": 146, "goal_tol": 146, "goal_bonu": 146, "gaussianpolici": 146, "valuenet": 146, "gaussian_kl": 146, "mean_old": 146, "log_std_old": 146, "mean_new": 146, "log_std_new": 146, "n_old": 146, "n_new": [146, 228], "var_old": 146, "var_new": 146, "kl_per_dim": 146, "flat_param": 146, "set_flat_param": 146, "copy_": 146, "view_a": 146, "flat_grad": 146, "contigu": [146, 238, 322], "conjugate_gradi": 146, "fvp_fn": 146, "residual_tol": 146, "clone": [146, 353], "rdotr": 146, "avp": 146, "new_rdotr": 146, "trpo_upd": 146, "logp_old": 146, "backtrack_it": 146, "backtrack_coeff": 146, "old_param": 146, "mean_kl": 146, "surr": 146, "allow_unus": 146, "g_flat": 146, "fvp": 146, "create_graph": 146, "flat_kl_grad": 146, "kl_v": 146, "grads2": 146, "hvp": 146, "step_dir": 146, "full_step": 146, "eval_surr_and_kl": 146, "surr_old_v": 146, "step_frac": 146, "surr_new_v": 146, "kl_new_val": 146, "new_param": 146, "surr_old": 146, "surr_new": 146, "collect_batch": 146, "value_net": 146, "steps_per_batch": 146, "wasn": 146, "last_val": 146, "adv_buf": 146, "ret_buf": 146, "4096": 146, "vf_lr": 146, "vf_batch": 146, "snapshot_everi": 146, "vf_optim": 146, "ep_ret_mean": 146, "ep_ret_p10": 146, "ep_ret_p90": 146, "policy_std": 146, "policy_snapshot": 146, "v_loss": 146, "ep_mean": 146, "ep_p10": 146, "ep_p90": 146, "obs_grid": 146, "03d": 146, "p10": 146, "p90": 146, "snap": 146, "trpo_mpi": 146, "export": [146, 334, 338, 352, 381, 386], "session": [146, 237, 341, 342, 345, 351], "vi": [167, 168, 197, 205], "despit": 148, "dirichlet": [148, 152, 224], "alpha_dist": 148, "reciproc": [148, 153, 154, 166, 167, 177, 178, 182, 184], "literatur": [148, 195, 218], "lifetim": [148, 154, 165, 167, 169, 171, 173, 180, 187, 197, 199, 204, 213, 216, 220], "repair": [148, 173], "pareto": [148, 154, 168, 172, 182, 198, 240, 241], "denot": [148, 156, 158, 160, 166, 184, 185, 189, 194, 197, 201, 208, 214, 218, 222, 228, 231], "int_": [148, 149, 155, 156, 157, 158, 159, 160, 161, 164, 175, 176, 177, 179, 181, 183, 189, 192, 194, 195, 196, 199, 200, 202, 207, 208, 209, 214, 216, 221, 242], "alpha_pdf": 148, "xa": 148, "alpha_logpdf": 148, "logpdf": [148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 207, 208, 209, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 227, 240, 241], "alpha_cdf": 148, "alpha_ppf": 148, "int_x": 148, "law": [148, 153, 154, 157, 160, 166, 172, 175, 178, 179, 182, 187, 193, 198, 202, 219, 220, 223, 224, 225, 228, 231, 235, 240, 241], "expon": [148, 154, 157, 159, 170, 171, 186, 202, 203, 215, 240, 241], "surviv": [148, 151, 155, 160, 164, 167, 169, 173, 178, 183, 186, 187, 191, 192, 194, 196, 201, 203, 213, 214, 215, 216, 220, 226, 233, 237, 248, 252, 254, 259, 373], "fourth": [148, 149, 156, 185, 202, 220, 221], "m_x": [148, 150, 151, 152, 155, 156, 158, 160, 162, 163, 165, 166, 167, 168, 169, 170, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 208, 213, 214, 215, 216, 217, 218, 219, 220, 223, 226, 228, 230, 232, 233, 236, 237, 238, 239, 241], "varphi_x": [148, 150, 151, 155, 158, 160, 162, 163, 165, 166, 167, 168, 169, 170, 172, 173, 174, 176, 178, 179, 181, 182, 183, 184, 186, 188, 189, 190, 191, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 208, 213, 214, 215, 216, 219, 220, 223, 226, 230, 232, 233, 236, 237, 238, 239, 241], "itx": [148, 149, 150, 154, 155, 160, 162, 163, 165, 166, 168, 172, 173, 175, 176, 178, 179, 181, 184, 187, 190, 191, 194, 199, 204, 206, 207, 216, 217, 220, 223, 224, 226, 232, 233, 234, 236, 239, 241], "kurt": [148, 151, 153, 159, 160, 164, 165, 170, 172, 174, 175, 177, 179, 190, 195, 198, 202, 205, 210, 212, 213, 217, 220, 224, 225, 226, 227, 230, 231, 232, 235, 239, 240, 248, 254], "mvsk": [148, 149, 151, 153, 154, 157, 160, 161, 163, 164, 165, 166, 167, 170, 171, 172, 173, 175, 176, 177, 179, 186, 187, 188, 191, 192, 193, 196, 197, 199, 200, 202, 203, 205, 207, 208, 209, 212, 213, 214, 215, 216, 218, 219, 220, 222, 224, 225, 227, 228, 229, 231, 232, 233, 234, 235, 237, 238, 240, 241], "nempir": 148, "20_000": [148, 152, 158, 159, 161, 162, 169, 170, 171, 183, 184, 188, 210, 213, 214, 222, 224, 228, 233, 235, 236, 238, 241, 245, 251, 260, 262, 263], "rv": [148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241], "rapidli": [148, 171], "promin": [148, 177], "asymptot": [148, 151, 155, 162, 163, 171, 172, 175, 176, 177, 190, 193, 199, 203, 208, 213, 229, 233, 239, 242, 244, 247, 248, 253, 255, 256, 260], "a_valu": [148, 158, 186, 198, 208, 229, 241, 251], "x_tail": [148, 160], "sf": [148, 151, 154, 157, 160, 163, 165, 166, 167, 169, 171, 172, 174, 175, 176, 177, 179, 186, 187, 189, 190, 191, 192, 193, 194, 198, 199, 200, 202, 203, 209, 214, 216, 218, 220, 225, 226, 227, 229, 231, 232, 233, 234, 235, 236, 237, 239, 240, 246, 247, 253, 259, 262, 270, 356], "f_z": [148, 157, 161, 188, 197], "integrand": [148, 149, 155, 158, 160, 164, 181, 182, 194, 199, 202, 215, 216, 220], "alpha_loglik": 148, "alpha_scor": 148, "a_tru": [148, 158, 173, 195, 198, 207, 208, 224, 225, 229], "3_000": [148, 160, 163, 165, 194, 195, 210, 221, 222, 229, 239], "a_hat_grid": 148, "a_hat_scipi": 148, "loc_hat": [148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 186, 187, 188, 190, 192, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 214, 215, 217, 218, 219, 220, 222, 229], "scale_hat": [148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 179, 180, 182, 183, 184, 186, 187, 188, 190, 192, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 214, 215, 217, 218, 219, 220, 221, 222], "floc": [148, 151, 152, 153, 154, 158, 160, 162, 163, 165, 166, 168, 169, 170, 171, 173, 174, 178, 179, 180, 182, 183, 184, 186, 187, 190, 192, 193, 196, 198, 199, 200, 201, 202, 203, 204, 205, 209, 211, 213, 215, 216, 218, 219, 220], "fscale": [148, 151, 152, 153, 154, 158, 160, 166, 170, 171, 174, 180, 182, 184, 187, 192, 193, 198, 199, 200, 202, 203, 209, 211, 213, 215, 216, 222], "reject": [148, 151, 152, 154, 158, 166, 169, 180, 185, 192, 193, 198, 202, 209, 220, 243, 245, 247, 248, 249, 251, 252, 253, 254, 256, 257, 258, 259, 260, 261, 263, 264, 266, 267, 269, 270], "sampler": [148, 151, 152, 154, 155, 156, 158, 159, 160, 163, 164, 165, 166, 167, 168, 169, 172, 173, 174, 175, 178, 180, 181, 182, 184, 187, 188, 191, 192, 193, 195, 196, 197, 198, 199, 200, 204, 206, 208, 209, 210, 214, 215, 217, 219, 220, 221, 223, 224, 225, 227, 228, 230, 231, 232, 233, 234, 236, 237, 238, 239, 240, 241], "alpha_rvs_numpi": 148, "size_tupl": [148, 169, 190, 197, 208, 214, 231, 237], "isscalar": 148, "oversampl": 148, "overhead": [148, 382], "x_np": [148, 160, 172, 178, 220, 225, 233], "x_sp": [148, 160, 172, 220, 224, 233], "pdf_grid": [148, 149, 156, 160, 164, 171, 213, 219, 220, 246], "ecdf": [148, 154, 160, 166, 167, 168, 169, 170, 176, 177, 180, 184, 187, 190, 192, 197, 199, 201, 205, 208, 209, 214, 215, 216, 218, 219, 220, 221, 242], "cdf_grid": [148, 149, 160, 164, 171, 219, 220, 256], "ks_2samp": [148, 152, 168, 198, 203, 215, 220], "freez": [148, 160, 173, 177, 179, 216, 220], "5_000": [148, 155, 158, 160, 161, 163, 181, 182, 186, 189, 194, 198, 200, 204, 220, 221, 222, 223, 230, 232, 237, 238, 244, 245, 262], "nfit": [148, 165, 209, 220], "est": [148, 220, 286, 287, 288, 289, 292, 300, 318], "kolmogorov": [148, 149, 158, 160, 161, 164, 173, 179, 180, 195, 206, 212, 217, 220, 242], "smirnov": [148, 149, 158, 160, 161, 164, 173, 179, 180, 195, 206, 212, 217, 220, 242], "procedur": [148, 160, 173, 179, 185, 209, 214, 220, 243, 244, 249, 264], "kstest": [148, 149, 150, 156, 158, 160, 161, 164, 165, 167, 168, 169, 171, 173, 174, 179, 180, 184, 186, 188, 193, 195, 198, 206, 212, 215, 217, 219, 220], "p_valu": [148, 151, 153, 154, 155, 160, 161, 163, 165, 170, 172, 173, 174, 176, 177, 180, 181, 184, 187, 189, 190, 197, 198, 199, 200, 202, 203, 204, 208, 213, 214, 216, 218, 220, 221, 223, 225, 226, 227, 228, 229, 231, 234, 235, 238, 240, 241, 243, 246, 247, 248, 250, 251, 253, 254, 255, 257, 260, 261, 263, 265, 266, 267, 269, 270], "log_lik": [148, 151, 153, 155, 157, 160, 161, 165, 174, 175, 176, 181, 184, 193, 197, 200, 204, 213, 216, 218, 227, 233, 234, 240, 241], "log_post_unnorm": [148, 151, 155, 160, 167, 174, 181, 200, 204, 213, 216, 218, 227, 233, 234, 238, 241], "log_post": [148, 154, 157, 160, 161, 165, 167, 168, 175, 176, 181, 184, 187, 193, 197, 204, 216, 218, 219, 222, 229, 238, 240], "post_unnorm": [148, 161, 174, 176, 184, 202, 211, 212, 213, 240], "a_map": 148, "80_000": [148, 158, 160, 163, 164, 166, 167, 169, 171, 173, 181, 183, 188, 190, 192, 193, 195, 196, 198, 200, 201, 202, 203, 205, 206, 207, 208, 209, 210, 215, 218, 219, 220, 229, 233, 235, 236, 240, 249, 267], "ccdf": [148, 215], "ccdf_tail": 148, "anchor": [148, 271], "enorm": [148, 178, 179], "johnson": [148, 155, 166, 173, 220, 252], "kotz": [148, 155, 166, 173, 220], "balakrishnan": [148, 155, 166, 173, 220], "2nd": [148, 166, 212, 220, 234], "ed": [148, 166, 220], "wilei": [148, 166, 173, 220], "1994": [148, 170, 220], "salvia": 148, "ieee": 148, "character": [149, 167, 222], "2x": [149, 162, 182, 204, 218], "arcsin": [149, 152, 202, 206], "2u": [149, 182, 201], "anglit_sp": 149, "von": [149, 156, 222, 256], "mise": [149, 156, 222, 256], "handi": [149, 151, 171, 198, 203, 216, 233], "unimod": [149, 152, 156, 158, 161, 165, 168, 181, 206, 210], "anglit_pdf": 149, "anglit_cdf": 149, "anglit_ppf": 149, "f_x": [149, 150, 157, 161, 163, 164, 165, 167, 171, 173, 177, 180, 187, 188, 191, 197, 203, 206, 207, 208, 210, 216], "f_y": [149, 150, 163, 164, 167, 171, 173, 176, 177, 178, 179, 180, 187, 188, 198, 203, 204, 206, 216, 219, 220], "kappa_": 149, "varphi": [149, 151, 153, 154, 161, 164, 167, 171, 175, 180, 187, 194, 196, 206, 207, 208, 211, 212, 214, 224, 227, 228, 229, 234, 235, 240], "singular": [149, 150, 156, 169, 170, 189], "pm": [149, 155, 156, 158, 161, 175, 181, 194, 197, 202, 206, 214, 229, 261], "mean_clos": 149, "var_clos": 149, "m4_close": 149, "kurt_clos": 149, "excess_clos": 149, "entropy_clos": [149, 179], "mean_scipi": [149, 188, 197, 199, 205, 208, 209, 214, 233], "var_scipi": [149, 188, 197, 199, 205, 208, 209, 214, 233], "skew_scipi": [149, 188, 197, 199, 205, 208, 214, 233], "kurt_excess_scipi": [149, 197], "entropy_scipi": [149, 179, 199, 230, 233], "2z": [149, 167, 214], "frac14": 149, "400_001": 149, "mean_num": [149, 171], "var_num": [149, 171], "unusu": [149, 160, 163, 225, 236, 237, 248, 261, 269, 284], "sample_anglit": 149, "overlaid": [149, 164, 166, 171, 211, 212], "loc_tru": [149, 157, 158, 161, 163, 164, 171, 172, 173, 177, 179, 180, 195, 197, 200, 207, 208, 213, 218, 219, 229], "scale_tru": [149, 157, 158, 161, 163, 164, 171, 172, 173, 177, 179, 180, 195, 197, 200, 207, 208, 213, 218, 219, 220, 221], "ks_statistic_to_fitted_anglit": 149, "x_ob": [149, 161, 163, 164, 180, 193, 197, 199, 204, 216, 224, 228, 230, 232, 233, 237, 246], "d_ob": [149, 164, 239, 256, 261], "modest": [149, 164, 238, 268], "p_boot": [149, 163, 164, 195, 219], "anglit_logpdf": 149, "scale_known": 149, "loglik": [149, 154, 163, 164, 168, 172, 173, 176, 180, 185, 186, 187, 202, 206, 207, 208, 218, 220, 227, 232], "logpost": [149, 164, 173, 208, 232], "mu_map": 149, "wrap_to_pi": [149, 222], "roundoff": [149, 227], "brownian": [150, 178, 179, 183, 195, 218, 222], "motion": [150, 178, 179, 183, 195, 218, 222], "lowest": [150, 393], "obtain": [150, 153, 157, 163, 165, 173, 174, 177, 181, 185, 186, 216, 225, 295], "noninform": 150, "_check_ab": [150, 184], "arcsine_pdf": 150, "interior": [150, 152, 170, 212], "arcsine_logpdf": 150, "friendlier": 150, "arcsine_cdf": 150, "protect": [150, 227, 332, 339], "arcsine_ppf": 150, "arcsine_rv": 150, "bessel": [150, 193, 195, 202, 205, 206, 210, 239], "i_0": [150, 205], "j_0": 150, "arcsine_mean": 150, "arcsine_var": 150, "arcsine_mgf": 150, "arcsine_cf": 150, "j0": 150, "1j": [150, 151, 155, 163, 164, 165, 167, 169, 173, 175, 176, 178, 180, 181, 184, 186, 190, 195, 197, 198, 200, 204, 206, 207, 208, 210, 211, 212, 217, 222, 223, 229, 232, 233, 234, 235, 237, 239, 240, 241], "arcsine_entropi": 150, "n_mc": [150, 151, 164, 182, 199, 202, 219, 238, 259, 268, 269], "x_mc": [150, 151, 156, 158, 160, 162, 164, 183, 186, 192, 206, 219, 238], "rigid": [150, 171], "uparrow": [150, 174, 178, 218, 219], "fig_pdf": [150, 153, 154, 156, 162, 183, 184, 187, 188, 190, 194, 195, 198, 202, 203, 206, 211, 212, 213, 214, 217, 219], "fig_cdf": [150, 153, 154, 156, 162, 183, 184, 187, 188, 190, 194, 195, 198, 202, 203, 206, 211, 212, 213, 214, 217, 219, 223, 225, 226, 227, 231, 232, 233, 234, 235, 236, 238, 239, 240], "60_000": [150, 157, 158, 160, 163, 165, 166, 171, 175, 176, 178, 181, 184, 188, 190, 194, 212, 213, 218, 220, 241, 244, 246, 247, 267], "pdf_scipi": [150, 154, 157, 162, 168, 173, 187, 188, 191, 198, 201, 206, 211], "cdf_scipi": [150, 154, 157, 162, 168, 173, 187, 188, 191, 198, 201, 206, 211, 226, 228, 229, 236, 237], "pdf_beta": [150, 202], "s_scipi": [150, 151, 211, 216, 222], "s_numpi": [150, 216], "tricki": [150, 159, 178, 207, 269], "epsilon_i": 150, "frac_posit": 150, "pvalu": [120, 124, 127, 131, 132, 148, 150, 152, 158, 167, 168, 171, 174, 179, 186, 188, 198, 203, 206, 207, 215, 217, 219, 220, 223, 226, 230, 239, 246, 248, 258, 260, 264, 267, 268, 269, 270], "prior_jeffrei": 150, "prior_uniform": 150, "post_jeffrei": 150, "post_uniform": [150, 206], "ci_low": [150, 151, 174, 181, 208, 218, 227, 232, 234, 236, 238, 241, 245, 249, 250, 266], "ci_high": [150, 151, 174, 181, 208, 218, 227, 232, 234, 236, 238, 241, 245, 249, 250, 266], "025": [122, 148, 150, 161, 165, 174, 181, 182, 183, 188, 190, 197, 198, 201, 208, 215, 216, 218, 226, 227, 232, 236, 238, 242], "975": [22, 122, 150, 161, 165, 174, 181, 182, 183, 188, 190, 197, 198, 201, 208, 215, 216, 218, 226, 227, 232, 236, 238], "credibl": [150, 151, 161, 166, 173, 174, 184, 201, 208, 215, 216, 218, 227, 233, 234, 238], "p_arcsin": 150, "p_uniform": 150, "k_arcsin": 150, "k_uniform": 150, "pose": [150, 237], "famou": [151, 206, 214, 218], "kinemat": [151, 204, 206], "minimize_scalar": [151, 158, 174, 175, 178, 179, 191, 193, 204, 213, 214, 216, 222, 226, 232, 233, 240, 241], "chi2": [151, 153, 154, 162, 165, 169, 170, 172, 174, 176, 177, 178, 181, 182, 185, 187, 189, 190, 192, 193, 196, 198, 199, 200, 201, 202, 203, 208, 209, 213, 214, 216, 218, 221, 222, 227, 229, 230, 231, 233, 235, 236, 238, 240, 241, 247], "chi": [151, 153, 154, 162, 163, 165, 166, 169, 170, 172, 173, 174, 176, 177, 178, 180, 181, 182, 185, 186, 187, 189, 190, 191, 192, 194, 196, 197, 199, 201, 202, 203, 205, 207, 208, 209, 210, 213, 218, 221, 224, 227, 228, 229, 230, 231, 233, 235, 236, 238, 240, 241, 244, 249, 250, 251, 252, 253, 254, 256, 257, 259], "pile": [151, 153, 219], "downarrow": [151, 220], "incomplet": [151, 152, 157, 158, 159, 166, 169, 173, 180, 182, 190, 191, 196, 197, 202, 210, 215, 216, 226, 231, 236, 246], "argus_psi": 151, "gammainc": [151, 158, 169, 173, 180, 190, 197, 216], "argus_pdf": 151, "norm_const": 151, "argus_cdf": 151, "psi_chi": 151, "xgrid": [151, 152, 155, 175, 182, 184, 188, 193, 198, 211], "chi_test": 151, "max_pdf_err": [151, 197, 211], "max_cdf_err": [151, 197, 211], "i_1": [151, 205, 206], "gamma_1": [151, 152, 163, 164, 166, 167, 169, 174, 177, 180, 182, 183, 184, 186, 190, 193, 196, 198, 199, 200, 201, 203, 208, 211, 212, 215, 216, 218, 219, 220, 223, 224, 227, 233, 234, 235, 237, 240], "mu_3": [151, 164, 165, 170, 172, 174, 184, 190, 199, 205, 211, 215, 220, 227, 233], "gamma_2": [151, 152, 156, 161, 163, 164, 166, 167, 169, 174, 177, 180, 182, 183, 184, 186, 190, 193, 196, 197, 198, 199, 200, 201, 202, 203, 206, 208, 211, 212, 216, 218, 219, 220, 223, 224, 227, 229, 233, 234, 235, 237, 238, 240], "mu_4": [151, 164, 165, 170, 172, 174, 184, 190, 199, 205, 211, 215, 220, 223, 227, 233], "quadratur": [151, 164, 167, 170, 195, 199, 205, 216], "argus_mean": 151, "argus_e_x2": 151, "branch": [151, 171, 211, 222, 332, 333], "358": [94, 102, 151], "65690625": 151, "94": [49, 151, 209], "1010625": 151, "2625": 151, "175": [53, 136, 151], "polyv": 151, "argus_var": 151, "m_formula": [151, 204], "v_formula": [151, 204], "m_scipi": [151, 190, 199, 204, 214], "v_scipi": [151, 199, 204, 214], "k_scipi": 151, "mf": 151, "vf": 151, "ss": [151, 199, 385], "cf": [151, 152, 158, 163, 164, 165, 169, 180, 181, 183, 184, 188, 193, 198, 200, 201, 203, 208, 212, 214, 217, 219, 223, 224, 235, 240, 241, 338, 339], "chi0": 151, "ws": [151, 167, 200, 221], "nmgf": [151, 164, 171], "mc": [151, 159, 163, 164, 166, 167, 168, 171, 172, 173, 178, 179, 181, 182, 185, 186, 189, 191, 192, 198, 201, 202, 203, 206, 209, 211, 217, 218, 219, 221, 222, 223, 224, 226, 227, 231, 232, 233, 234, 235, 236, 237, 239, 240, 242, 244], "ncharacterist": 151, "\u03c9": [151, 164, 190, 202, 211, 212], "i\u03c9x": [151, 164, 211], "nentropi": 151, "argus_mod": 151, "interest": [151, 174, 201, 210, 267, 268, 389], "i_n": [151, 185], "simplif": [151, 168], "argus_loglik": 151, "argus_loglik_grad": 151, "psi_prim": 151, "chi_tru": 151, "chi_hat": 151, "h0": [151, 153, 154, 155, 162, 170, 172, 174, 175, 176, 177, 181, 182, 183, 185, 187, 189, 190, 192, 196, 197, 198, 199, 201, 202, 204, 205, 206, 207, 214, 216, 217, 218, 221, 222, 228, 229, 232, 233, 234, 235, 239, 242, 243, 245, 246, 247, 248, 251, 253, 254, 255, 256, 257, 259, 260, 262, 263, 266, 267, 268, 270], "lr_stat": [151, 165, 169, 202, 203, 214, 233], "nlrt": 151, "argus_rvs_numpi": 151, "size1d": 151, "atleast_1d": [151, 226, 233], "num_accept": 151, "echi": 151, "standard_gamma": 151, "chi_check": 151, "chis_plot": 151, "chi_mc": 151, "bargap": [151, 166, 169, 180, 190, 197, 198, 205, 208, 215, 216, 218, 228, 237, 244, 246], "rv_continu": [151, 158, 167, 177, 209], "nrv": 151, "x_data": [151, 154, 161, 168, 181, 187, 188], "ntrue": [151, 154, 164, 171, 187, 229], "chi_0": 151, "inaccur": [151, 191, 209, 258, 261], "bkg": 151, "lrt": [151, 153, 154, 157, 162, 163, 165, 172, 174, 176, 177, 181, 187, 190, 198, 199, 200, 204, 213, 214, 216, 218, 224, 228, 235], "post_cdf": [151, 155, 175, 181, 212, 241], "post_mean": [151, 152, 153, 162, 174, 179, 181, 184, 193, 198, 200, 203, 208, 212, 218, 227, 232, 238, 241], "nposterior": 151, "lightblu": 151, "chi_bkg": 151, "mu_sig": 151, "sigma_sig": 151, "97": [151, 245], "pi_sig": 151, "n_sig": 151, "n_bkg": 151, "x_bkg": 151, "x_sig": [151, 204], "x_mix": [151, 163, 188, 213, 220, 248], "convers": [115, 146, 152, 153, 170, 171, 181, 189, 223, 224, 225, 226, 228, 237, 251], "lpha": [152, 156, 159, 160, 193, 231, 261, 264, 267, 305], "blend": 152, "g_1": [152, 172, 181, 202, 219, 220, 224, 229, 231, 234], "g_2": [152, 172, 181, 202, 219, 220, 224, 229, 258], "i_x": [152, 210], "beta_pdf": 152, "log_pdf": [152, 174, 196, 198, 246, 250], "betaln": [152, 166, 191, 202, 210, 224, 225], "beta_cdf": 152, "betainc": [152, 166, 191, 202, 210], "alpha0": [152, 159, 160, 162, 169, 179, 183, 186, 196, 198, 210, 213, 220, 226, 228, 235, 236, 241], "rise": [152, 168, 169, 171, 211, 216, 225, 228, 389], "pochhamm": [152, 225, 228], "_1f_1": [152, 190, 198, 205], "confluent": [152, 190, 198, 205], "arphi_x": [152, 156, 217], "ln": [152, 153, 156, 161, 162, 174, 181, 183, 188, 194, 201, 213, 217, 219, 242, 244, 264, 389], "digamma": [152, 154, 158, 159, 166, 173, 174, 178, 180, 187, 188, 190, 202, 210, 220, 221, 228, 240], "beta_mo": 152, "excess_kurt": [152, 153, 163, 167, 168, 170, 172, 180, 182, 184, 191, 195, 196, 198, 200, 203, 210, 213, 214, 215, 219, 226, 227, 231, 237, 239, 240, 241, 254], "hyp1f1": [152, 190, 198, 205], "samples_scipi": [152, 162, 163, 168, 169, 170, 174, 181, 183, 184, 198, 203, 205, 208, 215, 219, 226, 230, 236], "mc_mean": [152, 168, 184, 193, 198, 200, 203, 210, 226, 231, 232, 236, 239, 241], "mc_var": [152, 168, 184, 193, 198, 200, 203, 210, 226, 231, 232, 236, 239, 241], "mc_mgf_1": 152, "mc_mgf_m1": 152, "param_set": [152, 165, 167, 170, 193, 195, 214, 239], "\u03ba": 152, "m_fix": 152, "beta_loglikelihood": 152, "overset": [152, 176, 181, 186, 197, 200, 201, 202, 209, 215, 227, 247, 249], "gamma_rvs_numpi": [152, 166, 169, 180, 190, 193, 197], "boost": [152, 158, 166, 169, 175, 190, 193, 306], "0331": [152, 166, 169, 180, 190, 193, 197], "log_v": [152, 166, 193], "accept2": [152, 166, 193], "beta_rvs_numpi": 152, "g1": [152, 172, 202, 219, 220, 224, 229, 248, 257, 259], "g2": [152, 172, 202, 219, 220, 224, 229, 257, 258, 259], "samples_numpi": [152, 166, 168, 174, 193, 199, 203, 215], "emp_x": [152, 173, 174, 181, 193, 200], "emp_cdf": [152, 153, 173, 174, 181, 185, 188, 193, 200, 207, 240], "clopper": 152, "pearson": [152, 176, 230, 248, 255, 258, 265], "lpha_0": [152, 159], "eta_0": 152, "pseudo": [152, 224, 228, 359], "cp_low": 152, "cp_high": 152, "alpha_prior": [152, 228, 230], "beta_prior": 152, "alpha_post": [152, 162, 169, 179, 186, 198, 220, 223, 226, 228, 230, 231, 235, 236], "beta_post": [152, 162, 169, 179, 198, 223, 226, 231, 235, 236], "0f": [152, 193, 196, 223, 226, 246], "post_prob": 152, "win": [153, 237, 239, 288], "_validate_c": [153, 182], "bradford_pdf": 153, "bradford_cdf": 153, "bradford_ppf": 153, "20001": [153, 156], "pdf_val": [153, 157, 166, 194, 196, 203, 210], "max_abs_pdf_diff": [153, 188], "max_abs_cdf_diff": [153, 188, 232], "2c": [153, 167, 174, 175, 178, 182, 211, 222, 229], "2cl": 153, "neat": [153, 156, 202, 239], "shortcut": [153, 211], "bradford_raw_moments_1_to_4": 153, "ex1": 153, "ex2": [153, 212], "ex3": 153, "ex4": 153, "bradford_mean_var": 153, "bradford_skew_kurtosis_excess": 153, "mu3": [153, 154, 157, 160, 164, 165, 168, 170, 171, 172, 173, 174, 184, 187, 190, 191, 192, 205, 211, 213, 214, 215, 216, 219, 220, 223, 225, 227, 228, 233, 241], "mu4": [153, 154, 157, 160, 164, 165, 168, 170, 171, 172, 173, 174, 184, 187, 190, 191, 192, 205, 211, 213, 214, 215, 216, 219, 220, 223, 225, 227, 228, 233, 241], "bradford_entropi": 153, "bradford_mgf": 153, "result_typ": 153, "tt": [153, 175, 210, 211, 212, 217, 238], "expi": [153, 184], "ex": [153, 174, 186, 206, 217, 252, 345], "c_valu": [153, 161, 168, 178, 180, 182, 200, 215, 216, 219, 220], "vars_": 153, "2l": 153, "bradford_loglik": 153, "bradford_mle_c": 153, "c_init": [153, 168], "log_c": [153, 165, 168, 199, 267], "x_sim": [153, 172, 174, 186], "c_scipi": 153, "loc_scipi": 153, "scale_scipi": 153, "c_fit": [153, 161, 168, 178, 180, 182, 216], "bradford_rvs_numpi": 153, "mean_theori": [153, 159, 165, 169, 183, 187, 188, 197, 208, 213, 227, 230], "var_theori": [153, 165, 169, 183, 187, 188, 197, 208, 213, 225, 227], "x_plot": [153, 156, 178], "h_0": [153, 154, 155, 157, 165, 166, 172, 176, 177, 178, 181, 185, 187, 189, 190, 191, 193, 194, 199, 200, 202, 204, 205, 207, 208, 213, 216, 217, 218, 222, 223, 227, 228, 234, 235, 243, 244, 245, 247, 248, 249, 251, 252, 254, 256, 257, 258, 259, 260, 261, 263, 264, 266, 267, 268], "h_1": [153, 154, 157, 165, 172, 176, 177, 181, 187, 190, 191, 193, 199, 200, 202, 204, 205, 208, 213, 216, 218, 222, 227, 228, 234, 243, 244, 245, 247, 248, 252, 256, 257, 259, 262, 264, 266, 267, 268, 270], "2_1": [153, 154, 162, 165, 170, 174, 177, 181, 187, 188, 190, 193, 194, 202, 203, 208, 213, 218, 227, 233, 235], "serv": [153, 167, 203, 235, 339, 344, 345, 351], "ll_hat": [153, 176, 198, 202, 203, 213, 229, 233, 235], "ll_0": [153, 174, 176, 213, 229, 235], "c_prior": [153, 180, 202], "posterior_unnorm": 153, "post_map": [153, 238], "intend": [153, 264], "collis": [153, 164, 371, 372], "bibliometr": 153, "made": [153, 211, 327, 341], "wait": [154, 162, 163, 169, 171, 173, 178, 180, 187, 196, 213, 218, 225, 231, 235, 236, 338, 339, 342, 344, 350, 351, 355, 356], "burriii": 154, "wealth": [154, 160, 168, 187, 196, 198, 215], "hydrolog": [154, 165, 168, 169, 172, 173, 187, 197, 220], "environment": [154, 165, 168, 183, 195, 197, 216, 220], "fisk": [154, 187], "xii": [154, 168], "burrxii": 154, "burr12": 154, "unshift": [154, 187, 239], "burr_logpdf": 154, "xm": [154, 160, 166, 174, 182, 187, 191, 193, 195, 196, 201, 203, 210, 216, 218, 220], "logx": [154, 168, 183, 187, 220], "log1p_xnegc": 154, "burr_pdf": 154, "burr_logcdf": 154, "burr_cdf": 154, "burr_ppf": 154, "burr_rvs_numpi": 154, "burr_raw_mo": 154, "burr_entropi": 154, "burr_summary_stat": 154, "exkurt": [154, 187, 192, 200, 213, 218, 233, 235], "m3": [154, 160, 164, 165, 168, 170, 171, 173, 174, 184, 187, 190, 191, 192, 199, 205, 211, 213, 214, 215, 216, 225, 228, 239, 241, 248, 254, 264], "m4": [154, 156, 158, 160, 161, 164, 165, 168, 170, 171, 173, 174, 184, 187, 190, 191, 192, 199, 205, 211, 213, 214, 215, 216, 225, 228, 239, 241, 248, 254, 258], "elementari": [154, 157, 159, 160, 163, 165, 167, 168, 172, 175, 183, 187, 191, 194, 195, 205, 218, 220, 224, 231, 233], "pdf_np": [154, 161, 172, 177, 187, 212], "pdf_sp": [154, 161, 172, 177, 187, 212], "pdf_numpi": [154, 187], "mean_sp": [154, 161, 163, 165, 171, 172, 177, 187, 200, 218, 220, 224, 227, 231, 232, 235], "var_sp": [154, 161, 163, 165, 171, 172, 177, 187, 200, 212, 218, 220, 224, 227, 231, 232, 235], "skew_sp": [154, 161, 163, 165, 171, 172, 177, 187, 212, 218, 220, 224, 227, 231, 232, 235], "exkurt_sp": [154, 172, 187, 218, 235], "nmoment": [154, 209], "lighter": [154, 157, 161, 181, 187, 195, 196, 210, 215, 220, 248, 258], "d_fix": 154, "c_list": 154, "fig_pdf_c": 154, "c_fix": [154, 173, 199, 215], "d_list": 154, "fig_pdf_d": 154, "burr_loglik": 154, "d_true": [154, 211], "c_try": 154, "d_try": 154, "c_samp": 154, "d_samp": 154, "q_emp": [154, 175, 176, 178, 187], "q_theori": [154, 176, 186, 187, 209], "nsampl": [154, 187, 209, 251], "c_vi": [154, 161, 202], "d_vi": 154, "fig_cdf2": 154, "samples_vi": [154, 187], "fig_hist": [154, 156, 187, 202, 214], "fig_ecdf": [154, 156, 187, 214], "remind": [154, 163, 255], "x_eval": [154, 187], "d_hat": [154, 211, 219], "x_dens": [154, 187], "max_pdf_diff": [154, 187, 198], "max_cdf_diff": [154, 187, 198], "nmax": [154, 187, 189], "cdf_numpi": [154, 187, 228, 229, 237], "nest": [154, 170, 187, 191, 296], "multimod": [154, 156, 181, 187], "c_hat1": 154, "d_hat1": 154, "c_hat0": [154, 187], "d_hat0": 154, "ll1": [154, 157, 165, 170, 172, 177, 181, 187, 190, 197, 199, 200, 204, 205, 208, 222, 228], "ll0": [154, 157, 165, 170, 172, 177, 181, 187, 190, 197, 199, 200, 204, 205, 208, 222, 228], "lrt_stat": [154, 162, 187], "seriou": [154, 167, 187], "sum_logx": [154, 187, 215], "d_grid": 154, "logprior": [154, 164, 187, 208, 232], "i_map": [154, 157, 187], "j_map": [154, 157, 187], "fig_post": [154, 184, 187], "colorbar_titl": [154, 187, 237, 238], "patholog": 155, "x_0": [155, 174, 183], "z_2": [155, 186, 205], "tan": [155, 175, 207, 222], "arctan": [155, 204, 207, 222], "cauchy_pdf": 155, "cauchy_logpdf": 155, "cauchy_cdf": 155, "cauchy_ppf": 155, "iqr": [155, 168, 175, 181, 252], "\u03b3": [155, 169, 191, 197, 204, 216, 220, 222, 231, 246], "hwhm": 155, "princip": [155, 171, 179, 189, 207], "howev": [155, 179, 210, 222, 241], "xrightarrow": [155, 207, 254], "trunc_abs_mo": [155, 207], "cauchy_loglik": 155, "cauchy_mle_scipi": 155, "log_gamma": [155, 180, 246], "x0_init": 155, "q25": [155, 168, 175, 252], "gamma_init": 155, "mead": [155, 163, 165, 166, 168, 175, 199, 210, 212, 225], "x0_hat": 155, "log_gamma_hat": 155, "true_x0": 155, "true_gamma": 155, "x_sampl": [155, 175], "gamma_hat": 155, "x0_med": 155, "gamma_iqr": 155, "sample_cauchy_inverse_cdf": 155, "sample_cauchy_ratio_norm": 155, "x_inv": [155, 176, 236], "x_rat": 155, "x_samp": [155, 161, 165, 177, 182, 185, 204, 213], "x_vi": [155, 158, 175], "running_mean": [155, 175, 196, 223], "block_median": [155, 175], "running_block_median": 155, "loc_m": [155, 175], "scale_iqr": [155, 175], "4n": [155, 175], "median_z_test_cauchy_loc": 155, "x0_null": 155, "se": [155, 156, 175, 189, 243, 245, 247, 249, 261, 266, 267, 268, 269], "x_h0": [155, 175], "x_h1": [155, 175], "4001": 155, "x0_map": 155, "med_z": 155, "scale_z": 155, "bump": [156, 197, 214], "tendenc": [156, 216, 255, 260], "pedagog": [156, 167], "tractabl": [156, 174, 195, 197, 203], "wigner": 156, "semicircl": [156, 202], "rcsin": 156, "f_0": [156, 175, 256], "cosine_support": 156, "cosine_pdf": 156, "cosine_cdf": 156, "cosine_logpdf": 156, "cosz": 156, "mass_trapz": 156, "max_abs_pdf_err": 156, "max_abs_cdf_err": 156, "sinh": [156, 181, 207, 229], "var0": [156, 177], "kurtosis_excess0": 156, "entropy0": [156, 175], "400_000": [156, 198, 210, 231, 249, 250, 268], "mean_mc": [156, 159, 161, 176, 180, 181, 188, 205, 213, 219, 224, 227, 229, 230, 233], "var_mc": [156, 161, 176, 180, 181, 188, 205, 213, 219, 224, 225, 227, 229, 233], "m4_mc": 156, "kurtosis_excess_mc": 156, "cosine_loglik": 156, "true_loc": [156, 175, 178, 206], "true_scal": [156, 168, 173, 175, 206, 220], "loc_grid": [156, 197], "scale_grid": [156, 167, 168, 173, 219], "mg": 156, "cosine_rvs_numpi": 156, "acceptance_r": 156, "accepted_tot": 156, "acc_rat": [156, 165], "w_k": [156, 191, 288], "varieti": 156, "priori": [156, 206, 212, 219, 238], "loc0": [156, 163, 165, 167, 168, 170, 172, 175, 177, 211, 219], "scale0": [156, 163, 165, 167, 168, 170, 172, 173, 175, 211, 212, 219], "x_u": [156, 233], "z_test_uniform_vs_cosin": 156, "z_u": 156, "z_c": [156, 200], "circular": [156, 206, 222], "inher": [156, 173], "absorpt": 157, "attach": [157, 240, 322, 339, 342, 357, 359], "radi": 157, "contamin": [157, 333], "normal_pdf": [157, 248, 261, 266, 269], "normal_cdf": [157, 258, 260, 261], "abs_z": 157, "2316419": [157, 261], "319381530": [157, 261], "356563782": [157, 261], "781477937": [157, 261], "821255978": [157, 261], "330274429": [157, 261], "normal_ppf": [157, 261], "969683028665376e01": [157, 199, 200, 248, 252, 261], "209460984245205e02": [157, 199, 200, 248, 252, 261], "759285104469687e02": [157, 199, 200, 248, 252, 261], "383577518672690e02": [157, 199, 200, 248, 252, 261], "066479806614716e01": [157, 199, 200, 248, 252, 261], "506628277459239e00": [157, 199, 200, 248, 252, 261], "447609879822406e01": [157, 199, 200, 248, 252, 261], "615858368580409e02": [157, 199, 200, 248, 252, 261], "556989798598866e02": [157, 199, 200, 248, 252, 261], "680131188771972e01": [157, 199, 200, 248, 252, 261], "328068155288572e01": [157, 199, 200, 248, 252, 261], "784894002430293e": [157, 199, 200, 248, 252, 261], "223964580411365e": [157, 199, 200, 248, 252, 261], "400758277161838e00": [157, 199, 200, 248, 252, 261], "549732539343734e00": [157, 199, 200, 248, 252, 261], "374664141464968e00": [157, 199, 200, 248, 252, 261], "938163982698783e00": [157, 199, 200, 248, 252, 261], "784695709041462e": [157, 199, 200, 248, 252, 261], "224671290700398e": [157, 199, 200, 248, 252, 261], "445134137142996e00": [157, 199, 200, 248, 252, 261], "754408661907416e00": [157, 199, 200, 248, 252, 261], "plow": [157, 199, 200, 248, 252, 254, 261], "02425": [157, 199, 200, 248, 252, 254, 261], "phigh": [157, 199, 200, 248, 252, 254, 261], "_validate_crystalball_param": 157, "crystalball_const": 157, "tail_area": 157, "gauss_area": 157, "p_tail": [157, 270], "crystalball_pdf": 157, "core_mask": 157, "z_core": 157, "z_tail": 157, "crystalball_cdf": 157, "phi_minus_beta": 157, "phi_z": 157, "crystalball_ppf": 157, "tail_mask": [157, 246, 270], "crystalball_rv": 157, "kurtosi": [122, 157, 162, 164, 165, 168, 169, 171, 173, 176, 180, 186, 188, 189, 193, 194, 197, 199, 201, 208, 209, 214, 217, 218, 221, 223, 228, 229, 237, 241], "g_0": [157, 234], "m_z": [157, 181, 197], "tb": [157, 184, 212, 217], "varphi_z": [157, 197], "_gaussian_core_mo": 157, "max_ord": [157, 191], "exp_term": 157, "_tail_raw_mo": 157, "comb": [157, 174, 206, 228], "crystalball_raw_moments_standard": 157, "tail_k": 157, "crystalball_stat": 157, "kurtosis_excess": [157, 211], "mean_z": 157, "var_z": 157, "stats_np": 157, "sp_stat": 157, "skew_": [157, 160, 164, 165, 170, 173, 176, 193, 197, 215, 219, 229, 241], "obei": 157, "rv_scale": 157, "h_scale": 157, "bulk": [157, 160, 178], "cdf_val": [157, 166, 194, 196, 203, 210, 231, 241], "pdf_max_abs_err": 157, "cdf_max_abs_err": 157, "m_true": [157, 185, 190, 234], "rv_true": [157, 173, 195, 218, 221, 225, 237], "m_hat": [157, 185, 190, 212], "sig0": 157, "loc1": [157, 165, 170, 172, 175, 177, 197], "scale1": [157, 165, 170, 172, 197], "loc_fix": [157, 158, 165, 167, 174], "scale_fix": [157, 158, 174, 197], "beta_map": 157, "m_map": 157, "rv_map": 157, "understood": [158, 180, 182, 214], "coin": [158, 161], "lasso": [158, 176], "repel": 158, "bimod": [158, 161], "dgamma_logpdf_standard": 158, "indetermin": 158, "dgamma_pdf_standard": 158, "dgamma_cdf_standard": 158, "pm1": [158, 202], "halv": 158, "disjoint": [158, 236], "dgamma_even_mo": 158, "dgamma_theory_summari": 158, "entropy_nat": [158, 198, 226, 232, 233, 241], "a_demo": [158, 208], "plot_pdf_famili": [158, 191, 214], "quickest": 158, "trigamma": [158, 180, 188], "psi_1": [158, 180, 188], "fit_a_mle_standard": 158, "polygamma": [158, 180], "x_synth": [158, 219], "9d": [158, 169, 180, 190], "cz": [158, 166, 167, 169, 180, 190], "dv": [158, 162, 169, 180, 190, 192, 194, 213, 214], "longleftarrow": 158, "gamma_rvs_mt": 158, "n_acc": 158, "dgamma_rvs_numpi": 158, "a_mc": 158, "plot_cdf_famili": 158, "a_vi": 158, "995": [158, 160, 161, 162, 163, 165, 167, 169, 171, 173, 178, 183, 190, 196, 197, 199, 203, 205, 218, 220, 225, 231, 250, 254], "empirical_cdf": [158, 163], "x_ecdf": [158, 199, 201, 219], "y_ecdf": [158, 199, 201, 219], "x_scipi": [158, 186], "a_fit": 158, "loc_fit": [158, 161, 166, 168, 175, 178, 179, 180, 182], "scale_fit": [158, 161, 166, 168, 175, 179, 180, 182], "a_fit_fix": 158, "lilliefor": [158, 162, 256], "repuls": 158, "a_dg": 158, "loc_dg": 158, "scale_dg": 158, "loc_lap": 158, "scale_lap": 158, "mu_n": [158, 183, 194, 210], "sd_n": 158, "ll_dg": 158, "ll_lap": 158, "ll_n": 158, "aic_dg": 158, "aic_lap": 158, "aic_n": 158, "a_known": 158, "ks_dg": 158, "ks_lap": 158, "ks_n": [158, 234], "neg_log_posterior": 158, "12_000": [158, 172, 188, 269], "a_gen": 158, "quantiz": [158, 161, 229], "simplex": [159, 228, 230], "matplotlib": [159, 271, 297, 298], "pyplot": [159, 271, 297, 298], "plt": [159, 271, 297, 298], "mtri": 159, "toggl": [159, 185, 221], "elsewher": [159, 185, 221, 354], "300_000": [159, 176, 177, 179, 192, 203, 239, 250, 268, 269], "rcparam": 159, "figsiz": [159, 271, 297, 298], "validate_alpha": [159, 240], "validate_simplex": 159, "allow_zero": 159, "dirichlet_logpdf_numpi": 159, "sample_dirichlet_numpi": 159, "dirichlet_mean": 159, "dirichlet_cov": 159, "beta_skew": 159, "beta_excess_kurtosi": 159, "dirichlet_entropi": 159, "sqrt3": 159, "simplex3_grid": 159, "min_compon": 159, "simplex3_to_xi": 159, "equilater": 159, "e2": [159, 160, 176, 225, 256, 402], "e3": [159, 225], "plot_simplex3_outlin": 159, "lw": 159, "set_aspect": 159, "set_xtick": 159, "set_ytick": 159, "plot_dirichlet_simplex3": 159, "scalarmapp": 159, "triangul": 159, "tricontourf": 159, "cmap": 159, "dirichlet_fit_ml": 159, "alpha_init": [159, 228], "sum_log_x": 159, "a0_est": 159, "grad_alpha": 159, "alpha_hat": [159, 196, 228, 240, 394], "alpha_1": [159, 228], "alpha_k": [159, 228], "alpha_0": [159, 162, 186, 224, 228, 241], "preview": [159, 334, 338], "lda": [159, 189], "speci": [159, 228], "alpha_2": 159, "conjugaci": [159, 165, 169, 170, 175, 180, 186, 195, 200, 206, 208, 213, 218, 224], "overdispers": [159, 169, 225, 228, 230, 239], "x_3": [159, 228, 230], "alpha_3": 159, "lauricella": 159, "cov_theori": [159, 230], "cov_mc": [159, 230], "skew_theori": [159, 169, 197, 208, 221], "exkurt_theori": [159, 208], "skew_mc": [159, 176, 180, 181, 221, 229], "exkurt_mc": [159, 180], "constrained_layout": 159, "mappabl": 159, "min_comp": 159, "set_titl": [159, 271], "cb": [159, 184, 217], "set_label": 159, "2e_i": 159, "x_ix_j": 159, "e_j": [159, 169, 227, 284, 322], "alpha_tru": [159, 169, 196, 228, 240], "8_000": [159, 175, 200, 217, 221, 222, 241, 250, 262], "046": 159, "samp": [159, 167, 209, 241], "4_000": [159, 185, 220, 244], "set_xlabel": 159, "set_ylabel": 159, "ax2": 159, "twinx": 159, "tab": 159, "lines1": 159, "labels1": 159, "get_legend_handles_label": 159, "lines2": 159, "labels2": 159, "notabl": [159, 173, 181, 185, 201, 207, 221, 338], "nontrivi": [159, 221, 233], "6_000": [159, 165, 244], "p_1": [159, 230, 237, 261], "p_2": [159, 230], "prior_alpha": 159, "posterior_alpha": 159, "rv_post": 159, "post_sampl": 159, "250_000": [159, 175, 180, 206, 221, 232, 247, 249], "p_gt": 159, "p_draw": [159, 235, 237], "future_count": 159, "pseudocount": 159, "dpln": 160, "bodi": [160, 350, 355], "firm": [160, 196], "logcdf": [160, 163, 171, 173, 191, 194, 199, 200, 203, 208, 226, 239], "dpln_dist": 160, "winner": 160, "phenomena": [160, 178, 196, 216, 219], "e_1": [160, 176, 230], "e_2": [160, 176], "v_2": 160, "y_2": [160, 239], "mill": 160, "igl": 160, "igr": 160, "log_sqrt_2pi": [160, 183, 188, 214], "log_phi": [160, 167], "log_ndtr": [160, 167, 203, 208, 214, 218], "log_phic": 160, "log_r": [160, 174], "log1mexp": 160, "dpln_logpdf": 160, "dpln_pdf": 160, "dpln_logcdf": 160, "t1": [160, 164, 184, 211, 266], "t5": 160, "return_sign": 160, "temp": [160, 348], "dpln_cdf": 160, "dpln_logsf": 160, "dpln_sf": 160, "dpln_raw_moment": 160, "dpln_mvsk_from_raw": 160, "kurt_excess": [160, 163, 164, 165, 166, 173, 176, 177, 211, 216, 224, 228, 229, 232, 234], "mean_f": [160, 176, 220, 229], "var_f": [160, 176, 220, 229], "skew_f": [160, 176, 220, 229], "kurt_f": [160, 176, 220, 229], "entropy_": [160, 164, 173, 193, 219], "80k": 160, "fig_alpha": 160, "fig_beta": 160, "fig_sigma": [160, 188], "kz": 160, "ke_1": 160, "ke_2": 160, "dpln_loglik": 160, "ll_true": [160, 172, 189, 195, 197, 198, 207], "ll_perturb": 160, "dpln_rvs_numpi": 160, "standard_exponenti": 160, "sf_tail": 160, "logsf": [160, 163, 167, 171, 191, 194, 199, 203, 240], "reusabl": [160, 219, 332, 333, 334, 335], "true_param": 160, "u_hat": [160, 185], "s_hat": [160, 168, 179, 181, 187, 199], "shape_ln": 160, "loc_ln": 160, "scale_ln": 160, "d_ln": 160, "p_ln": 160, "ll_dpln": 160, "ll_lognorm": 160, "k_dpln": 160, "k_lognorm": 160, "aic_dpln": 160, "aic_lognorm": 160, "q99": [160, 197], "reed": 160, "jorgensen": 160, "hajargasht": 160, "griffith": 160, "poverti": 160, "tour": [161, 197], "peaked": [161, 222, 248, 254, 258], "morph": [161, 163], "dip": 161, "bullet": 161, "rayleigh": [161, 186, 190, 205, 216, 220], "2q": [161, 229], "4pt": [161, 182], "_validate_param": [161, 167, 173, 227, 232], "dweibull_pdf": 161, "az": [161, 208, 334, 345, 351, 357], "dweibull_logpdf": 161, "nz": [161, 303], "dweibull_cdf": 161, "zneg": 161, "zpo": 161, "dweibull_ppf": 161, "qmid": 161, "out_mid": 161, "c_test": [161, 168, 182], "q_grid": 161, "x_from_q": 161, "q_back": 161, "max_err": [161, 229], "itz": 161, "tz": [161, 181], "57721": [161, 172, 179, 219, 220], "euler": [161, 172, 179, 186, 188, 201, 219, 220], "mascheroni": [161, 172, 179, 186, 188, 201, 219, 220], "dweibull_theoretical_stat": 161, "dweibull_entropi": 161, "euler_gamma": [161, 172, 179, 186, 188, 201, 219, 220], "c_demo": [161, 180, 199, 202], "mean_th": [161, 177, 180, 183, 205, 218, 219], "var_th": [161, 177, 180, 183, 205, 218, 219], "skew_th": [161, 177, 180, 218, 219], "kurt_th": [161, 177], "h_th": 161, "kurt_sp": [161, 163, 165, 177, 212, 220, 224, 227, 231, 232], "h_sp": 161, "nanquantil": 161, "y_plot": 161, "tfrac1c": 161, "frac1c": 161, "loglike_c": 161, "dweibull_rvs_numpi": 161, "c_sim": 161, "loc_vi": 161, "scale_vi": 161, "cdf_np": [161, 172, 177, 212, 229, 232, 240], "cdf_sp": [161, 172, 177, 212, 224, 229, 232, 240], "pdf_line": [161, 267], "suit": 161, "pdf_true": 161, "pdf_fit": 161, "c_true_bay": 161, "x_bay": 161, "c_map": [161, 168, 219], "c_lo": [161, 216, 220], "c_hi": [161, 216, 220], "noise_gauss": 161, "noise_dw": 161, "y_dw": 161, "strang": 161, "nonexist": [161, 182, 210], "strip": [161, 181, 250, 251, 268], "cornerston": 162, "packet": 162, "proof": [162, 188, 242, 244, 247, 252, 253, 254, 259, 261, 265], "exp_pdf": [162, 196], "exp_cdf": 162, "sample_expon_invers": 162, "exp_loglik": 162, "true_rat": 162, "rate_ml": 162, "loglik_tru": [162, 183, 194, 195], "loglik_ml": [162, 183], "\u2113": [162, 198, 236], "rate_hat": 162, "max_abs_diff": [162, 195], "hypothes": [162, 213, 218, 234, 238, 245, 249, 252, 258, 260, 263, 265], "\u03bb0": 162, "lambda0": [162, 227, 235, 236], "s_dist": 162, "p_two_sid": [162, 166, 182, 194, 196, 201, 245, 251], "p_lrt": 162, "p_two_sided_exact": 162, "p_lrt_asymptot": 162, "lam_grid": [162, 169, 193, 213, 227, 235, 236], "prior_pdf": [162, 169, 214, 223], "post_pdf": [162, 169, 214, 223], "simulate_poisson_process": 162, "arrival_tim": 162, "nonneg": [162, 164, 171, 173, 174, 178, 190, 201, 205, 219, 224, 228, 229, 230, 234, 252], "censor": [162, 213, 214, 216, 264], "\u03bbx": 162, "brentq": [163, 180, 190, 209, 215, 220], "erfc": [163, 178, 188], "reaction": 163, "psycholog": 163, "neurosci": 163, "motor": 163, "burst": [163, 303, 355], "chromatographi": 163, "spectrometri": 163, "exgauss_to_scipi": 163, "scipy_to_exgauss": 163, "exponnorm_logpdf_standard": 163, "erfcx": 163, "exponnorm_logpdf": 163, "exponnorm_pdf": 163, "exponnorm_cdf_standard": 163, "term1": [163, 190, 203, 210, 248, 258], "log_term2": [163, 218], "term2": [163, 190, 203, 210, 248, 258], "exponnorm_cdf": 163, "exponnorm_stats_closed_form": 163, "exponnorm_mgf": 163, "exponnorm_cf": 163, "\u03c6_x": [163, 181, 197, 202], "sample_exponnorm_numpi": 163, "sample_mo": [163, 176, 229], "k_from_skew": 163, "gamma1": 163, "exponnorm_mom_initial_guess": 163, "x_grid_for_plot": 163, "q_low": [163, 195, 196, 250], "q_high": [163, 195, 196, 250], "pdf_err": [163, 207, 216], "cdf_err": [163, 207, 216], "mean_cf": [163, 172, 224], "var_cf": [163, 172, 224], "skew_cf": [163, 172, 224], "kurt_cf": [163, 224], "6k": 163, "scipy_stat": [163, 167, 203, 247], "mgf_theori": [163, 181], "mgf_mc": [163, 171, 181, 193, 200, 217], "cf_theori": 163, "cf_mc": [163, 165, 200], "h_scipi": [163, 165, 216, 218, 225], "h_mc": [163, 165, 218], "k_hat_scipi": 163, "loc_hat_scipi": [163, 186], "scale_hat_scipi": [163, 186], "fit_exponnorm_ml": 163, "logk": [163, 241], "logscal": 163, "logk_hat": 163, "logscale_hat": 163, "k_hat_opt": 163, "loc_hat_opt": 163, "scale_hat_opt": 163, "delic": [163, 187, 195, 197, 206, 211], "k_hat": [163, 187, 209], "m_0": [163, 172, 175, 185, 190, 204], "halfnorm": 163, "pymc": [163, 172, 218], "ture": 163, "emiss": [163, 205, 229, 230], "hmm": 163, "rv0": 163, "ll_norm": [163, 188], "ll_expn": 163, "t_ob": [163, 197, 204, 263, 267, 268, 269], "t_boot": 163, "mu_b": [163, 266], "sigma_b": 163, "ll_n_b": 163, "loc_b": [163, 195], "scale_b": [163, 195, 219], "ll_e_b": 163, "suffer": [163, 165, 172, 216], "sf_naiv": 163, "sf_stabl": 163, "affin": [163, 172, 180, 189, 194, 196, 217, 219], "longrightarrow": [164, 178, 180, 186, 199, 201, 218, 226, 235], "gompertz": 164, "exponpow_sp": 164, "hazard": [164, 201, 216], "weibul": [164, 168, 171, 172, 173, 183, 201, 215], "sharpli": [164, 174, 176, 218, 229, 234], "_validate_exponpow_param": 164, "exponpow_logpdf": 164, "zb": 164, "logz_term": 164, "exponpow_pdf": 164, "exponpow_cdf": 164, "exponpow_ppf": 164, "sample_exponpow": 164, "exponpow_raw_mo": 164, "epsab": [164, 209], "epsrel": [164, 209], "exponpow_mgf": 164, "exponpow_cf": 164, "integrand_r": 164, "integrand_im": 164, "exponpow_entropi": 164, "m_3": [164, 170, 184, 205, 215, 254, 264], "3m_2m_1": 164, "2m_1": [164, 184], "m_4": [164, 170, 184, 205, 215, 254], "4m_3m_1": 164, "6m_2m_1": 164, "3m_1": [164, 184], "entropy_num": 164, "kurt_excess_": [164, 173], "mgf_t1": 164, "mgf_t2": 164, "cf_w1": 164, "mgf_mc_t1": 164, "mgf_mc_t2": 164, "cf_mc_w1": 164, "b_check": 164, "999999": [150, 160, 164, 172, 231], "500_000": [164, 211, 269], "mean_trunc": 164, "var_trunc": 164, "trunc": [164, 215], "b_samp": 164, "x_ppf": 164, "x_transform": 164, "b_vi": 164, "pdf_diff": [164, 171], "cdf_diff": [164, 171], "ks_statistic_to_fitted_exponpow": 164, "improp": [164, 184], "b_map": 164, "radial": [164, 201], "radial_nois": 164, "b_small": 164, "b_larg": 164, "row_height": [164, 254, 256], "bathtub": [165, 220], "exponweib_dist": 165, "weibull_min": [165, 168, 216, 219], "w_m": [165, 221, 301], "materi": [165, 167, 172, 175, 188, 219, 220, 236], "wear": [165, 220], "exponweib_cdf": 165, "zm": 165, "exm1c": 165, "exponweib_logpdf": 165, "neg_zc": 165, "exponweib_pdf": 165, "exponweib_ppf": 165, "qm": [165, 220], "exponweib_rvs_numpi": 165, "exponweib_sf": 165, "exponweib_hazard": 165, "logf": 165, "exponweib_raw_moment_seri": 165, "max_term": [165, 193, 256], "prefactor": [165, 225], "s_new": 165, "exponweib_mvsk_from_raw_mo": 165, "nscipi": [165, 170, 209, 229, 267], "infant": [165, 220], "mortal": [165, 220], "plot_pdf_grid": 165, "plot_cdf_grid": 165, "plot_hazard_grid": 165, "jy": 165, "justifi": [165, 202, 220], "routin": [165, 176, 177, 192, 200, 209, 210, 212, 224, 225, 257, 259], "exponweib_loglik": 165, "fit_exponweib_mle_via_minim": 165, "log_a": [165, 184, 214, 225], "log_scal": [165, 168, 175, 210], "crude": 165, "mean_emp": [165, 183], "var_emp": [165, 183], "fa": [165, 216, 221, 256], "nweibul": 165, "metropoli": [165, 188], "hast": 165, "frequentist": 165, "alt": [165, 251, 268], "broad": [165, 332, 384], "prior_mu": [165, 197], "prior_sigma": [165, 197], "1_500": [165, 170], "step_scal": 165, "a_ml": 165, "c_mle": [165, 174, 202, 216], "loc_ml": [165, 179, 202], "scale_ml": [165, 179, 202], "cur_lp": 165, "prop": [135, 137, 165, 228, 398], "prop_lp": 165, "scale_": [165, 171, 197], "a_mean": 165, "scale_mean": [165, 167, 168, 219], "a_95": 165, "c_95": [165, 216], "scale_95": 165, "rv_mle": 165, "x_mle": 165, "15_000": [165, 185, 221, 241], "pp_sampl": 165, "rv_i": 165, "admit": [165, 178, 182, 196], "snedecor": 166, "anova": [166, 191, 209, 244, 246, 248, 252, 259, 267, 268], "signific": [166, 191, 242, 243, 244, 246, 247, 248, 250, 252, 253, 254, 255, 256, 258, 259, 260, 262, 263, 264, 267, 268, 269, 270], "dfd": [166, 189, 191], "beta_func": 166, "s_2": [166, 250], "t_": [166, 192, 209, 210, 245, 262, 263, 266, 267], "prime": [166, 187], "_z": 166, "f_logpdf": [166, 191], "f_pdf": [166, 191, 250], "f_cdf": [166, 191], "2d_1": 166, "5d_2": 166, "f_moment_raw": 166, "f_mean": 166, "f_var": 166, "f_skew": 166, "f_kurt_excess": 166, "f_entropi": 166, "scipy_m": 166, "scipy_v": 166, "scipy_": 166, "scipy_k": 166, "dfn_fix": 166, "params_tail": 166, "dfd_fix": 166, "params_peak": 166, "f_loglik": 166, "rng_fit": [166, 224, 228], "dfn_true": [166, 191], "dfd_true": [166, 191], "neg_loglik": [166, 213], "dfn_hat": 166, "dfd_hat": 166, "dfn_fit": 166, "dfd_fit": 166, "mle_manu": 166, "mle_scipy_fit": [166, 188], "chisquare_rvs_numpi": [166, 193], "chisquar": [166, 191, 192, 193, 221, 230, 238, 240, 241, 246, 247, 249, 250, 259, 268], "f_rvs_numpi": 166, "m_theori": [166, 192], "v_theori": [166, 192], "n_1": [166, 226, 231, 244, 255, 260, 267], "n_2": [166, 226, 231, 255, 260, 267], "s_x": [166, 267], "jeffrei": [166, 184, 217], "bigg": [166, 205], "nu_2": 166, "nu_1": 166, "nu_i": 166, "n_i": [166, 243, 244, 249, 252, 257, 259], "rng_test": [166, 181, 228], "f_stat": [166, 189, 243], "p_left": [166, 182, 250], "nu1": [166, 205], "nu2": [166, 195], "scale_ratio": 166, "ci_level": [166, 267], "ci_post": 166, "sigma1_sq": 166, "sigma2_sq": 166, "ratio_mc": 166, "ci_mc": [166, 268], "y_heavi": 166, "y_normal": 166, "p_tail_heavi": 166, "p_tail_norm": 166, "variance_ratio_test": 166, "posterior_ci_closed_form": 166, "posterior_ci_monte_carlo": 166, "tail_p": 166, "fatiguelife_sp": 167, "sqrt2": 167, "sqrt2pi": 167, "microscop": 167, "damag": 167, "crack": 167, "competitor": 167, "2cx": 167, "fatiguelife_pdf": 167, "y_m": [167, 245], "fatiguelife_logpdf": 167, "log_jac": 167, "fatiguelife_cdf": 167, "ndtr": [167, 194, 197, 203, 208, 214], "fatiguelife_sf": 167, "5c": 167, "4c": 167, "11c": 167, "6c": 167, "93c": 167, "fatiguelife_mo": 167, "93": [19, 39, 134, 136, 167, 182, 191, 209, 253], "normal_expectation_gauss_hermit": 167, "hermit": 167, "hermgauss": 167, "fatiguelife_from_norm": 167, "fatiguelife_mgf_gh": 167, "fatiguelife_cf_gh": 167, "3c": 167, "fatiguelife_nl": 167, "fatiguelife_rvs_numpi": 167, "samples_np": [167, 170, 184, 200], "xs_sort": 167, "hist_xc": 167, "samps_sp": 167, "fit_c": 167, "fit_loc": [167, 210, 239], "fit_scal": [167, 210], "pit": [167, 171], "sigma_c": [167, 199], "logc_grid": 167, "logs_grid": 167, "burr": [168, 187], "_log1pexp": 168, "_expit": 168, "ea": 168, "_logit": 168, "fisk_logpdf": 168, "logz": [168, 213, 214, 216, 232, 234, 241], "fisk_pdf": 168, "fisk_cdf": 168, "fisk_sf": 168, "fisk_ppf": 168, "fisk_raw_mo": 168, "fisk_entropi": 168, "fisk_mod": 168, "fisk_moment": 168, "m0": [168, 183, 185, 189, 190, 203, 204, 224, 266], "fisk_hazard": 168, "pleasant": 168, "sine": [168, 207, 295, 300, 327], "fisk_loglikelihood": 168, "fisk_mle_loc_fix": 168, "mu_init": [168, 181, 188], "scale_init": [168, 175], "log_c_hat": 168, "log_scale_hat": [168, 175], "u_n": [168, 198], "fisk_rvs_numpi": 168, "clearest": 168, "ecdf_i": [168, 191, 216], "logistic_dist": 168, "pdf_our": [168, 173, 188, 206], "cdf_our": [168, 173, 188, 206], "pp": [168, 171, 230], "exceed": [168, 172, 213, 258], "true_c": [168, 173, 178, 216, 220], "ll_fisk": 168, "aic_fisk": 168, "s_logn": 168, "loc_logn": 168, "scale_logn": 168, "ll_logn": 168, "aic_logn": 168, "c_w": 168, "loc_w": 168, "scale_w": 168, "ll_w": 168, "aic_w": 168, "dist_hat": 168, "log_scale_grid": 168, "log_prior_c": [168, 222], "log_prior_scal": 168, "ij_map": 168, "scale_map": [168, 173, 219], "aft": 168, "scale_x": 168, "x_gen": 168, "fisk_pdf_naiv": 168, "x_big": 168, "1e10": 168, "1e50": 168, "log_stabl": 168, "accord": [169, 185], "certain": [169, 206, 232, 234, 242, 263], "erlang": 169, "gamma_logpdf": 169, "gamma_pdf": 169, "gamma_cdf": 169, "gamma_entropi": 169, "gamma_mgf": 169, "mgf": [169, 188, 201, 208, 214, 228], "gamma_cf": 169, "phi_x": 169, "closur": [169, 195, 234, 236], "excess_kurt_theori": [169, 221], "entropy_theori": 169, "memoryless": [169, 171, 213, 219, 220], "eventu": [5, 169, 341, 406], "theta_fix": 169, "alpha_fix": 169, "overlin": 169, "gamma_loglik": 169, "theta_hat_if_alpha_known": 169, "_gamma_rvs_mt_shape_ge_1": [169, 180, 190, 197], "smoke": [169, 190, 197, 205, 208], "alpha_test": 169, "theta_test": 169, "alpha_viz": 169, "theta_viz": 169, "n_viz": [169, 180, 190, 197, 199, 201, 208, 219], "sample_mean": [169, 190, 195, 197, 208, 226, 228, 231, 232, 233, 236, 237, 239], "sample_var": [169, 195, 197, 208, 231, 239], "theory_mean": [169, 190, 195, 208, 226, 228, 231, 232, 233, 236, 239, 241], "theory_var": [169, 195, 208, 231, 232, 233, 236, 239, 241], "intens": [169, 171, 174, 190, 203, 216], "alpha_data": 169, "theta_data": 169, "unrestrict": [169, 181, 214], "theta0_hat": 169, "ll_null": [169, 198, 202, 203, 214, 216, 218, 233], "ll_alt": [169, 195, 198, 214, 216, 218], "p_value_lrt": 169, "p_value_k": 169, "lambda_tru": [169, 220, 231], "alpha_lat": 169, "theta_lat": 169, "counts_mixtur": 169, "mean_count": 169, "counts_poisson": 169, "bin_spec": 169, "hurdl": 169, "_2f_1": [170, 224, 225, 234, 240], "elicit": [170, 211, 212], "armero": 170, "bayarri": 170, "cite": 170, "spirit": [170, 206, 242, 249], "kummer": 170, "gausshyper_norm": 170, "zx": 170, "hyp2f1": [170, 224, 225, 234, 240], "gausshyper_pdf_formula": 170, "m_n": [170, 172, 174, 187, 205], "raw_moment": 170, "mu2": [170, 172, 175, 183, 189, 191, 205, 211, 218, 228, 239, 267], "mom": [170, 181, 197, 198, 202, 211, 214, 221, 232, 237, 239, 241], "entropy_trapz": 170, "legendr": 170, "mgf_legendr": 170, "n_node": 170, "leggauss": 170, "8f": [170, 235], "gausshyper_logpdf_formula": 170, "xs_test": 170, "max_logpdf_err": 170, "rvs_gausshyper_numpi": 170, "return_accept": 170, "logm": 170, "logw": [170, 227, 232], "n_take": 170, "100_000_000": 170, "accept_r": [170, 188], "cookbook": 170, "data_fit": [170, 184], "z_fix": 170, "z0": [170, 194, 204, 258], "fz": 170, "p_gh": 170, "y_gh": 170, "p_beta": 170, "y_beta": 170, "mind": [170, 197], "assess": [170, 189, 215], "royal": [170, 244], "societi": [170, 244], "statistician": 170, "genexpon_sp": 171, "renew": 171, "bc": [171, 211, 261], "_validate_genexpon_param": 171, "genexpon_logsf": 171, "one_minus_exp": 171, "genexpon_sf": 171, "genexpon_cdf": 171, "genexpon_logpdf": 171, "genexpon_pdf": 171, "genexpon_hazard": 171, "genexpon_raw_moment_seri": 171, "term_k": 171, "log_ab": [171, 225], "genexpon_mgf_seri": 171, "kurt_excess_sp": 171, "entropy_sp": [171, 220], "mean_seri": 171, "var_seri": 171, "skew_seri": 171, "kurt_excess_seri": 171, "mgf_seri": 171, "980": [35, 38, 171, 178, 182, 192, 233, 265], "ct": 171, "ckx": 171, "insert": [171, 196, 253], "lambertw": 171, "x_hi": [171, 180, 199, 219], "sf_grid": 171, "ex2_num": 171, "genexpon_ppf_bisect": 171, "bracket": [171, 175, 180, 190, 204, 214, 215, 220, 227, 232, 233, 266], "cdf_mid": [171, 204], "sample_genexpon": 171, "interarriv": 171, "loc_": [171, 197], "ll_exp": 171, "ll_gen": 171, "k_exp": 171, "k_gen": 171, "naic": 171, "maxima": [172, 198, 219], "annual": 172, "wind": [172, 201, 216, 220, 222], "genextreme_sp": 172, "zeta": [172, 188, 197, 241], "gumbel": [172, 180, 181, 220], "b_n": 172, "tippett": 172, "gnedenko": 172, "climat": [172, 173], "discharg": 172, "fr\u00e9chet": 172, "cousin": [172, 175], "gpd": [172, 196], "gev_support": 172, "\u03be": 172, "gev_cdf": 172, "gev_pdf": 172, "gev_logpdf": 172, "gev_ppf": 172, "gev_rv": 172, "evt_to_scipi": 172, "scipy_to_evt": 172, "genextreme_pdf": 172, "genextreme_cdf": 172, "genextreme_ppf": 172, "g_k": [172, 220], "g_3": [172, 219, 220], "3g_2g_1": [172, 219], "2g_1": [172, 219], "g_4": [172, 219, 220], "4g_3g_1": [172, 219], "6g_2g_1": [172, 219], "3g_1": [172, 219], "13955": 172, "gev_closed_form_stat": 172, "g3": [172, 219, 220, 257, 259], "g4": [172, 219, 220], "exkurt_cf": 172, "entr_cf": 172, "entr_sp": 172, "q_t": [172, 303], "gev_loglikelihood": 172, "xi_tru": 172, "ll_bad": 172, "q_np": 172, "q_sp": 172, "xi_hat": 172, "shaki": 172, "lr_test_xi_zero": 172, "f0": [172, 177, 199, 209, 256], "ll_h1": 172, "ll_h0": 172, "h1_param": 172, "h0_param": 172, "gev_ppf_naiv": 172, "x_gumbel": 172, "x_naiv": 172, "x_stabl": 172, "err_naiv": 172, "err_stabl": 172, "0e": 172, "gengamma_dist": 173, "resembl": 173, "ca": [173, 184, 217], "int_u": 173, "gengamma_logpdf": 173, "ym": [173, 206], "gengamma_pdf": 173, "gengamma_cdf": 173, "gammaincc": [173, 197, 236], "gengamma_raw_mo": 173, "gengamma_mvsk": 173, "gengamma_entropi": 173, "gengamma_rvs_numpi": 173, "phi_hat": 173, "thinner": [173, 217], "a_fix": [173, 208, 241], "nca": 173, "mean_tru": 173, "var_tru": 173, "mean_hat": 173, "rv_fit": [173, 216], "true_a": [173, 186, 212, 216, 217, 241], "logpost_unnorm": 173, "cdf_post": [173, 174, 216, 218, 232, 234], "staci": 173, "1962": [173, 238], "annal": 173, "genhalflogistic_support": 174, "genhalflogistic_logpdf": 174, "log_u": [174, 200], "log_t": 174, "genhalflogistic_pdf": 174, "genhalflogistic_cdf": 174, "genhalflogistic_ppf": 174, "r_pow": 174, "cj": 174, "ey_pow": 174, "genhalflogistic_raw_mo": 174, "genhalflogistic_mo": 174, "ex_kurt": [174, 193, 209, 225, 238], "c_check": [174, 180], "pdf_z": 174, "2a": [174, 186, 202, 212, 239, 260], "genhalflogistic_loglikelihood": 174, "genhalflogistic_mle_c": 174, "genhalflogistic_rvs_numpi": 174, "ks_numpi": 174, "ks_scipi": 174, "iii": [174, 187, 219], "simplefilt": [174, 209, 237], "c_hat_fix": [174, 178, 219], "c_upper": 174, "ll_mle": [174, 184, 197], "x_bound": 174, "famous": 175, "charg": [175, 188, 349, 351], "absorb": [175, 188, 196, 203, 236, 355], "straggl": [175, 188], "chamber": 175, "mallow": 175, "stuck": 175, "moyal": 175, "1944": [159, 175, 209], "ioniz": [175, 188], "undergo": 175, "transfer": [175, 188], "rai": [175, 344, 349], "infrequ": [175, 339], "radiat": 175, "deposit": 175, "silicon": 175, "excurs": [175, 188], "cauchi": [175, 177, 204, 210], "deleg": [2, 175], "median0": 175, "q25_0": 175, "q75_0": 175, "iqr0": 175, "f0_at_median": 175, "brent": 175, "mode0": 175, "landau_cf_standard": 175, "complex128": [175, 211, 227], "0j": [175, 184, 193, 203, 204, 217, 224, 234, 240], "3001": [175, 269], "plot_landau_parameter_effect": 175, "tail_pdf_const": 175, "tail_sf_const": 175, "landau_loglik": 175, "landau_loc_scale_init": 175, "loc_init": 175, "landau_mle_scipi": 175, "landau_rvs_numpi": 175, "emp": [175, 223, 229, 237, 238], "symptom": 175, "clip_lo": 175, "clip_hi": 175, "fraction_clip": 175, "x_clip": [175, 178], "running_mean_clip": 175, "avg_block_median": 175, "loc_iqr": 175, "inappropri": 175, "c_2": [175, 251, 286], "median_z_test_landau_loc": 175, "loc_nul": 175, "m_null": 175, "5001": 175, "loc_map": [175, 197], "loc_to_mu": 175, "mu_to_loc": 175, "loc2": 175, "mu_z": 175, "c_z": 175, "loc_z": 175, "q_naiv": 175, "q_corr": 175, "underpin": [176, 193, 209], "privaci": [176, 229], "2p": [176, 182, 223, 226, 237], "_check_scal": [176, 188], "laplace_pdf": [176, 182], "laplace_logpdf": 176, "laplace_cdf": 176, "laplace_ppf": 176, "laplace_mo": 176, "ent_f": [176, 229], "ent_": [176, 229], "kurt_mc": [176, 181, 229], "laplace_cf": 176, "thick": [176, 219, 254], "laplace_loglik": 176, "laplace_mle_closed_form": 176, "b_floor": 176, "mu_hat_sp": 176, "b_hat_sp": 176, "iid": [176, 183, 186, 192, 194, 200, 202, 208, 209, 212, 221, 230, 249], "laplace_rvs_invers": 176, "laplace_rvs_exp_differ": 176, "mu_hat_cf": 176, "b_hat_cf": 176, "mu_0": [176, 181, 189, 192, 194, 203, 210, 218, 222, 245, 266, 268], "primit": [176, 211, 238, 268, 331, 332, 344, 350, 351, 358, 359], "releas": [176, 229, 332, 333, 346, 367], "laplace_lrt_mu": 176, "data0": [176, 219], "data1": 176, "lr1": 176, "b_prior": [176, 215], "theta_map": [176, 229], "theta_grid": [176, 229, 232], "theta_map_grid": 176, "theta_map_clos": 176, "\u03b4f": 176, "true_count": [176, 229], "b_nois": 176, "t95": 176, "glue": [177, 346, 347, 349, 350, 356], "_validate_kappa_scal": 177, "laplace_asymmetric_pdf": 177, "laplace_asymmetric_logpdf": 177, "laplace_asymmetric_cdf": 177, "20_001": 177, "_asymmetr": 177, "laplace_asymmetric_mo": 177, "laplace_asymmetric_entropi": 177, "meet": [177, 357], "laplace_asymmetric_nl": 177, "laplace_asymmetric_rvs_numpi": 177, "kappa_tru": 177, "kappa_hat": 177, "pdf_hat": 177, "cdf_hat": 177, "k1": [177, 191, 195, 237], "chi2_1": 177, "ald": 177, "nll_val": 177, "loc_hat_grid": 177, "loc_tau_quantil": 177, "kozubowski": 177, "podg": 177, "u00f3rski": 177, "passag": [178, 179, 203, 218], "anomal": 178, "implic": [178, 206, 236, 359], "erfcinv": [178, 188], "t_a": 178, "barrier": 178, "subordin": 178, "levy_pdf": 178, "zp": 178, "levy_logpdf": 178, "levy_cdf": 178, "levy_ppf": 178, "levy_ppf_via_norm": 178, "2ct": 178, "2ict": 178, "ac": 178, "pdf_tail": 178, "int_c": [178, 211], "levy_loglik": 178, "levy_mle_scale_given_loc": 178, "profil": [178, 220, 242, 256, 292, 341, 342], "levy_profile_nll_loc": 178, "min_x": 178, "sample_levy_numpi": 178, "q_the": 178, "qe": [178, 229, 235], "qt": [178, 196], "clip_q": 178, "pdf_center": 178, "run_mean": 178, "loc_hat_fix": [178, 179, 219], "levy_scale_ci_known_loc": 178, "a_post": [178, 182, 190, 196, 201, 224, 225, 237], "b_post": [178, 182, 186, 190, 196, 201, 215, 224, 225, 237], "nonposit": [178, 183], "stick": 178, "2_n": 178, "feller": 178, "sato": 178, "levi": 179, "levy_st": 179, "levy_l_dist": 179, "driftless": 179, "_l": 179, "erf": [179, 186, 188, 194, 201, 236, 242, 247, 252, 255, 258, 260, 264, 270, 389], "levy_l_logpdf": 179, "levy_l_pdf": 179, "levy_l_cdf": 179, "levy_l_ppf": 179, "pdf_max_err": [179, 203], "cdf_max_err": [179, 203], "ppf_max_err": 179, "roundtrip_max_err": 179, "invgamma": [179, 183], "scale_valu": 179, "loc_valu": 179, "scale_mle_given_loc": 179, "levy_l_loglik": 179, "profile_loglik": 179, "max_x": 179, "scipy_fit": 179, "profile_ml": 179, "optimizer_success": [179, 241], "levy_l_rvs_numpi": 179, "samples_trunc": 179, "scale_hat_fix": [179, 219], "fit_floc": 179, "post_ci": 179, "shock_scal": 179, "marsaglia": [180, 193], "tsang": [180, 193], "loggamma_logpdf": 180, "z_hi": 180, "709": [180, 188, 242], "loggamma_pdf": 180, "loggamma_cdf": 180, "loggamma_stat": 180, "pg3": 180, "loggamma_mgf": 180, "loggamma_cf": 180, "psi_2": 180, "psi_3": 180, "psi_k": 180, "sz": [180, 181, 199], "kappa_n": [180, 183, 210], "loc_demo": [180, 208], "scale_demo": [180, 208, 221], "exkurt_th": [180, 218, 219], "entropy_th": [180, 219], "dist_demo": 180, "samples_demo": 180, "entropy_mc": [180, 195, 199, 200], "mean_grid": [180, 198], "mode_grid": 180, "sd_grid": 180, "\u03c8": [180, 197], "\u03c8\u2081": 180, "loggamma_loglik_c": 180, "loggamma_score_c": 180, "mle_c_from_sampl": 180, "1e8": 180, "sol": [180, 189, 190, 220], "root_scalar": [180, 190, 220], "loggamma_rvs_numpi": 180, "s_np": 180, "s_sp": 180, "c_viz": [180, 199, 219], "loc_viz": [180, 197, 208, 219], "scale_viz": [180, 197, 208, 219], "x_lo": [180, 199, 219], "position": 180, "dist_fit": 180, "theo_q": 180, "samp_q": 180, "lambda_sampl": [180, 221], "log_lambda": 180, "bell": [181, 194, 195, 202, 226, 239], "5513": 181, "4s": [134, 136, 145, 181], "sech": 181, "logistic_cdf": 181, "logistic_pdf": 181, "logistic_logpdf": 181, "logistic_ppf": 181, "logistic_rv": 181, "logistic_mo": 181, "logistic_entropi": 181, "logistic_mgf": 181, "logistic_cf": 181, "interquartil": 181, "logistic_sd": 181, "logistic_iqr": 181, "antisymmetr": 181, "logistic_loglik": 181, "fit_logistic_ml": 181, "s_init": 181, "log_": [181, 197, 199, 204], "log_s_hat": 181, "scipy_loc": 181, "scipy_scal": 181, "samples_mc": [181, 199], "true_mu": [181, 183, 194, 222], "true_": 181, "x_fit": [181, 188], "mle_unrestrict": 181, "mle_mu_fix": 181, "s_tild": 181, "mle_h0": 181, "s_known": 181, "1201": 181, "mixture_logistic_pdf": 181, "mixture_logistic_rv": 181, "mix_sampl": 181, "pixelcnn": 181, "saliman": 181, "prone": 182, "sharper": [182, 327], "stackrel": [182, 188, 192, 208, 212, 221, 230, 252], "loglaplace_pdf_std": 182, "loglaplace_logpdf_std": 182, "loglaplace_cdf_std": 182, "loglaplace_ppf_std": 182, "loglaplace_rvs_numpi": 182, "loglaplace_pdf": 182, "loglaplace_logpdf": 182, "loglaplace_cdf": 182, "loglaplace_ppf": 182, "15c": 182, "7c": 182, "138c": 182, "615c": 182, "449c": 182, "132c": 182, "loglaplace_raw_mo": 182, "loglaplace_mean": 182, "loglaplace_vari": 182, "loglaplace_skew": 182, "loglaplace_excess_kurtosi": 182, "138": [182, 254], "615": [122, 182], "449": [49, 108, 182], "loglaplace_entropi": 182, "int_1": [182, 215], "2x_i": 182, "loglaplace_loglik_c": 182, "loglaplace_mle_c": 182, "x_left": [182, 264], "x_right": [182, 264], "c_mc": [182, 219], "z_samp": 182, "zgrid": 182, "c_hat_clos": 182, "c_hat_scipi": 182, "test_stat": [182, 201], "chi2_": [182, 221], "posterior_mean": [182, 198, 223, 226, 230, 236, 241], "posterior_ci": [182, 226, 236], "u_j": 183, "biomed": 183, "lognorm_logpdf": 183, "lognorm_pdf": 183, "lognorm_cdf": 183, "lognorm_ppf": 183, "lognorm_raw_mo": 183, "lognorm_mean": 183, "lognorm_var": 183, "lognorm_skew": 183, "lognorm_excess_kurtosi": 183, "lognorm_entropi": 183, "sample_lognorm": 183, "lognorm_loglik": 183, "log_mean_emp": 183, "log_std_emp": 183, "mu_valu": [183, 236], "ty": 183, "log_sampl": [183, 184], "z_mean_emp": 183, "z_std_emp": 183, "pdf_max_abs_diff": 183, "cdf_max_abs_diff": 183, "shape_hat": 183, "fit_loc_hat": 183, "fit_mu_hat": 183, "fit_sigma_hat": 183, "true_sigma": [183, 194, 201], "shapiro": [183, 248], "wilk": [183, 227, 248], "anderson": [183, 189, 247, 256], "darl": [183, 247, 256], "shapiro_stat": 183, "shapiro_p": 183, "t_stat": [183, 210, 249, 262, 266, 267, 269], "ttest_1samp": [183, 217, 269], "popmean": [183, 217, 269], "osm": 183, "osr": 183, "probplot": 183, "line_x": 183, "t_test_stat_for_mu": 183, "t_test_p": 183, "qq_r": 183, "kappa0": [183, 210], "ssq": [183, 210], "alpha_n": [183, 210], "beta_n": [183, 210], "sigma2_samp": 183, "mu_samp": 183, "median_samp": 183, "ci_95": [183, 196, 198], "posterior_mu_mean": 183, "posterior_sigma_mean": 183, "median_tru": 183, "median_95_ci": 183, "sigma_pr": 183, "log_prod": 183, "subseteq": [184, 237], "decad": 184, "normaliz": 184, "loguniform_pdf": 184, "log_b_over_a": 184, "loguniform_logpdf": 184, "loguniform_cdf": 184, "loguniform_ppf": 184, "int_a": [184, 211, 212, 216, 217], "xl": [184, 267], "3m_1m_2": 184, "4m_1m_3": 184, "6m_1": 184, "2m_2": 184, "ta": [184, 212, 217], "itb": [184, 217], "ita": [184, 217], "equivari": 184, "loguniform_raw_mo": 184, "loguniform_entropi": 184, "loguniform_mgf": 184, "loguniform_cf": 184, "loguniform_mo": 184, "mc_skew": [184, 239], "mc_excess_kurt": [184, 239], "mc_mgf_t1": 184, "mc_mgf_t2": 184, "1e4": [184, 228], "a_min": [184, 251, 261], "b_max": 184, "loguniform_loglik": 184, "ll_expand": 184, "ll_shrunk_invalid": 184, "loguniform_rvs_numpi": 184, "1e3": [184, 228, 233], "fig_log": 184, "samples_scipy_smal": 184, "uninform": [184, 217, 255], "loguniformli": 184, "a_test": [184, 186, 208], "b_test": 184, "sigma_min": 184, "sigma_max": 184, "sigma_grid": 184, "post_mod": 184, "fig_lr": 184, "a_big": 184, "b_big": 184, "1e200": 184, "x_logspac": 184, "x_power": 184, "alia": [184, 241], "n_experi": 185, "vec_f": 185, "fortran": 185, "kron": 185, "unvec_f": 185, "ar1_cov": 185, "chol_spd": 185, "validate_matrix_normal_param": 185, "rowcov": 185, "colcov": 185, "matrix_normal_rvs_numpi": 185, "l_u": 185, "l_v": 185, "matrix_normal_logpdf_numpi": 185, "logdet_u": 185, "logdet_v": 185, "quad_form": 185, "manova": 185, "spatiotempor": 185, "i_p": 185, "m_": [185, 192, 205, 234, 255], "wishart": [185, 189], "lebesgu": [185, 207], "rvert_f": 185, "componentwis": [185, 230], "phi_": 185, "logpdf_scipi": [185, 189], "logpdf_numpi": 185, "entrywis": 185, "jj": [185, 221], "isserli": [185, 221], "wick": 185, "iT": [185, 221], "x_vec": 185, "sigma_theori": 185, "mean_err": 185, "rel_cov_err": 185, "cu": 185, "rho_u": 185, "rho_v": 185, "flop": 185, "flip_flop_ml": 185, "trace_v": 185, "prev_ll": 185, "u_new": 185, "v_new": 185, "u_tru": 185, "v_true": 185, "v_hat": 185, "rel_sigma_err": 185, "azb": 185, "l_vl_v": 185, "l_ul_u": 185, "bivari": [185, 208, 262], "mu_ij": 185, "var_ij": 185, "s_samp": [185, 187], "einsum": [185, 221, 393], "i1": [185, 205, 206, 244, 252, 289], "j1": [185, 206], "i2": [185, 289], "j2": 185, "yg": 185, "histogram2dcontour": 185, "nbinsi": 185, "showlabel": [185, 189, 254], "m_small": [185, 224], "1x2": 185, "u_smal": 185, "v_small": 185, "sigma_smal": [185, 205], "cdf_small": 185, "q_r": 185, "mnp": 185, "crit": [185, 191, 192, 193, 242, 244, 249, 252, 254], "frobeniu": [185, 221], "kinet": 186, "boltzmann": [186, 235], "molecular": 186, "isotrop": [186, 201, 205], "\u03c7": 186, "erfi": 186, "z_3": 186, "2_3": 186, "v_z": 186, "ga": [186, 252], "thermodynam": 186, "chi_": 186, "_validate_scal": 186, "maxwell_pdf": 186, "maxwell_logpdf": 186, "maxwell_cdf": 186, "3a": 186, "2t": [186, 193, 203, 221], "iz": 186, "5772": 186, "5772156649015328606": 186, "maxwell_mean": 186, "maxwell_var": 186, "maxwell_mod": 186, "maxwell_skew": 186, "maxwell_excess_kurtosi": 186, "maxwell_entropi": 186, "maxwell_mgf": 186, "maxwell_cf": 186, "k_excess": 186, "3n": [186, 253], "maxwell_loglik": 186, "maxwell_ml": 186, "a_hat_clos": [186, 198], "maxwell_rvs_numpi": 186, "sim_a": 186, "min_q": 186, "max_q": 186, "beta_sampl": 186, "a_sampl": 186, "vx": 186, "genuin": 186, "anisotropi": [186, 189], "precipit": [187, 197], "mielke_logpdf": 187, "log1p_x": 187, "mielke_pdf": 187, "mielke_logcdf": 187, "log1p_xneg": 187, "mielke_cdf": 187, "mielke_ppf": 187, "mielke_rvs_numpi": 187, "mielke_raw_mo": 187, "mielke_entropi": 187, "mielke_summary_stat": 187, "pdf_burr": 187, "s_fix": [187, 199], "fig_pdf_k": 187, "k_fix": [187, 209], "s_list": 187, "fig_pdf_": 187, "mielke_loglik": 187, "k_try": 187, "s_try": 187, "k_samp": 187, "k_vi": 187, "s_vi": 187, "k_hat1": 187, "s_hat1": 187, "s_grid": [187, 254, 389], "s_term": 187, "remark": [188, 204], "sqrt_2": 188, "moyal_logpdf": 188, "exp_neg_z": 188, "745": [134, 188], "moyal_pdf": 188, "moyal_cdf": 188, "moyal_ppf": 188, "riemann": 188, "skew_standard": 188, "excess_kurt_standard": 188, "excess_kurt_scipi": [188, 214], "moyal_nll_mu_logsigma": 188, "logsigma": 188, "mu_ml": [188, 236], "sigma_ml": [188, 205], "mu_fit_scipi": 188, "sigma_fit_scipi": 188, "mle_optim": 188, "opt_success": [188, 226, 232, 233], "moyal_rvs_numpi": 188, "mu_v": [188, 218], "sigma_v": 188, "moyal_loc": 188, "moyal_scal": 188, "normal_loc": 188, "normal_scal": 188, "ll_moyal": 188, "aic_moy": 188, "aic_norm": 188, "ks_moyal": 188, "ks_norm": 188, "moyal_fit": 188, "normal_fit": 188, "log_likelihood": [188, 224], "log_posterior": 188, "step_mu": 188, "step_logsigma": 188, "mu_chain": 188, "logsig_chain": 188, "sigma_init": [188, 205], "mu_curr": 188, "logsig_curr": 188, "logp_curr": 188, "mu_prop": 188, "logsig_prop": 188, "logp_prop": 188, "mu_post": 188, "sigma_post": 188, "mu_mean": [188, 222], "mu_ci95": 188, "sigma_mean": 188, "sigma_ci95": 188, "fig_mu": 188, "params1": [188, 208], "params2": 188, "trim": [188, 245, 259, 263, 266], "qda": 189, "allow_singular": 189, "relax": 189, "ellipsoid": 189, "mahalanobi": 189, "i_d": 189, "2_d": 189, "rectangl": [189, 211, 217], "orthant": [189, 228], "_check_mean_cov": 189, "mvn_logpdf": 189, "maha2": 189, "mvn_pdf": 189, "mvn_rv": 189, "mvn_cdf_mc": 189, "standard_error": 189, "logpdf_our": 189, "mardia": 189, "subvector": 189, "x_a": [189, 256], "x_b": [189, 256], "lambda_1": 189, "lambda_d": 189, "\u03c1": 189, "line_smooth": 189, "cov_hat_ml": 189, "nsigma_tru": 189, "nsigma_hat": 189, "mu_fit": [189, 194], "cov_fit": 189, "ll_fit": [189, 207], "nlog": 189, "delta2": [189, 193], "z_pdf": 189, "rv2": 189, "z_cdf": 189, "x_point": 189, "p_mc": [189, 246, 247, 253, 256, 259], "se_mc": 189, "p_scipi": [189, 243, 247, 251, 252, 253, 259, 262, 265], "nmu_fit": 189, "hotel": 189, "gmm": [189, 194], "vae": 189, "xbar": [189, 194, 227], "s_unbias": 189, "2_i": 189, "delta2_sort": 189, "chi2_q": 189, "maxv": 189, "mvn": 189, "vn": 189, "prec0": 189, "precl": 189, "wireless": [190, 201, 205], "envelop": [190, 201, 205], "baseband": 190, "rician": [190, 201], "textur": 190, "_validate_nakagami_param": 190, "nakagami_logpdf": 190, "nakagami_pdf": 190, "nakagami_cdf": 190, "mu_r": [190, 233], "4m": 190, "tfrac32": [190, 202, 206, 218], "m_y": 190, "nakagami_raw_mo": 190, "nakagami_mean": 190, "nakagami_var": 190, "nakagami_skew_kurt": 190, "nakagami_mgf": 190, "gamma_ratio": 190, "nakagami_cf": 190, "nakagami_entropi": 190, "m_ex": 190, "omega_ex": 190, "mu_ex": 190, "var_ex": 190, "skew_ex": [190, 197], "kurt_ex": 190, "entropy_ex": 190, "develop": [190, 333, 335, 358], "multipath": [190, 201, 205], "nakagami_loglik": 190, "nakagami_ml": 190, "omega_hat": 190, "infin": [190, 220], "omega_tru": 190, "nakagami_rvs_numpi": 190, "m_test": 190, "omega_test": 190, "m_viz": 190, "omega_viz": 190, "sample_m2": 190, "theory_m2": 190, "omega_scipi": 190, "nu_hat": [190, 205], "m_hat_scipi": 190, "omega_hat_scipi": 190, "m_hat_ml": 190, "omega_hat_ml": 190, "omega_0": 190, "nm": 190, "circularli": 190, "m_alt": 190, "omega_alt": 190, "omega0": 190, "omega1": 190, "m_known": 190, "lambda_samp": [190, 201, 220], "omega_samp": 190, "rapid": 190, "alouini": [190, 205], "nc": [191, 192, 193, 220], "df1": [191, 250, 259], "df2": [191, 250, 259], "nct": 191, "i_": [191, 193, 202, 207, 210, 226, 231, 239], "i_z": [191, 202], "validate_ncf_param": 191, "logc": [191, 200, 215, 229], "poisson_weights_trunc": 191, "ncf_pdf_seri": 191, "wk": 191, "renorm": 191, "ncf_cdf_seri": 191, "pdf_seri": 191, "cdf_seri": 191, "bulki": 191, "ncx2_raw_moment": 191, "dof": [191, 246], "\u03ba_r": 191, "kappa_r": [191, 232, 237], "k2": [191, 237, 248], "k3": [191, 237], "k4": [191, 237], "chisquare_neg_mo": 191, "ncf_raw_moment": 191, "ev_inv": 191, "raw_to_centr": 191, "\u03bc2": 191, "\u03bc3": 191, "\u03bc4": 191, "ncf_mean_clos": 191, "ncf_var_clos": 191, "size\u00b2": 191, "nc_true": [191, 193], "neg_loglik_nc": 191, "ncf_rvs_numpi": 191, "fit_r": [191, 223, 227, 231, 234, 235, 236, 237, 238, 239, 240, 241], "nc_hat": [191, 192, 193], "f_crit": 191, "nc_grid": [191, 193], "flavor": [191, 192, 199, 228], "prior_nc": 191, "prior_pow": 191, "e_prior": 191, "ncf": 192, "dedic": [192, 266, 323, 334, 352], "nctdtr": 192, "nct_pdf": 192, "nct_logpdf": 192, "nct_cdf": 192, "varphi_t": [192, 210], "e_v": 192, "_e_scaled_inv_chi_pow": 192, "nct_moments_closed_form": 192, "y4": [192, 265], "s4": 192, "nc_fix": 192, "df_fix": [192, 209], "t_1": [192, 210, 263], "t_n": 192, "nct_neg_loglik": 192, "true_df": 192, "true_nc": 192, "nct_rvs_numpi": 192, "df_hat": [192, 193, 209, 210, 221], "mathsf": [192, 202], "power_two_sided_t": 192, "mu_minus_mu0": 192, "isf": 192, "sig": 192, "61": [192, 231], "eff": 192, "prior_d": 192, "prior_delta": 192, "challeng": 192, "nonconvex": 192, "2_k": 193, "\u03bd": [193, 205, 210], "arepsilon_i": 193, "wald": [193, 214], "u_2": [193, 194, 212, 260], "rac12": 193, "marcum": [193, 205], "q_m": 193, "w_j": 193, "ncx2_logpdf": 193, "i_v": [193, 239], "log_iv": [193, 239], "ncx2_pdf": 193, "ncx2_cdf_poisson": 193, "chi2_cdf": [193, 246], "_df0": 193, "_nc0": 193, "_dist0": 193, "area_scipi": 193, "area_numpi": 193, "arphi": 193, "2it": 193, "ncx2_moment": 193, "ncx2_mgf": 193, "ncx2_cf": 193, "df0": [193, 221, 267], "nc0": 193, "exkurt_": [193, 215, 219], "t_val": 193, "mgf_th": [193, 217], "2nc": 193, "mean_target": [193, 237], "param_same_mean": 193, "ncx2_loglikelihood": 193, "df_true": [193, 209, 221], "nc_mle": 193, "ncx2_rvs_numpi": 193, "df_eff": 193, "ks_stat": [193, 219], "ks_p": [193, 198, 219], "zcrit": [193, 261], "mu_val": 193, "\u03bc1": 193, "sqrt_2pi": [194, 261], "norm_pdf": [194, 214, 254], "norm_cdf": [194, 214, 242, 264, 389], "norm_logpdf": [194, 214], "norm_loglik": 194, "norm_ml": 194, "sample_norm_box_mul": 194, "u1": [194, 260], "u2": [194, 260], "68": [51, 142, 169, 194, 240, 260], "loglik_hat": 194, "z_0": 194, "big_sampl": 194, "sigma_fit": 194, "cdf_direct": 194, "logcdf_stabl": 194, "sf_direct": 194, "logsf_stabl": 194, "tau_0": 194, "tau_n": 194, "sigma_known": 194, "z_crit": 194, "tau0": 194, "tau_n2": 194, "tfrac1n": 194, "nig": 195, "turbul": 195, "l\u00e9vy": 195, "hyperbol": [195, 207], "nig_valid": 195, "nig_gamma": 195, "nig_logpdf": 195, "kve": 195, "log_k1": 195, "nig_pdf": 195, "to_scipy_param": [195, 211], "from_scipy_param": [195, 211], "iux": 195, "delta_1": 195, "delta_2": 195, "nig_mean": 195, "nig_var": 195, "nig_skew": 195, "nig_excess_kurt": 195, "nig_mgf": 195, "nig_cf": 195, "nig_loglik": 195, "misspecifi": 195, "loglik_alt": 195, "michael": 195, "schucani": 195, "haa": 195, "sample_invgauss_msh": 195, "sample_nig": 195, "plot_nig_pdf": 195, "rv_hat": 195, "ks_ob": [195, 219], "ks_boot": [195, 219], "a_b": 195, "b_b": 195, "rv_b": 195, "eps_nig": 195, "eps_norm": 195, "s_nig": 195, "s_norm": 195, "bursti": [3, 4, 196], "lomax": 196, "pareto_pdf": 196, "pareto_sf": 196, "pareto_cdf": 196, "pareto_ppf": 196, "pareto_rv": 196, "xm0": 196, "pareto_mo": 196, "scipy_mean": [196, 216, 228, 232, 233], "scipy_var": [196, 216, 225, 228, 232, 233], "scipy_skew": [196, 216, 225, 228, 232], "scipy_excess_kurt": 196, "scipy_entropi": 196, "xm_demo": 196, "alphas_demo": 196, "n_demo": [196, 234, 264], "yaxis_typ": [196, 198, 215, 242, 258, 264], "pareto_mle_alpha": 196, "pareto_ml": 196, "xm_hat": 196, "xm_true": 196, "scipy_b_hat": 196, "scipy_loc_hat": 196, "scipy_scale_hat": 196, "scipy_fit_floc0": 196, "pareto_loglik_alpha": 196, "pareto_rvs_via_exponenti": 196, "b_hat0": 196, "loc_hat0": 196, "scale_hat0": 196, "alpha_ml": 196, "xm_mle": 196, "fit_free_loc": 196, "fit_floc0": 196, "lorenz": 196, "alpha_low": 196, "alpha_high": 196, "test_h0_alpha": 196, "0_p": 196, "target_shar": 196, "alpha_8020": 196, "top_share_emp": 196, "top_share_theori": 196, "w_sort": 196, "lorenz_theori": 196, "embrecht": 196, "kl\u00fcppelberg": 196, "mikosch": 196, "newman": 196, "zipf": [196, 198, 240, 241], "been": [197, 234], "flood": 197, "pollut": 197, "norm2pearson_transit": 197, "6e": 197, "pearson3_standard_param": 197, "pearson3_support": 197, "_norm_logpdf": 197, "_norm_cdf": 197, "pearson3_logpdf": 197, "mask_po": [197, 219, 220], "mask_zero": [197, 219, 220], "pearson3_pdf": 197, "pearson3_cdf": 197, "pearson3_entropi": 197, "h_gamma": 197, "pearson3_mgf": 197, "pearson3_cf": 197, "loc_ex": [197, 219], "scale_ex": [197, 219], "kurt_excess_theori": 197, "skew_fix": 197, "pearson3_loglik": 197, "skew_tru": 197, "loc_mom": 197, "scale_mom": 197, "skew_mom": 197, "params_mom": 197, "params_ml": 197, "ll_mom": 197, "support_mom": 197, "pearson3_rvs_numpi": 197, "skew_test": 197, "loc_test": [197, 208], "scale_test": [197, 208], "sample_skew": [197, 239, 248, 264], "skew_viz": 197, "90_000": 197, "lb": [197, 369], "ub": 197, "skew_hat": [197, 217, 223], "fit_norm_and_l": 197, "fit_p3_and_l": 197, "skew_alt": 197, "loc_alt": 197, "scale_alt": 197, "skew1": 197, "ll0b": 197, "ll1b": 197, "bootstrap_p_valu": [197, 245], "p3_fit_skew": 197, "loc_lo": 197, "loc_hi": 197, "_ci": [197, 226, 232, 236], "skew_lp3": 197, "loc_lp3": 197, "scale_lp3": 197, "log10q": 197, "q999": 197, "lesssim": 197, "vii": 197, "agenc": 197, "guidanc": 197, "sx": [198, 228, 230, 255], "powerlaw_pdf": 198, "powerlaw_cdf": 198, "powerlaw_ppf": 198, "powerlaw_mo": 198, "powerlaw_mgf": 198, "1f1": [198, 205], "powerlaw_cf": 198, "mc_mgf": 198, "theory_mgf": 198, "agrid": 198, "fig_mean": 198, "powerlaw_loglikelihood": 198, "powerlaw_mle_shap": 198, "powerlaw_rvs_numpi": 198, "a_hat_fit": [198, 216], "rv_beta": 198, "max_pdf_diff_beta": 198, "p_value_chi2": 198, "ks_d": 198, "max_u": 198, "samples_pw": 198, "xs1": 198, "ys1": 198, "ys2": 198, "problemat": 198, "powerlognorm_dist": 199, "y_c": [199, 249, 262], "trigger": [134, 136, 138, 139, 141, 143, 144, 145, 146, 199, 244, 248, 249, 332, 333, 340, 347, 348, 349, 350, 354, 356, 373, 384], "lehmann": [199, 200, 260], "powerlognorm_logpdf": 199, "powerlognorm_pdf": 199, "powerlognorm_logsf": 199, "powerlognorm_sf": 199, "powerlognorm_cdf": 199, "powerlognorm_ppf": 199, "ksz": 199, "powerlognorm_raw_moment_quad": 199, "log_val": 199, "s_demo": 199, "mean_quad": 199, "var_quad": 199, "kurt_scipi": [199, 205, 214], "skew_quad": 199, "kurt_excess_quad": 199, "earliest": 199, "_x_grid_for_param": 199, "param_list": 199, "params_c": 199, "x_grid_c": 199, "params_": 199, "powerlognorm_nl": 199, "params_unconstrain": 199, "norm_ppf_acklam": [199, 200], "acklam": [199, 200, 248, 252, 254, 261], "ration": [199, 200, 203, 248, 252, 254, 261], "peter": [199, 200], "2003": 199, "powerlognorm_rvs_numpi": 199, "powerlognorm_rvs_numpy_integer_c": 199, "c_int": [199, 200], "c_chk": 199, "s_chk": 199, "n_chk": 199, "m_numpi": 199, "v_numpi": 199, "s_viz": 199, "c_alt": 199, "s_alt": 199, "h1_fit": 199, "h0_fit": 199, "fragil": [199, 374], "misconcept": [199, 262], "weakest": [200, 220], "subcompon": 200, "emphasi": 200, "powernorm_logpdf": 200, "powernorm_pdf": 200, "powernorm_cdf": 200, "log_sf": 200, "powernorm_ppf": 200, "n_entropi": 200, "x_ent": 200, "ent_mc": 200, "true_mean": 200, "true_var": 200, "true_skew": 200, "true_exkurt": 200, "true_ent": 200, "true_entropi": 200, "john": 200, "powernorm_rvs_numpi": 200, "mean_np": 200, "var_np": [200, 212], "sum_log_phi": 200, "sum_log_u": 200, "n_group": 200, "nist": [200, 243], "handbook": [200, 243], "rice": 201, "rotation": 201, "polar": [201, 206, 222], "f_r": [201, 205, 209], "sight": [201, 205], "demodul": 201, "mri": [201, 205], "byproduct": 201, "rayleigh_pdf": 201, "rayleigh_cdf": 201, "rayleigh_logpdf": 201, "rayleigh_ppf": 201, "rayleigh_mean": 201, "rayleigh_var": 201, "rayleigh_skew": 201, "rayleigh_excess_kurtosi": 201, "rayleigh_entropi": 201, "rayleigh_mgf": 201, "landmark": 201, "rayleigh_loglik": 201, "rayleigh_mle_sigma": 201, "rayleigh_rvs_numpi": 201, "rayleigh_rvs_via_norm": 201, "sigma_viz": [201, 205], "x_y": 201, "2_2": [201, 248], "p_lower": [201, 239], "p_upper": [201, 236, 239], "sigma_ci_lo": 201, "sigma_ci_hi": 201, "sigma_samp": 201, "amp": [201, 318, 319], "jq": [201, 359], "misspecif": [201, 220, 239, 254], "borrow": 202, "phenomenolog": 202, "_check_c": 202, "rdist_logpdf": 202, "rdist_pdf": 202, "rdist_cdf": 202, "rdist_rvs_numpi": 202, "rdist_mean": 202, "rdist_var": 202, "rdist_excess_kurtosi": 202, "rdist_even_mo": 202, "rdist_mgf": 202, "abs_t": [202, 249, 269], "rdist_cf": 202, "abs_w": 202, "jv": 202, "rdist_entropi": 202, "frac32": 202, "rdist_loglik": 202, "rdist_mom_c": 202, "c_mom": 202, "n_hist": 202, "pdf_r": 202, "transformed_beta_pdf": 202, "rdist_loglik_scipi": 202, "c_sphere": 202, "coord": 202, "scientif": [202, 240], "c_big": 202, "x_edg": 202, "pdf_direct": 202, "rig": 203, "travel": [203, 218, 353], "recipinvgauss_logpdf": 203, "recipinvgauss_pdf": 203, "recipinvgauss_cdf": 203, "recipinvgauss_mo": 203, "variou": 203, "recipinvgauss_loglikelihood": 203, "recipinvgauss_mle_mu": 203, "invgauss_rvs_numpi": [203, 218], "y_star": [203, 263], "recipinvgauss_rvs_numpi": 203, "mu_hat_clos": 203, "mu_hat_fit": 203, "like_mean": 203, "like_var": 203, "prior_prec": 203, "like_prec": 203, "post_prec": 203, "post_std": 203, "untrunc": [203, 214, 216], "n_draw": [203, 235], "theta_draw": 203, "mu_draw": 203, "mu_tau": 203, "y_mix": [203, 231], "reson": 204, "relbw": 204, "collid": 204, "meson": 204, "analys": [204, 252, 267], "imaginari": [151, 204, 207], "_check_posit": 204, "rel_breitwigner_k": 204, "rel_breitwigner_pdf": 204, "rel_breitwigner_logpdf": 204, "rel_breitwigner_cdf": 204, "rho_test": 204, "200_001": 204, "rel_breitwigner_mean": 204, "rel_breitwigner_second_mo": 204, "rel_breitwigner_var": 204, "rel_breitwigner_cf": 204, "f_co": 204, "f_sin": 204, "plot_pdf_cdf_for_rho": 204, "pdf_rbw": 204, "pdf_cauchi": 204, "nll_rho_onli": 204, "rho_tru": 204, "rel_breitwigner_ppf_bisect": 204, "mask1": 204, "uu": 204, "cdf_hi": 204, "go_right": 204, "rel_breitwigner_rvs_numpi": 204, "rho_hat": 204, "1876": [204, 244], "4952": 204, "110": [142, 204, 260, 299], "gev": [204, 219], "logpdf_uniform_bg": 204, "logpdf_sign": 204, "logpdf_mixtur": 204, "x_bg": 204, "t_null": [204, 268, 269], "ll0_b": 204, "ll1_b": 204, "rho_grid": 204, "rho_map": 204, "noncentr": 205, "reparam": 205, "sinusoid": [205, 265], "gg": 205, "int_b": [205, 211], "rice_logpdf": 205, "log_i0": 205, "rice_pdf": 205, "rice_rvs_numpi": 205, "m_r": [205, 215], "rice_raw_mo": 205, "rice_mean": 205, "rice_central_mo": 205, "rice_skew_kurtosi": 205, "nu0": [205, 221], "mean_our": 205, "var_our": 205, "skew_our": 205, "kurt_our": 205, "i_2": 205, "r_1": [205, 251, 260], "rice_negloglik": 205, "nu_tru": 205, "nu_init": 205, "nu_ml": 205, "nu_test": 205, "sigma_test": 205, "nu_viz": 205, "b_viz": 205, "rayleigh_sigma_ml": 205, "loglik_ric": 205, "loglik_rayleigh": 205, "nu_alt": 205, "sigma_alt": 205, "llr": 205, "nu_big": 205, "r_grid": 205, "spectra": [206, 295], "ry": [206, 265], "_check_loc_scal": 206, "semicircular_pdf": 206, "semicircular_cdf": 206, "semicircular_logpdf": 206, "y_in": 206, "semicircular_rv": 206, "catalan": 206, "c_n": 206, "j_1": 206, "rt": [206, 236, 389], "2i_1": 206, "2j_1": 206, "semicircular_mean": 206, "semicircular_var": 206, "semicircular_excess_kurtosi": 206, "catalan_numb": 206, "semicircular_central_moment_2n": 206, "semicircular_mgf": 206, "semicircular_cf": 206, "semicircular_entropi": 206, "4th": [206, 223, 248], "mu4_mc": 206, "mu4_th": 206, "x_semi": 206, "x_unif": 206, "ks_semi": 206, "ks_unif": 206, "_normalize_on_grid": 206, "log_unnorm_dens": 206, "un": 206, "sigma_ob": 206, "logprior_uniform": 206, "logprior_semi": 206, "post_semi": 206, "mean_uniform": [206, 227], "mean_semi": 206, "eigvalsh": [206, 221], "binomtest": [207, 223, 226, 239], "predominantli": 207, "_check_skewcauchy_param": 207, "skewcauchy_pdf": 207, "skewcauchy_logpdf": 207, "skewcauchy_cdf": 207, "skewcauchy_ppf": 207, "q0": [207, 237], "skewcauchy_rv": 207, "skewcauchy_rvs_mixtur": 207, "u_sign": 207, "ppf_err": [207, 216], "shi": 207, "skewcauchy_cf_standard": 207, "sgn": 207, "b_minu": 207, "b_plu": 207, "um": 207, "shi_p": 207, "chi_p": 207, "shichi": 207, "shi_m": 207, "chi_m": 207, "isp": 207, "ism": 207, "a_val": [207, 261], "4\u03c0": 207, "subtl": [207, 247], "term_p": 207, "term_m": 207, "trunc_pv_mean": 207, "trunc_second_mo": 207, "tangent": [207, 222], "halfcauchi": 207, "th_cdf": 207, "direction": 207, "a_hat_from_sign": 207, "owens_t": 208, "sn": [208, 340, 347, 355, 356], "owen": 208, "skewnorm_logpdf": 208, "skewnorm_pdf": 208, "skewnorm_cdf": 208, "pdf_close": 208, "cdf_close": 208, "_delta": 208, "skewnorm_mean": 208, "skewnorm_var": 208, "skewnorm_skew": 208, "skewnorm_excess_kurtosi": 208, "skewnorm_mgf": 208, "skewnorm_cf": 208, "exkurt_scipi": [208, 233], "skewnorm_loglik": 208, "skewnorm_rvs_numpi": 208, "skewnorm_entropy_mc": 208, "a_viz": 208, "002": [142, 208, 394], "998": [21, 22, 208], "adequ": [208, 233, 246], "normal_loglik_ml": 208, "skewnorm_loglik_ml": 208, "params0": 208, "801": [208, 232], "5x": 208, "treatment": [209, 243, 245, 249, 251, 252, 253, 260, 261, 263, 270], "f_q": 209, "tq": 209, "varphi_q": 209, "itq": 209, "dq": 209, "nmont": [209, 229], "df_test": 209, "krt": 209, "df_": [209, 269], "q_n": 209, "q_i": 209, "experiment": 209, "inv_chi2_scaled_mo": 209, "normal_range_mo": 209, "er": 209, "er2": 209, "var_pr": 209, "npredict": 209, "vectoriz": [209, 218], "studentized_range_rvs_numpi": 209, "q_numpi": 209, "q_scipi": [209, 253], "qcrit": 209, "nqcrit": 209, "s_p": [209, 244, 267], "abc": 209, "group_mean": [209, 243], "df_error": 209, "ss_within": [209, 243, 259], "p_adj": [209, 249], "unbalanc": 209, "t_dist": 210, "_validate_df_loc_scal": 210, "t_logpdf": 210, "t_pdf": [210, 266, 267], "t_cdf": [210, 267], "ib": 210, "m_t": [210, 329], "t_moment": 210, "t_entropi": 210, "t_charfun": 210, "log_const": 210, "kv": [210, 226, 231, 234, 236, 239, 240, 312, 313, 314, 315, 316, 317], "df_demo": [210, 246], "phi_formula": 210, "phi_mc": 210, "t_loglik": 210, "t_nll": 210, "mle_hat": 210, "t_rvs_numpi": 210, "fit_df": 210, "justif": [210, 212], "n_rep": [210, 244, 250, 252, 259], "x_bar": 210, "rng2": [210, 237], "loc_pr": 210, "scale_pr": 210, "pred_pdf": 210, "plug_in_pdf": 210, "breakpoint": 211, "taper": 211, "pretti": 211, "soften": 211, "fuzz": 211, "trapezoidparam": 211, "validate_trapezoid_param": 211, "trapezoid_height": 211, "trapezoid_pdf": 211, "trapezoid_cdf": 211, "trapezoid_ppf": 211, "w3": 211, "trapezoid_rv": 211, "trapezoid_raw_mo": 211, "trapezoid_mo": 211, "trapezoid_entropi": 211, "trapezoid_mgf": 211, "iscomplexobj": [211, 227], "near0": [211, 217], "trapezoid_cf": 211, "i\u03c9": 211, "c_shape": 211, "d_shape": 211, "w_3": 211, "h_num": [211, 216], "cleaner": [211, 322, 323], "benefit": [211, 288, 346], "trapezoid_mean_geometr": 211, "m_left": 211, "m_mid": [211, 227, 232], "m_right": 211, "mean_geom": 211, "mean_raw": 211, "trapezoid_loglik": 211, "fit_unconstrain": 211, "fit_fixed_support": 211, "x_alt": [211, 269], "ll_uniform": 211, "ll_trap": 211, "prior_param": 211, "lik": [211, 212], "prior_u": 211, "post_u": 211, "legitim": 211, "triang_dist": 212, "pert": 212, "irwin": [212, 217], "hall": [212, 217], "6pt": 212, "8pt": 212, "_validate_triang_param": 212, "triang_params_to_scipi": 212, "scipy_params_to_triang": 212, "triang_pdf": 212, "triang_cdf": 212, "triang_ppf": 212, "triang_rvs_numpi": 212, "triang_mean": 212, "triang_second_mo": 212, "triang_vari": 212, "triang_skew": 212, "triang_excess_kurtosi": 212, "triang_entropi": 212, "triang_mgf": 212, "triang_cf": 212, "triang_loglik": 212, "mu_np": 212, "skew_np": 212, "kurt_np": 212, "mu_sp": 212, "bm": 212, "tm": 212, "mgf_val": [212, 216], "mean_fd": 212, "m_valu": 212, "int_m": 212, "triang_fit_ml": 212, "xmin": 212, "xmax": [212, 254, 269], "atanh": 212, "unpack": 212, "true_m": 212, "fig_mc": [212, 223, 225, 226, 227, 231, 232, 233, 234, 235, 236, 238, 239], "post_median": 212, "n_project": 212, "n_task": 212, "project_tot": 212, "timeout": [4, 7, 213, 348, 349, 355, 356, 381, 382, 384], "request": [4, 6, 213, 236, 241, 339, 340, 341, 368, 370, 373, 374, 378, 379, 381, 386], "abort": 213, "_one_minus_exp_neg": 213, "truncexpon_pdf": 213, "in_support": [213, 238], "truncexpon_cdf": 213, "truncexpon_ppf": 213, "truncexpon_rvs_np": 213, "truncexpon_raw_moments_std": 213, "truncexpon_mean_var_skew_kurt": 213, "floatingpointerror": 213, "truncexpon_entropy_std": 213, "truncexpon_mgf": 213, "not_clos": 213, "truncexp": 213, "b_valu": [213, 215], "ent": [213, 228, 235, 238, 240], "sci_mean": 213, "sci_var": 213, "sci_skew": 213, "sci_exkurt": 213, "sci_ent": 213, "truncexp_loglik_lambda": 213, "lam_tru": [213, 218], "lam_hat": [213, 218, 235, 236], "u_grid": 213, "ppf_our": 213, "ppf_scipi": 213, "hist_edg": 213, "b_hat1": 213, "loc_hat1": 213, "scale_hat1": 213, "b_hat2": 213, "loc_hat2": 213, "scale_hat2": 213, "lambda_0": [213, 227, 235, 236], "mle_lambda_given_b": 213, "lam0": 213, "lam_post_mean": 213, "lam1": 213, "lam2": 213, "ly": 214, "psychometr": 214, "survei": [214, 230, 247, 251], "tobit": 214, "norm_logcdf": 214, "_logdiffexp": 214, "truncnorm_standardized_bound": 214, "truncnorm_logz": 214, "logphi_a": 214, "logphi_b": 214, "logz_cdf": 214, "logsf_a": 214, "logsf_b": 214, "logz_sf": 214, "use_sf": 214, "truncnorm_logpdf": 214, "truncnorm_pdf": 214, "truncnorm_cdf": 214, "truncnorm_mo": 214, "phi_a": 214, "var_t": 214, "truncnorm_entropi": 214, "truncnorm_mgf": 214, "truncnorm_loglik": 214, "chop": 214, "param_sets_1": 214, "param_sets_2": 214, "fit_truncnorm_ml": 214, "1e300": 214, "truncnorm_rvs_rejection_numpi": 214, "batch_multipli": 214, "isneginf": 214, "isposinf": 214, "mean_formula": 214, "var_formula": 214, "skew_formula": 214, "excess_kurt_formula": 214, "drawn": [214, 232, 233, 234, 238], "pm2": 214, "fit_sigma_given_mu": 214, "mu_fix": [214, 218, 231], "log_sigma": 214, "sigma0_hat": 214, "sigma_hat_under_h0": 214, "p_value_chi2_approx": 214, "post_var": 214, "post_mu": 214, "post_sigma": 214, "post_mu_untrunc": 214, "post_sigma_untrunc": 214, "posterior_mean_trunc": 214, "w_normal": 214, "w_trunc": 214, "max_abs_norm": 214, "max_abs_trunc": 214, "pdf_normal": 214, "pdf_trunc": 214, "ineffici": 214, "rv_wrong": 214, "rv_right": 214, "wrong_support": 214, "right_support": 214, "earthquak": 215, "wildfir": 215, "geographi": 215, "payout": 215, "mimic": 215, "_check_truncpareto_param": 215, "truncpareto_logpdf": 215, "log_k": 215, "truncpareto_pdf": 215, "truncpareto_cdf": 215, "truncpareto_ppf": 215, "c_neg_b": 215, "x_neg_b": 215, "tc": 215, "truncpareto_raw_mo": 215, "truncpareto_mo": 215, "truncpareto_entropi": 215, "elogx": 215, "b_fix": 215, "truncpareto_loglikelihood": 215, "truncpareto_mle_c": 215, "_score_b": 215, "truncpareto_mle_b": 215, "f_lo": [215, 233], "f_hi": [215, 233], "bb": 215, "b_hat_known_c": 215, "truncpareto_rvs_numpi": 215, "l_post": 215, "surv_emp": 215, "surv_theori": 215, "phenomenon": [216, 219], "stapl": 216, "administr": 216, "truncweibul": 216, "_min": [216, 219], "_logz_truncweibull_min": 216, "truncweibull_min_logpdf": 216, "truncweibull_min_pdf": 216, "truncweibull_min_cdf": 216, "delta_x": 216, "delta_b": 216, "truncweibull_min_ppf": 216, "truncweibull_min_raw_mo": 216, "gamma_": 216, "truncweibull_min_mo": 216, "scipy_kurt": 216, "mgf_numer": 216, "cf_numer": 216, "integrand_co": 216, "integrand_sin": 216, "entropy_numer": 216, "t_valu": 216, "cf_val": 216, "confin": 216, "plot_pdf_family_by_c": 216, "plot_pdf_family_by_trunc": 216, "trunc_pair": 216, "loglike_c_given_ab": 216, "truncweibull_min_rvs_numpi": 216, "a3": [216, 242, 258, 264], "b3": [216, 261], "ecdf_x": 216, "c4": 216, "a4": [216, 242, 258, 264], "b4": [216, 261], "c_hat_fit": 216, "b_hat_fit": 216, "loc_hat_fit": 216, "scale_hat_fit": 216, "fb": [216, 256], "quantif": 216, "a5": [216, 242, 258, 264], "b5": [216, 261], "bate": 217, "uniform_pdf": 217, "uniform_cdf": 217, "uniform_logpdf": 217, "uniform_mean": 217, "uniform_var": 217, "uniform_mgf": 217, "uniform_cf": 217, "uniform_entropi": 217, "exkurt_hat": 217, "_a": 217, "inclus": [217, 238], "sample_uniform": 217, "exttt": 217, "interchang": 218, "sooner": 218, "cognit": 218, "fatigu": [218, 220, 340, 383], "invgauss_logpdf": 218, "invgauss_pdf": 218, "invgauss_cdf": 218, "log_term1": 218, "wald_pdf": 218, "wald_cdf": 218, "lam_test": 218, "rv_ig": 218, "increasingli": [218, 239], "lam_fix": 218, "lam_i": 218, "invgauss_loglik": 218, "invgauss_ml": 218, "invgauss_mle_lam_given_mu": 218, "s_wald": 218, "mu_shape_hat": 218, "inferenti": 218, "lam_hat_mu0": 218, "lam_known": 218, "lam_v": 218, "std_y": 218, "gof": [218, 246], "_max": 219, "weibull_max_logpdf": 219, "weibull_max_pdf": 219, "weibull_max_cdf": 219, "weibull_max_ppf": 219, "weibull_max_entropi": 219, "weibull_max_mo": 219, "g_r": 219, "c_ex": 219, "weibull_max_loglik": 219, "ll_manual": 219, "ll_scipi": 219, "weibull_max_rvs_numpi": 219, "loc_mc": 219, "scale_mc": 219, "c_b": 219, "d_b": 219, "loc_known": 219, "weibull_min_loglik": [219, 220], "logi": 219, "mildli": 219, "lognormal_logpdf": 219, "s_val": [219, 389], "true_curv": 219, "alarm": [219, 338, 340, 354], "weibull_min_dist": 220, "weibullmin": 220, "weibull_max": 220, "lim_": 220, "weibull_min_pdf": 220, "weibull_min_logpdf": 220, "weibull_min_cdf": 220, "weibull_min_sf": 220, "weibull_min_hazard": 220, "weibull_min_ppf": 220, "weibull_min_pdf_loc_scal": 220, "weibull_min_cdf_loc_scal": 220, "weibull_min_ppf_loc_scal": 220, "rv_std": 220, "rv_l": 220, "x_haz": 220, "haz": 220, "weibull_min_raw_mo": 220, "weibull_min_mean": 220, "weibull_min_vari": 220, "weibull_min_skew": 220, "weibull_min_excess_kurtosi": 220, "weibull_min_entropi": 220, "entropy_f": 220, "632": [142, 220], "x_pdf": 220, "weibull_min_scale_hat": 220, "weibull_min_shape_score_profil": 220, "score_v": 220, "c_hat_sp": 220, "loc_hat_sp": 220, "scale_hat_sp": 220, "ll_prof": 220, "weibull_min_rvs_numpi": 220, "subpopul": 220, "c_known": 220, "r_post": 220, "beta_samp": 220, "x_earli": 220, "x_wear": 220, "nelson": 220, "multigammaln": 221, "cone": 221, "gamma_p": [221, 246], "loewner": 221, "preceq": 221, "is_square_matrix": 221, "is_symmetr": 221, "cholesky_spd": 221, "validate_scal": 221, "validate_df": 221, "wishart_logpdf_numpi": 221, "wishart_p": 221, "sign_w": 221, "logdet_w": 221, "sign_": 221, "logdet_": 221, "trace_term": 221, "wishart_pdf_numpi": 221, "wishart_mean": 221, "wishart_cov_entri": 221, "w_ij": 221, "w_kl": 221, "indexerror": [221, 232], "wishart_var_matrix": 221, "wishart_expected_logdet": 221, "wishart_entropi": 221, "digamma_sum": 221, "wishart_mgf": 221, "tw": 221, "jk": [221, 393], "tighten": [221, 224, 250, 262], "wishart_fit_scale_ml": 221, "wishart_fit_df_mom": 221, "w_ii": 221, "sigma_ii": 221, "2_df": 221, "axis1": 221, "axis2": 221, "wishart_fit_df_scale_mom": 221, "df_by_diag": 221, "aa": 221, "laa": 221, "x_r": 221, "sum_r": 221, "wishart_rvs_bartlett": 221, "la": 221, "wishart_rvs_norm": 221, "df_int": 221, "sni": 221, "snj": 221, "sij": 221, "w_demo": 221, "difficult": 221, "w_one": 221, "w11": 221, "w22": 221, "excess_kurt_mc": 221, "w_11": 221, "pdf_theori": 221, "cdf_theori": 221, "w_22": 221, "scale3": 221, "ws0": 221, "df_col": 221, "dist_col": 221, "lmin": 221, "prob_hat": 221, "whiten": 221, "sigma_0": 221, "nu_0": 221, "nu_post": 221, "s_post": 221, "lambda_mean": 221, "sigma_sampl": 221, "sigma_mean_mc": 221, "sigma_target": 221, "modulo": 222, "wrappedcauchi": 222, "prevail": 222, "compass": 222, "magnet": 222, "interfer": 222, "oscillatori": [222, 316], "bear": 222, "bmod": 222, "exit": 222, "planar": 222, "wrap_angl": 222, "wrapcauchy_pdf": 222, "wrapcauchy_logpdf": 222, "_wrapcauchy_cdf_delta": 222, "wrapcauchy_cdf": 222, "wrapcauchy_ppf": 222, "sample_wrapcauchy_numpi": 222, "trig_moment": 222, "circular_mean_direct": 222, "mean_resultant_length": 222, "m1_hat": 222, "mean_lin": 222, "var_lin": 222, "skew_lin": 222, "kurt_lin": 222, "wrapcauchy_entropi": 222, "grid_siz": 222, "hs": 222, "unwrap": 222, "radian": 222, "iti": 222, "iki": 222, "theta_n": 222, "wrapcauchy_loglik": 222, "mle_wrapcauchi": 222, "logit_c": 222, "logit_c_hat": 222, "48": [39, 51, 110, 118, 134, 222, 255, 267, 268], "barpolar": 222, "recut_to_interv": 222, "s_recut": 222, "c_hat2": 222, "mu_hat2": 222, "\u03bc0": [222, 269], "nll_c": 222, "res0": [222, 253], "\u03c7\u00b2": [222, 244, 251, 252, 254], "noise_angl": 222, "true_unwrap": 222, "obs_unwrap": 222, "deg2rad": 222, "xlogi": [223, 234, 237], "xlog1pi": 223, "toss": 223, "validate_p": 223, "bernoulli_pmf": 223, "bernoulli_cdf": 223, "p_demo": 223, "3pq": 223, "bernoulli_mean": 223, "bernoulli_var": 223, "bernoulli_skew": 223, "bernoulli_excess_kurtosi": 223, "bernoulli_mgf": 223, "bernoulli_cf": 223, "bernoulli_entropi": 223, "p_arr": 223, "27": [29, 75, 100, 107, 112, 122, 134, 135, 142, 195, 223, 247, 248, 264, 389], "excess_kurt_hat": 223, "mgf_hat": 223, "cf_hat": 223, "bernoulli_log_likelihood": 223, "sample_bernoulli_numpi": 223, "fig_pmf": [223, 225, 226, 227, 231, 232, 233, 234, 235, 236, 238, 239, 240], "rv_discret": [223, 225, 227, 231, 232, 234, 235, 239], "p_0": [223, 226, 261], "na\u00efv": 223, "proportion_ci": [223, 226], "confidence_level": [223, 226, 261], "boolean": [223, 261], "propens": [224, 232, 233, 258], "p\u00f3lya": [224, 228], "urn": [224, 228, 232], "lfloor": [224, 225, 226, 227, 231, 232, 233, 235, 236, 237, 238, 240, 241], "rfloor": [224, 225, 226, 227, 232, 233, 235, 236, 237, 238, 240, 241], "betabinom_logpmf": 224, "log_choos": [224, 225, 234, 251, 261], "betabinom_pmf": 224, "betabinom_cdf": 224, "cdf_full": 224, "k_clip": 224, "betabinom_entropi": 224, "betabinom_stats_closed_form": 224, "rvs_betabinom_numpi": 224, "betabinomi": [224, 228, 234], "6n": [224, 234], "3t": [224, 234], "3tn": [224, 234], "18tn": [224, 234], "closed_form": 224, "betabinom_pgf": 224, "k_m": [224, 225, 231], "k_i": [224, 225, 231, 235, 240], "monte_carlo": 224, "u2264k": [224, 229], "pmf_mc": 224, "logpmf": [224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240], "pmf_sp": [224, 227, 229, 232, 235, 240], "betabinom_moments_init": 224, "v_bin": 224, "fit_betabinom_ml": 224, "issubdtyp": [224, 228, 230, 232, 241], "impress": [224, 230], "difficulti": [224, 253], "rng_use": 224, "ll_binom": 224, "aic_binom": 224, "ll_bb": 224, "aic_bb": 224, "rng_bay": 224, "2024": 224, "pmf_pred": [224, 237], "p_samp": 224, "y_samp": 224, "pmf_direct": 224, "pmf_from_log": 224, "_r": [224, 228], "negbin": [225, 236], "funnel": 225, "retri": [1, 3, 4, 7, 225, 347, 349, 350, 354, 355, 356, 365, 370, 382], "signup": 225, "purchas": 225, "logpmf_betanbinom": 225, "k_int": [225, 226, 227, 231, 232, 234, 236, 237, 239, 241], "pmf_betanbinom": 225, "cdf_betanbinom": 225, "k_floor": [225, 234], "ndenumer": 225, "support_for_plot": 225, "fallback_max": 225, "resort": 225, "max_abs_err": 225, "stirl": [225, 228], "factorial_mo": 225, "poch": 225, "raw_moments_up_to_4": 225, "f3": [225, 228], "f4": [225, 228], "e4": 225, "mean_var_skew_kurt": 225, "scipy_mu": 225, "scipy_ex_kurt": 225, "pgf_betanbinom": 225, "log_pref": 225, "ks_h": 225, "pmf_h": [225, 233], "h_trunc": 225, "tail_mass": [225, 229, 240], "pgf_sum": 225, "pgf_close": 225, "opportun": 225, "plot_pmf": 225, "params_list": [225, 238], "params_n": 225, "mu_theori": 225, "mu_mc": 225, "rvs_betanbinom_numpi": 225, "negative_binomi": [225, 231], "neg_loglik_ab": 225, "fit_ab_ml": 225, "k_ob": [225, 226, 234, 236], "saw": [225, 230, 234, 244, 251], "p_post_mean": 225, "rv_pred": [225, 231], "visitor": 226, "epidemiolog": 226, "6p": [226, 237], "_validate_n_p": [226, 231], "n_int": [226, 227, 230, 231, 241, 246], "p_float": [226, 231], "binom_logpmf": 226, "log_binom_coeff": 226, "lgamma": [226, 230, 231, 236, 240, 250, 261, 266, 267, 269], "binom_pmf": [226, 236], "binom_pmf_support": 226, "binom_pmf_arrai": 226, "binom_cdf": 226, "binom_mo": 226, "binom_entropi": 226, "h_nat": [226, 234, 237, 239, 241], "est_mean": [226, 231, 236], "est_var": [226, 231, 236], "formula_mean": [226, 231, 236, 239], "formula_var": [226, 231, 236, 239], "n_fix": [226, 231, 241], "p_fix": 226, "n_valu": [226, 231, 233, 241], "i_i": 226, "i_j": 226, "logl": [226, 232, 233, 236], "didact": 226, "sample_binom_bernoulli_sum": 226, "sample_binom_inverse_cdf": 226, "bernoulli_sum_mean": 226, "inverse_cdf_mean": 226, "pmf_hat": [226, 231, 232, 233, 234, 239, 241], "pmf_scipi": [226, 228, 229, 230, 236, 237], "pmf_sum": [226, 230, 232, 233], "cdf_last": [226, 233, 236], "p_mle_clos": 226, "p_mle_opt": 226, "betabinom": [226, 228], "posterior_95": [226, 232, 236], "k_new": 226, "pred_pmf": [226, 236], "p_dai": 226, "avg_visitor": 226, "avg_rat": 226, "casella": 226, "berger": 226, "thermal": [227, 235], "equilibrium": [227, 235], "boltzmann_logz": 227, "boltzmann_logpmf": 227, "is_int": [227, 229, 238, 239], "boltzmann_pmf": 227, "boltzmann_cdf": 227, "boltzmann_mean_var": 227, "rn": [227, 234], "one_minus_r": 227, "one_minus_rn": 227, "boltzmann_entropi": 227, "boltzmann_mgf": 227, "geom_sum": 227, "boltzmann_stat": 227, "pmf_np": [227, 229, 232, 235, 240], "mom_np": 227, "ent_sp": [227, 232, 235], "mgf_sum": [227, 235], "mgf_close": [227, 235], "flatter": [227, 241], "partial_": 227, "boltzmann_loglik": 227, "x_sum": 227, "boltzmann_mle_lambda": 227, "e_lambda": 227, "bisect": [227, 232, 233, 266], "true_lambda": [227, 235], "lambda_hat": 227, "logsumexp_np": 227, "boltzmann_rvs_numpi": 227, "emp_p": [227, 242], "true_n": [227, 231, 241], "underestim": 227, "dirichletmultinomi": 228, "themselv": [228, 271, 386], "nlp": [228, 230], "ecolog": [228, 232, 233], "site": [89, 115, 127, 131, 132, 134, 135, 136, 137, 138, 139, 141, 143, 144, 145, 146, 151, 160, 201, 209, 228, 230, 240, 389], "genom": 228, "allel": [228, 230], "cohort": [228, 252], "prod_i": [228, 230], "_validate_alpha": 228, "_validate_count": [228, 230], "dirichlet_multinomial_logpmf": 228, "n_vec": 228, "log_multinomial_coeff": 228, "dirichlet_multinomial_pmf": 228, "enumerate_support": [228, 230], "dm_cdf_small_n": 228, "summat": [228, 230, 232, 246], "simplex_xy_3": [228, 230], "barycentr": [228, 230], "atleast_2d": [228, 230], "dirichlet_rvs_numpi": [228, 230], "dirichlet_multinomial_rvs_numpi": 228, "pmf_numpi": [228, 229, 237], "dm_mean": 228, "dm_cov": 228, "beta_binomial_moments_via_factori": 228, "dm_entropy_small_n": 228, "dm_mgf_small_n": 228, "kex": 228, "scipy_kex": 228, "tri_x": [228, 230], "tri_i": [228, 230], "scattergl": 228, "p_j": [228, 230, 237, 241], "g_j": 228, "theory_cov": 228, "sample_cov": 228, "alpha2": [228, 239], "alpha3": 228, "dm": 228, "alpha1": [228, 239], "dirichlet_multinomial_rvs_scipi": 228, "dm_loglik": 228, "dm_loglik_grad": 228, "dm_mom_alpha_init": 228, "fit_dirichlet_multinomial_ml": 228, "multinomial_loglik": 228, "lrt_statist": 228, "lrt_ob": 228, "p_hat_ob": 228, "alpha_hat_ob": 228, "lrt_boot": 228, "alpha_top": 228, "n_word": [228, 230], "p3": 228, "combinatori": [228, 232, 234], "explos": 228, "u201cdoubl": 229, "u201d": [229, 253], "lattic": 229, "u2208": 229, "u211d": 229, "u2019ll": [229, 253], "u201cmostli": 229, "u201cgeometr": 229, "ell_1": 229, "die": [229, 230, 238], "stepwis": [229, 298], "_check_a": 229, "dlaplace_pmf": 229, "x_round": 229, "dlaplace_logpmf": 229, "dlaplace_cdf": 229, "dlaplace_mo": 229, "dlaplace_mgf": 229, "tk": [229, 231, 235, 238, 240, 241], "dlaplace_cf": 229, "dlaplace_rvs_numpi": 229, "mass_in_rang": 229, "12e": 229, "fk": [229, 252], "200k": 229, "asinh": [229, 264], "dlaplace_loglik": 229, "dlaplace_mle_closed_form": 229, "arcsinh": [229, 264], "26": [20, 49, 53, 65, 74, 75, 93, 101, 107, 112, 113, 117, 118, 120, 122, 123, 124, 125, 127, 129, 131, 132, 135, 136, 137, 138, 142, 143, 144, 146, 151, 153, 154, 155, 158, 160, 162, 163, 165, 166, 168, 170, 175, 176, 177, 178, 179, 181, 182, 183, 185, 187, 189, 191, 192, 193, 194, 195, 196, 198, 199, 202, 204, 207, 209, 210, 211, 212, 213, 216, 217, 218, 221, 222, 223, 224, 225, 229, 230, 233, 234, 235, 237, 238, 240, 241, 242, 246, 247, 251, 254, 256, 257, 258, 259, 261, 264, 267, 268, 269, 285], "pmf_theori": [229, 241], "ki": 229, "u00a01": 229, "a_hat_cf": 229, "loc_hat_cf": 229, "fitter": [229, 236, 237], "counterpart": [229, 321], "theta_median": 229, "chose": 230, "genet": [230, 232], "creativ": 230, "multinoulli": 230, "ind": [135, 137, 209, 230, 246], "_validate_n": 230, "_validate_p": 230, "require_sum_n": 230, "_lgamma_vec": 230, "multinomial_logpmf": 230, "log_coeff": [230, 231, 236, 246, 250, 266], "x_log_p": 230, "multinomial_pmf": 230, "multinomial_cdf_small_n": 230, "support_s": 230, "min_pmf": 230, "max_pmf": 230, "2p_i": 230, "6p_i": 230, "omega_i": 230, "mean_cov_multinomi": 230, "max_abs_mean_err": 230, "max_abs_cov_err": 230, "vertex": 230, "plot_simplex_pmf": 230, "n_j": [230, 249], "fit_multinomial_ml": 230, "total_count": [230, 247], "l1_error": 230, "multinomial_rvs_categorical_count": 230, "multinomial_rvs_sequential_binomi": 230, "remaining_n": 230, "remaining_prob": 230, "pi_cond": 230, "max_abs_mean_err_categor": 230, "max_abs_mean_err_sequenti": 230, "max_abs_cov_err_categor": 230, "max_abs_cov_err_sequenti": 230, "pmf_our": 230, "example_cdf": 230, "pmf_sum_scipi": 230, "pmf_sum_our": 230, "max_abs_pmf_diff": [230, 232], "mean_empir": 230, "example_cdf_small_n": 230, "power_diverg": 230, "f_ob": [230, 238, 240, 241, 246, 247], "f_exp": [230, 238, 240, 241, 246, 247], "gtest": 230, "chi2_stat": [230, 241, 246, 247], "chi2_pvalu": 230, "g_stat": 230, "g_pvalu": 230, "p_word": 230, "rna": 231, "seq": [231, 234], "gene": 231, "g_n": 231, "geom": 231, "arphi_k": 231, "itk": [231, 240, 241], "k_2": 231, "n_float": 231, "nbinom_logpmf": 231, "nbinom_pmf": 231, "nbinom_mean": 231, "nbinom_var": 231, "nbinom_skew": 231, "nbinom_excess_kurt": 231, "nbinom_pmf_cdf_trunc": 231, "pmf0": 231, "pmf_val": 231, "pmf_k": 231, "nbinom_entropy_trunc": 231, "entropy_trunc_nat": [231, 236], "nbinom_loglik": 231, "kbar": 231, "p_hat_clos": 231, "sample_nbinom_poisson_gamma": 231, "sample_nbinom_geometric_sum": 231, "is_integ": [231, 238, 246], "true_p": 231, "significantli": 231, "ybar": 231, "p_value_ov": 231, "dispersion_ratio_var_over_mean": 231, "p_value_overdispers": 231, "predictive_n": 231, "predictive_p": 231, "predictive_mean": 231, "headach": 231, "audit": [232, 233, 234, 331, 340, 346, 350, 353, 381], "nchypergeom_walleniu": 232, "walleniu": 232, "coincid": 232, "a_x": 232, "kappa_3": [232, 237], "kappa_2": [232, 237], "kappa_4": [232, 237], "sum_x": [232, 233], "_validate_m_n_n": 232, "nchypergeom_fisher_support": 232, "_log_factori": 232, "max_n": 232, "logfact": 232, "_log_choos": 232, "_logsumexp": 232, "_nchgf_loga": 232, "loga": 232, "nchypergeom_fisher_logz_theta": 232, "nchypergeom_fisher_logz": 232, "nchypergeom_fisher_logpmf_arrai": 232, "nchypergeom_fisher_logpmf": 232, "nchypergeom_fisher_pmf_arrai": 232, "nchypergeom_fisher_pmf": 232, "nchypergeom_fisher_cdf_arrai": 232, "nchypergeom_fisher_cdf": 232, "nchypergeom_fisher_stat": 232, "nchypergeom_fisher_log_mgf": 232, "nchypergeom_fisher_mgf": 232, "nchypergeom_fisher_log_cf": 232, "nchypergeom_fisher_cf": 232, "nchypergeom_fisher_mean_from_logodd": 232, "logodd": 232, "fit_nchypergeom_fisher_odds_ml": 232, "nchg": 232, "e_theta": 232, "data_int": 232, "1e12": 232, "theta_lo": 232, "theta_hi": 232, "m_lo": 232, "m_hi": 232, "theta_mid": 232, "mgf_ratio": 232, "mgf_direct": 232, "mgf_abs_diff": 232, "cf_at_1": 232, "odds_valu": [232, 233], "odds_grid": [232, 233], "odds_hat": [232, 233], "sample_nchypergeom_fisher_inverse_cdf": 232, "numpy_mo": 232, "scipy_kurt_excess": 232, "scipy_entropy_nat": 232, "odds_tru": [232, 233], "odds_hat_bisect": 232, "odds_hat_opt": 232, "unexpos": [232, 261], "fisher_exact": [232, 251, 261], "greater": [232, 244, 245, 249, 250, 255, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270], "a_ob": [232, 251, 261], "p_cond_great": 232, "oddsratio_hat": 232, "p_fisher_great": 232, "sample_table_with_fixed_margin": 232, "c_new": 232, "d_new": 232, "odds_sim": 232, "sample_t": 232, "n_expos": [232, 261], "n_case": 232, "p_cond_greater_odds1": 232, "fisher_exact_great": 232, "posterior_mean_odd": [232, 233], "sample_table_at_odds_sim": 232, "hypergeom": [232, 233, 234], "preferenti": [233, 240], "subgroup": 233, "recaptur": 233, "catchabl": 233, "inspector": 233, "quota": [233, 349, 372], "met": [233, 370], "nchypergeom_fish": 233, "decrement": 233, "_validate_m_n_n_odd": 233, "wallenius_support": 233, "sample_wallenius_numpi": 233, "draw_r": 233, "discrete_moments_from_pmf": 233, "mgf_from_pmf": 233, "cf_from_pmf": 233, "wallenius_mean_field_mean": 233, "left_bas": 233, "f_mid": 233, "pmf_unbias": 233, "max_abs_diff_odds1": 233, "mom_from_pmf": 233, "odds1_matches_hypergeom_max_abs_diff": 233, "mean_pmf": 233, "mean_mean_field": 233, "var_pmf": 233, "mgf_t": 233, "cf_t": 233, "odds_fix": 233, "xs_": 233, "pmf_": 233, "odds_ml": 233, "mean_field_mean_at_tru": 233, "biasedurn": 233, "np_mean": 233, "scipy_theory_mean": 233, "np_var": 233, "nll_odd": 233, "enrich": [233, 349, 381, 382, 385], "p_ge": 233, "nll1": 233, "p_lr": 233, "p_value_one_sided_g": 233, "p_value_lr_chi2_approx": 233, "log_odds_grid": 233, "post_log": 233, "dlog": 233, "lo_log": 233, "hi_log": 233, "credible_interval_90_odd": 233, "odds_list": 233, "clash": 233, "nhg": 234, "card": 234, "deck": 234, "hg": 234, "validate_nhypergeom_param": 234, "_is_integr": 234, "nhypergeom_logpmf": 234, "valid_k": 234, "log_num1": 234, "log_num2": 234, "log_den": 234, "nhypergeom_pmf": 234, "nhypergeom_pmf_arrai": 234, "nhypergeom_cdf_arrai": 234, "nhypergeom_cdf": 234, "m_demo": 234, "r_demo": 234, "ks_demo": 234, "pmf_demo": 234, "cdf_demo": 234, "nhypergeom_mean": 234, "nhypergeom_var": 234, "nhypergeom_skew": 234, "nhypergeom_excess_kurtosi": 234, "nhypergeom_pgf": 234, "nhypergeom_mgf": 234, "nhypergeom_cf": 234, "nhypergeom_entropi": 234, "1st": 234, "g_m": [234, 256], "exchang": [234, 245, 255, 256, 257, 260, 262, 352], "nhypergeom_loglikelihood": 234, "dist_tru": 234, "n_min": 234, "n_max": [234, 238], "n_grid": [234, 238, 266, 269], "n_mle": 234, "t_r": 234, "rem": 234, "sample_nhypergeom_posit": 234, "blue_po": 234, "sample_nhypergeom_sequenti": 234, "red_rem": 234, "blue_rem": 234, "red_seen": 234, "blue_seen": 234, "p_red": 234, "x_seq": 234, "n_hat": [234, 241], "n_0": 234, "post_mean_n": 234, "pmf_mix": 234, "pmf_n": 234, "fig_pp": 234, "photon": [235, 236], "wavelength": 235, "quantum": 235, "excit": 235, "boson": 235, "validate_lambda": 235, "_is_integer_arrai": 235, "planck_logpmf": 235, "planck_pmf": 235, "planck_cdf": 235, "cdf_tail": 235, "pgf": [235, 237], "qz": 235, "planck_mean": 235, "planck_vari": 235, "planck_skew": 235, "planck_excess_kurtosi": 235, "planck_entropi": 235, "planck_mgf": 235, "planck_cf": 235, "var_grid": 235, "validate_sampl": 235, "planck_loglik": 235, "planck_mle_lambda": 235, "lam_hat_clos": 235, "planck_rvs_numpi": 235, "emp_pmf": [235, 238, 240, 241], "planck_lrt": 235, "lambda_draw": 235, "degeneraci": 235, "helpdesk": 236, "mutat": [236, 335, 385], "dna": 236, "equidispers": 236, "_validate_mu": [236, 239], "poisson_pmf_arrai": 236, "poisson_logpmf": 236, "log_fact": [236, 251], "otyp": [209, 236, 240, 261], "poisson_pmf": 236, "poisson_mo": 236, "poisson_entropy_trunc": 236, "poisson_entropy_asymptot": 236, "entropy_asymptotic_nat": 236, "mu_max": 236, "sample_poisson_knuth": 236, "ndindex": 236, "sample_poisson_inverse_cdf": 236, "x_knuth": 236, "knuth_mean": 236, "inv_cdf_mean": 236, "knuth_var": 236, "inv_cdf_var": 236, "worth": 236, "log_pmf": 236, "pmf_binom": 236, "pmf_poi": 236, "std_norm_cdf": 236, "normal_approx": 236, "pmf_sum_over_rang": 236, "mle_mu_hat_closed_form": 236, "fit_mu_hat_scipi": 236, "fit_loc_hat_scipi": 236, "fit_success": [236, 239], "upper_tail_p_valu": 236, "_ci_for_lambda": 236, "nbinom": 236, "prior_mean": 236, "exposure_i": 236, "mean_lambda": 236, "poissonbinomi": 237, "pb": 237, "elect": 237, "district": 237, "discoveri": [237, 311, 312, 313, 314, 315, 316, 317, 343, 344, 348, 358, 386], "g_x": 237, "validate_p_vector": 237, "poisson_binom_support": 237, "poisson_binom_pmf_arrai": 237, "pmf_next": 237, "poisson_binom_logpmf": 237, "poisson_binom_pmf": 237, "poisson_binom_cdf": 237, "kappa_1": 237, "poisson_binom_cumul": 237, "poisson_binom_mo": 237, "poisson_binom_log_mgf": 237, "log_term": 237, "poisson_binom_mgf": 237, "poisson_binom_cf": 237, "poisson_binom_entropi": 237, "concav": 237, "show_pmf_comparison": 237, "pvec": 237, "p_equal": 237, "p_mixtur": 237, "p_extrem": 237, "multiset": [237, 253], "poisson_binom_log_likelihood": 237, "p1_grid": 237, "p2_grid": 237, "sample_poisson_binom_numpi": 237, "neg_log_likelihood_unconstrain": 237, "1e30": 237, "p_value_upp": 237, "p_latent": 237, "pmf_accum": 237, "pmf_draw": 237, "fft": 237, "pickl": 237, "unpickl": 237, "consecut": [238, 271], "week": 238, "augment": [238, 271], "_as_int_lik": 238, "validate_low_high": 238, "randint_support": 238, "randint_pmf": 238, "randint_cdf": 238, "low_demo": 238, "high_demo": 238, "randint_mo": 238, "randint_mgf": 238, "mgf_emp": 238, "mgf_theo": 238, "randint_log_likelihood": 238, "randint_ml": 238, "low_hat": 238, "high_hat": 238, "low_tru": 238, "high_tru": 238, "low_grid": 238, "high_grid": 238, "ll_plot": 238, "sample_randint_numpi": 238, "theo_pmf": [238, 240], "x_cont": 238, "german": 238, "tank": 238, "max_seri": 238, "poi": 239, "departur": [239, 248, 254], "sport": 239, "delet": [239, 331, 335, 338, 341, 342, 355, 358, 373, 375, 379, 382], "2y_1": 239, "1a": 239, "1b": 239, "mu_float": 239, "_validate_mu1_mu2": 239, "skellam_logpmf": 239, "skellam_pmf": 239, "skellam_mo": 239, "skellam_mgf": 239, "skellam_cf": 239, "sample_excess_kurtosi": 239, "skellam_entropi": 239, "tail_prob": [239, 270], "skellam_mom_estim": 239, "mu2_hat": 239, "formula_skew": 239, "formula_excess_kurt": 239, "entropy_bit": 239, "mu1_tru": 239, "mu2_tru": 239, "mu1_mom": 239, "mu2_mom": 239, "log_param": 239, "mu1_ml": 239, "mu2_ml": 239, "sample_skellam_numpi": 239, "prob_mass_in_plot_window": 239, "mc_mass_in_plot_window": 239, "pmf_sum_on_grid": 239, "cdf_last_on_grid": 239, "fit_mu1": 239, "fit_mu2": 239, "p_two": 239, "binom_r": 239, "skellam_two_sided_p": 239, "conditional_binomtest_p": 239, "y1_ob": 239, "y2_ob": 239, "n_game": 239, "post_alpha1": 239, "post_beta1": 239, "post_alpha2": 239, "post_beta2": 239, "mu1_": 239, "mu2_": 239, "y1_pred": 239, "y2_pred": 239, "d_pred": 239, "k_lo": 239, "k_hi": 239, "posterior_mean_mu1": 239, "posterior_mean_mu2": 239, "predictive_mean_diff": 239, "predictive_var_diff": 239, "mu_plu": 239, "mu_minu": 239, "drift_theori": 239, "drift_empir": 239, "unequ": [239, 243, 244, 249, 295, 313, 314, 316], "190": [239, 322], "iv_val": 239, "ive_v": 239, "pmf_naiv": 239, "logpmf_stabl": 239, "logpmf_scipi": 239, "k_far": 239, "citat": 240, "blockbust": 240, "_lgamma": 240, "yulesimon_logpmf": 240, "yulesimon_pmf": 240, "yulesimon_logsf": 240, "yulesimon_sf": 240, "yulesimon_cdf": 240, "mass_trunc": 240, "yulesimon_theoretical_stat": 240, "yulesimon_pgf": 240, "yulesimon_mgf": 240, "yulesimon_cf": 240, "yulesimon_loglik": 240, "yulesimon_scor": 240, "yulesimon_rvs_numpi": 240, "mc_sort": 240, "k_tail": 240, "emp_sf": 240, "theo_sf": 240, "fig_tail": 240, "nllf": 240, "hmc": 240, "alpha_grid": 240, "alpha_map": 240, "alpha_mean": 240, "simon_process_count": 240, "p_new": 240, "token": [2, 240, 332, 333, 341, 350, 356, 376, 400], "owner": [240, 332], "n_type": 240, "type_id": 240, "alpha_theori": 240, "song": 241, "catalog": [241, 283, 284, 295, 322, 348], "_validate_a_n": 241, "_logsumexp_np": 241, "log_w": 241, "zipfian_logz": 241, "zipfian_logpmf": 241, "zipfian_pmf": 241, "zipfian_pmf_arrai": 241, "zipfian_cdf": 241, "zipfian_raw_mo": 241, "zipfian_mo": 241, "zipfian_expected_log": 241, "zipfian_entropi": 241, "zipfian_log_mgf": 241, "zipfian_mgf": 241, "zipfian_cf": 241, "h_direct": 241, "h_via_formula": 241, "entropy_nats_check": 241, "ks_": 241, "_validate_sampl": 241, "x_int": 241, "zipfian_loglik": 241, "zipfian_mle_a": 241, "opt_r": 241, "sample_zipfian_numpi": 241, "size_int": 241, "p_value_na": 241, "logz_post": 241, "_credible_interv": 241, "n_vocab": 241, "n_token": 241, "f_n": [242, 256], "f_grid": 242, "2i": 242, "_as_1d_finit": [242, 248], "erf_approx": [242, 258, 264], "abramowitz": [242, 258, 261, 264], "stegun": [242, 258, 261, 264], "3275911": [242, 258, 264], "254829592": [242, 258, 264], "284496736": [242, 258, 264], "421413741": [242, 258, 264], "453152027": [242, 258, 264], "061405429": [242, 258, 264], "anderson_darling_statist": 242, "fi": 242, "anderson_darling_contribut": 242, "ad_norm": 242, "a2_star": 242, "ad_pvalue_normal_approx": 242, "stephen": [242, 256], "436": 242, "223": 242, "73": 242, "34": [75, 107, 110, 116, 127, 142, 143, 192, 193, 221, 242, 341], "318": [135, 137, 150, 242], "796": [118, 209, 242], "59": [122, 242, 250, 260, 299], "938": [22, 242, 280], "9177": 242, "279": [176, 242], "38": [53, 75, 81, 110, 127, 132, 142, 145, 148, 202, 207, 214, 218, 242, 261], "2937": 242, "0186": [97, 242], "ad_null_stats_norm": 242, "res_norm": [242, 254, 258], "p_approx_norm": 242, "null_stat": [242, 244, 245], "p_mc_norm": 242, "theory_p": 242, "x\u1d62": [242, 265], "contrib_star": 242, "nmc": 242, "res_t": 242, "p_approx_t": 242, "p_mc_t": 242, "xs_emp": 242, "p_emp": 242, "p_fit": 242, "contrib_n": 242, "contrib_t": 242, "contrib_n_star": 242, "contrib_t_star": 242, "c_\u03b1": 242, "1974": [242, 259], "1976": [242, 252], "edf": 242, "ssb": 243, "ssw": 243, "\u03b7\u00b2": 243, "revenu": [243, 263], "blood": [243, 270], "fwer": 243, "group_nam": [243, 252, 257, 259], "n_per_group": [243, 244], "means_alt": 243, "groups_alt": 243, "values_alt": 243, "labels_alt": 243, "df_alt": 243, "overall_mean": 243, "means_by_group": 243, "groupbi": [243, 296], "violin": [243, 244, 245, 249, 250, 252, 257, 259, 260, 262, 263, 266, 267, 269, 270], "ss_t": 243, "ss_b": 243, "ss_w": 243, "df_b": 243, "df_w": 243, "ms_b": 243, "ms_w": 243, "one_way_anova_from_scratch": 243, "means_i": 243, "ss_between": [243, 259], "ss_total": 243, "df_between": 243, "df_within": 243, "ms_between": 243, "ms_within": 243, "eta_sq": 243, "res_alt": 243, "agg": [243, 382], "ci95": 243, "error_i": [243, 249], "permutation_test_anova": 243, "n_permut": [243, 260, 263], "null_f": 243, "split_point": 243, "perm_group": 243, "f_observ": 243, "f_null": 243, "perm_r": 243, "conclud": 243, "tukei": [243, 249], "hsd": [243, 249], "means_nul": 243, "groups_nul": 243, "res_nul": 243, "homoscedast": [243, 244, 249, 252, 254, 259], "fitted_alt": 243, "residuals_alt": 243, "df_re": 243, "vars_by_group": 243, "f_scipi": 243, "f_onewai": 243, "welch": [243, 244, 249, 252, 259, 269], "kruskal": [243, 253, 260], "walli": [243, 260], "bonferroni": [243, 249, 256, 257], "montgomeri": 243, "gelman": 243, "eager": 244, "leven": [244, 250, 252], "brown": [244, 247, 250, 259], "forsyth": [244, 250, 259], "in_i": [244, 252], "simulate_groups_norm": 244, "sigmas_equ": 244, "sigmas_unequ": 244, "groups_equ": 244, "groups_unequ": 244, "n_equal": 244, "n_unequ": 244, "box_vis": [244, 245, 249, 250, 257, 259, 260, 262, 263, 267, 269], "meanline_vis": [244, 245, 249, 250, 257, 259, 260, 262, 263, 267, 269], "violingap": [244, 263], "violingroupgap": 244, "sample_vari": 244, "s2_equal": 244, "s2_unequ": 244, "bartlett_statist": 244, "sample_s": [244, 247], "n_minus_k": 244, "pooled_var": 244, "t_equal": 244, "pooled_equ": 244, "t_unequ": 244, "pooled_unequ": 244, "chi2_pdf": [244, 246, 248, 252], "bartlett_null_distribut": 244, "weighted_s2_sum": 244, "weighted_log_s2_sum": 244, "bartlett_test_numpi": 244, "p_value_mc": [244, 247, 253, 268], "res_equ": [244, 250], "35_000": 244, "res_unequ": 244, "h\u2080": [244, 251, 254, 265], "simulate_bartlett_stat": 244, "distribution_fn": 244, "null_stats_norm": 244, "stats_norm": 244, "scale_t3": 244, "stats_t3": 244, "sigma_logn": 244, "var_logn": 244, "stats_logn": 244, "empirical_type1": 244, "sigma_4": 244, "simulate_bartlett_stats_norm": 244, "\u03c3\u2084": 244, "unsur": [244, 266], "1937": [244, 253], "proceed": 244, "undesir": 245, "seed_data": 245, "seed_bootstrap": 245, "rng_data": [245, 256], "fuzzi": [245, 264], "uncomfort": 245, "observed_mean": 245, "n_boot_demo": 245, "bootstrap_mean": 245, "boot": [245, 342], "mu_x": 245, "delta_0": 245, "bootstrap_diff_in_mean": 245, "sample_a": 245, "sample_b": 245, "n_boot": [245, 255, 262], "n_b": [245, 250, 260, 266], "idx_a": 245, "idx_b": 245, "boot_a": 245, "boot_b": 245, "bootstrap_null_diff_in_mean": 245, "delta0": 245, "pooled_mean": 245, "mu_a0": 245, "mu_b0": 245, "sample_a_nul": 245, "sample_b_nul": 245, "observed_stat": 245, "bootstrap_ci_percentil": 245, "bootstrap_stat": 245, "conf_level": 245, "observed_diff": 245, "p_greater": [245, 251], "boot_stat": 245, "boot_s": 245, "72b7b2": 245, "willing": [245, 288], "garbag": 245, "efron": [245, 263], "jackknif": 245, "davison": 245, "hinklei": 245, "pk": [246, 341], "zk": 246, "z1\u00b2": 246, "zk\u00b2": 246, "_lanczos_coeff": 246, "99999999999980993": 246, "676": 246, "5203681218851": 246, "1259": [209, 246], "1392167224028": 246, "771": 246, "3234287776531": 246, "176": [27, 184, 246, 261], "6150291621406": 246, "507343278686905": 246, "13857109526572012": 246, "984369578019572e": 246, "5056327351493116e": 246, "_lanczos_g": 246, "lanczo": 246, "\u03c0z": 246, "z_minus_1": 246, "_gamma_p_seri": 246, "_gamma_q_contfrac": 246, "fpmin": 246, "gamma_q": 246, "chi2_sf": 246, "chi2_sim": 246, "214": [148, 246, 261, 267, 268, 269, 270], "39": [75, 118, 132, 142, 207, 231, 232, 240, 246, 254, 261, 267, 268, 269, 270], "cram\u00e9r": [246, 247, 256], "chi_square_statist": 246, "chi_square_contribut": 246, "standardized_residu": [246, 247], "chi_square_gof": 246, "expected_prob": [246, 247], "expected_count": [246, 247], "expected_counts_independ": 246, "chi_square_independ": 246, "cramers_v": [246, 247], "sim_count": 246, "sim_stat": 246, "e\u1d62\u2c7c": 246, "row_total\u1d62": 246, "col_total\u2c7c": 246, "o\u1d62\u2c7c": 246, "row_label": [246, 251], "col_label": [246, 251], "chat": [246, 333], "email": [246, 341, 349, 354, 355, 386], "phone": 246, "expected_ind": 246, "resid_ind": 246, "contrib_ind": 246, "annotated_heatmap": 246, "fmt": [246, 335], "heatmap_kwarg": 246, "causal": [246, 261, 262], "row_prob": 246, "col_prob": 246, "cell_prob": 246, "sim_flat": 246, "sim_tabl": 246, "expected_sim": 246, "exhaust": [246, 247, 283], "bewar": 246, "chi2_conting": 246, "yate": 246, "ngof": 246, "nindepend": 246, "unfair": 246, "intro": [246, 266], "mobil": 247, "desktop": [247, 358], "tablet": 247, "0k": 247, "0i": 247, "o_1": 247, "o_i": 247, "discrep": 247, "observed_count": 247, "wilson": [247, 252], "hilferti": [247, 252], "_as_1d_nonneg": 247, "array_lik": 247, "chi_square_gof_statist": 247, "prob_sum": 247, "expected_sum": 247, "chi_square_gof_df": 247, "chi_square_sf_mc": 247, "chisq_df": 247, "count_g": 247, "count_nonzero": 247, "chi_square_sf_wilson_hilferti": 247, "cramers_v_gof": 247, "chi_square_gof_test": 247, "p_mc_se": 247, "p_wh": 247, "p_value_mc_s": 247, "p_value_wh": 247, "reject_h0_mc": 247, "uniform_prob": 247, "n_roll": 247, "rng_exampl": 247, "observed_fair": 247, "observed_bias": 247, "rng_mc_fair": 247, "rng_mc_bias": 247, "fair_result": 247, "biased_result": 247, "chi2_fair": 247, "p_mc_fair": 247, "reject_fair": 247, "chi2_bias": 247, "p_mc_bias": 247, "reject_bias": 247, "disagre": [247, 256], "636efa": [247, 251, 260, 268, 308], "chi2_ob": 247, "rng_null": [247, 256], "null_sampl": 247, "critical_valu": [247, 250], "p_value_wh_approx": 247, "brand": 247, "yellow": 247, "expected_probs_claim": 247, "observed_color": 247, "rng_mc_color": 247, "202": [182, 247, 269], "color_result": 247, "expected_color": 247, "add_bar": 247, "counts_from_prob": 247, "add_to": 247, "chi2_valu": 247, "chi2_scipi": 247, "numpy_stat": 247, "scipy_p_valu": [247, 248, 260], "1900": [38, 247], "introductori": [247, 269], "omnibu": [248, 252, 253, 257, 259], "autom": [248, 297, 298, 331, 332, 333, 335, 342, 347, 349, 350, 351, 369], "k2_": 248, "3rd": 248, "normaltest": 248, "_central_moments_1d": 248, "sample_kurtosis_pearson": [248, 258], "dagostino_skew_z": 248, "anscombe_glynn_kurt_z": 248, "varb2": [248, 258], "x_stat": 248, "sqrtbeta1": [248, 258], "dagostino_k2_test": 248, "z_skew": 248, "z_kurt": 248, "kurtosis_pearson": 248, "scipy_k2": 248, "norm_ppf": [248, 252, 254], "qq_points_standard": 248, "add_hist_with_normal_fit": 248, "add_qq": 248, "x_normal": 248, "x_logn": 248, "k\u00b2": 248, "dagostino_components_batch": 248, "samples_norm": 248, "samples_logn": 248, "samples_t3": 248, "samples_mix": 248, "z1_n": 248, "z2_n": 248, "z1_l": 248, "z2_l": 248, "z1_t": 248, "z2_t": 248, "z1_m": 248, "z2_m": 248, "k2_thresh": 248, "circle_x": 248, "circle_i": 248, "z_skew\u00b2": 248, "z_kurt\u00b2": 248, "biometrika": [248, 258], "anscomb": [248, 261], "glynn": 248, "skewtest": 248, "kurtosistest": [248, 258], "dose": 249, "placebo": 249, "fwer_independ": 249, "gj": 249, "mu_g": 249, "t_j": [249, 257], "pooled_ms": 249, "sum_g": 249, "y_gj": 249, "mean_g": 249, "n_total": [249, 257, 263], "k_group": 249, "dunnett_corr": 249, "n_control": [249, 263], "n_treatment": [249, 263], "dunnett_t_stat": 249, "treat_nam": 249, "besid": 249, "mean_c": 249, "simulate_max_stat": 249, "dunnett_test": 249, "n_t": 249, "sim_rng": [249, 252], "max_stat": 249, "t_for_p": 249, "max_stat_sim": 249, "violinmod": [249, 259, 263], "print_result": 249, "arrayminu": [249, 266], "simulate_abs_t": 249, "crit_unadj": 249, "crit_bonf": 249, "crit_dun": 249, "456": [209, 249, 347], "any_unadj": 249, "any_bonf": 249, "any_dun": 249, "1955": 249, "df\u2081": 250, "n\u2081": 250, "df\u2082": 250, "n\u2082": 250, "nameerror": [75, 107, 112, 153, 201, 217, 250, 261, 271, 275, 281, 290, 291, 294, 297, 298, 302, 304, 307, 309, 310, 320, 321, 324, 325, 326], "traceback": [75, 107, 112, 127, 131, 132, 135, 137, 153, 201, 207, 209, 213, 217, 230, 232, 250, 261, 271, 275, 281, 290, 291, 293, 294, 297, 298, 302, 304, 307, 309, 310, 319, 320, 321, 323, 324, 325, 326, 389], "s\u00b2": 250, "\u03c3\u2081\u00b2": 250, "\u03c3\u2082\u00b2": 250, "fligner": [250, 259], "killeen": [250, 259], "f_rv": 250, "stdlib": 250, "log_beta": 250, "scaled_s2": 250, "f_sim": [250, 259], "s\u2081\u00b2": 250, "s\u2082\u00b2": 250, "df_1": 250, "df_2": 250, "f_test_vari": 250, "s1_sq": 250, "s2_sq": 250, "alternative_norm": 250, "two_sid": 250, "alternative_canon": 250, "mc_se": 250, "reject_h0": 250, "ci_var_ratio": 250, "plot_f_test": 250, "x_max_quantil": 250, "997": [21, 22, 146, 250], "rng_plot": 250, "f_sim_plot": 250, "shade": [250, 258, 261, 267, 269], "239": [250, 260, 299], "bgcolor": [135, 137, 250, 265], "255": [142, 250, 265, 310], "\u03c3\u2081": 250, "\u03c3\u2082": 250, "781384820492569": 250, "6656962640243989": 250, "0694535726391445": 250, "87165": 250, "0005288579145195805": 250, "3850427399035428": 250, "4863470025297367": 250, "43013045707257586": 250, "777493150259251": 250, "400000": [156, 250, 268], "res_diff": 250, "7968991166284403": 250, "228029458951296": 250, "18848002937664016": 250, "00098": 250, "947321497537834e": 250, "38428465507232556": 250, "4922479853766086": 250, "07562651489039465": 250, "490469829822288": 250, "dictionari": [135, 137, 250, 288], "rng_crit": 250, "f_crit_sim": 250, "600_000": 250, "y_norm": 250, "f_norm": 250, "reject_norm": 250, "t_df": [250, 268], "reject_t": 250, "047375": 250, "292375": 250, "h\u2081": [251, 254, 265], "odds_ratio": [251, 261], "r_2": 251, "log_factorials_upto": 251, "hypergeom_pmf_for_a_valu": 251, "odds_ratio_for_a_valu": 251, "or_": 251, "or_valu": 251, "111111": 251, "p_ob": [251, 261], "p_less": 251, "fisher_exact_numpi": 251, "return_detail": 251, "or_scipi": 251, "or_np": 251, "p_np": 251, "plot_pmf_with_rejection_region": 251, "ef553b": [251, 260, 305, 308], "b0b0b0": 251, "two_sided_p_for_each_a": 251, "a_sim": 251, "ngood": 251, "nbad": 251, "p_sim": 251, "1922": 251, "df_t": 252, "gc": 252, "mad": [252, 259], "group_id": 252, "rankdata": [252, 270], "rankdata_averag": [252, 257, 260, 265, 270], "a_sort": [252, 270], "s_a": 252, "fligner_killeen_statist": 252, "a_bar": 252, "a_bar_i": 252, "varsq": 252, "stat_fk": 252, "df_fk": 252, "norm_cdf_scalar": 252, "chi2_sf_wilson_hilferti": 252, "p_approx": 252, "spread_nam": 252, "rng_loc": 252, "n_loc": 252, "hb": 252, "hc": 252, "stat_loc": 252, "df_loc": 252, "p_loc_approx": 252, "x_loc": 252, "labels_loc": 252, "simulate_fk_stat": 252, "scale_c": 252, "stats_h0": 252, "stats_h1": 252, "df_ref": 252, "chi2_ppf_wilson_hilferti": 252, "stats_alt": 252, "sample1": 252, "sample2": 252, "stat_scipi": 252, "6g": [252, 253, 267], "bartlett": [252, 259], "rejection_r": [252, 254, 259, 264], "rej": 252, "levene_median": 252, "p_b": 252, "p_l": 252, "gl": 252, "conov": [252, 257, 260], "1981": [178, 252], "u2026": 253, "u2019t": 253, "n_block": 253, "u00d7": 253, "k_treatment": 253, "drug": 253, "ordin": [253, 255, 257, 259, 260, 265, 266, 270], "u201cnot": 253, "u201crandomli": 253, "u2211_i": 253, "t_g": 253, "q_ob": 253, "concord": 253, "u2248": 253, "rankdata_average_ties_1d": 253, "x_work": 253, "rank_avg": 253, "rank_rows_average_ti": 253, "friedman_statistic_from_rank": 253, "tie_correct": 253, "rank_sum": [253, 257], "tie_sum": 253, "expected_rank_sum": 253, "tie_correction_factor": 253, "friedman_q_from_rank_sum": 253, "friedman_null_q_from_rank": 253, "n_resampl": [253, 255, 265], "ranks_perm": 253, "broadcast_to": 253, "friedman_test_numpi": 253, "higher_is_bett": 253, "q_null": 253, "ranks_toi": 253, "algo": 253, "mean_rank": [253, 257], "viridis_r": 253, "underpow": [253, 263], "friedmanchisquar": 253, "iman": 253, "davenport": 253, "nemenyi": 253, "u2013wal": 253, "n_blocks_0": 253, "k_0": 253, "baseline0": 253, "effects0": 253, "scores0": 253, "dem": 253, "u0161ar": 253, "insuffici": [254, 270], "comprehens": 254, "_to_1d_finit": 254, "central_mo": 254, "sample_skewness_kurtosi": 254, "jarque_bera_test": 254, "skew_compon": 254, "kurtosis_compon": 254, "chi2_df2_pdf": 254, "chi2_df2_sf": 254, "plot_jb_pvalu": 254, "xs_tail": 254, "sup": 254, "simulate_jb_under_norm": 254, "jb_val": 254, "n_for_geometri": 254, "241": 254, "e_grid": 254, "jb_grid": 254, "crit_level": 254, "rh": 254, "s_line": 254, "e_lin": 254, "69683028665376": 254, "9460984245205": 254, "275": [136, 254], "9285104469687": 254, "3577518672690": 254, "66479806614716": 254, "506628277459239": 254, "54": [99, 110, 116, 134, 238, 254], "47609879822406": 254, "5858368580409": 254, "155": [49, 102, 140, 254], "6989798598866": 254, "66": [110, 151, 175, 240, 254], "80131188771972": 254, "28068155288572": 254, "007784894002430293": 254, "3223964580411365": 254, "400758277161838": 254, "549732539343734": 254, "374664141464968": 254, "938163982698783": 254, "007784695709041462": 254, "3224671290700398": 254, "445134137142996": 254, "754408661907416": 254, "z_sampl": 254, "z_sort": 254, "bundl": [254, 352], "1980": 254, "likert": [255, 257, 260, 265], "opposit": [255, 262], "tau_a": 255, "tau_b": 255, "_clean_xi": 255, "kendall_pair_count": 255, "t_y": 255, "t_xy": 255, "kendall_tau_a": 255, "kendall_tau_b": 255, "xaxis_tickangl": 255, "p_conc": 255, "p_disc": 255, "x_tie": 255, "y_tie": 255, "counts_a": 255, "counts_b": 255, "xj": 255, "yj": 255, "n_small": 255, "counts_smal": 255, "s_from_matrix": 255, "x_nl": [255, 262], "y_nl": [255, 262], "tau_raw": 255, "tau_exp": 255, "kendall_permutation_test": 255, "tau_ob": 255, "tau_perm": 255, "y_perm": 255, "x_ex": 255, "y_ex": 255, "tau_nul": 255, "_normal_cdf": [255, 270], "kendall_tau_a_asymptotic_test": 255, "p_asym": [255, 256], "bootstrap_tau_b": 255, "tau_sampl": 255, "tau_boot": 255, "1938": 255, "kendalltau": 255, "ecdf_step": 256, "x_step": 256, "y_step": 256, "padded_linspac": 256, "cdf_uniform_01": 256, "ks_1samp_statist": 256, "sup_x": 256, "d_plus_val": 256, "d_minus_v": 256, "d_plu": 256, "d_minu": 256, "y_emp": 256, "y_cdf": 256, "x_star": [256, 263], "ks_2samp_statist": 256, "ks_pvalue_asymptotic_two_sid": 256, "vet": 256, "ks_1samp_null_d": 256, "mc_pvalue_right_tail": 256, "stat_ob": [256, 263], "stats_nul": 256, "ks_2samp_pvalue_perm": 256, "n_perm": [256, 257, 262], "y_b": 256, "somewher": 256, "d_n": [256, 268, 270], "cdf_exponenti": 256, "ds_null_1samp": 256, "one_sample_result": 256, "res_1samp": 256, "ecdf_grid": 256, "abs_gap": 256, "d_crit_05": 256, "d_correct": 256, "d_wrong": 256, "lack": 256, "rng_a": 256, "rng_b": 256, "res_2samp": 256, "rng_perm": [256, 260], "p_perm": [256, 260, 262], "ds_perm_2samp": 256, "x_sorted_a": 256, "x_step_a": 256, "y_step_a": 256, "x_sorted_b": 256, "x_step_b": 256, "y_step_b": 256, "fa_star": 256, "fb_star": 256, "fdr": [256, 265], "smirnov_test": [], "1970": 256, "lilliefors_test": 256, "biolog": 257, "groups_tini": 257, "group_names_tini": 257, "tie_count": 257, "sorted_x": [257, 265], "run_start": 257, "run_end": 257, "all_values_tini": 257, "all_ranks_tini": 257, "tie_counts_tini": 257, "labels_tini": 257, "rank_sums_tini": 257, "reduceat": 257, "ns_tini": 257, "mean_ranks_tini": 257, "overall_mean_rank_tini": 257, "kruskal_wallis_h": 257, "tie_term": [257, 260], "h_corr": 257, "epsilon_sq": 257, "h_uncorrect": 257, "tie_correction_c": 257, "epsilon_squar": 257, "kruskal_wallis_permutation_test": 257, "h_ob": 257, "h_perm": 257, "rank_sums_ob": 257, "details_tini": 257, "p_tini": 257, "h_obs_tini": 257, "h_perm_tini": 257, "overall_mean_rank": 257, "a_ti": 257, "b_ti": 257, "c_ti": 257, "details_ti": 257, "h_correct": 257, "pooled_ti": 257, "ranks_ti": 257, "holm": 257, "benjamini": 257, "hochberg": 257, "usefulli": 258, "leptokurt": 258, "platykurt": 258, "n_big": 258, "had": 258, "24n": 258, "normal_sf": 258, "pvalue_from_z": [258, 264], "kurtosistestresult": 258, "expected_b2": 258, "var_b2": 258, "kurtosis_test_anscombe_glynn": 258, "scipy_kurtosistest": 258, "standard_normal_pdf": 258, "plot_pvalue_shad": 258, "mask_left": [258, 269], "mask_right": [258, 269], "x_heavi": 258, "res_heavi": 258, "kurtosis_test_statistic_vector": 258, "agostino": 258, "227": 258, "234": 258, "trimmed_mean": 259, "proportiontocut": 259, "_center": 259, "levene_statist": 259, "z_group": 259, "z_mean": [259, 264], "z_bar": 259, "f_pvalue_mc": 259, "levene_test_numpi": 259, "plot_raw_vs_devi": 259, "center_label": 259, "plot_mean_abs_devi": 259, "grand": 259, "plot_f_null_distribut": 259, "f_dist": 259, "levene_scipi": 259, "w_scipi": 259, "pvalue_f": 259, "estimate_type1_error": 259, "gen_group": 259, "gen_norm": 259, "gen_t3_heavy_tail": 259, "dist_nam": 259, "gen": 259, "df_rate": 259, "longitudin": 260, "group_a": 260, "group_b": 260, "scalemod": 260, "sorted_v": 260, "return_index": [260, 270], "u_from_pair": 260, "gt": 260, "mann_whitney_u_from_rank": 260, "u1_pair": 260, "u1_rank": 260, "u2_rank": 260, "shouldn": 260, "mw_u_permutation_test": 260, "obs_r1": 260, "obs_u1": 260, "perm_r1": 260, "perm_u1": 260, "mu_nul": 260, "mu_u": 260, "mw_u_normal_approx": 260, "u1_norm": 260, "p_norm": 260, "superior": 260, "cliffs_delta": 260, "r_effect": 260, "probability_of_superior": 260, "cliff": 260, "00cc96": 260, "rng_shape": 260, "u1_xi": 260, "z_xy": 260, "p_xy": 260, "sample_median_x": 260, "sample_median_i": 260, "mannwhitneyu": 260, "ours_u1": 260, "ours_p_valu": 260, "scipy_u1": 260, "log_odd": 261, "haldan": 261, "odds1": 261, "odds0": 261, "5th": 261, "cdf_po": [261, 267], "odds_ratio_wald_test": 261, "table_2x2": 261, "log_or": 261, "ci_log": 261, "ci_or": 261, "log_odds_ratio": 261, "se_log_odds_ratio": 261, "res_cc": 261, "zab": 261, "simulate_tables_under_h0": 261, "n_unexpos": 261, "p_event": 261, "wald_z_for_t": 261, "tables_h0": 261, "c_ob": 261, "a_support": 261, "p_observed_t": 261, "steelblu": 261, "p1_from_p0_and_or": 261, "ors": 261, "rr": 261, "causat": [261, 262, 265], "agresti": 261, "eda": 262, "misus": 262, "pearson_r": [262, 265], "ssx": 262, "ssy": 262, "ols_lin": 262, "pearson_t_stat": 262, "pearson_p_value_parametr": 262, "pearson_p_value_permut": 262, "r_ob": 262, "r_perm": 262, "bootstrap_ci_r": 262, "xb_c": 262, "yb_c": 262, "r_boot": 262, "p_param": 262, "mask_extrem": [262, 263], "r_nl": 262, "simulate_r_under_rho": 262, "r_n20": 262, "r_n80": 262, "r_n300": 262, "pearsonr": 262, "r_scipi": 262, "1935": [238, 262], "resourc": [1, 262, 331, 334, 335, 338, 340, 341, 343, 345, 346, 347, 349, 351, 356, 357, 358, 368, 369, 370, 371, 373, 374, 378, 379], "n_x": 263, "n_y": 263, "reshuffl": 263, "strata": 263, "_as_1d_float_arrai": 263, "_permutation_p_valu": 263, "perm_stat": 263, "permutation_test_two_sampl": 263, "statistic_fn": 263, "permutation_test_paired_sign_flip": 263, "control_mean": 263, "treatment_mean": 263, "control_median": 263, "treatment_median": 263, "legendgroup": 263, "stat_mean_diff": 263, "result_mean": 263, "observed_mean_diff": 263, "reject_at_0": 263, "t_perm": 263, "p_run": 263, "stat_median_diff": 263, "result_median": 263, "mean_diff": [263, 268], "median_diff": [263, 270], "t_obs_m": 263, "p_med": 263, "t_perm_m": 263, "mask_extreme_m": 263, "paired_result": 263, "321": [135, 137, 263], "t_obs_p": 263, "p_p": 263, "t_perm_p": 263, "mask_extreme_p": 263, "vagu": 263, "peek": 263, "hack": [263, 266], "ernst": 263, "manli": 263, "biologi": 263, "x_sym": 264, "eta_2": 264, "27n": 264, "dagostino_z_from_skew": 264, "nf": 264, "dagostino_skewtest": 264, "summarize_test": 264, "res_two": 264, "res_great": 264, "res_less": 264, "b2_grid": 264, "skewness_vector": 264, "z_std": 264, "scipy_r": [264, 268, 269, 270], "abs_diff_z": 264, "abs_diff_p": 264, "1990": 264, "scipy_spearmanr": 265, "kendal": 265, "y\u1d62": 265, "drop_nan_pair": 265, "spearman_rho": 265, "rx": 265, "rho_corr": 265, "rho_d2": 265, "medium": [265, 266, 270, 287, 306], "spearman_permutation_test": 265, "return_nul": 265, "rx_c": 265, "ry_c": 265, "rho_ob": 265, "ry_perm": 265, "spearman_bootstrap_ci": 265, "return_sampl": 265, "x4": 265, "pear": 265, "spear": 265, "x_annot": 265, "y_annot": 265, "bordercolor": [135, 137, 265], "borderwidth": [135, 137, 265], "pear_orig": 265, "pear_tran": 265, "spear_orig": 265, "spear_tran": 265, "rho_nul": 265, "ci_lo": 265, "ci_hi": 265, "rho_boot": 265, "rho_scipi": 265, "62": [34, 35, 37, 175, 179, 240, 265], "1904": 265, "mu_d": [266, 268], "t_cdf_numer": 266, "t_ab": [266, 267], "200000": 266, "t_p_valu": [266, 267], "t_ppf_numer": 266, "p_target": 266, "ci_two_sid": 266, "t_crit": [266, 267, 269], "one_sample_t_test": 266, "reject_at_alpha": 266, "two_sample_t_test": 266, "diff0": 266, "equal_var": [266, 267], "raw_diff": 266, "sp2": [266, 267], "se2": 266, "paired_t_test": 266, "mean_befor": 266, "mean_aft": 266, "plot_t_p_valu": 266, "res_1": 266, "\u03bc\u2080": 266, "error_x": 266, "mu_a": 266, "res_welch": [266, 267], "res_pool": 266, "res_pair": 266, "ci_excludes_zero": 266, "one_sampl": 266, "ci_excludes_0": 266, "kick": [266, 268], "true_effect": [266, 268], "false_po": 266, "1908": [266, 267], "unpair": 267, "scipy_t": 267, "ttest_ind": 267, "has_scipi": 267, "sigma_x": 267, "satterthwait": 267, "tdistlookup": 267, "t_max": 267, "make_t_lookup": 267, "cdf_ab": 267, "t_ppf": 267, "p_ab": 267, "independentttestresult": 267, "mean2": 267, "var1": 267, "var2": 267, "cohens_d": 267, "cohens_d_method": 267, "t_test_independent_numpi": 267, "lookup_n": 267, "format_result": 267, "group1": 267, "group2": 267, "res_stud": 267, "nwelch": 267, "plot_two_sided_p_value_region": 267, "polygon": 267, "yl": 267, "includes_zero": 267, "group2_outli": 267, "res_welch_outli": 267, "student_t_stats_matrix": 267, "lookup0": 267, "t_stats0": 267, "cdf0": 267, "p_vals0": 267, "r_student": 267, "r_welch": 267, "1947": 267, "unclear": 268, "s_d": 268, "00a6d6": 268, "d_z": 268, "_paired_clean": 268, "paired_t_statist": 268, "dbar": 268, "sd_diff": 268, "se_mean_diff": 268, "cohens_dz": 268, "simulate_student_t": 268, "paired_t_test_numpi": 268, "tcrit": [268, 269], "student_t_pdf": [268, 269], "mean_nul": 268, "p_signflip": 268, "ab63fa": 268, "ci_scipi": 268, "reorder": 268, "descript": [135, 137, 269, 275, 357], "250ml": 269, "252": [263, 269], "ttest_1samp_numpi": 269, "cohen_d": 269, "mc_sampl": 269, "mc_seed": 269, "ymax": 269, "xline": 269, "mu0_sim": 269, "mu0_pow": 269, "sigma_pow": 269, "b_power": 269, "b_crit": 269, "rng_power": 269, "t_alt": 269, "first_idx": 270, "start_rank": 270, "end_rank": 270, "signed_rank_compon": 270, "d_nz": 270, "abs_d": 270, "w_plu": 270, "w_minu": 270, "wilcoxon_exact_pmf_no_ti": 270, "wilcoxon_signed_rank": 270, "total_rank_sum": 270, "has_ti": 270, "method_": 270, "w_plus_int": 270, "w_cc": 270, "rank_biseri": 270, "zero_method": 270, "wilcox": 270, "w_plus_ob": 270, "w_plus_sim": 270, "p_mc_greater": 270, "biseri": 270, "rbc": 270, "paired": 270, "weaken": 270, "trickier": 270, "lectur": 270, "load_airlin": [271, 275, 281, 297, 298, 302, 303, 304, 307, 309, 310, 323, 326], "passeng": [271, 275, 281, 297, 298, 302, 304, 307, 309, 326], "isna": 275, "performance_metr": [271, 297, 298, 304, 307, 310], "naiveforecast": [271, 281, 301, 304, 307, 310, 323], "temporal_train_test_split": [271, 281, 297, 298, 299, 302, 304, 306, 307, 309, 310, 323], "forecastinghorizon": [271, 281, 297, 298, 302, 304, 306, 307, 309, 310, 323], "fh": [271, 281, 297, 298, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 323], "is_rel": [271, 281, 297, 298, 302, 304, 306, 307, 309, 310, 323], "square_root": [271, 304, 307], "leakag": [281, 296, 304, 307, 310, 323, 400], "transformedtargetforecast": [281, 301, 323], "to_timestamp": [271, 280, 281, 296, 297, 298, 301, 302, 303, 304, 306, 307, 309, 310, 326], "elast": [287, 290, 295, 316, 319, 341, 353, 381, 382, 384, 385], "load_basic_mot": [287, 289, 290, 291, 294, 320, 321, 324, 325], "load_unit_test": [290, 291, 293, 294, 320, 321, 324, 325], "return_x_i": [287, 289, 290, 291, 293, 294, 320, 321, 324, 325], "distance_bas": [287, 290, 319], "ridgeclassifiercv": 291, "interval_bas": [289, 294, 321], "autoregress": [297, 298, 328], "y_log": [297, 298], "y_diff": [297, 298, 323], "tsaplot": [271, 297, 298], "plot_acf": [271, 297, 298], "plot_pacf": [271, 297, 298], "ywm": [271, 297, 298], "tight_layout": [271, 297, 298], "autoarima": 297, "suppress_warn": 298, "exp_smooth": 302, "exponentialsmooth": 302, "rethink": [304, 307], "seasonal_last": 307, "extrapol": [308, 309], "competit": 309, "thetaforecast": [301, 309], "rocket": [320, 324], "ridgeclassifi": [324, 325], "tsfresh": 325, "default_fc_paramet": 325, "zt": 326, "orchestr": [331, 333, 343, 344, 346, 348, 350, 351, 356, 358, 378], "docker": [332, 333, 343], "helm": 331, "kustom": [331, 372], "aw": [340, 341, 344, 347, 355], "github": [138, 139, 140, 141, 142, 144, 146, 331, 335, 379], "argo": 344, "terraform": [339, 344, 354, 356, 357, 362], "pulumi": 362, "prometheu": 371, "grafana": [], "elk": [], "sync": [0, 4, 331, 349, 366], "health": [331, 343, 367, 374], "namespac": [331, 340, 344, 358, 359, 371, 374, 376], "configmap": [331, 371], "git": [331, 333, 335, 338, 376], "rollback": [5, 331, 338, 367], "reconcil": 331, "app": [1, 331, 332, 334, 335, 343, 345, 347, 349, 351, 358, 359, 365, 367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 381, 382, 385], "concern": 331, "revert": 331, "poll": [331, 343, 346, 348, 350, 355], "webhook": [331, 333, 354], "revis": 331, "destin": [331, 385], "bind": [127, 131, 132, 331], "bring": [331, 335, 350, 359], "heal": 331, "rbac": [2, 331, 344, 372, 376], "canari": [331, 336], "argocd": 331, "apivers": [331, 365, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379, 383], "argoproj": 331, "v1alpha1": 331, "payment": [331, 333, 351, 381], "repourl": 331, "targetrevis": 331, "valuefil": 331, "yaml": [331, 338, 344, 358, 359], "server": [4, 331, 333, 339, 342, 344, 345, 349, 350, 351, 358, 366, 368, 382, 386, 401], "svc": [331, 377, 378], "syncpolici": 331, "selfheal": 331, "syncopt": 331, "createnamespac": 331, "prunelast": 331, "ghcr": [331, 332, 358], "sha": [331, 332], "reconcili": 331, "declar": [331, 333, 334, 335, 338, 358, 367, 371, 385], "cli": [331, 334, 335, 350, 358, 359], "imper": [331, 334], "seal": 331, "ownership": [331, 359], "kubectl": [331, 344, 371, 372], "edit": [331, 352, 358, 371], "fight": 331, "authorit": 331, "replica": [331, 351, 367, 368, 371, 374, 378, 382], "ingress": [331, 357, 364, 371], "approv": [331, 332, 333, 335, 346, 356], "opengitop": 331, "runner": [332, 346], "yml": [332, 358, 386], "pull_request": 332, "dispatch": 332, "host": [332, 333, 342, 345, 352, 359, 369, 371, 385], "lint": 332, "sast": 332, "status": 332, "workload": [3, 4, 332, 341, 342, 343, 344, 346, 353, 357, 366, 370, 374, 375], "marketplac": 332, "harden": [332, 333, 342], "fresh": [332, 345], "vm": [332, 333, 351, 358], "ephemer": [332, 333, 346, 373, 374, 377], "shell": [332, 333], "permiss": [332, 344, 346, 347, 348, 349, 350, 353, 354, 356, 358, 359], "github_token": 332, "workflow_dispatch": 332, "upload": [332, 350, 352], "review": [332, 333, 335, 338, 371], "oidc": [2, 332], "credenti": [332, 333, 340, 341, 342, 347, 348, 352, 355, 376], "openid": 332, "ci_cd": 332, "content": [332, 339, 350, 352, 355, 382, 400], "ubuntu": [332, 358, 359], "checkout": [332, 333, 367, 368, 377, 381, 382, 384, 386], "v4": 332, "npm": 332, "build_and_push_imag": 332, "login": [332, 333], "v3": [332, 338, 341, 347, 355], "registri": [283, 284, 285, 286, 287, 288, 289, 292, 295, 300, 318, 322, 332, 333, 334, 335, 358, 360], "usernam": 332, "password": [332, 345, 351, 353, 376], "v6": 332, "deploy_stag": 332, "deploy_prod": 332, "onboard": 332, "conflict": 332, "scope": [332, 333, 353, 365, 372], "syntax": [217, 332, 333], "plugin": [333, 335, 350, 359, 385], "linux": [261, 333, 359, 381], "linter": [333, 334], "infra": [333, 335, 338], "prem": [333, 335, 346, 357], "air": 333, "scm": 333, "burden": [333, 343, 351], "upgrad": [333, 335, 344, 378], "executor": 333, "static": [285, 333, 339, 352], "pod": [333, 359, 364, 367, 369, 370, 372, 375, 377, 378, 384], "workspac": [333, 335], "notifi": [333, 340, 384], "statu": [1, 333, 335, 343, 344, 346, 348, 350, 356, 381, 382, 383, 384, 386], "freestyl": 333, "multibranch": 333, "immut": [333, 358, 362], "disableconcurrentbuild": 333, "app_nam": 333, "git_commit": 333, "junit": 333, "xml": 333, "archiveartifact": 333, "fingerprint": 333, "withcredenti": 333, "usernamepassword": 333, "credentialsid": 333, "cred": 333, "usernamevari": 333, "passwordvari": 333, "cleanw": 333, "enterpris": 333, "privat": [333, 343, 344, 351, 358, 359], "customiz": 333, "sprawl": 333, "regularli": 333, "cve": 333, "privileg": [11, 333, 342, 343, 349, 359, 376], "multistag": 333, "www": [285, 333, 334, 381, 382, 384, 385], "book": 333, "adopt": [334, 335], "vpc": [334, 335, 338, 342, 343, 344, 345, 346, 349, 350, 351], "subnet": [334, 335, 338, 342, 343, 344, 345, 346, 350, 351, 357], "iam": [11, 334, 335, 338, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 354, 356], "zone": [334, 335, 357, 379], "typescript": 334, "java": [334, 338, 341, 347, 349, 355], "dsl": 334, "azur": [334, 335], "gcp": [334, 335], "saa": [334, 335, 347], "creation": [334, 350, 373], "arn": [334, 335, 338, 340, 343, 344, 347, 348, 349, 350, 354, 356], "encrypt": [2, 334, 335, 352, 353, 376], "provis": [334, 335, 338, 341, 345, 346, 350, 351, 373, 377, 379], "guardrail": 334, "unifi": [295, 334], "url": [1, 334, 339, 350, 352, 383, 405], "pulumi_aw": 334, "get_stack": 334, "bucketversioningarg": 334, "ec2": [334, 343, 344, 346, 352, 357], "cidr_block": 334, "enable_dns_hostnam": 334, "get_availability_zon": 334, "public_subnet": 334, "public": [334, 335, 339, 342, 344, 351, 353, 357], "vpc_id": [334, 357], "availability_zon": 334, "bucket_nam": [334, 335], "public_subnet_id": [334, 357], "east": [334, 338, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357], "destroi": [334, 335], "accident": [334, 359], "sdk": 334, "datadog": 335, "aws_s3_bucket": 335, "remot": [335, 358], "hcl": 335, "cdn": [335, 339], "aws_inst": 335, "aws_vpc": 335, "lock": [335, 341, 342], "dynamodb": [335, 343, 349, 356, 357], "required_vers": 335, "required_provid": 335, "hashicorp": 335, "aws_s3_bucket_vers": 335, "versioning_configur": 335, "bucket_arn": 335, "tfplan": 335, "referenc": 335, "collabor": [4, 335], "ansibl": [335, 358], "remedi": 335, "for_each": 335, "intent": 335, "amazon": [337, 339, 350, 356], "package_07312025": 337, "svg": 337, "64px": 337, "json": [338, 347, 348, 349, 355, 356, 381, 382, 383, 384, 385], "complianc": [338, 340, 357, 381], "cleanup": [338, 343, 344, 349, 350, 351, 357, 358, 366, 370], "acknowledg": 338, "capability_named_iam": 338, "boto3": [338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357], "incur": [338, 343, 344, 346, 349, 351, 352, 357], "client": [4, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 386], "region_nam": [338, 340, 342, 343, 344, 345, 346, 348, 349, 350, 351, 352, 354, 356, 357], "stack_nam": 338, "templateurl": 338, "template_bodi": 338, "utf": [338, 349], "parameterkei": 338, "parametervalu": 338, "bucketnam": 338, "create_stack": 338, "stacknam": 338, "templatebodi": 338, "get_wait": [338, 339, 342, 351], "stack_create_complet": 338, "describe_stack": 338, "update_stack": 338, "stack_update_complet": 338, "clienterror": 338, "handle_update_error": 338, "delete_stack": 338, "ssm": [338, 342, 349], "rd": [338, 341, 350], "deletionpolici": 338, "consum": [4, 8, 338, 347, 354, 355, 359, 371, 381], "waiter": [338, 351], "gatewai": [339, 349, 357], "fetch": [339, 342, 351], "waf": [13, 339], "dxxxxx": 339, "hostnam": [339, 358], "cooki": [339, 400], "ttl": [339, 345, 370], "expiri": 339, "spa": 339, "offload": 339, "media": 339, "video": [339, 355], "geograph": 339, "cacheabl": 339, "egress": [339, 357], "distributionconfig": 339, "schema": [339, 348, 353, 382], "create_distribut": 339, "callerrefer": 339, "comment": [339, 356], "domainnam": 339, "amazonaw": [339, 343, 357], "s3originconfig": 339, "oac": 339, "defaultcachebehavior": 339, "targetoriginid": 339, "viewerprotocolpolici": 339, "redirect": 339, "cachepolicyid": 339, "originrequestpolicyid": 339, "distribution_id": 339, "domain_nam": 339, "d111111abcdef8": 339, "sparingli": 339, "create_invalid": 339, "distributionid": 339, "invalidationbatch": 339, "distribution_deploi": 339, "cloudform": [339, 344, 354, 356, 357], "cdk": [339, 356, 357], "dashboard": [340, 351, 353, 381, 382, 384, 386], "notif": [340, 347, 349, 383, 384], "alert": [340, 342, 347, 354, 380, 381], "throttl": [340, 345], "autosc": [340, 344, 351, 361, 374], "troubleshoot": 340, "retain": [340, 373], "retent": [340, 352, 381, 382], "p50": 340, "p95": [340, 381, 383, 386], "5xxerrorr": 340, "functionnam": [340, 349, 356], "datapoint": 340, "timezon": [340, 366], "cw": 340, "millisecond": [340, 341, 345], "demoapp": 340, "metric_nam": 340, "inferencelatencym": 340, "put_metric_data": 340, "metricdata": 340, "metricnam": 340, "utc": 340, "200m": 340, "alarm_nam": 340, "sns_topic_arn": 340, "123456789012": [340, 347, 348, 354], "put_metric_alarm": 340, "alarmnam": 340, "evaluationperiod": 340, "comparisonoper": 340, "greaterthanthreshold": 340, "treatmissingdata": 340, "extendedstatist": 340, "alarmact": 340, "get_metric_statist": 340, "starttim": 340, "endtim": 340, "upfront": 341, "authent": [2, 341, 344], "shop": 341, "iot": 341, "idempot": [1, 4, 341, 347, 348, 349, 354, 355, 370], "serverless": [341, 343, 346, 347, 348, 349, 351], "microservic": [341, 344, 347, 355], "postgr": [341, 351, 358, 359], "opensearch": 341, "gsi": 341, "lsi": 341, "acid": [341, 351], "awssdk": [341, 347, 355], "ddb": 341, "table_nam": 341, "user_id": [1, 341, 345, 381, 386], "create_t": 341, "tablenam": 341, "keyschema": 341, "attributenam": 341, "keytyp": 341, "hash": [341, 371], "attributedefinit": 341, "attributetyp": 341, "billingmod": 341, "pay_per_request": 341, "provisionedthroughput": 341, "put_item": 341, "u_123": 341, "created_at": 341, "2026": [116, 122, 341, 348, 381, 382], "06t00": 341, "00z": 341, "get_item": 341, "consistentread": 341, "user_item": 341, "atom": [341, 345], "update_item": 341, "updateexpress": 341, "last_login": 341, "expressionattributevalu": 341, "06t12": 341, "56z": 341, "u_999": 341, "conditionexpress": 341, "attribute_not_exist": 341, "delete_item": 341, "race": 341, "ip": [342, 357, 374, 377], "port": [342, 343, 345, 351, 358, 359, 367, 369, 372, 374, 377, 378, 381, 385], "ssh": 342, "virtual": [342, 353, 358, 377], "preinstal": 342, "ram": 342, "m7i": 342, "g5": 342, "xlarg": [342, 346], "eb": [342, 352], "lifecycl": [342, 344, 352, 358], "etl": [342, 343, 346, 347, 348, 350, 370], "backfil": [5, 342, 347, 350], "alb": [342, 343, 344], "nlb": [342, 343, 344], "cloudwatch": [342, 343, 344, 347, 348, 349, 350, 351, 354], "inbound": [342, 358, 359], "outbound": [342, 357, 358], "hardcod": [342, 343, 346, 348, 349, 351, 352, 353, 376], "profile_nam": 342, "launch": [342, 343, 357], "run_inst": [342, 357], "imageid": [342, 357], "0abc1234def567890": 342, "instancetyp": [342, 344, 346, 357], "mincount": [342, 357], "maxcount": [342, 357], "subnetid": [342, 344, 350, 357], "0123456789abcdef0": 342, "securitygroupid": [342, 344, 350, 357], "sg": [342, 343, 344, 350, 351, 357], "keynam": 342, "keypair": 342, "tagspecif": 342, "resourcetyp": 342, "instance_id": 342, "instanceid": 342, "instance_run": 342, "desc": [342, 356], "describe_inst": 342, "terminate_inst": 342, "ec": [342, 350, 352, 356], "ek": [342, 346, 357], "fargat": [343, 344], "blueprint": 343, "ecr": [343, 357, 358], "container": [343, 344, 358], "elt": [343, 348, 350, 353], "cluster_nam": [343, 344], "create_clust": [343, 344], "clusternam": [343, 344], "task_def": 343, "register_task_definit": 343, "requirescompat": 343, "networkmod": 343, "awsvpc": 343, "executionrolearn": [343, 350], "ecstaskexecutionrol": 343, "taskrolearn": 343, "demoapptaskrol": 343, "containerdefinit": 343, "dkr": 343, "portmap": 343, "containerport": [343, 367, 374], "8080": [343, 358, 359, 367, 372, 374, 377, 386], "tcp": 343, "logconfigur": 343, "logdriv": 343, "awslog": 343, "task_definition_arn": 343, "taskdefinit": 343, "taskdefinitionarn": 343, "run_task": 343, "launchtyp": 343, "networkconfigur": [343, 350], "awsvpcconfigur": 343, "aaaa": 343, "bbbb": 343, "securitygroup": 343, "cccccccc": 343, "assignpublicip": 343, "task_arn": 343, "taskarn": 343, "describe_task": 343, "create_servic": 343, "etcd": 344, "deepli": 344, "cronjob": 344, "kubeflow": 344, "mlflow": 344, "hybrid": [308, 344, 357], "portabl": [344, 369, 373, 379], "author": [2, 344, 350], "ons": 344, "cni": [344, 358], "coredn": 344, "kube": [344, 359], "eksctl": 344, "cluster_vers": 344, "29": [75, 101, 103, 107, 112, 142, 148, 172, 231, 234, 267, 268, 344, 389], "cluster_role_arn": 344, "eksclusterrol": 344, "node_role_arn": 344, "eksnoderol": 344, "eni": 344, "subnet_id": 344, "aaa": 344, "bbb": 344, "security_group_id": 344, "rolearn": [344, 356], "resourcesvpcconfig": 344, "endpointpublicaccess": 344, "endpointprivateaccess": 344, "describe_clust": [344, 346], "sleep": [344, 346, 348, 350], "create_nodegroup": 344, "nodegroupnam": 344, "ng": 344, "noderol": 344, "m5": [344, 346], "scalingconfig": 344, "minsiz": 344, "desireds": 344, "maxsiz": 344, "ca_data": 344, "certificateauthor": 344, "gitop": [344, 372], "kubeconfig": 344, "build_kubeconfig": 344, "certificate_authority_data": 344, "auth_via_iam": 344, "k8": [344, 359, 369, 379], "kubernetescli": 344, "apply_yaml": 344, "manifest": [344, 371], "createclust": 344, "createnodegroup": 344, "describeclust": 344, "redi": 345, "memcach": 345, "counter": [6, 286, 345, 381, 386], "leaderboard": 345, "asid": 345, "stateless": [315, 345, 357, 368], "pub": [4, 345, 354], "describe_replication_group": 345, "replicationgroupid": 345, "rg": 345, "replicationgroup": 345, "nodegroup": 345, "primaryendpoint": 345, "redis_host": 345, "redis_port": 345, "ssl": 345, "user_profil": 345, "query_user_profil": 345, "failov": [345, 378, 408], "spark": [346, 348, 350], "apach": [346, 348], "hadoop": 346, "hdf": 346, "hive": [288, 346], "presto": 346, "trino": 346, "lake": [346, 348, 351, 352], "submit": [346, 355], "airflow": 346, "prefect": 346, "curat": [346, 348, 351, 352, 353], "migrat": [5, 346, 370, 379], "lift": 346, "dispos": [346, 358, 359], "s3_code_uri": 346, "s3_input_uri": 346, "s3_output_uri": 346, "s3_log_uri": 346, "service_rol": 346, "emr_defaultrol": 346, "job_flow_rol": 346, "emr_ec2_defaultrol": 346, "run_job_flow": 346, "releaselabel": 346, "loguri": 346, "ec2subnetid": 346, "xxxxxxxx": [346, 350, 351], "keepjobflowalivewhennostep": 346, "terminationprotect": 346, "instancegroup": 346, "instancerol": 346, "instancecount": 346, "on_demand": 346, "actiononfailur": 346, "terminate_clust": 346, "hadoopjarstep": 346, "jar": 346, "servicerol": 346, "jobflowrol": 346, "visibletoallus": 346, "jobflowid": 346, "terminal_st": 346, "terminated_with_error": 346, "clusterid": 346, "aliv": [346, 356], "terminate_job_flow": 346, "payload": [2, 347, 349, 354, 355, 356], "deliv": [347, 354, 355], "kinesi": [347, 349], "successor": 347, "decoupl": [3, 4, 347, 354, 355, 373], "ordercr": 347, "paymentfail": 347, "sagemak": [347, 350, 356, 357], "cron": [347, 349, 356, 366], "retrain": 347, "buse": 347, "partner": [347, 353], "invok": [347, 349, 356], "bus_nam": 347, "rule_nam": 347, "create_event_bu": 347, "orderid": 347, "customerid": 347, "put_rul": 347, "eventbusnam": 347, "eventpattern": 347, "lambda_arn": 347, "put_target": 347, "processorderlambda": 347, "inputtransform": 347, "send": [135, 137, 347, 349, 354, 355, 374, 382, 383, 385], "dlq": [347, 355], "deadletterconfig": 347, "dlq_arn": 347, "put_ev": 347, "detailtyp": 347, "json_str": 347, "contract": [1, 8, 347], "putrul": 347, "puttarget": 347, "putev": 347, "crawler": 348, "athena": 348, "warehous": [348, 351, 353], "redshift": [348, 351], "csv": 348, "parquet": 348, "interoper": 348, "queryabl": 348, "jdbc": 348, "sso": [348, 352], "create_": 348, "database_nam": 348, "my_data_lake_raw": 348, "crawler_nam": 348, "raw_s3_crawl": 348, "table_prefix": 348, "raw_": 348, "s3_target_path": 348, "job_nam": [348, 386], "etl_raw_to_cur": 348, "iam_role_arn": 348, "awsglueservicerol": 348, "myrol": 348, "script_loc": 348, "create_databas": 348, "databaseinput": 348, "create_crawl": 348, "databasenam": 348, "s3target": 348, "tableprefix": 348, "start_crawl": 348, "get_crawl": 348, "create_job": 348, "glueetl": 348, "scriptloc": 348, "pythonvers": 348, "gluevers": 348, "defaultargu": 348, "tempdir": 348, "source_db": 348, "source_t": 348, "target_s3": 348, "start_job_run": 348, "jobnam": 348, "run_id": 348, "jobrunid": 348, "jr": 348, "get_job_run": 348, "runid": 348, "predecessorsinclud": 348, "jobrun": 348, "jobrunst": 348, "succeed": 348, "final_statu": 348, "eventbridg": [349, 356], "concurr": [349, 353], "invoc": 349, "handler": 349, "async": [0, 4, 349, 350, 356], "resiz": [349, 373], "housekeep": 349, "function_nam": [349, 356], "role_arn": [349, 356], "byte": [349, 352], "zip_byt": 349, "create_funct": 349, "python3": [89, 115, 127, 131, 132, 134, 135, 136, 137, 138, 139, 141, 143, 144, 145, 146, 151, 160, 201, 209, 230, 240, 349, 389], "zipfil": 349, "memorys": 349, "ada": [1, 349], "invocationtyp": 349, "requestrespons": 349, "dump": [349, 355, 356, 365], "payload_text": 349, "redeploi": 349, "update_function_cod": 349, "delete_funct": 349, "cold": 349, "ingest": [350, 356, 382, 385], "emr": 350, "dags_prefix": 350, "upload_fil": [350, 352], "filenam": 350, "example_pipelin": 350, "create_environ": 350, "airflowvers": 350, "sourcebucketarn": 350, "dags3path": 350, "aaaaaaa": 350, "bbbbbbb": 350, "environmentclass": 350, "mw1": 350, "loggingconfigur": 350, "dagprocessinglog": 350, "loglevel": 350, "schedulerlog": 350, "tasklog": 350, "webserverlog": 350, "workerlog": 350, "wait_until_avail": 350, "get_environ": 350, "webserv": 350, "create_cli_token": 350, "webserverhostnam": 350, "cli_token": 350, "clitoken": 350, "http_post": 350, "aws_mwaa": 350, "bearer": 350, "txt": 350, "bill": 350, "postgresql": [351, 358, 359], "mysql": 351, "mariadb": 351, "aurora": 351, "olap": 351, "durabl": [351, 352, 355, 356, 373], "oltp": [351, 353], "admin": 351, "psql": 351, "orm": 351, "beforehand": 351, "db_subnet_group_nam": 351, "vpc_security_group_id": 351, "db_id": 351, "create_db_inst": 351, "dbinstanceidentifi": 351, "dbinstanceclass": 351, "allocatedstorag": 351, "masterusernam": 351, "masteruserpassword": 351, "dbsubnetgroupnam": 351, "vpcsecuritygroupid": 351, "publiclyaccess": 351, "storageencrypt": 351, "multiaz": 351, "db_instance_avail": 351, "describe_db_inst": 351, "dbinstanc": 351, "create_db_snapshot": 351, "dbsnapshotidentifi": 351, "ongo": 351, "delete_db_inst": 351, "skipfinalsnapshot": 351, "tradit": 352, "filesystem": [352, 358, 359, 373, 374], "ef": 352, "bronz": 352, "silver": 352, "create_bucket": 352, "createbucketconfigur": 352, "locationconstraint": 352, "local_path": 352, "pkl": 352, "list_objects_v2": 352, "download_path": 352, "download_fil": 352, "generate_presigned_url": 352, "clientmethod": 352, "get_object": 352, "expiresin": 352, "3600": [352, 370], "organiz": 353, "unload": 353, "ultra": 353, "analyz": 353, "bi": 353, "kpi": 353, "dbt": 353, "connector": 353, "oauth": 353, "conn": 353, "snowflake_account": 353, "snowflake_us": 353, "snowflake_password": 353, "analyst": 353, "compute_wh": 353, "cursor": [1, 353], "current_vers": 353, "snowflake_vers": 353, "fetchon": 353, "total_revenu": 353, "daily_revenu": 353, "dateadd": 353, "current_d": 353, "BY": 353, "fetchal": 353, "snowpark": 353, "subscrib": 354, "subscript": 354, "order_cr": 354, "model_training_complet": 354, "operation": 354, "create_top": 354, "topic_arn": 354, "topicarn": 354, "queue_arn": 354, "processor": 354, "o_123": [354, 355], "training_complet": 354, "messageattribut": 354, "event_typ": 354, "datatyp": 354, "stringvalu": 354, "fifo": [354, 355], "kb": [354, 355], "pointer": 354, "effort": 355, "dedupl": [4, 355], "enqueu": 355, "waittimesecond": 355, "dead": [3, 355], "letter": [3, 355], "messagegroupid": 355, "dedup": 355, "messagededuplicationid": 355, "create_queu": 355, "queuenam": 355, "visibilitytimeout": 355, "messageretentionperiod": 355, "345600": 355, "redrivepolici": 355, "queue_url": 355, "queueurl": 355, "send_messag": 355, "messagebodi": 355, "receive_messag": 355, "maxnumberofmessag": 355, "receipt": 355, "receipthandl": 355, "handle_order_ev": 355, "delete_messag": 355, "poison": 355, "sendmessagebatch": 355, "receivemessag": 355, "asl": 356, "inputpath": 356, "resultpath": 356, "outputpath": 356, "backoff": [4, 7, 356, 370], "callback": 356, "start_execut": 356, "create_state_machin": 356, "update_state_machin": 356, "stepfunct": 356, "state_machine_nam": 356, "account_id": 356, "step_functions_execution_rol": 356, "lambda_function_arn": 356, "startat": 356, "invokelambda": 356, "errorequ": 356, "intervalsecond": 356, "maxattempt": 356, "backoffr": 356, "state_machine_arn": 356, "statemachinearn": 356, "statemachinealreadyexist": 356, "exec": [356, 358, 359], "execution_arn": 356, "executionarn": 356, "describe_execut": 356, "cidr": 357, "deni": 357, "acl": 357, "internet": [357, 358, 369], "igw": 357, "vpn": 357, "blast": [357, 359], "premis": 357, "create_vpc": 357, "cidrblock": 357, "vpcid": 357, "modify_vpc_attribut": 357, "enablednssupport": 357, "enablednshostnam": 357, "create_subnet": 357, "availabilityzon": 357, "igw_id": 357, "create_internet_gatewai": 357, "internetgatewai": 357, "internetgatewayid": 357, "attach_internet_gatewai": 357, "rt_id": 357, "create_route_t": 357, "routet": 357, "routetableid": 357, "create_rout": 357, "destinationcidrblock": 357, "gatewayid": 357, "associate_route_t": 357, "sg_id": 357, "create_security_group": 357, "groupnam": 357, "groupid": 357, "create_vpc_endpoint": 357, "vpcendpointtyp": 357, "servicenam": [357, 378], "nacl": 357, "daemon": [358, 359], "maco": 358, "dockerd": [358, 359], "dockerfil": 358, "l3": 358, "nginx": [358, 359, 369], "myapp": [358, 359], "myrepo": [358, 359], "bash": [358, 359], "pid": 358, "ut": 358, "ipc": 358, "cgroup": 358, "union": 358, "overlayf": 358, "writabl": [358, 359], "oci": [358, 359], "containerd": 358, "runc": [358, 359], "veth": 358, "ethernet": 358, "cabl": 358, "eth0": 358, "docker0": 358, "172": [136, 358], "iptabl": 358, "masquerad": 358, "dnat": 358, "containerip": 358, "reachabl": [358, 359, 377, 386], "swarm": 358, "127": [138, 184, 240, 310, 358], "pgdata": [358, 359], "postgres_password": [358, 359], "pwd": [358, 359], "slim": [358, 359], "uid": 358, "_default": 358, "database_url": 358, "5432": [358, 378], "depends_on": 358, "postgres_us": 358, "postgres_db": 358, "digest": 358, "dockerignor": 358, "impenetr": 358, "daemonless": 359, "unprivileg": 359, "crun": 359, "socket": 359, "interop": 359, "apppod": 359, "mywork": 359, "slirp4netn": 359, "pasta": 359, "localhost": 359, "networkset": 359, "home": [89, 115, 134, 136, 138, 139, 141, 143, 144, 145, 146, 151, 160, 201, 240, 359], "selinux": 359, "postur": 359, "systemd": 359, "systemctl": 359, "reload": 359, "mount": [365, 373, 376], "log_level": 365, "feature_flag_x": 365, "timeout_m": 365, "envfrom": [365, 370, 374, 376], "configmapref": [365, 374], "volumemount": [365, 373, 376, 378], "mountpath": [365, 373, 376, 378], "midnight": 366, "concurrencypolici": 366, "forbid": 366, "successfuljobshistorylimit": 366, "failedjobshistorylimit": 366, "jobtempl": 366, "backofflimit": [366, 370], "restartpolici": [366, 370], "startingdeadlinesecond": 366, "replicaset": [367, 368], "matchlabel": [367, 375, 378], "rollingupd": 367, "maxsurg": 367, "maxunavail": 367, "readinessprob": [367, 374], "httpget": [367, 374], "statefulset": [367, 368, 374, 377], "horizontalpodautoscal": 368, "scaletargetref": 368, "minreplica": 368, "maxreplica": 368, "averageutil": 368, "read_metr": 368, "cpu_util": 368, "desired_replica": 368, "current_replica": 368, "scale_workload_to": 368, "thrash": 368, "shard": [368, 382, 410], "traefik": 369, "entrypoint": 369, "ingressclassnam": 369, "secretnam": [369, 376], "pathtyp": 369, "certif": 369, "cert": 369, "forev": 370, "ttlsecondsafterfinish": 370, "secretref": [370, 374, 376], "retries_remain": 370, "starv": 370, "agnost": 371, "skeleton": 371, "_exampl": 371, "configmapgener": 371, "parti": 371, "suffix": 371, "grant": 372, "targetport": [372, 377], "storageclass": [372, 373], "crd": 372, "minifi": 372, "reschedul": 373, "csi": [373, 379], "accessmod": [373, 378, 379], "readwriteonc": [373, 378, 379], "storageclassnam": [373, 378, 379], "10gi": [373, 379], "claimnam": 373, "rwo": 373, "readwritemani": 373, "rwx": 373, "reclaim": [373, 379], "trap": [373, 379], "sidecar": 374, "shipper": [374, 381, 382], "100m": 374, "128mi": 374, "500m": 374, "512mi": 374, "initialdelaysecond": 374, "periodsecond": 374, "emptydir": 374, "pvc": [374, 378], "indirectli": 375, "crash": 375, "running_pods_matching_selector": 375, "base64": [2, 376], "stringdata": 376, "opaqu": 376, "db_user": 376, "db_password": 376, "me": [376, 381], "readonli": 376, "administ": 376, "clusterip": [377, 378], "nodeport": 377, "loadbalanc": 377, "headless": [377, 378], "vip": 377, "unreadi": 377, "volumeclaimtempl": 378, "20gi": 378, "pend": 379, "tier": [379, 382], "ssd": 379, "hdd": 379, "pv": 379, "provision": 379, "reclaimpolici": 379, "volumebindingmod": 379, "waitforfirstconsum": 379, "allowvolumeexpans": 379, "persistentvolumeclaim": 379, "investig": 382, "trace_id": [381, 382, 384, 385], "attent": 382, "pars": [381, 382], "keyword": [127, 131, 132, 318, 382], "ilm": [381, 382], "rollov": 382, "stdout": [381, 382, 385], "filebeat": [381, 382, 385], "fluent": [381, 382], "logstash": [381, 382], "kibana": [381, 382, 385], "ndjson": 382, "curl": 382, "xpost": 382, "es": 382, "9200": [382, 385], "_bulk": 382, "_index": 382, "07t20": [381, 382], "11z": [381, 382], "504": [381, 382], "12z": 382, "gte": 382, "15m": 382, "by_statu": 382, "pain": 382, "30d": 382, "90d": 382, "elasticsearch": [381, 383, 384], "loki": 383, "tempo": 383, "shareabl": 383, "promql": 383, "rp": [383, 386], "http_requests_tot": [381, 383, 386], "5m": [383, 384, 386], "histogram_quantil": [383, 386], "http_request_duration_seconds_bucket": [383, 386], "oncal": [383, 384], "datasourc": 383, "9090": 383, "isdefault": 383, "slo": [380, 381, 383, 386, 408], "golden": [381, 383, 386], "pivot": 384, "5xx": [381, 384, 386], "formerli": 384, "4bf92f3577b34da6a3ce929d0e0e4736": [381, 384], "customer_ti": 384, "1m": 384, "brittl": 384, "kueri": 384, "geoip": 385, "pseudocod": [385, 386], "input_stream": 385, "grok": 385, "dissect": 385, "user_ag": 385, "should_drop": 385, "5044": 385, "combinedapachelog": 385, "mmm": 385, "yyyi": 385, "hh": 385, "mm": 385, "add_field": 385, "codec": 385, "rubydebug": 385, "backpressur": [4, 385], "slowdown": 385, "tsdb": 386, "collector": [381, 386], "node_export": 386, "postgres_export": 386, "consul": 386, "alertmanag": [381, 386], "pagerduti": 386, "silenc": 386, "gaug": [6, 386], "http_request_duration_second": [381, 386], "handle_request": [381, 386], "req": [381, 386], "start_tim": [381, 386], "do_work": [381, 386], "inc": [381, 386], "observe_dur": [381, 386], "12034": 386, "scrape_interv": 386, "scrape_config": 386, "static_config": 386, "high5xxrat": 386, "expr": 386, "10m": [381, 386], "request_id": [381, 386], "necessari": 386, "pushgatewai": 386, "irr": 396, "greek": 388, "hedg": 388, "cvar": 395, "vue": [], "svelt": [], "redux": [], "zustand": [], "vital": 399, "wcag": 399, "86": [19, 151, 240], "3129837863524164": 19, "8666666666666667": 19, "29755669561639714": 19, "27348769453997146": 19, "9478571428571428": 19, "14365309037199106": 19, "9333333333333333": 19, "15531360103865552": 19, "14805155593491454": 19, "13017641005047428": 19, "1488189262504534": 19, "14634598848775623": 19, "_c": [20, 146], "0x786441d68290": 20, "cu126": [20, 134, 135, 136, 137, 138, 142, 144, 146], "570": [20, 122], "270": [20, 99, 106, 254, 269], "949535": 20, "457": [20, 134], "063779": 20, "046973": 20, "392": [20, 35, 239], "046404": 20, "322": [20, 135, 137], "038749": 20, "299": [20, 35], "1178": 20, "2782": 20, "750055": 20, "316": [20, 135, 137, 142], "064718": 20, "312": [20, 135, 136, 137, 228], "047928": 20, "152": 20, "046996": 20, "416": 20, "038497": 20, "290": 20, "0882": 20, "2428": 20, "948046": 20, "205258": 20, "078450": 20, "058539": 20, "046161": 20, "924206": 20, "171874": 20, "076581": 20, "070679": 20, "067584": 20, "1347": [21, 22], "0222": 21, "552": 21, "562": 21, "7954": 21, "880": [21, 105], "864": 21, "2587": 21, "769": 21, "3640": 21, "949": [21, 103, 244], "977": [21, 100], "956": [21, 22], "0924": 21, "973": [21, 22, 105], "951": [21, 148], "0610": 21, "991": [21, 176], "0353": 21, "989": [21, 22], "960": [21, 22], "09": [21, 22, 110, 116, 262, 264, 393], "0345": [21, 175], "971": [21, 22], "0274": [21, 136, 190], "84": [21, 289], "1325": [21, 171], "309": [21, 134, 135, 137, 255], "6937": 21, "765": [21, 191, 255, 280], "751": 21, "3111": [21, 245], "841": [21, 120, 148], "813": 21, "0346": 21, "906": 21, "873": [21, 177], "8131": 21, "927": 21, "884": 21, "6370": 21, "944": 21, "911": 21, "5183": 21, "952": 21, "929": 21, "4214": 21, "958": 21, "936": 21, "3520": 21, "964": [21, 22, 100], "940": [21, 146], "2969": 21, "6529": 22, "678": [22, 255], "660": 22, "3443": 22, "941": 22, "953": 22, "1182": 22, "1146": 22, "974": [22, 228], "0602": 22, "988": 22, "969": 22, "0358": 22, "0244": 22, "993": [22, 252], "978": [22, 106], "0231": 22, "996": [22, 52, 90, 176], "0153": [22, 117], "0050": [22, 142], "976": 22, "58": [22, 39, 116], "7513": 22, "731": [22, 74, 94], "693": 22, "7211": 22, "920": 22, "3630": 22, "970": 22, "2235": 22, "967": 22, "1704": [22, 217], "987": 22, "982": [22, 106, 221], "1335": 22, "0961": [22, 107, 159], "984": [22, 221], "0769": 22, "0609": 22, "0495": 22, "105427357601002e": [27, 179], "196": [27, 142, 238], "904": [27, 115], "947": 27, "42278": 27, "283": [27, 65], "38156": 27, "4554": 27, "23052": 27, "3745": 27, "16412": 27, "0213": 27, "4571": 27, "1708": 27, "4122": 27, "0284": 27, "2861": [27, 155, 267], "4723": [27, 200], "2175": [27, 146], "4576": [27, 152], "1825": 27, "6325": 27, "1413": 27, "0827": 27, "344": 27, "966": [27, 96], "0053": 28, "0124": 28, "03431239684685934": 29, "226099e": 29, "194457e": 29, "563523e": 29, "045843": 29, "038304": 29, "990990": 29, "045848": 29, "038141": 29, "990970": 29, "068116": 29, "049934": 29, "986239": 29, "282550": 29, "317378": 29, "9705": 30, "0295": 30, "9954": 30, "0953": 30, "0001": [30, 38, 142, 190, 203, 244, 252], "9427": 30, "0573": 30, "ipykernel_650858": 31, "1100078143": 31, "29867683921252447": 34, "63396899162787": 34, "4575": 34, "92": [34, 78, 145, 202], "9142857142857143": 34, "5375": 34, "9285714285714286": 34, "9071428571428571": 34, "772": 35, "53": [35, 37, 116], "589": [35, 255], "347": 35, "133": [35, 169], "018": [35, 146], "203": [35, 39, 202], "88": [35, 41, 122, 142, 160, 284], "197": [35, 127, 131, 132, 136], "507": 35, "147": [35, 94], "338": [35, 139], "845": 35, "498": [35, 176], "491": 35, "109": [35, 134, 136, 138, 139, 141, 143, 144, 145, 146], "818": 35, "7715416667": 35, "7977777778": 35, "733": [35, 57], "7329897748": 35, "935": [35, 231], "945": 35, "000000": [36, 64, 70, 84, 93, 102, 122, 151, 186, 224, 259], "500000": [36, 93], "666667": [36, 49], "600000": 36, "428571": [36, 64], "6916666666666667": 36, "6068815234220586": 36, "6068815234220585": 36, "4679788743919764": 36, "4679788743919763": 36, "05366666666666667": 36, "054": [36, 280], "053": [36, 148], "32685299468607276": 36, "0044": 36, "0011": 36, "0008": [36, 78, 142], "04463333333333334": 36, "3175857876688931": 36, "000100": 36, "326853": 36, "000464": 36, "002154": 36, "010000": 36, "046416": 36, "215443": [36, 65], "327212": 36, "3272119853443016": 36, "3165096666872798": 36, "6666666666666666": [37, 39, 53, 67, 217], "9900": 37, "0000": [37, 45, 47, 59, 72, 78, 81, 93, 102, 142, 229, 242, 249, 254, 255, 265], "179": [37, 142, 202], "5250": 37, "8367": 37, "1525": 37, "8433333333333334": 37, "8416666666666667": 37, "940625": 37, "525": 37, "88125": 37, "8866666666666667": 37, "7375": 37, "8366666666666667": 37, "7233333333333334": 37, "834375": 37, "8333333333333334": 37, "5483333333333333": 37, "8183333333333334": 37, "2087": 38, "1651": 38, "734": [38, 75, 269], "1763": 38, "0703": 38, "2477": 38, "1775": 38, "1879": 38, "0110": 38, "0691": [38, 207], "1896": 38, "1880": 38, "0687": 38, "3392506425102862": 38, "3285352441601213": 38, "3431820394131602": 38, "0208": 38, "0200": 38, "3333333333333333": [39, 67, 210, 217], "46": [39, 51, 142, 201, 206, 310], "212": [39, 142], "9269406392694064": 39, "9592760180995475": 39, "76154236428209": 39, "07616093736538296": 39, "218": [39, 94], "145": [39, 244], "76": [39, 110, 171], "9954337899543378": 39, "3438914027149321": 39, "5171783971028183": 39, "01327805815909637": 39, "115": [39, 50], "219": 39, "5251141552511416": 39, "9909502262443439": 39, "02511415525114": 39, "4792227017785283": 39, "144": 39, "717": 39, "008": [39, 159], "866": [39, 175], "051": [39, 269], "044393708777271": 39, "10936410464043908": 39, "006566010065659933": 41, "02898015572377166": 41, "05021724810620465": 41, "050217248106204426": 41, "390": 41, "672": 41, "767": [41, 57], "879": 41, "764": 41, "926": 41, "5161290322580645": 41, "35000000000000003": 41, "6727748691099477": 41, "381": [41, 138], "69": [41, 136, 139], "332926": 45, "331711": 45, "2450": 45, "5236": 45, "7584": 45, "0648": 45, "5545": 45, "6785": 45, "1888": 45, "0410": 45, "8358": 45, "0385": [45, 223], "8459": 45, "9737837898808718": 46, "4054570626616003": 46, "3819229190361464": 46, "258491560577216": 46, "12075603565990804": 46, "07421418195747594": 46, "8206929808323062": 46, "8897282386094872": 46, "06472355069849435": 46, "9038299722408762": 46, "140995184095699": 47, "765286603584786": 47, "9999999999999998": [47, 241], "6673140760825534": 47, "8928": 47, "6309": 47, "1410": 47, "6967": 47, "000000000000": [47, 223, 229, 235], "726341544169852": 47, "33609233877721406": 47, "8092268103302992": 47, "8086706878351096": 47, "517782560805999": 47, "14902422012004707": 47, "6732590227960631": 47, "5539906103286385": 49, "335908": 49, "336667": 49, "336466": 49, "8973": 49, "1027": 49, "3621": 49, "0781": [49, 104], "8771": 49, "34500000000000003": 49, "9702970297029703": 49, "44": [49, 75, 99, 132, 142, 158, 201, 231, 241, 261, 310], "448": 49, "7884615384615384": 49, "8817204301075269": 49, "9791666666666666": 49, "9038461538461539": 49, "47": [49, 110, 142, 201], "447": [49, 254], "4875": 49, "4175": 49, "2575": 49, "6667": [49, 53, 95, 228], "638889": 49, "667": [50, 228, 255], "6266666666666667": 50, "5333333333333333": 50, "11625": 50, "6936": 50, "3378": 50, "2818": 50, "2603": 50, "249": [50, 116, 269], "1120": 50, "2243": 50, "1140": 50, "1160": 50, "1180": 50, "1199": 50, "3058": 50, "3105": 50, "3151": 50, "3197": 50, "3242": [50, 104], "5800": 50, "5850": 50, "5005": 50, "5900": 50, "5950": 50, "5015": 50, "5999": [50, 193], "502": [50, 174], "188": 51, "333": [51, 146, 252, 389], "222": [51, 94], "528672497390485": 51, "1437": 51, "1420": 51, "14201388888888886": 51, "13819444444444445": 51, "30000000000000004": 52, "5771675247777874": 52, "12760727393472507": 52, "012641047919911632": 52, "42857142857142855": 53, "7916666666666666": 53, "7222222222222222": 53, "5555555555555555": 53, "3333": [53, 191, 228], "10285714285714286": 53, "09333333333333334": 53, "6206896551724138": 53, "7666666666666667": 53, "2857142857142857": [53, 152], "22839300363692283": 56, "6864438223668599": 56, "6931471805599453": 56, "33238400682532043": 56, "3323840068253205": 56, "33238400682532054": 56, "45572277119982485": 56, "4442069329282946": 56, "4666666666666667": 57, "759901798558076": 57, "ipykernel_653561": 57, "325970358": 57, "2526279986": 57, "305": [57, 162], "578": 57, "931": [57, 89], "706": 57, "567": 57, "934": [57, 217], "607": [57, 209], "921": 57, "609": [57, 209], "5667784612933667": 57, "chadfbeg": 59, "acbfehdg": 59, "2915": 59, "5954": 59, "8421": 59, "8269": 59, "477778": 59, "371429": 59, "06e": [59, 136], "463501": 59, "357834": 59, "487567": 59, "378214": 59, "09e": 59, "495100": 59, "391870": 59, "03e": 59, "801454": 59, "736041": 59, "54e": 59, "9360": 59, "9669": 59, "9579": 59, "9159": 59, "4260": 59, "9687": 59, "7920": 59, "9810": 59, "5714285714285714": 64, "142857": 64, "285714": 64, "571429": [64, 224, 225], "714286": [64, 174, 240], "857143": 64, "6571428571428571": 64, "4551141695339381": 64, "171": [64, 200, 239], "8279306666666666": 64, "6333778374447112": 64, "2010312536095087": 64, "7989558370421088": 64, "5415525504964054": 64, "9139835858585859": 64, "9127604166666666": 64, "186": [65, 136], "251": [65, 280], "744": 65, "79928": 65, "226": 65, "8933": 65, "6374": 65, "0462": 65, "5134": 65, "165": [65, 218], "9231": 65, "33333333333333337": 67, "6666666666666667": [67, 196, 210, 215, 240], "6392579150890872": 67, "11434965799864971": 67, "2840": 67, "4675": 67, "6995": 67, "2800": 67, "6984": 67, "1358": 67, "2457": [67, 209], "2074": 67, "16502260912888653": 69, "12559873432804056": 69, "9249381865602224": 69, "7333333333333333": 70, "318182": 70, "733333": 70, "24498": 70, "33525": 70, "33538": 70, "101025": 70, "5606692408470919": 70, "1620852830713": 70, "291": 70, "49398337816893": 70, "8667985639192363": 70, "253": [70, 269], "34081970634463": 70, "7233392630713212": 70, "215": 70, "61620906403215": 70, "5838640527190261": 70, "189": 70, "80284588981752": 70, "8262": 72, "9049": 72, "9594": 72, "5589": 72, "7063": 72, "511": 73, "10262206779885": 73, "9981481481481481": 73, "38664615200057156": 74, "3866461520005713": 74, "7755575615628914e": [74, 158, 172], "361322636978866": 74, "3978227444815982": 74, "3866099752111638": 74, "183769": 74, "285507": 74, "292989": 74, "162616": 74, "564168": 74, "386764": 74, "746407": 74, "345365": 74, "776640": 74, "098401": 74, "782764": 74, "474743": 74, "907931": 74, "673546": 74, "390869": 74, "635738": 74, "770866": 74, "776498": 74, "890938": 74, "950224": 74, "968447": 74, "538": [75, 142], "syntaxerror": [75, 153, 217, 261, 270], "untermin": [75, 153, 261, 270], "33": [75, 107, 122, 134, 135, 142, 201, 225, 240, 261, 299], "43": [75, 142, 162, 201, 232, 261, 289, 310], "007663540181941153": 77, "007663540181940872": 77, "8102520310824275e": 77, "6704302058675669": 77, "003990": 78, "64e": 78, "004427": 78, "85e": 78, "079174": 78, "94e": [78, 136, 165], "0986": [78, 102, 181], "4862": 78, "6346": 78, "0995": 78, "1196": 78, "3175": 78, "2191": 78, "954": 78, "914": [78, 200], "442": 78, "2973": 78, "3048": [78, 99], "0034": [78, 194], "7857142857142857": 81, "2462": 81, "7538": 81, "5004736300915591": 83, "528": [83, 122], "809": 83, "821": 83, "7382865700820038": 83, "7380559615275238": 83, "760188": 84, "005959": 84, "7647058823529411": 86, "016801157504288795": 86, "01921790647673083": 86, "7787010392304238": 86, "33910291099295586": 86, "5645274708659884": 86, "5574020784608475": 86, "4731975975371019": 86, "4452618667501379": 86, "3068": 86, "2318": 86, "2531": 86, "2574517183454593": 86, "1399640289860704": 86, "3731633735620893": 86, "8653": 86, "5073": 86, "0334": [86, 269], "5742": 86, "44939361486933627": 86, "412878104406565": 87, "4261650061141289": 87, "0455": 87, "7727": 87, "5638604228888011": 87, "1124": [87, 174], "1877": [87, 259], "2139": [87, 209], "17130461752532478": 87, "0198": [87, 155, 249], "2158": 87, "26390620369117923": 87, "1955308060885197": 87, "35437222526113604": 87, "5755556075140252": 87, "9090909090909091": 87, "5795454545454546": 87, "245096850405492": 87, "36342747394411146": 87, "2703": 87, "271546583795644": 87, "000e": [88, 98, 172, 186], "5782287829762082": 88, "5782287833631345": 88, "8944126033656888": 89, "8944094638062047": 89, "05654500849911091": 89, "0012966387524886791": 89, "05654332722705647": 89, "9778046284015942": 89, "0591382860040883": 89, "0012966387524886": 89, "53551208789518": 89, "552713678800501e": [89, 150, 151, 178], "6971716305768838": 89, "7011039492575686": 89, "9109617275936569": 89, "04588904212295869": 89, "9088559234066942": 89, "473680853439166": 89, "47366507095168253": 89, "2818587167868259": 89, "0029071829705829798": 89, "28185026507400146": 89, "tempa": [89, 115, 134, 136, 138, 139, 141, 143, 144, 145, 146, 151, 160, 201, 240], "miniconda3": [89, 115, 127, 131, 132, 134, 135, 136, 137, 138, 139, 141, 143, 144, 145, 146, 151, 160, 201, 209, 230, 240, 389], "_regress": 89, "930": 89, "1705": 89, "11973865514890675": 89, "169799844269795": 89, "8436035954505202": 89, "9504664689590617": 89, "4944": 89, "6951145770136242": 89, "917476198469688e": 89, "6951145770146998": 89, "22740982130503978": 89, "9646517961590391": 89, "732659123073972e": 89, "2563190118563668": 89, "9652494187042723": 89, "9662444560416645": 89, "0856700581900787": 89, "1008232505127644": 89, "5180131987928035": 89, "6951145770147": 89, "4201735699636053": 89, "5363082167501443": 89, "9662444560416775": 89, "780784635203714": 89, "2563190118560888": 89, "9652494187043099": 89, "08567005818901435": 89, "6951145770147051": 89, "9662444560416782": 89, "9652494187043107": 89, "2563190118560831": 89, "382": 90, "016": [90, 94], "34697546337952": 90, "9970499860377036": 90, "7826401886556796": 90, "4007587709322311": 90, "424859636373611": 90, "8094854370763436": 90, "9269440646911562": 90, "317537398451267": 90, "397525580220899": 90, "45912538286567": 90, "14334962923664443": 91, "06675038086235976": 91, "07859386281040903": 91, "1673": 91, "1563": [91, 134], "1535": 91, "131": 91, "118": [91, 136, 240, 246], "054298341287004614": 91, "991047304742386": 91, "5939862944862195": 91, "034722899043242": 91, "9884324902995665": 91, "556270780903915": 91, "0142419496584196": 91, "001810613820674": 91, "8120687855249078": 91, "118168492697624": 91, "9732338388900619": 91, "1155": 91, "1505": 91, "1875": 91, "6525": 91, "021217652798245": 91, "189188988502492": 92, "65270765": 92, "3344239": 92, "11974124": 92, "490739317496624": 92, "796215955793969": 92, "021166597032021": 92, "3234497534673614": 92, "139": 92, "99874478140572": 92, "45111": 92, "330009565856": 92, "369710958357132": 92, "5535421606512725": 92, "28248252581867633": 92, "162": 92, "72868717407727": 92, "75607": 92, "15743363052": 92, "3169360284034368": 92, "693602840343686": 92, "nbsp": 93, "100000": [93, 141], "8052": 93, "3863": 93, "6137": 93, "3948": 93, "styler": 93, "0x796358e94da0": 93, "0568528194400546": 93, "378436722535223": 93, "3822041665484144": 93, "477e": 93, "719e": 93, "883e": 93, "181e": 93, "660e": 93, "342e": 93, "026e": 93, "787e": 93, "520e": 93, "491e": 93, "188e": 93, "543e": [93, 172], "860e": 93, "309e": 93, "947e": 93, "803e": 93, "875e": 93, "567e": 93, "893e": 93, "937e": 93, "989e": 93, "03858702982088678": 93, "3581594109476653": 93, "632742976010974": 93, "03697952466385566": 93, "2560484806999526": 93, "10897917526945": 93, "2218": [93, 263], "8851": 93, "5517": 93, "16124082232077153": 93, "18385887160506967": 93, "18385841689188462": 93, "0333": 94, "1667": 94, "00e": [94, 235], "1162": 94, "1234": 94, "7306963005697273": 94, "22191021030730798": 94, "0163591712333595": 94, "8064745345330414": 94, "259015414769386": 94, "3579550011540444": 94, "743": 94, "806": 94, "842": [94, 108, 181], "259": 94, "594": 94, "2667": 94, "2666": 94, "5943": [94, 191], "5942": 94, "2589": 94, "2564": 94, "606757123122003": 95, "4106910529758423": 95, "1111": [95, 209], "0952": 95, "3078": 95, "6558": 95, "9821": 95, "5725": 96, "475": [96, 122], "6438": 96, "9581": 96, "9788": 96, "9059": 96, "03973012298459379": 97, "19932416558108": 97, "0611": 97, "0547": 97, "058": 97, "0384": [97, 152], "0793": 97, "0236": 97, "0056": 97, "0618": 97, "0478": 97, "7382724858458961": 97, "9098627244134785": 97, "7381944920965867": 97, "9098824642871552": 97, "8020": 97, "024141455282": 97, "3214": 97, "396742264166": 97, "0271819896986292": 97, "128488167880701": 97, "12848816788070097": 97, "4260151319598084": 98, "7781745930520232": 98, "6875": 98, "12753010019949473": 98, "192": [98, 136, 177], "783": [98, 254], "7361": 98, "19246904943966447": 98, "7827": 98, "7361175245303142": 98, "7361175244957865": 98, "726479852543726": 99, "22811342804441603": 99, "3299": 99, "3327": [99, 117], "3263042693906659": 99, "012": 99, "3255882359758968": 99, "2562381006417402": 99, "206246485594046": 99, "23791194121513426": 99, "198741198055658": 99, "212982820690415": 99, "403": 100, "6001913242214": 100, "1614": 100, "0415": [100, 194], "5628": 100, "1093": 100, "626": [100, 135, 137], "266": [100, 134, 240], "129": 100, "547e": 100, "8817": 100, "8907791234783493": 100, "7509": 100, "7757": 100, "7692": 100, "7652668866547568": 100, "764809940184828": 100, "9932": 100, "4779": 100, "9430322406480296": 100, "288": [101, 208], "1349008767288886": 101, "45323041": 101, "53601038": 101, "40367295": 101, "4660120349767279": 101, "846541": 101, "591784": 101, "749457": 101, "674895": 101, "591783": 101, "674896": 101, "13490088": 101, "22890107": 101, "955401025072826": 101, "2794530081249567": 101, "095310": 102, "693147": 102, "397895": 102, "615121": 102, "6931": 102, "3979": 102, "6151": 102, "1972": [102, 181], "7958": 102, "4055": 102, "1807": 102, "05932808530023383": 102, "24357357266385413": 102, "5038": 102, "1603": 102, "9536": 102, "2174": 102, "2333": 102, "2297": 102, "23046738688656432": 102, "4927333701234642": 102, "34749067593865945": 102, "24267736906455": 102, "56476300415895": 102, "3474906789145831": 102, "351898734177215": 103, "16683544303797468": 103, "6056786127882988": 103, "055": [103, 110], "687509884300587": 103, "77": [103, 153, 207, 257], "9666666666666667": [104, 106], "8208": 104, "0538": 104, "6087": 104, "3772": [104, 200], "4849": 104, "3797": 104, "2432": 104, "2419": 104, "2458": [104, 209], "1576": 104, "1594": 104, "2339": 104, "1522": 104, "8925925925925926": 104, "028": [105, 142], "173": [105, 136], "205": 105, "208": [105, 280], "211": [105, 134, 136], "9466666666666667": 105, "9314285714285715": 105, "9533333333333334": 105, "9814814814814815": 106, "985": 106, "981": 106, "135": 106, "5896": 106, "4104": 106, "996017195166255": 107, "9971905099769254": 107, "225": [107, 136, 139, 230], "5167": 107, "2547": 107, "8184": 107, "674": [107, 190, 244], "221855599191807": 107, "5613497744532487": 107, "5167030598770732": 107, "2206829487952962": 107, "5617707598473143": 107, "5172826696255273": 107, "2349": 107, "7957": 107, "6741": 107, "2137240283725328": 107, "564269035433256": 107, "5220139241124422": 107, "073": 107, "6111": 107, "6742": 107, "2517741006491223": 107, "5506089328833015": 107, "5458280302704095": 107, "2685": 107, "7048": 107, "6596": 107, "220446049250313e": [107, 153, 154, 163, 183, 201, 202, 206, 212, 216, 230, 258], "2158339344013227": 107, "5635115721487047": 107, "023": 107, "5535": 107, "6674": [107, 243], "27909288052184": 107, "5408014000121864": 107, "494": 107, "6406": 107, "3964369179099974": 107, "4986745001551752": 107, "6242": 107, "5845": 107, "5759458587189812": 107, "4342301931310043": 107, "4975": 107, "4452": 107, "2218555991918068": 107, "2137240283725332": 107, "5642690354332558": 107, "3964372563318266": 107, "4986743786606125": 107, "365775969037568": 107, "5096818828174675": 107, "2112856232633256": 107, "5651444309806803": 107, "050": [108, 242], "825": 108, "9916666666666667": 108, "451": 108, "9011": 108, "0989": 108, "1622": 108, "178": [108, 136, 165], "7166666666666667": 108, "01262595102773109": 109, "9779801440241067": 109, "3957878668246275": 110, "0788": 110, "4589": 110, "911504424778761": 110, "230": 110, "476": [110, 260], "352": 110, "479": [110, 228], "378": 110, "536": 110, "537": [110, 228], "757": 110, "07297656765298927": 110, "06900414442614336": 110, "8938053097345132": 110, "9203539823008849": 110, "9287833827893175": 110, "631": 112, "488j": 112, "matmul": 112, "operand": 112, "gufunc": 112, "0625": [113, 193], "4082456807214128": 113, "7170998763678297": 113, "05216475228517619": 114, "9387": 114, "0124577283931864": 114, "8422": 114, "4018": 114, "0152504473095068": 114, "100584": 115, "138668": 115, "117924": 115, "949499": 115, "206905": 115, "284578": 115, "113908": 115, "170669": 115, "379175": 115, "167341": 115, "788166": 115, "901": 115, "735823": 115, "220774": 115, "484951": 115, "902": [115, 265], "761379": 115, "274206": 115, "487173": 115, "903": 115, "964227": 115, "327639": 115, "636588": 115, "_json": 115, "558": 115, "nanosecond": 115, "888172": 116, "57": [116, 118, 289], "909024": 116, "006114": 116, "476490": 116, "720164": 116, "2019": 116, "911005": 116, "239645": 116, "273459": 116, "970637": 116, "234690": 116, "116": [116, 289], "042": 116, "sat": [116, 122], "jan": [116, 122], "244": [116, 145], "084": 116, "257": [116, 138, 269], "488": 116, "hqic": [116, 122], "402": 116, "opg": [116, 122], "0532": 117, "0974": 117, "9693": 117, "1923": 117, "6448": 117, "4924": 117, "062": [117, 136, 220], "0421": 117, "0675": 117, "4556": 117, "8706": 117, "4152628017403557": 118, "0926": 118, "3248j": 118, "3683": 118, "1919j": 118, "2392": 118, "1381j": 118, "196020": 118, "288455": 118, "672731": 118, "200209": 118, "739549": 118, "524796": 118, "320734": 118, "348595": 118, "525616": 118, "008172": 118, "622605": 118, "386434": 118, "921646": 118, "184484": 118, "343241": 118, "059707": 118, "130046": 118, "799": [118, 209], "004962": 118, "118251": 118, "798": [118, 209], "005384": 118, "181576": 118, "797": [118, 209], "008751": 118, "238028": 118, "017841": 118, "300307": 118, "795": 118, "039101": 118, "374861": 118, "794": 118, "4896672335687779": 118, "824": [119, 136, 146, 148], "23e": 119, "OF": [119, 224], "factr": [119, 224], "epsmch": [119, 224], "19534310083057616": 119, "5284": 119, "1357": 119, "523": 119, "9380685254836366": 119, "003120780574746758": 120, "7024190892644842": 120, "significanceresult": [120, 124, 127, 131, 132], "20620374582574355": 120, "9020350758599663": 120, "949314": 122, "312201": 122, "000185": 122, "714617": 122, "044978": 122, "394950": 122, "999359": 122, "280054": 122, "865835": 122, "6851935314621316": 122, "7018128229455727": 122, "370597378351971": 122, "4392971938785968": 122, "156": [122, 136, 155], "276": [122, 211], "565": 122, "229": [122, 142], "583": 122, "572": 122, "661": 122, "2550": 122, "754": 122, "863": 122, "897": 122, "613": 122, "3388": 122, "462": [122, 209], "409": [122, 244], "269": 122, "3796": 122, "666": 122, "577": [122, 255], "685": 122, "074": 122, "5277": 122, "067": 122, "872": 122, "396": [122, 134, 135, 137, 221], "659": 122, "2335": 122, "107": [122, 252, 289], "183": [122, 193], "029": 122, "024": [122, 146], "443": [122, 142], "0176": 122, "829": 122, "466": [122, 223], "jb": 122, "338761": 122, "379605": 122, "76806591": 122, "28392131": 122, "13479592": 122, "51265418": 122, "20647124": 122, "6113110846360617": 122, "648": 123, "0881": [123, 155], "0713": [123, 175], "4179": 123, "0591": 123, "2066": 123, "7877": 123, "2877": 123, "6314": 123, "3512": 124, "158801683041921e": 124, "8543250028588507": 124, "5576490029991557": 124, "7566726864848627": 124, "340": 125, "285": [125, 142], "434": [125, 176], "_param_valid": [127, 131, 132], "194": [127, 131, 132, 184, 221], "validate_param": [127, 131, 132], "decor": [127, 131, 132], "191": [127, 131, 132], "func_sig": [127, 131, 132], "193": [127, 131, 132, 214, 234], "195": [127, 131, 132, 240, 269], "apply_default": [127, 131, 132], "3277": [127, 131, 132, 176], "3272": [127, 131, 132], "3273": [127, 131, 132], "boundargu": [127, 131, 132], "3274": [127, 131, 132], "3275": [127, 131, 132], "3276": [127, 131, 132], "_bind": [127, 131, 132], "3266": [127, 131, 132], "3256": [127, 131, 132], "3257": [127, 131, 132], "3258": [127, 131, 132], "3263": [127, 131, 132, 252], "3264": [127, 131, 132], "3265": [127, 131, 132], "3267": [127, 131, 132], "3268": [127, 131, 132], "3270": [127, 131, 132], "_bound_arguments_cl": [127, 131, 132], "022139488149232": 127, "7655684826389506": 127, "147517772919136": 127, "3417216075363839": 127, "0957017770743134": 129, "589710861221658": 129, "506010971830327": 129, "41093602627152837": 131, "7574081863879396": 131, "633108641106042": 131, "1625850026815621": 131, "24839058285380267": 132, "4313360450269337": 132, "9226931240248826": 132, "14066887396930364": 132, "174": [134, 136, 138, 139, 141, 143, 144, 145], "incorrectli": [134, 136, 138, 139, 141, 143, 144, 145, 146], "cuda_visible_devic": [134, 136, 138, 139, 141, 143, 144, 145, 146], "c10": [134, 136, 138, 139, 141, 143, 144, 145, 146], "cudafunct": [134, 136, 138, 139, 141, 143, 144, 145, 146], "cpp": [134, 136, 138, 139, 141, 143, 144, 145, 146], "4189": 134, "6692": 134, "0s": [134, 136, 138, 141, 145], "82": [134, 146, 207, 223], "6804": 134, "146": 134, "0746": 134, "5s": [134, 138, 141, 145], "9465": 134, "3818": 134, "10000": [134, 145], "7835": 134, "343": 134, "4184": 134, "14000": 134, "371": 134, "3684": 134, "16000": 134, "71": [134, 138, 235], "0661": 134, "18000": 134, "431": 134, "2570": 134, "0435": 134, "7s": [134, 136, 141, 145], "22000": 134, "487": 134, "0582": 134, "24000": 134, "514": 134, "26000": 134, "551": 134, "28000": 134, "574": [134, 252], "63": [134, 146, 178, 179, 240], "1548": 134, "30000": 134, "1326": 134, "746": 134, "29840": 134, "141999": 134, "279103": 134, "612243": 134, "273748": 134, "747": 134, "29880": 134, "164299": 134, "443412": 134, "641806": 134, "466463": 134, "748": 134, "29920": 134, "135936": 134, "744340": 134, "590112": 134, "532006": 134, "749": 134, "29960": 134, "104616": 134, "020100": 134, "607867": 134, "825297": 134, "107253": 134, "492551": 134, "637384": 134, "567428": 134, "474": 134, "319": [134, 135, 137], "245": [134, 136], "374": 134, "419": 134, "354": 134, "247": [134, 145], "292": 134, "85440826416016": 134, "graph_obj": [135, 137], "_figur": [135, 137], "24196": [135, 137], "arrowcolor": [135, 137], "arrowsid": [135, 137], "arrowwidth": [135, 137], "borderpad": [135, 137], "captureev": [135, 137], "clicktoshow": [135, 137], "hoverlabel": [135, 137], "standoff": [135, 137], "startarrowhead": [135, 137], "startarrows": [135, 137], "startstandoff": [135, 137], "templateitemnam": [135, 137], "textangl": [135, 137], "valign": [135, 137], "xclick": [135, 137], "xshift": [135, 137], "yclick": [135, 137], "exclude_empty_subplot": [135, 137], "23891": [135, 137], "23892": [135, 137], "23893": [135, 137], "24192": [135, 137], "24193": [135, 137], "24194": [135, 137], "_layout": [135, 137], "new_obj": [135, 137], "24197": [135, 137], "24198": [135, 137], "24199": [135, 137], "24200": [135, 137], "24201": [135, 137], "24202": [135, 137], "24203": [135, 137], "24204": [135, 137], "24205": [135, 137], "24206": [135, 137], "24207": [135, 137], "24208": [135, 137], "24209": [135, 137], "24210": [135, 137], "24211": [135, 137], "24212": [135, 137], "24213": [135, 137], "24214": [135, 137], "24215": [135, 137], "24216": [135, 137], "24217": [135, 137], "24218": [135, 137], "24219": [135, 137], "24220": [135, 137], "24221": [135, 137], "24222": [135, 137], "24223": [135, 137], "24224": [135, 137], "24225": [135, 137], "24226": [135, 137], "24227": [135, 137], "24228": [135, 137], "24229": [135, 137], "24230": [135, 137], "24231": [135, 137], "24232": [135, 137], "24233": [135, 137], "24234": [135, 137], "24235": [135, 137], "24236": [135, 137], "24237": [135, 137], "24238": [135, 137], "24239": [135, 137], "24240": [135, 137], "24241": [135, 137], "24242": [135, 137], "24243": [135, 137], "_add_annotation_lik": [135, 137], "24244": [135, 137], "24245": [135, 137], "24250": [135, 137], "24251": [135, 137], "_annot": [135, 137], "1680": [135, 137], "1678": [135, 137], "_set_properti": [135, 137], "1679": [135, 137], "1681": [135, 137], "1682": [135, 137], "basedatatyp": [135, 137], "4403": [135, 137], "baseplotlytyp": [135, 137], "4397": [135, 137], "4398": [135, 137], "4399": [135, 137], "4400": [135, 137], "4401": [135, 137], "4402": [135, 137], "_set_property_provided_valu": [135, 137], "398": [135, 137], "397": [135, 137], "4932": [135, 137], "__setitem__": [135, 137], "4928": [135, 137], "_set_array_prop": [135, 137], "4930": [135, 137], "4931": [135, 137], "_set_prop": [135, 137], "4933": [135, 137], "4934": [135, 137], "4935": [135, 137], "_init_prop": [135, 137], "5276": [135, 137], "5274": [135, 137], "5275": [135, 137], "5278": [135, 137], "5279": [135, 137, 222], "5280": [135, 137], "5281": [135, 137], "5271": [135, 137], "5268": [135, 137], "_get_valid": [135, 137], "5270": [135, 137], "validate_coerc": [135, 137], "5272": [135, 137], "5273": [135, 137, 176], "_skip_invalid": [135, 137], "_plotly_util": [135, 137], "basevalid": [135, 137], "enumeratedvalid": [135, 137], "623": [135, 137, 226], "perform_replacemenet": [135, 137], "624": [135, 137], "in_valu": [135, 137], "raise_invalid_v": [135, 137], "313": [135, 137], "314": [135, 137], "typ": [2, 135, 137], "pname": [135, 137], "315": [135, 137, 221], "317": [135, 137], "valid_clr_desc": [135, 137], "parent_nam": [135, 137], "type_str": [135, 137], "323": [135, 137], "324": [135, 137], "builtin": [135, 137], "40000": 136, "0061": 136, "0359": 136, "0197": 136, "4610": 136, "4545": 136, "40e": 136, "6s": 136, "59e": 136, "066": [136, 244], "87": [136, 257, 289], "209": [136, 200], "044": [136, 146], "60e": 136, "036": [136, 185], "47e": 136, "030": [136, 252], "159": [136, 142], "95e": 136, "87e": 136, "040": [136, 184], "216": [136, 221], "78e": 136, "019": [136, 146], "28e": 136, "049": [136, 142, 244], "04e": 136, "063": 136, "273": 136, "05e": 136, "048": [136, 252], "865": 138, "836": 138, "7001": 138, "802": 139, "612": 139, "3917": [139, 181], "465": 139, "5403": 139, "6690": 139, "7833": 139, "74": [139, 175, 227], "8792": 139, "dict_kei": [139, 141], "9600000102072954": 140, "2068": 140, "8834500104933977": 140, "322598197569875": 140, "955": [140, 265], "971886157989502": 140, "5999999865889549": 140, "3750": 141, "6250": 141, "7500": 141, "20480": 142, "0002": [142, 265], "0020": 142, "0003": [142, 255], "105": [142, 181, 221, 241], "142": 142, "0006": [142, 175], "0005": [142, 193], "242": 142, "268": 142, "0067": 142, "0029": [142, 220], "336": 142, "353": 142, "367": 142, "387": 142, "0119": 142, "406": 142, "089": 142, "0049": [142, 146, 269], "424": [142, 214], "006": [142, 159, 394], "0045": 142, "459": [142, 209], "478": 142, "021": 142, "0051": 142, "495": 142, "0019": 142, "510": 142, "0024": [142, 186, 193], "521": 142, "0060": 142, "556": 142, "0015": 142, "566": 142, "0062": 142, "586": 142, "595": 142, "0004": [142, 178], "606": [142, 151, 209], "0068": [142, 146], "621": 142, "095": 142, "646": 142, "657": 142, "0036": 142, "003087": 142, "048697": 142, "692916": 142, "000009": 142, "001868": 142, "419497": 142, "691513": 142, "000157": 142, "1536": 142, "004179": 142, "124797": 142, "688415": 142, "002013": 142, "001415": 142, "220530": 142, "686069": 142, "000294": 142, "2560": 142, "001063": 142, "217341": 142, "683129": 142, "000024": 142, "syntaxwarn": 143, "escap": 143, "ipykernel_2186937": 143, "206611049": 143, "726": 143, "237": [144, 280], "88667494160109": 144, "1301": [145, 174], "1504": 145, "1295": 145, "1086": 145, "817": [145, 202], "1039": 145, "526": [145, 280], "7000": 145, "9000": 145, "106": [145, 257], "34952581981875": 145, "0x75de937b1190": 146, "206": 146, "57660868987693": 146, "ipykernel_1016759": 146, "1044679479": 146, "deprecationwarn": [146, 153, 181, 189], "deprec": [146, 153, 181, 189], "1083": 146, "0086": 146, "004": 146, "0092": [146, 165], "948": [146, 197], "009": 146, "117": [146, 225, 243], "0070": 146, "014": 146, "640": 146, "2436": 146, "0089": 146, "1728113403610725": 148, "83321": 148, "30422": 148, "25150": 148, "584": 148, "803": 148, "602": 148, "497": 148, "16423": 148, "937": 148, "8385771543086173": 148, "836523437500002": 148, "kstestresult": [148, 152, 158, 167, 168, 174, 188, 198, 203, 215, 220], "005519999999999969": 148, "42984315222942004": 148, "statistic_loc": [148, 152, 158, 167, 168, 174, 188, 198, 203, 215, 220], "0048665241757195": 148, "statistic_sign": [148, 152, 158, 167, 168, 174, 188, 198, 203, 215, 220], "63292": 148, "2476": 148, "00323": 148, "51164": 148, "86093": 148, "98651": 148, "60403": 148, "28935": 148, "38106": 148, "65239": 148, "43316": 148, "5148437500000016": 148, "018166844743858906": 148, "5181148318909714": 148, "7925531914893618": 148, "8381684906603133": 148, "219827793554541": 148, "191825495643975": 148, "34695": 148, "03256416532": 148, "11685027506808487": 149, "8062497699541868": 149, "8062497699541786": 149, "3068528194400547": 149, "3929984748491564e": 149, "1168502750644443": 149, "0017822315715813274": 149, "11693584576419093": 149, "002866540728205996": 149, "9999568082303634": 149, "9998657111910878": 149, "1102230246251565e": [149, 155, 156, 161, 162, 164, 171, 173, 177, 178, 179, 197, 203, 206, 211, 237, 240], "2007715567009445": 149, "7011704429753689": 149, "03853867853294057": 149, "4262948207171315": 149, "000001": 150, "310045": 150, "735105": 150, "63662": [150, 202], "4999078439779247": 150, "12498062340322307": 150, "2415644752704905": 150, "35102": 150, "333278": 150, "957626": 150, "620713": 150, "864426": 150, "331615": 150, "148247": 150, "814071": 150, "448362": 150, "69346": 150, "5012310506354244": 150, "12544470668500474": 150, "425294": 150, "712055": 150, "864634": 150, "234072": 150, "38168": 150, "638791": 150, "463073": 150, "730777": 150, "226557": 150, "552068": 150, "0000041654452665": 150, "00059414578592": 150, "02575": 150, "009764424160149908": 150, "16666666666666666": [150, 202, 236], "04413134197515587": 150, "348577710858454": 150, "08146666666666667": 150, "0201": 150, "07906666666666666": 150, "020866666666666665": 150, "318309": 150, "886184": 150, "318313": 150, "407023": 150, "670781": 150, "451583": 150, "670792": 150, "7763568394002505e": [151, 170, 222], "590227": 151, "053005": 151, "2966": [151, 249], "7982": [151, 221], "596428": 151, "052891": 151, "3230": 151, "7800": 151, "618703": 151, "052157": 151, "4204": 151, "6939": 151, "762779": 151, "035555": 151, "1882": 151, "0606": [151, 181], "956717": 151, "001359": 151, "8768": 151, "8944": [151, 246], "123343": 151, "123745": 151, "224313": 151, "216045": 151, "000000j": 151, "252645": 151, "292744j": 151, "253406": 151, "133822": 151, "107030j": 151, "133083": 151, "48713485149744684": 151, "_quadpack_pi": [151, 209], "complexwarn": 151, "7106": 151, "7862": 151, "9300": 151, "9864": 151, "5179774750503756": 151, "3556725523121713e": 151, "386": [151, 175], "62155391177384": 151, "5017064542421926e": 151, "7621546176726476": 151, "7627785650581257": 151, "035698472048319115": 151, "035554890425441354": 151, "13515406": 151, "36789472": 151, "89991027": 151, "15877251": 151, "01283353": 151, "06035862": 151, "17934912": 151, "46903877": 151, "44379125": 151, "96750725": 151, "75501664": 151, "64295312": 151, "792296": 151, "528417968750004": 151, "526546565812786": 151, "294": [151, 280], "2642747018417": 151, "853726097616042e": 151, "5215534518729363": 151, "3998870486119035": 151, "6156776669782578": 151, "9999999999225003": 152, "025510204081632654": 152, "5962847939999439": [152, 231], "48453071499548805": 152, "2850010733170977": 152, "02540504391457564": 152, "3483340379497217": 152, "3473002240829173": 152, "7608141393691706": 152, "7613179409507954": 152, "493": 152, "07429490684376": 152, "2857694499926869": 152, "025682506385920862": 152, "00824999999999998": 152, "5014359645922872": 152, "2744678864589129": 152, "5552": 152, "4608": 152, "3446": 152, "7667": 152, "959": 152, "9984": 152, "3445": 152, "4805": 152, "0498": 152, "2403": 152, "4281": 152, "9849242586340088": 152, "951405202339398": 152, "2755665796145515": 152, "47235164055168316": 152, "29530027558732863": 152, "0000000054000913": 153, "881784197001252e": [153, 170], "768058113979663": 153, "768066406250014": 153, "ipykernel_1028195": 153, "432199472": 153, "06932741764435588": 153, "05276408527131783": 153, "3306690738754696e": [154, 183, 187, 191, 202, 203, 216], "4760910375888234": 154, "4760910375888239": 154, "7147250598130057": 154, "7147250598130044": 154, "514406493629222": 154, "514406493629242": 154, "8398041366589724": 154, "8398041366582019": 154, "1821440631620528": 154, "893569811063055": 154, "525904615830015": 154, "2336": 154, "3535391062123": 154, "2114": 154, "319013644667": 154, "2273": 154, "9298182857347": 154, "2514": 154, "0593433068734": 154, "2289": 154, "942828886021": 154, "775767": 154, "346368": 154, "6389": [154, 181], "900616": 154, "773326": 154, "341504": 154, "644159": 154, "833366": 154, "6135746770341746": 154, "612266101541527": 154, "4486312796347882": 154, "4312632716739029": 154, "131687": 154, "263374": 154, "009373": 154, "012346": 154, "790123": 154, "98419": 154, "21869142304750552": 154, "36061158934588": 154, "0007293936222674": 154, "9803751910399106": 154, "551115123125783e": [154, 156, 171, 178, 187, 188, 237], "547213421880941": 154, "025130683635059": 154, "5686523437500033": 154, "7672483125884355": 154, "3810696572372613": 154, "971910112359551": 154, "8943820224719101": 154, "3877787807814457e": [155, 227], "023594778811368573": 155, "001232560754852": 155, "04780667370458491": 155, "0239694365750378": 155, "003911078464110154": 155, "9991072407476334": 155, "0014358686297880883": 155, "0013452766464317": 155, "025394999999999945": 155, "0715": [155, 234], "6778": 155, "0955": 155, "4031": 155, "9146": 155, "3602": 155, "5764": 155, "4971939014159894": 155, "7836337981785467": 155, "4846293035097757": 155, "7825255275576956": 155, "275109825687059": 155, "022899342386556443": 155, "409909935899163": 155, "4560552763498436e": 155, "9440000000000008": 155, "9388992434096356": 155, "007899555278458287": 155, "995657428390161": 155, "2898681336964528": 156, "5937628755982818": 156, "5310242469692907": [156, 207], "0005897480997648315": 156, "2884274555095643": 156, "5946739650596489": 156, "5006909090909091": 156, "0017187970087170262": 156, "2959937908105679": 156, "7922314131197986": 156, "03356901014089397": 156, "3209829769831638": 156, "7131579341389477": 156, "419646281119494": 156, "0411654516887457": 157, "172424140432902": 157, "8462097026771533": 157, "041165454536300744": 157, "1724241522428485": 157, "8462097472699548": 157, "502838180880596": 157, "419128912754751": 157, "6935221497659256e": 157, "2512497056527128e": 157, "7406026024354304": 157, "239285901013936": 157, "168093594434854": 157, "7763910211945402": 157, "9983338376114": 157, "9983338376333": 157, "3655745685100555e": 157, "9341772151898735": 157, "488888888888889": 157, "498001805406602e": 158, "1900000000000002": 158, "394957983193281": 158, "2880073609822311": 158, "4973861961360124": 158, "0004996194824755228": 158, "994535773412378": 158, "ipykernel_1028713": 158, "929170082": 158, "9895099177905788": 158, "4892242478889066": 158, "8093153852790433": 158, "997460937500002": 158, "77359": 158, "24609802279": 158, "78144": 158, "37384621782": 158, "78673": 158, "30533222358": 158, "006236167694384731": 158, "9893872415885169": 158, "8300866939944515": 158, "06931275631257258": 158, "482564548958877e": 158, "9514659718253009": 158, "09992138634150076": 158, "546842977802951e": 158, "532669826254665": 158, "3643": [158, 249], "5400": 158, "8294": 158, "17124595542752363": 159, "3014": 159, "4986": 159, "0145": 159, "0055": 159, "0091": [159, 175], "0191": [159, 200], "0136": 159, "0227": [159, 190], "0054": 159, "0193": 159, "0138": 159, "0229": 159, "8292": 159, "4825": 159, "8266": 159, "5013": 159, "0018": 159, "4904": 159, "1392": 159, "4615": [159, 228], "4889": 159, "4437": 159, "4611820247291334": 159, "8104": 159, "2148": 159, "0558": 159, "12039": 159, "241319728375": 159, "0629": 159, "1306": [159, 183], "8066": 159, "0858": 159, "867": [159, 252], "0472": 159, "2672": 159, "7132": 159, "0196": [159, 193], "7872": 159, "2098": 159, "097": [159, 228], "3468": 159, "5562": 159, "7211221842088231": 159, "5429765107632374": 159, "2917": 159, "5139": 159, "0252": 159, "0305": 159, "270846226905952": 159, "4036": 159, "082": 159, "6722": 159, "5652": 159, "2609": 159, "1739": 159, "0102": 159, "9525": 159, "6581": 159, "2254": 159, "1164": 159, "1698276715473797": 160, "9301438713517878": 160, "787565892454241": 160, "307973079452186": 160, "7875658924542424": 160, "0436993462234498": 160, "1713176076871294": 160, "9315080413645616": 160, "044800564368963": 160, "2294": 160, "9214816192944": 160, "2600": 160, "229763380172": 160, "1982726939077264": 160, "1967383826043556": 160, "8688818370335867": 160, "8725882969800218": 160, "027764": 160, "274118": 160, "462581": 160, "000945": 160, "000139": 160, "013823": 160, "538674": 160, "997068": 160, "412395": 160, "857961": 160, "926468": 160, "45226": 160, "671159": 160, "10183273702285217": 160, "7123237885111698": 160, "6887988783026655": 160, "1678064142366296": 160, "_continuous_distn": [160, 209], "1963": [160, 209], "01289957414019094": 160, "6952763982788772": 160, "03175003284745531": 160, "004620185724241905": 160, "6550": 160, "366513886966": 160, "6654": 160, "193797013038": 160, "140906784453676": 160, "5539715901899305": 160, "640716249820006": 160, "2277": 160, "2901435545964": 160, "8734973177090273": 160, "1817893858567854": 160, "771254078804477": 160, "8552624536584": 160, "7198174084958109": 160, "2711930633331923": 160, "5614201502442215": 160, "600886798001836": 160, "029145": 161, "777367": 161, "802443982398021": 161, "7919597989949749": 161, "014103101477437954": 161, "3469432497508005": 161, "323350970447843": 161, "8918390627792722": 161, "2964891361570203": 161, "3802126275005553": 161, "015158632683738738": 161, "19873182866725814": 161, "7455759599332219": 161, "7472222579871374": 161, "7182876018799911": 161, "7762668748027535": 161, "5876066849609238": 162, "34170872750465553": 162, "5882352941176471": 162, "34602076124567477": 162, "2681344724009203": 162, "02253233559685": 162, "304": 162, "9812395274336": 162, "593214983382439": 162, "6857295045012564": 162, "80640950151249": 162, "1413854860274195": 162, "3857960784607864": 162, "8371053131042316": 162, "3602259671779372": 162, "1823669274709439": 162, "0376": 162, "8452": 162, "5469": 162, "4493": 162, "0343": 162, "942890293094024e": [163, 225], "0000000000000002": 163, "0800000000000005": 163, "1520696383139373": 163, "1520696383139375": 163, "8757396449704142": 163, "45999999999999996": 163, "5616000000000003": 163, "9067529857542795": 163, "0897608169846813": 163, "5616": 163, "0897608169846817": 163, "4597599350100935": 163, "5543152074902815": 163, "9030605189927701": 163, "0771188553706823": 163, "3989309187572552": 163, "3974357979472805": 163, "5055499322164319": 163, "1371935417217969j": 163, "5057498583668312": 163, "13764341874813715j": 163, "5894958483983916": 163, "5875920033245619": 163, "343323830978064": 163, "5385454706669304": 163, "8036398274203335": 163, "343429820268832": 163, "538601664756589": 163, "8036168180048361": 163, "4950": 163, "712560390255": 163, "4949": 163, "376344116159": 163, "376344452656": 163, "6940026389829959": 163, "190001974195752": 163, "5937727858392163": 163, "170714839086485": 163, "6900000000000002": 163, "1901000000000006": 163, "5987419144908114": 163, "201611672415372": 163, "027719": 163, "161068": 163, "327328": 163, "275103": 163, "129876": 163, "010279": 163, "093035": 163, "347585": 163, "667741": 163, "867593": 163, "1180461380307114": 163, "4026713345023387": 163, "8899021130108721": 163, "556442873253898": 163, "004999999999999975": 163, "563440711130625": 163, "1355160639014264e": 163, "31944444444445": 163, "7157241036182413": 164, "7157241036160373": 164, "08408636982305884": 164, "0840863698206612": 164, "07996816284010574": 164, "07996816537754364": 164, "6442012956595629": 164, "6442012687791223": 164, "15916045411593882": 164, "1591604541159396": 164, "1324299366788018": 164, "1329246561336936": 164, "5098943716313215": 164, "5095343059718397": 164, "723201242055198": 164, "6292690069604462j": 164, "7230631556167272": 164, "6297777730873335j": 164, "9999989999982012": 164, "7157224426511368": 164, "08408547601757835": 164, "715674128103815": 164, "08409526226307099": 164, "9996192849611022": 164, "9958703903250411": 164, "272004091710933": 164, "3759151362515315": 164, "6789211052609123": 164, "024309941278901404": 164, "9043824701195219": 164, "0923028785982476": 164, "9576": 165, "4294714656111736": 165, "7333895473411074": 165, "3022259281402193": 165, "474111034724598": 165, "429471462970749": 165, "7333895579577634": 165, "30222591791057": 165, "4741110129320223": 165, "756397": 165, "757041": 165, "5638539622591024": 165, "489223667427389j": 165, "2521834895613472": 165, "4322972648554105j": 165, "07024447912956258": 165, "2711293646917929j": 165, "01435532670293679": 165, "14062825155057773j": 165, "6943268223977832": 165, "1384941757974947": 165, "556153488212525": 165, "4353": 165, "7418": 165, "4295": 165, "7334": 165, "548109": 165, "096218": 165, "644327": 165, "192436": 165, "740545": 165, "295522": 165, "171121": 165, "069922": 165, "024508": 165, "00785": 165, "351985": 165, "721415": 165, "899531": 165, "967212": 165, "388222664766818": 165, "2931256583561437": 165, "2045665712074545": 165, "5427975513751417": 165, "7025618683212835": 165, "2710907010507073": 165, "9742363049697826": 165, "082356652940917": 165, "4663239585093428": 165, "7688940378192104": 165, "856": [165, 280], "4587089908602129": 165, "2533464400252319": 165, "084652557279298": 165, "0627486616378665": 165, "2450850386814643": 165, "0083703414202325": 165, "4947448812498432": 165, "1649431209050984": 165, "8530214219000483": 165, "0869565217391304": 166, "4822344816943791": 166, "741779266684047": 166, "791950464396285": 166, "7919504643962885": 166, "8571957656704647": 166, "8571957656704612": 166, "26112794339186": 166, "819704450943895": 166, "261003935389471": 166, "820016818351448": 166, "2529035200365988": 166, "3745254004774181": 166, "3541666666666667": 166, "61496": 166, "67983": 166, "46719": 166, "15676": 166, "02124": 166, "09586": 166, "26351": 166, "55505": 166, "84137": 166, "97256": 166, "41411": 166, "15258": 166, "53981": 166, "69128": 166, "04488": [166, 189], "006050540012662": 166, "86095144322162": 166, "06647032697333": 166, "9077897055189864": 166, "4166185566400728": 166, "545110186554938": 166, "418158015120004": 166, "5405681465872147": 166, "033525": 166, "0026333333333333334": 166, "5185185185185186": 167, "851851851851851": 167, "1368683772161603e": [167, 178], "243943": 167, "852748": 167, "772983": 167, "725928": 167, "481773": 167, "9997818369711162": 167, "001552102122452088": 167, "0038068173424053": 167, "0016533666280400539": 167, "9807346694212495": 167, "7203466333719599": 167, "0045700659359345": 167, "9890536073446352": 167, "13791866423119": 168, "7145293838425228": 168, "4852755496867136": 168, "556191909249108": 168, "8442158229634555": 168, "083709268125845": 168, "081944016481647": 168, "9992827793076853": 168, "137557641110836": 168, "7035045300612408": 168, "009700000000000042": 168, "11809773491898767": 168, "1769456563992517": 168, "998041440572122": 168, "007897677685366": 168, "459344430482952": 168, "6658920422291383": 168, "4812": 168, "347844437876": 168, "7263480358234555": 168, "661320104043914": 168, "4824": 168, "475216282033": 168, "3345162113961129": 168, "3881880476861284": 168, "5114": 168, "144353642654": 168, "01612416741026612": 168, "8241228923230904": 168, "6508596780817344": 168, "5669389607324895": 168, "697934398969099": 168, "547899159663866": 168, "6841726618705037": 168, "0216": 168, "5457": 168, "689": [168, 244], "1661": 168, "2250000000000005": 169, "2649110640673518": 169, "9923121739725458": 169, "5106385112629404": 169, "2476485440524825": 169, "233222259786438": 169, "2598087590265608": 169, "286106165978027": 169, "970249528831039": 169, "5243399321816582": 169, "8915919589344": 169, "491780106731331e": 169, "01017051215045639": 169, "9558863897485597": 169, "6923076923076925": 169, "98515": 169, "7931294775": 169, "9583533975000003": 169, "2021617732371373": 170, "017617376175620106": 170, "0050439355317722": 170, "910103419130583": 170, "20216177323713735": 170, "017617376175620078": 170, "0050439355317775": 170, "9101034191305897": 170, "7379404086142544": 170, "50168881": 170, "82387791": 170, "00000000": 170, "23537399": 170, "65727886": 170, "2027499903270397": 170, "01751052124828153": 170, "627632642063357": 170, "7906632180054841": 170, "021297063942282413": 170, "9764016414539523": 170, "079528064526103": 170, "333843481262363": 170, "37090878984369335": 170, "721573236948028": 170, "708069116289048": 170, "038367704355453": 170, "675183494500131": 170, "453529357407323": 170, "1092": 170, "9216112905583": 170, "1097": 170, "7549215034153": 170, "666620425713973": 170, "0018764617850800525": 170, "28176394627450635": 170, "73694559": 170, "92441084": 170, "6330583443564004": 171, "6330583443564002": 171, "32480146094947066": 171, "32480146094957457": 171, "7447600281534774": 171, "7447600281939166": 171, "621541991785324": 171, "621541990075665": 171, "5344790035243877": 171, "8376730717305914": 171, "8326085115945967": 171, "6330057127705082": 171, "32428303098588623": 171, "630914735153167": 171, "3263278688475253": 171, "7730376604261671": 171, "5652789598973224": 171, "2253635858863332": 171, "8000577257220729": 171, "8518451733244654": 171, "1737074881086293": 171, "8111183222726284": 171, "4769073218547977": 171, "019322688734407012": 171, "7538128001659254": 171, "1345": 171, "9993175118516": 171, "120700479394": 171, "6959525666650759": 172, "6959525666650779": 172, "664262775040937": 172, "664262775040893": 172, "5350716046213435": 172, "535071604621334": 172, "091512125815335": 172, "2232870489440097": 172, "3657": 172, "8563555300343": 172, "3837": 172, "5357980189947": 172, "862651": 172, "878569": 172, "592e": 172, "327733": 172, "328652": 172, "193e": 172, "118156": 172, "118494": 172, "384e": 172, "688802": 172, "670319": 172, "848e": 172, "234961": 172, "251763": 172, "680e": 172, "771561172376096e": [172, 195, 240], "7178987556895622": 172, "3894315601860372": 172, "05133996828013741": 172, "41424013354981": 172, "8446596489538924e": 172, "15153848777245724": 172, "04781441553700701": 172, "0114994159620951": 172, "13652098131156487": 172, "0862344920342504": 172, "7756": 172, "439e": 172, "545e": 172, "544e": 172, "307135070065489": 173, "3071350700654891": 173, "04921521947520513": 173, "049215219475204686": 173, "1262322238186198": 173, "1262322238187161": 173, "6645270107947754": 173, "6645270107930443": 173, "1699451239020231": 173, "16994512390202365": 173, "887246702960949": 173, "886184597056009": 173, "527400457004914": 173, "548009631523051": 173, "8464391259204764": 173, "2301080320124074": 173, "133363346645424": 173, "06359559061112985": 173, "0029546837073747357": 173, "8631642601470884": 173, "790712999885101": 173, "9140843629849709": 173, "82517": 173, "77339": 173, "05547": 173, "93852": 173, "65291": 173, "56727": 173, "520494": 174, "025508": 174, "588225": 174, "108542": 174, "040529": 174, "76406": 174, "116864": 174, "611420": 174, "7568": 174, "858407": 174, "241944": 174, "9674": 174, "613706": 174, "078188": 174, "4861": 174, "9072": 174, "386294": 174, "017443": 174, "2410": [174, 240], "4707": [174, 221], "6935424053619349": 174, "6935424053619348": 174, "11739913996796586": 174, "11739913996796691": 174, "1978173305441422": 174, "8009576229790984": 174, "004323522460566553": 174, "30646164988542945": 174, "8517412564229457": 174, "0038695613076692448": 174, "4413362972326398": 174, "0575559553964073": 174, "6955189103487112": 174, "178571": 174, "357143": 174, "535714": 174, "892857": 174, "071429": 174, "577952": 174, "669933": 174, "77612": 174, "892186": 174, "000554": 174, "039049": 174, "096047": 174, "207249": 174, "336163": 174, "485046": 174, "654412": 174, "838528": 174, "185392": 174, "730945": 174, "131448": 174, "997256": 174, "890909": 174, "170096": 174, "209137": 174, "418321": 174, "8303250105495901": 174, "00041257333440255226": 174, "036444080494296": 174, "8006713867187498": 174, "8003833488776558": 174, "6391867823797": 174, "5336085331253253e": 174, "111": 174, "8007104667025451": 174, "7937395928868959": 174, "8035088739427898": 174, "972138548466678e": 174, "9999955881114526": 174, "5756301439450783": 175, "9685804468711794": 175, "20448174823121082": 175, "3726364400044817": 175, "42931451047613484": 175, "6366197723675814": 175, "6366302229376012": 175, "6366252002772144": 175, "822319499230927": 175, "2222099320256232": 175, "845424930556134": 175, "1921741420882102": 175, "6281": 175, "9793": 175, "5848": 175, "0574": 175, "8577": 175, "6275": 175, "9828": 175, "5756": 175, "1287": 175, "0205": 175, "0035": 175, "1629": 175, "02051286847637": 175, "034275000000000055": 175, "5740334667297927": 175, "450544223310818": 175, "35810": 175, "086533710426": 175, "0247": 175, "4054": 175, "0023": 175, "2469": 175, "306": 175, "3279": 175, "9101": 175, "7543": 175, "5786": 175, "5066176345155946": 175, "1137226858667808": 175, "48943289656940303": 175, "1127280900386476": 175, "10679392033603453": 175, "9149524707614403": 175, "318171989669451": 175, "5135449277513544e": 175, "2550943293575374": 175, "2440297824189852": 175, "9265": [175, 176], "2747": 175, "9485": 175, "7269": 175, "7329": 175, "9425": 175, "6017": 175, "2156525147857526": 175, "2800000000000002": 176, "4700036292457357": 176, "501420070672676": 176, "2685335280033816": 176, "0003665014939261965": 176, "9428857779033946": 176, "000653645441159": 176, "716006489989578": 176, "2718": 176, "1622654572566": 176, "2631": 176, "3318": 176, "2641": 176, "3348": 176, "5003": 176, "3281": [176, 178], "2367": 176, "2562": 176, "4983": 176, "3328": 176, "2574": 176, "0439": 176, "2325": 176, "3245": 176, "0613": 176, "0527": 176, "6106": 176, "3046": 176, "8555": [176, 267], "1789": 176, "7094": 176, "7282358708034962": 176, "1857197356240277": 176, "698": 176, "608e": 176, "056666666666666664": 176, "983": [176, 257], "9999640133864247": 177, "631994380998788e": 177, "4571428571428573": 177, "12326530612245": 177, "123265306122448": 177, "2778689469997964": 177, "126472849550327": 177, "4485982444560452": 177, "4485982444560457": 177, "498592859519291": 177, "219823735932372": 177, "77405071546256": 177, "7976169855634092": 177, "110592466580817": 177, "335640138408304": 177, "7114842962167574": 177, "8021232338422095": 177, "5919613682845734": 177, "004820162907619045": 177, "9954160254634811": 177, "010996988292344": 177, "18640242191121764": 177, "1263487813287028": 177, "8838591601696771": 177, "634036655805251": 177, "9994876189685": 177, "406681390690768e": 177, "7971737044184": 177, "7943029024378885": 177, "5289999728329602": 178, "5290039062500016": 178, "41549549648756096": 178, "30890712001029735": 178, "0516969535184806": 178, "3089117456740079": 178, "0516693766560499": 178, "3699": 178, "3696": 178, "7591": 178, "7557": 178, "2115": 178, "9013": 178, "8492": 178, "8245": 178, "20295360934385015": 178, "9358360873038567": 178, "9446289062499998": 178, "2108": 178, "3262": 178, "0485": 178, "0046": 178, "4432416413976406": 178, "2501422793918129": 178, "650005786032107": 178, "0231191657045369": 178, "1013038928094692": 178, "326672684688674e": 179, "6653345369377348e": [179, 187, 201, 232], "3244828015117402": 179, "32448280139689": 179, "9859227840906253": 179, "004317043822053": 179, "9859283784918061": 179, "0043267837576417": 179, "818698": 179, "192106": 179, "367231": 179, "328118": 179, "198109": 179, "369612": 179, "0126691262593843": 179, "9297875350509812": 179, "9673828125000024": 179, "00113": 179, "211162": 179, "015913": 179, "999989": 179, "835218": 179, "339551": 179, "03198370647931559": 179, "0909550922196165": 179, "7086563866193003": 180, "7093708477579757": 180, "6167983135580041": 180, "6203395972311763": 180, "645416386779895": 180, "6499426099932761": 180, "8224594703414813": 180, "8131285555641372": 180, "1454927800033334": 180, "1454927800033339": 180, "0014571989242746": 180, "0010786593035603254": 180, "004672665089558881": 180, "6194629453741767": 180, "2601228248649343": 180, "4124450567933038": 180, "559877145947005": 181, "703193870225651": 181, "502046897613281": 181, "004496053448897028": 181, "170427457166342": 181, "3077": 181, "0653": 181, "1538": [181, 228], "9598": 181, "9587": 181, "1905": 181, "1902": 181, "6343": 181, "9069": 181, "8138": 181, "6276": 181, "3944": 181, "2258002867931699": 181, "7831215632335": 181, "successfulli": [181, 191, 212, 223, 227, 231, 234, 238, 241], "8783": 181, "809900252894": 181, "2258003058433171": 181, "7831215768119856": 181, "5094692359972378": 181, "4866561100536": 181, "507718906382747": 181, "4992795266980339": 181, "08335766686663254": 181, "0099": 181, "0994": 181, "4993": 181, "8989": 181, "1192": 181, "2689": 181, "7311": 181, "8808": 181, "9978": 181, "6964": 181, "7808": 181, "5159770568469728": 181, "9025679317202033": 181, "ipykernel_1031270": 181, "2293021024": 181, "26463042446936813": 181, "9882888911189841": 181, "9992910134947958": 181, "410232061566376": 181, "0021577791606112173": 181, "5288318801511985": 181, "2875000000000001": 181, "7708333333333335": 181, "7947076036992655e": 182, "1904761904761905": 182, "3605442176870748": 182, "0416666666666667": 182, "10540674603174603": 182, "0046141326124665": 182, "717785467128024": 182, "4890218861144686": 182, "1881560637980781": 182, "9558356968621015": 182, "60896": 182, "72759": 182, "92112": 182, "64573": 182, "02715": 182, "05631": 182, "92279": 182, "92654": 182, "26469": 182, "42424": 182, "20849": 182, "52608": 182, "004309521405735": 182, "0137861206612757": 182, "0034857193644913936": 182, "000027126069282": 182, "0630561150287168": 182, "836183726795856": 182, "3029522418961106": 182, "6061428639658745": 182, "21649390394049": 182, "166998473555129": 182, "8784506146804234": 182, "4758606604180544": 182, "7248113319636609": 183, "7246083823764353": 183, "8704011965756784": 183, "8806817386743675": 183, "30066798415101526": 183, "6993513672997337": 183, "4328500520233074": 183, "8032840930173821": 183, "8813146389489": 183, "1933977477677": 183, "3002472380387193": 183, "6995177336636519": 183, "0003531971981704151": 183, "9993110480909314": 183, "20712347539101095": 183, "8994332226964946": 183, "993361660448632": 183, "026728693326586762": 183, "2115097780447683": 183, "22627348624645166": 183, "9972006534532416": 183, "33776111088030053": 183, "6733830448193903": 183, "3498588075760032": 183, "2778456708726476": 183, "538595654436261": 183, "8062257748298549": 183, "1007461339910088": 183, "805805795463638": 183, "0000000003534637": 184, "85627631137654": 184, "425": 184, "00936160142885": 184, "4046918148882312": 184, "220825298069535": 184, "2203268063678467": 184, "811263090405161": 184, "44185606541447": 184, "4113563079778877": 184, "272143004630019": 184, "125593645982451": 184, "064962298664382": 184, "7625167097977015": 184, "7624525613686373": 184, "4559": 184, "564681994808": 184, "4602": 184, "7252905037785": 184, "789027117487663": 184, "90882792302494": 184, "857362": 184, "108574": 184, "001086": 184, "199854": 184, "361304": 184, "721396": 184, "553983": 184, "034943": 184, "01001312790477221": 184, "9984421995704": 184, "011160865291876099": 184, "9621323409117997": 184, "2998699911173841": 184, "2974883391590261": 184, "27616277085842267": 184, "3257213674590149": 184, "746323e": 184, "919517e": 184, "269969e": 184, "157": 184, "665470e": 184, "658093e": 184, "792107996744354": 185, "792107996744427": 185, "283063041541027e": 185, "013396987029412295": 185, "021002378515706396": 185, "037808598539744685": 185, "07246270804981933": 185, "18895790539751117": 185, "5586039053370001": 185, "61422078234059": 185, "614220782342528": 185, "3471505869384755": 185, "5957691216057308": 186, "45352091052967447": 186, "4856928280495921": 186, "10816384281628826": 186, "10816384281629526": 186, "9961541981062054": 186, "242522": 186, "242496": 186, "084e": 186, "596076": 186, "596124": 186, "092e": 186, "403010": 186, "401649": 186, "664e": 186, "274996": 186, "205933": 186, "861e": 186, "3809148077229623": 186, "380919232732261": 186, "6571": 186, "750760746983": 186, "6568": 186, "950376805914": 186, "9947114020071635": 186, "7086264227026163": 186, "9932654141116128": 186, "7103638546989847": 186, "1798": 186, "3651": 186, "2655": 186, "0971": 186, "0199": 186, "0707": 186, "3867": 186, "7456": 186, "9351": 186, "9898": 186, "3253": 186, "6552": 186, "8196": 186, "5334": 186, "3075": 186, "1840633901945228": 186, "1840600406715882": 186, "08079599885578": 186, "023420813354591785": 186, "634194125013562": 186, "2707": 186, "3204": 186, "3733": [186, 263], "0023012231114213485": 186, "005287111232994": 186, "495423340949614": 187, "4954233409496127": 187, "6941719835054267": 187, "6941719835053937": 187, "2317": 187, "0192153765065": 187, "2192": 187, "250620713471": 187, "2271": 187, "5919986517115": 187, "2430": 187, "591198727745": 187, "2332": 187, "061147185981": 187, "409355": 187, "921199": 187, "945194": 187, "387239": 187, "406851": 187, "916873": 187, "950439": 187, "351833": 187, "1137956021290585": 187, "1129126745223055": 187, "8749178323085646": 187, "8646985368757909": 187, "712222": 187, "701539": 187, "125904": 187, "003942": 187, "16025": 187, "561231": 187, "906511": 187, "993382": 187, "025821632419133145": 187, "725107179530955": 187, "4983676379870374": 187, "0199409878085794": 187, "992007221626409e": 187, "525228570404704": 187, "5103231593958144": 187, "5155273437500036": 187, "043273791422052454": 187, "8352105904552609": 187, "4134831460674153": 187, "0820224719101126": 187, "5351415907229062": 188, "0163": 188, "1583": 188, "5351": 188, "0154038243715915": 188, "0690070365107665": 188, "0153779868371826": 188, "0689827738192625": 188, "6485366779464337": 188, "6433265609153302": 188, "024978622724565": 188, "99718978244119": 188, "006157959722548512": 188, "43246486363740355": 188, "503244691922463": 188, "1690578312389472": 188, "9084984164318166": 188, "7965922961909722": 188, "7011334169300067": 188, "6947313365937005": 188, "5827992986018258": 188, "2049": 188, "215752722065": 188, "2257": 188, "7602247153422": 188, "02229227363429831": 188, "9201234117259488": 188, "11025845030503556": 188, "288996193893122e": 188, "47433333333333333": 188, "1168208745438195": 188, "9563590687149044": 188, "2839317728708906": 188, "9271449297214939": 188, "8451908384406034": 188, "0167339182440416": 188, "99764": 189, "00281": 189, "50352": 189, "01425": 189, "3019": 189, "19628": 189, "99606": 189, "39907": 189, "49794": 189, "440892098500626e": [189, 198, 213], "564889": 189, "0870789137": 189, "564884": 189, "8911281398": 189, "007935607274497": 189, "065157788886816": 189, "270207507991013": 189, "27102": 189, "0028111788246214433": 189, "11516": 189, "00797": 189, "16143": 189, "83159": 189, "10384": 189, "21598": 189, "00246": 189, "1614286874386144": 189, "98169": 189, "02102": 189, "9965": 189, "30165": 189, "98532": 189, "301062635065886": 189, "673223560444946": 189, "055836249807211434": 189, "ipykernel_1032085": 189, "3864252406": 189, "93823": 189, "82923": 189, "02482": 189, "00985": 189, "03713": 189, "1512425464397995": 190, "17464059926680608": 190, "40569507726266335": 190, "0592950893995936": 190, "059295089399593603": 190, "5288352805664636": 190, "055715894644666": 190, "5069096363629064": 190, "1525436945219076": 190, "5038743907493182": 190, "1524272744432116": 190, "5024354377047782": 190, "7755": 190, "4796": 190, "988644559230805": 190, "4934785377454523": 190, "988614048401301": 190, "4934772333000144": 190, "976324368518703": 190, "0012587550407712": 190, "9860946700712": 190, "22779501891415e": 190, "149": 190, "9768": 190, "0016": 190, "275957200481571e": 191, "8056810852034035": 191, "6692626621651225": 191, "2778": 191, "7302": 191, "3333333333333335": 191, "166666666666667": 191, "766743077969323": 191, "412571428571438": 191, "7667430779693272": 191, "412571428571429": 191, "982072333858543": 191, "329072332845629": 191, "114308408422413": 191, "22501760747977675": 191, "14848821017085254": 191, "4224": 191, "2932": 191, "5741": 191, "1304": 191, "9476495499863073": 191, "fitparam": [191, 223, 227, 231, 234, 235, 238, 240, 241], "966537234116151": 191, "49195779903889264": 191, "9291": 191, "300467": 192, "358786": 192, "472341": 192, "349288": 192, "115124": 192, "501746": 192, "093929": 192, "017647": 192, "304653": 192, "964547": 192, "448490": 192, "194098582508634": 192, "2025931855233258": 192, "302083304452847": 192, "356864236401281": 192, "3004667695269725": 192, "35878618135608": 192, "1774": 192, "2949": 192, "0125": 192, "1311": 192, "7734": 192, "9942": 192, "426": 192, "1903": 192, "0526": 192, "8375": 192, "5144120934998153": 192, "19392060339923": 192, "1072185503404517": 192, "3202083333333333": 192, "9998999999954213": 193, "999899999995421": 193, "9281099901829891": 193, "2041522491349481": 193, "0995600010269304": 193, "021687398489853": 193, "00836025071894": 193, "1822": 193, "5992": 193, "8182": 193, "8162": 193, "8698": 193, "8234": 193, "881234572685431": 193, "99531473084796": 193, "053812112584495": 193, "00580082933823875": 193, "8118991628381108": 193, "0749": 193, "0158": 193, "3463": 193, "9842": 193, "6537": 193, "0142": 193, "2524": 193, "0148": [193, 200], "9244": 193, "1567": 193, "415276209807526": 193, "432624331417813": 193, "0502": [193, 221], "0508": 193, "0519": [193, 245], "0533": 193, "8414588206941254": 193, "96872510672175": 193, "4563135974860988": 194, "7969433986282367": 194, "716": 194, "0835277507142": 194, "715": 194, "1801474751153": 194, "7031752075013465": 194, "2937846790607508": 194, "1861": 194, "3069": 194, "0013": 194, "0228": 194, "1587": 194, "8413": 194, "9772": 194, "9987": 194, "3951": 194, "3869": 194, "9551": 194, "3398": [194, 217], "1837": 194, "6852965688237751": 194, "3020645349649365": 194, "804": 194, "6084420137539": 194, "1249403105684774": 194, "5573736131335747": 194, "0003745812231249413": 194, "5051452782639159": 194, "744735342873039": 194, "077070510118755": 194, "309426373877638": 194, "9797": 194, "0441": 194, "0095": 194, "8152": 194, "9817": [194, 221], "10531231768391913": 195, "5644389450812155": 195, "569429411031021": 195, "4878339661647202": 195, "2272073243850334": 195, "2185": 195, "389754329737": 195, "2212": 195, "5723866013323": 195, "18263227159514": 195, "13341510615123034": 195, "13565855667130944": 195, "7147789033673897": 195, "7160715875654602": 195, "008404": 195, "519158": 195, "28318": 195, "002845": 195, "371315": 195, "820179": 195, "29686269665968856": 195, "7145890817830703": 195, "080842815399469": 195, "6938365831228384": 195, "21570215913180396": 195, "4409291715704364": 195, "01620866142668531": 195, "21934": 195, "787824": 195, "211728": 195, "341481": 195, "964354": 195, "208528": 195, "544096": 195, "255063": 195, "975488": 195, "075406": 195, "9999999999999999": [196, 232], "1102230246251563e": 196, "2222222222222223": 196, "483709268125845": 196, "3195079107728942": 196, "4837092681258448": 196, "523314680630405": 196, "000025688150666": 196, "415793": 196, "132384": 196, "755368": 196, "413034": 196, "147542": 196, "814283": 196, "414214": 196, "162278": 196, "388099": 196, "281208": 196, "03218": 196, "063325": 196, "535648": 196, "472583": 196, "287302": 196, "250062": 196, "510556": 196, "9473724039537028": 196, "02377036106946595": 196, "476315778565303": 196, "9680604915855544": 196, "5000861396347691": 196, "1500942564639236": 196, "003664756067939": 196, "301614469333093": 196, "04437503708196632": 196, "160964047443681": 196, "776595898635988": 196, "3975": 197, "44243522909": 197, "2499229604521087": 197, "47616893803532": 197, "0112388704572353": 197, "6943494725056225": 197, "1819509816812133": 197, "4762059470050811": 197, "0047791374840935": 197, "1236522369213": 197, "0038070626427584": 197, "037192684901968": 197, "5279894563295269": 197, "2304529907529282": 197, "5751002226713251": 197, "0022026684074685": 197, "134": 197, "65971186480692": 197, "012345679012345678": 197, "4289216067243458": 197, "552217453505007": 197, "3589194706864023": 197, "6688667024234018": 197, "662514114546": 197, "1730": 197, "2757084623959": 197, "3326": 197, "7075721286647": 197, "5740": 197, "577006565781": 197, "9999975000038249": 198, "7142857142857143": [198, 270], "045351473922902494": 198, "7318040653635675": 198, "7566433566433566": 198, "24335664335664337": 198, "31629073187415513": 198, "7148571686605475": 198, "045105947985351946": 198, "430906200738553": 198, "429630435055177": 198, "5199151026621225": 198, "16051": 198, "629136719428": 198, "16053": 198, "198881460783": 198, "37499999999999994": 198, "09014423076923074": 198, "4625924443258073": 198, "9468599033816425": 198, "0531400966183575": 198, "15584104290067602": 198, "3743840717431062": 198, "09018237402830535": 198, "4607797772203317": 198, "0573167628324114": 198, "495491295398117": 198, "6645352591003757e": [198, 232], "5879063580561444": 198, "1697": [198, 249], "6355832402796": 198, "009659281640087447": 198, "735458175746772": 198, "399059202286664": 198, "2951": 198, "5053": 198, "005637499999999962": 198, "15667073167578494": 198, "9452325925703184": 198, "766598898637241": 199, "14357805872728147": 199, "7665988986464012": 199, "14357805819281622": 199, "4125699795241162": 199, "6893681890406604": 199, "4125700104903471": 199, "689368147505827": 199, "3104859755515168": 199, "31121527710431507": 199, "4902987185051226": 199, "6958602222515958": 199, "8202735128240072": 199, "11734781330343225": 199, "820029631513031": 199, "11811345419595665": 199, "5037406995962112": 199, "8232233047033631": 199, "1767766952966369": 199, "4953664703862923": 199, "6993813269605423": 199, "985513381597837": 199, "5955967131454634": 199, "5949218749999997": 199, "2274": 199, "3346858406258": 199, "7043": 200, "5572": 200, "1372": [200, 221], "0169": 200, "6371": 200, "1457": 200, "0446": 200, "0103": 200, "4823": 200, "4112": 200, "3441": 200, "7935": 200, "0808": 200, "0308": 200, "3063": 200, "8463": 200, "5595": 200, "2132": 200, "1166": 200, "1236": 200, "4236": 200, "3729": 200, "2881": 200, "8462843753214871": 200, "846065136921111": 200, "5594672038228536": 200, "556191412401224": 200, "1248251350586798": 200, "1238705507099147": 200, "6394311262015824": 200, "701076896522755": 200, "559707628301136": 200, "8513324178004397": 200, "38152936152009354j": 200, "510420735156466": 200, "5607402301350501j": 200, "004128908027490085": 200, "3364882431292367j": 200, "4874559748406924": 200, "5902795863276724": 200, "0293753730037913": 200, "196533388211137": 200, "4917152369000162": 200, "1034": [200, 209], "2517": 200, "1575": 200, "0996": 200, "4358": 200, "8525": 200, "3989": 200, "5165": [200, 234], "6074": 200, "0545": 200, "0905": 200, "5854": 200, "9082": 200, "976137952372347": 200, "4973638148560626": 200, "2194210660018447": 200, "0048303375756196": 200, "777": 200, "4190504574754": 200, "381812106467419e": 200, "importerror": 201, "16666666666666663": 202, "7499999999999991": 202, "49334217451750995": 202, "4933421745175011": 202, "0004876065533899298": 202, "1668664435284834": 202, "0859813581363065": 202, "0855688443043081": 202, "837035002401219": 202, "830761718750015": 202, "1271": 202, "0385836930934": 202, "1270": 202, "5214543060163": 202, "5207357833792": 202, "687984": 202, "570477": 202, "755541": 202, "147472": 202, "250969": 202, "816589": 202, "7435": 202, "996741": 202, "828464": 202, "881516": 202, "9967410604892193": 202, "8815164217779459": 202, "028463": 202, "421625": 202, "551513": 202, "616446": 202, "000019": 202, "072463": 202, "195777": 202, "342673": 202, "657327": 202, "804223": 202, "927537": 202, "999981": 202, "022809": 202, "961042": 202, "883764": 202, "258481": 202, "646669": 202, "054687500000011": 202, "0624023437500085": 202, "0196089693518": 202, "0758209264796379e": 202, "806879": 202, "032073": 202, "825476": 202, "97678": 202, "148": 202, "130524": 202, "381763": 202, "4000000000102597": 203, "399999998838463": 203, "4744060267436274": 203, "4744060304700746": 203, "374999944645813": 203, "166121": 203, "166259": 203, "412576": 203, "412801": 203, "785599": 203, "785431": 203, "398831941273997": 203, "399184268895933": 203, "868685": 203, "599603": 203, "306416": 203, "7103637479819758": 203, "0027800000000000047": 203, "9901116464472421": 203, "9112842485865573": 203, "7642504527853546": 203, "7692307692307692": 203, "761629618364975": 203, "769230769230769": 203, "0132": 203, "0811": 203, "6593": [203, 245], "3056": 203, "3773": 203, "2918": 203, "2086896614467806": 203, "208691406250003": 203, "492655677690741": 203, "012848466228206235": 203, "9097522260451599": 203, "619436549633346": 203, "4614": 203, "6127": 203, "7995": 203, "6444642305320814": 203, "9596146024645902": 203, "5669629470726485": 203, "7937453680464364": 203, "9677723903719386": 203, "586557781439685": 203, "028211054677508": 203, "691210436430917": 203, "9999926082589535": 204, "9999926082589539": 204, "3286859777676976": 204, "3286859777676975": 204, "09592630856260402": 204, "09592630856260406": 204, "9653913793583742": 204, "965391379358374": 204, "4822330470336309": 204, "284899599858133": 204, "2848995998581327": 204, "9496269250927831": 204, "9496269250927867": 204, "7677961497524766": 204, "9999999999999997": 204, "5630438239678969": 204, "7174512887274822j": 204, "1597740266239293": 204, "7104281135014987j": 204, "2863681210052288": 204, "20255826100750324j": 204, "4911323685576505": 204, "8575346488861357": 204, "8521891046099694": 204, "8987076883363847": 204, "041531475763699": 204, "138329": 204, "153167": 204, "212814": 204, "691646": 204, "006217": 204, "071569": 204, "160358": 204, "583635": 204, "99095": 204, "292835": 204, "588495": 204, "863896": 204, "080456": 204, "086615": 204, "5159002307382545": 204, "0010439852719006": 204, "15435313231501": 204, "0230383973288815": 204, "474457072384077": 205, "4744570723840766": 205, "2570621969284224": 205, "2570621969284217": 205, "34234947509082275": 205, "3423494750908338": 205, "835812529966139": 205, "1641874700338617": 205, "9683706333582578": 205, "9633278327527912": 205, "7337792125752307": 205, "7345364036221205": 205, "5240102238815233": 205, "5213834645096407": 205, "346012": 205, "250942": 205, "012433": 205, "000045": 205, "242633": 205, "841085": 205, "995869": 205, "99999": 205, "9749664963783742": 205, "9964787814644809": 205, "4926947250781553": 205, "5823631882104543": 205, "9880517248571086": 205, "58952187373336": 205, "467827": 205, "121463": 205, "9188": 205, "774993": 205, "663442": 205, "49854065493504535": 206, "0025105699993875": 206, "0002972765510045654": 206, "0034177602258956": 206, "3378770664093453": 206, "0066310114582215": 206, "560276": 206, "157799": 206, "942746": 206, "7539": 206, "73464": 206, "511127": 206, "158642": 206, "243663": 206, "867028": 206, "499481": 206, "5069591823846296": 206, "698045426706722": 206, "04323935373187415": 206, "20588329780325731": 206, "06402741241309892": 206, "013958570716509898": 206, "ipykernel_1034072": 206, "1049027462": 206, "930360346008193": 206, "9533443905131391": 206, "531024246969": 207, "9974": 207, "9494": 207, "1595": 207, "0747": 207, "9982": 207, "986": 207, "1294": 207, "0484": 207, "9641": 207, "1591": 207, "9816": 207, "3031": 207, "2879": 207, "80144": 207, "4900946289203073": 207, "0407488749013953": 207, "019498790841202": 207, "4840": 207, "023312243398": 207, "4839": 207, "383368018449": 207, "3999999999999999": 207, "507061557352626e": 207, "4288740671735822": 208, "5771929673324073": 208, "7844267553823129": 208, "7844267553823128": 208, "6327847548211796": 208, "78999919486678": 208, "8949220542394136": 208, "8953462544575976": 208, "7695971251211239": 208, "7602165828457118": 208, "218454607392225": 208, "3213416599784268": 208, "720966601172293": 208, "7694839518527028": 208, "5944520723662186": 208, "781273301264674": 208, "022768496311229187": 208, "9544398008289063": 208, "62538440764183": 208, "00011139849742594632": 208, "05972705368089612": 208, "05989457000981375": 208, "520661086851837": 209, "3419965211478724": 209, "188652638505497": 209, "999458199777277": 209, "keyboardinterrupt": 209, "_distn_infrastructur": 209, "rv_gener": 209, "kwd": 209, "1108": 209, "1109": 209, "_random_st": 209, "_rv": 209, "1113": 209, "1115": 209, "1037": 209, "1029": 209, "1030": 209, "1031": 209, "properli": 209, "1035": 209, "1036": 209, "_ppf": 209, "1038": 209, "1052": 209, "1051": 209, "_ppfvec": 209, "function_bas": [209, 240], "2372": 209, "__call__": 209, "2369": 209, "_init_stage_2": 209, "2370": 209, "_call_as_norm": 209, "2365": 209, "2362": 209, "varg": 209, "2363": 209, "_vectorize_cal": 209, "2455": [209, 240], "2452": 209, "2453": 209, "asanyarrai": 209, "ufunc": 209, "nout": 209, "_ppf_singl": 209, "1961": 209, "_ppf_to_solv": 209, "1964": 209, "xtol": 209, "_zeros_pi": 209, "full_output": 209, "_rtol": 209, "_wrap_nan_rais": 209, "_zero": 209, "_brentq": 209, "results_c": 209, "f_rais": 209, "_function_cal": 209, "1943": 209, "2137": 209, "cond": 209, "2138": 209, "goodarg": 209, "argsreduc": 209, "_cdf": 209, "2140": 209, "2141": 209, "12344": 209, "studentized_range_gen": 209, "12341": 209, "frompyfunc": 209, "_single_cdf": 209, "12343": 209, "12339": 209, "12337": 209, "llc": 209, "lowlevelcal": 209, "from_cython": 209, "_stat": 209, "cython_symbol": 209, "usr_data": 209, "12338": 209, "nquad": 209, "1206": 209, "1204": 209, "1205": 209, "_optfunc": 209, "_nquad": 209, "1260": 209, "1258": 209, "quad_r": 209, "1261": 209, "1262": 209, "1263": 209, "abserr": 209, "wvar": 209, "wopt": 209, "maxp1": 209, "limlst": 209, "complex_func": 209, "retval": 209, "458": 209, "_quad": 209, "461": 209, "608": 209, "_quadpack": 209, "_qags": 209, "_qagi": 209, "infbound": 209, "610": 209, "611": 209, "627502672414396": 210, "6380083522442455": 210, "4939574148670296": 210, "7853995473987132": 210, "0026917757260773163": 210, "3319992347178284": 210, "002866": 210, "018138": 210, "135473": 210, "521502": 210, "274424": 210, "001902": 210, "009998": 210, "068652": 210, "392352": 210, "851679": 210, "833234442641876": 210, "198612165986697": 210, "7063928901680383": 210, "47777777777777775": 211, "052283950617283886": 211, "06384207577550371": 211, "9776791202787192": 211, "12101540578511419": 211, "47773031266121874": 211, "0521678953325731": 211, "06165757434756212": 211, "9794766229452243": 211, "12101540752540882": 211, "5668662649434": 211, "47476570557688047": 211, "47767874741864774": 211, "09811792447989266": 211, "1809937986958925": 211, "18285880192823223": 211, "688053309454262": 211, "261": 211, "55753985773356": 211, "2276372793264453": 211, "6866876636087544": 211, "43333333333333335": 212, "37722222222222224": 212, "1292309797579062": 212, "12923097975790612": 212, "9054651081081644": 212, "9054651081081645": 212, "39999999999999997": 212, "04666666666666667": 212, "47613605131159786": 212, "1931471805599453": 212, "4010680676452827": 212, "004055796177896897": 212, "29460842560364947": 212, "0028833997301208": 212, "377": 212, "97189131874006": 212, "000138145172893": 212, "168342390818645": 212, "1666666666666665": [212, 236], "333333": [212, 253], "521739": 212, "347826": 212, "173913": 212, "116667": 212, "452174": 212, "756522": 212, "93913": 212, "428577": 212, "39136": 212, "017822": 212, "494647": 212, "385795": 212, "3331743756744738": 212, "9843826668287806": 212, "4809642734577553": 212, "17538543172565524": 212, "4965816066289745": 212, "03351144747930468": 212, "7469182474457042": 212, "6803733951541852": 212, "6798399199599799": 212, "attributeerror": [213, 389], "4472584711835175": 213, "8428129105262321": 213, "8452472222924361": 213, "5037309504814621": 213, "5059742689284107": 213, "509329": 213, "308923": 213, "009329": 213, "40081": 213, "257258": 213, "704176": 213, "265893": 213, "66483": 213, "184419": 213, "1847469403034272": 213, "8491731695113298": 213, "168808471117396": 213, "3286667936902536": 213, "902455836679641": 213, "4847492967374485": 213, "83350937849366": 213, "2874257215855778e": 213, "484737376630421": 213, "6063036262023139": 214, "9776753030120942": 214, "0744134977913906": 214, "3838567001159119": 214, "4995503501371839": 214, "229687469851479": 214, "9997033556964805": 214, "999994264038702": 214, "49656530813860444": 214, "3467": 214, "4215": 214, "2033": 214, "7967": 214, "7351": 214, "2584": [214, 254], "6063036262023138": 214, "1095450525138721": 214, "9161971056921887": 214, "6441090041345641": 214, "4780312277747587": 214, "5615952358558073": 214, "023327322118709": 214, "862372609449451": 214, "166": 214, "35630655358545": 214, "6241821384229533e": 214, "7145105676253577": 214, "7133725805292019": 214, "018208926018230744": 214, "673029245895192": 214, "9999682329410746": 214, "666666666666667": 215, "5752178731265971": 215, "5752178731265976": 215, "897052928779272": 215, "8970529287792715": 215, "587240444439618": 215, "5872404444395976": 215, "5648510858655371": 215, "564851085865537": 215, "966201346197002": 215, "006680000000000019": 215, "21359969753360408": 215, "5599207153635837": 215, "6649106936679934": 215, "94363698958849": 215, "829190701746747": 215, "973639795656418": 215, "012295004694353129": 215, "8395284823777183": 215, "96832887580269": 215, "162678360578365": 215, "9731336719402": 215, "699845415743587": 215, "8838055783319058": 216, "19039626228275253": 216, "5000215465747762": 216, "585680805798487": 216, "5000215465747815": 216, "585680805798499": 216, "23492536535757963": 216, "45106303854527163": 216, "5944101662659167": 216, "08811862717309919": 216, "6682569212463516j": 216, "5811634487536085": 216, "698157117953174j": 216, "8829961202882072": 216, "4168074733874823j": 216, "4714474041561004": 216, "7778192822675947": 216, "8850091193506309": 216, "8853549491974178": 216, "597198": 216, "847306": 216, "72325": 216, "176502": 216, "027815": 216, "213994": 216, "631769": 216, "972303": 216, "357434": 216, "830846": 216, "51064": 216, "787695312500002": 216, "904282724745143": 216, "83": 216, "81779762028248": 216, "425417704887916e": 216, "897811196254147": 216, "7183616784367284": 216, "0639336197638096": 216, "011202726156228": 217, "9865008503031785": 217, "9752981241469505": 217, "7711": 217, "6848": 217, "9919358062770378": 217, "980194788380514": 217, "9882589821034764": 217, "012517525083212355": 217, "0863724270399534": 217, "121320343559643": 218, "1683115761812808": 218, "1673168314822207": 218, "6979415068846022": 218, "9342328565348255": 218, "3765": 218, "005001936604": 218, "3764": 218, "79254307707": 218, "4978110241273188": 218, "1084760209581126": 218, "9850123489974157": 218, "9642769362574072": 218, "19128589639592256": 218, "5316481216288031": 218, "707057237926007": 218, "055512548439454": 218, "381122312541543": 218, "4295590938454583": 218, "08395022407058": 218, "769428012935727e": 218, "6233797987498713": 218, "5284105131414267": 218, "7281602002503131": 218, "6083134294865697": 218, "1183377846342366": 218, "6616332462510139": 219, "656673361303171": 219, "865023442264403": 219, "8650234422644058": 219, "7723789795422564": 219, "1125138955348604": 219, "4263": 219, "328347635146": 219, "48703560503710946": 219, "48734119515417307": 219, "2115187094928475": 219, "1931747543380187": 219, "5248013159497331": 219, "9960156700152405": 219, "8989292504413816": 219, "5377865960944537": 219, "9045985622077737": 219, "02737955313267515": 219, "9170449942340866": 219, "023270299995085675": 219, "855": 219, "3812785388127855": 219, "9876712328767123": 219, "3877289041166823": 219, "994075094693863": 219, "805490585901867": 220, "5027611392557279": 220, "0719865728909583": 220, "0719865728909592": 220, "3904035615957744": 220, "3904035615957788": 220, "4800872940856251": 220, "681490527901736": 220, "4991075083424734": 220, "6814619463263676": 220, "499116178166809": 220, "004012499999999974": 220, "5387311821802074": 220, "492943742605249": 220, "06823": 220, "21694": 220, "22073": 220, "00381": 220, "00761": 220, "12926": 220, "63212": 220, "9971": 220, "99239": 220, "87074": 220, "36788": 220, "36998": 220, "91892": 220, "90068": 220, "49376": 220, "3901687026330698": 220, "2085788623684626": 220, "03232217170754775": 220, "029962541380471608": 220, "39838": 220, "48644": 220, "57815": 220, "4000915006124321": 220, "3065326608485597": 220, "6408964289216006": 220, "807": 221, "4193": 221, "1853": 221, "04274089576966": 221, "185358204431287": 221, "919": 221, "688": 221, "094": 221, "889": 221, "356": 221, "1647": 221, "092": [221, 280], "9336": 221, "8141": 221, "0002542559011445013": 221, "277169313297081": 221, "6922652617053153": 221, "3414": 221, "9574804185486624": 221, "0314": 221, "0074": 221, "0235": 221, "0692": 221, "2528": 221, "1047": 221, "3462": 221, "4882": 221, "762": 221, "6616846079018803": 222, "4525444672960833j": 222, "6602684919277427": 222, "4517139787160283j": 222, "8016377082039997": 222, "599857582268681": 222, "141592653589793": 222, "5890465337294515": 222, "797345980028823e": 222, "895697594807302": 222, "7619482686444916": 222, "1108576330168647": 222, "3966025177674441": 222, "8497815832008019": 222, "7503": [222, 230], "1826": 222, "0646": 222, "0392": 222, "0338": 222, "3493": 222, "4335": 222, "4721": 222, "5665": 222, "6507": 222, "009233644109653879": 222, "8038418546610053": 222, "3055669821339948": 222, "8038775620591454": 222, "3051673737537706": 222, "7425742951471538": 222, "9118284272710974": 222, "1025": 222, "1174573307458": 222, "4254246315029266": 222, "8075766191924449": 222, "2700": 223, "2696": 223, "1969": 223, "0361": 223, "9264": 223, "9215": 223, "6264": 223, "6255": 223, "8278": 223, "2517j": 223, "8281": 223, "2513j": 223, "5833": 223, "31299999784461363": 223, "binomtestresult": 223, "04138946533203125": 223, "5089541282920425": 223, "9134285308985655": 223, "7083333333333334": 223, "893": [223, 280], "000000000001": 223, "500000000000": 223, "999999999999": 223, "262": [223, 280], "291606": 224, "690476": 224, "2577232124962414": 224, "518957094288793": 224, "572700": 224, "446845": 224, "316327": 224, "65555": 224, "7927041975": 224, "051885": 224, "070752": 224, "080018": 224, "084018": 224, "084571": 224, "122637": 224, "202655": 224, "286674": 224, "371245": 224, "041290796966522": 224, "036609641147764": 224, "5706": 224, "819056152122": 224, "2510": 224, "347071": 224, "5022": 224, "694142": 224, "1527": 224, "653209": 224, "3059": 224, "306418": 224, "001878631572159702": 224, "277211654327845": 224, "571428571428572": 225, "044897959183615": 225, "84601064484599": 225, "57126976284624": 225, "044898": 225, "846011": 225, "57127": 225, "828474": 225, "827167": 225, "90e": 225, "142197143995": 225, "55e": 225, "384537": 225, "03206": 225, "4657421564": 225, "0321": 225, "068627": 225, "108359": 225, "119195": 225, "113519": 225, "176987": 225, "296182": 225, "409701": 225, "2164460599996625": 225, "083330357835461": 225, "0027753438349855664": 225, "2711864406779661": 225, "18257418583505536": 226, "016666666666666666": 226, "999065": 226, "510134125775002": 226, "423340794934518": 226, "74378": 226, "74036": 226, "4082": 226, "4000000000000004": 226, "348475": 226, "3484751594559644": 226, "10037920682387039": 226, "22915706682058734": 226, "5080686477145561": 226, "37037037037037035": 226, "24787219846491212": 226, "5019667760094333": 226, "9833333333333": 226, "3130981451528444": 226, "3273108178480401": 227, "4344431884043245": 227, "510337952872525": 227, "30179503342743": 227, "7413900989073794": 227, "5103379528725243": 227, "301795033427425": 227, "7413900989073795": 227, "1293215104592877": 227, "1293215104592875": 227, "188392420649003": 227, "43825": 227, "4310125322436335": 227, "4382499999510091": 227, "3537": 227, "129610521816": 227, "3536": 227, "960983993395": 227, "9864338408867821": 227, "959484948528839": 227, "98722": 227, "9630466716000001": 227, "632121": [227, 235], "232544": [227, 235], "085548": [227, 235], "031471": [227, 235], "011578": [227, 235], "864665": [227, 235], "950213": [227, 235], "981684": [227, 235], "993262": [227, 235], "5819766656462539": 227, "92067276974634": 227, "2148140377734147": 227, "0982790587590858": 227, "334": [227, 389], "1736246842629": 227, "1851773758214812e": 227, "9563436545547456": 227, "821300695264435": 227, "0950861245578618": 227, "999778782798785e": 227, "999999999995e": 227, "027972027972027885": 228, "02797202797202796": 228, "632783294297951e": 228, "4792": 228, "9167": 228, "5625": [228, 256], "3125": 228, "885255849427407": 228, "711": 228, "703": 228, "153": 228, "479166666666666": 228, "9743975315293802": 228, "7108891108891111": 228, "indentationerror": 228, "016968325791855168": 228, "55351295663786e": 228, "0448": 228, "4962": 228, "8207": 228, "1419": 228, "3391": 228, "519": 228, "3846": 228, "009784938442900492": 228, "2054": 228, "403206622123": 228, "2211": 228, "5888": 228, "5766": 228, "2586": 228, "3898742580986": 228, "019809144837e": 229, "073e": 229, "9635341891843727": 229, "3374349463048447": 229, "868512": 229, "963534189184372": 229, "3374349463048434": 229, "0022": [229, 243], "9261851600000006": 229, "002202117614788409": 229, "2796668981421906": 229, "8925832494794965": 229, "938893903907228e": [229, 235], "8189853250010287": 229, "8189852974582236": 229, "0802": 229, "877": 229, "000000000000001": 230, "400000000000006e": 230, "13500000000000018": 230, "004515": 230, "99794": 230, "99156": 230, "005985": 230, "008440000000000225": 230, "03195538522499941": 230, "100496": 230, "250112": 230, "049712": 230, "199728": 230, "399952": 230, "0012160000000000712": 230, "019259999999999167": 230, "012549999999999173": 230, "06312542559999734": 230, "05956750249998599": 230, "9999999999999992": 230, "9999999999999982": 230, "3973": 230, "60692": 230, "99578": 230, "5338043228652705": 230, "6555341562499992": 230, "100627": 230, "250553": 230, "04976": 230, "200673": 230, "398387": 230, "0037066666666667053": 230, "ipykernel_1039728": 230, "2878626965": 230, "_stats_pi": 230, "sum_check": 230, "7501": 230, "power_divergenceresult": [230, 246], "62338763": 230, "09949846": 230, "7502": 230, "hypothesis_chisquar": 230, "7504": 230, "e501": 230, "7505": 230, "_power_diverg": 230, "7506": 230, "7317": 230, "7318": 230, "7319": 230, "7320": 230, "relative_diff": 230, "7321": 230, "7322": 230, "7323": 230, "7324": 230, "4901161193847656e": 230, "010101": 230, "153846": 230, "245283": 230, "490566": 230, "264151": 230, "85714285714286": 231, "44897959183674": 231, "7235728659282991": 231, "7735576923076923": 231, "2473831980948553": 231, "87479": 231, "5450724559": 231, "34881185960322647": 231, "928571428571429": 231, "939795": 231, "79591836734694": 231, "908960357975": 231, "000017": 231, "000121": 231, "000471": 231, "001319": 231, "002968": 231, "005698": 231, "009687": 231, "014946": 231, "000138": 231, "000609": 231, "001928": 231, "004896": 231, "010594": 231, "020282": 231, "035228": 231, "999999999999996": 231, "999999999999986": 231, "5222222222222223": 231, "291640885791076": 231, "36794014275523457": 231, "116666666666667": 231, "39437012263098": 231, "349069902429585": 231, "1300": 231, "371900826446": 231, "170": [231, 284], "9807692307692307": 231, "3333333333333406": 231, "84617666410596": 232, "5157582737848507": 232, "07413333143896454": 232, "06191163716561654": 232, "8796270056055946": 232, "166494155672198": 232, "166494155672201": 232, "24157732458970443": 232, "14079792710599145j": 232, "821547577983897": 232, "000000000005244": 232, "440983579653024": 232, "44034": 232, "7055318413112284": 232, "7098006844": 232, "1649348980190553e": 232, "515758273784844": 232, "07413333143901642": 232, "06191163716506498": 232, "8796270056055933": 232, "9686032021920052": 232, "9685984980781974": 232, "9999999999759758": 233, "1518563880485999e": 233, "649038741000833": 233, "64903874100567": 233, "666666666660603": 233, "6575": 233, "208241763338343": 233, "208241761190717": 233, "199268749999998": 233, "035671995651632836": 233, "014465480478890846": 233, "471394837792706": 233, "970488004642451": 233, "003122019680244857": 233, "015529111336782947j": 233, "9999700467109": 233, "197826063638786": 233, "27202": 233, "25174": 233, "265095957990887": 233, "4177051196": 233, "4803669724": 233, "67215": 233, "018665484494152507": 233, "0282392492127608": 233, "1560453396623622": 233, "184447627708847": 233, "433333333333334": 233, "846355555555555": 233, "633933333333333": 233, "991661862222221": 233, "652333333333335": 233, "408194555555555": 233, "0000000000000013": 234, "068965517241385": 234, "0689655172413794": 234, "3400713436385256": 234, "732243001701697": 234, "3979990329137162": 234, "769665911112108": 234, "7322430017017011": 234, "39799903291370464": 234, "5059": 234, "006525189999999": 234, "97880775": 234, "511627906976744": 234, "9961650031958307": 234, "1048": 234, "2096": 234, "2353": 234, "1277": 234, "3143": 234, "5496": 234, "7426": 234, "8704": 234, "9419": 234, "976727427779557": 234, "999999999999982": 234, "3746305205153175": 235, "5149785474168952": 235, "5149785474168951": 235, "437586605774912": 235, "4375866057749125": 235, "941828460653257": 235, "8052046593263178": 235, "32105769": 235, "ipykernel_1040229": 235, "2480825993": 235, "1066768485048402": 235, "1066767722935067": 235, "68208": 235, "6851177504050078": 235, "1418368736": 235, "1545040823250263": 235, "004259": 235, "997521": 235, "5819767068693265": 235, "9206735942077924": 235, "2552519304127614": 235, "086161269630487": 235, "0406518522564083": 235, "9855410710546102": 235, "9855410569229435": 235, "1951784870591609": 235, "78071204285334": 235, "702401395301426e": 235, "4082482904638631": 236, "299299563148505": 236, "3009293789298115": 236, "00111": 236, "9929587679": 236, "00228": 236, "00994": 236, "999994801600001": 236, "968961196399998": 236, "9999999729280461": 236, "9999999729280464": 236, "5089": 236, "508900029898882": 236, "0054530919130093445": 236, "200575108722218": 236, "96158504817696": 236, "097560975609756": 236, "5013649093750003": 236, "7399398087126885": 236, "76247509267191": 236, "7933333333333334": 236, "923955555555557": 236, "6775": 237, "03900275742662621": 237, "17698560749445102": 237, "2220616806986953": 237, "752005": 237, "6768534799749998": 237, "1099999999999999": 237, "06926288077113398": 237, "1184562941320082": 237, "06926288077112831": 237, "1184562941319698": 237, "4700953431353814": 237, "808": 237, "4896": 237, "00132964999999996": 237, "6094379124341003": 238, "6290750483186573": 238, "626635073807003": 238, "1956": 238, "2067": 238, "2079": 238, "3345381516340064": 238, "210": 238, "254": 238, "001663333333333": 239, "952040566655556": 239, "06400386879521874": 239, "06958811620543011": 239, "07692307692307693": 239, "06572870545169307": 239, "896700141704304": 239, "923159111111111": 239, "904492444444444": 239, "928769718257335": 239, "9101030817961346": 239, "49472": 239, "4990721216": 239, "9984984715902749": 239, "998655": 239, "998847831553688": 239, "9992059941388924": 239, "929998999999999": 239, "284579179865933": 239, "275579077706104": 239, "12687630672173225": 239, "4275728197733406": 239, "9975202827806741": 239, "43624": 239, "7678146623999997": 239, "46646": 239, "415": 239, "127058179463747e": 239, "98731101331043": 239, "9999999999999994": 240, "503896885539161": 240, "555555555555555": 240, "0232863517009578": 240, "5208333333333334": 240, "235382907247958": 240, "6061305592752749": 240, "6798440777897914": 240, "5734322687509957": 240, "6747782631823974j": 240, "_discrete_distn": 240, "1834": 240, "466878956783674": 240, "0001069346399162896": 240, "4668784592208555": 240, "661185": 240, "414319395774998": 240, "15873": 240, "05772": 240, "02664": 240, "014208": 240, "873016": 240, "930736": 240, "957376": 240, "971584": 240, "5872600619798414": 240, "1991": 240, "4834873154202": 240, "5961292376240657": 240, "3587": 240, "827": 240, "3609": [240, 269], "785": 240, "821869911711197": 240, "4583050042312996": 240, "61563126252505": 240, "6291776944815863": 240, "50000": 240, "9973": 240, "8061": 240, "483213566153296": 241, "37129111277592": 241, "891549252553807": 241, "885075724224906": 241, "8850757242249063": 241, "85361543255586": 241, "882518427186466": 241, "03586759328104913": 241, "31936532991899086j": 241, "3436470243677288": 241, "700596007114799": 241, "6452": 241, "289": 241, "1532440210312": 241, "286": 241, "57043695999994": 241, "344329": 241, "139841": 241, "017257": 241, "48417": 241, "787082": 241, "347698178395121": 241, "22290111165175": 241, "1749257170027665": 241, "278884110189842": 241, "2397758165626769": 241, "151112295598441": 241, "181215720032025": 241, "5091224145363746": 241, "295206090499907": 241, "2813627254509017": 241, "311823647294589": 241, "025721174006128944": 242, "7695278508490445": 242, "40370944560065425": 242, "40763615075512927": 242, "3479": 242, "3688": 242, "5714": 242, "6443": 242, "7715": 242, "8856": 242, "0426": 242, "015710624639228243": 242, "6263187423964756": 242, "4402203779633993": 242, "4639553339834337": 242, "304717": 243, "039984": 243, "750451": 243, "940565": 243, "951035": 243, "5086": 243, "1001": 243, "0383": 243, "3132": 243, "4740": 243, "5630": 243, "002088": 243, "766": 244, "834": 244, "675": 244, "881": 244, "786": 244, "7666": 244, "052": [244, 254], "4086666666666667": 244, "6696666666666666": 244, "5396": 244, "31111429489836495": 245, "0867": 245, "0404": 245, "1816": 245, "049433": 246, "5785552914362746": 246, "5857282854342913": 246, "6708": 246, "2236": 246, "555555555555557": 246, "01387345776252751": 246, "20682789409984761": 246, "013919721605567889": 246, "5785552914362739": 246, "0138734577625275": 246, "4472": 247, "18619": 247, "266025641025641": 247, "511144": 247, "06531481945948898": 247, "419327083852984e": 247, "3820492834449359": 249, "11140381300226458": 249, "9206856310625974": 249, "08548638452023795": 249, "392486887925362": 249, "7378219350831077": 249, "2706": 249, "6145": 249, "9056": 249, "3027": 249, "7720": 249, "6496": 249, "9559": 249, "5124": 249, "3100": 249, "9031": 249, "9909334640191727": 249, "4425017266737616": 249, "00000000e": 251, "04895105e": 251, "10139860e": 251, "30419580e": 251, "67132867e": 251, "57342657e": 251, "36013986e": 251, "74125874e": 251, "024475524475524438": 251, "9991258741258742": 251, "03496503496503492": 251, "024476": 251, "999126": 251, "034965": 251, "03565": 251, "325": 252, "673": 252, "725": [252, 256, 262], "389": 252, "517": 252, "719": 252, "8165": 252, "000079": 252, "8041": 252, "6745": 252, "816476": 252, "9763e": 252, "5383333333333333": 252, "045": 252, "04833333333333333": 252, "746899": 253, "760026": 253, "733429": 253, "792990": 253, "783612": 253, "806848": 253, "793979": 253, "835027": 253, "746782": 253, "770176": 253, "827571": 253, "810202": 253, "683131": 253, "721469": 253, "712109": 253, "741547": 253, "697234": 253, "716301": 253, "710524": 253, "756548": 253, "950000000000045": 253, "999750012499375e": 253, "6937500000000006": 253, "083333": 253, "708333": 253, "875000": 253, "950000": 253, "18748e": 253, "99975e": 253, "102041": 253, "04458e": 253, "8500000000000227": 253, "8501574921253937": 253, "011805555555555871": 253, "6762": [254, 263], "093": 254, "2202": 254, "243": 254, "379": 254, "071": 254, "870": 255, "489125293076057": 255, "654": 255, "05514334949238031": 256, "027218963900686455": 256, "498639097854449": 256, "3375": 256, "39264334949238033": 256, "9604079184163168": 256, "9636165170896432": 256, "2747444532695955": 256, "0035513851998576484": 256, "1966034782973949": 256, "45025554673040447": 256, "0001999600079984003": 256, "934385383992118e": 256, "18472222222222223": 256, "026124833534033623": 256, "37777777777777777": 256, "08322919270182455": 256, "09825246208122136": 256, "600000000000001": 257, "05398920215956809": 257, "7284": 257, "007499": 257, "083": 257, "433": 257, "0437": 257, "8297": 257, "99506": 257, "8785": 257, "38188910789173036": 258, "7025437321638381": 258, "3818891078917334": 258, "7025436197478272": 258, "08531513314186485": 258, "9320107311880461": 258, "897119191236123": 258, "970149253731343": 258, "11136036352709348": 258, "138267812060432": 258, "666621285524464": 258, "6790": 259, "477": 259, "1864": 259, "0895": 259, "052857": 259, "040000": 259, "067143": 259, "041429": 259, "9872234195640509": 260, "7597615779329113": 260, "9504917274585137": 260, "7089964448880488": 260, "224": 260, "024098795060246987": 260, "2360857240006173": 260, "025346156404938203": 260, "3600000000000001": 260, "3071499960863374": 260, "1307394221048977": 260, "010240851796336825": 260, "x86_64": 261, "glibc2": 261, "429": 261, "017149022768408462": 261, "6010": 262, "6416": 262, "756e": 262, "28446912567606": 263, "844945693858993": 263, "0542446701518544": 263, "6992762958243015": 263, "5604765681829329": 263, "01879906004699765": 263, "3385": 263, "0269": 263, "2484": 263, "0782": 263, "6450316256724471": 263, "011899405029748513": 263, "5770377629999737": 263, "05504724763761812": 263, "2227": 263, "5949": 263, "3792": 263, "5078": 263, "003983194961544123": 264, "979806008441165": 264, "901827954731168": 264, "33403897478489747": 264, "1391470464804974": 264, "25464193619392184": 264, "0681651963774472": 264, "204306467065742": 264, "001354010697767749": 264, "314018629424382": 264, "399094653879995": 264, "713003297686981e": 264, "616686399904669": 264, "78336467838644": 264, "344590824409636e": 264, "672295412204818e": 264, "9999999963277046": 264, "010093399552716806": 264, "9999562884320329": 264, "0476": 264, "5556762139133857": 264, "304601238442498": 264, "3449606122843268e": 264, "9582": 265, "8908": 265, "9550": 265, "6760694827820508": 266, "1448991639983137": 266, "04670272951904608": 266, "011058309525378007": 266, "3410806560387236": 266, "897981559364187": 266, "3018367277038695": 266, "97827544805771": 266, "33553605768968287": 266, "9311915269948647": 266, "32751807158712576": 266, "1793406145972717": 266, "48117734230114123": 266, "7546575962141199": 266, "1955516622986013": 266, "0182971425705634": 266, "3143669449743095": 266, "9000228288264907": 266, "29634937341875167": 266, "903508293293421": 266, "7405904074002199": 266, "0998231022246423": 266, "19165794524122026": 266, "9986745318280623": 266, "07036480566932": 266, "97387309896274": 266, "035389987592057665": 267, "8310923822923664": 267, "6753054649687451": 267, "7321879696862332": 267, "3101": 267, "00171715": 267, "0354": 267, "6753": 267, "7107": 267, "2147": 267, "1417": 267, "2797": 267, "9108": 267, "00189875": 267, "2163": 267, "1455": 267, "2759": 267, "9074": 267, "1784": 267, "00255332": 267, "8589": 267, "8943": 267, "2814": 267, "4596": 267, "3290": 267, "04875": 267, "3100619557330977": 267, "00171714967615853": 267, "0017171497826875548": 267, "286069304555434": 267, "0018987486385477889": 267, "2860693045554346": 267, "001898748756941293": 267, "85930307250626": 268, "340805958609465": 268, "4815028861032147": 268, "628114155415627": 268, "6623999880416477": 268, "7462302700814556": 268, "6839649415107614": 268, "0009": 268, "1329486494524064": 268, "830057122754023": 268, "0007931638812911782": 268, "1267427956120888": 268, "8362629765943406": 268, "7343483866156": 269, "124737477155004": 269, "9034": 269, "248": 269, "4376": 269, "1813": 269, "2406": 269, "0312": 269, "5181": 269, "699": 269, "3066": 269, "235": 269, "0510021553137605": 269, "30644215697136534": 269, "983304": 270, "364337": 270, "776162": 270, "892147": 270, "95964": 270, "335939": 270, "499282": 270, "001827239990234375": 270, "7795950541624563": 270, "wilcoxonresult": 270, "0025555243609691396": 270, "0017": 270, "european": 389, "bond": [389, 391], "arbitrag": 389, "frictionless": 389, "exercis": 389, "matur": 389, "black_scholes_cal": 389, "black_scholes_put": 389, "black_scholes_delta": 389, "option_typ": 389, "black_scholes_vega": 389, "call_payoff": 389, "put_payoff": 389, "call_pric": 389, "put_pric": 389, "__getattr__": 389, "attr": 389, "330": 389, "331": 389, "tester": 389, "sig_val": 389, "s_mesh": 389, "sig_mesh": 389, "c_surfac": 389, "delta_cal": 389, "markowitz": 393, "tangenc": 393, "n_asset": 393, "randn": [286, 287, 289, 292, 393], "n_portfolio": 393, "portfolio_return": 393, "portfolio_vol": 393, "risk_fre": 393, "max_sharpe_idx": 393, "min_vol_idx": 393, "frontier_r": 393, "frontier_v": 393, "sel_vol": 393, "sel_ret": 393, "vol": 393, "r_f": [393, 394], "beta_m": 394, "mkt": 394, "smb": 394, "beta_h": 394, "hml": 394, "abnorm": [284, 322, 394], "true_alpha": 394, "excess_ret": 394, "betas_hat": 394, "002565914382535999": 394, "07486223": 394, "36082155": 394, "15714763": 394, "cumprod": 394, "idiosyncrat": 394, "ipython": [389, 393, 394], "show_plot": [389, 393, 394], "to_html": [389, 393, 394], "include_plotlyj": [389, 393, 394], "full_html": [389, 393, 394], "r_p": 393, "sigma_p": 393, "pagin": [], "websocket": [0, 4], "oauth2": 2, "jwt": [], "abac": 2, "rpc": 4, "sent": 4, "bidirect": 4, "realtim": 4, "breaker": [4, 7], "crud": 4, "listen": 4, "93smirnov_test": 256, "mase": [280, 299, 303], "naive_denom": 280, "period_rang": [280, 296, 301, 303, 306], "forecast_na": 280, "horizon_index": 280, "forecast_seasonal_na": 280, "last_season": 280, "forecast_moving_averag": 280, "mean_val": 280, "pred_naiv": 280, "pred_season": 280, "pred_ma": 280, "compute_metr": 280, "163": 280, "710": 280, "412": 280, "059": 280, "056": 280, "857": 280, "267": 280, "618": 280, "549": 280, "scale_depend": 280, "scale_fre": 280, "metrics_long": 280, "x10": 280, "test_outli": 280, "outlier_effect": 280, "544": 280, "439": 280, "687": 280, "364": 280, "disproportion": 280, "crp": 280, "winkler": 280, "anomalydetector": [], "seriesannot": [], "catch22": [], "edr": [], "boss": 286, "weasel": 286, "shapelet": 288, "data_sci": [284, 285, 295, 322], "time_seri": [284, 285, 295, 322], "sktime_algorithm": [284, 285, 295, 322], "get_start": 285, "api_refer": 285, "auto_gener": 285, "_tag": 285, "object_typ": 285, "base_class_regist": 285, "class_ref": 285, "exc": [285, 286, 287, 288, 289, 292, 300, 312, 313, 314, 315, 316, 317, 318], "all_estim": [285, 286, 287, 288, 289, 292, 300, 311, 312, 313, 314, 315, 316, 317, 318], "treemap": [285, 311, 312, 313, 314, 315, 316, 317], "as_datafram": [285, 286, 287, 288, 289, 292, 300, 318], "return_tag": 285, "estimator_typ": [285, 286, 287, 288, 289, 292, 300, 311, 312, 313, 314, 315, 316, 317, 318], "all_tag": 285, "filter_tag": 285, "to_list": 285, "value_count": [285, 311, 312, 313, 314, 315, 316, 317], "scityp": [284, 295, 311, 312, 313, 314, 315, 316, 317, 322], "verb": 1, "get_us": 1, "refresh": [2, 316], "alg": 2, "hs256": 2, "user123": 2, "1710000000": 2, "safest": 5, "bulkhead": 7, "pyramid": 8, "mfa": 11, "mortem": [12, 363], "ddo": 13, "broken": 14, "ssrf": 14, "attack": 15, "sbom": 16, "1959": [], "1957": [], "1958": [], "airlin": 271, "hourli": [271, 300], "periodindex": 271, "loess": 271, "dickei": 271, "fuller": 271, "abla": 271, "adf_stat": 271, "adf_p": 271, "kpss_stat": 271, "kpss_p": 271, "ho_k": 271, "fanci": 271, "slidingwindowsplitt": [271, 299, 310], "step_length": [271, 310], "toolkit": 271, "disciplin": 271, "taxonomi": [], "dictionary_bas": 286, "shapelet_bas": [292, 293], "intermitt": [], "croston": [], "sba": [], "tsb": [], "intermittent_demand": [], "fed": 286, "alphabet": 286, "abcd": 286, "to_symbol": 286, "_estimators_df": [286, 287, 289, 292], "__module__": [286, 287, 289, 292, 311, 312, 313, 314, 315, 316, 317], "df_dict": 286, "unavail": [286, 287, 289, 292], "motif": [286, 292], "dtw_cost_path": 287, "df_distanc": 287, "kneighborstimeseriesclassifi": 287, "phi_k": 289, "polyfit": [289, 308, 318], "features_df": 289, "650330": 289, "462681": 289, "037496": 289, "643084": 289, "257621": 289, "839211": 289, "198921": 289, "012329": 289, "225615": 289, "632476": 289, "i3": 289, "114": 289, "787726": 289, "371754": 289, "114739": 289, "322912": 289, "376118": 289, "i4": 289, "492651": 289, "478912": 289, "060491": 289, "129733": 289, "615441": 289, "i5": 289, "373543": 289, "264580": 289, "095520": 289, "024957": 289, "739853": 289, "i6": 289, "630118": 289, "401690": 289, "026529": 289, "597618": 289, "df_interv": 289, "timeseriesforestclassifi": 289, "insert_at": 292, "distance_profil": 292, "df_shapelet": 292, "han": 293, "afford": [288, 293], "2a3f5f": [299, 305, 308], "train_start": 299, "train_end": 299, "test_start": 299, "test_end": 299, "y_true_al": 299, "y_pred_al": 299, "naive_diff": 299, "197256": 299, "169641": 299, "968146": 299, "expandingwindowsplitt": [299, 310], "forecastinggridsearchcv": [299, 310], "normaldist": 305, "forecast_idx": [305, 308], "mean_forecast": 305, "q_forecast": 305, "inv_cdf": 305, "fdebd0": 305, "f6ddcc": 305, "f5cba7": 305, "edbb99": 305, "e59866": 305, "dc7633": 305, "sim_n": 305, "interval_80": 305, "788": 305, "predict_interv": 305, "predict_quantil": 305, "predict_var": 305, "dirrec": 308, "mock": 308, "recursive_pr": [306, 308], "direct_pr": [306, 308], "multi_pr": 308, "make_reduct": [306, 308], "_resolve_all_estim": [311, 312, 313, 314, 315, 316, 317], "sktime_avail": [311, 312, 313, 314, 315, 316, 317], "_err": [311, 312, 313, 314, 315, 316, 317], "get_class_tag": [311, 312, 313, 314, 315, 316, 317], "learning_typ": [311, 312, 313, 314, 315, 316, 317], "module_famili": [311, 312, 313, 314, 315, 316, 317], "missing_valu": 311, "unequal_length": 311, "fillna": [311, 315], "_safe_tag": [312, 313, 314, 315, 316, 317], "_matches_scityp": [312, 313, 314, 315, 316, 317], "_top_tag_kei": [312, 313, 314, 315, 316, 317], "tag_dict": [312, 313, 314, 315, 316, 317], "tag_kei": [312, 313, 314, 315, 316, 317], "bool_tag": [312, 313, 314, 315, 316, 317], "share_tru": [312, 313, 314, 315, 316, 317], "shortlist": 312, "series_a": 313, "series_b": 313, "series_": 315, "make_seri": 319, "deseason": [301, 323], "windowsummar": [323, 328, 329], "fourierfeatur": [323, 327], "boxcox": 323, "lag_1": [323, 328], "lag_12": [323, 328], "roll_mean_12": 323, "152359": 323, "530008": 323, "207276": 323, "620282": 323, "956533": 323, "598910": 323, "363920": 323, "808121": 323, "340451": 323, "976522": 323, "792352": 323, "061104": 323, "204228": 323, "633015": 323, "244283": 323, "213621": 323, "384584": 323, "665805": 323, "422795": 323, "runbook": 363, "sli": [380, 408], "forens": 381, "trail": 381, "viz": 381, "opentelemetri": 381, "eu": 381, "west": 381, "scrape": 381, "joinabl": 381, "tracer": 381, "start_trac": 381, "logger": 381, "timer": 381, "request_complet": 381, "http_errors_tot": 381, "request_fail": 381, "AND": 381, "mitig": 381, "unstructur": 381, "annuiti": 396, "aria": 399, "xss": 400, "csrf": 400, "clickjack": 400, "csp": 400, "samesit": 400, "dom": 403, "cssom": 403, "shorten": 405, "pacelc": 406, "quorum": 406, "clarifi": 407, "dive": [283, 407], "cqr": 410, "mtype": 283, "brows": [283, 284], "06_annotation_catalog": [284, 322], "var_avg": 288, "cote": 288, "to_str": [288, 300, 318], "archetyp": [295, 316], "_make_group": 295, "05_clusterer_catalog": 295, "multiindex": 296, "panel_long": 296, "north": 296, "south": 296, "from_product": 296, "g_effect": 296, "s_effect": 296, "hier": 296, "promo": 296, "season_daili": 300, "season_weekli": 300, "t_short": 300, "sum_m": 301, "2012": 301, "naive_forecast": 301, "seasonal_templ": 301, "seasonal_na": 301, "934244175340366": 301, "2139413746873176": 301, "9922014053496209": 301, "forecastingpipelin": 301, "multiplexforecast": 301, "ensembleforecast": 301, "stackingforecast": 301, "polynomialtrendforecast": 301, "multiplex": 301, "spare": 303, "synteto": 303, "boylan": 303, "teunter": 303, "babai": 303, "p_demand": 303, "croston_forecast": 303, "z_hist": 303, "p_hist": 303, "f_hist": 303, "f_croston": 303, "tsb_forecast": 303, "f_sba": 303, "f_tsb": 303, "z_tsb": 303, "p_tsb": 303, "irregularli": 303, "make_lag_matrix": 306, "lag_": [306, 328], "fit_direct_model": 306, "y_h": 306, "x_h": 306, "last_window": 306, "direct_index": 306, "plot_cv_split": 310, "splitter": 310, "max_split": 310, "fh_step": 310, "cv_slide": 310, "cv_expand": 310, "initial_window": 310, "gscv": 310, "best_forecast": 310, "best_forecaster_": 310, "proto": 316, "change_point": [317, 322], "anom": [317, 322], "n_seri": 318, "lightsalmon": 318, "thousand": 318, "timeseriesforest": 318, "drcif": 318, "tau_1": 322, "tau_2": 322, "ell_t": 322, "tau_": 322, "tau_k": 322, "112": 322, "iou": 322, "rangeindex": [327, 328, 329], "774018": 327, "214326": 327, "206555": 327, "401972": 327, "662917": 327, "basis_fig": 327, "tbat": 327, "014315": 328, "288076": 328, "119692": 328, "808723": 328, "458697": 328, "make_lag": 328, "df_lag": 328, "lag_2": 328, "lag_3": 328, "183091": 328, "299466": 328, "229017": 328, "742646": 328, "224513": 328, "scatter_df": 328, "224618": 329, "151616": 329, "350909": 329, "144355": 329, "268918": 329, "w_short": 329, "w_long": 329, "df_roll": 329, "roll_mean_": 329, "roll_std_": 329, "roll_mean_7": 329, "roll_mean_30": 329, "roll_std_7": 329, "275296": 329, "290944": 329, "672380": 329, "828287": 329, "992565": 329, "782086": 329, "954815": 329, "106518": 329, "061358": 329, "023125": 329, "040663": 329, "159894": 329, "975400": 329, "078670": 329, "436225": 329, "431686": 329, "221704": 329, "429480": 329, "435091": 329}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"backend": 0, "api": [1, 301, 303, 306, 382], "design": [1, 4, 263, 404, 407], "auth": 2, "secur": [2, 13, 14, 400], "cach": 3, "queue": [3, 355], "data": [5, 17, 19, 21, 22, 31, 34, 70, 73, 125, 151, 163, 189, 208, 225, 241, 242, 253, 260, 263, 267, 268, 291, 296, 353, 394, 401], "storag": [5, 352], "model": [5, 15, 19, 22, 26, 36, 37, 38, 46, 47, 49, 51, 59, 70, 72, 75, 81, 86, 87, 88, 91, 92, 93, 94, 96, 97, 98, 99, 100, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 120, 121, 122, 124, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 249, 290, 291, 294, 297, 298, 300, 304, 306, 307, 310, 315, 320, 331, 332, 333, 334, 335, 358, 385, 389, 394, 406], "observ": [6, 41, 78, 113, 125, 141, 159, 226, 312, 380, 381], "resili": 7, "perform": [7, 399], "test": [8, 49, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 304, 307, 402], "qualiti": 8, "knowledg": 9, "archiv": [9, 138], "how": [9, 35, 41, 46, 53, 69, 74, 77, 84, 88, 95, 101, 110, 112, 113, 114, 116, 122, 141, 161, 166, 204, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 256, 257, 261, 262, 265, 267, 270, 312, 313, 314, 315, 316, 317, 331, 332, 333, 358, 359, 365, 367, 369, 371, 372, 373, 374, 376, 379, 381, 382, 383, 384, 385, 386], "us": [4, 9, 26, 29, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 107, 111, 112, 113, 114, 119, 125, 135, 140, 144, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 245, 246, 247, 249, 251, 253, 254, 255, 257, 259, 260, 262, 264, 265, 266, 267, 268, 269, 270, 286, 287, 288, 289, 292, 293, 297, 298, 300, 304, 307, 309, 312, 313, 314, 315, 316, 317, 331, 332, 333, 334, 335, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 382, 383, 384, 385, 386], "thi": [9, 93, 95, 98, 142, 143, 146, 169, 170, 175, 180, 185, 188, 190, 195, 197, 202, 205, 208, 209, 214, 218, 219, 226, 227, 230, 231, 232, 233, 234, 235, 236, 237, 240, 247, 312, 313, 314, 315, 316, 317, 328, 329, 371], "core": [0, 4, 9, 10, 25, 69, 108, 112, 129, 137, 162, 243, 247, 255, 256, 259, 260, 263, 264, 266, 271, 285, 286, 287, 288, 289, 292, 296, 306, 318, 323, 330, 331, 332, 333, 334, 335, 338, 340, 341, 342, 344, 347, 348, 355, 358, 359, 382, 387, 397, 400, 404], "categori": [9, 108, 230, 246, 247], "cybersecur": 10, "ident": [11, 81, 161], "access": [11, 385, 399], "incid": [12, 363, 381], "respons": [12, 114, 117, 118, 363], "network": [13, 19, 21, 22, 134, 137, 138, 139, 140, 144, 358, 359], "cloud": [13, 342, 353, 357], "code": [14, 143, 331, 332, 333, 334, 335, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 362], "owasp": 14, "threat": 15, "vulner": 16, "manag": [16, 350, 358, 371], "scienc": 17, "deep": [18, 137, 138, 139, 278], "learn": [18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 37, 39, 46, 47, 50, 51, 53, 56, 57, 64, 65, 67, 69, 70, 72, 73, 77, 81, 83, 84, 86, 87, 88, 89, 91, 92, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 119, 122, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 148, 149, 150, 152, 154, 155, 157, 158, 160, 162, 163, 164, 165, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 186, 187, 188, 191, 192, 193, 196, 198, 199, 200, 201, 203, 204, 206, 207, 209, 210, 211, 213, 215, 216, 217, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 242, 243, 244, 246, 247, 248, 249, 250, 251, 253, 254, 255, 256, 257, 258, 259, 260, 263, 264, 265, 266, 267, 268, 269, 270, 278, 279, 285, 295], "linear": [19, 23, 26, 28, 30, 86, 87, 89, 90, 94, 96, 97, 100, 101, 104, 106, 107, 113, 136, 262, 306], "algebra": [23, 30, 107], "machin": [24, 109, 279, 296], "reinforc": 133, "statist": [26, 30, 35, 114, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 246, 247, 249, 250, 252, 253, 254, 256, 257, 258, 260, 263, 266, 267, 268, 269, 270], "time": [20, 114, 118, 125, 126, 128, 132, 271, 272, 273, 274, 275, 280, 281, 282, 284, 285, 286, 287, 288, 289, 292, 295, 310, 312, 313, 314, 315, 316, 318, 326, 328, 396], "seri": [20, 118, 119, 120, 125, 126, 128, 132, 171, 271, 272, 273, 274, 275, 280, 281, 282, 284, 285, 286, 287, 288, 289, 292, 295, 296, 297, 298, 303, 310, 312, 313, 314, 315, 316, 317, 318, 322, 323, 326, 328], "devop": 330, "ci": [245, 266, 332, 333, 336], "cd": [331, 332, 333, 336], "containeris": [358, 359], "cost": [28, 361], "capac": 361, "iac": [], "kubernet": [331, 344, 364], "sre": 380, "telemetri": 381, "displai": 381, "financ": [26, 113, 387], "deriv": [73, 88, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 388], "econometr": 390, "fix": [232, 391], "incom": 391, "portfolio": 392, "risk": 395, "valu": [86, 91, 134, 138, 139, 140, 141, 143, 144, 146, 172, 221, 229, 239, 243, 244, 245, 246, 247, 248, 250, 251, 254, 256, 258, 260, 262, 263, 264, 266, 267, 268, 269, 270, 312, 314, 396], "monei": 396, "frontend": [397, 400, 402], "framework": 398, "architectur": [333, 381, 386, 398], "state": [20, 113, 378, 401], "web": [134, 141, 142, 403], "fundament": [1, 403], "project": 32, "ckc": [], "regist": [], "system": [118, 123, 404], "case": [26, 37, 41, 46, 53, 65, 72, 77, 81, 84, 86, 87, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 102, 107, 111, 119, 125, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 405], "studi": 405, "consist": 406, "checklist": [25, 30, 107, 244, 247, 259, 262, 296, 310, 407], "reliabl": 408, "dr": 408, "requir": [112, 113, 114, 116, 122, 123, 368, 409], "tradeoff": [117, 409], "scalabl": 410, "pattern": [2, 3, 4, 21, 22, 112, 203, 262, 301, 313, 331, 332, 333, 371, 378, 410], "overview": [0, 10, 17, 18, 23, 24, 133, 147, 271, 276, 283, 285, 330, 387, 397, 404], "plan": [], "track": 113, "next": [135, 137, 253, 284, 295, 322], "step": [20, 25, 27, 28, 30, 112, 113, 114, 121, 127, 131, 132, 134, 142, 143, 146, 154, 195, 252, 253, 284, 295, 322, 356], "section": [], "navig": [], "tip": [19, 103, 253, 303, 318, 323, 331, 332, 333, 334, 335, 338, 340, 341, 342, 344, 347, 349, 350, 357, 358, 359, 385], "notebook": [21, 22, 126, 128, 130, 134, 135, 136, 137, 139, 140, 142, 143, 144, 146, 157, 158, 159, 162, 163, 169, 176, 180, 183, 185, 186, 189, 190, 191, 194, 195, 197, 198, 201, 205, 208, 209, 211, 212, 213, 214, 216, 218, 219, 221, 223, 229, 234, 235, 237, 238, 240, 241, 257], "artifici": 19, "neural": [19, 21], "mlp": 19, "tabular": [19, 33, 68, 85, 139, 306], "goal": [19, 21, 22, 25, 26, 28, 30, 31, 32, 36, 39, 41, 46, 47, 49, 50, 51, 53, 56, 57, 65, 67, 70, 72, 73, 75, 77, 81, 84, 86, 87, 88, 89, 91, 92, 94, 96, 97, 98, 99, 100, 103, 104, 106, 107, 108, 109, 110, 111, 114, 115, 117, 118, 121, 122, 123, 125, 127, 134, 135, 137, 138, 140, 141, 143, 144, 145, 148, 149, 150, 154, 155, 158, 160, 164, 165, 166, 167, 170, 171, 172, 175, 176, 177, 178, 179, 187, 191, 192, 199, 204, 206, 207, 210, 216, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 242, 243, 244, 246, 247, 248, 250, 252, 253, 254, 255, 256, 257, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 331, 332, 333, 334, 335, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 371, 381, 382, 383, 384, 385, 386], "notat": [19, 25, 26, 30, 31, 32, 34, 47, 51, 53, 56, 67, 72, 83, 89, 93, 101, 102, 103, 105, 107, 109, 110, 119, 141, 143, 153, 154, 162, 163, 183, 185, 186, 187, 194, 195, 198, 201, 209, 211, 212, 213, 218, 284, 285, 295, 303, 308, 312, 313, 314, 315, 316, 317, 322, 323], "quick": [19, 21, 22, 25, 30, 31, 37, 40, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 87, 88, 92, 93, 100, 101, 102, 107, 112, 121, 134, 157, 243, 245, 248, 249, 252, 261, 266, 267, 299, 311, 323, 331, 332, 333, 334, 335, 338, 340, 341, 342, 344, 347, 349, 350, 354, 357, 358, 359], "tabl": [19, 25, 26, 30, 31, 32, 47, 51, 56, 57, 67, 69, 70, 77, 81, 84, 103, 104, 106, 107, 108, 109, 110, 154, 170, 187, 226, 230, 232, 233, 236, 239, 246, 248, 251, 261, 263], "content": [19, 25, 26, 30, 31, 32, 47, 51, 56, 57, 67, 77, 103, 104, 106, 107, 108, 109, 110, 154, 170, 187, 226, 230, 233, 236, 239, 248, 263], "1": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 51, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 122, 123, 125, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 270, 271, 280, 312, 313, 358, 386], "what": [4, 19, 22, 27, 29, 30, 45, 47, 65, 67, 70, 72, 75, 78, 83, 84, 89, 102, 103, 105, 107, 110, 111, 112, 113, 114, 116, 117, 118, 119, 123, 135, 139, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 285, 295, 322, 331, 332, 333, 334, 335, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 371, 382, 384, 386], "make": [19, 59, 72, 100, 135, 251, 270, 271, 297, 298], "special": [19, 132, 173, 211, 218, 221, 249, 271], "2": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 51, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 122, 123, 125, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 270, 271, 280, 358, 386], "A": [19, 32, 34, 35, 51, 73, 74, 83, 91, 93, 100, 101, 102, 105, 108, 110, 113, 140, 141, 143, 144, 146, 149, 153, 159, 161, 162, 164, 166, 169, 172, 174, 175, 177, 183, 195, 197, 201, 205, 206, 208, 213, 214, 218, 225, 226, 227, 229, 230, 231, 232, 233, 234, 236, 237, 239, 241, 242, 243, 245, 246, 250, 251, 252, 255, 257, 260, 261, 263, 268, 270, 313], "tini": [19, 21, 22, 83, 93, 101, 102, 140, 141, 146, 247, 255, 257], "nonlinear": [19, 27, 262], "dataset": [19, 21, 22, 84, 100, 105, 140, 243, 253, 275, 313, 319], "why": [19, 20, 22, 26, 30, 34, 36, 37, 38, 41, 49, 53, 56, 67, 69, 70, 73, 78, 86, 90, 92, 93, 94, 96, 98, 99, 100, 103, 104, 105, 107, 108, 109, 111, 113, 116, 117, 119, 121, 131, 132, 134, 141, 143, 146, 148, 151, 155, 160, 171, 175, 178, 207, 210, 242, 243, 246, 247, 249, 250, 255, 259, 261, 262, 264, 265, 266, 268, 288, 291, 296, 323, 331, 332, 333, 365, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379, 381, 382, 383, 384, 385, 386], "scale": [19, 29, 30, 59, 74, 92, 93, 97, 98, 103, 105, 109, 122, 149, 151, 154, 156, 161, 162, 163, 164, 165, 167, 168, 169, 171, 172, 173, 175, 177, 178, 180, 187, 188, 194, 196, 197, 198, 199, 200, 203, 204, 206, 207, 208, 213, 215, 216, 219, 220, 221, 255, 371], "matter": [19, 32, 38, 53, 69, 105, 116, 125, 138, 264, 296, 323], "3": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 51, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 116, 117, 118, 122, 123, 125, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 270, 271, 280, 358, 381, 386], "baselin": [19, 46, 86, 87, 100, 117, 123, 134, 136, 138, 140, 141, 142, 143, 145, 146, 271, 280, 301], "logist": [19, 34, 36, 37, 38, 45, 46, 51, 56, 57, 59, 65, 67, 69, 75, 78, 103, 168, 174, 181], "regress": [19, 34, 36, 37, 38, 45, 46, 51, 56, 57, 59, 65, 67, 69, 75, 78, 85, 86, 89, 90, 91, 93, 94, 95, 96, 97, 100, 101, 102, 103, 104, 105, 107, 109, 110, 112, 122, 125, 126, 130, 132, 250, 282, 314, 318, 319], "boundari": [19, 105, 174, 184], "4": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 51, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 116, 117, 118, 122, 123, 125, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 245, 247, 248, 249, 250, 251, 252, 253, 255, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 270, 271, 280], "from": [19, 20, 21, 22, 25, 28, 29, 30, 31, 34, 35, 36, 38, 39, 46, 49, 56, 57, 59, 64, 65, 67, 73, 74, 75, 77, 78, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 107, 109, 110, 112, 113, 115, 118, 125, 136, 138, 139, 143, 144, 145, 150, 171, 179, 206, 243, 244, 245, 246, 247, 250, 251, 252, 257, 259, 260, 261, 266, 267, 268, 269, 303], "scratch": [19, 20, 21, 22, 25, 28, 30, 31, 34, 35, 36, 38, 46, 49, 57, 59, 65, 67, 74, 75, 77, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 107, 109, 110, 112, 115, 118, 125, 136, 138, 139, 143, 144, 145, 243, 245, 246, 247, 251, 257, 259, 260, 266, 268, 269, 303], "layer": [19, 135, 136], "numpi": [19, 20, 21, 22, 25, 34, 35, 38, 46, 47, 49, 51, 56, 57, 59, 64, 65, 67, 73, 74, 75, 77, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 105, 110, 112, 113, 116, 118, 119, 122, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 172, 174, 175, 176, 177, 178, 179, 182, 183, 186, 187, 189, 190, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 217, 218, 219, 220, 221, 222, 223, 225, 227, 229, 231, 234, 235, 237, 238, 240, 241, 243, 244, 246, 247, 248, 249, 251, 257, 259, 260, 264, 266, 267, 268, 269, 270], "forward": [19, 20], "pass": 19, "binari": [19, 34, 37, 46, 50, 51, 53, 56, 57, 108], "classif": [19, 33, 34, 37, 51, 53, 56, 59, 67, 103, 105, 109, 110, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 273, 286, 287, 288, 289, 292, 313], "5": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 51, 53, 56, 57, 59, 64, 69, 70, 73, 74, 75, 77, 78, 81, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 112, 113, 116, 117, 118, 122, 123, 125, 134, 136, 137, 138, 139, 140, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 270, 271, 280], "practic": [19, 20, 21, 22, 25, 26, 27, 30, 32, 34, 35, 36, 37, 52, 64, 74, 81, 83, 87, 88, 89, 91, 92, 94, 96, 97, 98, 101, 102, 103, 105, 107, 109, 110, 112, 119, 125, 142, 181, 242, 243, 244, 245, 246, 247, 250, 251, 252, 253, 254, 257, 258, 259, 260, 261, 262, 264, 266, 267, 268, 269, 285, 296, 299, 303, 305, 308, 318, 323, 327, 334, 335, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 359, 374, 375, 385], "same": [19, 20, 53, 84, 100, 139, 247, 260, 266], "pytorch": [19, 20, 21, 22, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146], "6": [19, 20, 22, 25, 26, 27, 30, 31, 32, 35, 36, 37, 38, 41, 45, 46, 49, 52, 53, 57, 59, 64, 69, 70, 73, 74, 75, 77, 78, 81, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 116, 117, 118, 123, 134, 136, 138, 139, 140, 142, 143, 144, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 270, 271, 280], "compar": [19, 28, 46, 59, 100, 110, 157, 252, 264, 268, 303], "diagnost": [19, 20, 21, 22, 29, 38, 46, 49, 50, 52, 53, 67, 73, 74, 83, 84, 89, 91, 93, 94, 97, 98, 101, 102, 112, 113, 114, 116, 121, 122, 134, 138, 139, 140, 142, 144, 145, 242, 243, 248, 249, 255, 256, 257, 258, 260, 263, 265, 266, 267, 268, 270, 297, 298], "7": [19, 20, 22, 25, 27, 30, 35, 36, 37, 38, 41, 45, 46, 53, 57, 64, 69, 70, 73, 74, 75, 77, 78, 81, 83, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 116, 117, 118, 123, 134, 136, 138, 139, 140, 142, 143, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 247, 248, 249, 250, 251, 252, 254, 255, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 270, 271], "real": [19, 119, 122, 148, 150, 151, 152, 153, 154, 155, 157, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 314, 334], "8": [19, 21, 22, 25, 35, 37, 38, 45, 52, 53, 57, 64, 69, 70, 73, 74, 77, 78, 89, 92, 93, 94, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 112, 113, 116, 117, 123, 134, 140, 142, 143, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 247, 248, 249, 250, 251, 252, 255, 257, 260, 261, 262, 264, 265, 266, 267, 268, 271], "exercis": [19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 116, 117, 122, 123, 134, 138, 140, 142, 224, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 331, 332, 333, 334, 335, 358, 359, 382, 383, 384, 385, 386], "refer": [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 113, 116, 117, 119, 122, 123, 133, 134, 136, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 160, 163, 165, 169, 173, 177, 189, 190, 197, 201, 205, 220, 225, 234, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 269, 270, 272, 273, 274, 276, 277, 278, 279, 282, 331, 332, 333, 334, 335, 338, 339, 340, 341, 342, 344, 347, 349, 350, 357, 358, 359, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 381, 382, 383, 384, 385, 386], "lstm": 20, "gru": 20, "forecast": [20, 112, 115, 116, 117, 120, 121, 123, 124, 125, 127, 131, 132, 271, 276, 277, 278, 279, 280, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312], "0": [20, 34, 57, 67, 77, 86, 93, 98, 182, 187, 197, 199, 229, 250, 253, 261, 262], "problem": [20, 31, 45, 245, 249, 250, 263], "setup": [20, 47, 139, 140, 266, 284, 295, 312, 313, 314, 315, 316, 317, 359], "one": [20, 47, 51, 64, 90, 91, 93, 104, 107, 112, 119, 127, 131, 132, 143, 243, 246, 256, 257, 266, 306], "ahead": [20, 112], "gate": 20, "rnn": 20, "help": [20, 22, 108, 251, 268, 288], "explicit": 20, "memori": [20, 358], "cell": 20, "fewer": 20, "separ": [20, 74, 83, 185], "bptt": 20, "visual": [20, 21, 22, 26, 27, 28, 30, 31, 36, 41, 64, 70, 74, 81, 84, 91, 110, 116, 134, 140, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 245, 247, 248, 249, 251, 254, 255, 257, 262, 265, 268, 269, 270, 281, 285, 287, 293, 304, 307, 323, 393], "idea": [20, 25, 26, 103, 109, 112, 143, 169, 203, 221, 243, 249, 255, 259, 260, 264, 266, 286, 287, 288, 289, 292, 293, 306, 318], "nn": 20, "pitfal": [20, 21, 22, 25, 26, 29, 31, 34, 36, 38, 39, 46, 47, 49, 50, 51, 52, 53, 56, 59, 65, 67, 70, 72, 73, 74, 77, 78, 81, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 107, 111, 113, 114, 116, 122, 123, 125, 134, 138, 139, 142, 145, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 310, 331, 332, 333, 334, 335, 338, 340, 341, 342, 344, 347, 349, 350, 354, 357, 358, 359, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 381, 382, 383, 384, 386], "convolut": [21, 22, 163], "cnn": [21, 22], "imag": [21, 22, 108], "prerequisit": [21, 26, 27, 28, 29, 32, 34, 39, 41, 46, 50, 53, 64, 70, 81, 87, 88, 92, 93, 96, 97, 98, 100, 101, 102, 113, 114, 115, 116, 117, 123, 138, 139, 141, 142, 143, 145, 150, 157, 158, 162, 163, 183, 186, 191, 194, 195, 198, 201, 209, 211, 212, 213, 216, 218, 221, 223, 224, 228, 229, 230, 234, 235, 237, 238, 240, 244, 245, 246, 251, 253, 254, 256, 264, 267, 269, 270, 331, 332, 333, 334, 335, 342, 343, 346, 348, 350, 351, 352, 353, 356, 357, 358, 359, 381], "roadmap": [21, 22, 134, 136, 139, 140, 142, 143, 144, 145, 146, 157, 158, 159, 162, 163, 176, 183, 185, 186, 189, 191, 194, 195, 198, 201, 209, 211, 212, 213, 216, 218, 221, 223, 229, 234, 235, 237, 238, 240, 241, 257], "handwritten": [21, 22], "digit": [21, 22], "intuit": [21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 41, 45, 46, 47, 51, 53, 56, 57, 64, 67, 70, 72, 77, 78, 81, 83, 84, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 116, 118, 119, 121, 123, 125, 129, 131, 134, 139, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 248, 251, 252, 253, 254, 255, 257, 258, 264, 265, 267, 268, 269, 270, 280, 284, 287, 293, 299, 301, 328, 389], "filter": [1, 21, 22, 113, 285, 311], "detector": [21, 22], "option": [21, 22, 50, 73, 120, 139, 246, 247, 255, 264, 265, 287, 289, 301, 303, 306, 312, 389], "gradient": [21, 22, 31, 90, 93, 96, 97, 98, 100, 101, 102, 107, 110, 134, 135, 137, 138, 143, 146], "check": [21, 22, 28, 46, 51, 56, 57, 67, 69, 89, 94, 101, 140, 157, 188, 243, 247, 251, 261, 267, 268, 280, 305, 328], "small": [21, 22, 92, 93, 105, 243, 253, 255, 268, 334, 335], "slow": [21, 22, 105, 110], "train": [21, 22, 67, 97, 134, 136, 140, 141, 142, 143, 144, 304, 307], "implement": [21, 22, 34, 38, 46, 47, 49, 51, 56, 57, 59, 64, 67, 73, 74, 75, 77, 83, 84, 86, 87, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101, 102, 113, 116, 119, 122, 134, 138, 139, 140, 142, 143, 144, 145, 146, 200, 247, 248, 251, 257, 258, 259, 264, 266, 267, 268, 269, 270], "residu": [22, 107, 112, 119, 246, 394], "resnet": 22, "skip": 22, "connect": [22, 45, 94, 104, 186, 196, 250, 381], "vs": [5, 22, 25, 26, 27, 29, 30, 31, 32, 36, 38, 41, 45, 46, 49, 50, 51, 67, 69, 70, 73, 77, 78, 84, 91, 93, 97, 101, 102, 105, 106, 107, 110, 112, 113, 115, 116, 117, 122, 123, 140, 143, 199, 204, 224, 231, 233, 243, 249, 252, 255, 261, 263, 264, 265, 266, 267, 295, 310, 329, 359, 371, 389, 394], "take": [22, 102], "awai": 22, "dbscan": 25, "densiti": 25, "base": [25, 27, 110, 126, 130, 141, 216, 286, 287, 289, 292, 306, 318, 371], "cluster": [25, 68, 69, 70, 72, 73, 81, 83, 84, 111, 121, 274, 295, 316], "find": 25, "crowd": [25, 31], "instead": [25, 67, 111, 121], "shape": [25, 30, 91, 92, 93, 103, 151, 152, 158, 161, 162, 163, 164, 165, 166, 167, 168, 169, 172, 180, 181, 183, 185, 190, 193, 194, 196, 198, 200, 203, 204, 205, 207, 208, 211, 213, 216, 218, 219, 220, 221, 224, 227, 229, 232, 236, 313], "concept": [25, 296, 323, 331, 332, 333, 334, 335, 338, 340, 341, 342, 344, 347, 348, 355, 358, 359, 373, 382], "\u03b5": [25, 109], "neighborhood": [25, 28, 32], "border": 25, "nois": [25, 27, 30, 69, 70, 75, 78, 96, 113, 137, 229, 269, 271], "point": [25, 27, 64, 91, 105, 312, 322], "algorithm": [25, 26, 27, 28, 30, 31, 39, 70, 72, 74, 84, 105, 110, 112, 114, 127, 138, 143, 148, 153, 160, 163, 164, 165, 167, 172, 174, 177, 179, 184, 186, 187, 189, 198, 204, 205, 210, 214, 220, 222, 225, 232, 234, 236, 253, 283, 285], "reachabl": 25, "expans": 25, "pseudocod": [25, 138, 367, 368, 370, 371, 375, 381, 384], "classic": [25, 27, 29, 34, 262, 268, 277], "plotli": [25, 26, 27, 28, 29, 30, 31, 32, 112, 113, 136, 138, 140, 141, 142, 144, 257, 285], "lab": 25, "effect": [25, 112, 113, 116, 191, 245, 247, 251, 253, 255, 256, 262, 269, 326], "ep": [25, 73], "min_sampl": 25, "detect": [25, 163, 225, 231, 272, 284], "choos": [25, 73, 84, 107, 108, 118, 119, 263, 331, 332, 333], "comparison": [25, 26, 29, 30, 31, 32, 157, 249, 252, 256, 257], "k": [25, 36, 47, 56, 72, 73, 74, 77, 81, 83, 84, 105, 125, 135, 136, 154, 163, 187, 196, 248], "mean": [25, 65, 67, 72, 73, 74, 77, 81, 83, 84, 92, 93, 94, 96, 97, 98, 100, 101, 102, 111, 114, 116, 117, 121, 134, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 166, 167, 172, 173, 174, 175, 177, 178, 179, 181, 183, 184, 185, 187, 188, 191, 192, 193, 194, 195, 196, 197, 198, 200, 202, 203, 204, 205, 206, 207, 210, 211, 212, 213, 216, 218, 219, 220, 221, 222, 224, 225, 226, 227, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 250, 251, 253, 256, 257, 258, 259, 262, 263, 265, 266, 267, 268, 269, 270, 393], "hdbscan": 25, "scikit": [25, 26, 27, 34, 37, 46, 47, 53, 64, 65, 69, 70, 73, 81, 83, 87, 88, 89, 91, 92, 94, 96, 97, 98, 101, 102, 103, 105, 107, 109, 110], "paramet": [25, 84, 103, 105, 107, 108, 109, 111, 116, 121, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241], "map": [25, 29, 73, 103, 109, 110, 142, 143, 205, 284, 295, 299, 305, 308, 313, 314, 315, 322, 328, 329], "9": [25, 35, 37, 38, 45, 53, 69, 73, 74, 89, 93, 94, 96, 98, 101, 102, 105, 112, 113, 116, 117, 134, 140, 142, 143, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 247, 248, 249, 250, 251, 252, 255, 257, 260, 262, 264, 265, 266, 267, 268], "independ": [26, 78, 108, 245, 246, 267], "compon": [26, 30, 116, 159, 248, 386], "analysi": [26, 30, 106, 165, 168, 243], "ica": [26, 30], "mix": [26, 77, 195, 247], "unmix": 26, "voic": 26, "cocktail": 26, "parti": [26, 31], "foundat": [26, 32], "uncorrel": 26, "non": [26, 29, 30, 78, 93, 116, 119, 247, 265], "gaussian": [26, 31, 96, 103, 104, 106, 108, 113, 185, 193, 195, 203, 218, 221], "ha": [26, 109], "signal": [26, 141, 204, 269, 381], "grab": 26, "kurtosi": [26, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 163, 166, 167, 170, 172, 174, 175, 177, 178, 179, 181, 182, 183, 184, 185, 187, 190, 191, 192, 195, 196, 198, 200, 202, 203, 204, 205, 206, 207, 210, 211, 212, 213, 215, 216, 219, 220, 222, 224, 225, 226, 227, 230, 231, 232, 233, 234, 235, 236, 238, 239, 240, 248, 254, 258], "approx": 26, "negentropi": 26, "mechan": [26, 31, 116, 242], "whiten": 26, "maxim": [26, 30, 144], "fastica": 26, "pca": [26, 29, 30, 31], "process": [26, 29, 103, 113, 162], "neurosci": 26, "isomap": [27, 29, 32], "dimension": [27, 31, 103, 105, 106], "reduct": [27, 106, 110, 134, 268, 306], "geodes": 27, "distanc": [27, 29, 83, 91, 105, 125, 126, 287, 293, 295], "you": [27, 29, 35, 72, 83, 84, 95, 102, 105, 107, 119, 138, 139, 152, 157, 162, 163, 168, 169, 173, 174, 180, 181, 182, 183, 184, 186, 188, 190, 193, 196, 197, 198, 200, 201, 203, 205, 208, 209, 211, 213, 214, 215, 217, 218, 219, 227, 242, 249, 251, 255, 256, 257, 260, 265, 266, 268, 285, 295, 312, 331, 332, 333, 334, 335, 338, 340, 341, 342, 344, 347, 348, 355, 358, 359, 371, 381], "ll": [27, 29, 83, 105, 107, 119, 139, 140, 143, 152, 157, 162, 163, 168, 169, 173, 174, 180, 181, 182, 183, 184, 186, 188, 190, 193, 196, 197, 198, 200, 201, 203, 205, 208, 209, 211, 213, 214, 215, 217, 218, 219, 227, 249, 251, 260, 268, 358, 371], "measur": [27, 75, 78, 84, 93, 110, 113, 253, 254, 255, 264], "walk": [27, 119, 150], "path": [27, 358, 394], "fly": 27, "swiss": [27, 28], "roll": [27, 28, 271, 329], "metaphor": [27, 30, 32], "graph": [27, 32], "explan": [27, 28, 29, 30, 31], "knn": [27, 105, 125, 126], "via": [27, 34, 35, 75, 81, 103, 107, 127, 131, 132, 151, 161, 164, 166, 170, 171, 173, 180, 186, 188, 193, 199, 203, 204, 206, 218, 227, 231, 234, 235, 240, 244, 249, 300], "shortest": 27, "euclidean": 27, "matrix": [27, 29, 30, 34, 39, 41, 49, 50, 51, 57, 73, 75, 77, 78, 81, 112, 117, 135, 185, 221, 255], "view": [27, 30, 35, 36, 53, 57, 70, 72, 73, 75, 93, 96, 98, 112, 114, 123, 132, 149, 171, 192, 198, 203, 223, 265], "two": [27, 120, 169, 193, 229, 239, 245, 246, 250, 251, 256, 263, 266, 267, 301], "close": [27, 29, 101, 107, 191, 225, 227, 389], "far": [27, 252], "md": [27, 29], "embed": [27, 28, 29], "summari": [27, 65, 104, 105, 106, 108, 112, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 271], "unfold": 27, "anim": [27, 31], "failur": [27, 30, 167], "mode": [4, 27, 30, 152, 161, 166, 198, 221], "sensit": [27, 30, 70, 91, 101, 242, 247, 280], "disconnect": 27, "usag": [27, 34, 35, 36, 37, 52, 64, 74, 81, 83, 87, 88, 89, 91, 92, 94, 96, 97, 98, 101, 102, 122, 134, 136, 144, 243, 246, 252, 260, 262, 267, 268], "s": [27, 41, 50, 51, 67, 69, 70, 92, 94, 100, 103, 116, 168, 180, 187, 199, 209, 210, 232, 236, 244, 246, 247, 248, 249, 251, 252, 255, 259, 261, 262, 264, 265, 266, 267, 269, 270, 339, 389], "local": [28, 32], "lle": 28, "manifold": [28, 32], "mathemat": [28, 29, 30, 32, 114, 134], "reconstruct": 28, "weight": [28, 41, 49, 67, 89, 91, 92, 94, 96, 97, 100, 101, 105, 125, 238, 288], "global": [28, 32], "function": [28, 29, 57, 103, 106, 118, 123, 134, 137, 138, 139, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 327, 356], "preserv": [28, 29, 31, 32], "2d": [28, 70, 73, 105, 134], "illustr": [28, 31], "sklearn": [28, 36, 52, 73, 74, 108, 110], "saniti": [28, 46, 51, 56, 57, 67, 69, 94, 101, 140, 243, 251, 268], "strength": [28, 31, 233], "weak": 28, "multidimension": 29, "recreat": 29, "onli": [29, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 172, 174, 175, 176, 177, 178, 179, 182, 183, 186, 187, 189, 190, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 217, 218, 219, 220, 221, 222, 223, 225, 227, 229, 231, 234, 235, 237, 238, 240, 241, 243, 244, 246, 247, 248, 249, 251, 257, 264, 266, 267, 268, 269, 270], "pairwis": [29, 59, 81, 243], "dissimilar": 29, "stress": 29, "metric": [29, 32, 33, 37, 52, 68, 73, 84, 85, 93, 98, 101, 102, 260, 271, 280, 299, 381], "optim": [29, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 53, 56, 57, 59, 64, 67, 69, 70, 72, 73, 74, 78, 84, 86, 87, 88, 89, 90, 93, 94, 96, 97, 98, 99, 100, 101, 102, 104, 107, 136, 139, 140, 143, 146], "eigen": 29, "decomposit": [29, 38, 221, 230, 271], "form": [29, 46, 57, 90, 93, 101, 104, 107, 112, 114, 117, 118, 119, 134, 149, 156, 161, 164, 167, 172, 173, 174, 177, 180, 188, 191, 195, 197, 198, 200, 203, 206, 209, 213, 218, 225, 227, 229, 247, 389], "minim": [29, 91, 99, 134, 144, 287, 289, 371], "smacof": 29, "error": [29, 51, 67, 69, 86, 90, 91, 93, 94, 96, 97, 99, 101, 102, 104, 114, 120, 122, 267, 384], "princip": 30, "kernel": [30, 103, 109, 130, 132], "veri": [30, 164], "simpl": [30, 32, 36, 38, 39, 47, 49, 50, 59, 70, 72, 73, 74, 75, 78, 81, 84, 96, 107, 161, 186, 252, 306, 352, 354, 355], "rotat": 30, "camera": 30, "see": [30, 70, 84, 255, 257], "widest": 30, "shadow": 30, "wall": 30, "covari": [30, 113, 159, 185, 189, 221, 230], "built": 30, "varianc": [30, 89, 96, 100, 105, 110, 111, 121, 134, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 249, 250, 252, 259, 266, 267, 268, 393], "eigenvector": 30, "orthogon": 30, "pc": 30, "ar": [30, 36, 73, 103, 112, 122, 242, 248, 251, 262, 356, 357, 367, 372, 374, 377], "right": [30, 108, 270, 312], "angl": 30, "relationship": [30, 46, 51, 53, 89, 203, 262], "svd": 30, "anoth": 30, "wai": [30, 107, 112, 243, 257], "comput": [30, 65, 70, 75, 81, 242, 253, 262, 268, 269, 270, 342], "extens": [30, 117, 125, 280], "structur": [30, 32, 125, 138, 221, 249], "motiv": [30, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241], "when": [4, 30, 32, 34, 35, 36, 37, 38, 39, 46, 49, 50, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 81, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 112, 114, 116, 122, 125, 157, 182, 196, 242, 243, 244, 245, 246, 247, 249, 251, 253, 254, 255, 260, 265, 266, 267, 268, 269, 270, 286, 287, 288, 289, 292, 293, 297, 298, 300, 304, 306, 307, 309], "wrong": 30, "trick": [30, 109, 172, 186], "formul": [30, 122, 134], "high": [30, 31, 103, 105, 110, 112, 115, 166, 195, 221, 358, 369, 381], "level": [30, 74, 98, 110, 112, 113, 115, 116, 118, 119, 122, 134, 136, 139, 140, 141, 142, 144, 146, 166, 195, 221, 248, 358, 369, 381], "conceptu": [30, 383], "work": [30, 37, 74, 77, 93, 101, 102, 108, 114, 131, 242, 245, 249, 250, 253, 257, 258, 259, 264, 265, 267, 268, 291, 331, 332, 333, 358, 359, 367, 369, 371, 385], "fail": [30, 266, 269], "tend": [30, 74], "well": [30, 74, 112], "common": [2, 30, 36, 39, 47, 49, 51, 52, 56, 67, 70, 74, 84, 91, 92, 93, 95, 97, 98, 101, 102, 104, 111, 119, 121, 145, 175, 242, 243, 247, 251, 266, 323, 359, 368, 371, 377, 378, 381, 386], "issu": [30, 224, 226, 230, 236], "limit": [30, 37, 83, 103, 166, 211], "t": [31, 32, 34, 35, 53, 94, 97, 103, 107, 154, 192, 210, 242, 243, 244, 249, 256, 262, 266, 267, 268, 269, 312], "sne": [31, 32], "friendship": 31, "Not": [31, 247], "geographi": 31, "peopl": [31, 103, 259], "probabilist": [31, 73, 96, 98, 103, 305], "similar": [31, 53, 103, 259], "probabl": [31, 37, 38, 39, 45, 53, 64, 67, 150, 152, 159, 225, 226, 230, 237, 261], "low": [31, 74, 98, 113, 116, 118, 119, 122, 134, 136, 139, 140, 141, 142, 144, 146, 248], "student": [31, 209, 210, 266, 267, 269], "object": [31, 69, 78, 90, 96, 98, 101, 102, 134, 138, 140, 142, 143, 146, 256], "kl": [31, 135, 146], "diverg": [31, 146, 148, 179], "perplex": 31, "friend": [31, 107, 108], "circl": 31, "size": [31, 101, 191, 245, 247, 250, 251, 253, 255, 256, 262, 264, 269], "descent": [31, 90, 96, 100, 107], "earli": [31, 59], "exagger": 31, "import": [31, 37, 40, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 86, 87, 88, 92, 93, 98, 100, 101, 102, 112, 157, 250, 253, 267, 358, 359], "ones": [31, 32, 107, 138, 236], "umap": [31, 32], "uniform": [32, 105, 125, 149, 184, 206, 217, 236, 238, 247, 248], "approxim": [32, 93, 122, 226, 236, 247, 255, 260, 267, 393], "light": 32, "stretch": 32, "rubber": 32, "sheet": [32, 104, 107, 280, 358, 359], "b": [32, 83, 143, 153, 159, 161, 162, 164, 166, 169, 183, 195, 197, 201, 205, 208, 213, 214, 216, 218, 225, 226, 227, 229, 230, 231, 232, 233, 234, 236, 237, 239, 241, 246, 255, 263], "awar": [32, 104, 310], "math": [32, 41, 46, 50, 72, 74, 77, 83, 105, 112, 120, 124, 129], "assumpt": [32, 108, 112, 113, 114, 243, 244, 246, 247, 249, 250, 253, 257, 262, 263, 265, 266, 267, 268, 269, 389], "fuzzi": 32, "simplici": 32, "set": [32, 45, 49, 53, 270, 312], "construct": [32, 150, 206, 221, 245, 327], "cross": [32, 38, 56, 118, 267, 310], "entropi": [32, 38, 46, 56, 72, 77, 78, 84, 110, 134, 143, 144, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241], "hyperparamet": [32, 103, 110, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 310], "explain": [32, 45, 46, 88, 89, 100, 107, 134, 136, 138, 139, 141, 142, 143], "n_neighbor": 32, "min_dist": 32, "choic": [32, 65, 67, 74, 100, 125], "experi": [32, 139, 141, 234], "stabil": [32, 56, 118, 137, 138, 172], "run": [32, 139, 144, 243, 262, 263, 265, 339], "guidanc": [32, 248, 258], "often": [32, 108, 253, 259], "beat": 32, "doesn": [32, 107, 244, 262], "workflow": [32, 119, 285, 332, 334, 335, 350, 359, 381, 383, 384], "multilabel": [33, 34, 51, 53, 67], "rank": [33, 35, 36, 59, 64, 252, 253, 255, 257, 260, 265, 270], "accuracy_scor": 34, "accuraci": [34, 37, 41, 51, 57, 67, 73, 81], "definit": [34, 36, 37, 38, 39, 46, 47, 51, 56, 57, 67, 69, 73, 74, 81, 83, 84, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 111, 114, 117, 123, 141, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 251, 280, 328, 329], "gener": [34, 104, 106, 114, 119, 134, 140, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 379], "multiclass": [34, 37, 38, 49, 51, 53, 56, 57, 67, 104], "confus": [34, 39, 41, 49, 50, 57], "relat": [34, 90, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 351, 379], "loss": [34, 38, 45, 46, 51, 53, 56, 59, 67, 87, 88, 92, 94, 95, 107, 134, 139, 141, 143, 144, 188], "subset": [34, 51], "an": [34, 37, 46, 69, 73, 90, 101, 102, 114, 118, 164, 172, 191, 232, 301, 303, 338, 340, 341, 344, 347, 355], "averag": [34, 36, 47, 91, 101, 114, 117, 119], "per": [34, 45, 46, 67, 83, 134, 141, 142, 306], "sampl": [34, 46, 67, 83, 89, 101, 141, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 245, 247, 249, 250, 255, 256, 260, 261, 262, 263, 264, 266, 267, 269, 393], "outcom": 34, "depend": [34, 37, 39, 49, 74, 118, 224, 262, 269, 325], "decis": [34, 49, 50, 65, 67, 70, 105, 108, 110, 250, 263], "threshold": [34, 35, 36, 37, 39, 41, 49, 50, 51, 53, 57, 64, 67, 78], "imbalanc": [34, 108], "paradox": 34, "dure": 34, "we": [34, 67, 96, 112, 140, 143, 258, 262, 270], "usual": 34, "don": [34, 35, 53, 103], "directli": [34, 67, 89, 99], "pro": [34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102], "con": [34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 53, 56, 57, 59, 64, 65, 67, 69, 70, 72, 73, 74, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102], "good": [34, 37, 41, 46, 50, 51, 53, 56, 59, 65, 67, 72, 73, 74, 77, 81, 84, 86, 87, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 110, 125, 148, 149, 158, 160, 161, 167, 168, 171, 173, 179, 180, 186, 195, 206, 215, 220, 230, 238, 240, 241, 242, 246, 247, 252, 256, 270], "fit": [34, 50, 51, 56, 59, 91, 92, 98, 99, 101, 108, 112, 117, 123, 125, 148, 149, 158, 160, 161, 167, 168, 171, 173, 179, 180, 186, 195, 206, 215, 220, 224, 225, 227, 230, 231, 233, 234, 235, 238, 240, 241, 242, 246, 247, 256, 270, 290, 294, 297, 298, 302, 304, 306, 307, 309, 319, 320, 327, 381], "consid": 34, "altern": [34, 92, 140, 155, 175, 182, 198, 201, 224, 231, 261, 264, 266, 267], "auc": [35, 64, 65], "roc": [35, 39, 64, 65], "area": [35, 64, 269], "under": [35, 57, 69, 70, 244, 248, 251, 252, 258, 261, 264, 269, 270], "curv": [35, 46, 50, 64, 65, 107, 142, 252, 265], "about": [35, 72, 102, 143, 224, 225, 233, 234, 255, 270], "order": [35, 112, 119, 171, 199, 234, 255], "trapezoid": [35, 211], "rule": [35, 38, 49, 67, 108, 242, 250, 263, 319, 371, 386], "mann": [35, 260], "whitnei": [35, 260], "wilcoxon": [35, 260, 270], "monoton": [35, 265], "transform": [35, 120, 150, 161, 162, 164, 165, 166, 171, 178, 181, 182, 188, 194, 196, 198, 199, 201, 212, 217, 220, 226, 235, 264, 265, 315, 323, 326], "chang": [35, 41, 88, 101, 102, 113, 151, 158, 161, 162, 163, 166, 173, 181, 183, 185, 193, 194, 203, 204, 205, 211, 218, 221, 224, 227, 232, 236, 315, 322], "tpr": [35, 57, 64], "fpr": [35, 64], "move": [35, 53, 114, 117, 119, 137], "cutoff": 35, "classifi": [35, 50, 65, 105, 110, 286, 287, 288, 289, 292, 313], "smooth": [35, 78, 90, 108, 145, 302, 303, 315, 329], "surrog": [35, 50, 90, 142], "10": [35, 53, 69, 73, 74, 89, 93, 101, 102, 105, 112, 113, 134, 142, 143, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 247, 248, 249, 251, 252, 257, 260, 262, 266, 267, 268], "average_precision_scor": 36, "precis": [36, 49, 50, 53, 117, 119, 122, 137, 138, 139, 141, 143, 267], "ap": 36, "especi": [36, 47], "posit": [36, 104, 111, 113, 234], "rare": 36, "recal": [36, 49, 50, 53], "top": 36, "each": [36, 91, 111, 142, 143, 252, 253, 267, 313, 314], "hit": 36, "formal": [36, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241], "random": [36, 70, 110, 119, 150, 159, 185, 217, 221, 238, 263, 268], "inform": [36, 69, 78, 84, 135], "almost": 36, "perfect": 36, "score": [36, 38, 45, 46, 49, 50, 53, 64, 65, 72, 73, 75, 77, 78, 81, 83, 84, 86, 87, 88, 89, 94, 97, 100, 134, 252, 258], "balanced_accuracy_scor": 37, "plain": 37, "adjust": [37, 69, 70, 81], "balanc": 37, "exampl": [37, 45, 56, 67, 69, 73, 74, 77, 81, 83, 90, 93, 100, 101, 102, 105, 112, 113, 117, 119, 122, 123, 144, 177, 203, 229, 242, 243, 244, 245, 246, 247, 248, 249, 250, 253, 255, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 287, 289, 293, 314, 323, 331, 332, 333, 334, 335, 358, 371, 381, 382, 383, 384, 385, 386, 394], "alwai": [37, 109], "predict": [37, 94, 96, 97, 112, 113, 122, 192, 225, 231, 305, 312, 394], "major": 37, "class": [37, 56, 64, 72, 73, 106, 313], "label": [37, 41, 50, 51, 57, 59, 69, 70, 73, 75, 78, 84, 313], "guid": [37, 297, 298], "loop": [37, 49, 78, 81, 134, 136, 141, 144], "select": [37, 49, 67, 70, 72, 81, 83, 105, 112, 118, 280, 285, 310], "brier_score_loss": 38, "brier": [38, 45], "note": [38, 40, 42, 43, 44, 47, 48, 54, 55, 58, 60, 61, 62, 63, 66, 71, 76, 79, 80, 82, 101, 102, 111, 115, 121, 122, 125, 140, 145, 181, 251, 253, 254, 261, 264, 269, 290, 319, 322, 327, 345, 355, 374, 375, 382, 385], "proper": 38, "best": [38, 73, 87, 96, 110], "constant": [38, 46, 86, 87, 89, 96, 99, 101, 211, 215], "predictor": [38, 46, 87, 99, 101, 318], "skill": 38, "calibr": [38, 45, 305], "murphi": 38, "log": [38, 46, 56, 93, 95, 97, 98, 102, 103, 108, 161, 168, 180, 182, 184, 198, 199, 227, 261, 297, 298, 381, 382, 385], "class_likelihood_ratio": 39, "lr": 39, "likelihood": [39, 56, 93, 98, 103, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 244], "ratio": [39, 93, 97, 102, 142, 153, 155, 166, 218, 227, 232, 235, 244, 250, 251, 252, 261], "condit": [39, 77, 103, 106, 108, 111, 121, 141, 192, 195, 226, 230, 232, 251], "lr_": 39, "interpret": [39, 86, 87, 97, 122, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 294, 302], "geometri": [39, 96, 105, 248, 254], "classification_report": 40, "cohen": 41, "kappa": [41, 187], "cohen_kappa_scor": 41, "just": 41, "The": [41, 46, 49, 57, 69, 70, 72, 77, 83, 84, 87, 96, 98, 103, 104, 105, 107, 108, 110, 112, 116, 137, 143, 173, 190, 197, 233, 242, 243, 244, 246, 247, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 270, 358, 381], "expect": [41, 69, 78, 139, 149, 150, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 247], "agreement": 41, "preval": [41, 64], "ordin": 41, "tune": [41, 47, 51, 57, 65, 75, 77, 78, 142, 144, 310], "confusion_matrix": 42, "confusion_matrix_at_threshold": 43, "coverage_error": 44, "d\u00b2": [45, 46, 86, 87, 88], "d2_brier_scor": 45, "underli": [45, 389], "fraction": [45, 46, 88], "r": [45, 89, 94, 97, 117, 123, 202, 262, 314], "miscalibr": 45, "contribut": 45, "drive": [45, 246, 247], "where": [45, 47, 51, 53, 56, 74, 78, 84, 93, 95, 113, 150, 244, 250, 254, 313, 328, 329, 381], "d2_log_loss_scor": 46, "your": [46, 105, 108, 109, 386], "surpris": 46, "turn": [46, 140, 164, 172, 245, 263], "sum": [46, 100, 226, 231, 243, 246, 260], "null": [46, 244, 245, 247, 248, 251, 254, 260, 262, 263, 265, 268, 270], "plot": [46, 47, 51, 56, 57, 67, 72, 77, 83, 84, 98, 134, 141, 254, 275, 297, 298, 302, 309], "behav": [46, 69, 90, 95], "empir": [46, 87], "caveat": [46, 51, 56, 57], "dcg_score": 47, "discount": [47, 59], "cumul": [47, 59, 218, 239], "gain": [47, 59], "queri": [47, 59, 105, 312, 313, 314, 315, 316, 317, 384, 386], "dcg": [47, 59], "tie": [47, 253, 257], "handl": [47, 116, 119], "default": [47, 103, 122, 145, 358], "normal": [47, 59, 73, 107, 155, 163, 179, 185, 188, 189, 194, 195, 199, 200, 208, 211, 214, 215, 242, 244, 248, 252, 254, 255, 258, 260, 264, 267], "ndcg": [47, 59], "includ": [47, 83, 270], "det_curv": 48, "f1": [49, 53], "f1_score": 49, "evalu": [49, 67, 134, 144, 271, 299, 304, 307, 322], "macro": 49, "micro": [49, 51], "fbeta_scor": 50, "f\u03b2": 50, "role": [50, 109], "iso": 50, "line": [50, 99], "direct": [50, 221, 270, 306, 308], "differenti": [50, 150, 152, 158, 162, 174, 181, 183, 184, 194, 206, 213, 217], "soft": [50, 53, 109, 144], "hamming_loss": 51, "bitwis": 51, "rate": [51, 162, 169, 171, 213, 220, 231, 236, 239], "singl": [51, 65, 226], "indic": [51, 223, 238], "contrast": 51, "exact": [51, 145, 178, 226, 251, 261, 270], "match": 51, "hot": 51, "integ": [51, 171, 199, 200, 229, 231, 238, 239], "ham": 51, "hinge_loss": 52, "jaccard": 53, "intersect": 53, "over": [53, 77, 81, 103, 119, 142, 224, 227, 232, 233], "union": 53, "tp": 53, "fp": 53, "fn": 53, "iou": 53, "segment": [53, 77, 91, 322], "formula": [53, 95, 209, 214, 242, 244], "true": [53, 113, 250, 268], "neg": [53, 56, 83, 86, 93, 98, 225, 231, 234], "shine": [53, 57, 78, 306], "label_ranking_average_precision_scor": 54, "label_ranking_loss": 55, "log_loss": 56, "logit": 56, "numer": [56, 153, 157, 191, 224, 225, 226, 230, 236], "matthews_corrcoef": 57, "matthew": 57, "correl": [57, 122, 224, 249, 255, 262, 265, 381], "coeffici": [57, 83, 122], "mcc": 57, "recap": [57, 121], "pearson": [57, 197, 246, 247, 262], "tnr": 57, "trap": 57, "imbal": [57, 64], "multilabel_confusion_matrix": 58, "ndcg_score": 59, "reward": [59, 140, 141, 142], "relev": 59, "item": 59, "idcg": 59, "across": [59, 97, 101, 253], "ti": [59, 255], "other": [59, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 252], "y_score": 59, "all": [59, 81, 164], "zero": 59, "pointwis": 59, "mse": [59, 89, 91, 96, 97, 101], "ranknet": 59, "style": [59, 113, 127, 131, 132, 159, 249, 303, 359, 384], "precision_recall_curv": 60, "precision_recall_fscore_support": 61, "precision_scor": 62, "recall_scor": 63, "roc_auc_scor": 64, "sweep": 64, "correct": [64, 69, 70, 253, 257], "distribut": [64, 69, 103, 104, 125, 134, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 247, 250, 254, 256, 260, 262, 263, 265, 266, 268, 269, 270], "invari": [64, 69, 81, 89, 93, 265], "pr": 64, "receiv": 65, "oper": [65, 114, 117, 382, 385], "characterist": [65, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241], "number": [65, 69, 225, 233], "top_k_accuracy_scor": 66, "zero_one_loss": 67, "aggreg": [67, 89, 314, 382], "count": [67, 75, 81, 104, 108, 226, 230, 236], "version": [1, 67, 94, 113], "bay": [67, 108], "argmax": 67, "hard": [67, 109], "do": [67, 96, 103, 110, 112, 169, 173, 180, 190, 197, 205, 208, 214, 218, 219, 258, 266, 285, 339], "mutual": [69, 78, 84], "ami": [69, 78], "adjusted_mutual_info_scor": 69, "conting": [69, 70, 73, 75, 77, 78, 81, 84, 246], "mi": [69, 78], "need": [69, 265], "chanc": [69, 70, 81, 255], "emi": 69, "toi": [69, 77, 78, 105, 244, 280, 293, 319, 394], "permut": [69, 73, 75, 78, 243, 255, 262, 263, 265], "bia": [69, 89, 105, 233], "target": [69, 86, 89, 91, 92, 94, 99, 101, 104, 125, 137, 138, 139, 145, 314], "11": [69, 101, 112, 113, 134, 142, 143, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 247, 249, 251, 252, 257, 260, 262, 266], "adjusted_rand_scor": 70, "rand": [70, 81], "index": [70, 74, 81, 154, 187, 196, 271, 312, 382], "ari": 70, "pair": [70, 75, 81, 255, 263, 266, 268, 270], "effici": [70, 75, 81, 214, 393], "ri": 70, "action": [70, 134, 138, 139, 144, 236, 332], "calinski_harabasz_scor": 71, "complet": [72, 77, 84], "care": [72, 100, 102, 242, 255, 270], "split": [72, 75, 84, 110, 271, 304, 307], "should": [72, 84, 95, 242, 252, 257, 265, 331, 332, 333, 334, 335, 338, 340, 341, 342, 344, 347, 348, 355, 358, 359], "notic": 72, "contingency_matrix": 73, "dens": 73, "plu": 73, "spars": 73, "variant": [73, 143], "row": [73, 185], "wise": [73, 135, 159], "column": [73, 185], "differ": [73, 90, 91, 92, 97, 112, 113, 119, 177, 239, 244, 250, 252, 259, 260, 263, 266, 270, 297, 298, 359], "synthet": [73, 112, 117, 120, 123, 125, 267, 393], "align": [73, 122, 296, 328], "puriti": [73, 77], "extern": 73, "criterion": 73, "davies_bouldin_scor": 74, "davi": 74, "bouldin": 74, "dbi": 74, "ingredi": [74, 300], "s_i": 74, "m_": 74, "ij": 74, "worst": 74, "neighbor": [74, 105, 125], "react": 74, "dispers": 74, "fowlk": 75, "mallow": 75, "fowlkes_mallows_scor": 75, "fmi": 75, "actual": [75, 107, 110, 112, 242, 253, 265, 266, 268, 358, 371, 394], "behavior": [75, 112, 148, 154, 160, 171, 174, 175, 181, 187], "merg": [75, 84], "homogeneity_completeness_v_measur": 76, "homogen": [77, 84, 244, 259], "homogeneity_scor": 77, "affect": [77, 250], "can": [77, 98, 105, 122, 247, 250, 255, 261, 262, 268, 314, 315], "reach": 77, "grid": [77, 78, 105, 227], "search": [77, 78, 105, 382], "mutual_info_scor": 78, "doe": [78, 95, 106, 111, 116, 140, 142, 143, 155, 175, 177, 198, 207, 245, 247, 250, 251, 252, 256, 257, 258, 260, 262, 263, 264], "discret": [78, 108, 139, 229, 238, 242, 251, 253], "variabl": [78, 113, 118, 122, 173, 195, 205, 246, 262, 296, 312], "uncertainti": [78, 113, 245, 255, 262, 265], "share": 78, "arrai": 78, "ad": [78, 242], "up": [78, 84, 109, 250, 254], "co": [78, 185], "occurr": 78, "bonu": 78, "nmi": 78, "exist": [78, 98, 140, 143, 154, 155, 157, 164, 168, 171, 172, 173, 175, 182, 187, 191, 192, 196, 207, 209, 210, 240, 255, 374], "normalized_mutual_info_scor": 79, "pair_confusion_matrix": 80, "everi": 81, "without": [81, 233], "kei": [81, 89, 91, 101, 105, 109, 110, 154, 161, 162, 164, 172, 175, 187, 189, 206, 249, 253, 265, 373], "combinatori": 81, "properti": [81, 89, 91, 101, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 265], "worth": 81, "rememb": [81, 112], "relabel": [81, 141], "extrem": [81, 150, 172, 246, 251], "trivial": 81, "solut": 81, "silhouette_sampl": 82, "silhouett": 83, "valid": [83, 107, 252, 310], "am": 83, "i": [83, 148, 149, 151, 153, 160, 164, 166, 167, 168, 169, 171, 173, 179, 189, 197, 201, 202, 205, 212, 215, 220, 223, 234, 236, 238, 241, 267, 313, 314], "closer": 83, "my": 83, "own": 83, "intra": 83, "cohes": 83, "nearest": [83, 105, 125], "v": [84, 185], "v_measure_scor": 84, "warm": 84, "four": 84, "read": [84, 250, 268], "theoret": 84, "beta": [84, 107, 152, 166, 167, 169, 187, 195, 202, 223, 224, 225, 226, 234, 235], "which": [84, 246, 247], "mistak": 84, "hurt": [84, 98], "more": [84, 255, 257, 297, 298], "absolut": [86, 91, 93, 94, 161, 252], "d2_absolute_error_scor": 86, "l1": [86, 91, 105, 107], "analogu": 86, "r\u00b2": [86, 100], "multi": [86, 89, 91, 99, 121, 127], "output": [86, 89, 91, 99, 248, 250, 266, 267, 268], "edg": [86, 89, 102], "median": [86, 91, 198, 259, 260, 263], "while": [86, 87, 88, 100], "pinbal": [87, 94], "d2_pinball_scor": 87, "quantil": [87, 94, 148, 154, 155, 160, 161, 165, 168, 176, 178, 179, 181, 182, 187, 188, 192, 198, 199, 201, 215, 219, 220, 222, 305], "alpha": [87, 107, 148, 169, 195, 196, 224], "subgradi": [87, 91, 94], "tweedi": [88, 98, 104], "d2_tweedie_scor": 88, "devianc": [88, 93, 98, 104], "famili": [88, 98, 104, 143, 174, 200, 284, 308, 323], "behind": [88, 114], "d": [88, 116, 119, 140, 148, 149, 151, 153, 154, 160, 164, 166, 167, 168, 169, 171, 173, 179, 189, 197, 201, 202, 205, 212, 215, 220, 223, 234, 236, 238, 241, 248, 256, 264], "unit": [88, 92, 96, 97, 99, 104, 119], "d_p": 88, "y": [88, 99, 312, 313, 314], "mu": [88, 172, 194, 195, 218, 219], "p": [88, 98, 112, 116, 117, 118, 119, 123, 221, 224, 230, 243, 244, 245, 246, 247, 248, 250, 251, 253, 254, 256, 258, 260, 262, 263, 264, 266, 267, 268, 269, 270, 297, 298], "penalti": [88, 91, 93, 95, 101], "explained_variance_scor": 89, "shift": [89, 227], "blind": 89, "force_finit": 89, "multioutput": [89, 96, 97, 100, 101, 308], "sample_weight": 89, "ev": 89, "alongsid": 89, "max": [90, 172], "max_error": 90, "mae": [90, 91, 92, 94, 101], "rmse": [90, 101, 102], "bad": [90, 91], "outlier": [90, 91, 99, 101, 262, 267], "domin": [90, 92, 262], "minimax": 90, "program": 90, "convex": 90, "mean_absolute_error": 91, "length": 91, "mean_absolute_percentage_error": 92, "mape": 92, "thing": 92, "free": 92, "avoid": 92, "gamma": [93, 104, 138, 151, 152, 158, 161, 162, 169, 173, 180, 186, 190, 221, 231, 236], "mean_gamma_devi": 93, "come": [93, 95, 150, 244, 250], "rel": 93, "asymmetri": 93, "pictur": 93, "link": [93, 95, 103, 190], "parameter": [93, 136, 168, 171, 172, 175, 195, 211, 213, 214], "mean_pinball_loss": 94, "tilt": 94, "w": [94, 97, 171, 253], "quantileregressor": 94, "mean_poisson_devi": 95, "poisson": [95, 104, 162, 191, 193, 231, 236, 237, 239], "mean_squared_error": 96, "squar": [96, 97, 100, 101, 102, 104, 112, 188, 193, 243, 246, 247, 248], "natur": [96, 135, 146], "equal": [96, 250, 252, 267], "logarithm": [97, 102], "msle": 97, "domain": [97, 98, 102, 114], "constraint": [97, 98, 102, 109, 111, 121, 146, 264], "space": [97, 108, 113, 139, 144, 184, 188, 227, 254], "multipl": [97, 107, 120, 124, 249, 300], "symmetri": [97, 177, 233, 234], "mean_tweedie_devi": 98, "underpredict": 98, "lot": 98, "median_absolute_error": 99, "meda": 99, "typic": [99, 119, 125, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 199, 201, 202, 204, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 252, 266, 270, 313, 331, 332, 333, 334, 335, 359, 381, 383], "50th": 99, "percentil": 99, "robust": [99, 157, 229, 252, 259], "c": [99, 109, 153, 154, 159, 161, 162, 165, 166, 167, 168, 169, 172, 180, 183, 195, 197, 199, 200, 201, 205, 208, 213, 214, 216, 218, 219, 220, 226, 227, 229, 230, 231, 232, 233, 236, 237, 239, 241, 313], "r2_score": 100, "sens": 100, "rewrit": 100, "root": [101, 102, 119, 359], "vector": [101, 109, 117, 118, 132, 159], "extra": 101, "big": [101, 105, 109, 143, 236, 270], "miss": [101, 280], "least": [101, 112], "12": [101, 113, 134, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 247, 249, 252, 266], "13": [101, 113, 134], "rmsle": 102, "mostli": 102, "gp": 103, "like": [103, 174, 188, 252], "prior": [103, 150, 162, 206, 224, 225, 238], "equat": [103, 107, 111, 113, 116, 119, 121, 137, 139, 140, 143, 190], "margin": [103, 109, 159, 221, 230, 232, 251], "occam": 103, "razor": 103, "latent": [103, 113], "laplac": [103, 108, 176, 177, 178, 182, 229], "strategi": [103, 110, 299, 306, 308], "complex": [103, 117, 123], "input": [103, 123, 393], "glm": 104, "recip": [104, 263, 269], "exponenti": [104, 162, 163, 164, 165, 171, 172, 176, 177, 196, 213, 302], "cheat": [104, 107, 280, 358, 359], "edm": 104, "irl": 104, "invers": [104, 150, 154, 155, 161, 162, 164, 165, 168, 171, 174, 176, 178, 181, 182, 184, 187, 188, 195, 196, 198, 199, 200, 201, 203, 204, 207, 212, 213, 217, 218, 219, 220, 222, 226, 227, 232, 235, 236], "skew": [104, 148, 149, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 163, 166, 167, 170, 172, 174, 175, 177, 178, 179, 181, 182, 183, 184, 185, 187, 190, 191, 192, 195, 196, 198, 200, 202, 203, 204, 205, 206, 207, 208, 210, 211, 212, 213, 215, 216, 219, 220, 222, 224, 225, 226, 227, 230, 231, 232, 233, 234, 235, 236, 238, 239, 240, 248, 254, 260, 263, 264], "categor": [104, 108, 110, 230, 246], "ask": 105, "closest": 105, "gotcha": [105, 226, 230], "l2": [105, 107], "ball": [105, 157], "One": [105, 243, 251, 256, 264, 269], "motion": [105, 110], "larg": [105, 243, 255, 260, 261], "1d": [105, 110, 113], "dramat": 105, "demo": [105, 110, 112, 120, 124, 127, 131, 132, 250, 257], "curs": 105, "struggl": 105, "dimens": 105, "regressor": [105, 110, 125, 314, 318], "quadrat": 106, "discrimin": [106, 140], "lda": 106, "qda": 106, "constrain": [106, 135], "overfit": 106, "supervis": [106, 125], "ol": [107, 117, 118], "ridg": 107, "lasso": 107, "elast": [107, 342, 343, 344, 346], "net": 107, "stori": [107, 161, 233], "dial": 107, "mani": [107, 141, 243, 296], "featur": [107, 108, 109, 110, 129, 131, 296, 306, 315, 318, 323, 327, 328, 329, 371], "get": [107, 243], "tricki": [107, 117], "multicollinear": 107, "three": [107, 266], "regular": 107, "standard": [107, 149, 156, 157, 161, 164, 172, 173, 174, 177, 179, 195, 197, 200, 203, 206, 214, 216, 229, 237, 246, 264], "helper": [107, 246], "choleski": [107, 189], "equival": [107, 141, 207], "touch": 107, "linearregress": 107, "elasticnet": 107, "sgdregressor": 107, "rough": 107, "naiv": [108, 304, 307], "multinomi": [108, 228, 230, 234], "complement": 108, "bernoulli": [108, 150, 152, 223, 226], "out": 108, "belief": 108, "updat": [108, 113, 134, 136, 137, 139, 140, 142, 143, 144, 145, 159, 178], "mental": [108, 109, 110, 173, 331, 332, 333, 334, 335, 358, 385], "still": 108, "continu": [108, 137, 144, 146, 156, 331], "estim": [108, 109, 112, 113, 118, 123, 134, 143, 224, 285, 311, 394], "posterior": [108, 225, 227, 232, 233, 234], "gaussiannb": 108, "text": 108, "dirichlet": [108, 159, 228, 230, 234], "multinomialnb": 108, "complementnb": 108, "categoricalnb": 108, "partial_fit": 108, "support": [109, 132, 227, 285], "svc": 109, "svr": [109, 130, 132], "maximum": [109, 144, 219], "lagrang": 109, "multipli": 109, "kkt": 109, "thei": [109, 112, 144, 146, 157, 196, 269], "show": [109, 154, 250, 254], "inequ": 109, "svm": 109, "primal": 109, "dual": 109, "lagrangian": 109, "rbf": 109, "poli": 109, "simplifi": 109, "smo": 109, "tube": 109, "insensit": 109, "also": [109, 196, 221], "pick": [109, 110, 112], "tree": [110, 129], "forest": [110, 128], "boost": 110, "impur": 110, "question": [110, 242, 252], "did": 110, "gini": 110, "ensembl": [110, 128, 129, 288, 301], "bag": 110, "modern": 110, "librari": [110, 113], "tutor": 110, "analog": [110, 125], "xgboost": 110, "lightgbm": 110, "catboost": 110, "growth": 110, "arch": 111, "volatil": [111, 121, 329, 389], "heteroskedast": [111, 121], "financi": [111, 390], "market": [111, 121], "shock": [111, 117, 121, 123], "q": [111, 114, 116, 117, 119, 123, 137, 139, 141, 254, 297, 298], "latex": [111, 112, 113, 121, 185], "keep": 111, "h_t": 111, "stationar": [111, 112, 118, 119, 271], "finit": [111, 197], "uncondit": 111, "breakdown": [111, 121], "term": [111, 114, 261, 300, 327], "autoregress": [112, 117, 118, 119], "scalar": [112, 221, 314], "promis": 112, "lag": [112, 117, 118, 306, 328], "chosen": 112, "aic": 112, "bic": 112, "so": 112, "know": [112, 331, 332, 333, 334, 335, 338, 340, 341, 342, 344, 347, 348, 355, 358, 359], "truth": 112, "kalman": 113, "hidden": 113, "transit": [113, 141], "dynam": [113, 123, 136, 285, 312, 313, 314, 315, 316, 317, 389], "initi": 113, "arima": [113, 116, 119, 122, 297], "control": [113, 137, 146, 208, 249, 269], "correctli": 113, "concret": [113, 243], "noisi": 113, "sensor": 113, "14": 113, "evolut": [5, 113], "15": 113, "01": 114, "ma": [114, 117, 123], "backshift": [114, 119], "simul": [114, 117, 118, 123, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 249, 258, 261, 267, 301, 303, 394], "box": [114, 120, 194], "jenkin": [114, 333], "autocovari": 114, "autocorrel": [114, 271], "acf": [114, 271, 297, 298], "impuls": [114, 117, 118], "invert": 114, "innov": [114, 239], "prophet": 115, "wrapper": 115, "sarima": [116, 122], "season": [116, 120, 122, 124, 127, 271, 300, 307, 323, 327], "differenc": [116, 119, 323], "full": [116, 143, 311], "tupl": 116, "varma": [117, 123], "var": [117, 118], "varmax": [117, 123], "identifi": [117, 123], "multivari": [117, 118, 123, 189, 221], "mont": [117, 151, 162, 176, 183, 194, 195, 203, 209, 213, 229, 244, 249], "carlo": [117, 151, 162, 176, 183, 194, 195, 203, 209, 213, 229, 244, 249], "fan": 117, "chart": 117, "propag": [117, 123], "between": 118, "companion": 118, "interact": 118, "stabl": [118, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 153], "irf": 118, "takeawai": [118, 154, 187, 250], "integr": [119, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241], "first": 119, "second": [119, 162, 204, 213], "th": [119, 196], "determinist": [119, 134, 137, 138, 144], "trend": [119, 120, 271, 329], "warn": 119, "educ": [119, 122, 249], "arma": [119, 120, 122], "recurs": [119, 125, 131, 308], "world": [119, 122, 148, 150, 151, 152, 153, 154, 155, 157, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 245], "bat": [120, 300], "sketch": [120, 124, 127, 138, 159, 169, 190, 197], "cox": 120, "garch": 121, "sarimax": 122, "exogen": [122, 123, 296, 312], "incorpor": 122, "causal": 122, "leakag": 122, "intercept": 122, "varx": 123, "transfer": 123, "realli": [123, 264], "abstract": 123, "ignor": 123, "known": [123, 178, 194, 247], "futur": [123, 312, 314], "tbat": [124, 300], "long": [124, 329], "weekli": 124, "yearli": 124, "ts": 125, "window": [125, 127, 131, 132, 299, 310, 323, 329], "repeat": [125, 253], "confid": [125, 152, 196, 245, 255, 262, 265, 266], "beyond": 125, "composabletimeseriesforestregressor": 127, "sktime": [127, 131, 283, 284, 285, 286, 287, 288, 289, 292, 293, 295, 296, 297, 298, 299, 300, 301, 303, 305, 306, 308, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 322, 323, 328, 329], "tsf": [127, 129], "slide": [127, 131, 132, 310, 323], "timeseriesforestregressor": [129, 321], "interv": [129, 152, 196, 245, 255, 262, 265, 266, 289, 305, 318], "rocket": [130, 131, 291], "rocketregressor": [131, 320], "ridgecv": 131, "timeseriessvrtslearn": 132, "tslearn": 132, "page": 132, "a2c": 134, "advantag": [134, 143], "actor": [134, 135, 136, 137, 138, 142, 143, 144, 145], "critic": [134, 135, 136, 137, 138, 142, 143, 144, 145, 250], "cartpol": [134, 136, 142, 143], "v1": [134, 136, 143], "polici": [134, 135, 137, 138, 140, 142, 143, 145, 146], "return": [134, 139, 394], "theorem": 134, "bootstrap": [134, 245, 255, 265], "n": [134, 224, 225, 230, 231, 233, 234, 261, 262, 312, 313, 314, 315], "gae": [134, 136, 140, 142, 143], "episod": [134, 141, 142], "last": [134, 314], "slice": 134, "baselines3": [134, 138, 139, 141, 144, 145], "research": [134, 141, 142], "sb3": [134, 140, 141, 144], "signatur": 134, "acktr": [135, 136], "kroneck": 135, "factor": [135, 209, 394], "trust": [135, 146], "region": [135, 146, 250], "improv": 135, "fisher": [135, 224, 232, 251, 261], "fac": [135, 136], "curvatur": 135, "environ": [136, 139, 140, 141, 142, 146], "rollout": [136, 140, 142, 367], "snippet": [136, 383], "ddpg": [137, 138, 141, 145], "part": 137, "replai": [137, 139, 141, 144], "buffer": [137, 141, 144], "off": 137, "explor": 137, "want": [138, 312], "tensorflow": 138, "older": 138, "tau": [138, 255], "replay_s": 138, "batch_siz": 138, "start_step": 138, "update_aft": 138, "updates_per_step": 138, "noise_sigma": 138, "hidden_s": 138, "grad_clip_norm": 138, "dqn": 139, "mdp": 139, "bellman": 139, "gymnasium": [139, 141], "adversari": 140, "imit": 140, "gail": 140, "ppo": [140, 142, 143], "download": 140, "gym": 140, "expert": 140, "demonstr": 140, "trajectori": 140, "hindsight": 141, "her": 141, "rl": [141, 143, 144], "dict": 141, "agent": 141, "success": [141, 225], "sb": [141, 143], "ppo1": [142, 143], "clip": [142, 143], "r_t": 142, "hint": 142, "proxim": 143, "ppo2": 143, "break": [143, 250], "name": [143, 358, 359], "In": 143, "paper": 143, "openai": 143, "main": [143, 381], "lambda": [143, 162, 191, 219, 220, 227, 349], "sac": 144, "twin": [144, 145], "temperatur": 144, "delai": 145, "td3": 145, "min": 145, "glossari": 145, "trpo": 146, "lead": 146, "offlin": 146, "friendli": 146, "build": [146, 191, 263, 280], "block": [146, 191, 253], "titl": [148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241], "pdf": [148, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222], "cdf": [148, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 256], "ppf": [148, 160, 161, 165, 174, 179, 199, 215, 220], "moment": [148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241], "tail": [148, 154, 160, 171, 175, 181, 182, 187, 196, 229, 235, 236, 237, 242, 250, 269], "mgf": [148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241], "scipi": [148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 246, 247, 252, 260, 262, 264, 267, 268], "hypothesi": [148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 245, 250, 255, 260, 261, 262, 265, 266], "bayesian": [148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241], "anglit": 149, "through": 149, "sine": [149, 319], "locat": [149, 151, 154, 155, 156, 161, 164, 165, 167, 168, 171, 172, 177, 178, 180, 181, 187, 188, 194, 197, 198, 200, 203, 204, 206, 207, 208, 216, 219, 220, 227, 229, 252], "stat": [149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 164, 166, 167, 168, 169, 171, 172, 173, 174, 175, 178, 180, 181, 182, 183, 184, 185, 187, 188, 189, 192, 193, 194, 195, 197, 198, 199, 200, 201, 203, 204, 205, 207, 208, 209, 210, 211, 213, 214, 215, 217, 218, 219, 221, 222, 224, 227], "arcsin": 150, "memor": 150, "trig": 150, "substitut": 150, "law": [150, 181, 196, 206, 215], "jeffrei": 150, "binomi": [150, 152, 224, 225, 226, 230, 231, 234, 237], "argu": 151, "bessel": [151, 203], "appear": [151, 266], "mathbb": [151, 154, 314], "e": [151, 154, 253, 314], "x": [151, 154, 190, 195, 313, 314, 315], "truncat": [151, 213, 214, 215, 216, 236], "represent": [151, 191, 192, 199, 233, 295, 315], "uncertain": [152, 191, 237], "concentr": 152, "reparameter": 152, "regim": 152, "iid": [152, 159, 165, 181, 182, 227], "marsaglia": [152, 158, 166, 169, 190, 197], "tsang": [152, 158, 166, 169, 190, 197], "proport": [152, 200, 223], "bradford": 153, "higher": [153, 213, 237], "burr": 154, "type": [154, 197, 233, 267, 296, 377], "iii": [154, 197], "dagum": [154, 187], "raw": [154, 164, 165, 166, 168, 170, 171, 173, 182, 187, 190, 196, 199, 200, 203, 205, 214, 215, 216, 220, 241], "bodi": 154, "lower": [154, 230], "lomax": 154, "cauchi": [155, 207, 222], "method": [155, 182, 284, 309], "cosin": 156, "accept": [156, 214], "reject": [156, 170, 214, 242, 244, 250, 262], "crystal": 157, "crystalbal": 157, "our": 157, "dgamma": 158, "doubl": [158, 160, 161, 176], "2000": [158, 169, 197], "conjug": [159, 178, 186], "pareto": [160, 196, 215], "lognorm": [160, 183, 199], "dpareto_lognorm": 160, "dweibul": 161, "weibul": [161, 165, 216, 219, 220], "loc": [161, 163, 164, 167, 172, 173, 175, 177, 180, 200, 207, 213, 216, 219, 220, 227, 229], "expon": 162, "memoryless": [162, 235], "surviv": [162, 165, 168, 171, 199, 200, 235, 240], "hazard": [162, 165, 168, 171, 199, 200, 220], "nat": [162, 183, 194, 213, 217], "notabl": [162, 194, 217], "theta": [162, 169, 309], "mle": [162, 176, 178, 179, 182, 183, 184, 186, 190, 194, 196, 198, 201, 203, 217, 229, 230, 235], "exponnorm": 163, "modifi": 163, "exgaussian": 163, "hierarch": [163, 169, 224, 225, 296], "anomali": [163, 225, 272, 284, 322], "power": [164, 191, 192, 193, 196, 198, 199, 200, 215, 244, 252, 267, 269], "exponpow": 164, "everyth": 164, "exp": 164, "exponweib": 165, "nest": 165, "f": [166, 191, 195, 243, 250, 312], "fatigu": 167, "life": 167, "fatiguelif": 167, "birnbaum": 167, "saunder": 167, "fisk": 168, "workhors": 168, "abl": [169, 180, 190, 197, 205, 208, 214, 218, 219], "after": [169, 180, 190, 197, 205, 208, 214, 218, 219], "gausshyp": 170, "gauss": 170, "hypergeometr": [170, 232, 233, 234], "sampler": [170, 190, 201, 202, 203, 207, 218, 235], "genexpon": 171, "nice": 171, "converg": 171, "lambert": 171, "bisect": [171, 204], "here": [171, 251, 285], "genextrem": 172, "gev": 172, "evt": 172, "textbook": 172, "sigma": [172, 194, 221], "xi": [172, 208], "gengamma": 173, "most": [173, 267, 358, 359], "half": [174, 188, 252], "genhalflogist": 174, "bound": [174, 206, 215, 217, 238], "landau": [175, 188], "fact": [175, 177], "asymmetr": 177, "laplace_asymmetr": 177, "repres": 177, "l\u00e9vy": [178, 179], "levi": 178, "infinit": 178, "infer": [178, 193], "flight": 178, "left": [179, 312], "levy_l": 179, "profil": [179, 293], "loggamma": 180, "sigmoid": 181, "\u211d": 181, "symmetr": [182, 202, 208], "heavi": [182, 196, 229, 242, 250, 269], "infti": 182, "handi": 182, "viewpoint": 182, "loglaplac": 182, "qualit": 183, "loguniform": 184, "sit": 184, "matrix_norm": 185, "matric": [185, 221], "m": [185, 190, 233], "u": [185, 260], "maxwel": 186, "mielk": 187, "moyal": 188, "energi": [188, 227], "compat": 188, "chi": [188, 193, 246, 247, 248], "multivariate_norm": 189, "closur": 189, "nakagami": 190, "spread": 190, "omega": [190, 208, 233], "noncentr": [191, 192, 193, 232, 233], "ncf": 191, "central": 191, "mixtur": [191, 192, 193, 207, 225, 231, 238, 240], "degre": [191, 192, 221, 247, 266, 269], "freedom": [191, 192, 221, 247, 266, 269], "nu_1": 191, "nu_2": 191, "denomin": 191, "nct": 192, "nu": [192, 221], "delta": [192, 195, 389], "ncx2": 193, "norm": [193, 194], "side": [193, 229, 250, 251, 256, 264], "z": [193, 194, 258, 261, 264, 315], "muller": 194, "conjugaci": [194, 226, 230, 236], "norminvgauss": 195, "mid": 195, "cgf": 195, "minimum": [196, 199, 200, 216, 220, 331, 332, 333, 334, 335, 338, 340, 341, 342, 344, 347, 348, 355, 358, 359], "x_m": 196, "principl": [196, 334, 335], "endpoint": 197, "pearson3": 197, "powerlaw": 198, "canon": [198, 206], "powerlognorm": 199, "shortcut": 199, "powernorm": 200, "rayleigh": 201, "geometr": [201, 206, 229, 231, 235], "rdist": 202, "reciproc": 203, "recipinvgauss": 203, "invgauss": [203, 218], "gig": 203, "michael": [203, 218], "schucani": [203, 218], "haa": [203, 218], "relativist": 204, "breit": 204, "wigner": [204, 206], "rel_breitwign": 204, "background": 204, "rice": 205, "rician": 205, "polar": 205, "semicircular": 206, "semicircl": 206, "disk": 206, "skewcauchi": 207, "skewnorm": 208, "rang": 209, "studentized_rang": 209, "tukei": 209, "hsd": 209, "triangular": 212, "triang": 212, "truncexpon": 213, "truncnorm": 214, "truncpareto": 215, "arbitrari": 215, "doubli": 216, "truncweibull_min": 216, "wald": [218, 261], "weibull_max": 219, "weibull_min": 220, "wishart": 221, "scatter": [221, 328], "entrywis": 221, "argument": 221, "entri": 221, "bartlett": [221, 244], "wrap": 222, "wrapcauchi": 222, "trigonometr": [222, 300], "pmf": [223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 251], "coin": 223, "fair": [223, 246, 247], "betabinom": 224, "excess": [224, 234], "pgf": [224, 225, 234, 240], "intraclass": 224, "trial": [224, 226], "overdispers": [224, 231], "invalid": [224, 226, 230, 236], "suggest": 224, "betanbinom": 225, "result": [225, 242, 243, 244, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 260, 261, 262, 263, 265, 266, 269, 270], "factori": 225, "binom": 226, "boltzmann": 227, "partit": 227, "lrt": 227, "gibb": 227, "softmax": 227, "dirichlet_multinomi": 228, "dlaplac": 229, "decai": 229, "orthant": 230, "total": 230, "draw": [230, 233], "sequenti": [230, 233, 234], "nbinom": 231, "heterogen": 231, "nchypergeom_fish": 232, "odd": [232, 233, 251, 261], "nchypergeom_walleniu": 233, "walleniu": 233, "bias": 233, "urn": [233, 234], "replac": [233, 260], "swap": 233, "popul": 233, "composit": [233, 301], "field": 233, "od": 233, "nhypergeom": 234, "gap": 234, "replic": 234, "blue": 234, "planck": 235, "knuth": 236, "product": 236, "poisson_binom": 237, "randint": 238, "skellam": 239, "yule": 240, "simon": 240, "yulesimon": 240, "zipfian": 241, "anderson": 242, "darl": 242, "answer": [242, 252], "applic": [242, 331], "hypothes": [242, 243, 244, 246, 247, 248, 250, 251, 253, 256, 257, 259, 264, 267, 269, 270], "a\u00b2": 242, "thumb": [242, 371], "anova": [243, 249, 250, 253, 257], "decompos": [243, 315], "truli": 244, "solv": [245, 249, 250, 263], "exactli": [245, 250], "NOT": [246, 263], "\u03c7\u00b2": [246, 247], "x\u00b2": 246, "die": [246, 247], "discrep": 246, "gof": 247, "ok": 247, "candi": 247, "color": 247, "flag": 247, "deviat": [247, 252], "agostino": [248, 264], "dagostino_k2": 248, "inspect": [248, 285], "sim": 248, "dunnett": 249, "pool": [249, 266], "accur": 249, "enough": 249, "insight": 249, "fwer": 249, "h\u2080": 250, "f_ob": 250, "\u03b1": 250, "05": [250, 253], "h\u2081": 250, "everywher": 250, "greater": 251, "less": 251, "fligner": 252, "killeen": 252, "group": [252, 267, 296], "center": [252, 259], "convert": 252, "alon": 252, "trigger": 252, "look": [252, 258, 264], "h0": [252, 258, 261, 264, 269], "h1": 252, "friedman": 253, "nonparametr": [253, 270], "layout": 253, "overlook": 253, "within": [253, 267], "kendal": [253, 255], "u2019": 253, "If": 253, "g": [253, 313, 314], "report": [253, 257, 262], "jarqu": 254, "bera": 254, "jarque_bera": 254, "asymptot": 254, "jb": 254, "histogram": 254, "concord": 255, "discord": 255, "sign": [255, 263, 268, 270], "magnitud": [255, 270], "associ": 255, "than": 255, "recommend": 255, "kolmogorov": 256, "smirnov": 256, "ks": 256, "isn": 256, "ecdf": 256, "evid": 256, "tell": 256, "kruskal": 257, "walli": 257, "h": [257, 312], "explicitli": [257, 379], "realist": 257, "signific": [257, 266], "post": 257, "hoc": 257, "anscomb": 258, "glynn": 258, "leven": 259, "win": 260, "cautionari": 260, "impli": 260, "being": 261, "OR": 261, "mislead": 261, "h_0": [262, 270], "parametr": 262, "strong": 262, "have": 262, "exchang": 263, "flip": [263, 268], "skewtest": 264, "spearman": 265, "\u03c1": 265, "end": [265, 381], "vocabulari": 266, "welch": [266, 267], "df": 266, "t_test_independ": 267, "unequ": 267, "ttest_rel": 268, "must": 268, "happen": 269, "procedur": 269, "follow": 269, "tool": 270, "purpos": [17, 18, 23, 24, 133, 147, 272, 273, 274, 276, 277, 278, 279, 282, 285], "topic": [0, 10, 17, 18, 23, 24, 133, 147, 272, 273, 274, 276, 277, 278, 279, 282, 330, 387, 397, 404], "coverag": [275, 305], "pipelin": [281, 323, 382], "task": [285, 322], "kneighborstimeseriesclassifi": 290, "rocketclassifi": 291, "ridgeclassifi": 291, "timeseriesforestclassifi": 294, "stationari": [297, 298], "pacf": [271, 297, 298], "autoarima": 298, "et": 302, "horizon": [271, 304, 306, 307, 310, 312], "rockettransform": 324, "tsfreshfeatureextractor": 325, "instal": 325, "detrend": 326, "argo": 331, "gitop": 331, "deliveri": 331, "team": [331, 332, 333], "manifest": 331, "pseudo": [331, 332, 333, 334, 335, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 365, 366, 367, 369, 370, 373, 374, 375, 376, 377, 378], "capabl": [331, 332, 333, 334, 335, 359], "github": 332, "yaml": [332, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 386], "execut": 333, "flow": 333, "jenkinsfil": 333, "pulumi": 334, "infrastructur": [334, 335, 362], "languag": 334, "aw": [334, 335, 337, 338, 339, 342, 343, 345, 346, 348, 349, 350, 351, 352, 354, 356, 357], "stack": [334, 335, 381], "terraform": 335, "servic": [337, 343, 344, 351, 352, 354, 355, 377, 383], "icon": 337, "cloudform": 338, "sdk": [338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357], "cloudfront": 339, "amazon": [340, 341, 342, 343, 344, 345, 346, 347, 351, 352, 354, 355, 357], "cloudwatch": 340, "dynamodb": 341, "ec2": 342, "ec": 343, "contain": [296, 313, 343, 358, 359, 360], "ek": 344, "elasticach": 345, "emr": 346, "mapreduc": 346, "eventbridg": 347, "glue": 348, "apach": 350, "airflow": 350, "mwaa": 350, "rd": 351, "databas": 351, "s3": 352, "snowflak": 353, "platform": 353, "sn": 354, "notif": 354, "sq": 355, "vpc": 357, "virtual": 357, "privat": 357, "docker": [358, 359], "command": [358, 359], "intern": 358, "ip": [358, 359], "linux": 358, "volum": [358, 359, 373], "mount": [358, 359], "persist": [328, 358, 359, 373], "bind": [358, 359], "host": 358, "tmpf": 358, "back": 358, "compos": [358, 359], "file": [358, 371], "podman": 359, "rootless": 359, "server": 359, "admin": 359, "develop": 359, "configmap": 365, "templat": [365, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379], "pod": [365, 368, 373, 374, 376], "consum": [365, 376], "cronjob": 366, "deploy": 367, "stateless": 367, "workload": [367, 378], "hpa": 368, "horizont": 368, "autoscal": 368, "autosc": 368, "v2": 368, "ingress": 369, "job": 370, "kustom": 371, "overlai": 371, "repo": 371, "helm": 371, "namespac": 372, "put": 372, "resourc": 372, "pv": 373, "persistentvolumeclaim": 373, "pvc": [373, 379], "replicaset": 375, "replica": 375, "reconcili": 375, "secret": 376, "statefulset": 378, "storageclass": 379, "elasticsearch": [382, 385], "event": 382, "bulk": 382, "grafana": [381, 383], "health": 383, "dashboard": 383, "prometheu": [381, 383, 386], "alert": [383, 384, 386], "provis": 383, "kibana": 384, "kql": 384, "spike": 384, "logstash": 385, "pars": 385, "nginx": 385, "instrument": [381, 386], "app": 386, "configur": 386, "scrape": 386, "promql": 386, "black": 389, "schole": 389, "price": 389, "stock": 389, "payoff": 389, "expir": 389, "surfac": 389, "greek": 389, "vega": 389, "frontier": 393, "fama": 394, "french": 394, "monthli": 394, "load": 394, "commun": 4, "consider": 4, "piec": 280, "scityp": [285, 296], "catalog": [285, 311, 312, 313, 314, 315, 316, 317], "taxonomi": 285, "tag": 285, "avail": 285, "registri": [311, 312, 313, 314, 315, 316, 317], "rest": 1, "pagin": 1, "jwt": 2, "anatomi": 2, "sql": 5, "nosql": 5, "schema": 5, "frequenc": [271, 313], "stl": 271, "partial": 271, "backtest": [271, 299], "organ": [], "dive": [], "dictionari": 286, "inventori": [286, 287, 288, 289, 292, 300, 318], "shapelet": [292, 293], "shapelettransformclassifi": 293, "motif": 293, "pointer": [299, 305, 308], "refresh": 308, "nwe": 312, "y_": 312, "x_": 312, "na": [312, 313, 314], "dot": [312, 313], "hat": [312, 313, 314], "_": 312, "quad": 312, "nthe": 312, "panel": [296, 313], "nand": 313, "nclassif": 313, "emphas": 313, "tempor": 313, "distinguish": 313, "nin": 314, "ntarget": 314, "summar": 314, "slope": 314, "ntransform": 315, "appli": 315, "phi": 315, "produc": 315, "new": 315, "extract": 315, "downstream": 315, "kneighborstimeseriesregressor": 319, "wave": 319, "vari": 319, "amplitud": 319, "preprocess": 323, "engin": 323, "collect": 381, "elk": 381, "emit": 381, "theori": 392, "mitig": 400, "orient": 283, "vote": 288, "mtype": 296, "univari": 296, "fourier": [300, 327], "intermitt": 303, "demand": 303, "croston": 303, "sba": 303, "tsb": 303, "snapshot": 303, "creat": 306, "expand": 310, "cv": 310, "annot": [317, 322], "basi": 327, "live": [328, 329], "short": 329}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx": 56}})