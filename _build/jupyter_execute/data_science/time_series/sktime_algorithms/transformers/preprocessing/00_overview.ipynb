{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed3ae49",
   "metadata": {},
   "source": [
    "# sktime Preprocessing Transformers\n",
    "Time series pipelines often need careful preprocessing before modeling. sktime provides a consistent transformer API\n",
    "to handle detrending, deseasonalizing, variance stabilization, imputation, and feature generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d12af82",
   "metadata": {},
   "source": [
    "## Core notation\n",
    "Let a univariate series be $y_t$ for $t=1,\\dots,T$. Common transforms include:\n",
    "\n",
    "- First difference: $\\nabla y_t = y_t - y_{t-1}$\n",
    "- Seasonal difference: $\\nabla_s y_t = y_t - y_{t-s}$\n",
    "- Box-Cox: $y_t^{(\\lambda)} = \\frac{y_t^\\lambda - 1}{\\lambda}$ (or $\\log y_t$ when $\\lambda=0$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe72c9",
   "metadata": {},
   "source": [
    "## Why preprocessing matters\n",
    "- Improve stationarity so models can focus on short-term dynamics\n",
    "- Separate trend/seasonal components for cleaner residuals\n",
    "- Handle missing data and stabilize variance\n",
    "- Provide robust lagged or window-based features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa69870",
   "metadata": {},
   "source": [
    "## Common transformer families in sktime\n",
    "- **Trend/seasonality**: `Detrender`, `Deseasonalizer`\n",
    "- **Differencing**: `Differencer`\n",
    "- **Variance stabilization**: `BoxCoxTransformer`\n",
    "- **Missing data**: `Imputer`\n",
    "- **Feature engineering**: `Lag`, `WindowSummarizer`, `FourierFeatures`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc62ff",
   "metadata": {},
   "source": [
    "## Quick visual: differencing a seasonal series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a35354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "t = np.arange(0, 120)\n",
    "trend = 0.05 * t\n",
    "season = 2.0 * np.sin(2 * np.pi * t / 12)\n",
    "noise = rng.normal(0, 0.5, size=t.size)\n",
    "y = trend + season + noise\n",
    "\n",
    "y_diff = np.diff(y, n=1)\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.1)\n",
    "fig.add_trace(go.Scatter(x=t, y=y, name=\"original\"), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=t[1:], y=y_diff, name=\"first difference\"), row=2, col=1)\n",
    "fig.update_layout(height=500, title=\"Original vs First Difference\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2737e1",
   "metadata": {},
   "source": [
    "## sktime pipeline example\n",
    "The `TransformedTargetForecaster` applies a sequence of transformations before forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f00eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "from sktime.forecasting.model_selection import ForecastingHorizon, temporal_train_test_split\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.transformations.series.boxcox import BoxCoxTransformer\n",
    "from sktime.transformations.series.detrend import Detrender, Deseasonalizer\n",
    "\n",
    "y = load_airline()\n",
    "y_train, y_test = temporal_train_test_split(y, test_size=36)\n",
    "fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
    "\n",
    "pipe = TransformedTargetForecaster(steps=[\n",
    "    (\"boxcox\", BoxCoxTransformer()),\n",
    "    (\"deseasonalize\", Deseasonalizer(model=\"additive\", sp=12)),\n",
    "    (\"detrend\", Detrender()),\n",
    "    (\"forecaster\", NaiveForecaster(strategy=\"drift\")),\n",
    "])\n",
    "\n",
    "pipe.fit(y_train)\n",
    "pred = pipe.predict(fh)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=y_train.index, y=y_train, name=\"train\"))\n",
    "fig.add_trace(go.Scatter(x=y_test.index, y=y_test, name=\"test\"))\n",
    "fig.add_trace(go.Scatter(x=pred.index, y=pred, name=\"forecast\"))\n",
    "fig.update_layout(title=\"TransformedTargetForecaster pipeline\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cadc72e",
   "metadata": {},
   "source": [
    "## Sliding window feature engineering (concept)\n",
    "Even without a dedicated transformer, you can create lagged and rolling features directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b833bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"y\": y})\n",
    "df[\"lag_1\"] = df[\"y\"].shift(1)\n",
    "df[\"lag_12\"] = df[\"y\"].shift(12)\n",
    "df[\"roll_mean_12\"] = df[\"y\"].rolling(12).mean()\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd73a643",
   "metadata": {},
   "source": [
    "## Practical tips\n",
    "- Use **deseasonalization** before differencing when seasonality dominates.\n",
    "- Keep transformations in a pipeline to avoid leakage across train/test splits.\n",
    "- For long seasonal periods, combine seasonal differencing with Fourier features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}