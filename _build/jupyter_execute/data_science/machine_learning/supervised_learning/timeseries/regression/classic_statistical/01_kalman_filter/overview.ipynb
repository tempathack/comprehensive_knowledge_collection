{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f5db7a",
   "metadata": {},
   "source": [
    "# Kalman Filter — linear Gaussian state-space model (NumPy + Plotly)\n",
    "\n",
    "The **Kalman filter** is a **recursive Bayesian estimator** for **linear** dynamical systems with **Gaussian** noise.\n",
    "\n",
    "At each time step it computes the posterior distribution of a **hidden (latent) state** $\\mathbf{x}_t$ given the observations $\\mathbf{y}_{1:t}$:\n",
    "\n",
    "- filtered mean: $\\hat{\\mathbf{x}}_{t\\mid t} = \\mathbb{E}[\\mathbf{x}_t \\mid \\mathbf{y}_{1:t}]$\n",
    "- filtered covariance: $\\mathbf{P}_{t\\mid t} = \\mathrm{Cov}(\\mathbf{x}_t \\mid \\mathbf{y}_{1:t})$\n",
    "\n",
    "This notebook explains:\n",
    "\n",
    "- what the algorithm is and why it is a **state-space model**\n",
    "- how it differs from **ARIMA-style** time-series models\n",
    "- where it is used (tracking, finance, control systems)\n",
    "- intuition for the **predict \\u2192 update** cycle and **uncertainty propagation**\n",
    "- a low-level **NumPy** implementation + **Plotly** visualizations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d51b43",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Linear algebra: vectors/matrices, transpose, matrix multiplication\n",
    "- Gaussians: mean/covariance, conditioning intuition (\"posterior = prior + data\")\n",
    "- Basic time-series vocabulary (state, observation, noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013397a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "print(\"Python\", platform.python_version())\n",
    "print(\"NumPy\", np.__version__)\n",
    "print(\"Plotly\", plotly.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e692c",
   "metadata": {},
   "source": [
    "## 1) What the Kalman filter is\n",
    "\n",
    "The Kalman filter is an **online** (streaming) algorithm that updates an estimate as new measurements arrive.\n",
    "\n",
    "It solves this problem:\n",
    "\n",
    "> A system evolves over time with some randomness, and we observe **noisy measurements** of it. We want the **best estimate** of the system's current (hidden) state.\n",
    "\n",
    "In the **linear + Gaussian** case, the posterior distribution remains Gaussian. That means we only need to carry forward two objects:\n",
    "\n",
    "- the mean estimate $\\hat{\\mathbf{x}}$ (\"where we think the state is\")\n",
    "- the covariance $\\mathbf{P}$ (\"how uncertain we are\")\n",
    "\n",
    "Under the Kalman filter assumptions, this recursion is **optimal** among all estimators in the mean-squared-error sense.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6feea6",
   "metadata": {},
   "source": [
    "## 2) Why it is a state-space model\n",
    "\n",
    "A **state-space model** describes a process using:\n",
    "\n",
    "- a **state transition** equation: how the hidden state changes over time\n",
    "- an **observation** equation: how measurements are generated from the state\n",
    "\n",
    "Two key conditional independence (Markov) ideas:\n",
    "\n",
    "- **State is Markov**: $p(\\mathbf{x}_t \\mid \\mathbf{x}_{0:t-1}) = p(\\mathbf{x}_t \\mid \\mathbf{x}_{t-1})$\n",
    "- **Observation depends on current state only**: $p(\\mathbf{y}_t \\mid \\mathbf{x}_{0:t}, \\mathbf{y}_{1:t-1}) = p(\\mathbf{y}_t \\mid \\mathbf{x}_t)$\n",
    "\n",
    "This separation is why Kalman filtering is so common in **tracking** and **control**: you explicitly model both **dynamics** (physics) and **measurement** (sensor).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a1e042",
   "metadata": {},
   "source": [
    "## 3) Hidden (latent) state vs observed variables\n",
    "\n",
    "- **Hidden state** ($\\mathbf{x}_t$): the quantity you *care about* but cannot directly observe.\n",
    "- **Observed variable** ($\\mathbf{y}_t$): what you can measure (often noisy and partial).\n",
    "\n",
    "Example (tracking):\n",
    "\n",
    "- State: $\\mathbf{x}_t = [\\text{position}_t,\\ \\text{velocity}_t]^\\top$\n",
    "- Observation: $\\mathbf{y}_t = [\\text{measured position}_t]$\n",
    "\n",
    "You never measure velocity directly, but you infer it because the model links position and velocity over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6134cea",
   "metadata": {},
   "source": [
    "## 4) Model assumptions (linearity, Gaussian noise)\n",
    "\n",
    "The *classical* Kalman filter is exact for **linear Gaussian state-space models**.\n",
    "\n",
    "Assumptions (typical form):\n",
    "\n",
    "- **Linearity**: both dynamics and measurement are linear functions of the state.\n",
    "- **Gaussian noise**: both process noise and measurement noise are Gaussian.\n",
    "- **Independence**: noises are independent across time and independent of the initial state.\n",
    "- **Known parameters**: you know (or choose/tune) the matrices $\\mathbf{F}, \\mathbf{H}$ and covariances $\\mathbf{Q}, \\mathbf{R}$.\n",
    "\n",
    "If your system is nonlinear or non-Gaussian, you typically move to variants like the **Extended KF (EKF)**, **Unscented KF (UKF)**, or **particle filters**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc1b86a",
   "metadata": {},
   "source": [
    "## 5) State transition and observation equations (LaTeX)\n",
    "\n",
    "A discrete-time linear Gaussian state-space model is:\n",
    "\n",
    "### State transition (dynamics)\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_t = \\mathbf{F}_t\\,\\mathbf{x}_{t-1} + \\mathbf{B}_t\\,\\mathbf{u}_t + \\mathbf{w}_t,\n",
    "\\quad \\mathbf{w}_t \\sim \\mathcal{N}(\\mathbf{0},\\ \\mathbf{Q}_t)\n",
    "$$\n",
    "\n",
    "### Observation model (measurement)\n",
    "\n",
    "$$\n",
    "\\mathbf{y}_t = \\mathbf{H}_t\\,\\mathbf{x}_t + \\mathbf{v}_t,\n",
    "\\quad \\mathbf{v}_t \\sim \\mathcal{N}(\\mathbf{0},\\ \\mathbf{R}_t)\n",
    "$$\n",
    "\n",
    "### Initial state\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_0 \\sim \\mathcal{N}(\\hat{\\mathbf{x}}_{0\\mid 0},\\ \\mathbf{P}_{0\\mid 0})\n",
    "$$\n",
    "\n",
    "Step-by-step meaning:\n",
    "\n",
    "- $\\mathbf{x}_t \\in \\mathbb{R}^n$: latent state vector (size $n$)\n",
    "- $\\mathbf{y}_t \\in \\mathbb{R}^m$: observation vector (size $m$)\n",
    "- $\\mathbf{F}_t$: state transition matrix (how state evolves)\n",
    "- $\\mathbf{u}_t$: optional control input (known exogenous action)\n",
    "- $\\mathbf{B}_t$: maps control input into the state\n",
    "- $\\mathbf{w}_t$: **process noise** (unmodeled dynamics / disturbances)\n",
    "- $\\mathbf{Q}_t$: covariance of process noise (how \"wiggly\" the dynamics are)\n",
    "- $\\mathbf{H}_t$: observation matrix (maps state into measurement space)\n",
    "- $\\mathbf{v}_t$: **measurement noise** (sensor error)\n",
    "- $\\mathbf{R}_t$: covariance of measurement noise (sensor quality)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4705945",
   "metadata": {},
   "source": [
    "## 6) Kalman filter equations (prediction + update)\n",
    "\n",
    "Notation:\n",
    "\n",
    "- $\\hat{\\mathbf{x}}_{t\\mid t-1}$: estimate at time $t$ using observations up to $t-1$ (**prediction / prior**)\n",
    "- $\\hat{\\mathbf{x}}_{t\\mid t}$: estimate at time $t$ using observations up to $t$ (**update / posterior**)\n",
    "- $\\mathbf{P}_{t\\mid t-1}$ and $\\mathbf{P}_{t\\mid t}$: the corresponding covariances\n",
    "\n",
    "### Prediction step\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{x}}_{t\\mid t-1} = \\mathbf{F}_t\\,\\hat{\\mathbf{x}}_{t-1\\mid t-1} + \\mathbf{B}_t\\,\\mathbf{u}_t\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{P}_{t\\mid t-1} = \\mathbf{F}_t\\,\\mathbf{P}_{t-1\\mid t-1}\\,\\mathbf{F}_t^\\top + \\mathbf{Q}_t\n",
    "$$\n",
    "\n",
    "Step-by-step:\n",
    "\n",
    "- The mean is pushed forward by the dynamics.\n",
    "- The covariance is pushed forward and then **inflated by $\\mathbf{Q}_t$** to represent new uncertainty introduced by the process.\n",
    "\n",
    "### Update step\n",
    "\n",
    "Innovation (measurement residual):\n",
    "\n",
    "$$\n",
    "\\tilde{\\mathbf{y}}_t = \\mathbf{y}_t - \\mathbf{H}_t\\,\\hat{\\mathbf{x}}_{t\\mid t-1}\n",
    "$$\n",
    "\n",
    "Innovation covariance:\n",
    "\n",
    "$$\n",
    "\\mathbf{S}_t = \\mathbf{H}_t\\,\\mathbf{P}_{t\\mid t-1}\\,\\mathbf{H}_t^\\top + \\mathbf{R}_t\n",
    "$$\n",
    "\n",
    "Kalman gain:\n",
    "\n",
    "$$\n",
    "\\mathbf{K}_t = \\mathbf{P}_{t\\mid t-1}\\,\\mathbf{H}_t^\\top\\,\\mathbf{S}_t^{-1}\n",
    "$$\n",
    "\n",
    "Posterior mean:\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{x}}_{t\\mid t} = \\hat{\\mathbf{x}}_{t\\mid t-1} + \\mathbf{K}_t\\,\\tilde{\\mathbf{y}}_t\n",
    "$$\n",
    "\n",
    "Posterior covariance (common form):\n",
    "\n",
    "$$\n",
    "\\mathbf{P}_{t\\mid t} = (\\mathbf{I} - \\mathbf{K}_t\\,\\mathbf{H}_t)\\,\\mathbf{P}_{t\\mid t-1}\n",
    "$$\n",
    "\n",
    "Step-by-step:\n",
    "\n",
    "- $\\tilde{\\mathbf{y}}_t$ says how surprising the observation is relative to the prediction.\n",
    "- $\\mathbf{S}_t$ says how uncertain we expected the measurement to be (prediction uncertainty projected into measurement space + sensor noise).\n",
    "- $\\mathbf{K}_t$ is an adaptive weight: when sensors are noisy (large $\\mathbf{R}_t$), you trust the model more; when dynamics are noisy (large $\\mathbf{Q}_t$), you trust measurements more.\n",
    "- The covariance shrinks after incorporating data, especially in the directions you observe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e7ef1d",
   "metadata": {},
   "source": [
    "## 7) Prediction vs update intuition (1D version)\n",
    "\n",
    "In 1D with a direct observation ($y_t = x_t + v_t$), the update looks like:\n",
    "\n",
    "$$\n",
    "\\hat{x}_{t\\mid t} = \\hat{x}_{t\\mid t-1} + k_t\\,(y_t - \\hat{x}_{t\\mid t-1}),\n",
    "\\quad k_t = \\frac{p_{t\\mid t-1}}{p_{t\\mid t-1} + r}\n",
    "$$\n",
    "\n",
    "This is a **weighted average** between prediction and measurement:\n",
    "\n",
    "- if measurement noise variance $r$ is large \\u2192 $k_t$ is small \\u2192 you mostly keep the prediction\n",
    "- if prediction variance $p_{t\\mid t-1}$ is large \\u2192 $k_t$ is large \\u2192 you lean toward the measurement\n",
    "\n",
    "The multivariate Kalman filter is the same idea with matrices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fa0532",
   "metadata": {},
   "source": [
    "## 8) How it differs from ARIMA-style models\n",
    "\n",
    "ARIMA-style models (AR, MA, ARMA, ARIMA, SARIMA) are usually presented as models for an **observed** univariate time series $y_t$:\n",
    "\n",
    "- they model autocorrelation via lagged terms (AR) and lagged shocks (MA)\n",
    "- they often assume stationarity after differencing (the \\\"I\\\" part)\n",
    "- the core object is the observed series itself\n",
    "\n",
    "The Kalman filter, in contrast:\n",
    "\n",
    "- explicitly separates **latent state** $\\mathbf{x}_t$ from **measurements** $\\mathbf{y}_t$\n",
    "- supports **multivariate** states/observations naturally\n",
    "- handles **missing observations** and **irregular measurement** patterns cleanly (skip or modify the update)\n",
    "- can include **control inputs** $\\mathbf{u}_t$ (common in control systems)\n",
    "\n",
    "Important connection:\n",
    "\n",
    "- Many ARIMA models can be rewritten as **state-space models**, and the Kalman filter can then be used to evaluate the likelihood and produce filtered estimates.\n",
    "- Conceptually: ARIMA is a *model class*; the Kalman filter is an *inference algorithm* for a (linear Gaussian) state-space representation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb79313",
   "metadata": {},
   "source": [
    "## 9) Where it is used (tracking, finance, control)\n",
    "\n",
    "Common application categories:\n",
    "\n",
    "- **Tracking / navigation / sensor fusion**: estimating position/velocity from GPS + IMU, radar/sonar tracking, robotics localization.\n",
    "- **Control systems**: state estimation inside feedback loops (e.g., LQG control: LQR + Kalman filter), industrial process control, aircraft/spacecraft navigation.\n",
    "- **Finance / econometrics**: estimating latent trends/levels, time-varying regression coefficients (dynamic linear models), smoothing noisy signals, nowcasting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7927c95",
   "metadata": {},
   "source": [
    "## 10) Requirements to use the model correctly\n",
    "\n",
    "To use a Kalman filter well, you need more than code — you need a *reasonable model*.\n",
    "\n",
    "Key requirements:\n",
    "\n",
    "- **State design**: choose $\\mathbf{x}_t$ so the process is approximately Markov (the state should contain the information needed to predict the next state).\n",
    "- **Correct dimensions**: make sure $\\mathbf{F}$ is $n\\times n$, $\\mathbf{H}$ is $m\\times n$, $\\mathbf{Q}$ is $n\\times n$, $\\mathbf{R}$ is $m\\times m$.\n",
    "- **Noise covariances**: $\\mathbf{Q}$ and $\\mathbf{R}$ must be symmetric positive semidefinite (and $\\mathbf{R}$ typically positive definite so $\\mathbf{S}_t$ is invertible).\n",
    "- **Units + time step**: $\\mathbf{F}, \\mathbf{Q}, \\mathbf{R}$ must correspond to the same sampling interval (e.g., if you change $\\Delta t$, you must adjust them).\n",
    "- **Observability**: measurements must contain enough information to infer the state (otherwise some components remain weakly determined).\n",
    "- **Outliers / non-Gaussian noise**: heavy tails or outliers can break the Gaussian assumption; consider robust filtering or gating.\n",
    "- **Tuning**: $\\mathbf{Q}$ vs $\\mathbf{R}$ encodes how much you trust the dynamics vs measurements; poor tuning leads to lag, overreaction, or divergence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa208698",
   "metadata": {},
   "source": [
    "## 11) A concrete example: tracking 1D position with noisy sensors\n",
    "\n",
    "We'll simulate a simple system:\n",
    "\n",
    "- State: $\\mathbf{x}_t = [p_t, v_t]^\\top$ (position + velocity)\n",
    "- Dynamics: constant velocity, with random acceleration treated as **process noise**\n",
    "- Observation: we measure position only, with **measurement noise**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f066e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_constant_velocity_model(dt: float, sigma_a: float, sigma_z: float):\n",
    "    \"\"\"Return (F, H, Q, R) for a 1D constant-velocity model.\n",
    "\n",
    "    State x_t = [position, velocity]^T.\n",
    "\n",
    "    We treat unknown acceleration as process noise with std sigma_a.\n",
    "    We observe position with measurement noise std sigma_z.\n",
    "    \"\"\"\n",
    "    F = np.array([[1.0, dt], [0.0, 1.0]])\n",
    "    H = np.array([[1.0, 0.0]])\n",
    "\n",
    "    # Standard constant-velocity discretization with white acceleration noise\n",
    "    q = sigma_a**2\n",
    "    Q = q * np.array(\n",
    "        [[dt**4 / 4.0, dt**3 / 2.0], [dt**3 / 2.0, dt**2]], dtype=float\n",
    "    )\n",
    "\n",
    "    R = np.array([[sigma_z**2]], dtype=float)\n",
    "    return F, H, Q, R\n",
    "\n",
    "\n",
    "def simulate_lgssm(\n",
    "    F: np.ndarray,\n",
    "    H: np.ndarray,\n",
    "    Q: np.ndarray,\n",
    "    R: np.ndarray,\n",
    "    x0: np.ndarray,\n",
    "    steps: int,\n",
    "    rng: np.random.Generator,\n",
    "):\n",
    "    \"\"\"Simulate a linear Gaussian state-space model.\n",
    "\n",
    "    x_t = F x_{t-1} + w_t,  w_t ~ N(0, Q)\n",
    "    y_t = H x_t + v_t,      v_t ~ N(0, R)\n",
    "    \"\"\"\n",
    "    n = F.shape[0]\n",
    "    m = H.shape[0]\n",
    "    x = np.zeros((steps, n), dtype=float)\n",
    "    y = np.zeros((steps, m), dtype=float)\n",
    "    x[0] = x0\n",
    "\n",
    "    for t in range(steps):\n",
    "        if t > 0:\n",
    "            w_t = rng.multivariate_normal(mean=np.zeros(n), cov=Q)\n",
    "            x[t] = F @ x[t - 1] + w_t\n",
    "        v_t = rng.multivariate_normal(mean=np.zeros(m), cov=R)\n",
    "        y[t] = H @ x[t] + v_t\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "dt = 1.0\n",
    "T = 80\n",
    "\n",
    "# \"True\" noise levels used to generate the data\n",
    "sigma_a_true = 0.5   # process noise std (acceleration)\n",
    "sigma_z_true = 2.0   # measurement noise std (position sensor)\n",
    "\n",
    "F, H, Q_true, R_true = make_constant_velocity_model(dt, sigma_a_true, sigma_z_true)\n",
    "\n",
    "x0_true = np.array([0.0, 1.0])\n",
    "x_true, y_obs = simulate_lgssm(F, H, Q_true, R_true, x0_true, steps=T, rng=rng)\n",
    "\n",
    "print(\"F=\\n\", F)\n",
    "print(\"H=\\n\", H)\n",
    "print(\"Q_true=\\n\", Q_true)\n",
    "print(\"R_true=\\n\", R_true)\n",
    "print(\"x_true shape\", x_true.shape, \"y_obs shape\", y_obs.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041a4c6",
   "metadata": {},
   "source": [
    "## 12) Low-level NumPy implementation (no filtering libraries)\n",
    "\n",
    "Below is a straightforward Kalman filter implementation that keeps track of:\n",
    "\n",
    "- predicted (prior) mean/covariance: $(\\hat{\\mathbf{x}}_{t\\mid t-1}, \\mathbf{P}_{t\\mid t-1})$\n",
    "- filtered (posterior) mean/covariance: $(\\hat{\\mathbf{x}}_{t\\mid t}, \\mathbf{P}_{t\\mid t})$\n",
    "\n",
    "Implementation notes:\n",
    "\n",
    "- It uses `np.linalg.solve` instead of explicitly computing $\\mathbf{S}^{-1}$.\n",
    "- It updates covariance with the **Joseph form** for better numerical stability.\n",
    "- If an observation contains `NaN`, it skips the update step (useful for missing data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe240be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_filter(\n",
    "    y: np.ndarray,\n",
    "    F: np.ndarray,\n",
    "    H: np.ndarray,\n",
    "    Q: np.ndarray,\n",
    "    R: np.ndarray,\n",
    "    x0: np.ndarray,\n",
    "    P0: np.ndarray,\n",
    "    B: np.ndarray | None = None,\n",
    "    u: np.ndarray | None = None,\n",
    "):\n",
    "    \"\"\"Run a discrete-time Kalman filter.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y:\n",
    "        Observations, shape (T, m) or (T,).\n",
    "    F, H, Q, R:\n",
    "        State-space matrices.\n",
    "    x0, P0:\n",
    "        Initial filtered mean/covariance (t=0).\n",
    "    B, u:\n",
    "        Optional control matrix and control sequence (T, k) or (T,).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys: x_pred, P_pred, x_filt, P_filt, K, innovation, S\n",
    "    \"\"\"\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if y.ndim == 1:\n",
    "        y = y[:, None]\n",
    "\n",
    "    F = np.asarray(F, dtype=float)\n",
    "    H = np.asarray(H, dtype=float)\n",
    "    Q = np.asarray(Q, dtype=float)\n",
    "    R = np.asarray(R, dtype=float)\n",
    "    x_prev = np.asarray(x0, dtype=float)\n",
    "    P_prev = np.asarray(P0, dtype=float)\n",
    "\n",
    "    T, m = y.shape\n",
    "    n = F.shape[0]\n",
    "\n",
    "    x_pred = np.zeros((T, n), dtype=float)\n",
    "    P_pred = np.zeros((T, n, n), dtype=float)\n",
    "    x_filt = np.zeros((T, n), dtype=float)\n",
    "    P_filt = np.zeros((T, n, n), dtype=float)\n",
    "    K = np.zeros((T, n, m), dtype=float)\n",
    "    innovation = np.zeros((T, m), dtype=float)\n",
    "    S = np.zeros((T, m, m), dtype=float)\n",
    "\n",
    "    I = np.eye(n)\n",
    "\n",
    "    for t in range(T):\n",
    "        # ---- Prediction (prior) ----\n",
    "        if B is not None and u is not None:\n",
    "            u_t = u[t]\n",
    "            x_pr = F @ x_prev + B @ u_t\n",
    "        else:\n",
    "            x_pr = F @ x_prev\n",
    "        P_pr = F @ P_prev @ F.T + Q\n",
    "\n",
    "        x_pred[t] = x_pr\n",
    "        P_pred[t] = P_pr\n",
    "\n",
    "        # ---- Update (posterior) ----\n",
    "        y_t = y[t]\n",
    "        if np.any(np.isnan(y_t)):\n",
    "            # Missing measurement: carry forward the prediction.\n",
    "            x_po = x_pr\n",
    "            P_po = P_pr\n",
    "            K_t = np.zeros((n, m))\n",
    "            innov = np.full((m,), np.nan)\n",
    "            S_t = np.full((m, m), np.nan)\n",
    "        else:\n",
    "            innov = y_t - (H @ x_pr)\n",
    "            S_t = H @ P_pr @ H.T + R\n",
    "            PHt = P_pr @ H.T\n",
    "\n",
    "            # K = P H^T S^{-1}  (use solve instead of inverse)\n",
    "            K_t = np.linalg.solve(S_t, PHt.T).T\n",
    "\n",
    "            x_po = x_pr + K_t @ innov\n",
    "\n",
    "            # Joseph form: P = (I-KH) P (I-KH)^T + K R K^T\n",
    "            KH = K_t @ H\n",
    "            P_po = (I - KH) @ P_pr @ (I - KH).T + K_t @ R @ K_t.T\n",
    "            P_po = 0.5 * (P_po + P_po.T)  # enforce symmetry\n",
    "\n",
    "        x_filt[t] = x_po\n",
    "        P_filt[t] = P_po\n",
    "        K[t] = K_t\n",
    "        innovation[t] = innov\n",
    "        S[t] = S_t\n",
    "\n",
    "        x_prev, P_prev = x_po, P_po\n",
    "\n",
    "    return {\n",
    "        \"x_pred\": x_pred,\n",
    "        \"P_pred\": P_pred,\n",
    "        \"x_filt\": x_filt,\n",
    "        \"P_filt\": P_filt,\n",
    "        \"K\": K,\n",
    "        \"innovation\": innovation,\n",
    "        \"S\": S,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf79eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter setup: deliberately start with uncertainty about the initial state\n",
    "x0_guess = np.array([0.0, 0.0])\n",
    "P0_guess = np.diag([10.0**2, 10.0**2])\n",
    "\n",
    "res = kalman_filter(y_obs, F, H, Q_true, R_true, x0_guess, P0_guess)\n",
    "x_pred = res[\"x_pred\"]\n",
    "P_pred = res[\"P_pred\"]\n",
    "x_filt = res[\"x_filt\"]\n",
    "P_filt = res[\"P_filt\"]\n",
    "\n",
    "rmse_pos = float(np.sqrt(np.mean((x_filt[:, 0] - x_true[:, 0]) ** 2)))\n",
    "rmse_vel = float(np.sqrt(np.mean((x_filt[:, 1] - x_true[:, 1]) ** 2)))\n",
    "print(\"RMSE position:\", rmse_pos)\n",
    "print(\"RMSE velocity:\", rmse_vel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26283b4b",
   "metadata": {},
   "source": [
    "## 13) Plotly: true state vs noisy observations vs filtered estimate\n",
    "\n",
    "We plot position (observed) along with the filter estimate and a \\u00b12\\u03c3 uncertainty band.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(T)\n",
    "\n",
    "pos_true = x_true[:, 0]\n",
    "pos_obs = y_obs[:, 0]\n",
    "pos_est = x_filt[:, 0]\n",
    "pos_std = np.sqrt(P_filt[:, 0, 0])\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=t, y=pos_true, name=\"True position\", line=dict(color=\"black\"))\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=t,\n",
    "        y=pos_obs,\n",
    "        name=\"Noisy observations\",\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=6, color=\"rgba(200,0,0,0.55)\"),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=t, y=pos_est, name=\"Filtered estimate\", line=dict(color=\"#1f77b4\"))\n",
    ")\n",
    "\n",
    "# Uncertainty band\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=t,\n",
    "        y=pos_est + 2.0 * pos_std,\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"rgba(31,119,180,0.25)\"),\n",
    "        name=\"+2σ\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=t,\n",
    "        y=pos_est - 2.0 * pos_std,\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"rgba(31,119,180,0.25)\"),\n",
    "        fill=\"tonexty\",\n",
    "        fillcolor=\"rgba(31,119,180,0.15)\",\n",
    "        name=\"-2σ\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Kalman filter on 1D position tracking\",\n",
    "    xaxis_title=\"Time step\",\n",
    "    yaxis_title=\"Position\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0),\n",
    "    height=450,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b933e8d3",
   "metadata": {},
   "source": [
    "## 14) Plotly: evolution of uncertainty (covariance)\n",
    "\n",
    "A nice way to *see* predict vs update is to compare:\n",
    "\n",
    "- prior variance (after prediction): $\\mathbf{P}_{t\\mid t-1}$\n",
    "- posterior variance (after update): $\\mathbf{P}_{t\\mid t}$\n",
    "\n",
    "We plot the diagonal entries for position and velocity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d514269",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_var_pred = P_pred[:, 0, 0]\n",
    "pos_var_filt = P_filt[:, 0, 0]\n",
    "vel_var_pred = P_pred[:, 1, 1]\n",
    "vel_var_filt = P_filt[:, 1, 1]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    subplot_titles=(\"Position variance\", \"Velocity variance\"),\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=t, y=pos_var_pred, name=\"pos var (pred)\", line=dict(color=\"#ff7f0e\")),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=t, y=pos_var_filt, name=\"pos var (filt)\", line=dict(color=\"#1f77b4\")),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=t, y=vel_var_pred, name=\"vel var (pred)\", line=dict(color=\"#ff7f0e\")),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=t, y=vel_var_filt, name=\"vel var (filt)\", line=dict(color=\"#1f77b4\")),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Uncertainty evolution (diagonal of covariance)\",\n",
    "    xaxis2_title=\"Time step\",\n",
    "    yaxis_title=\"Variance\",\n",
    "    yaxis2_title=\"Variance\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0),\n",
    "    height=520,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c371a2",
   "metadata": {},
   "source": [
    "## 15) Effect of changing process vs measurement noise\n",
    "\n",
    "The Kalman filter's behavior is governed by the relative size of:\n",
    "\n",
    "- $\\mathbf{Q}$ (process noise): how much you believe the dynamics can deviate from the model\n",
    "- $\\mathbf{R}$ (measurement noise): how noisy you believe the sensor is\n",
    "\n",
    "We'll keep the simulated data fixed, and run the filter with different *assumed* noise levels to show the tradeoff:\n",
    "\n",
    "- larger assumed $\\sigma_a$ (larger $\\mathbf{Q}$) \\u2192 more responsive to measurements, larger uncertainty\n",
    "- larger assumed $\\sigma_z$ (larger $\\mathbf{R}$) \\u2192 smoother estimates, measurements down-weighted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aed634",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_a_grid = [0.1, sigma_a_true, 1.5]\n",
    "sigma_z_grid = [0.5, sigma_z_true, 5.0]\n",
    "\n",
    "colors_a = {sigma_a_grid[0]: \"#1f77b4\", sigma_a_grid[1]: \"#2ca02c\", sigma_a_grid[2]: \"#d62728\"}\n",
    "colors_z = {sigma_z_grid[0]: \"#9467bd\", sigma_z_grid[1]: \"#8c564b\", sigma_z_grid[2]: \"#e377c2\"}\n",
    "\n",
    "runs_a = {}\n",
    "for sigma_a in sigma_a_grid:\n",
    "    _, _, Q_assumed, R_assumed = make_constant_velocity_model(dt, sigma_a, sigma_z_true)\n",
    "    out = kalman_filter(y_obs, F, H, Q_assumed, R_assumed, x0_guess, P0_guess)\n",
    "    runs_a[sigma_a] = out\n",
    "\n",
    "runs_z = {}\n",
    "for sigma_z in sigma_z_grid:\n",
    "    _, _, Q_assumed, R_assumed = make_constant_velocity_model(dt, sigma_a_true, sigma_z)\n",
    "    out = kalman_filter(y_obs, F, H, Q_assumed, R_assumed, x0_guess, P0_guess)\n",
    "    runs_z[sigma_z] = out\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=2,\n",
    "    shared_xaxes=True,\n",
    "    subplot_titles=(\n",
    "        \"Vary process noise (assumed σ_a)\",\n",
    "        \"Vary measurement noise (assumed σ_z)\",\n",
    "        \"Position variance vs σ_a\",\n",
    "        \"Position variance vs σ_z\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Context traces (true + observations) only once in the legend\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=t, y=pos_true, name=\"True position\", line=dict(color=\"black\")),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=t,\n",
    "        y=pos_obs,\n",
    "        name=\"Observations\",\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=5, color=\"rgba(200,0,0,0.45)\"),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=t,\n",
    "        y=pos_true,\n",
    "        name=\"True position (dup)\",\n",
    "        line=dict(color=\"black\"),\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=t,\n",
    "        y=pos_obs,\n",
    "        name=\"Observations (dup)\",\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=5, color=\"rgba(200,0,0,0.45)\"),\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "# Vary Q via sigma_a\n",
    "for sigma_a, out in runs_a.items():\n",
    "    x_f = out[\"x_filt\"]\n",
    "    P_f = out[\"P_filt\"]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=t,\n",
    "            y=x_f[:, 0],\n",
    "            name=f\"estimate (σ_a={sigma_a:g})\",\n",
    "            line=dict(color=colors_a[sigma_a]),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=t,\n",
    "            y=P_f[:, 0, 0],\n",
    "            name=f\"var (σ_a={sigma_a:g})\",\n",
    "            line=dict(color=colors_a[sigma_a], dash=\"dot\"),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=2,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "# Vary R via sigma_z\n",
    "for sigma_z, out in runs_z.items():\n",
    "    x_f = out[\"x_filt\"]\n",
    "    P_f = out[\"P_filt\"]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=t,\n",
    "            y=x_f[:, 0],\n",
    "            name=f\"estimate (σ_z={sigma_z:g})\",\n",
    "            line=dict(color=colors_z[sigma_z]),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=t,\n",
    "            y=P_f[:, 0, 0],\n",
    "            name=f\"var (σ_z={sigma_z:g})\",\n",
    "            line=dict(color=colors_z[sigma_z], dash=\"dot\"),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=2,\n",
    "        col=2,\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(title_text=\"Time step\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Time step\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"Position\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Position\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Variance\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Variance\", row=2, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Tuning intuition: Q vs R\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.05, xanchor=\"left\", x=0),\n",
    "    height=720,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12ed7ec",
   "metadata": {},
   "source": [
    "## Pitfalls + diagnostics\n",
    "\n",
    "Common issues in practice:\n",
    "\n",
    "- **Bad $\\mathbf{Q}/\\mathbf{R}$ tuning**: too small $\\mathbf{Q}$ \\u2192 lag / under-react; too small $\\mathbf{R}$ \\u2192 chase noise.\n",
    "- **Wrong state definition**: if the state is missing key dynamics, the filter compensates by inflating noise and may still perform poorly.\n",
    "- **Non-Gaussian noise / outliers**: large outliers can produce huge innovations and destabilize the estimate.\n",
    "- **Numerical issues**: keep covariances symmetric PSD; prefer stable updates (Joseph form), and avoid explicit matrix inverses.\n",
    "\n",
    "Diagnostics you can monitor:\n",
    "\n",
    "- innovations $\\tilde{\\mathbf{y}}_t$ (should look like zero-mean noise if the model is well calibrated)\n",
    "- normalized innovation squared (NIS): $\\tilde{\\mathbf{y}}_t^\\top \\mathbf{S}_t^{-1} \\tilde{\\mathbf{y}}_t$ (outlier/gating signal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3373df",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Extend the example to **2D position** with state $[x, y, v_x, v_y]^\\top$.\n",
    "2. Add a **control input** (e.g., commanded acceleration) and verify the filter follows it.\n",
    "3. Intentionally mis-specify $\\mathbf{Q}$ or $\\mathbf{R}$ and quantify how RMSE changes.\n",
    "4. Introduce missing data (set some observations to `NaN`) and verify the filter performs prediction-only on those steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec9cd0e",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- R. E. Kalman (1960), *A New Approach to Linear Filtering and Prediction Problems*\n",
    "- Dan Simon, *Optimal State Estimation*\n",
    "- Kevin P. Murphy, *Machine Learning: A Probabilistic Perspective* (state-space models chapter)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}