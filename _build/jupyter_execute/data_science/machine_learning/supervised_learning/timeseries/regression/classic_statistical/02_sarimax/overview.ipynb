{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6671f8a5",
   "metadata": {},
   "source": [
    "# SARIMAX (Seasonal ARIMA with Exogenous Variables)\n",
    "\n",
    "SARIMAX extends SARIMA by adding a **regression on external variables** (a.k.a. *exogenous* regressors).\n",
    "\n",
    "This notebook focuses on:\n",
    "- how exogenous variables enter the model\n",
    "- causal vs correlational interpretation (and what “counterfactual” means here)\n",
    "- practical requirements (alignment, scaling, forecast-time availability)\n",
    "- an end-to-end demo with **NumPy** + **statsmodels** + **Plotly**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1239a4bb",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "By the end you should be able to:\n",
    "\n",
    "- write SARIMAX in compact operator notation\n",
    "- explain how `exog` affects the conditional mean and how SARIMA handles residual autocorrelation\n",
    "- list practical requirements for exogenous variables (alignment, leakage, availability)\n",
    "- visualize the impact of exogenous variables and run scenario / counterfactual-style forecasts\n",
    "- implement a simple NumPy two-stage approximation (OLS + seasonal AR errors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac7ac69",
   "metadata": {},
   "source": [
    "## 1) Model formulation (regression + SARIMA errors)\n",
    "\n",
    "Let $y_t$ be the target series and $\\mathbf{x}_t \\in \\mathbb{R}^k$ be the vector of exogenous variables available at time $t$.\n",
    "\n",
    "**Regression (mean) part**\n",
    "\n",
    "$$\n",
    "y_t = \\beta_0 + \\mathbf{x}_t^\\top \\boldsymbol{\\beta} + u_t\n",
    "$$\n",
    "\n",
    "where $u_t$ is an autocorrelated error.\n",
    "\n",
    "**SARIMA error part**\n",
    "\n",
    "Let $B$ be the backshift operator $B y_t = y_{t-1}$. Define:\n",
    "\n",
    "$$\n",
    "\\phi(B) = 1 - \\phi_1 B - \\cdots - \\phi_p B^p,\\qquad\n",
    "\\theta(B) = 1 + \\theta_1 B + \\cdots + \\theta_q B^q\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Phi(B^s) = 1 - \\Phi_1 B^s - \\cdots - \\Phi_P B^{Ps},\\qquad\n",
    "\\Theta(B^s) = 1 + \\Theta_1 B^s + \\cdots + \\Theta_Q B^{Qs}\n",
    "$$\n",
    "\n",
    "Then the seasonal ARIMA($p,d,q$)×($P,D,Q$)$_s$ model for $u_t$ is:\n",
    "\n",
    "$$\n",
    "\\phi(B)\\,\\Phi(B^s)\\,(1-B)^d\\,(1-B^s)^D\\,u_t\n",
    "=\n",
    "\\theta(B)\\,\\Theta(B^s)\\,\\varepsilon_t,\n",
    "\\qquad \\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)\n",
    "$$\n",
    "\n",
    "Putting both together yields SARIMAX.\n",
    "\n",
    "Equivalently, you can write the combined model as:\n",
    "\n",
    "$$\n",
    "\\phi(B)\\,\\Phi(B^s)\\,(1-B)^d\\,(1-B^s)^D\\,\\big(y_t - \\beta_0 - \\mathbf{x}_t^\\top\\boldsymbol{\\beta}\\big)\n",
    "=\n",
    "\\theta(B)\\,\\Theta(B^s)\\,\\varepsilon_t\n",
    "$$\n",
    "\n",
    "\n",
    "**Key intuition**\n",
    "- $\\beta_0 + \\mathbf{x}_t^\\top\\boldsymbol{\\beta}$ explains the part of $y_t$ driven by observed external signals.\n",
    "- SARIMA explains the **remaining autocorrelation** in the residual $u_t$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6175a1",
   "metadata": {},
   "source": [
    "## 2) How exogenous variables are incorporated (precisely)\n",
    "\n",
    "In SARIMAX, exogenous variables enter the **observation equation** as a linear regression.\n",
    "\n",
    "In `statsmodels`, `exog` is a matrix $X$ whose $t$-th row is $\\mathbf{x}_t^\\top$. The coefficients $\\boldsymbol{\\beta}$ are estimated (typically) **jointly** with ARIMA parameters via **maximum likelihood** using a **state-space model** and the **Kalman filter**.\n",
    "\n",
    "Practical patterns:\n",
    "- **Contemporaneous effects:** include $x_t$.\n",
    "- **Lagged effects:** include $x_{t-1}, x_{t-2}, \\dots$ explicitly as extra columns.\n",
    "- **Event indicators / interventions:** use 0/1 dummies (policy change, promotions, outages).\n",
    "- **Deterministic seasonality/trend:** can be included either via SARIMA terms *or* as regressors (seasonal dummies, Fourier terms), depending on preference.\n",
    "\n",
    "Interpretation of $\\beta_j$: holding the ARIMA error structure fixed, increasing $x_{t,j}$ by 1 changes the model’s conditional mean for $y_t$ by $\\beta_j$ units (in the scale of your transformed variables).\n",
    "\n",
    "Econometric exogeneity (strong form) is often written as $\\mathbb{E}[\\varepsilon_t \\mid X_{1:T}] = 0$; if $\\mathbf{x}_t$ is correlated with the innovation $\\varepsilon_t$ (endogeneity), $\\hat{\\boldsymbol{\\beta}}$ is biased.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f22abd",
   "metadata": {},
   "source": [
    "## 3) Causal vs correlational usage (and real-world examples)\n",
    "\n",
    "### Predictive / correlational (the default)\n",
    "In most forecasting settings, SARIMAX is used to estimate conditional associations:\n",
    "\n",
    "$$\n",
    "\\beta_j \\approx \\text{partial association between } y_t \\text{ and } x_{t,j} \\text{ after accounting for autocorrelation.}\n",
    "$$\n",
    "\n",
    "This is often all you need for accurate forecasts.\n",
    "\n",
    "### When can coefficients be interpreted causally?\n",
    "A causal interpretation (“if we intervene on $x$, $y$ will change”) requires assumptions beyond SARIMAX:\n",
    "- **No reverse causality:** $y$ does not influence $x$ (or you model that feedback explicitly).\n",
    "- **No omitted confounders:** nothing unobserved drives both $x$ and $y$.\n",
    "- **Correct timing:** $\\mathbf{x}_t$ must be known at/ before time $t$ (no look-ahead).\n",
    "- **Structural stability:** the relationship is stable under the intervention you care about.\n",
    "\n",
    "Without these, a SARIMAX “counterfactual” is a *model-based scenario*, not a causal estimate.\n",
    "\n",
    "### Examples\n",
    "- **Finance (predictive):** forecasting volatility/returns using exogenous signals such as VIX, macro announcements, funding rates, or regime indicators. Be cautious: market variables frequently have feedback loops → endogeneity.\n",
    "- **Economics (scenario analysis):** forecasting inflation with oil prices and policy rates; demand with prices/promotions; unemployment with job openings. For policy *effects*, identification strategies (IV, DiD, SVAR, etc.) are typically needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49461ef1",
   "metadata": {},
   "source": [
    "## 4) Requirements for exogenous variables (alignment, scaling, leakage)\n",
    "\n",
    "**Minimal practical requirements (for forecasting):**\n",
    "- Same time granularity as $y_t$ (or resampled/aggregated correctly).\n",
    "- Correct **time alignment**: the row $\\mathbf{x}_t$ must only use information available at time $t$ (or earlier).\n",
    "- No unexpected missingness; handle gaps explicitly (impute, drop, or model).\n",
    "- Reasonable collinearity (high collinearity makes $\\boldsymbol{\\beta}$ unstable).\n",
    "- For future forecasting, $\\mathbf{x}_{t+h}$ must be **known or scenarized** for the horizon.\n",
    "\n",
    "**Alignment checklist (avoid leakage):**\n",
    "- Join $y$ and $X$ on the same timestamp index; confirm lengths after cleaning.\n",
    "- If a regressor is published with delay (common in macro data), shift it so $\\mathbf{x}_t$ reflects what was known at time $t$.\n",
    "- For lagged effects, create explicit lag columns (e.g., `x.shift(1)`); avoid `shift(-1)` features unless you truly know the future.\n",
    "- Decide how to handle missing timestamps (drop vs forward-fill) based on the meaning of the variable.\n",
    "\n",
    "**Scaling / transforms:**\n",
    "- Standardize continuous regressors using training mean/std and apply the same transform to future `exog`.\n",
    "- Keep binary indicators (0/1 dummies) unscaled in most cases.\n",
    "- Scaling $x$ does not change forecasts if you transform coefficients consistently, but it can improve numerical stability of MLE.\n",
    "- Interpret $\\boldsymbol{\\beta}$ in the scale of your transformed variables (log, diff, percent).\n",
    "\n",
    "**Lag specification:**\n",
    "- If effects are delayed, include lags explicitly; SARIMA terms capture autocorrelation, not causal delay in $x \\to y$.\n",
    "\n",
    "**Non-stationary series:**\n",
    "- Differencing is applied to the ARIMA error part; if $y$ and $x$ are trending, you may need trends, differences, or cointegration-aware modeling to avoid spurious relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11de454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"joblib\")\n",
    "\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "SEED = 7\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "import numpy, pandas, statsmodels, plotly\n",
    "print(\"numpy\", numpy.__version__)\n",
    "print(\"pandas\", pandas.__version__)\n",
    "print(\"statsmodels\", statsmodels.__version__)\n",
    "print(\"plotly\", plotly.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de25482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Synthetic data with known exogenous effects ---\n",
    "n = 180\n",
    "s = 12  # monthly seasonality\n",
    "idx = pd.date_range(\"2010-01-01\", periods=n, freq=\"MS\")\n",
    "\n",
    "# Exogenous variables (think: policy rate + a temporary intervention)\n",
    "rate = np.zeros(n)\n",
    "rate[0] = 2.0\n",
    "for t in range(1, n):\n",
    "    rate[t] = 0.9 * rate[t - 1] + 0.2 + rng.normal(0, 0.15)\n",
    "\n",
    "stimulus = np.zeros(n)\n",
    "stimulus[60:75] = 1.0\n",
    "stimulus[120:132] = 1.0\n",
    "\n",
    "# Seasonal AR errors: u_t = phi u_{t-1} + Phi u_{t-s} + eps_t\n",
    "phi = 0.5\n",
    "Phi = 0.3\n",
    "sigma = 1.5\n",
    "\n",
    "u = np.zeros(n)\n",
    "eps = rng.normal(0, sigma, size=n)\n",
    "for t in range(n):\n",
    "    ar1 = phi * u[t - 1] if t - 1 >= 0 else 0.0\n",
    "    sar1 = Phi * u[t - s] if t - s >= 0 else 0.0\n",
    "    u[t] = ar1 + sar1 + eps[t]\n",
    "\n",
    "# True regression effects\n",
    "beta0_true = 50.0\n",
    "beta_rate_true = -4.0\n",
    "beta_stimulus_true = 8.0\n",
    "\n",
    "y = beta0_true + beta_rate_true * rate + beta_stimulus_true * stimulus + u\n",
    "\n",
    "df = pd.DataFrame({\"y\": y, \"rate\": rate, \"stimulus\": stimulus}, index=idx)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209d003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the target and exogenous drivers\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df.index, y=df[\"y\"], name=\"y (target)\", line=dict(color=\"black\")),\n",
    "    secondary_y=False,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df.index, y=df[\"rate\"], name=\"rate (exog)\", line=dict(color=\"#4E79A7\")),\n",
    "    secondary_y=True,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(x=df.index, y=df[\"stimulus\"], name=\"stimulus (exog)\", opacity=0.25, marker_color=\"#E15759\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Synthetic series with exogenous drivers\",\n",
    "    xaxis_title=\"Date\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0),\n",
    ")\n",
    "fig.update_yaxes(title_text=\"y\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"rate / stimulus\", secondary_y=True)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f692475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fit SARIMAX (with exog) vs SARIMA (no exog) on a holdout split ---\n",
    "h = 24\n",
    "train = df.iloc[:-h]\n",
    "test = df.iloc[-h:]\n",
    "\n",
    "exog_cols = [\"stimulus\", \"rate\"]\n",
    "\n",
    "order = (1, 0, 0)\n",
    "seasonal_order = (1, 0, 0, 12)\n",
    "\n",
    "res_x = sm.tsa.SARIMAX(\n",
    "    train[\"y\"],\n",
    "    exog=train[exog_cols],\n",
    "    order=order,\n",
    "    seasonal_order=seasonal_order,\n",
    "    trend=\"c\",\n",
    "    enforce_stationarity=True,\n",
    "    enforce_invertibility=True,\n",
    ").fit(disp=False, method=\"lbfgs\", maxiter=500)\n",
    "\n",
    "res_0 = sm.tsa.SARIMAX(\n",
    "    train[\"y\"],\n",
    "    order=order,\n",
    "    seasonal_order=seasonal_order,\n",
    "    trend=\"c\",\n",
    "    enforce_stationarity=True,\n",
    "    enforce_invertibility=True,\n",
    ").fit(disp=False, method=\"lbfgs\", maxiter=500)\n",
    "\n",
    "fcst_x = res_x.get_forecast(steps=h, exog=test[exog_cols])\n",
    "fcst_0 = res_0.get_forecast(steps=h)\n",
    "\n",
    "pred_x = fcst_x.predicted_mean\n",
    "pred_0 = fcst_0.predicted_mean\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    return float(np.mean(np.abs(y_true - y_pred)))\n",
    "\n",
    "\n",
    "print(\"Test RMSE (with exog):\", rmse(test[\"y\"], pred_x))\n",
    "print(\"Test RMSE (no exog): \", rmse(test[\"y\"], pred_0))\n",
    "print(\"Test MAE  (with exog):\", mae(test[\"y\"], pred_x))\n",
    "print(\"Test MAE  (no exog): \", mae(test[\"y\"], pred_0))\n",
    "\n",
    "res_x.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d218f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot holdout forecasts\n",
    "ci_x = fcst_x.conf_int()\n",
    "lower_x = ci_x.iloc[:, 0]\n",
    "upper_x = ci_x.iloc[:, 1]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=train.index,\n",
    "        y=train[\"y\"],\n",
    "        name=\"train y\",\n",
    "        line=dict(color=\"rgba(0,0,0,0.35)\"),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=test.index, y=test[\"y\"], name=\"test y\", line=dict(color=\"black\")))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=test.index,\n",
    "        y=pred_0,\n",
    "        name=\"forecast: SARIMA (no exog)\",\n",
    "        line=dict(color=\"#F28E2B\"),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=test.index,\n",
    "        y=pred_x,\n",
    "        name=\"forecast: SARIMAX (with exog)\",\n",
    "        line=dict(color=\"#4E79A7\"),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=test.index, y=lower_x, showlegend=False, line=dict(color=\"rgba(78,121,167,0.0)\"))\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=test.index,\n",
    "        y=upper_x,\n",
    "        showlegend=False,\n",
    "        line=dict(color=\"rgba(78,121,167,0.0)\"),\n",
    "        fill=\"tonexty\",\n",
    "        fillcolor=\"rgba(78,121,167,0.15)\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_vline(x=test.index[0], line_dash=\"dash\", line_color=\"black\")\n",
    "fig.update_layout(\n",
    "    title=\"Forecast comparison (holdout): SARIMA vs SARIMAX\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"y\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0),\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66c348e",
   "metadata": {},
   "source": [
    "## Note on the intercept in ARMA/SARIMA\n",
    "\n",
    "In many ARMA/SARIMA parameterizations, the reported `intercept` is the ARMA constant $c$, not the unconditional mean $\\mu$.\n",
    "\n",
    "For an AR(1)×seasonal AR(1) model, the implied mean offset is:\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{c}{(1-\\phi_1)(1-\\Phi_1)}\n",
    "$$\n",
    "\n",
    "The chart below uses this implied $\\mu$ when drawing $\\mu + X\\hat\\beta$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7217d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plotly chart: estimated impact of exogenous variables ---\n",
    "params = res_x.params.copy()\n",
    "beta_hat = params.reindex(exog_cols).astype(float)\n",
    "\n",
    "intercept = float(params.get(\"intercept\", params.get(\"const\", 0.0)))\n",
    "phi1 = float(params.get(\"ar.L1\", 0.0))\n",
    "Phi1 = float(params.get(\"ar.S.L12\", 0.0))\n",
    "phi_at_1 = (1.0 - phi1) * (1.0 - Phi1)\n",
    "mu = intercept / phi_at_1 if phi_at_1 != 0.0 else intercept\n",
    "\n",
    "contrib = df[exog_cols].to_numpy() * beta_hat.to_numpy()  # (n, k) * (k,)\n",
    "total_contrib = contrib.sum(axis=1)\n",
    "mean_part = mu + total_contrib\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.07,\n",
    "    subplot_titles=(\n",
    "        \"Observed y vs estimated exog-driven mean (μ + Xβ)\",\n",
    "        \"Estimated contribution of each exogenous variable\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df[\"y\"], name=\"y\", line=dict(color=\"black\")), row=1, col=1)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df.index, y=mean_part, name=\"μ + Xβ\", line=dict(color=\"#4E79A7\")),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "for j, col in enumerate(exog_cols):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df.index, y=contrib[:, j], name=f\"{col} contribution\"),\n",
    "        row=2,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df.index,\n",
    "        y=total_contrib,\n",
    "        name=\"total Xβ\",\n",
    "        line=dict(color=\"rgba(0,0,0,0.6)\", dash=\"dash\"),\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title_text=\"y\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"contribution\", row=2, col=1)\n",
    "fig.update_layout(\n",
    "    title=\"Impact of exogenous variables (estimated from SARIMAX fit)\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "beta_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd0f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plotly chart: counterfactual-style forecast scenarios ---\n",
    "# IMPORTANT: this is a model-based conditional scenario, not necessarily a causal effect.\n",
    "\n",
    "exog_base = test[exog_cols].copy()\n",
    "exog_cf = exog_base.copy()\n",
    "exog_cf[\"stimulus\"] = 0.0\n",
    "\n",
    "pred_base = res_x.get_forecast(steps=h, exog=exog_base).predicted_mean\n",
    "pred_cf = res_x.get_forecast(steps=h, exog=exog_cf).predicted_mean\n",
    "\n",
    "effect = pred_base - pred_cf\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=train.index, y=train[\"y\"], name=\"train y\", line=dict(color=\"rgba(0,0,0,0.35)\"))\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=test.index, y=test[\"y\"], name=\"test y\", line=dict(color=\"black\")))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=test.index,\n",
    "        y=pred_base,\n",
    "        name=\"baseline forecast (observed exog)\",\n",
    "        line=dict(color=\"#4E79A7\"),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=test.index,\n",
    "        y=pred_cf,\n",
    "        name=\"counterfactual (stimulus=0)\",\n",
    "        line=dict(color=\"#E15759\", dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "fig.add_vline(x=test.index[0], line_dash=\"dash\", line_color=\"black\")\n",
    "fig.update_layout(\n",
    "    title=\"Counterfactual-style forecast: set stimulus=0 in the horizon\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"y\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "go.Figure(\n",
    "    data=[go.Bar(x=test.index, y=effect, name=\"baseline - counterfactual\")],\n",
    "    layout=go.Layout(\n",
    "        title=\"Estimated stimulus effect in the forecast horizon (model-based)\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Δy\",\n",
    "    ),\n",
    ").show()\n",
    "\n",
    "effect.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b8847",
   "metadata": {},
   "source": [
    "## 5) Low-level NumPy implementation (educational approximation)\n",
    "\n",
    "A full SARIMAX fit typically uses **maximum likelihood** via a **state-space model** and the **Kalman filter** (this is what `statsmodels` does).\n",
    "\n",
    "To keep the mechanics transparent, the next section implements a simple two-stage approximation:\n",
    "\n",
    "1) Fit the regression $y_t \\approx \\beta_0 + \\mathbf{x}_t^\\top\\boldsymbol{\\beta}$ by OLS.\n",
    "2) Fit a seasonal AR model on the residuals:\n",
    "\n",
    "$$\n",
    "u_t \\approx \\varphi_1 u_{t-1} + \\Phi_1 u_{t-s} + e_t\n",
    "$$\n",
    "\n",
    "3) Forecast by combining the regression mean and the recursive residual forecast.\n",
    "\n",
    "This corresponds to an ARIMAX-like model with **no MA terms** and no joint estimation; it is useful for intuition, not as a drop-in replacement for SARIMAX MLE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad715d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_intercept(X: np.ndarray) -> np.ndarray:\n",
    "    return np.column_stack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "\n",
    "def fit_ols(X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    beta, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
    "    return beta\n",
    "\n",
    "\n",
    "def fit_seasonal_ar(residuals: np.ndarray, lags: list[int]) -> np.ndarray:\n",
    "    max_lag = max(lags)\n",
    "    y = residuals[max_lag:]\n",
    "    X = np.column_stack([residuals[max_lag - lag : -lag] for lag in lags])\n",
    "    params, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
    "    return params\n",
    "\n",
    "\n",
    "def forecast_seasonal_ar(\n",
    "    residuals_history: np.ndarray,\n",
    "    ar_params: np.ndarray,\n",
    "    lags: list[int],\n",
    "    steps: int,\n",
    ") -> np.ndarray:\n",
    "    max_lag = max(lags)\n",
    "    hist = residuals_history.astype(float).copy()\n",
    "    if hist.shape[0] < max_lag:\n",
    "        raise ValueError(\"Need at least max(lags) residual history values.\")\n",
    "\n",
    "    preds: list[float] = []\n",
    "    for _ in range(steps):\n",
    "        t = hist.shape[0]\n",
    "        r_hat = 0.0\n",
    "        for coef, lag in zip(ar_params, lags):\n",
    "            r_hat += float(coef) * float(hist[t - lag])\n",
    "        preds.append(r_hat)\n",
    "        hist = np.append(hist, r_hat)\n",
    "\n",
    "    return np.asarray(preds)\n",
    "\n",
    "\n",
    "# Stage 1: OLS regression\n",
    "X_train = add_intercept(train[exog_cols].to_numpy())\n",
    "y_train = train[\"y\"].to_numpy()\n",
    "\n",
    "beta_ols = fit_ols(X_train, y_train)\n",
    "resid_train = y_train - X_train @ beta_ols\n",
    "\n",
    "# Stage 2: seasonal AR on residuals (lags 1 and 12)\n",
    "lags = [1, 12]\n",
    "ar_params = fit_seasonal_ar(resid_train, lags)\n",
    "\n",
    "# Forecast residuals and combine with regression mean\n",
    "resid_fcst = forecast_seasonal_ar(resid_train, ar_params, lags, steps=h)\n",
    "\n",
    "X_test = add_intercept(test[exog_cols].to_numpy())\n",
    "pred_numpy = X_test @ beta_ols + resid_fcst\n",
    "\n",
    "print(\"OLS betas (intercept, stimulus, rate):\", beta_ols)\n",
    "print(\"Seasonal AR params (lag 1, lag 12):\", ar_params)\n",
    "print(\"Test RMSE (NumPy two-stage):\", rmse(test[\"y\"], pred_numpy))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=test.index, y=test[\"y\"], name=\"test y\", line=dict(color=\"black\")))\n",
    "fig.add_trace(go.Scatter(x=test.index, y=pred_x, name=\"SARIMAX forecast\", line=dict(color=\"#4E79A7\")))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=test.index,\n",
    "        y=pred_numpy,\n",
    "        name=\"NumPy two-stage\",\n",
    "        line=dict(color=\"#59A14F\", dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Holdout forecast: statsmodels SARIMAX vs NumPy two-stage approximation\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"y\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229bc1c5",
   "metadata": {},
   "source": [
    "## Pitfalls + diagnostics\n",
    "\n",
    "- **Leakage (alignment errors):** if $x_t$ includes information from the future (even subtly via rolling features), you will overestimate performance.\n",
    "- **Endogeneity:** in many finance/econ settings, $x$ and $y$ influence each other. SARIMAX can forecast, but coefficients can be misleading as “effects”.\n",
    "- **Collinearity:** correlated regressors inflate variance in $\\hat{\\beta}$; interpret with caution.\n",
    "- **Forecasting exog:** SARIMAX needs future $\\mathbf{x}_{t+h}$; if you can’t know it, you must model it or do scenario ranges.\n",
    "- **Residual checks:** inspect residual ACF/PACF and run stationarity tests on residuals; remaining structure suggests mis-specified orders or missing regressors.\n",
    "- **Order selection:** start simple (small p/q/P/Q) and validate on rolling-origin backtests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004770d",
   "metadata": {},
   "source": [
    "## Exercises + references\n",
    "\n",
    "Exercises:\n",
    "1) Add a lagged version of `rate` (e.g., `rate.shift(1)`) and see how coefficients and forecasts change.\n",
    "2) Introduce a trend in `rate` and compare: include a trend term vs differencing.\n",
    "3) Replace the binary `stimulus` with a continuous “spend” variable and examine scaling/standardization.\n",
    "4) Do a rolling backtest and compare SARIMA vs SARIMAX stability over time.\n",
    "\n",
    "References:\n",
    "- `statsmodels.tsa.statespace.SARIMAX` documentation (state-space + Kalman filter implementation).\n",
    "- Box, Jenkins, Reinsel & Ljung: *Time Series Analysis: Forecasting and Control* (classic ARIMA/SARIMA reference).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}