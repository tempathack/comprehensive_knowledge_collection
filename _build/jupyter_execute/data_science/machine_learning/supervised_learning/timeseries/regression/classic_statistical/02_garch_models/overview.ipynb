{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afafd076",
   "metadata": {},
   "source": [
    "# GARCH(1,1) Models (Volatility Models)\n",
    "\n",
    "## Goals\n",
    "- Precisely define conditional heteroskedasticity and connect it to volatility clustering.\n",
    "- Explain why volatility (conditional variance) is modeled rather than the mean for many return series.\n",
    "- Derive and break down the GARCH(1,1) variance recursion in LaTeX.\n",
    "- Implement simulation, conditional variance recursion, and variance forecasts in low-level NumPy.\n",
    "- Visualize volatility clustering and variance forecasts using Plotly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc4cf7a",
   "metadata": {},
   "source": [
    "## Conditional heteroskedasticity (quick recap)\n",
    "\n",
    "A return innovation $\\varepsilon_t$ is **conditionally heteroskedastic** if its conditional variance depends on past information:\n",
    "\n",
    "$$\n",
    "r_t = \\mu + \\varepsilon_t, \\qquad \\mathbb{E}[\\varepsilon_t\\mid\\mathcal{F}_{t-1}] = 0, \\qquad \\operatorname{Var}(\\varepsilon_t\\mid\\mathcal{F}_{t-1}) = h_t,\\ \\text{with } h_t \\text{ time-varying}.\n",
    "$$\n",
    "\n",
    "In finance, $h_t$ is interpreted as **volatility squared** (conditional variance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aa9f1b",
   "metadata": {},
   "source": [
    "## Why model variance (volatility) instead of the mean?\n",
    "\n",
    "- Mean returns are often weakly predictable at short horizons; volatility is typically **persistent**.\n",
    "- Many tasks require a forecast of **risk** (uncertainty), not just expected return.\n",
    "\n",
    "Common financial use cases:\n",
    "- **VaR / Expected Shortfall** and stress testing\n",
    "- **Volatility forecasting** for portfolio risk budgets and leverage control\n",
    "- **Options / derivatives** context (realized vs implied volatility)\n",
    "- **Position sizing** (e.g., target volatility strategies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6056d5",
   "metadata": {},
   "source": [
    "## GARCH(1,1) model (LaTeX)\n",
    "\n",
    "GARCH extends ARCH by adding lagged conditional variance (persistence).\n",
    "\n",
    "$$\n",
    "\\varepsilon_t = z_t\\sqrt{h_t}, \\qquad z_t\\ \\text{i.i.d. with}\\ \\mathbb{E}[z_t]=0,\\ \\operatorname{Var}(z_t)=1\n",
    "$$\n",
    "\n",
    "$$\n",
    "h_t = \\omega + \\alpha\\varepsilon_{t-1}^2 + \\beta h_{t-1}\n",
    "$$\n",
    "\n",
    "### Variance equation breakdown\n",
    "$$\n",
    "h_t = \\underbrace{\\omega}_{\\text{baseline}} + \\underbrace{\\alpha\\varepsilon_{t-1}^2}_{\\text{shock/news impact}} + \\underbrace{\\beta h_{t-1}}_{\\text{volatility persistence}}\n",
    "$$\n",
    "\n",
    "- $\\alpha$: how strongly \"new information\" (yesterday's squared shock) moves volatility.\n",
    "- $\\beta$: how persistent volatility is (how slowly it decays).\n",
    "\n",
    "### Common parameter constraints\n",
    "- $\\omega > 0$, $\\alpha\\ge 0$, $\\beta\\ge 0$\n",
    "- **Second-order stationarity (finite unconditional variance):** $\\alpha + \\beta < 1$\n",
    "\n",
    "Under $\\alpha + \\beta < 1$, the long-run variance is:\n",
    "$$\n",
    "\\bar h = \\mathbb{E}[h_t] = \\frac{\\omega}{1-\\alpha-\\beta}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9d70d4",
   "metadata": {},
   "source": [
    "## Volatility clustering + market-shock intuition\n",
    "\n",
    "- A big market shock at time $t$ means $|\\varepsilon_t|$ is large.\n",
    "- That makes $\\varepsilon_t^2$ large, which pushes up $h_{t+1}$.\n",
    "- If $\\beta$ is large, elevated variance persists for many periods, producing **clusters** of large moves.\n",
    "\n",
    "### Variance forecasts (multi-step)\n",
    "Given $\\mathcal{F}_t$, the one-step-ahead forecast is directly:\n",
    "\n",
    "$$\n",
    "h_{t+1\\mid t} = \\omega + \\alpha\\varepsilon_t^2 + \\beta h_t.\n",
    "$$\n",
    "\n",
    "For $k\\ge 2$, we use $\\mathbb{E}[\\varepsilon_{t+k-1}^2\\mid\\mathcal{F}_t] = h_{t+k-1\\mid t}$, giving the recursion:\n",
    "$$\n",
    "h_{t+k\\mid t} = \\omega + (\\alpha+\\beta)\\,h_{t+k-1\\mid t}.\n",
    "$$\n",
    "\n",
    "Closed form (mean reversion to $\\bar h$):\n",
    "$$\n",
    "h_{t+k\\mid t} = \\bar h + (\\alpha+\\beta)^{k-1}\\,(h_{t+1\\mid t} - \\bar h).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d2417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78caf73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_garch11(\n",
    "    T: int,\n",
    "    omega: float,\n",
    "    alpha: float,\n",
    "    beta: float,\n",
    "    mu: float = 0.0,\n",
    "    burn: int = 500,\n",
    "    seed: int = 7,\n",
    "):\n",
    "    \"\"\"Simulate a GARCH(1,1) process with Gaussian innovations.\"\"\"\n",
    "    if omega <= 0:\n",
    "        raise ValueError(\"omega must be > 0\")\n",
    "    if alpha < 0 or beta < 0:\n",
    "        raise ValueError(\"alpha and beta must be >= 0\")\n",
    "    if alpha + beta >= 1:\n",
    "        raise ValueError(\"Need alpha + beta < 1 for finite unconditional variance in this demo\")\n",
    "\n",
    "    h_bar = omega / (1.0 - alpha - beta)\n",
    "    n = int(T + burn)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    z = rng.standard_normal(n)\n",
    "\n",
    "    eps = np.zeros(n)\n",
    "    h = np.full(n, h_bar)\n",
    "\n",
    "    eps[0] = np.sqrt(h_bar) * z[0]\n",
    "    for t in range(1, n):\n",
    "        h[t] = omega + alpha * (eps[t - 1] ** 2) + beta * h[t - 1]\n",
    "        eps[t] = np.sqrt(h[t]) * z[t]\n",
    "\n",
    "    eps = eps[burn:]\n",
    "    h = h[burn:]\n",
    "    r = mu + eps\n",
    "    return r, eps, h\n",
    "\n",
    "\n",
    "def garch11_conditional_variance(eps, omega: float, alpha: float, beta: float, initial_variance: float | None = None):\n",
    "    eps = np.asarray(eps, dtype=float)\n",
    "    if initial_variance is None:\n",
    "        if alpha + beta >= 1:\n",
    "            raise ValueError(\"Need alpha + beta < 1 to use the unconditional variance as initialization\")\n",
    "        initial_variance = omega / (1.0 - alpha - beta)\n",
    "\n",
    "    h = np.full(eps.size, float(initial_variance))\n",
    "    for t in range(1, eps.size):\n",
    "        h[t] = omega + alpha * (eps[t - 1] ** 2) + beta * h[t - 1]\n",
    "    return h\n",
    "\n",
    "\n",
    "def garch11_forecast_variance(eps_last: float, h_last: float, omega: float, alpha: float, beta: float, horizon: int):\n",
    "    \"\"\"Forecast h_{t+k|t} for k=1..horizon.\"\"\"\n",
    "    horizon = int(horizon)\n",
    "    if horizon < 1:\n",
    "        return np.array([], dtype=float)\n",
    "\n",
    "    h_fore = np.zeros(horizon, dtype=float)\n",
    "    h_fore[0] = omega + alpha * (eps_last**2) + beta * h_last\n",
    "    for k in range(1, horizon):\n",
    "        h_fore[k] = omega + (alpha + beta) * h_fore[k - 1]\n",
    "    return h_fore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4043df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: simulate a persistent GARCH(1,1) to show volatility clustering\n",
    "T = 2500\n",
    "mu = 0.0\n",
    "omega = 0.02\n",
    "alpha = 0.08\n",
    "beta = 0.90  # alpha+beta close to 1 => strong persistence\n",
    "\n",
    "r, eps, h = simulate_garch11(T=T, omega=omega, alpha=alpha, beta=beta, mu=mu, seed=123)\n",
    "\n",
    "view = 800\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"t\": np.arange(T),\n",
    "        \"return\": r,\n",
    "        \"eps_sq\": eps**2,\n",
    "        \"h\": h,\n",
    "        \"sigma\": np.sqrt(h),\n",
    "    }\n",
    ").tail(view)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.06,\n",
    "    subplot_titles=(\"Simulated returns\", \"Volatility clustering: squared returns vs conditional variance\"),\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df[\"t\"], y=df[\"return\"], mode=\"lines\", name=\"r_t\"), row=1, col=1)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df[\"t\"], y=df[\"eps_sq\"], mode=\"lines\", name=r\"$\\varepsilon_t^2$\", line=dict(width=1)),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df[\"t\"], y=df[\"h\"], mode=\"lines\", name=r\"$h_t$\", line=dict(width=2)),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title_text=\"return\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"variance\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"time\", row=2, col=1)\n",
    "fig.update_layout(height=650, legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d775eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance forecasts: baseline vs a one-time \"shock\" at the last observation\n",
    "horizon = 80\n",
    "\n",
    "eps_last = float(eps[-1])\n",
    "h_last = float(h[-1])\n",
    "\n",
    "h_fore = garch11_forecast_variance(eps_last=eps_last, h_last=h_last, omega=omega, alpha=alpha, beta=beta, horizon=horizon)\n",
    "\n",
    "shock_multiplier = 6.0\n",
    "eps_last_shocked = shock_multiplier * np.sqrt(h_last)\n",
    "h_fore_shocked = garch11_forecast_variance(\n",
    "    eps_last=eps_last_shocked, h_last=h_last, omega=omega, alpha=alpha, beta=beta, horizon=horizon\n",
    ")\n",
    "\n",
    "h_bar = omega / (1.0 - alpha - beta)\n",
    "\n",
    "lookback = 250\n",
    "hist_x = np.arange(T - lookback, T)\n",
    "fore_x = np.arange(T, T + horizon)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=hist_x, y=h[-lookback:], mode=\"lines\", name=r\"historical $h_t$\"))\n",
    "fig.add_trace(go.Scatter(x=fore_x, y=h_fore, mode=\"lines\", name=r\"forecast (baseline)\"))\n",
    "fig.add_trace(go.Scatter(x=fore_x, y=h_fore_shocked, mode=\"lines\", name=r\"forecast (last shock)\", line=dict(dash=\"dot\")))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.concatenate([hist_x, fore_x]),\n",
    "        y=np.full(hist_x.size + fore_x.size, h_bar),\n",
    "        mode=\"lines\",\n",
    "        name=r\"long-run $\\bar h$\",\n",
    "        line=dict(dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"GARCH variance forecasts: mean reversion and the impact of a market shock\",\n",
    "    xaxis_title=\"time\",\n",
    "    yaxis_title=\"variance\",\n",
    "    height=500,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be1d48e",
   "metadata": {},
   "source": [
    "## Notes / diagnostics\n",
    "\n",
    "- **Volatility persistence** is largely controlled by $\\alpha + \\beta$; values close to 1 create slow decay and strong clustering.\n",
    "- If $\\alpha + \\beta \\ge 1$, the long-run variance $\\bar h$ is not finite (often discussed as IGARCH / near-unit-root volatility).\n",
    "- Real data often has heavy tails; using a Student-t distribution for $z_t$ is common in practice.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}