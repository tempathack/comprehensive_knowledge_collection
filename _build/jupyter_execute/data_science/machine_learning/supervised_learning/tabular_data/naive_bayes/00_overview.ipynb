{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d3e759b",
   "metadata": {},
   "source": [
    "# Naive Bayes (Gaussian, Multinomial, Complement, Bernoulli, Categorical) + Out-of-core\n",
    "\n",
    "Naive Bayes is a family of **probabilistic, generative** models.\n",
    "\n",
    "It’s popular because it can be:\n",
    "- **fast** (training is mostly counting)\n",
    "- **strong** on sparse, high-dimensional data (e.g., text)\n",
    "- **surprisingly good** even when its assumptions are “wrong”\n",
    "\n",
    "## Learning goals\n",
    "By the end you should be able to:\n",
    "- explain Bayes’ rule and why Naive Bayes is a *generative* classifier\n",
    "- derive the Naive Bayes decision rule in log-space\n",
    "- understand the **conditional independence** assumption (and its consequences)\n",
    "- implement (from scratch) **Gaussian NB**, **Multinomial NB**, and **Bernoulli NB**\n",
    "- know when to use **Complement NB** and **Categorical NB**\n",
    "- train Naive Bayes **out-of-core** with `partial_fit` on streaming batches\n",
    "\n",
    "## Table of contents\n",
    "1. Bayes as “belief update”\n",
    "2. The naive assumption (conditional independence)\n",
    "3. Gaussian Naive Bayes (continuous features)\n",
    "4. Multinomial Naive Bayes (count features)\n",
    "5. Bernoulli Naive Bayes (binary features)\n",
    "6. Complement Naive Bayes (imbalanced text)\n",
    "7. Categorical Naive Bayes (discrete categories)\n",
    "8. Out-of-core (streaming) fitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d293470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import (\n",
    "    GaussianNB,\n",
    "    MultinomialNB,\n",
    "    ComplementNB,\n",
    "    BernoulliNB,\n",
    "    CategoricalNB,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe3734c",
   "metadata": {},
   "source": [
    "## 1) Bayes as “belief update”\n",
    "\n",
    "Bayes’ rule is just a way to update beliefs when you see evidence:\n",
    "\n",
    "$$\n",
    "P(y \\mid x) = \\frac{P(x \\mid y)\\,P(y)}{P(x)}\n",
    "$$\n",
    "\n",
    "- $P(y)$ is the **prior** (what you believed before seeing data)\n",
    "- $P(x \\mid y)$ is the **likelihood** (how compatible the data is with a hypothesis)\n",
    "- $P(y \\mid x)$ is the **posterior** (updated belief)\n",
    "- $P(x)$ is a normalization constant\n",
    "\n",
    "### A helpful mental image\n",
    "Think of $P(y)$ as a *base rate* and $P(x \\mid y)$ as an *evidence multiplier*.\n",
    "\n",
    "Naive Bayes turns this into a classifier by comparing posteriors across classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b4e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A classic Bayes example: medical test\n",
    "# Disease prevalence (prior)\n",
    "P_D = 0.01\n",
    "\n",
    "# Test quality\n",
    "sensitivity = 0.95           # P(test+ | disease)\n",
    "false_positive_rate = 0.05   # P(test+ | no disease)\n",
    "\n",
    "# Posterior P(disease | test+)\n",
    "P_pos = sensitivity * P_D + false_positive_rate * (1 - P_D)\n",
    "P_D_given_pos = sensitivity * P_D / P_pos\n",
    "\n",
    "print(f\"P(disease)               = {P_D:.3f}\")\n",
    "print(f\"P(test+ | disease)       = {sensitivity:.3f}\")\n",
    "print(f\"P(test+ | no disease)    = {false_positive_rate:.3f}\")\n",
    "print(f\"P(disease | test+)       = {P_D_given_pos:.3f}\")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=[\"prior P(D)\", \"posterior P(D|+)\"] , y=[P_D, P_D_given_pos]))\n",
    "fig.update_layout(title=\"Bayes update: rare disease + positive test\", yaxis_title=\"probability\", width=650, height=420)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709862b3",
   "metadata": {},
   "source": [
    "## 2) The naive assumption (conditional independence)\n",
    "\n",
    "Naive Bayes assumes:\n",
    "\n",
    "> given the class $y$, the features $x_1,\\dots,x_d$ are conditionally independent.\n",
    "\n",
    "Mathematically:\n",
    "\n",
    "$$\n",
    "P(x \\mid y) = \\prod_{j=1}^{d} P(x_j \\mid y)\n",
    "$$\n",
    "\n",
    "This is “naive” because real-world features are often correlated.\n",
    "\n",
    "### Why it still works often\n",
    "- The goal of classification is to pick the **argmax** class. Even if probabilities are imperfect, the ranking can be correct.\n",
    "- Many datasets have “mostly independent enough” signals (especially after preprocessing).\n",
    "- In text, the bag-of-words representation makes independence *less crazy* than it sounds.\n",
    "\n",
    "### Log-space is your friend\n",
    "Products become sums:\n",
    "\n",
    "$$\n",
    "\\log P(y \\mid x) = \\log P(y) + \\sum_{j=1}^{d} \\log P(x_j \\mid y) + \\text{const}\n",
    "$$\n",
    "\n",
    "This avoids numeric underflow and is computationally convenient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081cdda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual demo: correlated features (independence is violated)\n",
    "\n",
    "# Two classes with correlated 2D Gaussians\n",
    "n = 700\n",
    "mean0 = np.array([-1.0, -0.5])\n",
    "mean1 = np.array([+1.0, +0.5])\n",
    "\n",
    "cov = np.array([[1.0, 0.85], [0.85, 1.0]])  # strong correlation\n",
    "\n",
    "X0 = rng.multivariate_normal(mean0, cov, size=n // 2)\n",
    "X1 = rng.multivariate_normal(mean1, cov, size=n // 2)\n",
    "X_corr = np.vstack([X0, X1])\n",
    "y_corr = np.array([0] * (n // 2) + [1] * (n // 2))\n",
    "\n",
    "corr0 = np.corrcoef(X0.T)[0, 1]\n",
    "corr1 = np.corrcoef(X1.T)[0, 1]\n",
    "print(f\"Correlation (class 0): {corr0:.3f}\")\n",
    "print(f\"Correlation (class 1): {corr1:.3f}\")\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=X_corr[:, 0],\n",
    "    y=X_corr[:, 1],\n",
    "    color=y_corr.astype(str),\n",
    "    title=\"Correlated features (violates NB independence)\",\n",
    "    labels={\"x\": \"x1\", \"y\": \"x2\", \"color\": \"class\"},\n",
    ")\n",
    "fig.update_traces(marker=dict(size=6, opacity=0.6))\n",
    "fig.update_layout(width=720, height=470)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b360dfc",
   "metadata": {},
   "source": [
    "## 3) Gaussian Naive Bayes (continuous features)\n",
    "\n",
    "Gaussian NB assumes each feature is normally distributed *within each class*:\n",
    "\n",
    "$$\n",
    "(x_j \\mid y=c) \\sim \\mathcal{N}(\\mu_{c,j},\\,\\sigma^2_{c,j})\n",
    "$$\n",
    "\n",
    "### Parameter estimation\n",
    "For each class $c$ and feature $j$:\n",
    "\n",
    "- $\\mu_{c,j}$ is the sample mean\n",
    "- $\\sigma^2_{c,j}$ is the sample variance\n",
    "\n",
    "### Decision rule (log posterior)\n",
    "For a sample $x$:\n",
    "\n",
    "$$\n",
    "\\log P(y=c \\mid x) = \\log \\pi_c + \\sum_{j=1}^d \\log \\mathcal{N}(x_j \\mid \\mu_{c,j}, \\sigma^2_{c,j}) + \\text{const}\n",
    "$$\n",
    "\n",
    "Where $\\pi_c = P(y=c)$ is the class prior.\n",
    "\n",
    "Anecdote:\n",
    "> Gaussian NB is like saying: *“In class A, feature 1 tends to be around 3 with some wiggle; in class B, it’s around 7…”* and doing that for each feature independently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dc77ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ScratchGaussianNB:\n",
    "    var_smoothing: float = 1e-9\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y)\n",
    "        self.classes_, y_enc = np.unique(y, return_inverse=True)\n",
    "\n",
    "        n_classes = self.classes_.shape[0]\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        self.class_count_ = np.bincount(y_enc, minlength=n_classes).astype(float)\n",
    "        self.class_prior_ = self.class_count_ / self.class_count_.sum()\n",
    "\n",
    "        self.theta_ = np.zeros((n_classes, n_features), dtype=float)  # means\n",
    "        self.var_ = np.zeros((n_classes, n_features), dtype=float)    # variances\n",
    "\n",
    "        for c in range(n_classes):\n",
    "            Xc = X[y_enc == c]\n",
    "            self.theta_[c] = Xc.mean(axis=0)\n",
    "            self.var_[c] = Xc.var(axis=0)\n",
    "\n",
    "        # variance smoothing (like sklearn)\n",
    "        overall_var = X.var(axis=0).max()  # scalar\n",
    "        self.epsilon_ = self.var_smoothing * overall_var\n",
    "        self.var_ = self.var_ + self.epsilon_\n",
    "        return self\n",
    "\n",
    "    def _joint_log_likelihood(self, X: np.ndarray) -> np.ndarray:\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        # shape: (n_samples, n_classes)\n",
    "        n_samples = X.shape[0]\n",
    "        n_classes = self.classes_.shape[0]\n",
    "\n",
    "        log_prior = np.log(self.class_prior_ + 1e-300)\n",
    "\n",
    "        jll = np.empty((n_samples, n_classes), dtype=float)\n",
    "        for c in range(n_classes):\n",
    "            mean = self.theta_[c]\n",
    "            var = self.var_[c]\n",
    "            # sum_j [ -0.5 log(2π var_j) - (x_j - mean_j)^2 / (2 var_j) ]\n",
    "            log_prob = -0.5 * np.sum(np.log(2.0 * np.pi * var))\n",
    "            log_prob = log_prob - 0.5 * np.sum(((X - mean) ** 2) / var, axis=1)\n",
    "            jll[:, c] = log_prior[c] + log_prob\n",
    "        return jll\n",
    "\n",
    "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "        jll = self._joint_log_likelihood(X)\n",
    "        log_norm = logsumexp(jll, axis=1, keepdims=True)\n",
    "        return np.exp(jll - log_norm)\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        jll = self._joint_log_likelihood(X)\n",
    "        return self.classes_[np.argmax(jll, axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876fb41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A clean Gaussian-ish dataset (two blobs)\n",
    "X_g, y_g = make_blobs(\n",
    "    n_samples=800,\n",
    "    centers=[(-2, -1), (2, 1)],\n",
    "    cluster_std=[1.2, 1.1],\n",
    "    random_state=7,\n",
    ")\n",
    "X_tr_g, X_te_g, y_tr_g, y_te_g = train_test_split(X_g, y_g, test_size=0.3, random_state=7, stratify=y_g)\n",
    "\n",
    "scratch_gnb = ScratchGaussianNB(var_smoothing=1e-9).fit(X_tr_g, y_tr_g)\n",
    "sk_gnb = GaussianNB(var_smoothing=1e-9).fit(X_tr_g, y_tr_g)\n",
    "\n",
    "pred_scratch = scratch_gnb.predict(X_te_g)\n",
    "pred_sklearn = sk_gnb.predict(X_te_g)\n",
    "\n",
    "print(\"Scratch GaussianNB accuracy:\", accuracy_score(y_te_g, pred_scratch))\n",
    "print(\"sklearn GaussianNB accuracy:\", accuracy_score(y_te_g, pred_sklearn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4856f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_proba_boundary_2d(model, X, y, title: str, grid_steps: int = 220):\n",
    "    x_min, x_max = X[:, 0].min() - 1.0, X[:, 0].max() + 1.0\n",
    "    y_min, y_max = X[:, 1].min() - 1.0, X[:, 1].max() + 1.0\n",
    "\n",
    "    xs = np.linspace(x_min, x_max, grid_steps)\n",
    "    ys = np.linspace(y_min, y_max, grid_steps)\n",
    "    xx, yy = np.meshgrid(xs, ys)\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    proba = model.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Contour(\n",
    "        x=xs,\n",
    "        y=ys,\n",
    "        z=proba,\n",
    "        colorscale=\"RdBu\",\n",
    "        opacity=0.75,\n",
    "        contours=dict(showlines=False),\n",
    "        colorbar=dict(title=\"P(class=1)\"),\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=X[:, 0],\n",
    "        y=X[:, 1],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=y, colorscale=\"Viridis\", size=6, line=dict(width=0.5, color=\"white\")),\n",
    "        name=\"data\",\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(title=title, width=760, height=520)\n",
    "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig1 = plot_proba_boundary_2d(scratch_gnb, X_te_g, y_te_g, \"Scratch GaussianNB decision surface\")\n",
    "fig1.show()\n",
    "\n",
    "fig2 = plot_proba_boundary_2d(sk_gnb, X_te_g, y_te_g, \"sklearn GaussianNB decision surface\")\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e68709",
   "metadata": {},
   "source": [
    "### 3.1 `sklearn` GaussianNB parameters\n",
    "\n",
    "`GaussianNB(priors=None, var_smoothing=1e-9)`\n",
    "\n",
    "- `priors`: manually set class priors $\\pi_c$. Useful when your training data is not representative of deployment.\n",
    "- `var_smoothing`: adds a small value to variances to prevent numerical issues.\n",
    "\n",
    "Interpretation of `var_smoothing`:\n",
    "- too small → can blow up when a feature has tiny variance\n",
    "- too large → oversmooths and washes out feature differences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a72783",
   "metadata": {},
   "source": [
    "## 4) Multinomial Naive Bayes (counts / text)\n",
    "\n",
    "Multinomial NB is the classic choice for **bag-of-words** style inputs.\n",
    "\n",
    "Think:\n",
    "- features are **counts** (how many times word *j* appears)\n",
    "- a document is generated by repeatedly sampling words from a class-specific distribution\n",
    "\n",
    "### Model\n",
    "For class $c$, a vocabulary distribution $\\theta_c$ over $V$ words:\n",
    "\n",
    "$$\n",
    "\\theta_{c,j} \\ge 0,\\quad \\sum_{j=1}^V \\theta_{c,j} = 1\n",
    "$$\n",
    "\n",
    "Given a document count vector $x \\in \\mathbb{N}^V$:\n",
    "\n",
    "$$\n",
    "P(x \\mid y=c) \\propto \\prod_{j=1}^V \\theta_{c,j}^{x_j}\n",
    "$$\n",
    "\n",
    "Taking logs:\n",
    "\n",
    "$$\n",
    "\\log P(y=c \\mid x) = \\log \\pi_c + \\sum_{j=1}^V x_j \\log \\theta_{c,j} + \\text{const}\n",
    "$$\n",
    "\n",
    "### Smoothing (Dirichlet / Laplace)\n",
    "Without smoothing, unseen words can give $\\theta_{c,j}=0$ and kill probabilities.\n",
    "\n",
    "With additive smoothing ($\\alpha>0$):\n",
    "\n",
    "$$\n",
    "\\theta_{c,j} = \\frac{N_{c,j} + \\alpha}{\\sum_{k=1}^{V} N_{c,k} + \\alpha V}\n",
    "$$\n",
    "\n",
    "Anecdote:\n",
    "> Smoothing is like saying: *“Even if we haven’t seen the word ‘unicorn’ in spam yet, we won’t assume it’s impossible.”*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17e01dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_synthetic_text_dataset(\n",
    "    n_docs: int = 2000,\n",
    "    vocab_size: int = 30,\n",
    "    avg_len: int = 60,\n",
    "    imbalance: float = 0.5,\n",
    "    seed: int = 7,\n",
    "):\n",
    "    r = np.random.default_rng(seed)\n",
    "\n",
    "    # Class priors\n",
    "    p1 = float(imbalance)\n",
    "    y = (r.random(n_docs) < p1).astype(int)\n",
    "\n",
    "    # Class-specific word distributions (Dirichlet draws)\n",
    "    # Make them different by shifting concentration around two different centers.\n",
    "    base0 = r.random(vocab_size)\n",
    "    base1 = r.random(vocab_size)\n",
    "    base0 = base0 / base0.sum()\n",
    "    base1 = base1 / base1.sum()\n",
    "\n",
    "    # Sharpen and separate distributions\n",
    "    theta0 = r.dirichlet(25 * base0 + 1.0)\n",
    "    theta1 = r.dirichlet(25 * base1 + 1.0)\n",
    "\n",
    "    # Document lengths\n",
    "    lengths = r.poisson(lam=avg_len, size=n_docs) + 5\n",
    "\n",
    "    X = np.zeros((n_docs, vocab_size), dtype=int)\n",
    "    for i in range(n_docs):\n",
    "        theta = theta1 if y[i] == 1 else theta0\n",
    "        X[i] = r.multinomial(n=lengths[i], pvals=theta)\n",
    "\n",
    "    vocab = [f\"w{j:02d}\" for j in range(vocab_size)]\n",
    "    return X, y, theta0, theta1, vocab\n",
    "\n",
    "\n",
    "X_counts, y_text, theta0, theta1, vocab = make_synthetic_text_dataset(n_docs=3000, vocab_size=40, avg_len=70, imbalance=0.5)\n",
    "X_tr_t, X_te_t, y_tr_t, y_te_t = train_test_split(X_counts, y_text, test_size=0.3, random_state=7, stratify=y_text)\n",
    "\n",
    "# Plot the true underlying word probabilities (top words)\n",
    "idx0 = np.argsort(theta0)[-10:][::-1]\n",
    "idx1 = np.argsort(theta1)[-10:][::-1]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=[vocab[i] for i in idx0], y=theta0[idx0], name=\"class 0\"))\n",
    "fig.add_trace(go.Bar(x=[vocab[i] for i in idx1], y=theta1[idx1], name=\"class 1\"))\n",
    "fig.update_layout(\n",
    "    title=\"Synthetic text: top word probabilities per class (ground truth)\",\n",
    "    barmode=\"group\",\n",
    "    xaxis_title=\"word\",\n",
    "    yaxis_title=\"probability\",\n",
    "    width=900,\n",
    "    height=450,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ba24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ScratchMultinomialNB:\n",
    "    alpha: float = 1.0\n",
    "    fit_prior: bool = True\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        X = np.asarray(X)\n",
    "        if np.any(X < 0):\n",
    "            raise ValueError(\"MultinomialNB expects non-negative counts\")\n",
    "\n",
    "        y = np.asarray(y)\n",
    "        self.classes_, y_enc = np.unique(y, return_inverse=True)\n",
    "        n_classes = self.classes_.shape[0]\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        class_count = np.bincount(y_enc, minlength=n_classes).astype(float)\n",
    "\n",
    "        if self.fit_prior:\n",
    "            self.class_log_prior_ = np.log(class_count / class_count.sum())\n",
    "        else:\n",
    "            self.class_log_prior_ = np.full(n_classes, -np.log(n_classes), dtype=float)\n",
    "\n",
    "        # feature counts per class\n",
    "        feature_count = np.zeros((n_classes, n_features), dtype=float)\n",
    "        for c in range(n_classes):\n",
    "            feature_count[c] = X[y_enc == c].sum(axis=0)\n",
    "\n",
    "        smoothed_fc = feature_count + self.alpha\n",
    "        smoothed_cc = smoothed_fc.sum(axis=1, keepdims=True)\n",
    "        self.feature_log_prob_ = np.log(smoothed_fc) - np.log(smoothed_cc)\n",
    "        return self\n",
    "\n",
    "    def _joint_log_likelihood(self, X: np.ndarray) -> np.ndarray:\n",
    "        X = np.asarray(X)\n",
    "        return X @ self.feature_log_prob_.T + self.class_log_prior_[None, :]\n",
    "\n",
    "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "        jll = self._joint_log_likelihood(X)\n",
    "        return np.exp(jll - logsumexp(jll, axis=1, keepdims=True))\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        jll = self._joint_log_likelihood(X)\n",
    "        return self.classes_[np.argmax(jll, axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024588cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare scratch vs sklearn MultinomialNB\n",
    "scratch_mnb = ScratchMultinomialNB(alpha=1.0, fit_prior=True).fit(X_tr_t, y_tr_t)\n",
    "sk_mnb = MultinomialNB(alpha=1.0, fit_prior=True).fit(X_tr_t, y_tr_t)\n",
    "\n",
    "pred_scratch = scratch_mnb.predict(X_te_t)\n",
    "pred_sklearn = sk_mnb.predict(X_te_t)\n",
    "\n",
    "print(\"Scratch MultinomialNB accuracy:\", accuracy_score(y_te_t, pred_scratch))\n",
    "print(\"sklearn MultinomialNB accuracy:\", accuracy_score(y_te_t, pred_sklearn))\n",
    "\n",
    "print()\n",
    "print(\"Classification report (sklearn MultinomialNB):\")\n",
    "print(classification_report(y_te_t, pred_sklearn, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07bb820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of smoothing alpha\n",
    "alphas = np.logspace(-3, 1, 20)\n",
    "acc = []\n",
    "for a in alphas:\n",
    "    m = MultinomialNB(alpha=float(a)).fit(X_tr_t, y_tr_t)\n",
    "    acc.append(accuracy_score(y_te_t, m.predict(X_te_t)))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=alphas, y=acc, mode=\"lines+markers\"))\n",
    "fig.update_layout(\n",
    "    title=\"MultinomialNB: test accuracy vs smoothing alpha\",\n",
    "    xaxis_title=\"alpha (log scale)\",\n",
    "    yaxis_title=\"accuracy\",\n",
    "    width=800,\n",
    "    height=450,\n",
    ")\n",
    "fig.update_xaxes(type=\"log\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42ce192",
   "metadata": {},
   "source": [
    "### 4.1 `sklearn` MultinomialNB parameters\n",
    "\n",
    "`MultinomialNB(alpha=1.0, force_alpha=True, fit_prior=True, class_prior=None)`\n",
    "\n",
    "- `alpha`: additive smoothing strength\n",
    "- `force_alpha`: if `False`, may clamp tiny `alpha` values for numeric stability\n",
    "- `fit_prior`: learn class priors from data\n",
    "- `class_prior`: set priors manually (overrides `fit_prior`)\n",
    "\n",
    "Rules of thumb:\n",
    "- try `alpha` in `[0.01, 1.0]` for text\n",
    "- use `class_prior` when you know deployment base rates differ from training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58d3fbb",
   "metadata": {},
   "source": [
    "## 5) Bernoulli Naive Bayes (binary features)\n",
    "\n",
    "Bernoulli NB is like Multinomial NB, but it cares about **presence/absence** rather than counts.\n",
    "\n",
    "For binary $x_j \\in \\{0,1\\}$:\n",
    "\n",
    "$$\n",
    "P(x \\mid y=c) = \\prod_{j=1}^{V} p_{c,j}^{x_j} (1-p_{c,j})^{1-x_j}\n",
    "$$\n",
    "\n",
    "When does Bernoulli NB shine?\n",
    "- when word **frequency** is less important than word **presence**\n",
    "- when you want to explicitly model “word not present” as evidence\n",
    "\n",
    "In `sklearn`, `BernoulliNB` also supports a `binarize` threshold that turns counts into 0/1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare BernoulliNB vs MultinomialNB on the same synthetic text\n",
    "\n",
    "X_tr_bin = (X_tr_t > 0).astype(int)\n",
    "X_te_bin = (X_te_t > 0).astype(int)\n",
    "\n",
    "m_mnb = MultinomialNB(alpha=1.0).fit(X_tr_t, y_tr_t)\n",
    "m_bnb = BernoulliNB(alpha=1.0, binarize=None).fit(X_tr_bin, y_tr_t)\n",
    "\n",
    "acc_mnb = accuracy_score(y_te_t, m_mnb.predict(X_te_t))\n",
    "acc_bnb = accuracy_score(y_te_t, m_bnb.predict(X_te_bin))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=[\"MultinomialNB (counts)\", \"BernoulliNB (binary)\"] , y=[acc_mnb, acc_bnb]))\n",
    "fig.update_layout(title=\"Counts vs binary: accuracy comparison\", yaxis_title=\"accuracy\", width=700, height=420)\n",
    "fig.show()\n",
    "\n",
    "print(\"MultinomialNB accuracy:\", acc_mnb)\n",
    "print(\"BernoulliNB accuracy  :\", acc_bnb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c56a4d",
   "metadata": {},
   "source": [
    "## 6) Complement Naive Bayes (imbalanced text)\n",
    "\n",
    "Complement NB was designed for text classification when classes are imbalanced.\n",
    "\n",
    "Idea (intuition):\n",
    "- Instead of modeling “what class *c* looks like”, model “what *not c* looks like” (the **complement**).\n",
    "- Then classify by picking the class whose complement is *least compatible* with the document.\n",
    "\n",
    "In practice, `ComplementNB` often improves performance on imbalanced text datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c585454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an imbalanced dataset (class 1 is rare)\n",
    "X_counts_imb, y_imb, _, _, _ = make_synthetic_text_dataset(n_docs=6000, vocab_size=40, avg_len=60, imbalance=0.1, seed=11)\n",
    "X_tr_i, X_te_i, y_tr_i, y_te_i = train_test_split(X_counts_imb, y_imb, test_size=0.3, random_state=7, stratify=y_imb)\n",
    "\n",
    "m_mnb_i = MultinomialNB(alpha=1.0).fit(X_tr_i, y_tr_i)\n",
    "m_cnb_i = ComplementNB(alpha=1.0).fit(X_tr_i, y_tr_i)\n",
    "\n",
    "pred_mnb = m_mnb_i.predict(X_te_i)\n",
    "pred_cnb = m_cnb_i.predict(X_te_i)\n",
    "\n",
    "print(\"Class balance (test):\", np.bincount(y_te_i) / y_te_i.size)\n",
    "print()\n",
    "print(\"MultinomialNB report:\")\n",
    "print(classification_report(y_te_i, pred_mnb, digits=3))\n",
    "print(\"ComplementNB report:\")\n",
    "print(classification_report(y_te_i, pred_cnb, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aab0e1",
   "metadata": {},
   "source": [
    "### 6.1 `sklearn` ComplementNB parameters\n",
    "\n",
    "`ComplementNB(alpha=1.0, force_alpha=True, fit_prior=True, class_prior=None, norm=False)`\n",
    "\n",
    "- `norm`: if `True`, normalizes weights; sometimes helps.\n",
    "\n",
    "ComplementNB is typically used for **classification** (not regression).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb3ca7c",
   "metadata": {},
   "source": [
    "## 7) Categorical Naive Bayes (discrete categories)\n",
    "\n",
    "`CategoricalNB` is for features like:\n",
    "- color ∈ {red, green, blue}\n",
    "- browser ∈ {chrome, safari, firefox}\n",
    "- country ∈ {DE, FR, US, ...}\n",
    "\n",
    "Each feature is an integer code representing a category.\n",
    "\n",
    "For each class and feature, we estimate a categorical probability table.\n",
    "\n",
    "`CategoricalNB` is **not** the same as one-hot encoding + MultinomialNB.\n",
    "It’s a direct model of per-feature categorical distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy categorical dataset\n",
    "# Features: [weather, transport]\n",
    "# weather: 0=sunny,1=rainy,2=overcast\n",
    "# transport: 0=car,1=bus,2=bike\n",
    "# Label: 1=go_out, 0=stay_in\n",
    "\n",
    "weather = rng.integers(0, 3, size=800)\n",
    "transport = rng.integers(0, 3, size=800)\n",
    "\n",
    "# Make a slightly structured rule with noise\n",
    "p_go_out = (\n",
    "    0.15\n",
    "    + 0.25 * (weather == 0)  # sunny\n",
    "    + 0.10 * (weather == 2)  # overcast\n",
    "    + 0.15 * (transport == 2)  # bike\n",
    "    - 0.15 * (weather == 1)  # rainy\n",
    ")\n",
    "p_go_out = np.clip(p_go_out, 0.05, 0.95)\n",
    "\n",
    "y_cat = (rng.random(800) < p_go_out).astype(int)\n",
    "X_cat = np.c_[weather, transport]\n",
    "\n",
    "X_tr_c, X_te_c, y_tr_c, y_te_c = train_test_split(X_cat, y_cat, test_size=0.3, random_state=7, stratify=y_cat)\n",
    "\n",
    "m_cat = CategoricalNB(alpha=1.0).fit(X_tr_c, y_tr_c)\n",
    "acc_cat = accuracy_score(y_te_c, m_cat.predict(X_te_c))\n",
    "print(\"CategoricalNB accuracy:\", acc_cat)\n",
    "\n",
    "# Visualize predicted P(go_out=1) for each combination\n",
    "combos = np.array([(w, t) for w in range(3) for t in range(3)])\n",
    "proba = m_cat.predict_proba(combos)[:, 1]\n",
    "\n",
    "labels_weather = [\"sunny\", \"rainy\", \"overcast\"]\n",
    "labels_transport = [\"car\", \"bus\", \"bike\"]\n",
    "\n",
    "z = proba.reshape(3, 3)\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=z,\n",
    "    x=labels_transport,\n",
    "    y=labels_weather,\n",
    "    colorscale=\"Blues\",\n",
    "    colorbar=dict(title=\"P(go_out=1)\"),\n",
    "))\n",
    "fig.update_layout(title=\"CategoricalNB: predicted probability table\", width=650, height=450)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc09d47e",
   "metadata": {},
   "source": [
    "### 7.1 `sklearn` CategoricalNB parameters\n",
    "\n",
    "`CategoricalNB(alpha=1.0, force_alpha=True, fit_prior=True, class_prior=None, min_categories=None)`\n",
    "\n",
    "- `min_categories`: force each feature to have at least this many categories (useful if some categories are missing in training).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37b04f5",
   "metadata": {},
   "source": [
    "## 8) Out-of-core naive Bayes model fitting (`partial_fit`)\n",
    "\n",
    "Sometimes your dataset is too large to fit in memory.\n",
    "\n",
    "Naive Bayes is great here because you can train it incrementally:\n",
    "\n",
    "- stream data in batches\n",
    "- call `partial_fit` repeatedly\n",
    "- the model updates its sufficient statistics (counts / means / variances)\n",
    "\n",
    "Important details:\n",
    "- On the **first** `partial_fit`, you must pass `classes=np.array([...])`.\n",
    "- `partial_fit` is available for several NB variants (including MultinomialNB and GaussianNB).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c942333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_synthetic_text_batches(\n",
    "    n_docs: int,\n",
    "    vocab_size: int,\n",
    "    avg_len: int,\n",
    "    class_prior: float,\n",
    "    seed: int,\n",
    "    batch_size: int,\n",
    "):\n",
    "    r = np.random.default_rng(seed)\n",
    "\n",
    "    # fixed class word distributions\n",
    "    base0 = r.random(vocab_size)\n",
    "    base1 = r.random(vocab_size)\n",
    "    base0 = base0 / base0.sum()\n",
    "    base1 = base1 / base1.sum()\n",
    "    theta0 = r.dirichlet(30 * base0 + 1.0)\n",
    "    theta1 = r.dirichlet(30 * base1 + 1.0)\n",
    "\n",
    "    n_batches = (n_docs + batch_size - 1) // batch_size\n",
    "    for b in range(n_batches):\n",
    "        m = min(batch_size, n_docs - b * batch_size)\n",
    "        y = (r.random(m) < class_prior).astype(int)\n",
    "        lengths = r.poisson(lam=avg_len, size=m) + 5\n",
    "        X = np.zeros((m, vocab_size), dtype=int)\n",
    "        for i in range(m):\n",
    "            theta = theta1 if y[i] == 1 else theta0\n",
    "            X[i] = r.multinomial(n=int(lengths[i]), pvals=theta)\n",
    "        yield X, y\n",
    "\n",
    "\n",
    "# Fixed test set\n",
    "X_test_stream, y_test_stream, _, _, _ = make_synthetic_text_dataset(\n",
    "    n_docs=2500, vocab_size=80, avg_len=70, imbalance=0.2, seed=123\n",
    ")\n",
    "\n",
    "# Stream training batches\n",
    "batch_size = 400\n",
    "stream = stream_synthetic_text_batches(\n",
    "    n_docs=12000,\n",
    "    vocab_size=80,\n",
    "    avg_len=70,\n",
    "    class_prior=0.2,\n",
    "    seed=999,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "m_stream = MultinomialNB(alpha=0.5)\n",
    "classes = np.array([0, 1])\n",
    "\n",
    "seen = 0\n",
    "checkpoints = []\n",
    "accs = []\n",
    "\n",
    "for X_batch, y_batch in stream:\n",
    "    if seen == 0:\n",
    "        m_stream.partial_fit(X_batch, y_batch, classes=classes)\n",
    "    else:\n",
    "        m_stream.partial_fit(X_batch, y_batch)\n",
    "\n",
    "    seen += X_batch.shape[0]\n",
    "\n",
    "    if seen % (batch_size * 2) == 0:\n",
    "        y_pred = m_stream.predict(X_test_stream)\n",
    "        checkpoints.append(seen)\n",
    "        accs.append(accuracy_score(y_test_stream, y_pred))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=checkpoints, y=accs, mode=\"lines+markers\"))\n",
    "fig.update_layout(\n",
    "    title=\"Out-of-core MultinomialNB: accuracy vs streamed samples\",\n",
    "    xaxis_title=\"# samples seen\",\n",
    "    yaxis_title=\"accuracy on fixed test set\",\n",
    "    width=850,\n",
    "    height=450,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d599127",
   "metadata": {},
   "source": [
    "## Summary: choosing the right Naive Bayes\n",
    "\n",
    "- **GaussianNB**: continuous features; surprisingly strong baseline for numeric data.\n",
    "- **MultinomialNB**: count data (text word counts, event counts).\n",
    "- **BernoulliNB**: binary features (word present/absent).\n",
    "- **ComplementNB**: often better than MultinomialNB on **imbalanced** text.\n",
    "- **CategoricalNB**: discrete categorical features (integer-coded categories).\n",
    "\n",
    "## Exercises\n",
    "1. Create a dataset where features are highly correlated and see how GaussianNB degrades.\n",
    "2. For MultinomialNB, plot how `alpha` changes the *top words* for each class.\n",
    "3. For BernoulliNB, compare `binarize=0`, `binarize=1`, and manual binarization.\n",
    "4. Stream batches with `partial_fit` and compare to a single `fit`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}