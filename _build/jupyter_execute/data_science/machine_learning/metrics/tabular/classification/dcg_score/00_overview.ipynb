{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8acb0d9b",
   "metadata": {},
   "source": [
    "# dcg_score (Discounted Cumulative Gain)\n",
    "\n",
    "`dcg_score` measures **ranking quality**: it rewards putting highly relevant items at the top, and it discounts lower ranks logarithmically.\n",
    "\n",
    "If you care about *\"are the best things at the top?\"* (search, recommendations, multilabel ranking), DCG is a natural tool.\n",
    "\n",
    "## Learning goals\n",
    "- understand the DCG@k definition and the log discount\n",
    "- build intuition with plots (per-rank contributions + cumulative curves)\n",
    "- implement `dcg_score` in NumPy (including tie-averaging like scikit-learn)\n",
    "- see how DCG/NDCG is used to tune a simple linear ranking model\n",
    "- know pros/cons and common pitfalls\n",
    "\n",
    "## Quick import\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import dcg_score\n",
    "```\n",
    "\n",
    "## Table of contents\n",
    "1. Definitions and notation\n",
    "2. Intuition (plots)\n",
    "3. NumPy implementation (+ sanity checks vs sklearn)\n",
    "4. Using DCG/NDCG to optimize/tune a simple model\n",
    "5. Pros, cons, pitfalls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3082504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.metrics import dcg_score as sk_dcg_score\n",
    "from sklearn.metrics import ndcg_score as sk_ndcg_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "rng = np.random.default_rng(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0018ee08",
   "metadata": {},
   "source": [
    "## 1) Definitions and notation\n",
    "\n",
    "### Setup (one query)\n",
    "\n",
    "For one query (or one sample), assume we have $m$ items (documents, products, labels, …).\n",
    "\n",
    "- True **gain** (a.k.a. relevance): $y_j$ for item $j$  \n",
    "  (usually $y_j \\ge 0$, often an integer like 0/1/2/3)\n",
    "- Predicted score: $s_j$ for item $j$\n",
    "\n",
    "Let $\\pi$ be the permutation that sorts scores descending:\n",
    "\n",
    "$$\n",
    "s_{\\pi_1} \\ge s_{\\pi_2} \\ge \\dots \\ge s_{\\pi_m}\n",
    "$$\n",
    "\n",
    "Define a logarithmic **discount** at rank $r$ (1-indexed):\n",
    "\n",
    "$$\n",
    "d_r = \\frac{1}{\\log_b(r+1)}\n",
    "$$\n",
    "\n",
    "- $b$ is the log base (scikit-learn uses `log_base=2` by default)\n",
    "- note $d_1 = 1/\\log_b(2) = 1$, so the top rank is not discounted\n",
    "\n",
    "### DCG@k\n",
    "\n",
    "Discounted Cumulative Gain at cutoff $k$ is:\n",
    "\n",
    "$$\n",
    "\\mathrm{DCG@}k(y, s) = \\sum_{r=1}^{\\min(k,m)} y_{\\pi_r}\\, d_r\n",
    "$$\n",
    "\n",
    "Interpretation: each item's gain is counted, but **late ranks matter less**.\n",
    "\n",
    "### Important note: what is \"gain\"?\n",
    "\n",
    "In classical Information Retrieval, people often transform relevance levels with an exponential gain, e.g.\n",
    "\n",
    "$$\n",
    "g(y) = 2^y - 1\n",
    "$$\n",
    "\n",
    "and compute DCG on $g(y)$. scikit-learn's `dcg_score` does **not** apply a gain transform: it assumes `y_true` already contains the gains you want.\n",
    "\n",
    "### Tie handling (scikit-learn default)\n",
    "\n",
    "If some predicted scores are tied, scikit-learn averages over all tie permutations.\n",
    "For a tied group $T$ occupying ranks $r..r+|T|-1$:\n",
    "\n",
    "$$\n",
    "\\text{group contribution} = \\Big(\\frac{1}{|T|}\\sum_{j\\in T} y_j\\Big) \\cdot \\sum_{t=r}^{r+|T|-1} d_t\n",
    "$$\n",
    "\n",
    "This equals the **expected DCG** if you break ties uniformly at random.\n",
    "Set `ignore_ties=True` only if you are sure there are no ties.\n",
    "\n",
    "### Normalization (NDCG)\n",
    "\n",
    "Raw DCG depends on the scale of gains and the number of items. A common normalization is:\n",
    "\n",
    "$$\n",
    "\\mathrm{NDCG@}k = \\frac{\\mathrm{DCG@}k}{\\mathrm{IDCG@}k}\n",
    "$$\n",
    "\n",
    "where $\\mathrm{IDCG@}k$ is the DCG@k of the **ideal ranking** (items sorted by decreasing $y$). NDCG is typically in $[0,1]$ when gains are non-negative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb910f5",
   "metadata": {},
   "source": [
    "## 2) Intuition (plots)\n",
    "\n",
    "We'll use a toy query with 6 items.\n",
    "\n",
    "We'll compare two rankings:\n",
    "- a **good** model puts high-gain items near the top\n",
    "- a **bad** model pushes good items down\n",
    "\n",
    "We'll visualize:\n",
    "- per-rank gain, discount, and contribution\n",
    "- cumulative DCG curves\n",
    "- DCG@k as a function of the cutoff $k$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf14e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ids = np.array([f\"doc_{i}\" for i in range(6)])\n",
    "\n",
    "# Gains (true relevance). In sklearn, these are used directly (no gain transform).\n",
    "y_true_1q = np.array([3, 2, 3, 0, 1, 2], dtype=float)\n",
    "\n",
    "# Two different score vectors (both induce a ranking).\n",
    "y_score_good = np.array([0.90, 0.70, 0.80, 0.05, 0.30, 0.60])\n",
    "y_score_bad = np.array([0.10, 0.20, 0.30, 0.95, 0.80, 0.70])\n",
    "\n",
    "Y_true = y_true_1q[None, :]\n",
    "\n",
    "print(\"sklearn DCG (good):\", sk_dcg_score(Y_true, y_score_good[None, :]))\n",
    "print(\"sklearn DCG (bad): \", sk_dcg_score(Y_true, y_score_bad[None, :]))\n",
    "print(\"sklearn NDCG (good):\", sk_ndcg_score(Y_true, y_score_good[None, :]))\n",
    "print(\"sklearn NDCG (bad): \", sk_ndcg_score(Y_true, y_score_bad[None, :]))\n",
    "\n",
    "for k in [1, 3, 5]:\n",
    "    print(f\"DCG@{k} (good): {sk_dcg_score(Y_true, y_score_good[None, :], k=k):.4f}\")\n",
    "    print(f\"DCG@{k} (bad):  {sk_dcg_score(Y_true, y_score_bad[None, :], k=k):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba66fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_rank_contributions(y_true_1d, y_score_1d, *, k=None, log_base=2, doc_ids=None):\n",
    "    \"\"\"Return rank-wise DCG components for a single query.\n",
    "\n",
    "    This ignores tie-averaging and is meant for visualization.\n",
    "    \"\"\"\n",
    "    y_true_1d = np.asarray(y_true_1d, dtype=float)\n",
    "    y_score_1d = np.asarray(y_score_1d, dtype=float)\n",
    "    if y_true_1d.shape != y_score_1d.shape:\n",
    "        raise ValueError(\"y_true_1d and y_score_1d must have the same shape\")\n",
    "\n",
    "    n_labels = y_true_1d.size\n",
    "    order = np.argsort(y_score_1d)[::-1]\n",
    "\n",
    "    gains = y_true_1d[order]\n",
    "    scores = y_score_1d[order]\n",
    "\n",
    "    ranks = np.arange(1, n_labels + 1)\n",
    "    discount = 1.0 / (np.log(ranks + 1) / np.log(log_base))\n",
    "    if k is not None:\n",
    "        discount[k:] = 0.0\n",
    "\n",
    "    contrib = gains * discount\n",
    "    cum_dcg = np.cumsum(contrib)\n",
    "\n",
    "    if doc_ids is None:\n",
    "        doc_ids = np.arange(n_labels)\n",
    "    doc_ids = np.asarray(doc_ids)\n",
    "\n",
    "    return {\n",
    "        \"rank\": ranks,\n",
    "        \"doc\": doc_ids[order],\n",
    "        \"gain\": gains,\n",
    "        \"score\": scores,\n",
    "        \"discount\": discount,\n",
    "        \"contrib\": contrib,\n",
    "        \"cum_dcg\": cum_dcg,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dd92b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dcg_breakdown(components, *, title=\"DCG breakdown\"):\n",
    "    ranks = components[\"rank\"]\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=2,\n",
    "        cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.14,\n",
    "        specs=[[{\"secondary_y\": True}], [{\"secondary_y\": True}]],\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=ranks,\n",
    "            y=components[\"gain\"],\n",
    "            name=\"gain (y_true)\",\n",
    "            hovertemplate=\"rank=%{x}<br>gain=%{y}<br>doc=%{customdata[0]}<br>score=%{customdata[1]:.3f}<extra></extra>\",\n",
    "            customdata=np.c_[components[\"doc\"], components[\"score\"]],\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=ranks,\n",
    "            y=components[\"discount\"],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"discount\",\n",
    "            hovertemplate=\"rank=%{x}<br>discount=%{y:.3f}<extra></extra>\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "        secondary_y=True,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=ranks,\n",
    "            y=components[\"contrib\"],\n",
    "            name=\"gain × discount\",\n",
    "            hovertemplate=\"rank=%{x}<br>contrib=%{y:.3f}<extra></extra>\",\n",
    "        ),\n",
    "        row=2,\n",
    "        col=1,\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=ranks,\n",
    "            y=components[\"cum_dcg\"],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"cumulative DCG\",\n",
    "            hovertemplate=\"rank=%{x}<br>cum_dcg=%{y:.3f}<extra></extra>\",\n",
    "        ),\n",
    "        row=2,\n",
    "        col=1,\n",
    "        secondary_y=True,\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(title_text=\"rank (1 = top)\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"gain\", row=1, col=1, secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"discount\", row=1, col=1, secondary_y=True)\n",
    "    fig.update_yaxes(title_text=\"contribution\", row=2, col=1, secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"cumulative DCG\", row=2, col=1, secondary_y=True)\n",
    "    fig.update_layout(title=title, legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0))\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "good = dcg_rank_contributions(y_true_1q, y_score_good, k=None, doc_ids=doc_ids)\n",
    "bad = dcg_rank_contributions(y_true_1q, y_score_bad, k=None, doc_ids=doc_ids)\n",
    "\n",
    "plot_dcg_breakdown(good, title=\"Good ranking: per-rank DCG contributions\").show()\n",
    "plot_dcg_breakdown(bad, title=\"Bad ranking: per-rank DCG contributions\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8deb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_dcg_curve(y_true_1d, y_score_1d, *, log_base=2):\n",
    "    comps = dcg_rank_contributions(y_true_1d, y_score_1d, k=None, log_base=log_base)\n",
    "    return comps[\"rank\"], comps[\"cum_dcg\"]\n",
    "\n",
    "\n",
    "r, dcg_good = cumulative_dcg_curve(y_true_1q, y_score_good)\n",
    "_, dcg_bad = cumulative_dcg_curve(y_true_1q, y_score_bad)\n",
    "_, dcg_ideal = cumulative_dcg_curve(y_true_1q, y_true_1q)  # ideal ordering\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=r, y=dcg_good, mode=\"lines+markers\", name=\"good\"))\n",
    "fig.add_trace(go.Scatter(x=r, y=dcg_bad, mode=\"lines+markers\", name=\"bad\"))\n",
    "fig.add_trace(go.Scatter(x=r, y=dcg_ideal, mode=\"lines+markers\", name=\"ideal (IDCG)\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Cumulative DCG vs rank\",\n",
    "    xaxis_title=\"rank (1 = top)\",\n",
    "    yaxis_title=\"cumulative DCG\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = np.arange(1, len(y_true_1q) + 1)\n",
    "dcg_good_k = [sk_dcg_score(Y_true, y_score_good[None, :], k=int(k)) for k in ks]\n",
    "dcg_bad_k = [sk_dcg_score(Y_true, y_score_bad[None, :], k=int(k)) for k in ks]\n",
    "idcg_k = [sk_dcg_score(Y_true, Y_true, k=int(k), ignore_ties=True) for k in ks]\n",
    "ndcg_good_k = [g / i if i > 0 else 0.0 for g, i in zip(dcg_good_k, idcg_k)]\n",
    "ndcg_bad_k = [g / i if i > 0 else 0.0 for g, i in zip(dcg_bad_k, idcg_k)]\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=[\"DCG@k\", \"NDCG@k\"], shared_xaxes=True)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=ks, y=dcg_good_k, mode=\"lines+markers\", name=\"good\"), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=ks, y=dcg_bad_k, mode=\"lines+markers\", name=\"bad\"), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=ks, y=ndcg_good_k, mode=\"lines+markers\", name=\"good\"), row=1, col=2)\n",
    "fig.add_trace(go.Scatter(x=ks, y=ndcg_bad_k, mode=\"lines+markers\", name=\"bad\"), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"k (cutoff)\")\n",
    "fig.update_yaxes(title_text=\"score\")\n",
    "fig.update_layout(title=\"Effect of cutoff k\", legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.08, xanchor=\"left\", x=0))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f427da",
   "metadata": {},
   "source": [
    "## 3) NumPy implementation (including tie averaging)\n",
    "\n",
    "We'll implement a drop-in equivalent of scikit-learn's `dcg_score`:\n",
    "\n",
    "- works on `y_true` and `y_score` shaped `(n_samples, n_labels)`\n",
    "- supports `k`, `log_base`, `sample_weight`, and `ignore_ties`\n",
    "- matches scikit-learn tie-averaging when `ignore_ties=False`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a59ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _as_2d(a, *, name):\n",
    "    a = np.asarray(a)\n",
    "    if a.ndim == 1:\n",
    "        a = a[None, :]\n",
    "    if a.ndim != 2:\n",
    "        raise ValueError(f\"{name} must be 1D or 2D, got shape {a.shape}\")\n",
    "    return a\n",
    "\n",
    "\n",
    "def _discount_vector(n_labels, *, k=None, log_base=2):\n",
    "    if log_base <= 1:\n",
    "        raise ValueError(\"log_base must be > 1\")\n",
    "\n",
    "    ranks0 = np.arange(n_labels)\n",
    "    discount = 1.0 / (np.log(ranks0 + 2.0) / np.log(log_base))\n",
    "    if k is not None:\n",
    "        if not (1 <= int(k) <= n_labels):\n",
    "            raise ValueError(f\"k must be in [1, {n_labels}], got {k}\")\n",
    "        discount[int(k) :] = 0.0\n",
    "    return discount\n",
    "\n",
    "\n",
    "def _tie_averaged_dcg_1d(y_true_1d, y_score_1d, discount_cumsum):\n",
    "    \"\"\"DCG for one sample by averaging over all permutations of tied scores.\n",
    "\n",
    "    Matches sklearn.metrics._ranking._tie_averaged_dcg.\n",
    "    \"\"\"\n",
    "    _, inv, counts = np.unique(-y_score_1d, return_inverse=True, return_counts=True)\n",
    "\n",
    "    mean_gain_per_group = np.zeros(len(counts), dtype=float)\n",
    "    np.add.at(mean_gain_per_group, inv, y_true_1d)\n",
    "    mean_gain_per_group /= counts\n",
    "\n",
    "    groups_end = np.cumsum(counts) - 1\n",
    "\n",
    "    discount_sums = np.empty(len(counts), dtype=float)\n",
    "    discount_sums[0] = discount_cumsum[groups_end[0]]\n",
    "    discount_sums[1:] = np.diff(discount_cumsum[groups_end])\n",
    "\n",
    "    return float((mean_gain_per_group * discount_sums).sum())\n",
    "\n",
    "\n",
    "def _dcg_sample_scores_numpy(y_true, y_score, *, k=None, log_base=2, ignore_ties=False):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_score = np.asarray(y_score, dtype=float)\n",
    "    if y_true.shape != y_score.shape:\n",
    "        raise ValueError(f\"y_true and y_score must have the same shape, got {y_true.shape} vs {y_score.shape}\")\n",
    "\n",
    "    n_samples, n_labels = y_true.shape\n",
    "    discount = _discount_vector(n_labels, k=k, log_base=log_base)\n",
    "\n",
    "    if ignore_ties:\n",
    "        ranking = np.argsort(y_score, axis=1)[:, ::-1]\n",
    "        ranked_true = y_true[np.arange(n_samples)[:, None], ranking]\n",
    "        return discount @ ranked_true.T\n",
    "\n",
    "    discount_cumsum = np.cumsum(discount)\n",
    "    out = np.empty(n_samples, dtype=float)\n",
    "    for i in range(n_samples):\n",
    "        out[i] = _tie_averaged_dcg_1d(y_true[i], y_score[i], discount_cumsum)\n",
    "    return out\n",
    "\n",
    "\n",
    "def dcg_score_numpy(y_true, y_score, *, k=None, log_base=2, sample_weight=None, ignore_ties=False, return_per_sample=False):\n",
    "    \"\"\"NumPy implementation of sklearn.metrics.dcg_score.\"\"\"\n",
    "    y_true = _as_2d(y_true, name=\"y_true\")\n",
    "    y_score = _as_2d(y_score, name=\"y_score\")\n",
    "\n",
    "    scores = _dcg_sample_scores_numpy(y_true, y_score, k=k, log_base=log_base, ignore_ties=ignore_ties)\n",
    "\n",
    "    if return_per_sample:\n",
    "        return scores\n",
    "\n",
    "    if sample_weight is None:\n",
    "        return float(np.mean(scores))\n",
    "    sample_weight = np.asarray(sample_weight, dtype=float)\n",
    "    if sample_weight.shape != (scores.shape[0],):\n",
    "        raise ValueError(f\"sample_weight must have shape ({scores.shape[0]},), got {sample_weight.shape}\")\n",
    "    return float(np.average(scores, weights=sample_weight))\n",
    "\n",
    "\n",
    "def ndcg_score_numpy(y_true, y_score, *, k=None, sample_weight=None, ignore_ties=False, return_per_sample=False):\n",
    "    \"\"\"NumPy implementation of sklearn.metrics.ndcg_score (built from DCG).\"\"\"\n",
    "    y_true = _as_2d(y_true, name=\"y_true\")\n",
    "    y_score = _as_2d(y_score, name=\"y_score\")\n",
    "\n",
    "    gain = _dcg_sample_scores_numpy(y_true, y_score, k=k, log_base=2, ignore_ties=ignore_ties)\n",
    "    ideal = _dcg_sample_scores_numpy(y_true, y_true, k=k, log_base=2, ignore_ties=True)\n",
    "\n",
    "    out = np.zeros_like(gain, dtype=float)\n",
    "    mask = ideal != 0\n",
    "    out[mask] = gain[mask] / ideal[mask]\n",
    "\n",
    "    if return_per_sample:\n",
    "        return out\n",
    "\n",
    "    if sample_weight is None:\n",
    "        return float(np.mean(out))\n",
    "    sample_weight = np.asarray(sample_weight, dtype=float)\n",
    "    if sample_weight.shape != (out.shape[0],):\n",
    "        raise ValueError(f\"sample_weight must have shape ({out.shape[0]},), got {sample_weight.shape}\")\n",
    "    return float(np.average(out, weights=sample_weight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d57ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks vs scikit-learn\n",
    "Yt = rng.integers(0, 4, size=(50, 12))\n",
    "Ys = rng.normal(size=(50, 12))\n",
    "\n",
    "for ignore_ties in [True, False]:\n",
    "    for k in [None, 5]:\n",
    "        for base in [2, 10]:\n",
    "            sk = sk_dcg_score(Yt, Ys, k=k, log_base=base, ignore_ties=ignore_ties)\n",
    "            np_ = dcg_score_numpy(Yt, Ys, k=k, log_base=base, ignore_ties=ignore_ties)\n",
    "            print(f\"ignore_ties={ignore_ties} k={k} base={base} | abs diff={abs(sk - np_):.12f}\")\n",
    "\n",
    "# A tie-heavy example (by rounding scores)\n",
    "Ys_ties = np.round(Ys, 1)\n",
    "sk = sk_dcg_score(Yt, Ys_ties, k=5, ignore_ties=False)\n",
    "np_ = dcg_score_numpy(Yt, Ys_ties, k=5, ignore_ties=False)\n",
    "print(\"\\nTie-heavy check | sklearn:\", sk, \"numpy:\", np_, \"abs diff:\", abs(sk - np_))\n",
    "\n",
    "# The classic tied-top example from sklearn docs\n",
    "true_relevance = np.asarray([[10, 0, 0, 1, 5]])\n",
    "scores = np.asarray([[1, 0, 0, 0, 1]])\n",
    "print(\"\\nTies at the top (k=1)\")\n",
    "print(\"sklearn (tie-avg): \", sk_dcg_score(true_relevance, scores, k=1))\n",
    "print(\"numpy  (tie-avg): \", dcg_score_numpy(true_relevance, scores, k=1))\n",
    "print(\"sklearn (ignore):  \", sk_dcg_score(true_relevance, scores, k=1, ignore_ties=True))\n",
    "print(\"numpy  (ignore):  \", dcg_score_numpy(true_relevance, scores, k=1, ignore_ties=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd39bf2",
   "metadata": {},
   "source": [
    "## 4) Using DCG/NDCG to optimize/tune a simple model\n",
    "\n",
    "DCG depends on **sorting**, so it's not smoothly differentiable in the usual sense.\n",
    "In practice, you often:\n",
    "\n",
    "1. optimize a differentiable surrogate loss (pointwise/pairwise/listwise), and evaluate with NDCG/DCG\n",
    "2. or use a **black-box** optimizer to directly maximize NDCG/DCG\n",
    "\n",
    "Here we'll do (2) with a simple **linear scoring model**:\n",
    "\n",
    "$$\n",
    "s(x) = w^\\top x\n",
    "$$\n",
    "\n",
    "and optimize $w$ by coordinate ascent to maximize mean NDCG@k on a toy ranking dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0999e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_synthetic_ranking_data(*, n_queries=400, n_docs=12, n_features=6, noise=0.7, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    w_true = rng.normal(size=n_features)\n",
    "\n",
    "    X = rng.normal(size=(n_queries, n_docs, n_features))\n",
    "    raw = X @ w_true + noise * rng.normal(size=(n_queries, n_docs))\n",
    "\n",
    "    # Convert raw scores to graded relevance per query using quantiles.\n",
    "    q50 = np.quantile(raw, 0.50, axis=1, keepdims=True)\n",
    "    q75 = np.quantile(raw, 0.75, axis=1, keepdims=True)\n",
    "    q90 = np.quantile(raw, 0.90, axis=1, keepdims=True)\n",
    "\n",
    "    y = np.zeros_like(raw, dtype=int)\n",
    "    y += raw >= q50\n",
    "    y += raw >= q75\n",
    "    y += raw >= q90\n",
    "\n",
    "    return X, y.astype(float), w_true\n",
    "\n",
    "\n",
    "X, y_true, w_true = make_synthetic_ranking_data()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_true, test_size=0.30, random_state=0)\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"relevance levels in y:\", np.unique(y_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3507dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_ndcg_at_k(y_true, y_score, *, k=5):\n",
    "    return ndcg_score_numpy(y_true, y_score, k=k, ignore_ties=False)\n",
    "\n",
    "\n",
    "def coordinate_ascent_ndcg(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    *,\n",
    "    k=5,\n",
    "    n_passes=30,\n",
    "    step=0.5,\n",
    "    step_decay=0.9,\n",
    "    init_scale=0.2,\n",
    "    seed=0,\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_features = X_train.shape[-1]\n",
    "\n",
    "    w = rng.normal(scale=init_scale, size=n_features)\n",
    "    w0 = w.copy()\n",
    "\n",
    "    def score(X, w):\n",
    "        return X @ w\n",
    "\n",
    "    def evaluate(X, y, w):\n",
    "        return mean_ndcg_at_k(y, score(X, w), k=k)\n",
    "\n",
    "    history = {\n",
    "        \"pass\": [],\n",
    "        \"step\": [],\n",
    "        \"train_ndcg\": [],\n",
    "        \"val_ndcg\": [],\n",
    "    }\n",
    "\n",
    "    best_val = -np.inf\n",
    "    best_w = w.copy()\n",
    "\n",
    "    for p in range(n_passes):\n",
    "        improved = False\n",
    "        base_train = evaluate(X_train, y_train, w)\n",
    "\n",
    "        for j in range(n_features):\n",
    "            best_local = base_train\n",
    "            best_delta = 0.0\n",
    "\n",
    "            for delta in (+step, -step):\n",
    "                w_try = w.copy()\n",
    "                w_try[j] += delta\n",
    "                val = evaluate(X_train, y_train, w_try)\n",
    "                if val > best_local + 1e-12:\n",
    "                    best_local = val\n",
    "                    best_delta = delta\n",
    "\n",
    "            if best_delta != 0.0:\n",
    "                w[j] += best_delta\n",
    "                base_train = best_local\n",
    "                improved = True\n",
    "\n",
    "        train_ndcg = evaluate(X_train, y_train, w)\n",
    "        val_ndcg = evaluate(X_val, y_val, w)\n",
    "\n",
    "        history[\"pass\"].append(p)\n",
    "        history[\"step\"].append(step)\n",
    "        history[\"train_ndcg\"].append(train_ndcg)\n",
    "        history[\"val_ndcg\"].append(val_ndcg)\n",
    "\n",
    "        if val_ndcg > best_val:\n",
    "            best_val = val_ndcg\n",
    "            best_w = w.copy()\n",
    "\n",
    "        step *= step_decay\n",
    "        if not improved:\n",
    "            # No single-coordinate improvement found at this step size.\n",
    "            break\n",
    "\n",
    "    return w0, best_w, history\n",
    "\n",
    "\n",
    "w0, w_best, hist = coordinate_ascent_ndcg(X_train, y_train, X_val, y_val, k=5, n_passes=40, step=0.6, step_decay=0.9, seed=1)\n",
    "\n",
    "print(\"initial val NDCG@5:\", mean_ndcg_at_k(y_val, X_val @ w0, k=5))\n",
    "print(\"best    val NDCG@5:\", mean_ndcg_at_k(y_val, X_val @ w_best, k=5))\n",
    "print(\"true    val NDCG@5:\", mean_ndcg_at_k(y_val, X_val @ w_true, k=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f85de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=hist[\"pass\"], y=hist[\"train_ndcg\"], mode=\"lines+markers\", name=\"train NDCG@5\"))\n",
    "fig.add_trace(go.Scatter(x=hist[\"pass\"], y=hist[\"val_ndcg\"], mode=\"lines+markers\", name=\"val NDCG@5\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Coordinate ascent on NDCG@5 (linear scoring model)\",\n",
    "    xaxis_title=\"pass\",\n",
    "    yaxis_title=\"NDCG@5\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ac08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one query: relevance by predicted rank (before vs after)\n",
    "q = 0\n",
    "yq = y_val[q]\n",
    "s0 = (X_val[q] @ w0)\n",
    "s1 = (X_val[q] @ w_best)\n",
    "\n",
    "comp0 = dcg_rank_contributions(yq, s0, k=5)\n",
    "comp1 = dcg_rank_contributions(yq, s1, k=5)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=[\"initial ranking\", \"optimized ranking\"], shared_yaxes=True)\n",
    "\n",
    "fig.add_trace(go.Bar(x=comp0[\"rank\"], y=comp0[\"gain\"], name=\"gain\"), row=1, col=1)\n",
    "fig.add_trace(go.Bar(x=comp1[\"rank\"], y=comp1[\"gain\"], name=\"gain\"), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"rank (1 = top)\")\n",
    "fig.update_yaxes(title_text=\"gain (true relevance)\")\n",
    "fig.update_layout(title=f\"One validation query: gains by predicted rank (k=5)\")\n",
    "fig.show()\n",
    "\n",
    "print(\"Query DCG@5 (initial): \", dcg_score_numpy(yq, s0, k=5))\n",
    "print(\"Query DCG@5 (optimized):\", dcg_score_numpy(yq, s1, k=5))\n",
    "print(\"Query NDCG@5 (initial): \", ndcg_score_numpy(yq, s0, k=5))\n",
    "print(\"Query NDCG@5 (optimized):\", ndcg_score_numpy(yq, s1, k=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863b0597",
   "metadata": {},
   "source": [
    "## 5) Pros, cons, pitfalls\n",
    "\n",
    "### Pros\n",
    "- **Ranking-first**: directly measures whether relevant items are near the top.\n",
    "- **Top-heavy**: logarithmic discount matches many UX settings (users rarely scroll far).\n",
    "- **Graded relevance**: naturally supports 0/1/2/3 relevance, not just binary.\n",
    "- **Cutoff-friendly**: DCG@k focuses evaluation on the top-$k$ you actually show.\n",
    "\n",
    "### Cons\n",
    "- **Not normalized**: raw DCG depends on the gain scale and number of items; comparing across queries is hard (use NDCG).\n",
    "- **Non-smooth objective**: depends on sorting; direct gradient-based optimization is non-trivial.\n",
    "- **Ignores calibration**: only the **ordering** matters (monotonic transforms of scores keep DCG unchanged unless they create ties).\n",
    "\n",
    "### Common pitfalls\n",
    "- **Mixing queries**: DCG is defined per query (a list). Averaging over unrelated items can be meaningless.\n",
    "- **Ties**: if your model outputs few distinct scores, tie-handling matters; `ignore_ties=True` can be wrong.\n",
    "- **Gain definition**: if you expect exponential gain (e.g., $2^y-1$), you must transform `y_true` yourself.\n",
    "- **Negative gains**: NDCG may fall outside $[0,1]$ if `y_true` contains negative values.\n",
    "\n",
    "### Where DCG/NDCG is especially useful\n",
    "- search result ranking\n",
    "- recommendation lists\n",
    "- multilabel problems where you care about the **ordering of labels**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517c64e7",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Modify `dcg_score_numpy` to accept a `gain_fn` and compare linear vs exponential gains.\n",
    "2. Try different values of `k` and observe how the coordinate ascent solution changes.\n",
    "3. Create a dataset where optimizing a pointwise loss (e.g., MSE on gains) does **not** improve NDCG@k much. Why?\n",
    "\n",
    "## References\n",
    "- J\\u00e4rvelin, K., & Kek\\u00e4l\\u00e4inen, J. (2002). Cumulated gain-based evaluation of IR techniques.\n",
    "- scikit-learn: `sklearn.metrics.dcg_score`, `sklearn.metrics.ndcg_score`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}