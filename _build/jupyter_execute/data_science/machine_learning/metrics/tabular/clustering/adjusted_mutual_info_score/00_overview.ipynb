{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63cd8b3a",
   "metadata": {},
   "source": [
    "# Adjusted Mutual Information (AMI) — `adjusted_mutual_info_score`\n",
    "\n",
    "Adjusted Mutual Information (AMI) compares two **cluster labelings** (two partitions of the same `n` samples) and corrects Mutual Information (MI) for agreement **expected by chance**.\n",
    "\n",
    "AMI is an **external** clustering metric: it needs two labelings (e.g., ground truth classes and predicted clusters, or two different clustering algorithms).\n",
    "\n",
    "**Goals**\n",
    "- Build intuition: contingency tables → MI → chance correction → AMI.\n",
    "- Implement AMI from scratch in NumPy (including Expected MI).\n",
    "- Visualize how AMI behaves (permutation invariance, noise, number of clusters).\n",
    "- Use AMI as a black-box objective to tune a simple model (logistic regression threshold / regularization).\n",
    "\n",
    "**Quick import**\n",
    "```python\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec49e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from scipy.special import gammaln\n",
    "\n",
    "from sklearn.datasets import make_blobs, make_classification\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    adjusted_mutual_info_score as skl_adjusted_mutual_info_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "rng = np.random.default_rng(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1230f446",
   "metadata": {},
   "source": [
    "## 1) The core object: the contingency table\n",
    "\n",
    "Let two labelings of the same `n` samples be:\n",
    "\n",
    "- True partition: \\(U = \\{U_1,\\dots,U_R\\}\\)\n",
    "- Predicted partition: \\(V = \\{V_1,\\dots,V_C\\}\\)\n",
    "\n",
    "Define the **contingency table** \\(N\\in\\mathbb{N}^{R\\times C}\\) by\n",
    "\n",
    "\\[\n",
    "N_{ij} = |U_i \\cap V_j|.\n",
    "\\]\n",
    "\n",
    "Row and column sums are\n",
    "\n",
    "\\[\n",
    "a_i = \\sum_j N_{ij} = |U_i|,\\qquad b_j = \\sum_i N_{ij} = |V_j|,\\qquad n = \\sum_i a_i = \\sum_j b_j.\n",
    "\\]\n",
    "\n",
    "From counts we can define empirical probabilities:\n",
    "\n",
    "\\[\n",
    "p_{ij} = \\frac{N_{ij}}{n},\\qquad p_{i\\cdot} = \\frac{a_i}{n},\\qquad p_{\\cdot j} = \\frac{b_j}{n}.\n",
    "\\]\n",
    "\n",
    "AMI is computed entirely from \\(N\\) (it ignores feature geometry)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56937e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _relabel_to_integers(labels: np.ndarray) -> np.ndarray:\n",
    "    labels = np.asarray(labels)\n",
    "    _, relabeled = np.unique(labels, return_inverse=True)\n",
    "    return relabeled\n",
    "\n",
    "\n",
    "def contingency_matrix_np(labels_true: np.ndarray, labels_pred: np.ndarray) -> np.ndarray:\n",
    "    # Contingency table N_ij = |U_i ∩ V_j| for two labelings.\n",
    "    true_int = _relabel_to_integers(labels_true)\n",
    "    pred_int = _relabel_to_integers(labels_pred)\n",
    "\n",
    "    n_true = int(true_int.max()) + 1\n",
    "    n_pred = int(pred_int.max()) + 1\n",
    "\n",
    "    contingency = np.zeros((n_true, n_pred), dtype=np.int64)\n",
    "    np.add.at(contingency, (true_int, pred_int), 1)\n",
    "    return contingency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752275a7",
   "metadata": {},
   "source": [
    "## 2) Mutual Information (MI)\n",
    "\n",
    "The **mutual information** between partitions \\(U\\) and \\(V\\) is the mutual information between the discrete random variables “which cluster am I in?” under each labeling.\n",
    "\n",
    "\\[\n",
    "\\mathrm{MI}(U,V) = \\sum_{i=1}^{R}\\sum_{j=1}^{C} p_{ij}\\,\\log\\frac{p_{ij}}{p_{i\\cdot}\\,p_{\\cdot j}}.\n",
    "\\]\n",
    "\n",
    "Equivalent (using counts) for \\(N_{ij} > 0\\):\n",
    "\n",
    "\\[\n",
    "\\mathrm{MI}(U,V) = \\sum_{i,j: N_{ij}>0} \\frac{N_{ij}}{n}\\,\\log\\left(\\frac{n\\,N_{ij}}{a_i\\,b_j}\\right).\n",
    "\\]\n",
    "\n",
    "The entropies are\n",
    "\\[\n",
    "H(U) = -\\sum_i p_{i\\cdot}\\log p_{i\\cdot},\\qquad H(V) = -\\sum_j p_{\\cdot j}\\log p_{\\cdot j},\n",
    "\\]\n",
    "and \\(\\mathrm{MI}(U,V) = H(U) + H(V) - H(U,V)\\).\n",
    "\n",
    "**Units**: with natural logs, MI is in **nats** (use \\(\\log_2\\) for bits).\n",
    "\n",
    "### Why MI needs adjustment\n",
    "MI tends to **increase** when you use more clusters (more degrees of freedom), even for unrelated/random labelings. AMI fixes that by subtracting the MI you’d expect *by chance* given the cluster sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77282e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_from_counts(counts: np.ndarray) -> float:\n",
    "    counts = np.asarray(counts, dtype=np.float64)\n",
    "    n = counts.sum()\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "\n",
    "    p = counts[counts > 0] / n\n",
    "    return float(-np.sum(p * np.log(p)))\n",
    "\n",
    "\n",
    "def mutual_info_from_contingency(contingency: np.ndarray) -> float:\n",
    "    # Mutual information in nats, computed from a contingency table.\n",
    "    contingency = np.asarray(contingency, dtype=np.int64)\n",
    "    n = int(contingency.sum())\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "\n",
    "    row_sums = contingency.sum(axis=1)\n",
    "    col_sums = contingency.sum(axis=0)\n",
    "\n",
    "    row_idx, col_idx = np.nonzero(contingency)\n",
    "    nij = contingency[row_idx, col_idx].astype(np.float64)\n",
    "\n",
    "    # MI = sum (nij/n) * log( (n*nij)/(ai*bj) )\n",
    "    numerator = nij * n\n",
    "    denominator = row_sums[row_idx] * col_sums[col_idx]\n",
    "\n",
    "    return float(np.sum((nij / n) * np.log(numerator / denominator)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c94ac3",
   "metadata": {},
   "source": [
    "## 3) Chance correction: Expected Mutual Information (EMI)\n",
    "\n",
    "AMI uses the expected MI under the null model:\n",
    "\n",
    "- the two labelings are **random**\n",
    "- but their cluster size distributions \\(\\{a_i\\}\\) and \\(\\{b_j\\}\\) are **fixed** (same marginals as observed)\n",
    "\n",
    "This is the “generalized hypergeometric” model.\n",
    "\n",
    "For a fixed pair of clusters \\((i,j)\\), the intersection size \\(K = N_{ij}\\) follows a hypergeometric distribution:\n",
    "\n",
    "\\[\n",
    "K \\sim \\mathrm{Hypergeometric}(N=n,\\; K=a_i,\\; n=b_j)\n",
    "\\]\n",
    "\n",
    "so\n",
    "\n",
    "\\[\n",
    "\\mathbb{P}(K=k) = \\frac{\\binom{a_i}{k}\\binom{n-a_i}{b_j-k}}{\\binom{n}{b_j}},\\qquad k\\in[\\max(0,a_i+b_j-n),\\min(a_i,b_j)].\n",
    "\\]\n",
    "\n",
    "Then\n",
    "\n",
    "\\[\n",
    "\\mathrm{EMI} = \\mathbb{E}[\\mathrm{MI}(U,V)]\n",
    "= \\sum_{i=1}^{R}\\sum_{j=1}^{C}\\sum_{k} \\frac{k}{n}\\,\\log\\left(\\frac{n\\,k}{a_i\\,b_j}\\right)\\,\\mathbb{P}(K=k).\n",
    "\\]\n",
    "\n",
    "This looks heavy, but for typical cluster counts it’s feasible (the inner sum only ranges up to \\(\\min(a_i,b_j)\\))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a46fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_mutual_info_from_marginals(row_sums: np.ndarray, col_sums: np.ndarray) -> float:\n",
    "    # Expected mutual information under the hypergeometric null (fixed marginals).\n",
    "    row_sums = np.asarray(row_sums, dtype=np.int64)\n",
    "    col_sums = np.asarray(col_sums, dtype=np.int64)\n",
    "\n",
    "    n = int(row_sums.sum())\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # log-factorials for stable combinatorics: log(n!) = gammaln(n+1)\n",
    "    log_factorial = gammaln(np.arange(n + 1, dtype=np.float64) + 1.0)\n",
    "\n",
    "    def log_comb(n_: int, k_: np.ndarray | int) -> np.ndarray:\n",
    "        k_arr = np.asarray(k_, dtype=np.int64)\n",
    "        return log_factorial[n_] - log_factorial[k_arr] - log_factorial[n_ - k_arr]\n",
    "\n",
    "    expected_mi = 0.0\n",
    "\n",
    "    for a in row_sums:\n",
    "        for b in col_sums:\n",
    "            k_min = max(0, a + b - n)\n",
    "            k_max = min(a, b)\n",
    "            if k_max < k_min:\n",
    "                continue\n",
    "\n",
    "            # Include k=0 in the probability normalization. (Its contribution to MI is 0.)\n",
    "            k = np.arange(k_min, k_max + 1, dtype=np.int64)\n",
    "\n",
    "            # Hypergeometric PMF in log-space:\n",
    "            # P(K=k) = C(a,k) * C(n-a, b-k) / C(n,b)\n",
    "            log_p = log_comb(a, k) + log_comb(n - a, b - k) - log_comb(n, b)\n",
    "\n",
    "            # Normalize to avoid under/overflow in exp.\n",
    "            m = float(log_p.max())\n",
    "            p = np.exp(log_p - m)\n",
    "            p = p / p.sum()\n",
    "\n",
    "            mask = k > 0\n",
    "            if not np.any(mask):\n",
    "                continue\n",
    "\n",
    "            k_pos = k[mask]\n",
    "            term = (k_pos / n) * np.log((n * k_pos) / (a * b))\n",
    "            expected_mi += float(np.sum(p[mask] * term))\n",
    "\n",
    "    return float(expected_mi)\n",
    "\n",
    "\n",
    "def adjusted_mutual_info_score_np(\n",
    "    labels_true: np.ndarray,\n",
    "    labels_pred: np.ndarray,\n",
    "    *,\n",
    "    average_method: str = \"arithmetic\",\n",
    ") -> float:\n",
    "    # Adjusted mutual information (AMI) in NumPy (+ gammaln for stability).\n",
    "    contingency = contingency_matrix_np(labels_true, labels_pred)\n",
    "    n = int(contingency.sum())\n",
    "    if n == 0:\n",
    "        return 1.0\n",
    "\n",
    "    row_sums = contingency.sum(axis=1)\n",
    "    col_sums = contingency.sum(axis=0)\n",
    "\n",
    "    h_true = entropy_from_counts(row_sums)\n",
    "    h_pred = entropy_from_counts(col_sums)\n",
    "\n",
    "    # Degenerate case: both partitions put everything in one cluster.\n",
    "    if h_true == 0.0 and h_pred == 0.0:\n",
    "        return 1.0\n",
    "\n",
    "    mi = mutual_info_from_contingency(contingency)\n",
    "    emi = expected_mutual_info_from_marginals(row_sums, col_sums)\n",
    "\n",
    "    if average_method == \"arithmetic\":\n",
    "        normalizer = 0.5 * (h_true + h_pred)\n",
    "    elif average_method == \"min\":\n",
    "        normalizer = min(h_true, h_pred)\n",
    "    elif average_method == \"max\":\n",
    "        normalizer = max(h_true, h_pred)\n",
    "    elif average_method == \"geometric\":\n",
    "        normalizer = float(np.sqrt(h_true * h_pred))\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"average_method must be one of: 'arithmetic', 'min', 'max', 'geometric'\"\n",
    "        )\n",
    "\n",
    "    denom = normalizer - emi\n",
    "    if denom <= np.finfo(float).eps:\n",
    "        return 0.0\n",
    "\n",
    "    return float((mi - emi) / denom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d25d105",
   "metadata": {},
   "source": [
    "## 4) AMI definition (and why it’s useful)\n",
    "\n",
    "Given MI and its expectation under chance, AMI is\n",
    "\n",
    "\\[\n",
    "\\mathrm{AMI}(U,V) = \\frac{\\mathrm{MI}(U,V) - \\mathrm{EMI}}{\\mathrm{Normalizer} - \\mathrm{EMI}}.\n",
    "\\]\n",
    "\n",
    "In scikit-learn, the normalizer is based on \\(H(U)\\) and \\(H(V)\\) via `average_method`:\n",
    "\n",
    "- `arithmetic`: \\(\\frac{H(U) + H(V)}{2}\\) (default)\n",
    "- `min`: \\(\\min(H(U), H(V))\\)\n",
    "- `max`: \\(\\max(H(U), H(V))\\)\n",
    "- `geometric`: \\(\\sqrt{H(U)H(V)}\\)\n",
    "\n",
    "**Key properties**\n",
    "- **Permutation invariant**: renaming cluster IDs doesn’t change AMI.\n",
    "- **Chance-corrected**: unrelated random partitions have AMI ≈ 0.\n",
    "- **Comparable across different numbers of clusters** (unlike raw MI).\n",
    "- Can be **negative** if agreement is worse than chance (under this null model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c37752",
   "metadata": {},
   "source": [
    "## 5) Sanity check vs scikit-learn\n",
    "\n",
    "Below we compare our NumPy implementation to `sklearn.metrics.adjusted_mutual_info_score` on random labelings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424c950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assert_matches_sklearn(n_trials: int = 200) -> None:\n",
    "    for average_method in [\"arithmetic\", \"min\", \"max\", \"geometric\"]:\n",
    "        for n in [10, 50, 200]:\n",
    "            for _ in range(n_trials):\n",
    "                y_true = rng.integers(0, 6, size=n)\n",
    "                y_pred = rng.integers(0, 8, size=n)\n",
    "\n",
    "                ours = adjusted_mutual_info_score_np(\n",
    "                    y_true, y_pred, average_method=average_method\n",
    "                )\n",
    "                skl = skl_adjusted_mutual_info_score(\n",
    "                    y_true, y_pred, average_method=average_method\n",
    "                )\n",
    "                if not np.isclose(ours, skl, atol=1e-10, rtol=0.0):\n",
    "                    raise AssertionError(\n",
    "                        f\"Mismatch (n={n}, average_method={average_method}): \"\n",
    "                        f\"ours={ours}, sklearn={skl}\"\n",
    "                    )\n",
    "\n",
    "\n",
    "_assert_matches_sklearn(n_trials=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e7527",
   "metadata": {},
   "source": [
    "## 6) Toy examples: permutation invariance and errors\n",
    "\n",
    "Let’s build three predicted labelings from the same ground truth:\n",
    "\n",
    "1) Perfect match up to a label permutation\n",
    "2) A few mistakes (some points moved to the wrong cluster)\n",
    "3) Completely random labels\n",
    "\n",
    "We’ll look at the contingency tables and AMI values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d821ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])\n",
    "\n",
    "# Perfect up to relabeling: 0→2, 1→0, 2→1\n",
    "perm = {0: 2, 1: 0, 2: 1}\n",
    "y_pred_permuted = np.array([perm[v] for v in y_true])\n",
    "\n",
    "# A few mistakes\n",
    "y_pred_noisy = y_pred_permuted.copy()\n",
    "y_pred_noisy[[1, 4, 7]] = [0, 1, 2]\n",
    "\n",
    "# Random labels with 3 clusters\n",
    "rng_local = np.random.default_rng(1)\n",
    "y_pred_random = rng_local.integers(0, 3, size=y_true.size)\n",
    "\n",
    "examples = {\n",
    "    \"perfect (permuted labels)\": y_pred_permuted,\n",
    "    \"noisy\": y_pred_noisy,\n",
    "    \"random\": y_pred_random,\n",
    "}\n",
    "\n",
    "scores = {\n",
    "    name: adjusted_mutual_info_score_np(y_true, y_pred)\n",
    "    for name, y_pred in examples.items()\n",
    "}\n",
    "\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ad0ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=3,\n",
    "    subplot_titles=[\n",
    "        f\"{name}<br>AMI={scores[name]:.3f}\" for name in examples.keys()\n",
    "    ],\n",
    ")\n",
    "\n",
    "for col, (name, y_pred) in enumerate(examples.items(), start=1):\n",
    "    cont = contingency_matrix_np(y_true, y_pred)\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=cont,\n",
    "            coloraxis=\"coloraxis\",\n",
    "            text=cont,\n",
    "            texttemplate=\"%{text}\",\n",
    "            x=[f\"pred {j}\" for j in range(cont.shape[1])],\n",
    "            y=[f\"true {i}\" for i in range(cont.shape[0])],\n",
    "        ),\n",
    "        row=1,\n",
    "        col=col,\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    height=320,\n",
    "    width=950,\n",
    "    title_text=\"Contingency tables (counts)\",\n",
    "    coloraxis=dict(colorscale=\"Blues\"),\n",
    ")\n",
    "\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4edb3a9",
   "metadata": {},
   "source": [
    "## 7) How AMI behaves with label noise\n",
    "\n",
    "We start from the true labels, then randomly “corrupt” a fraction \\(p\\) of labels (assigning them to a random cluster). AMI should decrease smoothly from near 1 toward ~0.\n",
    "\n",
    "We also show that **AMI stays near 0 for random labels**, even if we keep the number of clusters fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ddce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_true = make_blobs(\n",
    "    n_samples=400,\n",
    "    centers=4,\n",
    "    cluster_std=1.2,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "n = y_true.size\n",
    "k_true = len(np.unique(y_true))\n",
    "\n",
    "noise_grid = np.linspace(0.0, 0.9, 19)\n",
    "\n",
    "amis = []\n",
    "for p in noise_grid:\n",
    "    y_pred = y_true.copy()\n",
    "    n_flip = int(round(p * n))\n",
    "    flip_idx = rng.choice(n, size=n_flip, replace=False)\n",
    "\n",
    "    # Random reassignment (may coincidentally keep the same label for some points)\n",
    "    y_pred[flip_idx] = rng.integers(0, k_true, size=n_flip)\n",
    "\n",
    "    amis.append(adjusted_mutual_info_score_np(y_true, y_pred))\n",
    "\n",
    "# Baseline: fully random labels with the same number of clusters\n",
    "n_trials = 80\n",
    "ami_random = np.array(\n",
    "    [\n",
    "        adjusted_mutual_info_score_np(y_true, rng.integers(0, k_true, size=n))\n",
    "        for _ in range(n_trials)\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=noise_grid,\n",
    "        y=amis,\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"AMI (corrupted labels)\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[noise_grid.min(), noise_grid.max()],\n",
    "        y=[ami_random.mean(), ami_random.mean()],\n",
    "        mode=\"lines\",\n",
    "        name=f\"AMI mean (random labels, k={k_true})\",\n",
    "        line=dict(dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[noise_grid.min(), noise_grid.max()],\n",
    "        y=[np.quantile(ami_random, 0.1), np.quantile(ami_random, 0.1)],\n",
    "        mode=\"lines\",\n",
    "        line=dict(width=0),\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[noise_grid.min(), noise_grid.max()],\n",
    "        y=[np.quantile(ami_random, 0.9), np.quantile(ami_random, 0.9)],\n",
    "        mode=\"lines\",\n",
    "        fill=\"tonexty\",\n",
    "        line=dict(width=0),\n",
    "        name=\"random AMI 10%–90% band\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"AMI vs label noise\",\n",
    "    xaxis_title=\"fraction of labels corrupted\",\n",
    "    yaxis_title=\"adjusted mutual information (AMI)\",\n",
    "    height=420,\n",
    ")\n",
    "\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3024e34a",
   "metadata": {},
   "source": [
    "## 8) Why the adjustment matters: number of clusters bias\n",
    "\n",
    "Raw MI (and many related measures) can grow when the predicted labeling uses **more clusters**, even if it’s random.\n",
    "\n",
    "Below we sample random predicted labels with different `k` and plot both **MI** and **AMI**. If the labels are unrelated to the ground truth, AMI should stay near 0 regardless of `k`, while MI tends to drift upward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858e8a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_grid = np.arange(2, 31)\n",
    "\n",
    "mi_by_k = []\n",
    "ami_by_k = []\n",
    "for k in k_grid:\n",
    "    y_pred = rng.integers(0, k, size=n)\n",
    "    cont = contingency_matrix_np(y_true, y_pred)\n",
    "\n",
    "    mi_by_k.append(mutual_info_from_contingency(cont))\n",
    "    ami_by_k.append(adjusted_mutual_info_score_np(y_true, y_pred))\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1, specs=[[{\"secondary_y\": True}]])\n",
    "fig.add_trace(go.Scatter(x=k_grid, y=mi_by_k, mode=\"lines+markers\", name=\"MI (nats)\"), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=k_grid, y=ami_by_k, mode=\"lines+markers\", name=\"AMI\"), secondary_y=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Random labels: MI increases with k, AMI stays near 0\",\n",
    "    xaxis_title=\"k (number of predicted clusters)\",\n",
    "    height=430,\n",
    ")\n",
    "fig.update_yaxes(title_text=\"MI (nats)\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"AMI\", secondary_y=True)\n",
    "\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c288defa",
   "metadata": {},
   "source": [
    "## 9) AMI under chance: distribution\n",
    "\n",
    "Even under the null model, AMI fluctuates around 0 for finite `n`. We can visualize this by sampling many random predicted labelings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b81f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = k_true\n",
    "n_trials = 250\n",
    "ami_samples = np.array(\n",
    "    [\n",
    "        adjusted_mutual_info_score_np(y_true, rng.integers(0, k, size=n))\n",
    "        for _ in range(n_trials)\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig = px.histogram(\n",
    "    ami_samples,\n",
    "    nbins=30,\n",
    "    title=f\"AMI distribution for random labels (k={k}, n={n})\",\n",
    "    labels={\"value\": \"AMI\"},\n",
    ")\n",
    "fig.add_vline(x=float(ami_samples.mean()), line_dash=\"dash\", line_color=\"black\")\n",
    "fig.update_layout(height=420)\n",
    "\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4559ca7d",
   "metadata": {},
   "source": [
    "## 10) Using AMI as an optimization target (logistic regression)\n",
    "\n",
    "AMI is defined on **discrete labels**, so it’s not differentiable with respect to model parameters. That means:\n",
    "\n",
    "- You typically **don’t** train models by gradient descent on AMI directly.\n",
    "- You **can** use AMI as a **black-box objective** for:\n",
    "  - choosing thresholds\n",
    "  - selecting hyperparameters (regularization strength, features, etc.)\n",
    "  - model selection\n",
    "\n",
    "Below is a from-scratch logistic regression trained with log-loss, and then tuned by maximizing AMI on a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2726dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z: np.ndarray) -> np.ndarray:\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "\n",
    "def standardize_fit(X: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    mean = X.mean(axis=0)\n",
    "    std = X.std(axis=0)\n",
    "    std = np.where(std == 0.0, 1.0, std)\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "def standardize_transform(X: np.ndarray, mean: np.ndarray, std: np.ndarray) -> np.ndarray:\n",
    "    return (X - mean) / std\n",
    "\n",
    "\n",
    "def add_intercept(X: np.ndarray) -> np.ndarray:\n",
    "    return np.c_[np.ones((X.shape[0], 1)), X]\n",
    "\n",
    "\n",
    "def train_logistic_regression_gd(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    *,\n",
    "    lr: float = 0.2,\n",
    "    n_steps: int = 2000,\n",
    "    reg_strength: float = 0.0,\n",
    ") -> np.ndarray:\n",
    "    # L2-regularized logistic regression with gradient descent.\n",
    "    # reg_strength corresponds to λ in: loss + (λ/2)||w||^2 (excluding intercept).\n",
    "    X = np.asarray(X, dtype=np.float64)\n",
    "    y = np.asarray(y, dtype=np.float64)\n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "    w = np.zeros(n_features, dtype=np.float64)\n",
    "\n",
    "    for _ in range(n_steps):\n",
    "        p = sigmoid(X @ w)\n",
    "        grad = (X.T @ (p - y)) / n_samples\n",
    "\n",
    "        # L2 penalty (do not regularize intercept)\n",
    "        grad[1:] += reg_strength * w[1:]\n",
    "\n",
    "        w -= lr * grad\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "def predict_proba_logreg(X: np.ndarray, w: np.ndarray) -> np.ndarray:\n",
    "    return sigmoid(X @ w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ae40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=800,\n",
    "    n_features=2,\n",
    "    n_redundant=0,\n",
    "    n_informative=2,\n",
    "    n_clusters_per_class=1,\n",
    "    class_sep=1.6,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.35, random_state=0, stratify=y\n",
    ")\n",
    "\n",
    "mean, std = standardize_fit(X_train)\n",
    "X_train_std = standardize_transform(X_train, mean, std)\n",
    "X_val_std = standardize_transform(X_val, mean, std)\n",
    "\n",
    "X_train_ = add_intercept(X_train_std)\n",
    "X_val_ = add_intercept(X_val_std)\n",
    "\n",
    "reg_grid = np.array([0.0, 1e-4, 1e-3, 1e-2, 1e-1, 1.0])\n",
    "threshold_grid = np.linspace(0.05, 0.95, 37)\n",
    "\n",
    "ami_grid = np.zeros((reg_grid.size, threshold_grid.size))\n",
    "acc_grid = np.zeros((reg_grid.size, threshold_grid.size))\n",
    "\n",
    "for i, reg in enumerate(reg_grid):\n",
    "    w = train_logistic_regression_gd(\n",
    "        X_train_, y_train, lr=0.25, n_steps=2500, reg_strength=float(reg)\n",
    "    )\n",
    "    p_val = predict_proba_logreg(X_val_, w)\n",
    "\n",
    "    for j, thr in enumerate(threshold_grid):\n",
    "        y_hat = (p_val >= thr).astype(int)\n",
    "        ami_grid[i, j] = adjusted_mutual_info_score_np(y_val, y_hat)\n",
    "        acc_grid[i, j] = accuracy_score(y_val, y_hat)\n",
    "\n",
    "best_idx = np.unravel_index(np.argmax(ami_grid), ami_grid.shape)\n",
    "best_reg = float(reg_grid[best_idx[0]])\n",
    "best_thr = float(threshold_grid[best_idx[1]])\n",
    "best_ami = float(ami_grid[best_idx])\n",
    "\n",
    "(best_reg, best_thr, best_ami)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74673c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    data=go.Heatmap(\n",
    "        z=ami_grid,\n",
    "        x=threshold_grid,\n",
    "        y=[str(v) for v in reg_grid],\n",
    "        colorscale=\"Viridis\",\n",
    "        colorbar=dict(title=\"AMI\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Validation AMI for logistic regression (best: λ={best_reg}, thr={best_thr:.2f}, AMI={best_ami:.3f})\",\n",
    "    xaxis_title=\"threshold\",\n",
    "    yaxis_title=\"L2 regularization strength λ\",\n",
    "    height=480,\n",
    ")\n",
    "\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5531e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the AMI-optimal threshold to accuracy-optimal threshold for the best λ\n",
    "\n",
    "w_best = train_logistic_regression_gd(\n",
    "    X_train_, y_train, lr=0.25, n_steps=2500, reg_strength=best_reg\n",
    ")\n",
    "p_val = predict_proba_logreg(X_val_, w_best)\n",
    "\n",
    "ami_curve = np.array(\n",
    "    [\n",
    "        adjusted_mutual_info_score_np(y_val, (p_val >= t).astype(int))\n",
    "        for t in threshold_grid\n",
    "    ]\n",
    ")\n",
    "acc_curve = np.array([accuracy_score(y_val, (p_val >= t).astype(int)) for t in threshold_grid])\n",
    "\n",
    "thr_acc = float(threshold_grid[np.argmax(acc_curve)])\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1, specs=[[{\"secondary_y\": True}]])\n",
    "fig.add_trace(go.Scatter(x=threshold_grid, y=ami_curve, name=\"AMI\"), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=threshold_grid, y=acc_curve, name=\"Accuracy\"), secondary_y=True)\n",
    "\n",
    "fig.add_vline(x=best_thr, line_dash=\"dash\", line_color=\"black\")\n",
    "fig.add_vline(x=thr_acc, line_dash=\"dot\", line_color=\"gray\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Threshold tuning at λ={best_reg} (dash: best AMI, dot: best accuracy)\",\n",
    "    xaxis_title=\"threshold\",\n",
    "    height=430,\n",
    ")\n",
    "fig.update_yaxes(title_text=\"AMI\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"Accuracy\", secondary_y=True)\n",
    "\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e98a74c",
   "metadata": {},
   "source": [
    "## 11) Pros, cons, and when to use AMI\n",
    "\n",
    "**Pros**\n",
    "- **Permutation invariant** (cluster labels are arbitrary).\n",
    "- **Corrects for chance**: random labelings tend to score near 0.\n",
    "- Works when the two labelings have **different numbers of clusters**.\n",
    "- Symmetric: \\(\\mathrm{AMI}(U,V)=\\mathrm{AMI}(V,U)\\).\n",
    "\n",
    "**Cons / pitfalls**\n",
    "- Requires **two** labelings; not an intrinsic clustering quality measure (can’t tell if clusters are “good” in feature space).\n",
    "- Based only on the contingency table; ignores geometry (two clusterings with the same contingency are indistinguishable).\n",
    "- **Not differentiable** → not a natural training loss; typically used for evaluation or black-box tuning.\n",
    "- Computing EMI can be more expensive than simpler indices (though usually fine for moderate `n` and cluster counts).\n",
    "- Interpretation is less immediate than, say, accuracy; AMI is best used comparatively.\n",
    "\n",
    "**Good use cases**\n",
    "- Evaluating clustering against **ground truth classes** (external validation).\n",
    "- Measuring agreement between two clustering algorithms / runs (stability studies).\n",
    "- Hyperparameter selection for clustering when a reference labeling is available (e.g., choose `k` in KMeans by maximizing AMI).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbecd27f",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1) Modify the noise experiment to keep the cluster sizes fixed while permuting membership. How does AMI behave?\n",
    "2) Implement `normalized_mutual_info_score` from the same building blocks and compare it to AMI across different `k`.\n",
    "3) Use AMI to select `k` for a simple KMeans implementation on `make_blobs` (treat the true labels as reference).\n",
    "\n",
    "## References\n",
    "\n",
    "- scikit-learn API: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html\n",
    "- Vinh, Epps, Bailey (2010): *Information Theoretic Measures for Clusterings Comparison*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}