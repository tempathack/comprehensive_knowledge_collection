{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8456fdbb",
   "metadata": {},
   "source": [
    "# Rand Score (Rand Index)\n",
    "\n",
    "`rand_score` (the **Rand index**) measures how similar two clusterings / partitions are by looking at **all pairs** of samples.\n",
    "\n",
    "A good mental model:\n",
    "\n",
    "- Each clustering turns the dataset into a binary relation: for every pair `(i, j)`, are they in the **same cluster** or **different clusters**?\n",
    "- The Rand index is the **accuracy** of those pairwise decisions.\n",
    "\n",
    "## Quick import\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import rand_score\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "- Understand Rand index as **pairwise agreement** (TP/TN/FP/FN over pairs)\n",
    "- Implement `rand_score` from scratch in NumPy (efficiently, without an `O(n^2)` loop)\n",
    "- Visualize where the score comes from on a small example\n",
    "- See common pitfalls (why it can be **inflated** when there are many clusters)\n",
    "- Use Rand score to **select** a simple clustering hyperparameter\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- NumPy basics (`shape`, broadcasting, `np.unique`)\n",
    "- Combinatorics: number of pairs `\\(\binom{n}{2}\\)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482ee8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.metrics import rand_score\n",
    "from sklearn.metrics.cluster import pair_confusion_matrix\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = \"notebook\"\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f6997e",
   "metadata": {},
   "source": [
    "## 1) Definition: Rand index as pairwise accuracy\n",
    "\n",
    "Let there be `n` samples and two labelings:\n",
    "\n",
    "- ground truth (or reference) labels: \\(y\\)\n",
    "- predicted clustering labels: \\(\\hat{y}\\)\n",
    "\n",
    "For every unordered pair \\((i, j)\\) with \\(i < j\\), define two *same-cluster indicators*:\n",
    "\n",
    "$$\n",
    "S_y(i, j) = \\mathbb{1}[y_i = y_j],\n",
    "\\qquad\n",
    "S_{\\hat{y}}(i, j) = \\mathbb{1}[\\hat{y}_i = \\hat{y}_j]\n",
    "$$\n",
    "\n",
    "Now count pairs into the familiar 2×2 confusion matrix:\n",
    "\n",
    "- **TP**: same in `y` and same in `\\(\\hat{y}\\)`\n",
    "- **TN**: different in `y` and different in `\\(\\hat{y}\\)`\n",
    "- **FP**: different in `y` but same in `\\(\\hat{y}\\)` (a *merge* error)\n",
    "- **FN**: same in `y` but different in `\\(\\hat{y}\\)` (a *split* error)\n",
    "\n",
    "Formally:\n",
    "\n",
    "$$\n",
    "\begin{aligned}\n",
    "\\mathrm{TP} &= \\sum_{i<j} S_y(i,j)\\,S_{\\hat{y}}(i,j) \\\n",
    "\\mathrm{TN} &= \\sum_{i<j} (1-S_y(i,j))\\,(1-S_{\\hat{y}}(i,j)) \\\n",
    "\\mathrm{FP} &= \\sum_{i<j} (1-S_y(i,j))\\,S_{\\hat{y}}(i,j) \\\n",
    "\\mathrm{FN} &= \\sum_{i<j} S_y(i,j)\\,(1-S_{\\hat{y}}(i,j))\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "There are \\(\binom{n}{2}\\) total pairs, so the **Rand index** is:\n",
    "\n",
    "$$\n",
    "\\mathrm{RI}(y, \\hat{y}) = \f",
    "rac{\\mathrm{TP} + \\mathrm{TN}}{\binom{n}{2}}\n",
    "$$\n",
    "\n",
    "Note: scikit-learn's `pair_confusion_matrix` counts **ordered** pairs `(i, j)` with `i != j`,\n",
    "so its entries sum to `n(n-1)` and are exactly **2×** the `i<j` counts above.\n",
    "\n",
    "Key properties:\n",
    "\n",
    "- **Label permutation invariance**: only equality matters; relabeling clusters doesn't change the score.\n",
    "- **Symmetry**: \\(\\mathrm{RI}(y,\\hat{y}) = \\mathrm{RI}(\\hat{y},y)\\).\n",
    "- **Range**: \\([0,1]\\). For `n < 2`, scikit-learn returns `1.0` by convention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc035d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tiny toy example (small n so we can visualize all pairs)\n",
    "y_true = np.array([0, 0, 0, 1, 1, 2, 2, 2])\n",
    "y_pred = np.array([1, 1, 0, 0, 0, 2, 3, 3])\n",
    "\n",
    "print('y_true:', y_true)\n",
    "print('y_pred:', y_pred)\n",
    "\n",
    "print('rand_score (sklearn):', rand_score(y_true, y_pred))\n",
    "\n",
    "pcm_ord = pair_confusion_matrix(y_true, y_pred)\n",
    "print('pair_confusion_matrix (sklearn, ordered pairs):')\n",
    "print(pcm_ord)\n",
    "print('pair confusion on i<j (unordered) is pcm_ord // 2:')\n",
    "print(pcm_ord // 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca806e66",
   "metadata": {},
   "source": [
    "### Visual intuition: every clustering is a pairwise matrix\n",
    "\n",
    "For a labeling `y`, define an \\(n\times n\\) matrix:\n",
    "\n",
    "$$\n",
    "A_y[i, j] = \\mathbb{1}[y_i = y_j]\n",
    "$$\n",
    "\n",
    "- Blocks of 1s correspond to clusters.\n",
    "- Comparing \\(A_y\\) and \\(A_{\\hat{y}}\\) tells you which pairs are treated the same.\n",
    "\n",
    "Below we color each pair `(i, j)` as:\n",
    "\n",
    "- **TP**: same in both\n",
    "- **TN**: different in both\n",
    "- **FP**: different in true, same in pred\n",
    "- **FN**: same in true, different in pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38788ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_category_matrix(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError('y_true and y_pred must have the same shape')\n",
    "\n",
    "    same_true = y_true[:, None] == y_true[None, :]\n",
    "    same_pred = y_pred[:, None] == y_pred[None, :]\n",
    "\n",
    "    # 0=TN, 1=FP, 2=FN, 3=TP\n",
    "    cat = np.zeros_like(same_true, dtype=int)\n",
    "    cat[(~same_true) & same_pred] = 1\n",
    "    cat[same_true & (~same_pred)] = 2\n",
    "    cat[same_true & same_pred] = 3\n",
    "\n",
    "    np.fill_diagonal(cat, -1)  # diagonal isn't a pair\n",
    "    return cat\n",
    "\n",
    "\n",
    "cat = pair_category_matrix(y_true, y_pred)\n",
    "\n",
    "# Count only i<j pairs\n",
    "upper_mask = np.triu(np.ones_like(cat, dtype=bool), k=1)\n",
    "vals = cat[upper_mask]\n",
    "\n",
    "counts = {\n",
    "    \"TN (different/different)\": int((vals == 0).sum()),\n",
    "    \"FP (merge error)\": int((vals == 1).sum()),\n",
    "    \"FN (split error)\": int((vals == 2).sum()),\n",
    "    \"TP (same/same)\": int((vals == 3).sum()),\n",
    "}\n",
    "\n",
    "axis_labels = [f\"{i}<br>t={y_true[i]}, p={y_pred[i]}\" for i in range(len(y_true))]\n",
    "\n",
    "name_map = {\n",
    "    -1: \"diag\",\n",
    "    0: \"TN (different/different)\",\n",
    "    1: \"FP (merge error)\",\n",
    "    2: \"FN (split error)\",\n",
    "    3: \"TP (same/same)\",\n",
    "}\n",
    "cat_name = np.vectorize(name_map.get)(cat)\n",
    "\n",
    "c_diag = \"#ffffff\"\n",
    "c_tn = \"#d9d9d9\"\n",
    "c_fp = \"#ff7f0e\"\n",
    "c_fn = \"#1f77b4\"\n",
    "c_tp = \"#2ca02c\"\n",
    "\n",
    "# With zmin=-1, zmax=3, normalized boundaries between integers are:\n",
    "# -0.5 -> 0.125, 0.5 -> 0.375, 1.5 -> 0.625, 2.5 -> 0.875\n",
    "colorscale = [\n",
    "    [0.0, c_diag],\n",
    "    [0.1249, c_diag],\n",
    "    [0.125, c_tn],\n",
    "    [0.3749, c_tn],\n",
    "    [0.375, c_fp],\n",
    "    [0.6249, c_fp],\n",
    "    [0.625, c_fn],\n",
    "    [0.8749, c_fn],\n",
    "    [0.875, c_tp],\n",
    "    [1.0, c_tp],\n",
    "]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    column_widths=[0.72, 0.28],\n",
    "    subplot_titles=(\n",
    "        \"Pair categories (upper triangle is unique)\",\n",
    "        \"Pair counts (i<j)\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=cat,\n",
    "        x=axis_labels,\n",
    "        y=axis_labels,\n",
    "        zmin=-1,\n",
    "        zmax=3,\n",
    "        colorscale=colorscale,\n",
    "        showscale=False,\n",
    "        customdata=cat_name,\n",
    "        hovertemplate=\"%{y} vs %{x}<br>%{customdata}<extra></extra>\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=list(counts.keys()),\n",
    "        y=list(counts.values()),\n",
    "        text=list(counts.values()),\n",
    "        textposition=\"outside\",\n",
    "        marker_color=[c_tn, c_fp, c_fn, c_tp],\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Rand index works on pairs: agreements (TP/TN) vs disagreements (FP/FN)\",\n",
    "    xaxis=dict(tickangle=0),\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"sample index (with labels)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"sample index (with labels)\", row=1, col=1)\n",
    "fig.update_xaxes(tickangle=45, row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"count\", row=1, col=2)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26975ef8",
   "metadata": {},
   "source": [
    "## 2) Efficient computation (without looping over all pairs)\n",
    "\n",
    "A naive implementation checks all \\(\binom{n}{2}\\) pairs, which is `O(n^2)`.\n",
    "\n",
    "We can compute the same TP/FP/FN/TN counts using a **contingency table**.\n",
    "\n",
    "Let \\(n_{ij}\\) be the number of samples that are in:\n",
    "\n",
    "- true cluster \\(i\\), and\n",
    "- predicted cluster \\(j\\).\n",
    "\n",
    "This forms a matrix \\(N = [n_{ij}]\\).\n",
    "\n",
    "### Key combinatorial identity\n",
    "\n",
    "The number of unordered pairs inside a group of size \\(m\\) is:\n",
    "\n",
    "$$\n",
    "\binom{m}{2} = \f",
    "rac{m(m-1)}{2}\n",
    "$$\n",
    "\n",
    "### Counting pairs via the contingency table\n",
    "\n",
    "- Pairs that are together in **both** partitions:\n",
    "\n",
    "$$\n",
    "\\mathrm{TP} = \\sum_{i,j} \binom{n_{ij}}{2}\n",
    "$$\n",
    "\n",
    "- Pairs that are together in **true** labels:\n",
    "\n",
    "$$\n",
    "\\sum_i \binom{n_{i\\cdot}}{2}\n",
    "\\quad\text{where } n_{i\\cdot}=\\sum_j n_{ij}\n",
    "$$\n",
    "\n",
    "- Pairs that are together in **pred** labels:\n",
    "\n",
    "$$\n",
    "\\sum_j \binom{n_{\\cdot j}}{2}\n",
    "\\quad\text{where } n_{\\cdot j}=\\sum_i n_{ij}\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\mathrm{FN} = \\sum_i \binom{n_{i\\cdot}}{2} - \\mathrm{TP}\n",
    "\\qquad\n",
    "\\mathrm{FP} = \\sum_j \binom{n_{\\cdot j}}{2} - \\mathrm{TP}\n",
    "$$\n",
    "\n",
    "Finally:\n",
    "\n",
    "$$\n",
    "\\mathrm{TN} = \binom{n}{2} - (\\mathrm{TP}+\\mathrm{FP}+\\mathrm{FN})\n",
    "$$\n",
    "\n",
    "This gives an `O(n + k_y k_\\hat{y})` implementation (where `k` is number of clusters).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b875320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb2(x):\n",
    "    '''Unordered pairs: C(m, 2) = m(m-1)/2.'''\n",
    "    x = np.asarray(x, dtype=np.int64)\n",
    "    return (x * (x - 1)) // 2\n",
    "\n",
    "\n",
    "def pairs_ordered(x):\n",
    "    '''Ordered pairs with i!=j inside a group: m(m-1) = 2*C(m,2).'''\n",
    "    x = np.asarray(x, dtype=np.int64)\n",
    "    return x * (x - 1)\n",
    "\n",
    "\n",
    "def _labels_to_integers(labels):\n",
    "    labels = np.asarray(labels)\n",
    "    _, inv = np.unique(labels, return_inverse=True)\n",
    "    return inv\n",
    "\n",
    "\n",
    "def contingency_matrix_np(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError('y_true and y_pred must have the same shape')\n",
    "\n",
    "    true_inv = _labels_to_integers(y_true)\n",
    "    pred_inv = _labels_to_integers(y_pred)\n",
    "\n",
    "    n_true = int(true_inv.max(initial=-1)) + 1\n",
    "    n_pred = int(pred_inv.max(initial=-1)) + 1\n",
    "\n",
    "    cont = np.zeros((n_true, n_pred), dtype=np.int64)\n",
    "    np.add.at(cont, (true_inv, pred_inv), 1)\n",
    "    return cont\n",
    "\n",
    "\n",
    "def pair_confusion_matrix_np(y_true, y_pred):\n",
    "    '''Match sklearn.metrics.cluster.pair_confusion_matrix.\n",
    "\n",
    "    scikit-learn counts ordered pairs (i, j) with i != j, so totals sum to n*(n-1).\n",
    "    '''\n",
    "\n",
    "    y_true = np.asarray(y_true)\n",
    "    n = int(y_true.size)\n",
    "\n",
    "    if n < 2:\n",
    "        return np.array([[0, 0], [0, 0]], dtype=np.int64)\n",
    "\n",
    "    cont = contingency_matrix_np(y_true, y_pred)\n",
    "\n",
    "    tp = int(pairs_ordered(cont).sum())\n",
    "    same_true = int(pairs_ordered(cont.sum(axis=1)).sum())\n",
    "    same_pred = int(pairs_ordered(cont.sum(axis=0)).sum())\n",
    "\n",
    "    fn = same_true - tp\n",
    "    fp = same_pred - tp\n",
    "\n",
    "    total_pairs = n * (n - 1)\n",
    "    tn = total_pairs - tp - fp - fn\n",
    "\n",
    "    return np.array([[tn, fp], [fn, tp]], dtype=np.int64)\n",
    "\n",
    "\n",
    "def rand_score_np(y_true, y_pred):\n",
    "    '''Rand index over unordered pairs (i<j), matching sklearn.metrics.rand_score.'''\n",
    "\n",
    "    y_true = np.asarray(y_true)\n",
    "    n = int(y_true.size)\n",
    "    if n < 2:\n",
    "        return 1.0\n",
    "\n",
    "    cont = contingency_matrix_np(y_true, y_pred)\n",
    "\n",
    "    tp = float(comb2(cont).sum())\n",
    "    same_true = float(comb2(cont.sum(axis=1)).sum())\n",
    "    same_pred = float(comb2(cont.sum(axis=0)).sum())\n",
    "\n",
    "    fn = same_true - tp\n",
    "    fp = same_pred - tp\n",
    "\n",
    "    total_pairs = float(comb2(n))\n",
    "    tn = total_pairs - tp - fp - fn\n",
    "\n",
    "    return (tp + tn) / total_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5046147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks vs scikit-learn\n",
    "\n",
    "for n in [0, 1, 5, 50]:\n",
    "    y_true = rng.integers(0, 4, size=n)\n",
    "    y_pred = rng.integers(0, 6, size=n)\n",
    "\n",
    "    ri_np = rand_score_np(y_true, y_pred)\n",
    "    ri_sk = rand_score(y_true, y_pred)\n",
    "\n",
    "    pcm_np = pair_confusion_matrix_np(y_true, y_pred)\n",
    "    pcm_sk = pair_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print(f\"n={n:>2}  rand_score close? {np.isclose(ri_np, ri_sk)}  pair_confusion close? {np.all(pcm_np == pcm_sk)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee9c79f",
   "metadata": {},
   "source": [
    "## 3) Properties worth remembering\n",
    "\n",
    "### 3.1) Invariant to relabeling\n",
    "\n",
    "If you permute cluster IDs (e.g., swap labels `0` and `1`), the Rand score **does not change**.\n",
    "\n",
    "That’s essential for clustering evaluation: cluster IDs are arbitrary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dc36e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([0, 0, 1, 1, 2, 2])\n",
    "y_pred = np.array([10, 10, 11, 11, 12, 12])\n",
    "\n",
    "perm = {10: 12, 11: 10, 12: 11}\n",
    "y_pred_perm = np.vectorize(perm.get)(y_pred)\n",
    "\n",
    "print('original:', rand_score_np(y_true, y_pred))\n",
    "print('permuted:', rand_score_np(y_true, y_pred_perm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887f50cb",
   "metadata": {},
   "source": [
    "### 3.2) Extremes and trivial solutions\n",
    "\n",
    "Some degenerate clusterings can get surprisingly high Rand scores.\n",
    "\n",
    "Two extremes:\n",
    "\n",
    "- **All-in-one cluster**: predicts every pair is \"same\".\n",
    "- **All-singletons**: predicts every pair is \"different\".\n",
    "\n",
    "Because real datasets often have *far more different-cluster pairs than same-cluster pairs*, the \"all-singletons\" solution can score high even though it's useless.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebadbb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_in_one(n):\n",
    "    return np.zeros(n, dtype=int)\n",
    "\n",
    "def all_singletons(n):\n",
    "    return np.arange(n, dtype=int)\n",
    "\n",
    "n = 200\n",
    "# True labels: 4 balanced clusters\n",
    "k_true = 4\n",
    "sizes = np.full(k_true, n // k_true)\n",
    "y_true = np.repeat(np.arange(k_true), sizes)\n",
    "\n",
    "y_all1 = all_in_one(n)\n",
    "y_single = all_singletons(n)\n",
    "\n",
    "def summarize(y_pred, name):\n",
    "    pcm_ord = pair_confusion_matrix_np(y_true, y_pred)\n",
    "    ri = rand_score_np(y_true, y_pred)\n",
    "    return name, ri, pcm_ord\n",
    "\n",
    "for name, ri, pcm_ord in [\n",
    "    summarize(y_true, 'perfect'),\n",
    "    summarize(y_all1, 'all-in-one'),\n",
    "    summarize(y_single, 'all-singletons'),\n",
    "]:\n",
    "    tn, fp, fn, tp = pcm_ord.ravel()\n",
    "    print(f\"{name:>14}  RI={ri:.4f}  TP={tp:,}  TN={tn:,}  FP={fp:,}  FN={fn:,}  (ordered pairs)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0106faa9",
   "metadata": {},
   "source": [
    "## 4) Pitfall: Rand score is *not* adjusted for chance\n",
    "\n",
    "If you assign labels **at random**, the expected Rand score is not a constant baseline like 0.\n",
    "\n",
    "In fact, when the predicted clustering has many clusters, most pairs become \"different\" in the prediction, which creates lots of **TN agreements**.\n",
    "\n",
    "This is a big reason why practitioners often prefer:\n",
    "\n",
    "- **Adjusted Rand index** (`adjusted_rand_score` / ARI): corrected so random labelings score around 0.\n",
    "\n",
    "We'll simulate this effect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a416a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "k_true = 4\n",
    "sizes = np.full(k_true, n // k_true)\n",
    "y_true = np.repeat(np.arange(k_true), sizes)\n",
    "\n",
    "k_pred_values = [2, 4, 8, 16, 32, 64, 128]\n",
    "reps = 200\n",
    "\n",
    "rand_scores = {k: [] for k in k_pred_values}\n",
    "adj_rand_scores = {k: [] for k in k_pred_values}\n",
    "\n",
    "for k in k_pred_values:\n",
    "    for _ in range(reps):\n",
    "        y_pred = rng.integers(0, k, size=n)\n",
    "        rand_scores[k].append(rand_score_np(y_true, y_pred))\n",
    "        adj_rand_scores[k].append(adjusted_rand_score(y_true, y_pred))\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Rand score (unadjusted)\", \"Adjusted Rand score (ARI)\"),\n",
    ")\n",
    "\n",
    "for k in k_pred_values:\n",
    "    fig.add_trace(go.Box(y=rand_scores[k], name=f\"k={k}\", boxmean=True, showlegend=False), row=1, col=1)\n",
    "    fig.add_trace(go.Box(y=adj_rand_scores[k], name=f\"k={k}\", boxmean=True, showlegend=False), row=1, col=2)\n",
    "\n",
    "fig.update_layout(title=\"Random predictions: Rand score inflates as #clusters increases\")\n",
    "fig.update_yaxes(title_text=\"score\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"score\", row=1, col=2)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acfd82a",
   "metadata": {},
   "source": [
    "## 5) Using Rand score to select a simple clustering model (k-means example)\n",
    "\n",
    "Rand score is an **external** clustering metric: it requires reference labels.\n",
    "\n",
    "That makes it useful when:\n",
    "\n",
    "- you're benchmarking clustering algorithms on labeled datasets, or\n",
    "- you're tuning hyperparameters in a *semi-supervised evaluation* setting.\n",
    "\n",
    "Below we:\n",
    "\n",
    "1. create synthetic blobs with known cluster IDs\n",
    "2. run a small **NumPy k-means** implementation for different `k`\n",
    "3. pick `k` that maximizes Rand score\n",
    "\n",
    "Important: in real unsupervised tasks you typically don't have `y_true`, so you'd use internal metrics (e.g., silhouette) instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d140196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic 2D blobs\n",
    "centers = np.array([[-2.0, -2.0], [2.0, -2.0], [-2.0, 2.0], [2.0, 2.0]])\n",
    "cluster_std = 0.55\n",
    "n_per = 80\n",
    "\n",
    "X_list = []\n",
    "y_true = []\n",
    "for k, c in enumerate(centers):\n",
    "    Xk = rng.normal(loc=c, scale=cluster_std, size=(n_per, 2))\n",
    "    X_list.append(Xk)\n",
    "    y_true.append(np.full(n_per, k, dtype=int))\n",
    "\n",
    "X = np.vstack(X_list)\n",
    "y_true = np.concatenate(y_true)\n",
    "\n",
    "# Shuffle\n",
    "perm = rng.permutation(len(X))\n",
    "X = X[perm]\n",
    "y_true = y_true[perm]\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=X[:, 0],\n",
    "    y=X[:, 1],\n",
    "    color=y_true.astype(str),\n",
    "    title=\"Synthetic data (ground truth clusters)\",\n",
    "    labels={\"x\": \"x1\", \"y\": \"x2\", \"color\": \"true cluster\"},\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "def kmeans_np(X, k, *, n_init=10, max_iter=100, tol=1e-4, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(0)\n",
    "\n",
    "    n, d = X.shape\n",
    "    best_inertia = np.inf\n",
    "    best_centroids = None\n",
    "    best_labels = None\n",
    "\n",
    "    for _ in range(n_init):\n",
    "        centroids = X[rng.choice(n, size=k, replace=False)].copy()\n",
    "\n",
    "        for _ in range(max_iter):\n",
    "            # squared distances: (n, k)\n",
    "            d2 = ((X[:, None, :] - centroids[None, :, :]) ** 2).sum(axis=2)\n",
    "            labels = d2.argmin(axis=1)\n",
    "\n",
    "            new_centroids = np.empty_like(centroids)\n",
    "            for j in range(k):\n",
    "                mask = labels == j\n",
    "                if mask.any():\n",
    "                    new_centroids[j] = X[mask].mean(axis=0)\n",
    "                else:\n",
    "                    # handle empty clusters by re-seeding to a random point\n",
    "                    new_centroids[j] = X[rng.integers(0, n)]\n",
    "\n",
    "            shift = np.linalg.norm(new_centroids - centroids)\n",
    "            centroids = new_centroids\n",
    "\n",
    "            if shift < tol:\n",
    "                break\n",
    "\n",
    "        inertia = float(((X - centroids[labels]) ** 2).sum())\n",
    "        if inertia < best_inertia:\n",
    "            best_inertia = inertia\n",
    "            best_centroids = centroids\n",
    "            best_labels = labels\n",
    "\n",
    "    return best_centroids, best_labels, best_inertia\n",
    "\n",
    "\n",
    "k_values = list(range(2, 9))\n",
    "results = []\n",
    "\n",
    "for k in k_values:\n",
    "    centroids, labels, inertia = kmeans_np(X, k, n_init=15, max_iter=100, tol=1e-4, rng=rng)\n",
    "    ri = rand_score_np(y_true, labels)\n",
    "    ari = adjusted_rand_score(y_true, labels)\n",
    "    results.append((k, ri, ari, inertia))\n",
    "\n",
    "results = np.array(results, dtype=float)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Rand score vs k\", \"ARI vs k\"))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=results[:, 0], y=results[:, 1], mode='lines+markers', name='RI'), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=results[:, 0], y=results[:, 2], mode='lines+markers', name='ARI'), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"k\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"k\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"score\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"score\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(title=\"Selecting k with external labels (demo)\")\n",
    "fig.show()\n",
    "\n",
    "best_k = int(results[results[:, 1].argmax(), 0])\n",
    "print('best k by Rand score:', best_k)\n",
    "\n",
    "centroids, labels_best, _ = kmeans_np(X, best_k, n_init=25, rng=rng)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Ground truth\", f\"k-means prediction (k={best_k})\"))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=X[:, 0], y=X[:, 1], mode='markers', marker=dict(color=y_true, colorscale='Viridis', size=6), showlegend=False),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=X[:, 0], y=X[:, 1], mode='markers', marker=dict(color=labels_best, colorscale='Viridis', size=6), showlegend=False),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"x1\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"x1\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"x2\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"x2\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(title=\"Clustering visualization (labels are arbitrary, Rand index is invariant)\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a39a1b6",
   "metadata": {},
   "source": [
    "## 6) Pros, cons, and when to use it\n",
    "\n",
    "### Pros\n",
    "\n",
    "- **Permutation invariant**: cluster IDs don't matter.\n",
    "- **Interpretable**: literally the fraction of pairwise agreements.\n",
    "- **Works for any number of clusters** and doesn't require distances/geometry.\n",
    "- **Fast to compute** via contingency counts (no need to enumerate all pairs).\n",
    "\n",
    "### Cons / pitfalls\n",
    "\n",
    "- **Not adjusted for chance**: random clusterings can get high RI, especially with many clusters.\n",
    "- Often dominated by **TN** (different/different) pairs, which can hide meaningful errors.\n",
    "- Can reward **over-segmentation** (too many clusters) in some settings.\n",
    "- **Not differentiable**: not suitable as a gradient-based training loss.\n",
    "\n",
    "### Good use cases\n",
    "\n",
    "- External evaluation of clustering when you have reference labels (benchmarks, ablations).\n",
    "- Comparing two clusterings of the same dataset when you care about pairwise co-membership.\n",
    "\n",
    "If you need a chance-corrected baseline, prefer **ARI** (`adjusted_rand_score`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dd9822",
   "metadata": {},
   "source": [
    "## 7) Practical usage (scikit-learn)\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import rand_score, adjusted_rand_score\n",
    "\n",
    "ri  = rand_score(y_true, y_pred)\n",
    "ari = adjusted_rand_score(y_true, y_pred)\n",
    "```\n",
    "\n",
    "`rand_score` is a thin wrapper around the pair confusion matrix.\n",
    "If you need debugging insight, inspect:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics.cluster import pair_confusion_matrix\n",
    "\n",
    "pair_confusion_matrix(y_true, y_pred)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e93b3",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Create a clustering that **splits** one true cluster into two; verify how TP/FN change.\n",
    "2. Create a clustering that **merges** two true clusters; verify how TN/FP change.\n",
    "3. Simulate random labelings with different `k` and estimate the expected Rand score.\n",
    "4. Implement `adjusted_rand_score` (ARI) from the contingency table and compare to scikit-learn.\n",
    "\n",
    "## References\n",
    "\n",
    "- W. M. Rand (1971). *Objective criteria for the evaluation of clustering methods*. Journal of the American Statistical Association.\n",
    "- L. Hubert, P. Arabie (1985). *Comparing partitions*. Journal of Classification. (Adjusted Rand index)\n",
    "- scikit-learn docs: https://scikit-learn.org/stable/modules/clustering.html#rand-index\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}