{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8536a16",
   "metadata": {},
   "source": [
    "# Root Mean Squared Error (RMSE) — Regression Metric (From Scratch)\n",
    "\n",
    "RMSE measures the *typical* size of prediction errors in **the same units as the target**. It is the square-root of mean squared error (MSE), so it **penalizes large errors** more than MAE.\n",
    "\n",
    "**Goals**\n",
    "- Build intuition with small numeric examples + Plotly visuals\n",
    "- Derive the formula (and gradients) with clear notation\n",
    "- Implement RMSE in NumPy (from scratch) and validate vs scikit-learn\n",
    "- Use RMSE/MSE to fit a simple linear regression with gradient descent\n",
    "- Summarize pros/cons, good use cases, and common pitfalls\n",
    "\n",
    "## Quick import\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "```\n",
    "\n",
    "Equivalent: `mean_squared_error(..., squared=False)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f8ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "rng = np.random.default_rng(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b16d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import sklearn\n",
    "\n",
    "print(\"numpy  :\", np.__version__)\n",
    "print(\"pandas :\", pd.__version__)\n",
    "print(\"sklearn:\", sklearn.__version__)\n",
    "print(\"plotly :\", plotly.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3377a889",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Basic regression setup: true targets $y$ and predictions $\\hat y$\n",
    "- Vector norms and means\n",
    "- (Optional) Basic derivatives for the gradient section\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e750bfd2",
   "metadata": {},
   "source": [
    "## 1) Definition and notation\n",
    "\n",
    "Let:\n",
    "\n",
    "- $y \\in \\mathbb{R}^n$ be the true targets\n",
    "- $\\hat y \\in \\mathbb{R}^n$ be the predictions\n",
    "- residuals (signed errors) $r_i = \\hat y_i - y_i$\n",
    "\n",
    "The **mean squared error (MSE)** is:\n",
    "\n",
    "$$\n",
    "\\mathrm{MSE}(y, \\hat y) = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat y_i)^2 = \\frac{1}{n}\\sum_{i=1}^n r_i^2\n",
    "$$\n",
    "\n",
    "The **root mean squared error (RMSE)** is:\n",
    "\n",
    "$$\n",
    "\\mathrm{RMSE}(y, \\hat y) = \\sqrt{\\mathrm{MSE}(y, \\hat y)}\n",
    "= \\sqrt{\\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat y_i)^2}\n",
    "$$\n",
    "\n",
    "### Vector form\n",
    "\n",
    "With residual vector $r = \\hat y - y$:\n",
    "\n",
    "$$\n",
    "\\mathrm{RMSE}(y, \\hat y) = \\frac{\\lVert r \\rVert_2}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "**Key interpretation:** RMSE is a scaled Euclidean distance between the prediction vector and the target vector.\n",
    "\n",
    "### Weighted RMSE\n",
    "\n",
    "For non-negative sample weights $w_i$:\n",
    "\n",
    "$$\n",
    "\\mathrm{RMSE}_w(y, \\hat y; w) = \\sqrt{\\frac{\\sum_{i=1}^n w_i (y_i - \\hat y_i)^2}{\\sum_{i=1}^n w_i}}\n",
    "$$\n",
    "\n",
    "### Multioutput targets\n",
    "\n",
    "For $y, \\hat y \\in \\mathbb{R}^{n \\times d}$, compute per-output RMSE:\n",
    "\n",
    "$$\n",
    "\\mathrm{RMSE}_j = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n (y_{ij} - \\hat y_{ij})^2}, \\quad j=1,\\dots,d\n",
    "$$\n",
    "\n",
    "and then aggregate (uniform average by default, or a weighted average over outputs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ceab4",
   "metadata": {},
   "source": [
    "## 2) Intuition: “average error size” with extra penalty for big misses\n",
    "\n",
    "If you make one error twice as large, its squared contribution becomes **4×** larger.\n",
    "\n",
    "That means RMSE:\n",
    "\n",
    "- has the same units as $y$ (unlike MSE)\n",
    "- behaves like a “typical” error magnitude\n",
    "- is **more sensitive to outliers** than MAE because of the square\n",
    "\n",
    "A common statistical view: if residuals are i.i.d. Gaussian with constant variance, minimizing MSE/RMSE is equivalent to maximum likelihood.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a34679",
   "metadata": {},
   "source": [
    "## 3) A tiny worked example\n",
    "\n",
    "We’ll compute RMSE step-by-step on a small set of points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871244d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([3.0, -0.5, 2.0, 7.0, 4.2])\n",
    "y_pred = np.array([2.5, 0.0, 2.1, 7.8, 1.9])\n",
    "\n",
    "residual = y_pred - y_true\n",
    "abs_error = np.abs(residual)\n",
    "sq_error = residual**2\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"residual (y_pred - y_true)\": residual,\n",
    "        \"|residual|\": abs_error,\n",
    "        \"residual^2\": sq_error,\n",
    "    }\n",
    ")\n",
    "\n",
    "mse = float(np.mean(sq_error))\n",
    "rmse = float(np.sqrt(mse))\n",
    "\n",
    "rmse_sklearn = root_mean_squared_error(y_true, y_pred)\n",
    "\n",
    "df, mse, rmse, rmse_sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe1aa34",
   "metadata": {},
   "source": [
    "## 4) How squaring changes “importance” across samples\n",
    "\n",
    "MAE gives each sample weight proportional to $|r_i|$.\n",
    "\n",
    "MSE/RMSE gives each sample weight proportional to $r_i^2$, so large residuals dominate more.\n",
    "\n",
    "Below we plot the *fraction of total error* each sample contributes under MAE vs MSE/RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c2018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(y_true))\n",
    "\n",
    "mae_weights = abs_error / abs_error.sum()\n",
    "mse_weights = sq_error / sq_error.sum()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=idx, y=mae_weights, name=\"MAE weight  (|r| / sum|r|)\"))\n",
    "fig.add_trace(go.Bar(x=idx, y=mse_weights, name=\"MSE/RMSE weight (r^2 / sum r^2)\"))\n",
    "fig.update_layout(\n",
    "    barmode=\"group\",\n",
    "    title=\"Per-sample influence under MAE vs RMSE\",\n",
    "    xaxis_title=\"sample index\",\n",
    "    yaxis_title=\"fraction of total error\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0598b2",
   "metadata": {},
   "source": [
    "## 5) Outlier sensitivity: RMSE vs MAE\n",
    "\n",
    "We’ll keep all residuals fixed except one, and sweep that one residual from 0 to a large value.\n",
    "\n",
    "Because RMSE squares residuals, it grows faster than MAE as the outlier grows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "base_residuals = rng.normal(0.0, 1.0, size=n)\n",
    "base_residuals[0] = 0.0\n",
    "\n",
    "outlier_values = np.linspace(0, 15, 200)\n",
    "rmse_vals = []\n",
    "mae_vals = []\n",
    "\n",
    "for v in outlier_values:\n",
    "    r = base_residuals.copy()\n",
    "    r[0] = v\n",
    "    rmse_vals.append(float(np.sqrt(np.mean(r**2))))\n",
    "    mae_vals.append(float(np.mean(np.abs(r))))\n",
    "\n",
    "df_sweep = pd.DataFrame({\"outlier |r|\": outlier_values, \"RMSE\": rmse_vals, \"MAE\": mae_vals})\n",
    "\n",
    "fig = px.line(\n",
    "    df_sweep,\n",
    "    x=\"outlier |r|\",\n",
    "    y=[\"RMSE\", \"MAE\"],\n",
    "    title=\"Single outlier sweep: RMSE grows faster than MAE\",\n",
    "    labels={\"value\": \"metric value (same units as y)\", \"variable\": \"metric\"},\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47c1b55",
   "metadata": {},
   "source": [
    "## 6) Key property: constant predictor → mean\n",
    "\n",
    "If your model can only predict a constant $c$ for every sample ($\\hat y_i = c$), then:\n",
    "\n",
    "$$\n",
    "\\mathrm{RMSE}(c) = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n (y_i - c)^2}\n",
    "$$\n",
    "\n",
    "Because the square-root is monotonic, the minimizer of RMSE$(c)$ is the same as the minimizer of:\n",
    "\n",
    "$$\n",
    "\\mathrm{MSE}(c) = \\frac{1}{n}\\sum_{i=1}^n (y_i - c)^2\n",
    "$$\n",
    "\n",
    "Differentiate and set to zero:\n",
    "\n",
    "$$\n",
    "\\frac{d}{dc}\\mathrm{MSE}(c) = -\\frac{2}{n}\\sum_{i=1}^n (y_i - c) = 0\n",
    "\\quad\\Rightarrow\\quad\n",
    "c^* = \\bar y\n",
    "$$\n",
    "\n",
    "This is one reason RMSE is sensitive to outliers: the mean shifts.\n",
    "\n",
    "In contrast, MAE is minimized by the **median** (more robust to outliers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5540f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_const = rng.normal(0.0, 1.0, size=60)\n",
    "y_const[0] = 8.0  # add a clear outlier\n",
    "\n",
    "c_grid = np.linspace(y_const.min() - 1, y_const.max() + 1, 400)\n",
    "rmse_curve = np.sqrt(np.mean((y_const[None, :] - c_grid[:, None]) ** 2, axis=1))\n",
    "mae_curve = np.mean(np.abs(y_const[None, :] - c_grid[:, None]), axis=1)\n",
    "\n",
    "c_mean = float(np.mean(y_const))\n",
    "c_median = float(np.median(y_const))\n",
    "y_top = float(max(rmse_curve.max(), mae_curve.max()))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=c_grid, y=rmse_curve, mode=\"lines\", name=\"RMSE(c)\"))\n",
    "fig.add_trace(go.Scatter(x=c_grid, y=mae_curve, mode=\"lines\", name=\"MAE(c)\"))\n",
    "fig.add_vline(x=c_mean, line_dash=\"dash\", line_color=\"#1f77b4\")\n",
    "fig.add_vline(x=c_median, line_dash=\"dash\", line_color=\"#ff7f0e\")\n",
    "fig.add_annotation(x=c_mean, y=y_top, text=\"mean\", showarrow=False, yshift=10, font=dict(color=\"#1f77b4\"))\n",
    "fig.add_annotation(\n",
    "    x=c_median,\n",
    "    y=y_top,\n",
    "    text=\"median\",\n",
    "    showarrow=False,\n",
    "    yshift=10,\n",
    "    font=dict(color=\"#ff7f0e\"),\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Constant predictor: RMSE is minimized by the mean (MAE by the median)\",\n",
    "    xaxis_title=\"constant prediction c\",\n",
    "    yaxis_title=\"metric value\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee2903f",
   "metadata": {},
   "source": [
    "## 7) NumPy implementation (from scratch)\n",
    "\n",
    "We’ll implement RMSE in a way that matches scikit-learn’s signature:\n",
    "\n",
    "- supports 1D or 2D targets (`n_outputs`)\n",
    "- optional `sample_weight`\n",
    "- `multioutput`: return per-output values (`raw_values`) or average (`uniform_average`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bc8d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _as_2d(y):\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if y.ndim == 1:\n",
    "        return y.reshape(-1, 1)\n",
    "    if y.ndim == 2:\n",
    "        return y\n",
    "    raise ValueError(\"y must be 1D or 2D (n_samples,) or (n_samples, n_outputs).\")\n",
    "\n",
    "\n",
    "def mse_np(y_true, y_pred, *, sample_weight=None, multioutput=\"uniform_average\"):\n",
    "    \"\"\"Mean squared error with scikit-learn-like multioutput handling.\"\"\"\n",
    "    y_true_2d = _as_2d(y_true)\n",
    "    y_pred_2d = _as_2d(y_pred)\n",
    "\n",
    "    if y_true_2d.shape != y_pred_2d.shape:\n",
    "        raise ValueError(f\"shape mismatch: y_true{y_true_2d.shape} vs y_pred{y_pred_2d.shape}\")\n",
    "\n",
    "    residual = y_pred_2d - y_true_2d\n",
    "\n",
    "    if sample_weight is None:\n",
    "        mse_per_output = np.mean(residual**2, axis=0)\n",
    "    else:\n",
    "        w = np.asarray(sample_weight, dtype=float)\n",
    "        if w.ndim != 1:\n",
    "            raise ValueError(\"sample_weight must be 1D of shape (n_samples,).\")\n",
    "        if w.shape[0] != y_true_2d.shape[0]:\n",
    "            raise ValueError(\"sample_weight length must match n_samples.\")\n",
    "        w = w.reshape(-1, 1)\n",
    "        mse_per_output = np.sum(w * residual**2, axis=0) / np.sum(w, axis=0)\n",
    "\n",
    "    if isinstance(multioutput, str):\n",
    "        if multioutput == \"raw_values\":\n",
    "            return mse_per_output\n",
    "        if multioutput == \"uniform_average\":\n",
    "            return float(np.mean(mse_per_output))\n",
    "        raise ValueError(\n",
    "            \"multioutput must be 'raw_values', 'uniform_average', or array-like of shape (n_outputs,).\"\n",
    "        )\n",
    "\n",
    "    weights = np.asarray(multioutput, dtype=float)\n",
    "    if weights.shape != (mse_per_output.shape[0],):\n",
    "        raise ValueError(\"multioutput weights must match n_outputs.\")\n",
    "    return float(np.average(mse_per_output, weights=weights))\n",
    "\n",
    "\n",
    "def rmse_np(y_true, y_pred, *, sample_weight=None, multioutput=\"uniform_average\"):\n",
    "    \"\"\"Root mean squared error (RMSE): sqrt(mean((y_pred - y_true)^2)).\"\"\"\n",
    "    mse_per_output = mse_np(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        sample_weight=sample_weight,\n",
    "        multioutput=\"raw_values\",\n",
    "    )\n",
    "    rmse_per_output = np.sqrt(mse_per_output)\n",
    "\n",
    "    if isinstance(multioutput, str):\n",
    "        if multioutput == \"raw_values\":\n",
    "            return rmse_per_output\n",
    "        if multioutput == \"uniform_average\":\n",
    "            return float(np.mean(rmse_per_output))\n",
    "        raise ValueError(\n",
    "            \"multioutput must be 'raw_values', 'uniform_average', or array-like of shape (n_outputs,).\"\n",
    "        )\n",
    "\n",
    "    weights = np.asarray(multioutput, dtype=float)\n",
    "    if weights.shape != (rmse_per_output.shape[0],):\n",
    "        raise ValueError(\"multioutput weights must match n_outputs.\")\n",
    "    return float(np.average(rmse_per_output, weights=weights))\n",
    "\n",
    "\n",
    "y_true_rand = rng.normal(size=(50, 3))\n",
    "y_pred_rand = y_true_rand + rng.normal(scale=0.5, size=y_true_rand.shape)\n",
    "\n",
    "print(\"ours raw:\", rmse_np(y_true_rand, y_pred_rand, multioutput=\"raw_values\"))\n",
    "print(\"sk   raw:\", root_mean_squared_error(y_true_rand, y_pred_rand, multioutput=\"raw_values\"))\n",
    "\n",
    "sample_w = rng.uniform(0.5, 2.0, size=y_true_rand.shape[0])\n",
    "print(\"ours weighted:\", rmse_np(y_true_rand, y_pred_rand, sample_weight=sample_w))\n",
    "print(\"sk   weighted:\", root_mean_squared_error(y_true_rand, y_pred_rand, sample_weight=sample_w))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b065110",
   "metadata": {},
   "source": [
    "## 8) RMSE as an objective: gradients and optimization\n",
    "\n",
    "RMSE is often reported to humans because it has the same units as $y$.\n",
    "\n",
    "When training with gradient-based methods, people often minimize **MSE** instead:\n",
    "\n",
    "- RMSE and MSE have the **same minimizer** (square-root is monotonic)\n",
    "- the MSE gradient is simpler and avoids dividing by RMSE\n",
    "\n",
    "Still, we can differentiate RMSE and optimize it directly; the next section shows both.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9886fa",
   "metadata": {},
   "source": [
    "### 8.1 Gradients\n",
    "\n",
    "Let $r_i = \\hat y_i - y_i$ and\n",
    "\n",
    "$$\n",
    "\\mathrm{MSE} = \\frac{1}{n}\\sum_{i=1}^n r_i^2,\n",
    "\\qquad\n",
    "\\mathrm{RMSE} = \\sqrt{\\mathrm{MSE}}\n",
    "$$\n",
    "\n",
    "Gradient w.r.t. predictions:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial\\,\\mathrm{MSE}}{\\partial \\hat y_i} = \\frac{2}{n} r_i\n",
    "$$\n",
    "\n",
    "If RMSE $> 0$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial\\,\\mathrm{RMSE}}{\\partial \\hat y_i}\n",
    "= \\frac{1}{2\\sqrt{\\mathrm{MSE}}}\\cdot \\frac{\\partial\\,\\mathrm{MSE}}{\\partial \\hat y_i}\n",
    "= \\frac{r_i}{n\\,\\mathrm{RMSE}}\n",
    "$$\n",
    "\n",
    "So (for RMSE $> 0$) the gradients point in the same direction; they differ by a scalar factor $\\frac{1}{2\\,\\mathrm{RMSE}}$.\n",
    "\n",
    "For a linear model $\\hat y_i = w x_i + b$, the parameter gradients are:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial\\,\\mathrm{MSE}}{\\partial w} = \\frac{2}{n}\\sum_{i=1}^n r_i x_i,\n",
    "\\qquad\n",
    "\\frac{\\partial\\,\\mathrm{MSE}}{\\partial b} = \\frac{2}{n}\\sum_{i=1}^n r_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial\\,\\mathrm{RMSE}}{\\partial w} = \\frac{1}{n\\,\\mathrm{RMSE}}\\sum_{i=1}^n r_i x_i,\n",
    "\\qquad\n",
    "\\frac{\\partial\\,\\mathrm{RMSE}}{\\partial b} = \\frac{1}{n\\,\\mathrm{RMSE}}\\sum_{i=1}^n r_i\n",
    "$$\n",
    "\n",
    "(At a perfect fit where RMSE $= 0$, the derivative is undefined; in code we add a tiny $\\varepsilon$.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5259187",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "x = rng.uniform(-3, 3, size=n)\n",
    "true_w, true_b = 1.8, -0.7\n",
    "y = true_w * x + true_b + rng.normal(0, 0.8, size=n)\n",
    "\n",
    "perm = rng.permutation(n)\n",
    "train_size = int(0.8 * n)\n",
    "train_idx = perm[:train_size]\n",
    "test_idx = perm[train_size:]\n",
    "\n",
    "x_tr, y_tr = x[train_idx], y[train_idx]\n",
    "x_te, y_te = x[test_idx], y[test_idx]\n",
    "\n",
    "x_tr.shape, x_te.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81681630",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(\n",
    "    {\n",
    "        \"x\": np.concatenate([x_tr, x_te]),\n",
    "        \"y\": np.concatenate([y_tr, y_te]),\n",
    "        \"split\": np.array([\"train\"] * len(x_tr) + [\"test\"] * len(x_te)),\n",
    "    }\n",
    ")\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_data,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=\"split\",\n",
    "    title=\"Synthetic 1D regression data\",\n",
    "    labels={\"x\": \"feature x\", \"y\": \"target y\"},\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee46e171",
   "metadata": {},
   "source": [
    "## 9) Using RMSE/MSE to fit linear regression (from scratch)\n",
    "\n",
    "Model (one feature):\n",
    "\n",
    "$$\n",
    "\\hat y = w x + b\n",
    "$$\n",
    "\n",
    "We’ll fit $(w, b)$ with gradient descent using either:\n",
    "\n",
    "- objective = MSE\n",
    "- objective = RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21b93a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_linear(x, w, b):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    return w * x + b\n",
    "\n",
    "\n",
    "def fit_linear_gd(x, y, *, lr=0.05, steps=200, objective=\"mse\"):\n",
    "    \"\"\"Fit y ≈ w x + b with gradient descent (objective: 'mse' or 'rmse').\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "\n",
    "    w = 0.0\n",
    "    b = 0.0\n",
    "    n = x.shape[0]\n",
    "\n",
    "    hist = {\"mse\": [], \"rmse\": [], \"w\": [], \"b\": []}\n",
    "\n",
    "    for _ in range(steps):\n",
    "        y_hat = predict_linear(x, w, b)\n",
    "        r = y_hat - y\n",
    "\n",
    "        mse = float(np.mean(r**2))\n",
    "        rmse = float(np.sqrt(mse))\n",
    "\n",
    "        if objective == \"mse\":\n",
    "            grad_w = (2.0 / n) * float(np.dot(r, x))\n",
    "            grad_b = (2.0 / n) * float(np.sum(r))\n",
    "        elif objective == \"rmse\":\n",
    "            denom = max(rmse, 1e-12)\n",
    "            grad_w = (1.0 / (n * denom)) * float(np.dot(r, x))\n",
    "            grad_b = (1.0 / (n * denom)) * float(np.sum(r))\n",
    "        else:\n",
    "            raise ValueError(\"objective must be 'mse' or 'rmse'.\")\n",
    "\n",
    "        w -= lr * grad_w\n",
    "        b -= lr * grad_b\n",
    "\n",
    "        hist[\"mse\"].append(mse)\n",
    "        hist[\"rmse\"].append(rmse)\n",
    "        hist[\"w\"].append(w)\n",
    "        hist[\"b\"].append(b)\n",
    "\n",
    "    return w, b, hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04bf875",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_mse, b_mse, hist_mse = fit_linear_gd(x_tr, y_tr, lr=0.05, steps=200, objective=\"mse\")\n",
    "w_rmse, b_rmse, hist_rmse = fit_linear_gd(x_tr, y_tr, lr=0.05, steps=200, objective=\"rmse\")\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    {\n",
    "        \"objective\": [\"mse\", \"rmse\"],\n",
    "        \"w\": [w_mse, w_rmse],\n",
    "        \"b\": [b_mse, b_rmse],\n",
    "        \"train_rmse\": [\n",
    "            rmse_np(y_tr, predict_linear(x_tr, w_mse, b_mse)),\n",
    "            rmse_np(y_tr, predict_linear(x_tr, w_rmse, b_rmse)),\n",
    "        ],\n",
    "        \"test_rmse\": [\n",
    "            rmse_np(y_te, predict_linear(x_te, w_mse, b_mse)),\n",
    "            rmse_np(y_te, predict_linear(x_te, w_rmse, b_rmse)),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1412a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist = pd.DataFrame(\n",
    "    {\n",
    "        \"iteration\": np.arange(1, len(hist_mse[\"rmse\"]) + 1),\n",
    "        \"rmse (objective=mse)\": hist_mse[\"rmse\"],\n",
    "        \"rmse (objective=rmse)\": hist_rmse[\"rmse\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "fig = px.line(\n",
    "    df_hist,\n",
    "    x=\"iteration\",\n",
    "    y=[\"rmse (objective=mse)\", \"rmse (objective=rmse)\"],\n",
    "    title=\"Training curve (RMSE on the training set)\",\n",
    "    labels={\"value\": \"RMSE\", \"variable\": \"training objective\"},\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d80f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_line = np.linspace(x.min(), x.max(), 200)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x_tr, y=y_tr, mode=\"markers\", name=\"train\"))\n",
    "fig.add_trace(go.Scatter(x=x_te, y=y_te, mode=\"markers\", name=\"test\"))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_line,\n",
    "        y=predict_linear(x_line, w_mse, b_mse),\n",
    "        mode=\"lines\",\n",
    "        name=\"fit (objective=mse)\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_line,\n",
    "        y=predict_linear(x_line, w_rmse, b_rmse),\n",
    "        mode=\"lines\",\n",
    "        name=\"fit (objective=rmse)\",\n",
    "        line=dict(dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Linear regression fits (same optimum, different objective scaling)\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"y\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532f626",
   "metadata": {},
   "source": [
    "## 10) Sanity check: closed-form least squares and scikit-learn\n",
    "\n",
    "For linear regression with squared error, the optimum has a closed-form (least squares) solution.\n",
    "\n",
    "We’ll compare:\n",
    "\n",
    "- gradient descent (above)\n",
    "- NumPy least squares (`np.linalg.lstsq`)\n",
    "- `sklearn.linear_model.LinearRegression`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b68428",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.column_stack([x_tr, np.ones_like(x_tr)])\n",
    "w_ls, b_ls = np.linalg.lstsq(A, y_tr, rcond=None)[0]\n",
    "\n",
    "rmse_train_ls = rmse_np(y_tr, predict_linear(x_tr, w_ls, b_ls))\n",
    "rmse_test_ls = rmse_np(y_te, predict_linear(x_te, w_ls, b_ls))\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"method\": [\"least_squares\"],\n",
    "        \"w\": [w_ls],\n",
    "        \"b\": [b_ls],\n",
    "        \"train_rmse\": [rmse_train_ls],\n",
    "        \"test_rmse\": [rmse_test_ls],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632a1602",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_model = LinearRegression().fit(x_tr.reshape(-1, 1), y_tr)\n",
    "w_sk = float(sk_model.coef_[0])\n",
    "b_sk = float(sk_model.intercept_)\n",
    "\n",
    "rmse_train_sk = root_mean_squared_error(y_tr, sk_model.predict(x_tr.reshape(-1, 1)))\n",
    "rmse_test_sk = root_mean_squared_error(y_te, sk_model.predict(x_te.reshape(-1, 1)))\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"method\": [\"sklearn\"],\n",
    "        \"w\": [w_sk],\n",
    "        \"b\": [b_sk],\n",
    "        \"train_rmse\": [rmse_train_sk],\n",
    "        \"test_rmse\": [rmse_test_sk],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092bb8e4",
   "metadata": {},
   "source": [
    "## 11) Practical usage notes (scikit-learn)\n",
    "\n",
    "- For reporting: `root_mean_squared_error(y_true, y_pred)`.\n",
    "- For cross-validation: scorers are usually **higher-is-better**, so scikit-learn uses `\"neg_root_mean_squared_error\"`.\n",
    "- For multi-output regression: set `multioutput=\"raw_values\"` to get one RMSE per output.\n",
    "- For weighted datasets: pass `sample_weight`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a7920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_2 = np.column_stack([y_true, 2 * y_true])\n",
    "y_pred_2 = np.column_stack([y_pred, 2 * y_pred + 0.2])\n",
    "\n",
    "print(\"ours  raw:\", rmse_np(y_true_2, y_pred_2, multioutput=\"raw_values\"))\n",
    "print(\"sk    raw:\", root_mean_squared_error(y_true_2, y_pred_2, multioutput=\"raw_values\"))\n",
    "\n",
    "output_weights = np.array([0.25, 0.75])\n",
    "print(\"ours weighted outputs:\", rmse_np(y_true_2, y_pred_2, multioutput=output_weights))\n",
    "print(\"sk   weighted outputs:\", root_mean_squared_error(y_true_2, y_pred_2, multioutput=output_weights))\n",
    "\n",
    "sample_w = np.linspace(1.0, 2.0, len(y_true))\n",
    "print(\"ours sample_weight:\", rmse_np(y_true, y_pred, sample_weight=sample_w))\n",
    "print(\"sk   sample_weight:\", root_mean_squared_error(y_true, y_pred, sample_weight=sample_w))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b46355e",
   "metadata": {},
   "source": [
    "## 12) Pros, cons, and when to use RMSE\n",
    "\n",
    "**Pros**\n",
    "\n",
    "- Same units as the target → easy to interpret\n",
    "- Differentiable for RMSE $> 0$ (unlike MAE at 0) and convex for linear models\n",
    "- Strongly penalizes large errors → good when big misses are especially costly\n",
    "- Closely tied to least squares / Gaussian noise assumptions\n",
    "\n",
    "**Cons**\n",
    "\n",
    "- Sensitive to outliers and heavy-tailed noise\n",
    "- Scale-dependent: RMSE values are not comparable across targets with different units/scales\n",
    "- Can hide *systematic bias* unless you also inspect residuals (RMSE is a single number)\n",
    "\n",
    "**Good default when**\n",
    "\n",
    "- You have a regression problem and care more about large errors than small ones\n",
    "- Residuals are roughly symmetric and not extremely heavy-tailed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6535189c",
   "metadata": {},
   "source": [
    "## 13) Common pitfalls and diagnostics\n",
    "\n",
    "- **Always plot residuals**: a low RMSE can still mask patterns (non-linearity, heteroscedasticity).\n",
    "- **Outliers dominate**: if your data has rare but huge errors, consider MAE, Huber loss, or quantile losses.\n",
    "- **Scale matters**: if you need comparability, report a normalized RMSE (e.g., divide by target std or range).\n",
    "- **Skewed targets**: if errors are multiplicative (percentage-like), consider RMSLE or modeling on a log scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91fce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_te = predict_linear(x_te, w_ls, b_ls)\n",
    "resid_te = y_hat_te - y_te\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=x_te,\n",
    "    y=resid_te,\n",
    "    title=\"Residuals on test set (least squares fit)\",\n",
    "    labels={\"x\": \"x\", \"y\": \"residual (y_pred - y_true)\"},\n",
    ")\n",
    "fig.add_hline(y=0, line_dash=\"dash\")\n",
    "fig.show()\n",
    "\n",
    "fig = px.histogram(\n",
    "    x=resid_te,\n",
    "    nbins=25,\n",
    "    title=\"Residual distribution on test set\",\n",
    "    labels={\"x\": \"residual (y_pred - y_true)\", \"count\": \"count\"},\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc8a67c",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Implement **normalized RMSE**: divide RMSE by `(y_true.max() - y_true.min())` or `y_true.std()`.\n",
    "2. Add a single extreme outlier to the regression dataset and compare the fitted line under RMSE/MSE vs MAE.\n",
    "3. Implement a finite-difference gradient check for the RMSE gradient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870fa35e",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- scikit-learn metric: https://scikit-learn.org/stable/api/sklearn.metrics.html\n",
    "- scikit-learn User Guide (mean squared error): https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "- *The Elements of Statistical Learning* (Hastie, Tibshirani, Friedman) — least squares and regression basics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}