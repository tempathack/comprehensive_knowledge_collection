{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ca0ab2",
   "metadata": {},
   "source": [
    "# mean_squared_error (MSE)\n",
    "\n",
    "Mean squared error (MSE) is one of the most common **regression** metrics and training losses.\n",
    "It measures the average squared distance between targets and predictions.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "- Understand the definition, units, and common variants (weights, multioutput)\n",
    "- Build intuition for why squaring emphasizes large errors (outliers)\n",
    "- Implement MSE from scratch in NumPy\n",
    "- Visualize the loss landscape for a simple model\n",
    "- Use MSE to fit a linear regression model via gradient descent\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic NumPy arrays and broadcasting\n",
    "- Derivatives of polynomials (or comfort with gradients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a522dff4",
   "metadata": {},
   "source": [
    "## 1) Definition\n",
    "\n",
    "Let $y \\in \\mathbb{R}^n$ be targets and $\\hat{y} \\in \\mathbb{R}^n$ predictions.\n",
    "\n",
    "$$\n",
    "\\mathrm{MSE}(y, \\hat{y}) = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Define the residual $r_i = y_i - \\hat{y}_i$. In vector form:\n",
    "\n",
    "$$\n",
    "\\mathrm{MSE}(y, \\hat{y}) = \\frac{1}{n}\\lVert y - \\hat{y} \\rVert_2^2\n",
    "$$\n",
    "\n",
    "### Weighted MSE\n",
    "\n",
    "If some samples matter more (or have different noise levels), use non-negative weights $w_i$:\n",
    "\n",
    "$$\n",
    "\\mathrm{WMSE}(y, \\hat{y}; w) = \\frac{\\sum_{i=1}^n w_i (y_i-\\hat{y}_i)^2}{\\sum_{i=1}^n w_i}\n",
    "$$\n",
    "\n",
    "### Multioutput\n",
    "\n",
    "For $y,\\hat{y} \\in \\mathbb{R}^{n\\times d}$ (d targets per sample), compute per-output MSE:\n",
    "\n",
    "$$\n",
    "\\mathrm{MSE}_j = \\frac{1}{n}\\sum_{i=1}^n (y_{ij}-\\hat{y}_{ij})^2\n",
    "$$\n",
    "\n",
    "and then aggregate across outputs (uniform average or a weighted average).\n",
    "\n",
    "### Units\n",
    "\n",
    "If $y$ is measured in meters, then MSE is measured in **meters²**.\n",
    "For interpretability, people often report $\\mathrm{RMSE}=\\sqrt{\\mathrm{MSE}}$ in meters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147feb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([2.0, 0.0, 4.0, 1.0])\n",
    "y_pred = np.array([1.5, 0.2, 3.0, 2.0])\n",
    "\n",
    "residual = y_true - y_pred\n",
    "sq_error = residual**2\n",
    "mse = float(np.mean(sq_error))\n",
    "\n",
    "print(\"y_true   =\", y_true)\n",
    "print(\"y_pred   =\", y_pred)\n",
    "print(\"residual =\", residual)\n",
    "print(\"(residual)^2 =\", sq_error)\n",
    "print(\"MSE (NumPy)  =\", mse)\n",
    "print(\"MSE (sklearn)=\", mean_squared_error(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b973f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(y_true))\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Residuals (y - ŷ)\", \"Contribution to MSE: (y - ŷ)²\"),\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=idx, y=y_true, mode=\"markers\", name=\"y_true\", marker=dict(size=10)),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=idx, y=y_pred, mode=\"markers\", name=\"y_pred\", marker=dict(size=10)),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "for i in idx:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[i, i],\n",
    "            y=[y_pred[i], y_true[i]],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"rgba(0,0,0,0.35)\", width=2),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "fig.add_trace(go.Bar(x=idx, y=sq_error, name=\"(y - ŷ)²\"), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"sample index\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"value\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"sample index\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"squared error\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(title=f\"MSE = mean((y - ŷ)²) = {mse:.3f}\", legend=dict(orientation=\"h\"))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f50fba5",
   "metadata": {},
   "source": [
    "## 2) Why do we square the errors?\n",
    "\n",
    "For a single residual $r$, the **squared loss** is:\n",
    "\n",
    "$$\n",
    "\\ell(r) = r^2\n",
    "$$\n",
    "\n",
    "Key properties:\n",
    "\n",
    "- **Emphasizes large errors**: doubling $|r|$ multiplies the penalty by $4$.\n",
    "- **Smooth and differentiable**: useful for gradient-based optimization.\n",
    "- For many models (e.g. linear regression), the MSE objective is **convex**.\n",
    "\n",
    "The derivative is simple:\n",
    "\n",
    "$$\n",
    "\\ell'(r)=2r\n",
    "$$\n",
    "\n",
    "For MSE, the derivative with respect to a prediction $\\hat{y}_i$ is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\hat{y}_i} \\mathrm{MSE}(y, \\hat{y}) = -\\frac{2}{n}(y_i - \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "So the gradient magnitude grows linearly with the residual: big mistakes produce big updates.\n",
    "\n",
    "A common alternative is **MAE** (mean absolute error), which is more robust to outliers but is not differentiable at $r=0$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f82ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.linspace(-5, 5, 400)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=r, y=r**2, mode=\"lines\", name=\"Squared loss r²\"))\n",
    "fig.add_trace(go.Scatter(x=r, y=np.abs(r), mode=\"lines\", name=\"Absolute loss |r|\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"How loss grows with the residual r\",\n",
    "    xaxis_title=\"residual r\",\n",
    "    yaxis_title=\"loss\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2b3743",
   "metadata": {},
   "source": [
    "## 3) Probabilistic view: why MSE is 'natural' for Gaussian noise\n",
    "\n",
    "Assume a regression model predicts the conditional mean and errors are Gaussian:\n",
    "\n",
    "$$\n",
    "Y_i = \\hat{y}_i + \\varepsilon_i, \\qquad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\n",
    "$$\n",
    "\n",
    "The negative log-likelihood (up to constants that don't depend on $\\hat{y}$) is:\n",
    "\n",
    "$$\n",
    "-\\log p(y\\mid \\hat{y}) \\propto \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i-\\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "So **minimizing squared error** is equivalent to **maximum likelihood estimation** under i.i.d. Gaussian noise.\n",
    "\n",
    "If different points have different noise levels (heteroskedasticity), a weighted MSE (weighted least squares) can be more appropriate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd371a5",
   "metadata": {},
   "source": [
    "## 4) Mean squared error from scratch (NumPy)\n",
    "\n",
    "Below is a small implementation that mirrors the core ideas in `sklearn.metrics.mean_squared_error`:\n",
    "\n",
    "- works for 1D targets `(n,)` and multioutput targets `(n, d)`\n",
    "- optional `sample_weight` for weighted MSE\n",
    "- `multioutput` aggregation: `'raw_values'`, `'uniform_average'`, or an array of output weights\n",
    "\n",
    "This is intentionally \"low-level\": no pandas, no sklearn internals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba44dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error_np(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    *,\n",
    "    sample_weight=None,\n",
    "    multioutput=\"uniform_average\",\n",
    "):\n",
    "    '''Compute mean squared error (MSE) with optional sample weights and multioutput support.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true, y_pred:\n",
    "        Array-like with shape (n,) or (n, d)\n",
    "    sample_weight:\n",
    "        None or array-like with shape (n,)\n",
    "    multioutput:\n",
    "        - 'raw_values'        -> return array of shape (d,)\n",
    "        - 'uniform_average'   -> return scalar (mean over outputs)\n",
    "        - array-like (d,)     -> weighted average over outputs\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float or np.ndarray\n",
    "    '''\n",
    "\n",
    "    y_true_arr = np.asarray(y_true, dtype=float)\n",
    "    y_pred_arr = np.asarray(y_pred, dtype=float)\n",
    "\n",
    "    if y_true_arr.shape != y_pred_arr.shape:\n",
    "        raise ValueError(f\"Shape mismatch: y_true {y_true_arr.shape} vs y_pred {y_pred_arr.shape}\")\n",
    "\n",
    "    if y_true_arr.ndim == 1:\n",
    "        y_true_arr = y_true_arr[:, None]\n",
    "        y_pred_arr = y_pred_arr[:, None]\n",
    "    elif y_true_arr.ndim != 2:\n",
    "        raise ValueError(\"y_true/y_pred must be 1D or 2D\")\n",
    "\n",
    "    n_samples, n_outputs = y_true_arr.shape\n",
    "\n",
    "    sq_error = (y_true_arr - y_pred_arr) ** 2  # (n, d)\n",
    "\n",
    "    if sample_weight is not None:\n",
    "        w = np.asarray(sample_weight, dtype=float)\n",
    "        if w.ndim != 1 or w.shape[0] != n_samples:\n",
    "            raise ValueError(f\"sample_weight must have shape ({n_samples},), got {w.shape}\")\n",
    "        if np.any(w < 0):\n",
    "            raise ValueError(\"sample_weight must be non-negative\")\n",
    "\n",
    "        denom = float(np.sum(w))\n",
    "        if denom == 0.0:\n",
    "            raise ValueError(\"sum(sample_weight) must be > 0\")\n",
    "\n",
    "        mse_per_output = np.sum(sq_error * w[:, None], axis=0) / denom\n",
    "    else:\n",
    "        mse_per_output = np.mean(sq_error, axis=0)\n",
    "\n",
    "    if isinstance(multioutput, str):\n",
    "        if multioutput == \"raw_values\":\n",
    "            return mse_per_output\n",
    "        if multioutput == \"uniform_average\":\n",
    "            return float(np.mean(mse_per_output))\n",
    "        raise ValueError(\n",
    "            \"multioutput must be 'raw_values', 'uniform_average', or array-like of output weights\"\n",
    "        )\n",
    "\n",
    "    output_weights = np.asarray(multioutput, dtype=float)\n",
    "    if output_weights.shape != (n_outputs,):\n",
    "        raise ValueError(f\"multioutput weights must have shape ({n_outputs},), got {output_weights.shape}\")\n",
    "\n",
    "    weight_sum = float(np.sum(output_weights))\n",
    "    if weight_sum == 0.0:\n",
    "        raise ValueError(\"sum(multioutput weights) must be > 0\")\n",
    "\n",
    "    return float(np.dot(mse_per_output, output_weights) / weight_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d1596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks vs sklearn\n",
    "\n",
    "# 1D\n",
    "y_true_1d = rng.normal(size=50)\n",
    "y_pred_1d = y_true_1d + rng.normal(scale=0.5, size=50)\n",
    "\n",
    "print(\n",
    "    \"1D equal:\",\n",
    "    np.isclose(mean_squared_error_np(y_true_1d, y_pred_1d), mean_squared_error(y_true_1d, y_pred_1d)),\n",
    ")\n",
    "\n",
    "# Multioutput\n",
    "y_true_2d = rng.normal(size=(50, 3))\n",
    "y_pred_2d = y_true_2d + rng.normal(scale=0.5, size=(50, 3))\n",
    "\n",
    "mse_raw_np = mean_squared_error_np(y_true_2d, y_pred_2d, multioutput=\"raw_values\")\n",
    "mse_raw_sk = mean_squared_error(y_true_2d, y_pred_2d, multioutput=\"raw_values\")\n",
    "\n",
    "print(\"multioutput raw close:\", np.allclose(mse_raw_np, mse_raw_sk))\n",
    "\n",
    "# Weighted\n",
    "w = rng.uniform(0.1, 2.0, size=50)\n",
    "\n",
    "mse_w_np = mean_squared_error_np(y_true_2d, y_pred_2d, sample_weight=w, multioutput=\"uniform_average\")\n",
    "mse_w_sk = mean_squared_error(y_true_2d, y_pred_2d, sample_weight=w, multioutput=\"uniform_average\")\n",
    "\n",
    "print(\"weighted uniform close:\", np.isclose(mse_w_np, mse_w_sk))\n",
    "\n",
    "# Weighted multioutput\n",
    "out_w = np.array([0.2, 0.3, 0.5])\n",
    "\n",
    "mse_wo_np = mean_squared_error_np(y_true_2d, y_pred_2d, sample_weight=w, multioutput=out_w)\n",
    "mse_wo_sk = mean_squared_error(y_true_2d, y_pred_2d, sample_weight=w, multioutput=out_w)\n",
    "\n",
    "print(\"weighted output close:\", np.isclose(mse_wo_np, mse_wo_sk))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58661e90",
   "metadata": {},
   "source": [
    "## 5) Geometry intuition: constant predictions\n",
    "\n",
    "Suppose your model can only predict a single constant value $a$ for every sample:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = a\n",
    "$$\n",
    "\n",
    "The MSE becomes a function of a single parameter:\n",
    "\n",
    "$$\n",
    "J(a) = \\frac{1}{n}\\sum_{i=1}^n (y_i-a)^2\n",
    "$$\n",
    "\n",
    "Differentiate and set to zero:\n",
    "\n",
    "$$\n",
    "\\frac{dJ}{da} = -\\frac{2}{n}\\sum_{i=1}^n (y_i-a)=0\n",
    "\\quad\\Rightarrow\\quad\n",
    "a = \\frac{1}{n}\\sum_{i=1}^n y_i = \\bar{y}\n",
    "$$\n",
    "\n",
    "So **the constant that minimizes MSE is the mean**.\n",
    "\n",
    "### The best constant MSE equals the variance\n",
    "\n",
    "At the optimum $a=\\bar{y}$, the minimum value is:\n",
    "\n",
    "$$\n",
    "J(\\bar{y}) = \\frac{1}{n}\\sum_{i=1}^n (y_i-\\bar{y})^2 = \\mathrm{Var}(y) \\quad (\\mathrm{ddof}=0)\n",
    "$$\n",
    "\n",
    "So predicting the mean gives an MSE equal to the (population) variance of the target.\n",
    "\n",
    "### Weighted MSE: the weighted mean\n",
    "\n",
    "If we use weights $w_i \\ge 0$:\n",
    "\n",
    "$$\n",
    "J_w(a)=\\frac{\\sum_i w_i (y_i-a)^2}{\\sum_i w_i}\n",
    "$$\n",
    "\n",
    "then the minimizer is the **weighted mean**:\n",
    "\n",
    "$$\n",
    "a^* = \\frac{\\sum_i w_i y_i}{\\sum_i w_i}\n",
    "$$\n",
    "\n",
    "Interpreting $w_i \\propto 1/\\sigma_i^2$ connects this to weighted least squares under heteroskedastic Gaussian noise.\n",
    "\n",
    "This is also why MSE is **sensitive to outliers**: a single extreme value can move the mean (and therefore the optimum) a lot.\n",
    "If you have a reason to trust some points less, sample weights can reduce their influence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4e181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = rng.normal(loc=0.0, scale=1.0, size=60)\n",
    "y_outlier = y.copy()\n",
    "y_outlier[0] = 8.0  # one extreme point\n",
    "\n",
    "a_grid = np.linspace(-4, 9, 500)\n",
    "\n",
    "mse_clean = np.mean((y[:, None] - a_grid[None, :]) ** 2, axis=0)\n",
    "mse_out = np.mean((y_outlier[:, None] - a_grid[None, :]) ** 2, axis=0)\n",
    "\n",
    "mu_clean = float(np.mean(y))\n",
    "mu_out = float(np.mean(y_outlier))\n",
    "\n",
    "mse_at_mu_clean = float(np.mean((y - mu_clean) ** 2))\n",
    "mse_at_mu_out = float(np.mean((y_outlier - mu_out) ** 2))\n",
    "\n",
    "# Downweight the outlier (one simple way to reduce its influence)\n",
    "w_down = np.ones_like(y_outlier)\n",
    "w_down[0] = 0.05\n",
    "\n",
    "wmse_down = (\n",
    "    np.sum(((y_outlier[:, None] - a_grid[None, :]) ** 2) * w_down[:, None], axis=0) / float(np.sum(w_down))\n",
    ")\n",
    "mu_w = float(np.sum(w_down * y_outlier) / np.sum(w_down))\n",
    "wmse_at_mu_w = float(np.sum(((y_outlier - mu_w) ** 2) * w_down) / np.sum(w_down))\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"MSE(a) is minimized at the mean\", \"Weighted MSE can reduce outlier influence\"),\n",
    ")\n",
    "\n",
    "# Left: clean data vs the same data with an outlier\n",
    "fig.add_trace(go.Scatter(x=a_grid, y=mse_clean, mode=\"lines\", name=\"MSE(a) (clean)\"), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=a_grid, y=mse_out, mode=\"lines\", name=\"MSE(a) (with outlier)\"), row=1, col=1)\n",
    "\n",
    "fig.add_vline(x=mu_clean, line_dash=\"dash\", line_color=\"rgba(0,0,0,0.45)\", row=1, col=1)\n",
    "fig.add_vline(x=mu_out, line_dash=\"dash\", line_color=\"rgba(0,0,0,0.45)\", row=1, col=1)\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=mu_clean,\n",
    "    y=mse_at_mu_clean,\n",
    "    text=f\"mean={mu_clean:.2f}<br>min MSE=Var(y)≈{mse_at_mu_clean:.2f}\",\n",
    "    showarrow=True,\n",
    "    yshift=10,\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_annotation(\n",
    "    x=mu_out,\n",
    "    y=mse_at_mu_out,\n",
    "    text=f\"mean={mu_out:.2f}\",\n",
    "    showarrow=True,\n",
    "    yshift=10,\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# Right: the outlier dataset with uniform weights vs a small outlier weight\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=a_grid,\n",
    "        y=mse_out,\n",
    "        mode=\"lines\",\n",
    "        name=\"MSE(a) (uniform weights)\",\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=a_grid, y=wmse_down, mode=\"lines\", name=\"WMSE(a) (downweight outlier)\"), row=1, col=2)\n",
    "\n",
    "fig.add_vline(x=mu_out, line_dash=\"dash\", line_color=\"rgba(0,0,0,0.45)\", row=1, col=2)\n",
    "fig.add_vline(x=mu_w, line_dash=\"dash\", line_color=\"rgba(0,0,0,0.45)\", row=1, col=2)\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=mu_out,\n",
    "    y=mse_at_mu_out,\n",
    "    text=f\"uniform mean={mu_out:.2f}\",\n",
    "    showarrow=True,\n",
    "    yshift=10,\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "fig.add_annotation(\n",
    "    x=mu_w,\n",
    "    y=wmse_at_mu_w,\n",
    "    text=f\"weighted mean={mu_w:.2f}\",\n",
    "    showarrow=True,\n",
    "    yshift=10,\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"constant prediction a\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"loss\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"constant prediction a\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"loss\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Constant predictor: mean (and weighted mean) minimize squared error\",\n",
    "    legend=dict(orientation=\"h\"),\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8d4ec0",
   "metadata": {},
   "source": [
    "## 6) Using MSE to optimize a model: simple linear regression\n",
    "\n",
    "### Model\n",
    "\n",
    "With one feature $x$, a linear model predicts:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = b_0 + b_1 x_i\n",
    "$$\n",
    "\n",
    "### Objective\n",
    "\n",
    "Minimize MSE over parameters $(b_0, b_1)$:\n",
    "\n",
    "$$\n",
    "J(b_0, b_1) = \\frac{1}{n}\\sum_{i=1}^n \\big(y_i - (b_0 + b_1 x_i)\\big)^2\n",
    "$$\n",
    "\n",
    "### Gradients\n",
    "\n",
    "Let $\\hat{y}_i=b_0+b_1x_i$ and residual $r_i=y_i-\\hat{y}_i$.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial b_0} = -\\frac{2}{n}\\sum_{i=1}^n r_i\n",
    "\\qquad\n",
    "\\frac{\\partial J}{\\partial b_1} = -\\frac{2}{n}\\sum_{i=1}^n x_i r_i\n",
    "$$\n",
    "\n",
    "### Gradient descent\n",
    "\n",
    "Update parameters with learning rate $\\eta$:\n",
    "\n",
    "$$\n",
    "(b_0, b_1) \\leftarrow (b_0, b_1) - \\eta\\,\\nabla J(b_0, b_1)\n",
    "$$\n",
    "\n",
    "For linear regression, there is also a closed-form solution (ordinary least squares), but gradient descent shows how MSE acts as an optimization landscape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic dataset\n",
    "n = 150\n",
    "x = rng.uniform(-3, 3, size=n)\n",
    "\n",
    "b0_true = 1.5\n",
    "b1_true = 2.0\n",
    "noise = rng.normal(0, 0.8, size=n)\n",
    "\n",
    "y = b0_true + b1_true * x + noise\n",
    "\n",
    "fig = px.scatter(x=x, y=y, title=\"Synthetic regression data\", labels={\"x\": \"x\", \"y\": \"y\"})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca1315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_for_line(x, y, b0, b1):\n",
    "    y_hat = b0 + b1 * x\n",
    "    r = y - y_hat\n",
    "    return float(np.mean(r**2))\n",
    "\n",
    "\n",
    "def mse_gradients_for_line(x, y, b0, b1):\n",
    "    'Return (mse, dJ/db0, dJ/db1) for y_hat = b0 + b1 x.'\n",
    "\n",
    "    y_hat = b0 + b1 * x\n",
    "    r = y - y_hat\n",
    "    n = x.shape[0]\n",
    "\n",
    "    mse = float(np.mean(r**2))\n",
    "    db0 = float((-2.0 / n) * np.sum(r))\n",
    "    db1 = float((-2.0 / n) * np.sum(x * r))\n",
    "    return mse, db0, db1\n",
    "\n",
    "\n",
    "def fit_line_gd(x, y, *, lr=0.05, n_steps=200):\n",
    "    b0, b1 = 0.0, 0.0\n",
    "\n",
    "    history = {\n",
    "        \"step\": [],\n",
    "        \"b0\": [],\n",
    "        \"b1\": [],\n",
    "        \"mse\": [],\n",
    "    }\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        mse, db0, db1 = mse_gradients_for_line(x, y, b0, b1)\n",
    "\n",
    "        history[\"step\"].append(step)\n",
    "        history[\"b0\"].append(b0)\n",
    "        history[\"b1\"].append(b1)\n",
    "        history[\"mse\"].append(mse)\n",
    "\n",
    "        b0 -= lr * db0\n",
    "        b1 -= lr * db1\n",
    "\n",
    "    return (b0, b1), history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb60c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(b0_gd, b1_gd), hist = fit_line_gd(x, y, lr=0.05, n_steps=200)\n",
    "\n",
    "# Closed-form OLS (for comparison)\n",
    "X = np.column_stack([np.ones_like(x), x])\n",
    "b0_ols, b1_ols = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "\n",
    "print(f\"true params: b0={b0_true:.3f}, b1={b1_true:.3f}\")\n",
    "print(f\"GD   params: b0={b0_gd:.3f}, b1={b1_gd:.3f}, MSE={mse_for_line(x, y, b0_gd, b1_gd):.4f}\")\n",
    "print(f\"OLS  params: b0={b0_ols:.3f}, b1={b1_ols:.3f}, MSE={mse_for_line(x, y, b0_ols, b1_ols):.4f}\")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=hist[\"step\"], y=hist[\"mse\"], mode=\"lines\", name=\"MSE\"))\n",
    "fig.update_layout(title=\"Gradient descent on MSE\", xaxis_title=\"step\", yaxis_title=\"MSE\")\n",
    "fig.show()\n",
    "\n",
    "# Fit line\n",
    "x_line = np.linspace(x.min(), x.max(), 200)\n",
    "\n",
    "y_hat_gd = b0_gd + b1_gd * x_line\n",
    "y_hat_ols = b0_ols + b1_ols * x_line\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y, mode=\"markers\", name=\"data\", marker=dict(size=6, opacity=0.75)))\n",
    "fig.add_trace(go.Scatter(x=x_line, y=y_hat_gd, mode=\"lines\", name=\"GD fit\"))\n",
    "fig.add_trace(go.Scatter(x=x_line, y=y_hat_ols, mode=\"lines\", name=\"OLS fit\", line=dict(dash=\"dash\")))\n",
    "fig.update_layout(title=\"Fitted line\", xaxis_title=\"x\", yaxis_title=\"y\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the MSE surface over (b0, b1) with the GD path\n",
    "\n",
    "b0_grid = np.linspace(b0_ols - 2.0, b0_ols + 2.0, 160)\n",
    "b1_grid = np.linspace(b1_ols - 2.0, b1_ols + 2.0, 160)\n",
    "\n",
    "B0, B1 = np.meshgrid(b0_grid, b1_grid)\n",
    "residuals = y[None, None, :] - (B0[:, :, None] + B1[:, :, None] * x[None, None, :])\n",
    "Z = np.mean(residuals**2, axis=2)\n",
    "\n",
    "stride = max(1, len(hist[\"step\"]) // 120)\n",
    "b0_path = np.array(hist[\"b0\"])[::stride]\n",
    "b1_path = np.array(hist[\"b1\"])[::stride]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Contour(\n",
    "        x=b0_grid,\n",
    "        y=b1_grid,\n",
    "        z=Z,\n",
    "        contours_coloring=\"heatmap\",\n",
    "        colorbar=dict(title=\"MSE\"),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=b0_path,\n",
    "        y=b1_path,\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"GD path\",\n",
    "        marker=dict(size=4, color=\"black\"),\n",
    "        line=dict(color=\"black\"),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[b0_ols],\n",
    "        y=[b1_ols],\n",
    "        mode=\"markers\",\n",
    "        name=\"OLS optimum\",\n",
    "        marker=dict(symbol=\"x\", size=10, color=\"white\", line=dict(color=\"black\", width=2)),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"MSE landscape for a line: convex bowl + gradient descent trajectory\",\n",
    "    xaxis_title=\"b0 (intercept)\",\n",
    "    yaxis_title=\"b1 (slope)\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae18993",
   "metadata": {},
   "source": [
    "## 7) Practical usage (scikit-learn)\n",
    "\n",
    "In practice, MSE is most often used to evaluate regression models on a validation/test set:\n",
    "\n",
    "- Lower is better.\n",
    "- Because it has squared units, also report $\\mathrm{RMSE}=\\sqrt{\\mathrm{MSE}}$ for interpretability.\n",
    "- Use `sample_weight` when some samples matter more or have different noise levels.\n",
    "- For multioutput regression, use `multioutput` to get per-target values or an aggregate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa940e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = x.reshape(-1, 1)\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_tr, y_tr)\n",
    "y_pred_te = model.predict(X_te)\n",
    "\n",
    "mse_te = mean_squared_error(y_te, y_pred_te)\n",
    "rmse_te = float(np.sqrt(mse_te))\n",
    "\n",
    "# Example: weighted evaluation (here we weight samples with large |x| more)\n",
    "w_te = 0.5 + np.abs(X_te[:, 0])\n",
    "mse_te_w = mean_squared_error(y_te, y_pred_te, sample_weight=w_te)\n",
    "\n",
    "print(f\"Test MSE:  {mse_te:.4f}\")\n",
    "print(f\"Test RMSE: {rmse_te:.4f}\")\n",
    "print(f\"Weighted Test MSE (w = 0.5 + |x|): {mse_te_w:.4f}\")\n",
    "\n",
    "min_v = float(min(y_te.min(), y_pred_te.min()))\n",
    "max_v = float(max(y_te.max(), y_pred_te.max()))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_te,\n",
    "        y=y_pred_te,\n",
    "        mode=\"markers\",\n",
    "        name=\"pred vs true\",\n",
    "        marker=dict(size=7, opacity=0.8),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=[min_v, max_v], y=[min_v, max_v], mode=\"lines\", name=\"ideal\", line=dict(dash=\"dash\")))\n",
    "fig.update_layout(\n",
    "    title=f\"Test set predictions (MSE={mse_te:.3f}, RMSE={rmse_te:.3f})\",\n",
    "    xaxis_title=\"y_true\",\n",
    "    yaxis_title=\"y_pred\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96de587",
   "metadata": {},
   "source": [
    "## 8) Pros, cons, and when to use MSE\n",
    "\n",
    "### Pros\n",
    "\n",
    "- **Simple and widely used** baseline for regression.\n",
    "- **Differentiable** and often **convex** (e.g. linear regression) → friendly for optimization.\n",
    "- Strongly penalizes large errors (useful when big misses are particularly costly).\n",
    "- Has a clear statistical interpretation: minimizing MSE corresponds to **maximum likelihood** under i.i.d. Gaussian noise.\n",
    "\n",
    "### Cons / pitfalls\n",
    "\n",
    "- **Outlier sensitive**: a few large residuals can dominate the average.\n",
    "- **Scale dependent**: MSE values depend on the units of $y$ (hard to compare across targets without normalization).\n",
    "- **Squared units**: less interpretable than RMSE or MAE.\n",
    "- Optimizing MSE targets the **conditional mean**; if you care about medians/quantiles or heavy-tailed noise, MAE / pinball loss / Huber can be better.\n",
    "\n",
    "### Good use cases\n",
    "\n",
    "- Standard regression tasks where errors are roughly symmetric and not extremely heavy-tailed.\n",
    "- When large errors should be penalized more than small ones.\n",
    "- As a training loss for linear models / neural nets when Gaussian noise is a reasonable assumption.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632f425",
   "metadata": {},
   "source": [
    "## 9) Exercises\n",
    "\n",
    "1. Implement `root_mean_squared_error_np` and verify it matches `sqrt(MSE)`.\n",
    "2. Create a dataset with 1% extreme outliers. Compare how MSE vs MAE changes.\n",
    "3. Extend `fit_line_gd` to multiple features: $\\hat{y}=b+Xw$.\n",
    "4. Derive the closed-form OLS solution and compare it to gradient descent.\n",
    "\n",
    "## References\n",
    "\n",
    "- scikit-learn docs: https://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error\n",
    "- Hastie, Tibshirani, Friedman — *The Elements of Statistical Learning* (least squares and loss functions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}