{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0046ebb0",
   "metadata": {},
   "source": [
    "# Skewness Test (D'Agostino)\n",
    "\n",
    "The **skewness test** checks whether a sample shows **statistically significant asymmetry**.\n",
    "\n",
    "It is commonly used as a diagnostic for:\n",
    "- **symmetry assumptions** (many parametric procedures implicitly assume roughly symmetric errors)\n",
    "- whether a **transformation** (log/sqrt/Box–Cox) might be useful\n",
    "- as one component of **normality diagnostics** (but **it is not a full normality test** by itself)\n",
    "\n",
    "## Learning goals\n",
    "By the end you should be able to:\n",
    "- explain what skewness measures (right/left tail intuition)\n",
    "- state the hypotheses behind the skewness test\n",
    "- implement D'Agostino’s skewness test with **NumPy only**\n",
    "- interpret the test statistic and p-value (including one-sided alternatives)\n",
    "- understand common pitfalls (outliers, sample size, “significant but tiny” effects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b06ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a620147f",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Sample mean and central moments\n",
    "- Z-scores and p-values\n",
    "- The standard normal distribution\n",
    "\n",
    "If any of these are fuzzy, you can still follow the notebook: the code is written to make each step explicit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5cf404",
   "metadata": {},
   "source": [
    "## 1) Intuition: what skewness measures\n",
    "\n",
    "Skewness is a **signed measure of asymmetry**:\n",
    "- **Positive skewness** → a **longer right tail** (“right-skewed”)\n",
    "- **Negative skewness** → a **longer left tail** (“left-skewed”)\n",
    "\n",
    "A common (moment-based) sample skewness is\n",
    "\n",
    "\\[\n",
    "\text{skew}(x)\n",
    "= \f",
    "rac{m_3}{m_2^{3/2}},\n",
    "\\qquad\n",
    "m_k = \f",
    "rac{1}{n}\\sum_{i=1}^n (x_i - \bar{x})^k.\n",
    "\\]\n",
    "\n",
    "This uses the **third central moment** \\(m_3\\), so it is **very sensitive to outliers**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23629991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_skewness(x: np.ndarray) -> float:\n",
    "    \"Moment-based sample skewness: m3 / m2^(3/2) using 1/n moments.\"\n",
    "    x = np.asarray(x, dtype=float).ravel()\n",
    "    x = x[np.isfinite(x)]\n",
    "    n = x.size\n",
    "    if n < 3:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    mean = x.mean()\n",
    "    centered = x - mean\n",
    "    m2 = np.mean(centered**2)\n",
    "    if m2 == 0:\n",
    "        return 0.0\n",
    "    m3 = np.mean(centered**3)\n",
    "    return float(m3 / (m2 ** 1.5))\n",
    "\n",
    "\n",
    "n_demo = 4000\n",
    "x_sym = rng.normal(0, 1, size=n_demo)\n",
    "x_right = rng.exponential(scale=1.0, size=n_demo)\n",
    "x_left = -rng.exponential(scale=1.0, size=n_demo)\n",
    "\n",
    "skews = {\n",
    "    \"Symmetric (normal)\": sample_skewness(x_sym),\n",
    "    \"Right-skewed (exponential)\": sample_skewness(x_right),\n",
    "    \"Left-skewed (-exponential)\": sample_skewness(x_left),\n",
    "}\n",
    "\n",
    "skews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508ba4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=3,\n",
    "    subplot_titles=[f\"{k}<br>skew={v:.3f}\" for k, v in skews.items()],\n",
    ")\n",
    "\n",
    "datasets = [\n",
    "    (\"Symmetric (normal)\", x_sym),\n",
    "    (\"Right-skewed (exponential)\", x_right),\n",
    "    (\"Left-skewed (-exponential)\", x_left),\n",
    "]\n",
    "\n",
    "for col, (name, x) in enumerate(datasets, start=1):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=x,\n",
    "            nbinsx=80,\n",
    "            histnorm=\"probability density\",\n",
    "            name=name,\n",
    "            marker=dict(line=dict(width=0)),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=col,\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    height=320,\n",
    "    width=1000,\n",
    "    showlegend=False,\n",
    "    title_text=\"Skewness: symmetric vs right/left skew\",\n",
    ")\n",
    "fig.update_xaxes(range=[-5, 5])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741be32b",
   "metadata": {},
   "source": [
    "## 2) What the skewness test is (and what it is not)\n",
    "\n",
    "### Goal\n",
    "We want to know whether the skewness we observe could plausibly be due to **sampling noise** when the underlying distribution is **normal** (which has population skewness 0).\n",
    "\n",
    "### Hypotheses\n",
    "For the standard two-sided skewness test:\n",
    "\n",
    "- \\(H_0\\): the population skewness is the same as the normal distribution (i.e. **0**)\n",
    "- \\(H_1\\): the population skewness is **not** 0\n",
    "\n",
    "You can also run one-sided versions:\n",
    "- `alternative='greater'`: \\(H_1\\): skewness \\(> 0\\) (right-skew)\n",
    "- `alternative='less'`: \\(H_1\\): skewness \\(< 0\\) (left-skew)\n",
    "\n",
    "### What it is *not*\n",
    "- It is **not** a complete normality test. A distribution can be symmetric (skew ≈ 0) but still very non-normal (e.g. heavy-tailed).\n",
    "- It does **not** tell you *why* data are skewed (mixtures, censoring, outliers, bounded support, etc.). You should always visualize the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c2fa23",
   "metadata": {},
   "source": [
    "## 3) D'Agostino’s skewness test: the core idea\n",
    "\n",
    "D'Agostino’s skewness test takes the sample skewness \\(b_2\\) and transforms it into a value \\(Z\\) that is approximately **standard normal** under \\(H_0\\):\n",
    "\n",
    "\\[\n",
    "Z \u0007pprox \\mathcal{N}(0,1) \\quad \text{(when the data are normal and } n\\ge 8\text{)}.\n",
    "\\]\n",
    "\n",
    "That lets us compute a p-value just like a z-test.\n",
    "\n",
    "### The transformation (as used by SciPy’s `skewtest`)\n",
    "Let \\(n\\) be the sample size and \\(b_2\\) the (moment-based) sample skewness. Define\n",
    "\n",
    "\\[\n",
    "y = b_2\\sqrt{\f",
    "rac{(n+1)(n+3)}{6(n-2)}}.\n",
    "\\]\n",
    "\n",
    "Then compute\n",
    "\n",
    "\\[\n",
    "\beta_2 = \f",
    "rac{3\\,(n^2 + 27n - 70)(n+1)(n+3)}{(n-2)(n+5)(n+7)(n+9)},\n",
    "\\quad\n",
    "W^2 = -1 + \\sqrt{2(\beta_2 - 1)}.\n",
    "\\]\n",
    "\n",
    "and\n",
    "\n",
    "\\[\n",
    "\\delta = \f",
    "rac{1}{\\sqrt{\tfrac{1}{2}\\ln(W^2)}},\n",
    "\\quad\n",
    "\u0007lpha = \\sqrt{\f",
    "rac{2}{W^2 - 1}}.\n",
    "\\]\n",
    "\n",
    "Finally,\n",
    "\n",
    "\\[\n",
    "Z = \\delta\\,\\operatorname{asinh}\\!\\left(\f",
    "rac{y}{\u0007lpha}\r",
    "ight)\n",
    "= \\delta\\,\\ln\\left(\f",
    "rac{y}{\u0007lpha} + \\sqrt{\\left(\f",
    "rac{y}{\u0007lpha}\r",
    "ight)^2 + 1}\r",
    "ight).\n",
    "\\]\n",
    "\n",
    "### Why the sample size constraint?\n",
    "The approximation is derived under normality and is intended for **\\(n\\ge 8\\)**. For smaller samples, you should prefer resampling-based checks or simply treat skewness as an *effect size*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f057e7c3",
   "metadata": {},
   "source": [
    "## 4) NumPy-only implementation\n",
    "\n",
    "The functions below implement:\n",
    "- sample skewness \\(b_2\\)\n",
    "- D'Agostino’s transformed statistic \\(Z\\)\n",
    "- p-values using a NumPy approximation to the normal CDF (via an `erf` approximation)\n",
    "\n",
    "The goal here is **transparency**, not squeezing out every last bit of numerical accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erf_approx(x: np.ndarray) -> np.ndarray:\n",
    "    \"Vectorized erf approximation (Abramowitz & Stegun 7.1.26).\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    sign = np.sign(x)\n",
    "    ax = np.abs(x)\n",
    "\n",
    "    p = 0.3275911\n",
    "    t = 1.0 / (1.0 + p * ax)\n",
    "\n",
    "    a1 = 0.254829592\n",
    "    a2 = -0.284496736\n",
    "    a3 = 1.421413741\n",
    "    a4 = -1.453152027\n",
    "    a5 = 1.061405429\n",
    "\n",
    "    poly = (((((a5 * t + a4) * t + a3) * t + a2) * t + a1) * t)\n",
    "    y = 1.0 - poly * np.exp(-ax * ax)\n",
    "    return sign * y\n",
    "\n",
    "\n",
    "def norm_cdf(z: np.ndarray) -> np.ndarray:\n",
    "    \"Standard normal CDF Φ(z) using erf approximation.\"\n",
    "    z = np.asarray(z, dtype=float)\n",
    "    return 0.5 * (1.0 + erf_approx(z / np.sqrt(2.0)))\n",
    "\n",
    "\n",
    "def pvalue_from_z(z: np.ndarray, alternative: str = \"two-sided\") -> np.ndarray:\n",
    "    \"Convert a z-statistic to a p-value under N(0,1).\"\n",
    "    z = np.asarray(z, dtype=float)\n",
    "\n",
    "    if alternative == \"two-sided\":\n",
    "        p = 2.0 * norm_cdf(-np.abs(z))\n",
    "    elif alternative == \"greater\":\n",
    "        p = norm_cdf(-z)\n",
    "    elif alternative == \"less\":\n",
    "        p = norm_cdf(z)\n",
    "    else:\n",
    "        raise ValueError(\"alternative must be one of: 'two-sided', 'greater', 'less'\")\n",
    "\n",
    "    return np.clip(p, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def dagostino_z_from_skewness(b2: np.ndarray, n: int) -> np.ndarray:\n",
    "    \"D'Agostino transform from sample skewness b2 to Z (approx N(0,1) under H0).\"\n",
    "    if n < 8:\n",
    "        raise ValueError(\"D'Agostino skewness test requires n >= 8\")\n",
    "\n",
    "    b2 = np.asarray(b2, dtype=float)\n",
    "    nf = float(n)\n",
    "\n",
    "    y = b2 * np.sqrt(((nf + 1.0) * (nf + 3.0)) / (6.0 * (nf - 2.0)))\n",
    "\n",
    "    beta2 = (\n",
    "        3.0\n",
    "        * (nf**2 + 27.0 * nf - 70.0)\n",
    "        * (nf + 1.0)\n",
    "        * (nf + 3.0)\n",
    "        / ((nf - 2.0) * (nf + 5.0) * (nf + 7.0) * (nf + 9.0))\n",
    "    )\n",
    "\n",
    "    w2 = -1.0 + np.sqrt(2.0 * (beta2 - 1.0))\n",
    "    delta = 1.0 / np.sqrt(0.5 * np.log(w2))\n",
    "    alpha = np.sqrt(2.0 / (w2 - 1.0))\n",
    "\n",
    "    # asinh(u) == log(u + sqrt(u^2 + 1)) but is more numerically stable\n",
    "    return delta * np.arcsinh(y / alpha)\n",
    "\n",
    "\n",
    "def dagostino_skewtest(x: np.ndarray, alternative: str = \"two-sided\") -> dict:\n",
    "    \"D'Agostino skewness test (NumPy-only implementation).\"\n",
    "    x = np.asarray(x, dtype=float).ravel()\n",
    "    x = x[np.isfinite(x)]\n",
    "    n = x.size\n",
    "    if n < 8:\n",
    "        raise ValueError(\"D'Agostino skewness test requires at least 8 observations\")\n",
    "\n",
    "    b2 = sample_skewness(x)\n",
    "    z = dagostino_z_from_skewness(b2, n)\n",
    "    p = pvalue_from_z(z, alternative=alternative)\n",
    "\n",
    "    return {\n",
    "        \"n\": int(n),\n",
    "        \"skewness\": float(b2),\n",
    "        \"z\": float(np.asarray(z)),\n",
    "        \"pvalue\": float(np.asarray(p)),\n",
    "        \"alternative\": alternative,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8996a059",
   "metadata": {},
   "source": [
    "## 5) Worked examples + interpretation\n",
    "\n",
    "**Interpretation guide (two-sided):**\n",
    "- Small p-value (e.g. < 0.05) → evidence the data are **asymmetric** (skewness ≠ 0) relative to normal sampling noise.\n",
    "- The **sign of Z** tells you the direction:\n",
    "  - `Z > 0` → right-skew (long right tail)\n",
    "  - `Z < 0` → left-skew (long left tail)\n",
    "\n",
    "Remember: with large \\(n\\), even tiny skewness can become “statistically significant”. Always look at the effect size (the skewness value) and the plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddff8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_test(x: np.ndarray, name: str, alternative: str = \"two-sided\") -> dict:\n",
    "    res = dagostino_skewtest(x, alternative=alternative)\n",
    "    return {\n",
    "        \"dataset\": name,\n",
    "        \"n\": res[\"n\"],\n",
    "        \"skewness\": res[\"skewness\"],\n",
    "        \"z\": res[\"z\"],\n",
    "        \"pvalue\": res[\"pvalue\"],\n",
    "        \"alternative\": res[\"alternative\"],\n",
    "    }\n",
    "\n",
    "\n",
    "n = 60\n",
    "x1 = rng.normal(0, 1, size=n)\n",
    "x2 = rng.exponential(1.0, size=n)\n",
    "x3 = -rng.exponential(1.0, size=n)\n",
    "\n",
    "results = [\n",
    "    summarize_test(x1, \"Normal sample\"),\n",
    "    summarize_test(x2, \"Right-skew (exponential)\"),\n",
    "    summarize_test(x3, \"Left-skew (-exponential)\"),\n",
    "]\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4626033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=3,\n",
    "    subplot_titles=[\n",
    "        f\"{r['dataset']}<br>skew={r['skewness']:.3f}, Z={r['z']:.2f}, p={r['pvalue']:.3g}\" for r in results\n",
    "    ],\n",
    ")\n",
    "\n",
    "for col, (x, r) in enumerate([(x1, results[0]), (x2, results[1]), (x3, results[2])], start=1):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=x,\n",
    "            nbinsx=30,\n",
    "            histnorm=\"probability density\",\n",
    "            name=r[\"dataset\"],\n",
    "            marker=dict(line=dict(width=0)),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=col,\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    height=320,\n",
    "    width=1100,\n",
    "    showlegend=False,\n",
    "    title_text=\"Skewness test on small samples (n=60)\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214ca1cb",
   "metadata": {},
   "source": [
    "### One-sided alternatives\n",
    "\n",
    "If you have a **directional** question, you can use a one-sided test:\n",
    "- `greater`: “is it right-skewed?” (skewness > 0)\n",
    "- `less`: “is it left-skewed?” (skewness < 0)\n",
    "\n",
    "One-sided p-values are smaller *only* when the observed skew is in the hypothesized direction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff58cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rng.exponential(1.0, size=60)\n",
    "\n",
    "res_two = dagostino_skewtest(x, alternative=\"two-sided\")\n",
    "res_greater = dagostino_skewtest(x, alternative=\"greater\")\n",
    "res_less = dagostino_skewtest(x, alternative=\"less\")\n",
    "\n",
    "{\n",
    "    \"two-sided\": res_two,\n",
    "    \"greater\": res_greater,\n",
    "    \"less\": res_less,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a9ac8",
   "metadata": {},
   "source": [
    "## 6) Why sample size matters (p-value vs skewness)\n",
    "\n",
    "Because the test statistic is a *standardized* measure of skewness, larger samples make it easier to detect small asymmetries.\n",
    "\n",
    "The plot below shows the **two-sided p-value** as a function of sample skewness \\(b_2\\) for different \\(n\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc21c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_grid = np.linspace(-2.5, 2.5, 501)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for n in [10, 30, 100, 500]:\n",
    "    z_grid = dagostino_z_from_skewness(b2_grid, n=n)\n",
    "    p_grid = pvalue_from_z(z_grid, alternative=\"two-sided\")\n",
    "    fig.add_trace(go.Scatter(x=b2_grid, y=p_grid, mode=\"lines\", name=f\"n={n}\"))\n",
    "\n",
    "fig.add_hline(y=0.05, line_dash=\"dash\", line_color=\"black\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Two-sided p-value vs sample skewness (D'Agostino transform)\",\n",
    "    xaxis_title=\"sample skewness b2\",\n",
    "    yaxis_title=\"p-value\",\n",
    "    yaxis_type=\"log\",\n",
    "    height=420,\n",
    "    width=900,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c648198",
   "metadata": {},
   "source": [
    "## 7) Does Z really look standard normal under H0?\n",
    "\n",
    "Under the null (normal data), the transformed statistic \\(Z\\) is designed to be approximately \\(\\mathcal{N}(0,1)\\).\n",
    "\n",
    "We can sanity-check that with a small Monte Carlo simulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b3d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewness_vectorized(samples: np.ndarray) -> np.ndarray:\n",
    "    \"Vectorized skewness for samples shaped (n_sims, n).\"\n",
    "    samples = np.asarray(samples, dtype=float)\n",
    "    mean = samples.mean(axis=1, keepdims=True)\n",
    "    centered = samples - mean\n",
    "    m2 = np.mean(centered**2, axis=1)\n",
    "    m3 = np.mean(centered**3, axis=1)\n",
    "\n",
    "    out = np.zeros_like(m2)\n",
    "    mask = m2 > 0\n",
    "    out[mask] = m3[mask] / (m2[mask] ** 1.5)\n",
    "    out[~mask] = 0.0\n",
    "    return out\n",
    "\n",
    "\n",
    "n = 20\n",
    "n_sims = 10_000\n",
    "samples = rng.normal(0, 1, size=(n_sims, n))\n",
    "\n",
    "b2 = skewness_vectorized(samples)\n",
    "z = dagostino_z_from_skewness(b2, n=n)\n",
    "\n",
    "z_mean = float(np.mean(z))\n",
    "z_std = float(np.std(z, ddof=0))\n",
    "rejection_rate = float(np.mean(pvalue_from_z(z, alternative=\"two-sided\") < 0.05))\n",
    "\n",
    "{\"z_mean\": z_mean, \"z_std\": z_std, \"rejection_rate@0.05\": rejection_rate}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Z with a standard normal PDF overlay\n",
    "\n",
    "x_grid = np.linspace(-4, 4, 400)\n",
    "pdf = (1.0 / np.sqrt(2 * np.pi)) * np.exp(-0.5 * x_grid**2)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=z,\n",
    "        nbinsx=60,\n",
    "        histnorm=\"probability density\",\n",
    "        name=\"Simulated Z (H0: normal)\",\n",
    "        opacity=0.75,\n",
    "        marker=dict(line=dict(width=0)),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=x_grid, y=pdf, mode=\"lines\", name=\"N(0,1) PDF\", line=dict(color=\"black\")))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Under H0, Z is approximately N(0,1) (n={n}, sims={n_sims})\",\n",
    "    xaxis_title=\"Z\",\n",
    "    yaxis_title=\"density\",\n",
    "    height=420,\n",
    "    width=900,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b95650b",
   "metadata": {},
   "source": [
    "## 8) Practical notes and pitfalls\n",
    "\n",
    "- **Outliers can dominate**: skewness uses \\((x-\bar{x})^3\\). One extreme point can flip the conclusion.\n",
    "- **Statistical vs practical significance**: with large \\(n\\), tiny skewness can yield tiny p-values.\n",
    "- **Not a full normality test**: skewness ≈ 0 does not imply normality.\n",
    "- **Independence matters**: if observations are dependent (time series, clustered data), p-values can be misleading.\n",
    "- **Use visuals**: combine the test with histograms/QQ-plots and domain knowledge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97f9809",
   "metadata": {},
   "source": [
    "## 9) Optional: compare with SciPy\n",
    "\n",
    "If you have SciPy available, you can verify that the NumPy implementation matches `scipy.stats.skewtest`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb2e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rng.lognormal(mean=0.0, sigma=0.8, size=200)\n",
    "\n",
    "ours = dagostino_skewtest(x)\n",
    "\n",
    "try:\n",
    "    from scipy.stats import skewtest\n",
    "\n",
    "    scipy_res = skewtest(x)\n",
    "    comparison = {\n",
    "        \"ours\": ours,\n",
    "        \"scipy\": {\"z\": float(scipy_res.statistic), \"pvalue\": float(scipy_res.pvalue)},\n",
    "        \"abs_diff_z\": float(abs(ours[\"z\"] - scipy_res.statistic)),\n",
    "        \"abs_diff_p\": float(abs(ours[\"pvalue\"] - scipy_res.pvalue)),\n",
    "    }\n",
    "except Exception as e:\n",
    "    comparison = {\"ours\": ours, \"scipy\": None, \"error\": repr(e)}\n",
    "\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce3d335",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "1. Simulate data from a symmetric but heavy-tailed distribution (e.g. Student t) and see how often the skewness test rejects.\n",
    "2. Create a mixture of two normals with different means and observe how skewness changes.\n",
    "3. For a fixed skewness, increase \\(n\\) and see how quickly the p-value shrinks.\n",
    "\n",
    "## References\n",
    "- R. B. D'Agostino et al. (1990), *A suggestion for using powerful and informative tests of normality*\n",
    "- SciPy documentation for `scipy.stats.skewtest`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}