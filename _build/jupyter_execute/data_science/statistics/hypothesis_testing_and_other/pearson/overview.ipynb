{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c1211e4",
   "metadata": {},
   "source": [
    "# Pearson correlation test (Pearson's r)\n",
    "\n",
    "## Goals\n",
    "- Understand what **Pearson's correlation** measures (and what it does *not* measure).\n",
    "- Run the **hypothesis test** for correlation and interpret the result.\n",
    "- Implement Pearson's r and a **permutation-based p-value** using **NumPy only**.\n",
    "- Build intuition with **Plotly** visualizations (scatter, null distribution, sampling variability).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e0da45",
   "metadata": {},
   "source": [
    "## 1) What is it used for?\n",
    "\n",
    "Pearson's correlation coefficient **r** answers a very specific question:\n",
    "\n",
    "> **How strong is the *linear* relationship between two numeric variables?**\n",
    "\n",
    "Typical uses:\n",
    "- Quick **EDA**: is there a linear trend between `x` and `y`?\n",
    "- Feature screening: does a feature move linearly with the target?\n",
    "- Model diagnostics: do residuals correlate with a predictor?\n",
    "\n",
    "Common misuses / misconceptions:\n",
    "- **`r = 0` does *not* mean “no relationship”** (it means no *linear* relationship).\n",
    "- Correlation is **not causation**.\n",
    "- Pearson r can be **very sensitive to outliers**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d450b78",
   "metadata": {},
   "source": [
    "## 2) The hypothesis test (what are we testing?)\n",
    "\n",
    "Let \\(\\rho\\) be the **population** correlation between random variables \\(X\\) and \\(Y\\).\n",
    "\n",
    "A standard Pearson correlation test (most common form):\n",
    "- **Null**: \\(H_0: \\rho = 0\\)  (no *linear* association)\n",
    "- **Alternative**:\n",
    "  - two-sided: \\(H_1: \\rho \\neq 0\\)\n",
    "  - one-sided: \\(H_1: \\rho > 0\\) or \\(H_1: \\rho < 0\\)\n",
    "\n",
    "### What does rejecting \\(H_0\\) mean?\n",
    "It means your sample provides **evidence of a non-zero linear association**.\n",
    "\n",
    "It does **not** automatically mean:\n",
    "- the relationship is strong (effect size can be tiny but “significant” with large `n`)\n",
    "- the relationship is causal\n",
    "- the relationship is linear everywhere or stable over time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671814fa",
   "metadata": {},
   "source": [
    "## 3) Assumptions (and why a permutation test is useful)\n",
    "\n",
    "The classic parametric Pearson test relies on a model where \\((X, Y)\\) is **approximately bivariate normal** (or at least well-behaved) so that a t-statistic has a known reference distribution.\n",
    "\n",
    "A **permutation test** provides an alternative that is often easier to reason about:\n",
    "- Under the null of **no association**, the pairing between `x` and `y` is arbitrary.\n",
    "- If we **shuffle** `y` many times and recompute `r`, we get a **null distribution**.\n",
    "- The p-value is the fraction of shuffles that produce a correlation as extreme as the observed one.\n",
    "\n",
    "This permutation approach is:\n",
    "- **NumPy-only** and conceptually direct\n",
    "- valid under **exchangeability** (roughly: the pairs are i.i.d. and shuffling breaks any real association)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b6b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Optional: SciPy for the classic parametric p-value (not required for the NumPy-only permutation test)\n",
    "try:\n",
    "    from scipy import stats\n",
    "except Exception:\n",
    "    stats = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb7fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_r(x, y):\n",
    "    x = np.asarray(x, dtype=float).ravel()\n",
    "    y = np.asarray(y, dtype=float).ravel()\n",
    "\n",
    "    if x.shape != y.shape:\n",
    "        raise ValueError(f\"x and y must have the same shape; got {x.shape} vs {y.shape}\")\n",
    "    if x.size < 2:\n",
    "        raise ValueError(\"Need at least 2 paired observations\")\n",
    "\n",
    "    x_c = x - x.mean()\n",
    "    y_c = y - y.mean()\n",
    "\n",
    "    ssx = float(np.dot(x_c, x_c))\n",
    "    ssy = float(np.dot(y_c, y_c))\n",
    "    if ssx == 0.0 or ssy == 0.0:\n",
    "        raise ValueError(\"Correlation is undefined when one input is constant\")\n",
    "\n",
    "    return float(np.dot(x_c, y_c) / np.sqrt(ssx * ssy))\n",
    "\n",
    "\n",
    "def ols_line(x, y):\n",
    "    x = np.asarray(x, dtype=float).ravel()\n",
    "    y = np.asarray(y, dtype=float).ravel()\n",
    "\n",
    "    x_mean = x.mean()\n",
    "    y_mean = y.mean()\n",
    "\n",
    "    x_c = x - x_mean\n",
    "    denom = float(np.dot(x_c, x_c))\n",
    "    if denom == 0.0:\n",
    "        raise ValueError(\"Cannot fit a line when x is constant\")\n",
    "\n",
    "    b = float(np.dot(x_c, y - y_mean) / denom)\n",
    "    a = float(y_mean - b * x_mean)\n",
    "    return a, b\n",
    "\n",
    "\n",
    "def pearson_t_stat(r, n):\n",
    "    if n < 3:\n",
    "        raise ValueError(\"Need n >= 3 for the t statistic\")\n",
    "    r = float(r)\n",
    "    if abs(r) >= 1.0:\n",
    "        return np.inf * np.sign(r)\n",
    "    return r * np.sqrt((n - 2) / (1 - r**2))\n",
    "\n",
    "\n",
    "def pearson_p_value_parametric(r, n, alternative=\"two-sided\"):\n",
    "    if stats is None:\n",
    "        raise RuntimeError(\"SciPy is not available; use the permutation test below instead\")\n",
    "\n",
    "    t = pearson_t_stat(r, n)\n",
    "    df = n - 2\n",
    "\n",
    "    if alternative == \"two-sided\":\n",
    "        return float(2 * stats.t.sf(abs(t), df))\n",
    "    if alternative == \"greater\":\n",
    "        return float(stats.t.sf(t, df))\n",
    "    if alternative == \"less\":\n",
    "        return float(stats.t.cdf(t, df))\n",
    "    raise ValueError(\"alternative must be 'two-sided', 'greater', or 'less'\")\n",
    "\n",
    "\n",
    "def pearson_p_value_permutation(x, y, n_perm=10_000, alternative=\"two-sided\", rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    x = np.asarray(x, dtype=float).ravel()\n",
    "    y = np.asarray(y, dtype=float).ravel()\n",
    "    if x.shape != y.shape:\n",
    "        raise ValueError(\"x and y must have the same shape\")\n",
    "\n",
    "    r_obs = pearson_r(x, y)\n",
    "\n",
    "    r_perm = np.empty(int(n_perm), dtype=float)\n",
    "    for i in range(r_perm.size):\n",
    "        r_perm[i] = pearson_r(x, rng.permutation(y))\n",
    "\n",
    "    if alternative == \"two-sided\":\n",
    "        extreme = np.abs(r_perm) >= abs(r_obs)\n",
    "    elif alternative == \"greater\":\n",
    "        extreme = r_perm >= r_obs\n",
    "    elif alternative == \"less\":\n",
    "        extreme = r_perm <= r_obs\n",
    "    else:\n",
    "        raise ValueError(\"alternative must be 'two-sided', 'greater', or 'less'\")\n",
    "\n",
    "    p = float((extreme.sum() + 1) / (r_perm.size + 1))\n",
    "    return r_obs, p, r_perm\n",
    "\n",
    "\n",
    "def bootstrap_ci_r(x, y, n_boot=5_000, ci=0.95, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    x = np.asarray(x, dtype=float).ravel()\n",
    "    y = np.asarray(y, dtype=float).ravel()\n",
    "    if x.shape != y.shape:\n",
    "        raise ValueError(\"x and y must have the same shape\")\n",
    "\n",
    "    n = x.size\n",
    "    if n < 2:\n",
    "        raise ValueError(\"Need at least 2 paired observations\")\n",
    "\n",
    "    idx = rng.integers(0, n, size=(int(n_boot), n))\n",
    "    xb = x[idx]\n",
    "    yb = y[idx]\n",
    "\n",
    "    xb_c = xb - xb.mean(axis=1, keepdims=True)\n",
    "    yb_c = yb - yb.mean(axis=1, keepdims=True)\n",
    "\n",
    "    num = np.sum(xb_c * yb_c, axis=1)\n",
    "    den = np.sqrt(np.sum(xb_c**2, axis=1) * np.sum(yb_c**2, axis=1))\n",
    "    r_boot = num / den\n",
    "\n",
    "    alpha = (1 - ci) / 2\n",
    "    lo, hi = np.quantile(r_boot, [alpha, 1 - alpha])\n",
    "    return float(lo), float(hi), r_boot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848e34db",
   "metadata": {},
   "source": [
    "## 4) Example: compute r and visualize the linear relationship\n",
    "\n",
    "We'll generate a simple synthetic dataset with a positive linear relationship plus noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a4c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 80\n",
    "x = rng.normal(0, 1, size=n)\n",
    "y = 0.9 * x + rng.normal(0, 1.2, size=n)\n",
    "\n",
    "r_obs = pearson_r(x, y)\n",
    "a, b = ols_line(x, y)\n",
    "\n",
    "x_grid = np.linspace(x.min(), x.max(), 200)\n",
    "y_hat = a + b * x_grid\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y, mode=\"markers\", name=\"data\", marker=dict(size=9, opacity=0.8)))\n",
    "fig.add_trace(go.Scatter(x=x_grid, y=y_hat, mode=\"lines\", name=\"OLS fit\", line=dict(width=3)))\n",
    "fig.update_layout(\n",
    "    title=f\"Scatter plot with fitted line (Pearson r = {r_obs:.3f})\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"y\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e1b518",
   "metadata": {},
   "source": [
    "### Interpreting r\n",
    "\n",
    "- **Sign**: `r > 0` means `y` tends to increase when `x` increases; `r < 0` means the opposite.\n",
    "- **Magnitude**: `|r|` closer to 1 means points lie closer to a straight line.\n",
    "\n",
    "A useful identity:\n",
    "\n",
    "\\[ r = \\frac{\\operatorname{cov}(x,y)}{\\operatorname{sd}(x)\\,\\operatorname{sd}(y)} \\]\n",
    "\n",
    "So Pearson r is a **standardized covariance**:\n",
    "- invariant to shifting and scaling of either variable\n",
    "- sensitive to outliers (because covariance is)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75479e8",
   "metadata": {},
   "source": [
    "## 5) Running the hypothesis test\n",
    "\n",
    "We'll compute a p-value in two ways:\n",
    "1. **Permutation test** (NumPy only) — our low-level, assumption-light implementation.\n",
    "2. **Parametric t-test** (optional, via SciPy) — the classical Pearson correlation test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2566c40",
   "metadata": {},
   "source": [
    "### Classic parametric Pearson test (t distribution)\n",
    "\n",
    "For paired observations \\\\n\\((x_i, y_i)\\) and sample size \\\n",
    "\\(n\\), compute the sample correlation \\\n",
    "\\(r\\). Under the classical assumptions (especially approximate bivariate normality) and \\\n",
    "\\(H_0: \\\r",
    "ho = 0\\), the test statistic\n",
    "\n",
    "\\[ t = r \\sqrt{\\frac{n-2}{1-r^2}} \\]\\n\n",
    "has a Student t distribution with \\\n",
    "\\(n-2\\) degrees of freedom.\n",
    "\n",
    "- two-sided: \\\n",
    "\\(p = 2\\,P(T_{n-2} \\ge |t|)\\)\n",
    "- one-sided: use the appropriate tail depending on \\\n",
    "\\(H_1\\)\n",
    "\n",
    "We include this mainly for interpretation and for cross-checking against libraries; the NumPy-only permutation test above does not require this reference distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22f721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "r_obs, p_perm, r_perm = pearson_p_value_permutation(x, y, n_perm=20_000, alternative=\"two-sided\", rng=rng)\n",
    "print(f\"Observed r = {r_obs:.4f}\")\n",
    "print(f\"Permutation p-value (two-sided) = {p_perm:.4g}\")\n",
    "\n",
    "if stats is not None:\n",
    "    p_param = pearson_p_value_parametric(r_obs, n=x.size, alternative=\"two-sided\")\n",
    "    t_stat = pearson_t_stat(r_obs, n=x.size)\n",
    "    print(f\"t statistic = {t_stat:.4f} (df={x.size-2})\")\n",
    "    print(f\"Parametric p-value (two-sided) = {p_param:.4g}\")\n",
    "else:\n",
    "    print(\"SciPy not available: skipping parametric p-value\")\n",
    "\n",
    "print(f\"Decision at alpha={alpha}: {'reject H0' if p_perm < alpha else 'fail to reject H0'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72042c39",
   "metadata": {},
   "source": [
    "### Visual: permutation null distribution\n",
    "\n",
    "Under the null (no association), shuffled pairings should produce correlations near 0.\n",
    "The p-value is the fraction of shuffled correlations that are at least as extreme as the observed one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3dd5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = abs(r_obs)\n",
    "mask_extreme = np.abs(r_perm) >= thr\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=r_perm,\n",
    "        nbinsx=60,\n",
    "        name=\"permuted r (null)\",\n",
    "        marker=dict(color=\"rgba(120,120,120,0.6)\"),\n",
    "        histnorm=\"probability density\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=r_perm[mask_extreme],\n",
    "        nbinsx=60,\n",
    "        name=f\"|r| >= {thr:.3f} (counts toward p)\",\n",
    "        marker=dict(color=\"rgba(220,0,0,0.65)\"),\n",
    "        histnorm=\"probability density\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_vline(x=r_obs, line_width=3, line_color=\"black\")\n",
    "fig.add_vline(x=-r_obs, line_width=3, line_color=\"black\", line_dash=\"dash\")\n",
    "fig.update_layout(\n",
    "    barmode=\"overlay\",\n",
    "    title=f\"Permutation null distribution (p ≈ {p_perm:.4g})\",\n",
    "    xaxis_title=\"Pearson r under H0 (shuffled)\",\n",
    "    yaxis_title=\"density\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e586ac",
   "metadata": {},
   "source": [
    "### What the p-value means (and doesn't mean)\n",
    "\n",
    "A (two-sided) p-value answers:\n",
    "\n",
    "> If \\(\\rho = 0\\) (no linear association), how often would we see a sample correlation at least as extreme as the one we observed?\n",
    "\n",
    "It is **not**:\n",
    "- the probability that \\(H_0\\) is true\n",
    "- the probability that the relationship is “real”\n",
    "- a measure of effect size (that is `r` itself)\n",
    "\n",
    "A good report includes **both**:\n",
    "- effect size: `r`\n",
    "- uncertainty: CI and/or p-value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7129fcb7",
   "metadata": {},
   "source": [
    "## 6) Confidence intervals (uncertainty on the effect size)\n",
    "\n",
    "A p-value tells you about compatibility with \\(\\rho = 0\\). A confidence interval tells you a range of plausible \\(\\rho\\) values.\n",
    "\n",
    "We'll compute a **bootstrap percentile CI** for `r` by resampling the paired observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99abea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, hi, r_boot = bootstrap_ci_r(x, y, n_boot=8_000, ci=0.95, rng=rng)\n",
    "print(f\"Bootstrap 95% CI for r: [{lo:.3f}, {hi:.3f}]\")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=r_boot, nbinsx=60, histnorm=\"probability density\", name=\"bootstrap r\"))\n",
    "fig.add_vline(x=r_obs, line_width=3, line_color=\"black\")\n",
    "fig.add_vline(x=lo, line_width=3, line_color=\"green\")\n",
    "fig.add_vline(x=hi, line_width=3, line_color=\"green\")\n",
    "fig.update_layout(\n",
    "    title=\"Bootstrap distribution of r with 95% CI\",\n",
    "    xaxis_title=\"bootstrap Pearson r\",\n",
    "    yaxis_title=\"density\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f74f844",
   "metadata": {},
   "source": [
    "## 7) Pitfall: outliers can dominate Pearson r\n",
    "\n",
    "Because Pearson r is based on means, variances, and covariance, a single extreme point can strongly change it.\n",
    "\n",
    "We'll compare the same dataset **with and without** one high-leverage outlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddefe129",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = rng.normal(0, 1, size=40)\n",
    "y0 = 0.5 * x0 + rng.normal(0, 1, size=40)\n",
    "\n",
    "r0 = pearson_r(x0, y0)\n",
    "\n",
    "# Add one outlier\n",
    "x1 = np.append(x0, 8.0)\n",
    "y1 = np.append(y0, -8.0)\n",
    "\n",
    "r1 = pearson_r(x1, y1)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(f\"No outlier (r={r0:.3f})\", f\"With outlier (r={r1:.3f})\"))\n",
    "fig.add_trace(go.Scatter(x=x0, y=y0, mode=\"markers\", marker=dict(size=9, opacity=0.8), showlegend=False), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=x1, y=y1, mode=\"markers\", marker=dict(size=9, opacity=0.8), showlegend=False), row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"x\")\n",
    "fig.update_yaxes(title_text=\"y\")\n",
    "fig.update_layout(title=\"A single point can change correlation a lot\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39321093",
   "metadata": {},
   "source": [
    "## 8) Pitfall: a strong relationship can have r ≈ 0 (nonlinear patterns)\n",
    "\n",
    "Pearson r measures **linear** association.\n",
    "\n",
    "Example: if `y = x^2` and `x` is symmetric around 0, the relationship is strong but **not linear**, and Pearson r can be close to 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164efda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nl = rng.uniform(-2.5, 2.5, size=200)\n",
    "y_nl = x_nl**2 + rng.normal(0, 0.2, size=x_nl.size)\n",
    "\n",
    "r_nl = pearson_r(x_nl, y_nl)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x_nl, y=y_nl, mode=\"markers\", marker=dict(size=7, opacity=0.7)))\n",
    "fig.update_layout(\n",
    "    title=f\"Nonlinear relationship (Pearson r = {r_nl:.3f} can be misleading)\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"y\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2449fc7",
   "metadata": {},
   "source": [
    "## 9) Sampling variability: r depends on n\n",
    "\n",
    "Even if the true correlation is \\(\\rho = 0\\), sample correlations won't be exactly 0.\n",
    "As `n` increases, the sampling distribution of `r` tightens around the true value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3668bfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_r_under_rho(rho, n, n_sims=4000, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    z1 = rng.normal(size=(n_sims, n))\n",
    "    z2 = rng.normal(size=(n_sims, n))\n",
    "    x = z1\n",
    "    y = rho * z1 + np.sqrt(1 - rho**2) * z2\n",
    "\n",
    "    x_c = x - x.mean(axis=1, keepdims=True)\n",
    "    y_c = y - y.mean(axis=1, keepdims=True)\n",
    "    num = np.sum(x_c * y_c, axis=1)\n",
    "    den = np.sqrt(np.sum(x_c**2, axis=1) * np.sum(y_c**2, axis=1))\n",
    "    return num / den\n",
    "\n",
    "rho = 0.0\n",
    "r_n20 = simulate_r_under_rho(rho, n=20, n_sims=4000, rng=rng)\n",
    "r_n80 = simulate_r_under_rho(rho, n=80, n_sims=4000, rng=rng)\n",
    "r_n300 = simulate_r_under_rho(rho, n=300, n_sims=4000, rng=rng)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Violin(y=r_n20, name=\"n=20\", box_visible=True, meanline_visible=True))\n",
    "fig.add_trace(go.Violin(y=r_n80, name=\"n=80\", box_visible=True, meanline_visible=True))\n",
    "fig.add_trace(go.Violin(y=r_n300, name=\"n=300\", box_visible=True, meanline_visible=True))\n",
    "fig.update_layout(\n",
    "    title=\"Sampling distribution of r when true rho = 0\",\n",
    "    yaxis_title=\"sample Pearson r\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fd022c",
   "metadata": {},
   "source": [
    "## 10) How to report and interpret results\n",
    "\n",
    "A good report includes:\n",
    "- `n` (sample size)\n",
    "- `r` (effect size)\n",
    "- a confidence interval for \\(\r",
    "ho\\) (recommended)\n",
    "- p-value and the alternative hypothesis\n",
    "\n",
    "Example phrasing:\n",
    "\n",
    "> “We found a positive linear association between X and Y (Pearson r = 0.42, 95% bootstrap CI [0.20, 0.60], permutation p = 0.003, n = 80).”\n",
    "\n",
    "### Interpretation checklist\n",
    "- Is the association **linear** (check a scatter plot)?\n",
    "- Are there **outliers** or clusters driving the correlation?\n",
    "- Is the result **practically meaningful** (not just statistically significant)?\n",
    "- Could a **confounder** explain both variables?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e92ea3",
   "metadata": {},
   "source": [
    "## 11) Practical usage (SciPy)\n",
    "\n",
    "If SciPy is available, `scipy.stats.pearsonr` computes:\n",
    "- Pearson r\n",
    "- the classical (parametric) p-value under the t-test reference distribution\n",
    "\n",
    "We'll compare it to our NumPy computations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016af96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if stats is None:\n",
    "    print(\"SciPy not available\")\n",
    "else:\n",
    "    r_scipy, p_scipy = stats.pearsonr(x, y)\n",
    "    print(f\"SciPy pearsonr: r={r_scipy:.4f}, p={p_scipy:.4g}\")\n",
    "    print(f\"NumPy pearson_r: r={pearson_r(x, y):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35141170",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Create a dataset where Pearson r is near 0 but there is a strong nonlinear relationship. Plot it.\n",
    "2. Simulate correlated data for \\(\r",
    "ho\\in\\{0, 0.2, 0.5\\}\\) and compare how often you reject \\(H_0\\) at `alpha=0.05` as `n` increases.\n",
    "3. Add a single outlier to a moderately correlated dataset and measure how much `r` changes.\n",
    "4. Implement **Spearman** correlation (rank-based) using NumPy and compare it on the nonlinear example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cf17ca",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Student's t relationship for Pearson correlation: standard results in most mathematical statistics texts.\n",
    "- Permutation tests / randomization tests: Fisher (1935), Good (2005), and many modern applied stats resources.\n",
    "- SciPy documentation: `scipy.stats.pearsonr`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}