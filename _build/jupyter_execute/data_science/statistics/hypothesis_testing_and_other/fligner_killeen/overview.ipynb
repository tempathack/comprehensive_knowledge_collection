{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de497d2",
   "metadata": {},
   "source": [
    "# Fligner–Killeen Test (robust test for equal variances)\n",
    "\n",
    "The **Fligner–Killeen test** checks whether multiple groups share the same variance (homoscedasticity).\n",
    "It is a **rank-based, median-centered** test designed to stay reliable when data are **non-normal** or contain **outliers**.\n",
    "\n",
    "## Goals\n",
    "- Understand the hypotheses and interpretation (`H0`: equal variances).\n",
    "- Build intuition from *absolute deviations* and *ranks*.\n",
    "- Implement the test statistic **from scratch with NumPy** (no stats libraries).\n",
    "- Use Plotly visuals + simulations to see *what the statistic is measuring*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1572a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc0dbc1",
   "metadata": {},
   "source": [
    "## 1) What question does the test answer?\n",
    "\n",
    "You have **k independent groups** (e.g., treatments, machines, cohorts) and want to know:\n",
    "\n",
    "- Are some groups **more variable** (more spread out) than others?\n",
    "\n",
    "Formally, the hypotheses are:\n",
    "\n",
    "\\begin{aligned}\n",
    "H_0 &: \\sigma_1^2 = \\sigma_2^2 = \\dots = \\sigma_k^2 \\\\\n",
    "H_1 &: \\text{at least one variance differs}\n",
    "\\end{aligned}\n",
    "\n",
    "The test returns a **single p-value**.\n",
    "\n",
    "- Small p-value → evidence that **variances are not all equal**.\n",
    "- Large p-value → **not enough evidence** to say variances differ (this is *not* proof they are equal).\n",
    "\n",
    "Why this matters:\n",
    "\n",
    "- Many models/analyses (e.g., **one-way ANOVA**, some regression diagnostics) assume equal variances.\n",
    "- In practice, data often violate normality; Fligner–Killeen is popular because it’s **robust**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726b4657",
   "metadata": {},
   "source": [
    "## 2) Intuition: compare “how far from typical” each group is\n",
    "\n",
    "If a group has larger variance, its observations tend to sit **farther away** from a typical value.\n",
    "\n",
    "Fligner–Killeen makes this idea robust:\n",
    "\n",
    "1. **Center each group** by its median (robust “typical value”).\n",
    "2. Look at **absolute deviations** from that median.\n",
    "3. Replace deviations by their **ranks** across all groups (robust to outliers).\n",
    "4. Convert ranks to **half-normal scores** (so the final statistic has a chi-square reference).\n",
    "\n",
    "Let’s build intuition on a heavy-tailed example (Student-t), with one group having a larger scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5721999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data: heavy-tailed (t distribution), with a location shift in group B\n",
    "n = 70\n",
    "df_t = 3\n",
    "\n",
    "gA = rng.standard_t(df=df_t, size=n) * 1.0 + 0.0\n",
    "gB = rng.standard_t(df=df_t, size=n) * 1.0 + 0.6  # location shift only\n",
    "gC = rng.standard_t(df=df_t, size=n) * 2.0 + 0.0  # larger scale (variance)\n",
    "\n",
    "groups = [gA, gB, gC]\n",
    "group_names = np.array([\"A\", \"B\", \"C\"])\n",
    "\n",
    "\n",
    "def mad(x: np.ndarray) -> float:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    m = np.median(x)\n",
    "    return float(np.median(np.abs(x - m)))\n",
    "\n",
    "\n",
    "for name, g in zip(group_names, groups):\n",
    "    print(\n",
    "        f\"{name}: n={len(g):d}, mean={g.mean(): .3f}, median={np.median(g): .3f}, \"\n",
    "        f\"std={g.std(ddof=1): .3f}, MAD={mad(g): .3f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f79651",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate(groups)\n",
    "labels = np.concatenate([np.full(len(g), name) for g, name in zip(groups, group_names)])\n",
    "\n",
    "fig = px.violin(\n",
    "    x=labels,\n",
    "    y=x,\n",
    "    color=labels,\n",
    "    box=True,\n",
    "    points=\"all\",\n",
    "    title=\"Raw data by group (B is shifted; C has larger scale)\",\n",
    ")\n",
    "fig.update_layout(xaxis_title=\"Group\", yaxis_title=\"Value\", legend_title_text=\"Group\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97f1297",
   "metadata": {},
   "source": [
    "## 3) Step 1: absolute deviations from each group’s center\n",
    "\n",
    "For group *i* and observation *j*:\n",
    "\n",
    "\\[\n",
    "Z_{ij} = |X_{ij} - c_i|\n",
    "\\]\n",
    "\n",
    "where the default Fligner–Killeen choice is:\n",
    "\n",
    "\\[\n",
    "c_i = \\text{median}(X_{i1}, \\dots, X_{in_i}).\n",
    "\\]\n",
    "\n",
    "If group variances are equal, the **distribution** of these deviations should be similar across groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cfc04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(groups)\n",
    "group_ids = np.concatenate([np.full(len(g), i) for i, g in enumerate(groups)])\n",
    "\n",
    "centers = np.array([np.median(g) for g in groups])\n",
    "z = np.abs(x - centers[group_ids])\n",
    "\n",
    "fig = px.box(\n",
    "    x=labels,\n",
    "    y=z,\n",
    "    color=labels,\n",
    "    points=\"all\",\n",
    "    title=\"Absolute deviations from each group median\",\n",
    ")\n",
    "fig.update_layout(xaxis_title=\"Group\", yaxis_title=\"|x - median(group)|\", legend_title_text=\"Group\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda39fc",
   "metadata": {},
   "source": [
    "## 4) Step 2: rank the deviations (robustness)\n",
    "\n",
    "Outliers can wildly inflate sample variances.\n",
    "To reduce sensitivity to tails, Fligner–Killeen replaces deviations by their **ranks** across *all* groups.\n",
    "\n",
    "- Small deviations → small ranks\n",
    "- Large deviations → large ranks\n",
    "\n",
    "Ties (identical deviations) get **average ranks**.\n",
    "\n",
    "We’ll implement `rankdata` ourselves with NumPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankdata_average(a: np.ndarray) -> np.ndarray:\n",
    "    # Average ranks for ties (like scipy.stats.rankdata(method='average'))\n",
    "    a = np.asarray(a)\n",
    "    if a.ndim != 1:\n",
    "        a = a.ravel()\n",
    "\n",
    "    sorter = np.argsort(a, kind=\"mergesort\")\n",
    "    a_sorted = a[sorter]\n",
    "\n",
    "    # Boundaries between distinct values\n",
    "    distinct = np.r_[True, a_sorted[1:] != a_sorted[:-1], True]\n",
    "    idx = np.flatnonzero(distinct)\n",
    "\n",
    "    ranks_sorted = np.empty_like(a_sorted, dtype=float)\n",
    "    for start, end in zip(idx[:-1], idx[1:]):\n",
    "        # ranks are 1..n; tie block gets the average rank\n",
    "        ranks_sorted[start:end] = 0.5 * (start + end - 1) + 1.0\n",
    "\n",
    "    ranks = np.empty_like(ranks_sorted)\n",
    "    ranks[sorter] = ranks_sorted\n",
    "    return ranks\n",
    "\n",
    "\n",
    "ex = np.array([10, 20, 20, 40])\n",
    "print(\"values:\", ex)\n",
    "print(\"ranks :\", rankdata_average(ex))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff13ca7",
   "metadata": {},
   "source": [
    "## 5) Step 3: convert ranks to *half-normal scores*\n",
    "\n",
    "Fligner–Killeen maps ranks to **expected order statistics** of \\(|N(0,1)|\\) (a half-normal distribution).\n",
    "\n",
    "If \\(U \\sim \\mathrm{Unif}(0,1)\\), then:\n",
    "\n",
    "\\[\n",
    "|Z| \\stackrel{d}{=} \\Phi^{-1}\\left(\\tfrac{1}{2} + \\tfrac{U}{2}\\right)\n",
    "\\]\n",
    "\n",
    "where \\(\\Phi^{-1}\\) is the standard normal quantile function.\n",
    "\n",
    "Using ranks \\(R_{ij}\\in\\{1,\\dots,N\\}\\) (with \\(N\\) total samples), we set:\n",
    "\n",
    "\\[\n",
    "A_{ij} = \\Phi^{-1}\\left(\\tfrac{1}{2} + \\tfrac{R_{ij}}{2(N+1)}\\right)\n",
    "\\]\n",
    "\n",
    "so all scores are **nonnegative** (matching deviations).\n",
    "\n",
    "Below is a standard rational approximation for \\(\\Phi^{-1}\\) (Acklam’s approximation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2897dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_ppf(p: np.ndarray) -> np.ndarray:\n",
    "    # Approx inverse-CDF (ppf) of N(0,1) using Acklam's rational approximation\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    eps = np.finfo(float).eps\n",
    "    p = np.clip(p, eps, 1.0 - eps)\n",
    "\n",
    "    # Coefficients in rational approximations\n",
    "    a = np.array([\n",
    "        -3.969683028665376e01,\n",
    "        2.209460984245205e02,\n",
    "        -2.759285104469687e02,\n",
    "        1.383577518672690e02,\n",
    "        -3.066479806614716e01,\n",
    "        2.506628277459239e00,\n",
    "    ])\n",
    "    b = np.array([\n",
    "        -5.447609879822406e01,\n",
    "        1.615858368580409e02,\n",
    "        -1.556989798598866e02,\n",
    "        6.680131188771972e01,\n",
    "        -1.328068155288572e01,\n",
    "    ])\n",
    "    c = np.array([\n",
    "        -7.784894002430293e-03,\n",
    "        -3.223964580411365e-01,\n",
    "        -2.400758277161838e00,\n",
    "        -2.549732539343734e00,\n",
    "        4.374664141464968e00,\n",
    "        2.938163982698783e00,\n",
    "    ])\n",
    "    d = np.array([\n",
    "        7.784695709041462e-03,\n",
    "        3.224671290700398e-01,\n",
    "        2.445134137142996e00,\n",
    "        3.754408661907416e00,\n",
    "    ])\n",
    "\n",
    "    plow = 0.02425\n",
    "    phigh = 1.0 - plow\n",
    "\n",
    "    x = np.empty_like(p)\n",
    "\n",
    "    # Lower region\n",
    "    mask = p < plow\n",
    "    if np.any(mask):\n",
    "        q = np.sqrt(-2.0 * np.log(p[mask]))\n",
    "        x[mask] = (\n",
    "            (((((c[0] * q + c[1]) * q + c[2]) * q + c[3]) * q + c[4]) * q + c[5])\n",
    "            /\n",
    "            ((((d[0] * q + d[1]) * q + d[2]) * q + d[3]) * q + 1.0)\n",
    "        )\n",
    "\n",
    "    # Upper region\n",
    "    mask = p > phigh\n",
    "    if np.any(mask):\n",
    "        q = np.sqrt(-2.0 * np.log(1.0 - p[mask]))\n",
    "        x[mask] = -(\n",
    "            (((((c[0] * q + c[1]) * q + c[2]) * q + c[3]) * q + c[4]) * q + c[5])\n",
    "            /\n",
    "            ((((d[0] * q + d[1]) * q + d[2]) * q + d[3]) * q + 1.0)\n",
    "        )\n",
    "\n",
    "    # Central region\n",
    "    mask = (~(p < plow)) & (~(p > phigh))\n",
    "    if np.any(mask):\n",
    "        q = p[mask] - 0.5\n",
    "        r = q * q\n",
    "        x[mask] = (\n",
    "            (((((a[0] * r + a[1]) * r + a[2]) * r + a[3]) * r + a[4]) * r + a[5]) * q\n",
    "            /\n",
    "            (((((b[0] * r + b[1]) * r + b[2]) * r + b[3]) * r + b[4]) * r + 1.0)\n",
    "        )\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "ps = np.array([1e-4, 1e-2, 0.5, 0.99, 0.9999])\n",
    "print(\"p:\", ps)\n",
    "print(\"ppf(p):\", norm_ppf(ps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5acc6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = rankdata_average(z)\n",
    "N = len(z)\n",
    "\n",
    "# Half-normal scores (match the classic Fligner–Killeen definition)\n",
    "u = ranks / (N + 1.0)\n",
    "a = norm_ppf(0.5 + 0.5 * u)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=z, y=a, mode=\"markers\", marker=dict(size=6, opacity=0.5)))\n",
    "fig.update_layout(\n",
    "    title=\"Deviation size vs half-normal score (after ranking)\",\n",
    "    xaxis_title=\"Absolute deviation |x - median(group)|\",\n",
    "    yaxis_title=\"Score  Φ⁻¹(0.5 + rank/(2(N+1)))\",\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.box(\n",
    "    x=labels,\n",
    "    y=a,\n",
    "    color=labels,\n",
    "    points=\"all\",\n",
    "    title=\"Half-normal scores by group (differences reflect scale differences)\",\n",
    ")\n",
    "fig.update_layout(xaxis_title=\"Group\", yaxis_title=\"Half-normal score\", legend_title_text=\"Group\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db8eb5",
   "metadata": {},
   "source": [
    "## 6) The Fligner–Killeen statistic\n",
    "\n",
    "Once we have the scores \\(A_{ij}\\), the test becomes a one-way “ANOVA on scores”:\n",
    "\n",
    "- Let \\(\\bar{A}_i\\) be the mean score within group *i*.\n",
    "- Let \\(\\bar{A}\\) be the overall mean score.\n",
    "\n",
    "The statistic is\n",
    "\n",
    "\\[\n",
    "T = \\frac{\\sum_{i=1}^k n_i(\\bar{A}_i - \\bar{A})^2}{s_A^2}\n",
    "\\]\n",
    "\n",
    "where \\(s_A^2\\) is the sample variance of all scores (ddof=1).\n",
    "\n",
    "Under \\(H_0\\), \\(T\\) is approximately\n",
    "\n",
    "\\[\n",
    "T \\sim \\chi^2_{k-1}.\n",
    "\\]\n",
    "\n",
    "We’ll implement the statistic with NumPy, then (later) validate against SciPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2545c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fligner_killeen_statistic(*samples: np.ndarray, center: str = \"median\") -> tuple[float, int]:\n",
    "    # Fligner–Killeen test statistic (NumPy-only implementation)\n",
    "    if len(samples) < 2:\n",
    "        raise ValueError(\"Need at least two groups.\")\n",
    "    if center not in {\"median\", \"mean\"}:\n",
    "        raise ValueError(\"center must be 'median' or 'mean'.\")\n",
    "\n",
    "    cleaned = []\n",
    "    for s in samples:\n",
    "        s = np.asarray(s, dtype=float).ravel()\n",
    "        s = s[~np.isnan(s)]\n",
    "        if s.size == 0:\n",
    "            raise ValueError(\"Groups must be non-empty after removing NaNs.\")\n",
    "        cleaned.append(s)\n",
    "\n",
    "    k = len(cleaned)\n",
    "    ni = np.array([len(s) for s in cleaned], dtype=int)\n",
    "    if np.any(ni < 2):\n",
    "        raise ValueError(\"Each group should contain at least 2 observations.\")\n",
    "\n",
    "    x_all = np.concatenate(cleaned)\n",
    "    group_ids = np.concatenate([np.full(len(s), i, dtype=int) for i, s in enumerate(cleaned)])\n",
    "\n",
    "    if center == \"median\":\n",
    "        centers = np.array([np.median(s) for s in cleaned])\n",
    "    else:\n",
    "        centers = np.array([np.mean(s) for s in cleaned])\n",
    "\n",
    "    z = np.abs(x_all - centers[group_ids])\n",
    "    ranks = rankdata_average(z)\n",
    "    N = len(z)\n",
    "\n",
    "    # Half-normal scores\n",
    "    u = ranks / (N + 1.0)\n",
    "    a = norm_ppf(0.5 + 0.5 * u)\n",
    "\n",
    "    # Group mean scores\n",
    "    a_bar = float(np.mean(a))\n",
    "    a_bar_i = np.array([np.mean(a[group_ids == i]) for i in range(k)])\n",
    "\n",
    "    varsq = float(np.var(a, ddof=1))\n",
    "    statistic = float(np.sum(ni * (a_bar_i - a_bar) ** 2) / varsq)\n",
    "    df = k - 1\n",
    "    return statistic, df\n",
    "\n",
    "\n",
    "stat_fk, df_fk = fligner_killeen_statistic(gA, gB, gC, center=\"median\")\n",
    "print(f\"Fligner–Killeen statistic = {stat_fk:.4f} (df={df_fk})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14214be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_cdf_scalar(x: float) -> float:\n",
    "    return 0.5 * (1.0 + math.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "\n",
    "def chi2_sf_wilson_hilferty(x: float, df: int) -> float:\n",
    "    # Approximate chi-square survival function using the Wilson–Hilferty transform\n",
    "    v = float(df)\n",
    "    z = ((x / v) ** (1.0 / 3.0) - (1.0 - 2.0 / (9.0 * v))) / math.sqrt(2.0 / (9.0 * v))\n",
    "    return 1.0 - norm_cdf_scalar(z)\n",
    "\n",
    "\n",
    "p_approx = chi2_sf_wilson_hilferty(stat_fk, df_fk)\n",
    "print(f\"Approx p-value (Wilson–Hilferty) ≈ {p_approx:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678e96c4",
   "metadata": {},
   "source": [
    "## 7) How to interpret the result\n",
    "\n",
    "- If `p-value < α` (often α = 0.05): reject \\(H_0\\) → evidence that **not all group variances are equal**.\n",
    "- If `p-value ≥ α`: fail to reject \\(H_0\\) → the data do **not** provide strong evidence of different variances.\n",
    "\n",
    "Important nuances:\n",
    "\n",
    "- “Fail to reject” does *not* mean variances are equal; the test might have low power for small samples.\n",
    "- The test is **omnibus**: it doesn’t tell you *which* groups differ.\n",
    "  Use visuals and (optionally) pairwise follow-ups with multiplicity control.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e03439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A practical diagnostic: summarize group spread with a few robust + non-robust measures\n",
    "spread_names = [\"std\", \"IQR\", \"MAD (median abs dev)\"]\n",
    "spread = np.zeros((len(groups), len(spread_names)))\n",
    "\n",
    "for i, g in enumerate(groups):\n",
    "    spread[i, 0] = np.std(g, ddof=1)\n",
    "    q75, q25 = np.percentile(g, [75, 25])\n",
    "    spread[i, 1] = q75 - q25\n",
    "    spread[i, 2] = mad(g)\n",
    "\n",
    "fig = go.Figure()\n",
    "for j, metric in enumerate(spread_names):\n",
    "    fig.add_trace(go.Bar(name=metric, x=group_names, y=spread[:, j]))\n",
    "\n",
    "fig.update_layout(\n",
    "    barmode=\"group\",\n",
    "    title=\"Group spread summaries (diagnostics, not the test itself)\",\n",
    "    xaxis_title=\"Group\",\n",
    "    yaxis_title=\"Spread\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155ba92e",
   "metadata": {},
   "source": [
    "### Location differences alone should not trigger the test\n",
    "\n",
    "Fligner–Killeen centers each group (by default at the **median**), so pure location shifts\n",
    "should not systematically change the deviation ranks.\n",
    "\n",
    "Here’s a quick example: same heavy-tailed distribution and same scale, but different medians.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c368597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_loc = np.random.default_rng(2)\n",
    "\n",
    "n_loc = 80\n",
    "hA = rng_loc.standard_t(df=df_t, size=n_loc) * 1.0 + -1.0\n",
    "hB = rng_loc.standard_t(df=df_t, size=n_loc) * 1.0 + 0.5\n",
    "hC = rng_loc.standard_t(df=df_t, size=n_loc) * 1.0 + 2.0\n",
    "\n",
    "stat_loc, df_loc = fligner_killeen_statistic(hA, hB, hC, center=\"median\")\n",
    "p_loc_approx = chi2_sf_wilson_hilferty(stat_loc, df_loc)\n",
    "\n",
    "print(f\"Location-only example: stat={stat_loc:.4f} (df={df_loc}), approx p≈{p_loc_approx:.4f}\")\n",
    "\n",
    "x_loc = np.concatenate([hA, hB, hC])\n",
    "labels_loc = np.concatenate(\n",
    "    [\n",
    "        np.full(len(hA), \"A (shift -1)\"),\n",
    "        np.full(len(hB), \"B (shift +0.5)\"),\n",
    "        np.full(len(hC), \"C (shift +2)\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig = px.violin(\n",
    "    x=labels_loc,\n",
    "    y=x_loc,\n",
    "    color=labels_loc,\n",
    "    box=True,\n",
    "    points=\"all\",\n",
    "    title=\"Different locations, same scale (visual check)\",\n",
    ")\n",
    "fig.update_layout(xaxis_title=\"Group\", yaxis_title=\"Value\", showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f5b7a3",
   "metadata": {},
   "source": [
    "## 8) What does the statistic “look like” under H0 vs H1?\n",
    "\n",
    "Under \\(H_0\\), the reference distribution is approximately \\(\\chi^2_{k-1}\\).\n",
    "Under \\(H_1\\), the statistic tends to be **larger** because group score means separate.\n",
    "\n",
    "We can see this by simulation.\n",
    "\n",
    "(These simulations are for intuition; the test itself uses the chi-square approximation.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_pdf(x: np.ndarray, df: int) -> np.ndarray:\n",
    "    # Chi-square pdf using only NumPy + math.gamma (for plotting)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    v = float(df)\n",
    "    c = 1.0 / (2.0 ** (v / 2.0) * math.gamma(v / 2.0))\n",
    "    return c * np.power(x, v / 2.0 - 1.0) * np.exp(-x / 2.0)\n",
    "\n",
    "\n",
    "def simulate_fk_stats(\n",
    "    *,\n",
    "    n_rep: int,\n",
    "    n: int,\n",
    "    df_t: int,\n",
    "    scale_c: float,\n",
    "    seed: int = 0,\n",
    ") -> np.ndarray:\n",
    "    sim_rng = np.random.default_rng(seed)\n",
    "    out = np.empty(n_rep, dtype=float)\n",
    "    for r in range(n_rep):\n",
    "        a = sim_rng.standard_t(df=df_t, size=n)\n",
    "        b = sim_rng.standard_t(df=df_t, size=n)\n",
    "        c = sim_rng.standard_t(df=df_t, size=n) * scale_c\n",
    "        out[r], _ = fligner_killeen_statistic(a, b, c)\n",
    "    return out\n",
    "\n",
    "\n",
    "n_rep = 1500\n",
    "n_sim = 40\n",
    "stats_h0 = simulate_fk_stats(n_rep=n_rep, n=n_sim, df_t=df_t, scale_c=1.0, seed=1)\n",
    "stats_h1 = simulate_fk_stats(n_rep=n_rep, n=n_sim, df_t=df_t, scale_c=2.0, seed=2)\n",
    "\n",
    "df_ref = 2  # k-1 for k=3 groups\n",
    "x_grid = np.linspace(0, np.percentile(stats_h1, 99.5), 400)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=stats_h0, name=\"H0: equal variances\", opacity=0.55, nbinsx=50))\n",
    "fig.add_trace(go.Histogram(x=stats_h1, name=\"H1: group C has larger variance\", opacity=0.55, nbinsx=50))\n",
    "fig.add_trace(go.Scatter(x=x_grid, y=chi2_pdf(x_grid, df_ref), name=f\"χ²(df={df_ref}) pdf\", mode=\"lines\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    barmode=\"overlay\",\n",
    "    title=\"Simulated Fligner–Killeen statistic under H0 vs H1 (and χ² reference)\",\n",
    "    xaxis_title=\"Test statistic\",\n",
    "    yaxis_title=\"Density / count\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a06f10",
   "metadata": {},
   "source": [
    "## 9) A simple power curve (variance ratio)\n",
    "\n",
    "One way to think about “power” here:\n",
    "\n",
    "- Fix a significance level \\(\\alpha\\) (say 0.05).\n",
    "- Under different variance ratios, simulate the probability we reject \\(H_0\\).\n",
    "\n",
    "This is not an exact analysis (it depends on distribution, n, etc.), but it builds intuition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7956a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_ppf_wilson_hilferty(p: float, df: int) -> float:\n",
    "    # Approximate chi-square quantile via Wilson–Hilferty (uses our norm_ppf)\n",
    "    v = float(df)\n",
    "    z = float(norm_ppf(np.array([p]))[0])\n",
    "    return v * (1.0 - 2.0 / (9.0 * v) + z * math.sqrt(2.0 / (9.0 * v))) ** 3\n",
    "\n",
    "\n",
    "alpha = 0.05\n",
    "df_ref = 2\n",
    "crit = chi2_ppf_wilson_hilferty(1.0 - alpha, df_ref)\n",
    "\n",
    "ratios = np.array([1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0])\n",
    "n_rep = 600\n",
    "n_sim = 40\n",
    "\n",
    "power = []\n",
    "for r, ratio in enumerate(ratios):\n",
    "    stats_alt = simulate_fk_stats(\n",
    "        n_rep=n_rep,\n",
    "        n=n_sim,\n",
    "        df_t=df_t,\n",
    "        scale_c=float(ratio),\n",
    "        seed=100 + r,\n",
    "    )\n",
    "    power.append(float(np.mean(stats_alt > crit)))\n",
    "\n",
    "power = np.array(power)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ratios, y=power, mode=\"lines+markers\"))\n",
    "fig.update_layout(\n",
    "    title=f\"Approx power vs variance ratio (n={n_sim}, reps={n_rep}, α={alpha})\",\n",
    "    xaxis_title=\"Scale multiplier of group C (≈ sqrt(variance ratio))\",\n",
    "    yaxis_title=\"Rejection rate\",\n",
    "    yaxis=dict(range=[0, 1]),\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a0ac20",
   "metadata": {},
   "source": [
    "## 10) Practical usage (SciPy) + validation\n",
    "\n",
    "SciPy provides a production-ready implementation:\n",
    "\n",
    "- `scipy.stats.fligner(sample1, sample2, ...)`\n",
    "\n",
    "We’ll compare its result to our NumPy implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d3e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stat_scipy, p_scipy = stats.fligner(gA, gB, gC, center=\"median\")\n",
    "print(f\"SciPy fligner: statistic={stat_scipy:.6f}, p-value={p_scipy:.6g}\")\n",
    "print(f\"Our FK stat : statistic={stat_fk:.6f} (df={df_fk})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d2534a",
   "metadata": {},
   "source": [
    "### Quick comparison to other variance tests\n",
    "\n",
    "- **Bartlett**: powerful under normality, but can be very sensitive to non-normality.\n",
    "- **Levene**: robust parametric alternative (uses absolute deviations; can center at mean/median).\n",
    "- **Fligner–Killeen**: very robust (rank-based, median-centered by default).\n",
    "\n",
    "On heavy-tailed data, Bartlett can have inflated false positives.\n",
    "Let’s check this empirically with a small simulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daf3eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejection_rates(*, n_rep: int, n: int, df_t: int, alpha: float, seed: int = 0) -> dict[str, float]:\n",
    "    sim_rng = np.random.default_rng(seed)\n",
    "\n",
    "    rej = {\"bartlett\": 0, \"levene_median\": 0, \"fligner\": 0}\n",
    "    for _ in range(n_rep):\n",
    "        a = sim_rng.standard_t(df=df_t, size=n)\n",
    "        b = sim_rng.standard_t(df=df_t, size=n)\n",
    "        c = sim_rng.standard_t(df=df_t, size=n)\n",
    "\n",
    "        # H0 is true here: all groups have the same distribution/variance\n",
    "        _, p_b = stats.bartlett(a, b, c)\n",
    "        _, p_l = stats.levene(a, b, c, center=\"median\")\n",
    "        _, p_f = stats.fligner(a, b, c, center=\"median\")\n",
    "\n",
    "        rej[\"bartlett\"] += int(p_b < alpha)\n",
    "        rej[\"levene_median\"] += int(p_l < alpha)\n",
    "        rej[\"fligner\"] += int(p_f < alpha)\n",
    "\n",
    "    return {k: v / n_rep for k, v in rej.items()}\n",
    "\n",
    "\n",
    "rates = rejection_rates(n_rep=600, n=35, df_t=df_t, alpha=0.05, seed=123)\n",
    "rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac6eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    x=list(rates.keys()),\n",
    "    y=list(rates.values()),\n",
    "    title=\"Empirical type I error on heavy-tailed data (H0 true)\",\n",
    ")\n",
    "fig.add_hline(y=0.05, line_dash=\"dash\", line_color=\"black\")\n",
    "fig.update_layout(xaxis_title=\"Test\", yaxis_title=\"Rejection rate (should be ≈ 0.05)\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ef4017",
   "metadata": {},
   "source": [
    "## 11) Pitfalls and good practice\n",
    "\n",
    "- The test assumes **independent** observations within/between groups.\n",
    "- It is an **omnibus** test: if you reject, use plots and follow-ups to locate differences.\n",
    "- If groups have very different shapes (not just scale), variance tests can reject for reasons that feel surprising.\n",
    "  Always look at the data (violin/box/QQ plots, etc.).\n",
    "- With tiny samples, the test can have low power.\n",
    "\n",
    "If you reject equal variances, common next steps:\n",
    "\n",
    "- Use methods that don’t assume equal variances (e.g., **Welch’s ANOVA**).\n",
    "- Consider variance-stabilizing transforms (log, sqrt) when appropriate.\n",
    "- Model heteroscedasticity directly (GLS, heteroscedastic regression, etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991692c4",
   "metadata": {},
   "source": [
    "## 12) Exercises\n",
    "\n",
    "1. Create 4 groups with equal variance but different medians; confirm the test typically does not reject.\n",
    "2. Hold the variance ratio fixed and vary `n` to see how power changes.\n",
    "3. Replace the t-distribution with a skewed distribution (e.g., lognormal) and compare Bartlett/Levene/Fligner.\n",
    "4. Add a single extreme outlier to one group; compare how the *sample variance* vs *MAD* vs the tests respond.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75848dac",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Fligner, M. A., & Killeen, T. J. (1976). Distribution-free two-sample tests for scale.\n",
    "- Conover, W. J., Johnson, M. E., & Johnson, M. M. (1981). A comparative study of tests for homogeneity of variances.\n",
    "- SciPy documentation: `scipy.stats.fligner`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}