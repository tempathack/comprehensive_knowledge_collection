{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c40ce904",
   "metadata": {},
   "source": [
    "# Levene’s Test (Homogeneity of Variances)\n",
    "\n",
    "Levene’s test is a hypothesis test for **equal variances** across **2+ independent groups**.\n",
    "It’s commonly used as an **assumption check** before methods that assume *homoscedasticity* (equal within-group variance), such as classical one-way ANOVA.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "By the end you should be able to:\n",
    "\n",
    "- state the **null/alternative hypotheses** and what rejecting means\n",
    "- explain the key trick: convert a **variance** problem into a **mean** problem\n",
    "- compute the Levene statistic **from scratch using NumPy**\n",
    "- interpret the output (test statistic, degrees of freedom, p-value)\n",
    "- use Plotly visuals to build intuition (raw samples vs deviation variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0abd683",
   "metadata": {},
   "source": [
    "## What it’s used for\n",
    "\n",
    "Levene’s test answers:\n",
    "\n",
    "> “Do these groups have the **same spread/variability**?”\n",
    "\n",
    "Typical use-cases:\n",
    "\n",
    "- **ANOVA / linear models**: check whether residual variability looks similar across groups.\n",
    "- **A/B/n tests**: check if one variant causes outcomes to be more variable.\n",
    "- **Quality control**: check if batches/machines differ in variability.\n",
    "- **Finance/ops**: detect regime changes where volatility differs across segments.\n",
    "\n",
    "Important:\n",
    "\n",
    "- This is a test about **variances**, not means. Groups can have different means and still have equal variances.\n",
    "- If you reject, Levene’s test does **not** tell you *which* groups differ; it only says “at least one variance differs”.\n",
    "- For two-sample mean comparisons, it’s often better to use **Welch’s t-test** directly rather than “pre-testing” variances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caebc52f",
   "metadata": {},
   "source": [
    "## Hypotheses and interpretation\n",
    "\n",
    "For $k$ groups with population variances $\\sigma_1^2, \\dots, \\sigma_k^2$:\n",
    "\n",
    "- **Null hypothesis**: $H_0: \\sigma_1^2 = \\sigma_2^2 = \\dots = \\sigma_k^2$ (all variances equal)\n",
    "- **Alternative**: $H_1$: at least one variance differs\n",
    "\n",
    "Decision rule at significance level $\\alpha$ (e.g. 0.05):\n",
    "\n",
    "- if `p-value < α`: reject $H_0$ → evidence that variances are not all equal\n",
    "- if `p-value ≥ α`: fail to reject $H_0$ → not enough evidence of a variance difference\n",
    "\n",
    "A **p-value** is not the probability that $H_0$ is true. It is the probability (under $H_0$) of getting a test statistic at least as extreme as the one observed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4239b39c",
   "metadata": {},
   "source": [
    "## The core idea (why Levene works)\n",
    "\n",
    "Levene’s test turns “equal variances?” into “equal means?” by constructing a new variable:\n",
    "\n",
    "1. For each group $i$, pick a **center** (one of):\n",
    "   - mean (original Levene)\n",
    "   - median (Brown–Forsythe variant; more robust)\n",
    "   - trimmed mean (robust)\n",
    "2. Compute **absolute deviations** from the group center:\n",
    "\n",
    "$$z_{ij} = |x_{ij} - c_i|$$\n",
    "\n",
    "If groups truly have the **same variance**, then the typical size of these deviations should be similar across groups.\n",
    "\n",
    "So we run a **one-way ANOVA** on $z_{ij}$:\n",
    "\n",
    "$$W = \\frac{\\text{MS}_{\\text{between}}}{\\text{MS}_{\\text{within}}}\n",
    "= \\frac{\\left(\\sum_i n_i(\\bar z_i-\\bar z)^2\\right)/(k-1)}{\\left(\\sum_i\\sum_j (z_{ij}-\\bar z_i)^2\\right)/(N-k)}$$\n",
    "\n",
    "Where $n_i$ is group size, $N=\\sum_i n_i$, and $\\bar z_i$ are group means of the deviations.\n",
    "\n",
    "Under $H_0$, $W$ is approximately $F$-distributed with `df1 = k-1` and `df2 = N-k`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ffa414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"plotly:\", __import__(\"plotly\").__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e209874",
   "metadata": {},
   "source": [
    "## From-scratch NumPy implementation\n",
    "\n",
    "Below is a low-level implementation of the Levene statistic. The goal is to make the mechanics explicit:\n",
    "\n",
    "- compute group centers $c_i$\n",
    "- convert samples to deviations $z_{ij} = |x_{ij}-c_i|$\n",
    "- compute the one-way ANOVA $F$ statistic on the deviations\n",
    "\n",
    "For the **p-value**, we show two options:\n",
    "\n",
    "- a **NumPy-only Monte Carlo** approximation using the $F$ distribution definition as a ratio of chi-squares\n",
    "- (optional) a **SciPy** reference value (`scipy.stats.f.sf`) to match what you’d do in practice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimmed_mean(x: np.ndarray, proportiontocut: float) -> float:\n",
    "    x = np.asarray(x, dtype=float).ravel()\n",
    "    if not (0 <= proportiontocut < 0.5):\n",
    "        raise ValueError(\"proportiontocut must be in [0, 0.5).\")\n",
    "    if x.size == 0:\n",
    "        raise ValueError(\"Empty sample.\")\n",
    "    k = int(np.floor(proportiontocut * x.size))\n",
    "    if 2 * k >= x.size:\n",
    "        raise ValueError(\"Trim proportion too large for this sample size.\")\n",
    "    x_sorted = np.sort(x)\n",
    "    return float(x_sorted[k : x.size - k].mean())\n",
    "\n",
    "\n",
    "def _center(x: np.ndarray, center: str, proportiontocut: float) -> float:\n",
    "    center = center.lower()\n",
    "    if center == \"mean\":\n",
    "        return float(np.mean(x))\n",
    "    if center == \"median\":\n",
    "        return float(np.median(x))\n",
    "    if center in {\"trimmed\", \"trimmed_mean\"}:\n",
    "        return trimmed_mean(x, proportiontocut)\n",
    "    raise ValueError(\"center must be one of: 'mean', 'median', 'trimmed'.\")\n",
    "\n",
    "\n",
    "def levene_statistic(*groups: np.ndarray, center: str = \"median\", proportiontocut: float = 0.05):\n",
    "    groups = [np.asarray(g, dtype=float).ravel() for g in groups]\n",
    "\n",
    "    if len(groups) < 2:\n",
    "        raise ValueError(\"Levene's test needs at least 2 groups.\")\n",
    "    if any(g.size < 2 for g in groups):\n",
    "        raise ValueError(\"Each group must contain at least 2 observations.\")\n",
    "    if not all(np.isfinite(g).all() for g in groups):\n",
    "        raise ValueError(\"All observations must be finite (no NaN/inf).\")\n",
    "\n",
    "    k = len(groups)\n",
    "    n = np.array([g.size for g in groups], dtype=int)\n",
    "    N = int(n.sum())\n",
    "    df1 = k - 1\n",
    "    df2 = N - k\n",
    "\n",
    "    centers = np.array([\n",
    "        _center(g, center=center, proportiontocut=proportiontocut) for g in groups\n",
    "    ])\n",
    "\n",
    "    z_groups = [np.abs(g - c) for g, c in zip(groups, centers)]\n",
    "    z_means = np.array([z.mean() for z in z_groups])\n",
    "    z_bar = float(np.sum(n * z_means) / N)\n",
    "\n",
    "    ss_between = float(np.sum(n * (z_means - z_bar) ** 2))\n",
    "    ss_within = float(np.sum([np.sum((z - m) ** 2) for z, m in zip(z_groups, z_means)]))\n",
    "\n",
    "    if ss_within == 0.0:\n",
    "        W = np.inf if ss_between > 0 else 0.0\n",
    "    else:\n",
    "        W = (ss_between / df1) / (ss_within / df2)\n",
    "\n",
    "    details = {\n",
    "        \"centers\": centers,\n",
    "        \"z_groups\": z_groups,\n",
    "        \"z_means\": z_means,\n",
    "        \"z_bar\": z_bar,\n",
    "        \"ss_between\": ss_between,\n",
    "        \"ss_within\": ss_within,\n",
    "        \"df1\": df1,\n",
    "        \"df2\": df2,\n",
    "    }\n",
    "    return W, details\n",
    "\n",
    "\n",
    "def f_pvalue_mc(W: float, df1: int, df2: int, n_mc: int = 200_000, seed: int = 0) -> float:\n",
    "    \"\"\"Right-tail p-value via NumPy-only Monte Carlo for an F(df1, df2) statistic.\"\"\"\n",
    "    if not np.isfinite(W):\n",
    "        return 0.0\n",
    "    if n_mc <= 0:\n",
    "        raise ValueError(\"n_mc must be positive.\")\n",
    "\n",
    "    rng_local = np.random.default_rng(seed)\n",
    "    f_sim = (rng_local.chisquare(df1, size=n_mc) / df1) / (rng_local.chisquare(df2, size=n_mc) / df2)\n",
    "    return float(np.mean(f_sim >= W))\n",
    "\n",
    "\n",
    "def levene_test_numpy(\n",
    "    *groups: np.ndarray,\n",
    "    center: str = \"median\",\n",
    "    proportiontocut: float = 0.05,\n",
    "    n_mc: int = 200_000,\n",
    "    seed: int = 0,\n",
    "):\n",
    "    W, details = levene_statistic(*groups, center=center, proportiontocut=proportiontocut)\n",
    "    p_mc = f_pvalue_mc(W, details[\"df1\"], details[\"df2\"], n_mc=n_mc, seed=seed)\n",
    "    return W, p_mc, details\n",
    "\n",
    "\n",
    "def plot_raw_vs_deviation(groups, group_names, centers, center_label: str):\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=2,\n",
    "        subplot_titles=(\n",
    "            \"Raw samples\",\n",
    "            f\"Absolute deviations |x - {center_label}(group)|\",\n",
    "        ),\n",
    "        horizontal_spacing=0.15,\n",
    "    )\n",
    "\n",
    "    for name, x, c in zip(group_names, groups, centers):\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=x,\n",
    "                name=name,\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                points=\"outliers\",\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=np.abs(x - c),\n",
    "                name=name,\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                points=\"outliers\",\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=1,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "    fig.update_layout(violinmode=\"group\", height=420)\n",
    "    fig.update_yaxes(title_text=\"value\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=f\"|x - {center_label}(group)|\", row=1, col=2)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_mean_abs_deviation(z_groups, group_names):\n",
    "    mad = np.array([float(np.mean(z)) for z in z_groups])\n",
    "    fig = go.Figure(go.Bar(x=group_names, y=mad, text=np.round(mad, 4)))\n",
    "    fig.add_hline(\n",
    "        y=float(mad.mean()),\n",
    "        line_dash=\"dash\",\n",
    "        annotation_text=\"grand mean\",\n",
    "        annotation_position=\"top left\",\n",
    "    )\n",
    "    fig.update_traces(textposition=\"outside\")\n",
    "    fig.update_layout(\n",
    "        title=\"Group means of |x - center(group)| (what the ANOVA compares)\",\n",
    "        xaxis_title=\"group\",\n",
    "        yaxis_title=\"mean absolute deviation\",\n",
    "        height=360,\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_f_null_distribution(W: float, df1: int, df2: int, n: int = 150_000, seed: int = 0):\n",
    "    rng_local = np.random.default_rng(seed)\n",
    "    f_sim = (rng_local.chisquare(df1, size=n) / df1) / (rng_local.chisquare(df2, size=n) / df2)\n",
    "\n",
    "    fig = go.Figure(go.Histogram(x=f_sim, nbinsx=80, histnorm=\"probability density\"))\n",
    "    fig.add_vline(\n",
    "        x=W,\n",
    "        line_color=\"crimson\",\n",
    "        line_width=3,\n",
    "        annotation_text=\"observed W\",\n",
    "        annotation_position=\"top right\",\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=f\"Null reference: simulated F({df1}, {df2}) density + observed W\",\n",
    "        xaxis_title=\"F value\",\n",
    "        yaxis_title=\"density\",\n",
    "        height=360,\n",
    "        showlegend=False,\n",
    "    )\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfe44cc",
   "metadata": {},
   "source": [
    "## Example 1: different means, similar variances\n",
    "\n",
    "Here the groups have noticeably different **means**, but we generate them with the same standard deviation.\n",
    "Levene’s test should typically **fail to reject** $H_0$ (equal variances).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6198596",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 160\n",
    "g1 = rng.normal(loc=0.0, scale=1.0, size=n)\n",
    "g2 = rng.normal(loc=2.0, scale=1.0, size=n)\n",
    "g3 = rng.normal(loc=-1.0, scale=1.0, size=n)\n",
    "\n",
    "groups = [g1, g2, g3]\n",
    "names = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "W, p_mc, details = levene_test_numpy(*groups, center=\"median\", n_mc=200_000, seed=1)\n",
    "print(f\"NumPy Levene (median center): W={W:.4f}, df=({details['df1']}, {details['df2']}), p_mc≈{p_mc:.4f}\")\n",
    "\n",
    "# Practical reference (analytic p-value)\n",
    "from scipy.stats import f as f_dist, levene as levene_scipy\n",
    "\n",
    "p_f = float(f_dist.sf(W, details[\"df1\"], details[\"df2\"]))\n",
    "W_scipy, p_scipy = levene_scipy(*groups, center=\"median\")\n",
    "print(f\"SciPy reference:         W={W_scipy:.4f}, p={p_scipy:.4f}\")\n",
    "print(f\"F survival (SciPy f.sf): p={p_f:.4f}\")\n",
    "\n",
    "fig = plot_raw_vs_deviation(groups, names, details[\"centers\"], center_label=\"median\")\n",
    "fig.update_layout(title=\"Example 1: raw samples vs absolute deviations\")\n",
    "fig.show()\n",
    "\n",
    "fig = plot_mean_abs_deviation(details[\"z_groups\"], names)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd064133",
   "metadata": {},
   "source": [
    "## Example 2: different variances\n",
    "\n",
    "Now the groups have similar means but different spreads.\n",
    "Levene’s test should typically **reject** $H_0$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf51df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 160\n",
    "g1 = rng.normal(loc=0.0, scale=1.0, size=n)\n",
    "g2 = rng.normal(loc=0.0, scale=2.0, size=n)\n",
    "g3 = rng.normal(loc=0.0, scale=0.5, size=n)\n",
    "\n",
    "groups = [g1, g2, g3]\n",
    "names = [\"sigma=1.0\", \"sigma=2.0\", \"sigma=0.5\"]\n",
    "\n",
    "W, p_mc, details = levene_test_numpy(*groups, center=\"median\", n_mc=200_000, seed=2)\n",
    "p_f = float(f_dist.sf(W, details[\"df1\"], details[\"df2\"]))\n",
    "\n",
    "print(f\"NumPy Levene (median center): W={W:.4f}, df=({details['df1']}, {details['df2']}), p_mc≈{p_mc:.6f}\")\n",
    "print(f\"Analytic p (SciPy f.sf):     p={p_f:.6f}\")\n",
    "\n",
    "fig = plot_raw_vs_deviation(groups, names, details[\"centers\"], center_label=\"median\")\n",
    "fig.update_layout(title=\"Example 2: raw samples vs absolute deviations\")\n",
    "fig.show()\n",
    "\n",
    "fig = plot_mean_abs_deviation(details[\"z_groups\"], names)\n",
    "fig.show()\n",
    "\n",
    "# A visual way to read the p-value: where does W fall under the null F distribution?\n",
    "fig = plot_f_null_distribution(W, details[\"df1\"], details[\"df2\"], n=150_000, seed=3)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4300304c",
   "metadata": {},
   "source": [
    "## Why people often use the median center (robustness)\n",
    "\n",
    "The original Levene test uses the **mean** as the group center, but a common robust variant uses the **median** (often called the Brown–Forsythe test).\n",
    "\n",
    "Intuition:\n",
    "\n",
    "- The mean is more sensitive to outliers and heavy tails.\n",
    "- Using the median tends to control false positives better when data are non-normal.\n",
    "\n",
    "Below we simulate under $H_0$ (equal variances) and compare how often each variant rejects at $\\alpha=0.05$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a1b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f as f_dist\n",
    "\n",
    "\n",
    "def pvalue_f(W: float, df1: int, df2: int) -> float:\n",
    "    return float(f_dist.sf(W, df1, df2))\n",
    "\n",
    "\n",
    "def estimate_type1_error(\n",
    "    *,\n",
    "    gen_groups,\n",
    "    center: str,\n",
    "    n_reps: int = 600,\n",
    "    alpha: float = 0.05,\n",
    "    seed: int = 123,\n",
    "):\n",
    "    rng_local = np.random.default_rng(seed)\n",
    "    rejects = 0\n",
    "\n",
    "    for _ in range(n_reps):\n",
    "        groups = gen_groups(rng_local)\n",
    "        W, details = levene_statistic(*groups, center=center)\n",
    "        p = pvalue_f(W, details[\"df1\"], details[\"df2\"])\n",
    "        rejects += int(p < alpha)\n",
    "\n",
    "    return rejects / n_reps\n",
    "\n",
    "\n",
    "k = 3\n",
    "n = 30\n",
    "\n",
    "\n",
    "def gen_normal(rng_local):\n",
    "    return [rng_local.normal(loc=0.0, scale=1.0, size=n) for _ in range(k)]\n",
    "\n",
    "\n",
    "def gen_t3_heavy_tails(rng_local):\n",
    "    # Standard t(df=3) has variance df/(df-2)=3, so scale by 1/sqrt(3) to make variance ~1.\n",
    "    return [rng_local.standard_t(df=3, size=n) / np.sqrt(3.0) for _ in range(k)]\n",
    "\n",
    "\n",
    "rates = []\n",
    "for dist_name, gen in [(\"Normal\", gen_normal), (\"t(df=3) heavy tails\", gen_t3_heavy_tails)]:\n",
    "    for center in [\"mean\", \"median\"]:\n",
    "        rate = estimate_type1_error(gen_groups=gen, center=center, n_reps=700, alpha=0.05, seed=7)\n",
    "        rates.append({\"distribution\": dist_name, \"center\": center, \"rejection_rate\": rate})\n",
    "\n",
    "df_rates = pd.DataFrame(rates)\n",
    "df_rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7323e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    df_rates,\n",
    "    x=\"distribution\",\n",
    "    y=\"rejection_rate\",\n",
    "    color=\"center\",\n",
    "    barmode=\"group\",\n",
    "    text=\"rejection_rate\",\n",
    "    title=\"Type I error under H0 (how often we reject when variances are equal)\",\n",
    ")\n",
    "fig.add_hline(\n",
    "    y=0.05,\n",
    "    line_dash=\"dash\",\n",
    "    annotation_text=\"alpha = 0.05\",\n",
    "    annotation_position=\"top left\",\n",
    ")\n",
    "fig.update_traces(texttemplate=\"%{text:.3f}\", textposition=\"outside\")\n",
    "fig.update_layout(yaxis_title=\"rejection rate\", height=380)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892805e6",
   "metadata": {},
   "source": [
    "## Practical checklist + pitfalls\n",
    "\n",
    "- **Independence matters**: Levene assumes observations are independent within and across groups.\n",
    "- **Scale of measurement**: works best for continuous/interval data; with discrete/ordinal outcomes interpret carefully.\n",
    "- **What rejection means**: at least one group variance differs → consider Welch’s ANOVA, robust methods, variance-stabilizing transforms, or modeling heteroscedasticity directly.\n",
    "- **What non-rejection means**: not enough evidence of variance differences ≠ proof of equal variances (power can be low for small samples).\n",
    "- **Multiple comparisons**: Levene is an omnibus test; if you follow with pairwise variance checks, correct for multiple testing.\n",
    "\n",
    "Alternatives:\n",
    "\n",
    "- **Bartlett’s test**: more powerful under normality, but very sensitive to non-normal data.\n",
    "- **Fligner–Killeen**: nonparametric/robust test for equal variances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38f2d4",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Modify Example 2 so only one group has a larger variance. How does $W$ change?\n",
    "2. Increase/decrease sample sizes and see how the p-value behaves.\n",
    "3. Implement a simple “follow-up” routine: plot sample variances and bootstrap confidence intervals per group.\n",
    "4. Compare Levene (median center) to `scipy.stats.fligner` on heavy-tailed data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ddb5d4",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Levene, H. (1960). *Robust tests for equality of variances.*\n",
    "- Brown, M. B., & Forsythe, A. B. (1974). *Robust tests for the equality of variances.*\n",
    "- SciPy documentation: `scipy.stats.levene`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}