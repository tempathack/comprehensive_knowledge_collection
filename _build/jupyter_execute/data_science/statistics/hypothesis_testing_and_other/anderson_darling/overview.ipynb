{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7db03062",
   "metadata": {},
   "source": [
    "# Anderson–Darling Test (Goodness-of-Fit / Normality)\n",
    "\n",
    "The Anderson–Darling (AD) test is a **goodness-of-fit** test: it asks whether a sample plausibly comes from a target distribution.\n",
    "It is similar in spirit to Kolmogorov–Smirnov, but it puts **much more weight on the tails**, which is often exactly what you care about in practice.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "By the end you should be able to:\n",
    "\n",
    "- state the null/alternative hypotheses for the one-sample AD test\n",
    "- explain why AD is *tail-sensitive*\n",
    "- compute the AD statistic from first principles (**NumPy-only**)\n",
    "- interpret the result via p-values / critical values\n",
    "- diagnose *where* the mismatch happens using CDF + contribution plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ff06fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792d846b",
   "metadata": {},
   "source": [
    "## 1) What the AD test is used for\n",
    "\n",
    "### The question it answers\n",
    "\n",
    "> “If the true data-generating distribution were `F`, how surprising is it to see a sample whose empirical CDF looks like this?”\n",
    "\n",
    "AD is most commonly used as a **normality test** (where `F` is a normal CDF with mean/variance estimated from the data),\n",
    "but it is more general: you can test against any *continuous* CDF you can evaluate.\n",
    "\n",
    "### Typical applications\n",
    "\n",
    "- checking **normality of residuals** (regression, control charts, signal processing)\n",
    "- validating a fitted distribution before using it for **probabilities/quantiles**\n",
    "- comparing tail behavior (outliers, risk, reliability)\n",
    "\n",
    "### When you should be careful\n",
    "\n",
    "- AD is derived for **continuous** distributions; ties/discrete data need extra care.\n",
    "- Observations should be roughly **i.i.d.** (dependence can inflate false positives).\n",
    "- The null distribution of the statistic depends on whether distribution parameters are **known** or **estimated**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2490645",
   "metadata": {},
   "source": [
    "## 2) Hypotheses and what “reject” means\n",
    "\n",
    "For the one-sample AD test:\n",
    "\n",
    "- **H0**: observations are i.i.d. from the target distribution with CDF `F(x)`\n",
    "- **H1**: the data are not from `F(x)`\n",
    "\n",
    "AD produces a statistic `A² ≥ 0`.\n",
    "\n",
    "- larger `A²` ⇒ larger deviation from `F` (especially in the tails)\n",
    "- you reject `H0` when `A²` is “too large” (via a p-value or critical value)\n",
    "\n",
    "Important: failing to reject does **not** prove the distribution is correct; it just means you didn’t find strong evidence against it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15de48c",
   "metadata": {},
   "source": [
    "## 3) Intuition: why AD is tail-sensitive\n",
    "\n",
    "Let:\n",
    "\n",
    "- `F(x)` be the hypothesized CDF\n",
    "- `F_n(x)` be the empirical CDF from your sample\n",
    "\n",
    "One way to write the AD statistic is:\n",
    "\n",
    "$$\n",
    "A^2 = n \\int_{-\\infty}^{\\infty} \\frac{\\big(F_n(x) - F(x)\\big)^2}{F(x)\\,(1-F(x))} \\, dF(x)\n",
    "$$\n",
    "\n",
    "The key is the **weight** term:\n",
    "\n",
    "$$\n",
    "w(F) = \\frac{1}{F(1-F)}\n",
    "$$\n",
    "\n",
    "When `F` is near 0 or near 1 (the tails), `w(F)` becomes very large, so tail mismatches are amplified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30415407",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_grid = np.linspace(1e-3, 1 - 1e-3, 2000)\n",
    "w = 1.0 / (F_grid * (1.0 - F_grid))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=F_grid, y=w, mode=\"lines\", name=\"w(F)=1/(F(1-F))\"))\n",
    "fig.update_layout(\n",
    "    title=\"AD tail weighting: w(F) blows up near 0 and 1\",\n",
    "    xaxis_title=\"F\",\n",
    "    yaxis_title=\"weight w(F)\",\n",
    "    yaxis_type=\"log\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf6edd",
   "metadata": {},
   "source": [
    "## 4) The discrete formula (how you actually compute A²)\n",
    "\n",
    "Sort the data:\n",
    "\n",
    "$$\n",
    "x_{(1)} \\le x_{(2)} \\le \\dots \\le x_{(n)}\n",
    "$$\n",
    "\n",
    "Compute CDF values under the null:\n",
    "\n",
    "$$\n",
    "F_i = F\\big(x_{(i)}\\big)\n",
    "$$\n",
    "\n",
    "Then the one-sample AD statistic is:\n",
    "\n",
    "$$\n",
    "A^2 = -n - \\frac{1}{n} \\sum_{i=1}^n (2i-1)\\Big(\\ln(F_i) + \\ln\\big(1 - F_{n+1-i}\\big)\\Big)\n",
    "$$\n",
    "\n",
    "Notes:\n",
    "\n",
    "- You must avoid `log(0)` by clipping `F_i` away from 0 and 1.\n",
    "- For the common **normality** version (unknown mean/variance), people often use a small-sample correction:\n",
    "\n",
    "$$\n",
    "A^{2\\,*} = A^2 \\left(1 + \\frac{0.75}{n} + \\frac{2.25}{n^2}\\right)\n",
    "$$\n",
    "\n",
    "Below we implement everything with **NumPy only**, including a normal CDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14af7280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _as_1d_finite(x):\n",
    "    x = np.asarray(x, dtype=float).ravel()\n",
    "    x = x[np.isfinite(x)]\n",
    "    return x\n",
    "\n",
    "\n",
    "def erf_approx(x):\n",
    "    \"\"\"Vectorized erf approximation (Abramowitz & Stegun 7.1.26).\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    sign = np.sign(x)\n",
    "    ax = np.abs(x)\n",
    "\n",
    "    p = 0.3275911\n",
    "    a1 = 0.254829592\n",
    "    a2 = -0.284496736\n",
    "    a3 = 1.421413741\n",
    "    a4 = -1.453152027\n",
    "    a5 = 1.061405429\n",
    "\n",
    "    t = 1.0 / (1.0 + p * ax)\n",
    "    poly = (((((a5 * t + a4) * t + a3) * t + a2) * t + a1) * t)\n",
    "    y = 1.0 - poly * np.exp(-(ax ** 2))\n",
    "    return sign * y\n",
    "\n",
    "\n",
    "def norm_cdf(x, mu=0.0, sigma=1.0):\n",
    "    \"\"\"Normal CDF using erf approximation (NumPy-only).\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    sigma = np.asarray(sigma, dtype=float)\n",
    "    if np.any(sigma <= 0):\n",
    "        raise ValueError(\"sigma must be positive.\")\n",
    "    z = (x - mu) / (sigma * np.sqrt(2.0))\n",
    "    return 0.5 * (1.0 + erf_approx(z))\n",
    "\n",
    "\n",
    "def ecdf(x):\n",
    "    \"\"\"Empirical CDF points (x_sorted, p).\"\"\"\n",
    "    x = _as_1d_finite(x)\n",
    "    xs = np.sort(x)\n",
    "    n = xs.size\n",
    "    p = np.arange(1, n + 1) / n\n",
    "    return xs, p\n",
    "\n",
    "\n",
    "def anderson_darling_statistic(x, cdf, args=(), eps=1e-12):\n",
    "    \"\"\"One-sample Anderson–Darling statistic A² for a continuous CDF F.\"\"\"\n",
    "    x = _as_1d_finite(x)\n",
    "    n = x.size\n",
    "    if n < 2:\n",
    "        raise ValueError(\"Need at least 2 finite observations.\")\n",
    "\n",
    "    xs = np.sort(x)\n",
    "    i = np.arange(1, n + 1)\n",
    "\n",
    "    Fi = np.asarray(cdf(xs, *args), dtype=float)\n",
    "    Fi = np.clip(Fi, eps, 1.0 - eps)\n",
    "\n",
    "    s = np.sum((2 * i - 1) * (np.log(Fi) + np.log1p(-Fi[::-1])))\n",
    "    return -n - s / n\n",
    "\n",
    "\n",
    "def anderson_darling_contributions(x, cdf, args=(), eps=1e-12):\n",
    "    \"\"\"Per-order-statistic contribution to A² (excluding the '-n' constant).\"\"\"\n",
    "    x = _as_1d_finite(x)\n",
    "    n = x.size\n",
    "    xs = np.sort(x)\n",
    "    i = np.arange(1, n + 1)\n",
    "\n",
    "    Fi = np.asarray(cdf(xs, *args), dtype=float)\n",
    "    Fi = np.clip(Fi, eps, 1.0 - eps)\n",
    "\n",
    "    term = (2 * i - 1) * (np.log(Fi) + np.log1p(-Fi[::-1]))\n",
    "    contrib = -term / n\n",
    "    return xs, contrib\n",
    "\n",
    "\n",
    "def ad_normality(x):\n",
    "    \"\"\"\n",
    "    AD normality test pieces (NumPy-only).\n",
    "\n",
    "    Estimates mu,sigma from the sample and applies the common correction:\n",
    "    A²* = A² * (1 + 0.75/n + 2.25/n²)\n",
    "    \"\"\"\n",
    "    x = _as_1d_finite(x)\n",
    "    n = x.size\n",
    "    if n < 2:\n",
    "        raise ValueError(\"Need at least 2 finite observations.\")\n",
    "\n",
    "    mu = x.mean()\n",
    "    sigma = x.std(ddof=0)\n",
    "    if sigma <= 0:\n",
    "        raise ValueError(\"sigma is 0; AD normality test is undefined.\")\n",
    "\n",
    "    A2 = anderson_darling_statistic(x, norm_cdf, args=(mu, sigma))\n",
    "    corr = 1.0 + 0.75 / n + 2.25 / (n**2)\n",
    "    A2_star = A2 * corr\n",
    "    return {\"n\": n, \"mu\": mu, \"sigma\": sigma, \"A2\": A2, \"A2_star\": A2_star, \"corr\": corr}\n",
    "\n",
    "\n",
    "def ad_pvalue_normal_approx(A2_star):\n",
    "    \"\"\"\n",
    "    Approximate p-value for the AD normality test (using A²*).\n",
    "\n",
    "    This is a widely used approximation (Stephens-style). For maximum accuracy,\n",
    "    especially in small samples, prefer a Monte Carlo p-value.\n",
    "    \"\"\"\n",
    "    A2_star = float(A2_star)\n",
    "\n",
    "    if A2_star < 0.2:\n",
    "        p = 1.0 - np.exp(-13.436 + 101.14 * A2_star - 223.73 * (A2_star**2))\n",
    "    elif A2_star < 0.34:\n",
    "        p = 1.0 - np.exp(-8.318 + 42.796 * A2_star - 59.938 * (A2_star**2))\n",
    "    elif A2_star < 0.6:\n",
    "        p = np.exp(0.9177 - 4.279 * A2_star - 1.38 * (A2_star**2))\n",
    "    else:\n",
    "        p = np.exp(1.2937 - 5.709 * A2_star + 0.0186 * (A2_star**2))\n",
    "\n",
    "    return float(np.clip(p, 0.0, 1.0))\n",
    "\n",
    "\n",
    "def ad_null_stats_normality(n, n_sim=3000, seed=0):\n",
    "    \"\"\"Monte Carlo null distribution for A²* under normality (mu,sigma estimated).\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    stats = np.empty(n_sim, dtype=float)\n",
    "\n",
    "    for j in range(n_sim):\n",
    "        sim = rng.standard_normal(n)\n",
    "        stats[j] = ad_normality(sim)[\"A2_star\"]\n",
    "\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2180a4a6",
   "metadata": {},
   "source": [
    "## 5) Worked example: data that are actually normal\n",
    "\n",
    "We generate a sample from a normal distribution. Under `H0`, we expect:\n",
    "\n",
    "- `A²*` to look typical for this sample size\n",
    "- a p-value that is not extremely small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d8ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 80\n",
    "x_norm = rng.normal(loc=0.0, scale=1.0, size=n)\n",
    "\n",
    "res_norm = ad_normality(x_norm)\n",
    "p_approx_norm = ad_pvalue_normal_approx(res_norm[\"A2_star\"])\n",
    "\n",
    "null_stats = ad_null_stats_normality(n, n_sim=4000, seed=123)\n",
    "p_mc_norm = float(np.mean(null_stats >= res_norm[\"A2_star\"]))\n",
    "\n",
    "alphas = np.array([0.15, 0.10, 0.05, 0.025, 0.01])\n",
    "crit = np.quantile(null_stats, 1 - alphas)\n",
    "\n",
    "print(\"Normal sample\")\n",
    "print({k: (float(v) if isinstance(v, (np.floating, float)) else v) for k, v in res_norm.items() if k != \"corr\"})\n",
    "print(f\"Approx p-value (normality): {p_approx_norm:.4f}\")\n",
    "print(f\"MC p-value (normality):     {p_mc_norm:.4f}\")\n",
    "print()\n",
    "print(\"Monte Carlo critical values for A²* (reject if A²* > critical):\")\n",
    "for a, c in zip(alphas, crit):\n",
    "    print(f\"  alpha={a:>5.3f}  critical={c:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d8002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P–P plot: theoretical CDF values vs empirical probabilities\n",
    "xs = np.sort(x_norm)\n",
    "i = np.arange(1, n + 1)\n",
    "emp_p = (i - 0.5) / n\n",
    "theory_p = norm_cdf(xs, res_norm[\"mu\"], res_norm[\"sigma\"])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=theory_p, y=emp_p, mode=\"markers\", name=\"data\"))\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode=\"lines\", name=\"y = x\"))\n",
    "fig.update_layout(\n",
    "    title=\"P–P plot for normality (normal sample)\",\n",
    "    xaxis_title=\"Theoretical CDF F(xᵢ)\",\n",
    "    yaxis_title=\"Empirical probability (i−0.5)/n\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ec35ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contribution view: where the statistic comes from\n",
    "_, contrib = anderson_darling_contributions(x_norm, norm_cdf, args=(res_norm[\"mu\"], res_norm[\"sigma\"]))\n",
    "contrib_star = contrib * res_norm[\"corr\"]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(1, n + 1),\n",
    "        y=contrib_star,\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"contribution\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Where A²* comes from (normal sample)\",\n",
    "    xaxis_title=\"Order statistic index i (1=smallest, n=largest)\",\n",
    "    yaxis_title=\"Contribution to A²*\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b002aad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    null_stats,\n",
    "    nbins=60,\n",
    "    title=f\"Null distribution of A²* under normality (n={n}, MC={len(null_stats)})\",\n",
    "    labels={\"value\": \"A²*\"},\n",
    ")\n",
    "fig.add_vline(x=res_norm[\"A2_star\"], line_color=\"red\", line_width=3)\n",
    "fig.add_annotation(\n",
    "    x=res_norm[\"A2_star\"],\n",
    "    y=0,\n",
    "    yanchor=\"bottom\",\n",
    "    text=f\"observed A²*={res_norm['A2_star']:.3f}\\nMC p≈{p_mc_norm:.3f}\",\n",
    "    showarrow=True,\n",
    "    arrowhead=2,\n",
    ")\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca74106",
   "metadata": {},
   "source": [
    "## 6) Worked example: heavy tails (t distribution)\n",
    "\n",
    "Now we generate data with **heavier tails** than a normal distribution.\n",
    "\n",
    "Because AD heavily weights the tails, it often detects this kind of deviation strongly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12a12ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = rng.standard_t(df=3, size=n)\n",
    "\n",
    "res_t = ad_normality(x_t)\n",
    "p_approx_t = ad_pvalue_normal_approx(res_t[\"A2_star\"])\n",
    "p_mc_t = float(np.mean(null_stats >= res_t[\"A2_star\"]))\n",
    "\n",
    "print(\"t(3) sample (heavy tails)\")\n",
    "print({k: (float(v) if isinstance(v, (np.floating, float)) else v) for k, v in res_t.items() if k != \"corr\"})\n",
    "print(f\"Approx p-value (normality): {p_approx_t:.4f}\")\n",
    "print(f\"MC p-value (normality):     {p_mc_t:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb6723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empirical CDF vs fitted normal CDF (visual goodness-of-fit)\n",
    "xs_emp, p_emp = ecdf(x_t)\n",
    "p_fit = norm_cdf(xs_emp, res_t[\"mu\"], res_t[\"sigma\"])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=xs_emp,\n",
    "        y=p_emp,\n",
    "        mode=\"lines\",\n",
    "        line_shape=\"hv\",\n",
    "        name=\"Empirical CDF\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=xs_emp, y=p_fit, mode=\"lines\", name=\"Fitted normal CDF\"))\n",
    "fig.update_layout(\n",
    "    title=\"Empirical CDF vs fitted normal CDF (t(3) sample)\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"CDF\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8154735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare contribution profiles: normal vs heavy-tailed\n",
    "_, contrib_n = anderson_darling_contributions(x_norm, norm_cdf, args=(res_norm[\"mu\"], res_norm[\"sigma\"]))\n",
    "_, contrib_t = anderson_darling_contributions(x_t, norm_cdf, args=(res_t[\"mu\"], res_t[\"sigma\"]))\n",
    "\n",
    "contrib_n_star = contrib_n * res_norm[\"corr\"]\n",
    "contrib_t_star = contrib_t * res_t[\"corr\"]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(1, n + 1),\n",
    "        y=contrib_n_star,\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Normal sample\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(1, n + 1),\n",
    "        y=contrib_t_star,\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"t(3) sample\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"AD is tail-sensitive: contributions often spike in the extremes\",\n",
    "    xaxis_title=\"Order statistic index i (tails are near 1 and n)\",\n",
    "    yaxis_title=\"Contribution to A²*\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25696a",
   "metadata": {},
   "source": [
    "## 7) How to interpret the result (what it means)\n",
    "\n",
    "### The mechanics\n",
    "\n",
    "1. Pick a null distribution `F` (and decide whether its parameters are **fixed** or **estimated**).\n",
    "2. Compute the AD statistic (for normality, we used `A²*`).\n",
    "3. Convert `A²` / `A²*` into a decision:\n",
    "   - **critical value**: reject if `A²* > c_α`\n",
    "   - **p-value**: reject if `p < α`\n",
    "\n",
    "### The meaning\n",
    "\n",
    "- If you **reject**: the sample is unlikely to come from the target distribution (given the test’s assumptions).\n",
    "  This does *not* tell you the exact alternative; use the plots to see whether the mismatch is in the center, skew, or tails.\n",
    "- If you **fail to reject**: you don’t have strong evidence against the target distribution. It is **not** a proof of normality.\n",
    "\n",
    "### A practical rule of thumb\n",
    "\n",
    "With large `n`, even tiny deviations can be statistically significant. Use AD as a **diagnostic** alongside effect-size thinking and domain context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9adf981",
   "metadata": {},
   "source": [
    "## 8) Common pitfalls and diagnostics\n",
    "\n",
    "- **Parameter estimation matters**: the null distribution changes if you estimate parameters from the data.\n",
    "- **Outliers**: AD will often flag a single extreme point (sometimes that’s desired; sometimes it’s a data-quality problem).\n",
    "- **Dependence** (time series, spatial data): AD assumes i.i.d.; autocorrelation can create false rejections.\n",
    "- **Discrete / rounded data**: ties violate the continuous-data derivation; consider simulation/permutation approaches.\n",
    "- **Multiple testing**: if you test many groups/features, adjust your significance threshold.\n",
    "\n",
    "Diagnostics that pair well with AD:\n",
    "\n",
    "- CDF / P–P plots (global mismatch)\n",
    "- contribution plots (where in the distribution the statistic is coming from)\n",
    "- domain-specific residual checks (e.g., heteroskedasticity, seasonality)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba5428d",
   "metadata": {},
   "source": [
    "## 9) Exercises\n",
    "\n",
    "1. Implement a CDF for another distribution (e.g., exponential with rate λ) and run `anderson_darling_statistic` against it.\n",
    "2. Use `ad_null_stats_normality` to compute your own critical values for different sample sizes (`n=20`, `n=200`) and compare.\n",
    "3. Build two alternatives (skewed vs heavy-tailed) and compare how the contribution plots differ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5711e71",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Anderson, T. W., & Darling, D. A. (1952). *Asymptotic theory of certain “goodness of fit” criteria based on stochastic processes*.\n",
    "- Stephens, M. A. (1974/1976). Approximations and corrections for EDF statistics (commonly used for AD p-values).\n",
    "- SciPy: `scipy.stats.anderson` (returns the statistic and critical values for several distributions).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}