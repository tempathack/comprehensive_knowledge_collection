{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "913073d6",
   "metadata": {},
   "source": [
    "# Chi-square goodness-of-fit test (χ² GOF)\n",
    "\n",
    "The chi-square goodness-of-fit test answers:\n",
    "\n",
    "> “Do these observed category counts look like they came from a **specified** categorical distribution?”\n",
    "\n",
    "It’s the right tool when you have:\n",
    "- **one** categorical variable (k categories)\n",
    "- **counts** per category (not measurements)\n",
    "- expected probabilities for each category under the null hypothesis\n",
    "\n",
    "---\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "By the end you should be able to:\n",
    "- set up $H_0/H_1$ for χ² GOF\n",
    "- compute the χ² statistic, degrees of freedom, and a p-value\n",
    "- interpret the result correctly (what “reject” / “fail to reject” mean)\n",
    "- diagnose *which* categories drive the result (residuals + contributions)\n",
    "- implement the test from scratch with NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301a8484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "from math import erf, sqrt\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254d6193",
   "metadata": {},
   "source": [
    "## 1) What it’s used for (and what it’s not)\n",
    "\n",
    "### Used for\n",
    "\n",
    "You use χ² GOF when you want to compare **observed counts** to an **expected distribution**.\n",
    "\n",
    "Examples:\n",
    "- Is a die fair (uniform probabilities across 6 faces)?\n",
    "- Does a website’s traffic split match a target mix (e.g., 50% mobile, 30% desktop, 20% tablet)?\n",
    "- Do survey responses match a claimed distribution?\n",
    "\n",
    "### Not the same as...\n",
    "\n",
    "- **χ² test of independence**: compares *two* categorical variables via a contingency table.\n",
    "- **KS / Anderson–Darling**: goodness-of-fit for *continuous* distributions (without binning).\n",
    "\n",
    "Conceptually, χ² GOF is a large-sample approximation to a **multinomial** model under $H_0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bbd638",
   "metadata": {},
   "source": [
    "## 2) Hypotheses\n",
    "\n",
    "Suppose there are $k$ categories with expected probabilities:\n",
    "\n",
    "$$\n",
    "\\mathbf{p}_0 = (p_{01}, \\dots, p_{0k}),\\quad \\sum_{i=1}^k p_{0i}=1\n",
    "$$\n",
    "\n",
    "With observed counts $\\mathbf{O}=(O_1,\\dots,O_k)$ and total $n=\\sum_i O_i$:\n",
    "\n",
    "- **Null** $H_0$: the data were generated with probabilities $\\mathbf{p}_0$\n",
    "- **Alternative** $H_1$: at least one category probability differs from $\\mathbf{p}_0$\n",
    "\n",
    "This is a *global* test: it detects that **something** differs, then you inspect residuals to see *where*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096b099f",
   "metadata": {},
   "source": [
    "## 3) The test statistic (Pearson’s χ²)\n",
    "\n",
    "Under $H_0$, the expected count in category $i$ is:\n",
    "\n",
    "$$\n",
    "E_i = n\\,p_{0i}\n",
    "$$\n",
    "\n",
    "Pearson’s chi-square statistic is:\n",
    "\n",
    "$$\n",
    "\\chi^2 = \\sum_{i=1}^k \\frac{(O_i - E_i)^2}{E_i}\n",
    "$$\n",
    "\n",
    "### Why this form?\n",
    "\n",
    "- $O_i-E_i$ is the raw discrepancy.\n",
    "- Dividing by $E_i$ scales it by the typical size of fluctuations (variance grows with $E_i$).\n",
    "- Squaring makes positive/negative deviations add up.\n",
    "\n",
    "A helpful diagnostic is the **standardized residual**:\n",
    "\n",
    "$$\n",
    "R_i = \\frac{O_i - E_i}{\\sqrt{E_i}}\n",
    "\\quad\\Rightarrow\\quad\n",
    "\\chi^2 = \\sum_i R_i^2\n",
    "$$\n",
    "\n",
    "So χ² is literally the sum of squared standardized residuals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d796a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warm-up: see the pieces on a tiny example\n",
    "observed_counts = np.array([18, 22, 20])\n",
    "expected_probs = np.array([1 / 3, 1 / 3, 1 / 3])\n",
    "\n",
    "n = observed_counts.sum()\n",
    "expected_counts = n * expected_probs\n",
    "\n",
    "differences = observed_counts - expected_counts\n",
    "standardized_residuals = differences / np.sqrt(expected_counts)\n",
    "contributions = differences**2 / expected_counts\n",
    "\n",
    "np.column_stack(\n",
    "    [observed_counts, expected_counts, differences, standardized_residuals, contributions]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db47e39",
   "metadata": {},
   "source": [
    "The columns above are:\n",
    "\n",
    "1. observed $O_i$\n",
    "2. expected $E_i$\n",
    "3. difference $O_i-E_i$\n",
    "4. standardized residual $R_i=(O_i-E_i)/\\sqrt{E_i}$\n",
    "5. contribution $(O_i-E_i)^2/E_i$ (these sum to χ²)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f3901",
   "metadata": {},
   "source": [
    "## 4) Degrees of freedom\n",
    "\n",
    "If all $k$ probabilities are fully specified under $H_0$ (no parameters estimated from the data), then:\n",
    "\n",
    "$$\n",
    "\\chi^2 \\overset{H_0}{\\approx} \\chi^2_{\\nu},\\quad \\nu = k-1\n",
    "$$\n",
    "\n",
    "Why $k-1$ and not $k$?\n",
    "\n",
    "- The probabilities must sum to 1, so only $k-1$ of the counts can vary freely.\n",
    "\n",
    "If you estimated $m$ parameters from the data (e.g., you fit a Poisson rate $\\lambda$ before comparing binned counts), you reduce df:\n",
    "\n",
    "$$\n",
    "\\nu = (k-1) - m\n",
    "$$\n",
    "\n",
    "This matters: estimating parameters makes the null more flexible, so you need fewer df.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b37c780",
   "metadata": {},
   "source": [
    "## 5) Assumptions / when the approximation is ok\n",
    "\n",
    "χ² GOF relies on an asymptotic (large-sample) approximation.\n",
    "\n",
    "Common practical checks:\n",
    "\n",
    "- Observations are **independent**.\n",
    "- Categories are **mutually exclusive** and **collectively exhaustive**.\n",
    "- Expected counts are not too small.\n",
    "  - Rule of thumb: all $E_i \\ge 5$ (or at least 80% ≥ 5 and none < 1).\n",
    "\n",
    "If expected counts are small:\n",
    "- combine rare categories, or\n",
    "- use a Monte Carlo / exact multinomial approach.\n",
    "\n",
    "Also remember:\n",
    "- The test is sensitive to sample size: with large $n$, tiny deviations can become statistically significant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f4645e",
   "metadata": {},
   "source": [
    "## 6) From-scratch implementation (NumPy-only core)\n",
    "\n",
    "We’ll implement:\n",
    "\n",
    "- χ² statistic and per-category contributions\n",
    "- degrees of freedom\n",
    "- p-value via Monte Carlo sampling from a χ² distribution (using only NumPy)\n",
    "- a fast p-value approximation (Wilson–Hilferty)\n",
    "- a simple effect size: Cramér’s V for GOF\n",
    "\n",
    "We’ll then compare with SciPy as a practical reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3e18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _as_1d_nonnegative(name, array_like):\n",
    "    values = np.asarray(array_like, dtype=float)\n",
    "    if values.ndim != 1:\n",
    "        raise ValueError(f\"{name} must be a 1D array-like.\")\n",
    "    if not np.all(np.isfinite(values)):\n",
    "        raise ValueError(f\"{name} must contain only finite values.\")\n",
    "    if np.any(values < 0):\n",
    "        raise ValueError(f\"{name} must be non-negative.\")\n",
    "    return values\n",
    "\n",
    "\n",
    "def chi_square_gof_statistic(observed_counts, *, expected_probs=None, expected_counts=None):\n",
    "    '''Compute Pearson's χ² GOF statistic and diagnostics.\n",
    "\n",
    "    Provide either expected_probs (summing to 1) or expected_counts.\n",
    "    '''\n",
    "\n",
    "    observed_counts = _as_1d_nonnegative(\"observed_counts\", observed_counts)\n",
    "    total_count = float(observed_counts.sum())\n",
    "    if total_count <= 0:\n",
    "        raise ValueError(\"observed_counts must sum to > 0.\")\n",
    "\n",
    "    if expected_counts is None:\n",
    "        if expected_probs is None:\n",
    "            raise ValueError(\"Provide expected_probs or expected_counts.\")\n",
    "\n",
    "        expected_probs = _as_1d_nonnegative(\"expected_probs\", expected_probs)\n",
    "        if expected_probs.shape != observed_counts.shape:\n",
    "            raise ValueError(\"expected_probs must have the same shape as observed_counts.\")\n",
    "\n",
    "        prob_sum = float(expected_probs.sum())\n",
    "        if not np.isclose(prob_sum, 1.0):\n",
    "            raise ValueError(f\"expected_probs must sum to 1. Got {prob_sum}.\")\n",
    "\n",
    "        expected_counts = total_count * expected_probs\n",
    "    else:\n",
    "        expected_counts = _as_1d_nonnegative(\"expected_counts\", expected_counts)\n",
    "        if expected_counts.shape != observed_counts.shape:\n",
    "            raise ValueError(\"expected_counts must have the same shape as observed_counts.\")\n",
    "\n",
    "        expected_sum = float(expected_counts.sum())\n",
    "        if expected_sum <= 0:\n",
    "            raise ValueError(\"expected_counts must sum to > 0.\")\n",
    "\n",
    "        # Rescale to match the observed total (helps with rounding or probabilities * n).\n",
    "        expected_counts = expected_counts * (total_count / expected_sum)\n",
    "\n",
    "    if np.any(expected_counts <= 0):\n",
    "        raise ValueError(\"All expected counts must be > 0 (no zero-probability categories).\")\n",
    "\n",
    "    differences = observed_counts - expected_counts\n",
    "    contributions = differences**2 / expected_counts\n",
    "    chi2_stat = float(contributions.sum())\n",
    "\n",
    "    standardized_residuals = differences / np.sqrt(expected_counts)\n",
    "\n",
    "    return {\n",
    "        \"chi2\": chi2_stat,\n",
    "        \"observed\": observed_counts,\n",
    "        \"expected\": expected_counts,\n",
    "        \"differences\": differences,\n",
    "        \"contributions\": contributions,\n",
    "        \"standardized_residuals\": standardized_residuals,\n",
    "        \"n\": total_count,\n",
    "        \"k\": int(observed_counts.size),\n",
    "    }\n",
    "\n",
    "\n",
    "def chi_square_gof_df(k, ddof=0):\n",
    "    df = int(k - 1 - ddof)\n",
    "    if df <= 0:\n",
    "        raise ValueError(\n",
    "            f\"Degrees of freedom must be positive. Got df={df} (k={k}, ddof={ddof}).\"\n",
    "        )\n",
    "    return df\n",
    "\n",
    "\n",
    "def chi_square_sf_mc(x, df, *, n_sim=200_000, batch_size=50_000, rng=None):\n",
    "    '''Monte Carlo estimate of P(ChiSq_df >= x).\n",
    "\n",
    "    Uses ChiSq_df = sum_{j=1..df} Z_j^2 where Z_j ~ N(0,1).\n",
    "    '''\n",
    "\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "\n",
    "    x = float(x)\n",
    "    if x < 0:\n",
    "        return 1.0, 0.0\n",
    "\n",
    "    n_sim = int(n_sim)\n",
    "    batch_size = int(batch_size)\n",
    "    if n_sim <= 0 or batch_size <= 0:\n",
    "        raise ValueError(\"n_sim and batch_size must be positive integers.\")\n",
    "\n",
    "    count_ge = 0\n",
    "    remaining = n_sim\n",
    "\n",
    "    while remaining > 0:\n",
    "        current = min(batch_size, remaining)\n",
    "        sims = np.square(rng.standard_normal(size=(current, df))).sum(axis=1)\n",
    "        count_ge += int(np.count_nonzero(sims >= x))\n",
    "        remaining -= current\n",
    "\n",
    "    p_value = count_ge / n_sim\n",
    "    se = sqrt(p_value * (1 - p_value) / n_sim)\n",
    "    return p_value, se\n",
    "\n",
    "\n",
    "def chi_square_sf_wilson_hilferty(x, df):\n",
    "    '''Fast upper-tail approximation using the Wilson–Hilferty transform.'''\n",
    "\n",
    "    x = float(x)\n",
    "    df = float(df)\n",
    "\n",
    "    if x <= 0:\n",
    "        return 1.0\n",
    "\n",
    "    z = ((x / df) ** (1 / 3) - (1 - 2 / (9 * df))) / sqrt(2 / (9 * df))\n",
    "    phi = 0.5 * (1.0 + erf(z / sqrt(2.0)))\n",
    "    return 1.0 - phi\n",
    "\n",
    "\n",
    "def cramers_v_gof(chi2_stat, n, k):\n",
    "    return sqrt(float(chi2_stat) / (float(n) * (k - 1)))\n",
    "\n",
    "\n",
    "def chi_square_gof_test(\n",
    "    observed_counts,\n",
    "    *,\n",
    "    expected_probs=None,\n",
    "    expected_counts=None,\n",
    "    ddof=0,\n",
    "    alpha=0.05,\n",
    "    n_sim=200_000,\n",
    "    rng=None,\n",
    "):\n",
    "    details = chi_square_gof_statistic(\n",
    "        observed_counts, expected_probs=expected_probs, expected_counts=expected_counts\n",
    "    )\n",
    "\n",
    "    df = chi_square_gof_df(details[\"k\"], ddof=ddof)\n",
    "\n",
    "    p_mc, p_mc_se = chi_square_sf_mc(details[\"chi2\"], df, n_sim=n_sim, rng=rng)\n",
    "    p_wh = chi_square_sf_wilson_hilferty(details[\"chi2\"], df)\n",
    "\n",
    "    return {\n",
    "        **details,\n",
    "        \"df\": df,\n",
    "        \"alpha\": float(alpha),\n",
    "        \"p_value_mc\": float(p_mc),\n",
    "        \"p_value_mc_se\": float(p_mc_se),\n",
    "        \"p_value_wh\": float(p_wh),\n",
    "        \"reject_h0_mc\": bool(p_mc < alpha),\n",
    "        \"cramers_v\": float(cramers_v_gof(details[\"chi2\"], details[\"n\"], details[\"k\"])),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77a4fa2",
   "metadata": {},
   "source": [
    "## 7) Example: is a die fair?\n",
    "\n",
    "We roll a 6-sided die $n$ times.\n",
    "\n",
    "- $H_0$: each face has probability $1/6$\n",
    "- $H_1$: at least one face differs\n",
    "\n",
    "We’ll look at two datasets:\n",
    "\n",
    "1) a sample from a fair die (should usually *not* reject)\n",
    "2) a sample from a biased die (should reject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d05cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = np.arange(1, 7)\n",
    "uniform_probs = np.ones(6) / 6\n",
    "\n",
    "n_rolls = 120\n",
    "\n",
    "rng_example = np.random.default_rng(1)\n",
    "observed_fair = rng_example.multinomial(n_rolls, uniform_probs)\n",
    "observed_biased = rng_example.multinomial(n_rolls, np.array([0.10, 0.10, 0.10, 0.10, 0.10, 0.50]))\n",
    "\n",
    "rng_mc_fair = np.random.default_rng(100)\n",
    "rng_mc_biased = np.random.default_rng(101)\n",
    "\n",
    "fair_result = chi_square_gof_test(observed_fair, expected_probs=uniform_probs, n_sim=200_000, rng=rng_mc_fair)\n",
    "biased_result = chi_square_gof_test(observed_biased, expected_probs=uniform_probs, n_sim=200_000, rng=rng_mc_biased)\n",
    "\n",
    "{\n",
    "    \"observed_fair\": observed_fair,\n",
    "    \"chi2_fair\": fair_result[\"chi2\"],\n",
    "    \"p_mc_fair\": fair_result[\"p_value_mc\"],\n",
    "    \"reject_fair@0.05\": fair_result[\"reject_h0_mc\"],\n",
    "    \"observed_biased\": observed_biased,\n",
    "    \"chi2_biased\": biased_result[\"chi2\"],\n",
    "    \"p_mc_biased\": biased_result[\"p_value_mc\"],\n",
    "    \"reject_biased@0.05\": biased_result[\"reject_h0_mc\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f723e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Sample from a fair die\", \"Sample from a biased die\"),\n",
    ")\n",
    "\n",
    "for col, observed in [(1, observed_fair), (2, observed_biased)]:\n",
    "    expected = observed.sum() * uniform_probs\n",
    "    fig.add_trace(go.Bar(name=\"Observed\", x=faces, y=observed), row=1, col=col)\n",
    "    fig.add_trace(\n",
    "        go.Bar(name=\"Expected (H0)\", x=faces, y=expected, marker_color=\"rgba(0,0,0,0.25)\"),\n",
    "        row=1,\n",
    "        col=col,\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Observed vs expected counts (χ² GOF setup)\",\n",
    "    barmode=\"group\",\n",
    "    legend_title_text=\"Counts\",\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Face\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Face\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Count\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Count\", row=1, col=2)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbe16ed",
   "metadata": {},
   "source": [
    "### Which categories drive the result?\n",
    "\n",
    "Two useful per-category diagnostics:\n",
    "\n",
    "- **Standardized residuals**: $R_i=(O_i-E_i)/\\sqrt{E_i}$ (signed)\n",
    "- **Contributions**: $(O_i-E_i)^2/E_i$ (non-negative)\n",
    "\n",
    "Large absolute residuals / contributions point to categories that disagree most with $H_0$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d94741",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.1,\n",
    "    subplot_titles=(\"Standardized residuals (signed)\", \"χ² contributions (sum = χ²)\"),\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=faces, y=biased_result[\"standardized_residuals\"], name=\"Residual\"),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_hline(y=0, line_width=1, line_color=\"black\", row=1, col=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=faces, y=biased_result[\"contributions\"], name=\"Contribution\", marker_color=\"#636EFA\"),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.update_layout(title=\"Diagnostics for the biased sample\")\n",
    "fig.update_xaxes(title_text=\"Face\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Residual\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Contribution\", row=2, col=1)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09cdb0d",
   "metadata": {},
   "source": [
    "### Visualizing the p-value (null distribution)\n",
    "\n",
    "Under $H_0$, the χ² statistic follows a χ² distribution (approximately).\n",
    "\n",
    "A p-value is:\n",
    "\n",
    "$$\n",
    "\\text{p-value} = \\Pr(\\chi^2_{\\nu} \\ge \\chi^2_{\\text{obs}} \\mid H_0)\n",
    "$$\n",
    "\n",
    "So it’s a tail probability under the null model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d7b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = biased_result[\"df\"]\n",
    "chi2_obs = biased_result[\"chi2\"]\n",
    "alpha = biased_result[\"alpha\"]\n",
    "\n",
    "rng_null = np.random.default_rng(123)\n",
    "null_samples = np.square(rng_null.standard_normal(size=(60_000, df))).sum(axis=1)\n",
    "\n",
    "critical_value = float(np.quantile(null_samples, 1 - alpha))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_histogram(\n",
    "    x=null_samples[null_samples < chi2_obs],\n",
    "    nbinsx=60,\n",
    "    name=\"Null samples (< observed)\",\n",
    "    marker_color=\"lightgray\",\n",
    "    opacity=0.8,\n",
    ")\n",
    "fig.add_histogram(\n",
    "    x=null_samples[null_samples >= chi2_obs],\n",
    "    nbinsx=60,\n",
    "    name=\"Tail samples (≥ observed)\",\n",
    "    marker_color=\"crimson\",\n",
    "    opacity=0.9,\n",
    ")\n",
    "\n",
    "fig.add_vline(\n",
    "    x=chi2_obs,\n",
    "    line_width=3,\n",
    "    line_color=\"crimson\",\n",
    "    annotation_text=f\"Observed χ² = {chi2_obs:.2f}\",\n",
    "    annotation_position=\"top right\",\n",
    ")\n",
    "fig.add_vline(\n",
    "    x=critical_value,\n",
    "    line_width=2,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"black\",\n",
    "    annotation_text=f\"Critical (α={alpha:.2f}) ≈ {critical_value:.2f}\",\n",
    "    annotation_position=\"top left\",\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Null distribution for χ²(df={df}) with observed statistic (biased sample)\",\n",
    "    barmode=\"overlay\",\n",
    "    xaxis_title=\"χ² statistic\",\n",
    "    yaxis_title=\"Frequency\",\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "{\n",
    "    \"df\": df,\n",
    "    \"chi2_obs\": chi2_obs,\n",
    "    \"p_value_mc\": biased_result[\"p_value_mc\"],\n",
    "    \"p_value_mc_se\": biased_result[\"p_value_mc_se\"],\n",
    "    \"p_value_wh_approx\": biased_result[\"p_value_wh\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375a1f48",
   "metadata": {},
   "source": [
    "## 8) How to interpret the result\n",
    "\n",
    "Pick a significance level α (often 0.05).\n",
    "\n",
    "- If p-value < α: **reject $H_0$**\n",
    "  - The observed counts are unlikely *if* the expected distribution were true.\n",
    "  - Interpretable as evidence of a mismatch.\n",
    "\n",
    "- If p-value ≥ α: **fail to reject $H_0$**\n",
    "  - The data are reasonably consistent with the expected distribution.\n",
    "  - This is not proof that $H_0$ is true (you may have low power).\n",
    "\n",
    "### What it does not mean\n",
    "\n",
    "- The p-value is not $\\Pr(H_0 \\mid \\text{data})$.\n",
    "- A non-significant p-value does not mean “the distributions are identical”.\n",
    "\n",
    "### Effect size (optional but useful)\n",
    "\n",
    "For goodness-of-fit, a common effect size is Cramér’s V:\n",
    "\n",
    "$$\n",
    "V = \\sqrt{\\frac{\\chi^2}{n(k-1)}}\n",
    "$$\n",
    "\n",
    "- $V \\approx 0$ means very close to the expected distribution.\n",
    "- For fixed proportional deviations, χ² grows with $n$, but $V$ stays roughly stable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef346aba",
   "metadata": {},
   "source": [
    "## 9) Example: known non-uniform expected mix (candy colors)\n",
    "\n",
    "Suppose a brand claims the following color mix:\n",
    "\n",
    "- Blue 24%, Orange 20%, Green 16%, Yellow 14%, Red 13%, Brown 13%\n",
    "\n",
    "We sample a bag and count colors. Are the counts consistent with the claim?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a794ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.array([\"Blue\", \"Orange\", \"Green\", \"Yellow\", \"Red\", \"Brown\"])\n",
    "expected_probs_claim = np.array([0.24, 0.20, 0.16, 0.14, 0.13, 0.13])\n",
    "\n",
    "# A sample that is slightly different from the claim\n",
    "observed_colors = np.array([40, 50, 30, 28, 28, 24])\n",
    "\n",
    "rng_mc_colors = np.random.default_rng(202)\n",
    "color_result = chi_square_gof_test(\n",
    "    observed_colors,\n",
    "    expected_probs=expected_probs_claim,\n",
    "    n_sim=250_000,\n",
    "    rng=rng_mc_colors,\n",
    ")\n",
    "\n",
    "{\n",
    "    \"observed\": dict(zip(colors, observed_colors.astype(int))),\n",
    "    \"chi2\": color_result[\"chi2\"],\n",
    "    \"df\": color_result[\"df\"],\n",
    "    \"p_value_mc\": color_result[\"p_value_mc\"],\n",
    "    \"reject@0.05\": color_result[\"reject_h0_mc\"],\n",
    "    \"cramers_v\": color_result[\"cramers_v\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a4604",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_colors = color_result[\"expected\"]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_bar(name=\"Observed\", x=colors, y=observed_colors)\n",
    "fig.add_bar(name=\"Expected (claim)\", x=colors, y=expected_colors, marker_color=\"rgba(0,0,0,0.25)\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Candy colors: observed vs expected\",\n",
    "    barmode=\"group\",\n",
    "    xaxis_title=\"Color\",\n",
    "    yaxis_title=\"Count\",\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03212588",
   "metadata": {},
   "source": [
    "## 10) Sample size sensitivity (why χ² can flag tiny deviations)\n",
    "\n",
    "If the true proportions differ from $\\mathbf{p}_0$ by some small amount, the χ² statistic tends to grow with $n$.\n",
    "\n",
    "We’ll keep the proportional deviation fixed and increase $n$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb66644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts_from_probs(n, probs):\n",
    "    probs = np.asarray(probs, dtype=float)\n",
    "    if not np.isclose(probs.sum(), 1.0):\n",
    "        raise ValueError(\"probs must sum to 1\")\n",
    "\n",
    "    raw = n * probs\n",
    "    counts = np.floor(raw).astype(int)\n",
    "    remainder = int(n - counts.sum())\n",
    "    if remainder > 0:\n",
    "        frac = raw - np.floor(raw)\n",
    "        add_to = np.argsort(frac)[::-1][:remainder]\n",
    "        counts[add_to] += 1\n",
    "    return counts\n",
    "\n",
    "\n",
    "# Base expectation: uniform over 6 categories\n",
    "p0 = np.ones(6) / 6\n",
    "\n",
    "# A small deviation that still sums to 0\n",
    "p_true = p0 + np.array([0.02, -0.01, 0.01, -0.02, 0.00, 0.00])\n",
    "\n",
    "sample_sizes = np.array([60, 120, 240, 500, 1000, 2000, 5000])\n",
    "chi2_values = []\n",
    "p_values = []\n",
    "\n",
    "from scipy.stats import chi2\n",
    "\n",
    "for n in sample_sizes:\n",
    "    observed = counts_from_probs(int(n), p_true)\n",
    "    result = chi_square_gof_statistic(observed, expected_probs=p0)\n",
    "    df = chi_square_gof_df(result[\"k\"])\n",
    "\n",
    "    chi2_values.append(result[\"chi2\"])\n",
    "    p_values.append(float(chi2.sf(result[\"chi2\"], df)))\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"χ² grows with n\", \"p-value shrinks with n\"))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=sample_sizes, y=chi2_values, mode=\"lines+markers\", name=\"χ²\"), row=1, col=1)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=sample_sizes, y=p_values, mode=\"lines+markers\", name=\"p-value\", marker_color=\"crimson\"),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"n\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"n\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"χ²\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"p-value\", type=\"log\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(title=\"Same proportional deviation, different sample sizes\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ebba2f",
   "metadata": {},
   "source": [
    "## 11) Practical check with SciPy\n",
    "\n",
    "SciPy has a built-in implementation that matches the formula:\n",
    "\n",
    "- `scipy.stats.chisquare(f_obs, f_exp, ddof=...)`\n",
    "\n",
    "It returns the χ² statistic and an exact p-value from the χ² distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d4c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "chi2_scipy, p_scipy = chisquare(observed_biased, f_exp=(observed_biased.sum() * uniform_probs))\n",
    "\n",
    "{\n",
    "    \"numpy_stat\": biased_result[\"chi2\"],\n",
    "    \"scipy_stat\": float(chi2_scipy),\n",
    "    \"scipy_p_value\": float(p_scipy),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d0396a",
   "metadata": {},
   "source": [
    "## 12) Checklist + common pitfalls\n",
    "\n",
    "- Use counts, not percentages (convert percentages to counts by multiplying by $n$).\n",
    "- Make sure expected probabilities sum to 1 and all expected counts are > 0.\n",
    "- Watch out for small expected counts (combine categories or use Monte Carlo / exact).\n",
    "- If you estimated parameters to build $\\mathbf{p}_0$ from the data, adjust df: $\\nu=(k-1)-m$.\n",
    "- A significant result doesn’t tell you which categories differ—use residuals / contributions.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1) Simulate many fair-die experiments and estimate the false-positive rate at α=0.05.\n",
    "2) Create a biased die with a subtle bias (e.g., 0.18 on one face) and see how large $n$ must be to detect it reliably.\n",
    "3) Try binning continuous data into categories and apply χ² GOF, adjusting df if you estimated parameters.\n",
    "\n",
    "## References\n",
    "\n",
    "- Pearson, K. (1900). *On the criterion...* (original χ² idea)\n",
    "- Any introductory statistics text on chi-square tests\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}