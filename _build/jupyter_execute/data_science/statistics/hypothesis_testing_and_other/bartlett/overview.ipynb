{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": [
    "# Bartlett’s test (homogeneity of variances)\n",
    "\n",
    "Bartlett’s test answers a very specific question:\n",
    "\n",
    "> **Do several groups look like they come from populations with the same variance?**\n",
    "\n",
    "It is most commonly used as a **variance-assumption check** before procedures that assume *equal variances* (homoscedasticity), such as:\n",
    "\n",
    "- one-way **ANOVA**\n",
    "- classical linear models with homoscedastic Gaussian noise\n",
    "\n",
    "Because Bartlett’s test is derived under **normality**, it can be *too eager* to reject when the data are heavy‑tailed or skewed. In those cases, consider robust alternatives like **Levene / Brown–Forsythe**.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning goals\n",
    "- State the null/alternative hypotheses for Bartlett’s test.\n",
    "- Understand the “why”: Bartlett as a likelihood‑ratio test under normality.\n",
    "- Implement the statistic from scratch with **NumPy only**.\n",
    "- Estimate p-values and critical values via **Monte Carlo** (NumPy only).\n",
    "- Use Plotly visuals to build intuition and interpret results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-prereq",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Sample variance (unbiased, `ddof=1`)\n",
    "- Logs and basic algebra\n",
    "- Hypothesis testing basics: p-values, significance level α\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-hypotheses",
   "metadata": {},
   "source": [
    "## What Bartlett’s test tests\n",
    "\n",
    "Assume we have `k` independent groups:\n",
    "\n",
    "- group *i* has observations $x_{i1},\\ldots,x_{in_i}$\n",
    "- each group is (approximately) normal with variance $\\sigma_i^2$\n",
    "\n",
    "### Hypotheses\n",
    "- **$H_0$**: $\\sigma_1^2 = \\sigma_2^2 = \\cdots = \\sigma_k^2$ (all variances equal)\n",
    "- **$H_1$**: not all $\\sigma_i^2$ are equal\n",
    "\n",
    "The test produces a statistic $T$ that (under $H_0$ and normality) is approximately:\n",
    "\n",
    "$$T \\sim \\chi^2_{k-1}$$\n",
    "\n",
    "So **large** values of $T$ are evidence *against* equal variances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-interpretation",
   "metadata": {},
   "source": [
    "## How to interpret the result\n",
    "\n",
    "- Choose a significance level $\\alpha$ (commonly 0.05).\n",
    "- Compute the test statistic $T$.\n",
    "- Compute the p-value: $\\mathbb{P}(\\chi^2_{k-1} \\ge T)$ (upper tail).\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "- **Small p-value** ($p \\le \\alpha$): reject $H_0$ → at least one group variance differs.\n",
    "- **Large p-value** ($p > \\alpha$): fail to reject $H_0$ → data are *compatible* with equal variances (not proof).\n",
    "\n",
    "In this notebook we’ll compute p-values / critical values with a Monte Carlo null distribution so we can stay NumPy-only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "SEED = 7\n",
    "rng = np.random.default_rng(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-toy-intuition",
   "metadata": {},
   "source": [
    "## Intuition via toy examples\n",
    "\n",
    "We’ll create two synthetic scenarios with the same group means:\n",
    "\n",
    "1) **Equal variances** (Bartlett should *not* reject)  \n",
    "2) **One group has a larger variance** (Bartlett should reject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-sim-toy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_groups_normal(sigmas, n_per_group, mu=0.0, rng=None):\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    groups = []\n",
    "    for sigma in sigmas:\n",
    "        groups.append(rng.normal(loc=mu, scale=float(sigma), size=int(n_per_group)))\n",
    "    return groups\n",
    "\n",
    "k = 4\n",
    "n_per_group = 40\n",
    "\n",
    "sigmas_equal = [1.0] * k\n",
    "sigmas_unequal = [1.0, 1.0, 1.0, 2.0]\n",
    "\n",
    "groups_equal = simulate_groups_normal(sigmas_equal, n_per_group=n_per_group, rng=rng)\n",
    "groups_unequal = simulate_groups_normal(sigmas_unequal, n_per_group=n_per_group, rng=rng)\n",
    "\n",
    "n_equal = [g.size for g in groups_equal]\n",
    "n_unequal = [g.size for g in groups_unequal]\n",
    "\n",
    "n_equal, n_unequal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-plot-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"$H_0$: equal variances\", \"$H_1$: one variance larger\"),\n",
    ")\n",
    "\n",
    "for col, groups in enumerate([groups_equal, groups_unequal], start=1):\n",
    "    for i, g in enumerate(groups, start=1):\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=g,\n",
    "                name=f\"G{i}\",\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                showlegend=(col == 1),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=col,\n",
    "        )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Same means, different spreads\",\n",
    "    height=450,\n",
    "    width=950,\n",
    "    violingap=0.05,\n",
    "    violingroupgap=0.2,\n",
    ")\n",
    "fig.update_yaxes(title_text=\"Value\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Value\", row=1, col=2)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-plot-variances",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_variances(groups):\n",
    "    return np.array([np.var(g, ddof=1) for g in groups], dtype=float)\n",
    "\n",
    "s2_equal = sample_variances(groups_equal)\n",
    "s2_unequal = sample_variances(groups_unequal)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Sample variances (equal)\", \"Sample variances (unequal)\"),\n",
    ")\n",
    "\n",
    "labels = [f\"G{i}\" for i in range(1, k + 1)]\n",
    "\n",
    "fig.add_trace(go.Bar(x=labels, y=s2_equal, showlegend=False), row=1, col=1)\n",
    "fig.add_trace(go.Bar(x=labels, y=s2_unequal, showlegend=False), row=1, col=2)\n",
    "\n",
    "fig.update_yaxes(title_text=\"Sample variance\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Sample variance\", row=1, col=2)\n",
    "fig.update_layout(height=380, width=950)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-statistic",
   "metadata": {},
   "source": [
    "## The Bartlett statistic (under normality)\n",
    "\n",
    "Let:\n",
    "\n",
    "- $n_i$ = sample size of group *i*\n",
    "- $s_i^2$ = unbiased sample variance of group *i* (`ddof=1`)\n",
    "- $N = \\sum_i n_i$\n",
    "- $k$ = number of groups\n",
    "\n",
    "Define the pooled variance:\n",
    "\n",
    "$$s_p^2 = \\frac{\\sum_i (n_i-1)s_i^2}{N-k}$$\n",
    "\n",
    "Bartlett’s statistic is:\n",
    "\n",
    "$$T = \\frac{(N-k)\\ln(s_p^2) - \\sum_i (n_i-1)\\ln(s_i^2)}{C}$$\n",
    "\n",
    "with a small correction factor:\n",
    "\n",
    "$$C = 1 + \\frac{1}{3(k-1)}\\left(\\sum_i \\frac{1}{n_i-1} - \\frac{1}{N-k}\\right)$$\n",
    "\n",
    "**Intuition**\n",
    "\n",
    "- If all group variances are similar, the pooled variance explains them well → $T$ is small.\n",
    "- If some $s_i^2$ differ a lot, the log terms diverge → $T$ grows.\n",
    "\n",
    "(Under $H_0$ and normality, $T$ is approximately $\\chi^2_{k-1}$.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-lrt",
   "metadata": {},
   "source": [
    "## Where the formula comes from (likelihood‑ratio test)\n",
    "\n",
    "Assuming each group is normally distributed, Bartlett’s test can be motivated as a **likelihood‑ratio test**.\n",
    "\n",
    "- Under $H_1$ (variances free): each group has its own variance $\\sigma_i^2$, and the likelihood is maximized by the group sample variances.\n",
    "- Under $H_0$ (common variance): all groups share one variance $\\sigma^2$, and the likelihood is maximized by the pooled variance $s_p^2$.\n",
    "\n",
    "The likelihood ratio $\\Lambda = L(H_0)/L(H_1)$ compares the best **single-variance** explanation to the best **separate-variances** explanation.\n",
    "After algebra, $-2\\log \\Lambda$ is (up to constants) exactly the numerator you saw: a weighted difference between $\\log(s_p^2)$ and the $\\log(s_i^2)$.\n",
    "\n",
    "Bartlett’s correction factor $C$ is a small finite-sample adjustment that makes the $\\chi^2_{k-1}$ approximation more accurate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-bartlett-stat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bartlett_statistic(groups):\n",
    "    \"Compute Bartlett's test statistic T (NumPy-only).\"\n",
    "\n",
    "    groups = [np.asarray(g, dtype=float).ravel() for g in groups]\n",
    "    k = len(groups)\n",
    "    if k < 2:\n",
    "        raise ValueError(\"Need at least two groups.\")\n",
    "\n",
    "    sample_sizes = np.array([g.size for g in groups], dtype=int)\n",
    "    if np.any(sample_sizes < 2):\n",
    "        raise ValueError(\"Each group must have at least 2 observations.\")\n",
    "\n",
    "    df = k - 1\n",
    "    weights = sample_sizes - 1\n",
    "    n_minus_k = int(sample_sizes.sum() - k)\n",
    "\n",
    "    sample_variances = np.array([np.var(g, ddof=1) for g in groups], dtype=float)\n",
    "    if np.any(sample_variances <= 0):\n",
    "        raise ValueError(\n",
    "            \"All groups must have positive sample variance (no constant groups).\"\n",
    "        )\n",
    "\n",
    "    pooled_var = float(np.sum(weights * sample_variances) / n_minus_k)\n",
    "\n",
    "    numerator = n_minus_k * np.log(pooled_var) - np.sum(weights * np.log(sample_variances))\n",
    "    c = 1.0 + (1.0 / (3.0 * df)) * (np.sum(1.0 / weights) - (1.0 / n_minus_k))\n",
    "\n",
    "    T = float(numerator / c)\n",
    "    return T, int(df), pooled_var, sample_sizes, sample_variances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-bartlett-toy",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_equal, df, pooled_equal, n_equal, s2_equal = bartlett_statistic(groups_equal)\n",
    "T_unequal, _, pooled_unequal, n_unequal, s2_unequal = bartlett_statistic(groups_unequal)\n",
    "\n",
    "print(f\"Equal-variance example:   T={T_equal:.3f}, df={df}, pooled_var={pooled_equal:.3f}\")\n",
    "print(f\"Unequal-variance example: T={T_unequal:.3f}, df={df}, pooled_var={pooled_unequal:.3f}\")\n",
    "print()\n",
    "print(\"Sample variances (equal):  \", np.round(s2_equal, 3))\n",
    "print(\"Sample variances (unequal):\", np.round(s2_unequal, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-mc",
   "metadata": {},
   "source": [
    "## NumPy-only p-values via a Monte Carlo null distribution\n",
    "\n",
    "Under $H_0$ (equal variances), the Bartlett statistic is **scale-invariant**: multiplying all data by a constant does not change $T$.\n",
    "\n",
    "That means the null distribution depends only on the group sizes $(n_1,\\ldots,n_k)$.\n",
    "So we can estimate a p-value without SciPy:\n",
    "\n",
    "1. Simulate many datasets under $H_0$ using **standard normal** samples with the same group sizes.\n",
    "2. Compute $T$ for each simulated dataset.\n",
    "3. Approximate\n",
    "   - **p-value**: fraction of simulated $T$ values greater than or equal to the observed $T$\n",
    "   - **critical value** at level $\\alpha$: the $(1-\\alpha)$ quantile of the simulated null distribution\n",
    "\n",
    "This is slower than the asymptotic $\\chi^2$ approximation, but it stays NumPy-only and is very explicit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-mc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_pdf(x, df):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    df = float(df)\n",
    "    coeff = 1.0 / (2.0 ** (df / 2.0) * math.gamma(df / 2.0))\n",
    "    return coeff * np.power(x, df / 2.0 - 1.0) * np.exp(-x / 2.0)\n",
    "\n",
    "\n",
    "def bartlett_null_distribution(sample_sizes, n_sim=25_000, seed=0):\n",
    "    \"Monte Carlo null distribution of Bartlett's T for given group sizes.\"\n",
    "\n",
    "    sample_sizes = np.asarray(sample_sizes, dtype=int)\n",
    "    if sample_sizes.ndim != 1 or sample_sizes.size < 2:\n",
    "        raise ValueError(\"sample_sizes must be 1D with length >= 2\")\n",
    "    if np.any(sample_sizes < 2):\n",
    "        raise ValueError(\"All sample sizes must be >= 2\")\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    k = int(sample_sizes.size)\n",
    "    df = k - 1\n",
    "\n",
    "    weights = sample_sizes - 1\n",
    "    n_minus_k = int(sample_sizes.sum() - k)\n",
    "\n",
    "    c = 1.0 + (1.0 / (3.0 * df)) * (np.sum(1.0 / weights) - (1.0 / n_minus_k))\n",
    "\n",
    "    weighted_s2_sum = np.zeros(n_sim, dtype=float)\n",
    "    weighted_log_s2_sum = np.zeros(n_sim, dtype=float)\n",
    "\n",
    "    for ni, wi in zip(sample_sizes, weights):\n",
    "        x = rng.standard_normal(size=(n_sim, int(ni)))\n",
    "        s2 = np.var(x, axis=1, ddof=1)\n",
    "        weighted_s2_sum += wi * s2\n",
    "        weighted_log_s2_sum += wi * np.log(s2)\n",
    "\n",
    "    pooled = weighted_s2_sum / n_minus_k\n",
    "    stats = (n_minus_k * np.log(pooled) - weighted_log_s2_sum) / c\n",
    "\n",
    "    return stats, df\n",
    "\n",
    "\n",
    "def bartlett_test_numpy(groups, n_sim=25_000, seed=0):\n",
    "    T, df, pooled_var, sample_sizes, sample_variances = bartlett_statistic(groups)\n",
    "    null_stats, _ = bartlett_null_distribution(sample_sizes, n_sim=n_sim, seed=seed)\n",
    "    p_value_mc = float(np.mean(null_stats >= T))\n",
    "    return {\n",
    "        \"stat\": T,\n",
    "        \"df\": df,\n",
    "        \"p_value_mc\": p_value_mc,\n",
    "        \"pooled_var\": pooled_var,\n",
    "        \"sample_sizes\": sample_sizes,\n",
    "        \"sample_variances\": sample_variances,\n",
    "        \"null_stats\": null_stats,\n",
    "    }\n",
    "\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "res_equal = bartlett_test_numpy(groups_equal, n_sim=35_000, seed=1)\n",
    "res_unequal = bartlett_test_numpy(groups_unequal, n_sim=35_000, seed=1)\n",
    "\n",
    "crit = float(np.quantile(res_equal[\"null_stats\"], 1 - alpha))\n",
    "\n",
    "print(f\"alpha = {alpha}\")\n",
    "print(f\"critical value (MC) ≈ {crit:.3f}\\n\")\n",
    "\n",
    "print(\"Equal-variance example\")\n",
    "print(f\"  T = {res_equal['stat']:.3f}  (df={res_equal['df']})\")\n",
    "print(f\"  p ≈ {res_equal['p_value_mc']:.4f}\\n\")\n",
    "\n",
    "print(\"Unequal-variance example\")\n",
    "print(f\"  T = {res_unequal['stat']:.3f}  (df={res_unequal['df']})\")\n",
    "print(f\"  p ≈ {res_unequal['p_value_mc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-plot-null",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_stats = res_equal[\"null_stats\"]\n",
    "\n",
    "x_max = float(np.quantile(null_stats, 0.999))\n",
    "x_grid = np.linspace(1e-6, x_max, 400)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=null_stats,\n",
    "        nbinsx=70,\n",
    "        histnorm=\"probability density\",\n",
    "        name=\"Monte Carlo null\",\n",
    "        opacity=0.6,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_grid,\n",
    "        y=chi2_pdf(x_grid, df=res_equal[\"df\"]),\n",
    "        mode=\"lines\",\n",
    "        name=f\"χ²(df={res_equal['df']}) approx\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_vline(\n",
    "    x=crit,\n",
    "    line=dict(color=\"black\", dash=\"dash\"),\n",
    "    annotation_text=f\"crit (α={alpha})\",\n",
    "    annotation_position=\"top left\",\n",
    ")\n",
    "fig.add_vline(\n",
    "    x=res_equal[\"stat\"],\n",
    "    line=dict(color=\"#2ca02c\"),\n",
    "    annotation_text=\"observed (equal)\",\n",
    "    annotation_position=\"top right\",\n",
    ")\n",
    "fig.add_vline(\n",
    "    x=res_unequal[\"stat\"],\n",
    "    line=dict(color=\"#d62728\"),\n",
    "    annotation_text=\"observed (unequal)\",\n",
    "    annotation_position=\"top right\",\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Bartlett statistic under H₀ (Monte Carlo) vs observed\",\n",
    "    xaxis_title=\"T\",\n",
    "    yaxis_title=\"Density\",\n",
    "    bargap=0.05,\n",
    "    height=450,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-reject-meaning",
   "metadata": {},
   "source": [
    "## What “rejecting” means (and what it doesn’t)\n",
    "\n",
    "If you reject $H_0$, you have evidence that **at least one** group variance differs.\n",
    "\n",
    "- Bartlett’s test does **not** tell you *which* groups differ.\n",
    "- A non-rejection does **not** prove variances are equal; it only means the data did not provide strong evidence against equality.\n",
    "\n",
    "A practical next step (if you reject) is to use methods that **do not require equal variances**, e.g. Welch’s ANOVA, robust regression, or variance-stabilizing transforms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-assumptions",
   "metadata": {},
   "source": [
    "## Assumptions and pitfalls\n",
    "\n",
    "Bartlett’s test is powerful under its assumptions, but those assumptions matter:\n",
    "\n",
    "- **Normality** within each group (or close to it). Bartlett can reject because of non-normality *even when variances are equal*.\n",
    "- **Independence** within and across groups.\n",
    "- **Outliers**: a single extreme value can inflate a sample variance and trigger rejection.\n",
    "\n",
    "If your groups are clearly skewed or heavy-tailed, prefer **Levene / Brown–Forsythe** (more robust), or consider transforming the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_bartlett_stats(distribution_fn, sample_sizes, n_rep=5_000, seed=0):\n",
    "    # distribution_fn(rng, size) must return an array of the given shape\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    sample_sizes = np.asarray(sample_sizes, dtype=int)\n",
    "\n",
    "    k = int(sample_sizes.size)\n",
    "    df = k - 1\n",
    "    weights = sample_sizes - 1\n",
    "    n_minus_k = int(sample_sizes.sum() - k)\n",
    "\n",
    "    c = 1.0 + (1.0 / (3.0 * df)) * (np.sum(1.0 / weights) - (1.0 / n_minus_k))\n",
    "\n",
    "    weighted_s2_sum = np.zeros(n_rep, dtype=float)\n",
    "    weighted_log_s2_sum = np.zeros(n_rep, dtype=float)\n",
    "\n",
    "    for ni, wi in zip(sample_sizes, weights):\n",
    "        x = distribution_fn(rng, size=(n_rep, int(ni)))\n",
    "        s2 = np.var(x, axis=1, ddof=1)\n",
    "        weighted_s2_sum += wi * s2\n",
    "        weighted_log_s2_sum += wi * np.log(s2)\n",
    "\n",
    "    pooled = weighted_s2_sum / n_minus_k\n",
    "    stats = (n_minus_k * np.log(pooled) - weighted_log_s2_sum) / c\n",
    "    return stats\n",
    "\n",
    "\n",
    "sample_sizes = np.array([20, 20, 20])\n",
    "alpha = 0.05\n",
    "\n",
    "# Critical value calibrated under normality\n",
    "null_stats_normal, df = bartlett_null_distribution(sample_sizes, n_sim=60_000, seed=0)\n",
    "crit = float(np.quantile(null_stats_normal, 1 - alpha))\n",
    "\n",
    "# Three equal-variance worlds: normal vs heavy-tailed vs skewed\n",
    "stats_normal = simulate_bartlett_stats(\n",
    "    lambda rng, size: rng.standard_normal(size),\n",
    "    sample_sizes,\n",
    "    n_rep=6_000,\n",
    "    seed=1,\n",
    ")\n",
    "\n",
    "# t(df=3) scaled to variance ~ 1 (Var = df/(df-2))\n",
    "scale_t3 = math.sqrt((3 - 2) / 3)\n",
    "stats_t3 = simulate_bartlett_stats(\n",
    "    lambda rng, size: rng.standard_t(df=3, size=size) * scale_t3,\n",
    "    sample_sizes,\n",
    "    n_rep=6_000,\n",
    "    seed=2,\n",
    ")\n",
    "\n",
    "# Lognormal scaled to variance ~ 1\n",
    "sigma_logn = 1.0\n",
    "var_logn = math.exp(2 * sigma_logn**2) - math.exp(sigma_logn**2)\n",
    "stats_logn = simulate_bartlett_stats(\n",
    "    lambda rng, size: rng.lognormal(mean=0.0, sigma=sigma_logn, size=size) / math.sqrt(var_logn),\n",
    "    sample_sizes,\n",
    "    n_rep=6_000,\n",
    "    seed=3,\n",
    ")\n",
    "\n",
    "empirical_type1 = {\n",
    "    \"Normal (assumption OK)\": float(np.mean(stats_normal >= crit)),\n",
    "    \"t(df=3) heavy-tailed\": float(np.mean(stats_t3 >= crit)),\n",
    "    \"Lognormal (skewed)\": float(np.mean(stats_logn >= crit)),\n",
    "}\n",
    "\n",
    "empirical_type1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-plot-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(empirical_type1.keys())\n",
    "values = list(empirical_type1.values())\n",
    "\n",
    "fig = go.Figure(\n",
    "    go.Bar(\n",
    "        x=labels,\n",
    "        y=values,\n",
    "        text=[f\"{v:.3f}\" for v in values],\n",
    "        textposition=\"outside\",\n",
    "    )\n",
    ")\n",
    "fig.add_hline(y=alpha, line=dict(color=\"black\", dash=\"dash\"))\n",
    "fig.update_layout(\n",
    "    title=f\"Empirical Type I error at α={alpha} (true variances equal)\",\n",
    "    xaxis_title=\"Data distribution\",\n",
    "    yaxis_title=\"P(reject H₀)\",\n",
    "    yaxis=dict(range=[0, max(values) + 0.05]),\n",
    "    height=420,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-power",
   "metadata": {},
   "source": [
    "## Power: when the variances truly differ\n",
    "\n",
    "“Power” here means: if one group’s variance is larger, how often does Bartlett’s test reject $H_0$?\n",
    "\n",
    "We’ll simulate normal data with 4 groups of equal size and vary the ratio $r = \\sigma_4/\\sigma$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_bartlett_stats_normal(sample_sizes, sigmas, n_rep=4_000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    sample_sizes = np.asarray(sample_sizes, dtype=int)\n",
    "    sigmas = np.asarray(sigmas, dtype=float)\n",
    "    if sample_sizes.size != sigmas.size:\n",
    "        raise ValueError(\"sample_sizes and sigmas must have same length\")\n",
    "\n",
    "    k = int(sample_sizes.size)\n",
    "    df = k - 1\n",
    "    weights = sample_sizes - 1\n",
    "    n_minus_k = int(sample_sizes.sum() - k)\n",
    "\n",
    "    c = 1.0 + (1.0 / (3.0 * df)) * (np.sum(1.0 / weights) - (1.0 / n_minus_k))\n",
    "\n",
    "    weighted_s2_sum = np.zeros(n_rep, dtype=float)\n",
    "    weighted_log_s2_sum = np.zeros(n_rep, dtype=float)\n",
    "\n",
    "    for ni, wi, sigma in zip(sample_sizes, weights, sigmas):\n",
    "        x = rng.normal(loc=0.0, scale=float(sigma), size=(n_rep, int(ni)))\n",
    "        s2 = np.var(x, axis=1, ddof=1)\n",
    "        weighted_s2_sum += wi * s2\n",
    "        weighted_log_s2_sum += wi * np.log(s2)\n",
    "\n",
    "    pooled = weighted_s2_sum / n_minus_k\n",
    "    stats = (n_minus_k * np.log(pooled) - weighted_log_s2_sum) / c\n",
    "    return stats\n",
    "\n",
    "\n",
    "sample_sizes = np.array([25, 25, 25, 25])\n",
    "alpha = 0.05\n",
    "\n",
    "null_stats, df = bartlett_null_distribution(sample_sizes, n_sim=60_000, seed=10)\n",
    "crit = float(np.quantile(null_stats, 1 - alpha))\n",
    "\n",
    "ratios = np.array([1.0, 1.1, 1.25, 1.5, 2.0, 3.0])\n",
    "\n",
    "power = []\n",
    "for r in ratios:\n",
    "    sigmas = np.array([1.0, 1.0, 1.0, r])\n",
    "    stats = simulate_bartlett_stats_normal(sample_sizes, sigmas, n_rep=5_000, seed=int(100 * r) + 1)\n",
    "    power.append(float(np.mean(stats >= crit)))\n",
    "\n",
    "power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-plot-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ratios, y=power, mode=\"lines+markers\", name=\"power\"))\n",
    "fig.add_hline(y=alpha, line=dict(color=\"black\", dash=\"dot\"), annotation_text=\"α\", annotation_position=\"bottom right\")\n",
    "fig.update_layout(\n",
    "    title=\"Power vs variance ratio (normal data)\",\n",
    "    xaxis_title=r\"Variance ratio r = σ₄ / σ\",\n",
    "    yaxis_title=\"P(reject H₀)\",\n",
    "    yaxis=dict(range=[0, 1.05]),\n",
    "    height=420,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-checklist",
   "metadata": {},
   "source": [
    "## Practical checklist\n",
    "\n",
    "- Use Bartlett when **normality is plausible** and you care about power.\n",
    "- If you reject $H_0$:\n",
    "  - consider **Welch’s ANOVA** (for means with unequal variances)\n",
    "  - use a **variance-stabilizing transform** (e.g., log for positive skew)\n",
    "  - use robust tests (**Levene / Brown–Forsythe**) when normality is doubtful\n",
    "- If you don’t reject $H_0$:\n",
    "  - treat it as *\"no strong evidence of unequal variances\"*, not proof of equality\n",
    "\n",
    "Tip: if you’re unsure about normality, you can skip the pre-test and directly use methods that are robust to unequal variances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-exercises",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Show (algebraically) that Bartlett’s statistic is **scale-invariant**.\n",
    "2. Modify `bartlett_null_distribution` to accept unequal group sizes like `[10, 20, 50]` and compare the null histogram shape.\n",
    "3. Implement **Levene’s test** (median-centered Brown–Forsythe variant) with NumPy and compare its Type I error to Bartlett on skewed data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-refs",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Bartlett, M. S. (1937). *Properties of sufficiency and statistical tests.* Proceedings of the Royal Society.\n",
    "- Any mathematical statistics text covering likelihood-ratio tests for normal models.\n",
    "- SciPy reference implementation: `scipy.stats.bartlett` (useful to compare against your NumPy implementation).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}