{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f39f871e",
   "metadata": {},
   "source": [
    "# Power Function Distribution (`powerlaw`)\n",
    "\n",
    "The **power function distribution** (called `powerlaw` in SciPy) is a simple one-parameter family of continuous distributions on $[0,1]$ with CDF\n",
    "\n",
    "$$F(x)=x^a.$$\n",
    "\n",
    "Equivalently,\n",
    "\n",
    "$$X \\sim \\texttt{powerlaw}(a) \\quad\\Longleftrightarrow\\quad X \\sim \\mathrm{Beta}(a,1).$$\n",
    "\n",
    "It’s useful whenever you need a flexible model for a **bounded proportion** that can concentrate near 0 or near 1. It also appears naturally in **order statistics**: the maximum of $n$ i.i.d. Uniform$(0,1)$ variables has `powerlaw` distribution with $a=n$.\n",
    "\n",
    "## What you’ll learn\n",
    "- classification, support, and parameterization (including SciPy’s `loc`/`scale`)\n",
    "- PDF/CDF/PPF and connections to Beta and order statistics\n",
    "- moments (mean/variance/skewness/kurtosis), MGF/CF, and entropy\n",
    "- how the shape parameter $a$ changes the distribution\n",
    "- derivations: expectation, variance, likelihood, and the MLE for $a$\n",
    "- **NumPy-only** sampling via inverse CDF + Monte Carlo validation\n",
    "- practical usage via `scipy.stats.powerlaw` (`pdf`, `cdf`, `rvs`, `fit`)\n",
    "- hypothesis testing, Bayesian modeling, and generative modeling patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fc26a1",
   "metadata": {},
   "source": [
    "## Notebook roadmap\n",
    "1) Title & classification\n",
    "2) Intuition & motivation\n",
    "3) Formal definition (PDF/CDF)\n",
    "4) Moments & properties\n",
    "5) Parameter interpretation\n",
    "6) Derivations (\\(\\mathbb{E}[X]\\), \\(\\mathrm{Var}(X)\\), likelihood)\n",
    "7) Sampling & simulation (NumPy-only)\n",
    "8) Visualization (PDF, CDF, Monte Carlo)\n",
    "9) SciPy integration (`scipy.stats.powerlaw`)\n",
    "10) Statistical use cases\n",
    "11) Pitfalls\n",
    "12) Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd09aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import special, stats\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "# Plotly rendering (CKC convention)\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 7\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "print(\"numpy \", np.__version__)\n",
    "print(\"scipy \", scipy.__version__)\n",
    "print(\"plotly\", plotly.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaca59e",
   "metadata": {},
   "source": [
    "## Prerequisites & notation\n",
    "\n",
    "**Prerequisites**\n",
    "- comfort with basic calculus (single-variable integration)\n",
    "- basic probability (PDF/CDF, expectation, variance)\n",
    "- basic statistics (likelihood, MLE)\n",
    "\n",
    "**Important terminology**\n",
    "- In SciPy, `powerlaw` is the **power function distribution** on a bounded interval.\n",
    "- It is *not* the heavy-tailed “power-law” distribution often used for wealth/city sizes (see `scipy.stats.pareto`, `scipy.stats.zipf`, etc.).\n",
    "\n",
    "**SciPy parameterization**\n",
    "SciPy uses a location-scale family:\n",
    "\n",
    "- `scipy.stats.powerlaw(a, loc=ℓ, scale=s)` has support \\(x \\in [\\ell,\\, \\ell+s]\\) with \\(s>0\\).\n",
    "- The canonical form in this notebook uses \\(\\ell=0\\), \\(s=1\\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2bfe8f",
   "metadata": {},
   "source": [
    "## 1) Title & Classification\n",
    "\n",
    "- **Name**: `powerlaw` (power function distribution)\n",
    "- **Type**: **Continuous**\n",
    "- **Support (canonical)**: \\(x \\in [0,1]\\) (density is defined for \\(0<x<1\\))\n",
    "- **Parameter space (canonical)**: shape \\(a>0\\)\n",
    "\n",
    "With SciPy’s location-scale parameters:\n",
    "\n",
    "- **Support**: \\(x \\in [\\ell, \\ell+s]\\)\n",
    "- **Parameters**: \\(a>0\\), \\(\\ell \\in \\mathbb{R}\\), \\(s>0\\)\n",
    "\n",
    "We write:\n",
    "\n",
    "$$X \\sim \\texttt{powerlaw}(a) \\equiv \\mathrm{Beta}(a,1).$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eed3916",
   "metadata": {},
   "source": [
    "## 2) Intuition & Motivation\n",
    "\n",
    "### 2.1 What it models\n",
    "`powerlaw` models a **bounded random variable** on \\([0,1]\\) whose probability mass can be “tilted” toward 0 or toward 1 with a single shape parameter \\(a\\).\n",
    "\n",
    "A useful way to think about it is via the transformation:\n",
    "\n",
    "- If \\(U \\sim \\mathrm{Uniform}(0,1)\\), then\n",
    "  $$X = U^{1/a} \\sim \\texttt{powerlaw}(a).$$\n",
    "\n",
    "So \\(a\\) controls how aggressively the uniform is “stretched” toward 0 (\\(a<1\\)) or toward 1 (\\(a>1\\)).\n",
    "\n",
    "### 2.2 Real-world use cases\n",
    "- **Proportions that lean toward 0 or 1**: completion rates, saturation fractions, normalized scores\n",
    "- **Order statistics**: maxima of uniforms (e.g., “best-of-\\(n\\)” effects)\n",
    "- **P-values under alternatives** (simple model): p-values often concentrate near 0; \\(\\mathrm{Beta}(a,1)\\) with \\(a<1\\) is a common approximation\n",
    "- **Simple generative noise on \\([0,1]\\)**: random thresholds, random quantiles\n",
    "\n",
    "### 2.3 Relations to other distributions\n",
    "- **Beta**: `powerlaw(a)` is exactly \\(\\mathrm{Beta}(a,1)\\).\n",
    "- **Uniform**: \\(a=1\\) gives \\(f(x)=1\\) on \\([0,1]\\).\n",
    "- **Exponential (via log transform)**: if \\(X \\sim \\texttt{powerlaw}(a)\\), then\n",
    "  $$-\\log X \\sim \\mathrm{Exponential}(\\text{rate}=a).$$\n",
    "- **Order statistic**: if \\(U_1,\\dots,U_n\\) are i.i.d. Uniform\\((0,1)\\), then \\(\\max_i U_i \\sim \\texttt{powerlaw}(n)\\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675a883f",
   "metadata": {},
   "source": [
    "## 3) Formal Definition\n",
    "\n",
    "### 3.1 Canonical PDF\n",
    "For \\(a>0\\) and \\(0<x<1\\):\n",
    "\n",
    "$$f(x\\mid a)= a\\,x^{a-1}.$$\n",
    "\n",
    "### 3.2 Canonical CDF\n",
    "The CDF is\n",
    "\n",
    "$$F(x\\mid a)=\\begin{cases}\n",
    "0, & x\\le 0\\\\\n",
    "x^a, & 0<x<1\\\\\n",
    "1, & x\\ge 1\\,.\n",
    "\\end{cases}$$\n",
    "\n",
    "### 3.3 Quantile function (inverse CDF)\n",
    "For \\(u\\in(0,1)\\):\n",
    "\n",
    "$$F^{-1}(u)=u^{1/a}.$$\n",
    "\n",
    "This yields a simple inverse-transform sampler.\n",
    "\n",
    "### 3.4 Location-scale form (SciPy)\n",
    "If \\(X\\sim\\texttt{powerlaw}(a)\\) on \\([0,1]\\) and we define \\(Y = \\ell + sX\\) with \\(s>0\\), then \\(Y\\) has support \\([\\ell,\\ell+s]\\) and\n",
    "\n",
    "$$f_Y(y\\mid a,\\ell,s)=\\frac{a}{s}\\left(\\frac{y-\\ell}{s}\\right)^{a-1},\\quad \\ell<y<\\ell+s,$$\n",
    "\n",
    "$$F_Y(y\\mid a,\\ell,s)=\\left(\\frac{y-\\ell}{s}\\right)^a,\\quad \\ell<y<\\ell+s.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d64daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerlaw_pdf(x: np.ndarray, a: float, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    '''Powerlaw (power function) PDF with SciPy-style loc/scale.\n",
    "\n",
    "    Canonical form corresponds to loc=0, scale=1.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    For a < 1, the density diverges as x -> loc (from the right).\n",
    "    '''\n",
    "\n",
    "    if a <= 0:\n",
    "        raise ValueError(\"a must be > 0\")\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    z = (x - loc) / scale\n",
    "\n",
    "    out = np.zeros_like(z, dtype=float)\n",
    "    mask = (z > 0) & (z < 1)\n",
    "\n",
    "    # Compute in log-space for numerical stability\n",
    "    log_pdf = (math.log(a) - math.log(scale)) + (a - 1.0) * np.log(z[mask])\n",
    "    out[mask] = np.exp(log_pdf)\n",
    "    return out\n",
    "\n",
    "\n",
    "def powerlaw_cdf(x: np.ndarray, a: float, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    '''Powerlaw CDF with SciPy-style loc/scale.'''\n",
    "\n",
    "    if a <= 0:\n",
    "        raise ValueError(\"a must be > 0\")\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    z = (x - loc) / scale\n",
    "\n",
    "    out = np.zeros_like(z, dtype=float)\n",
    "    out[z >= 1.0] = 1.0\n",
    "\n",
    "    mask = (z > 0) & (z < 1)\n",
    "    out[mask] = np.power(z[mask], a)\n",
    "    return out\n",
    "\n",
    "\n",
    "def powerlaw_ppf(u: np.ndarray, a: float, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    '''Powerlaw quantile function (inverse CDF).'''\n",
    "\n",
    "    if a <= 0:\n",
    "        raise ValueError(\"a must be > 0\")\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    u = np.asarray(u, dtype=float)\n",
    "    if np.any((u < 0) | (u > 1)):\n",
    "        raise ValueError(\"u must be in [0, 1]\")\n",
    "\n",
    "    return loc + scale * np.power(u, 1.0 / a)\n",
    "\n",
    "\n",
    "# Quick sanity check: PDF integrates to ~1 on [0,1]\n",
    "a0 = 2.5\n",
    "xgrid = np.linspace(1e-6, 1 - 1e-6, 400_000)\n",
    "area = np.trapz(powerlaw_pdf(xgrid, a0), xgrid)\n",
    "area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0103676",
   "metadata": {},
   "source": [
    "## 4) Moments & Properties\n",
    "\n",
    "A convenient closed form exists for **raw moments**. For \\(k>-a\\):\n",
    "\n",
    "$$\\mathbb{E}[X^k] = \\int_0^1 x^k\\,a x^{a-1}\\,dx = \\frac{a}{a+k}.$$\n",
    "\n",
    "### 4.1 Mean and variance\n",
    "Using \\(k=1\\) and \\(k=2\\):\n",
    "\n",
    "$$\\mathbb{E}[X] = \\frac{a}{a+1},\\qquad \\mathbb{E}[X^2] = \\frac{a}{a+2},$$\n",
    "\n",
    "$$\\mathrm{Var}(X) = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2 = \\frac{a}{(a+1)^2(a+2)}.$$\n",
    "\n",
    "### 4.2 Skewness and kurtosis\n",
    "Because `powerlaw(a)` is \\(\\mathrm{Beta}(a,1)\\), we can reuse standard beta formulas:\n",
    "\n",
    "$$\\gamma_1 = \\frac{2(1-a)\\sqrt{a+2}}{(a+3)\\sqrt{a}},$$\n",
    "\n",
    "$$\\gamma_2\\;\\text{(excess)} = \\frac{6\\big((a-1)^2(a+2)-a(a+3)\\big)}{a(a+3)(a+4)}.$$\n",
    "\n",
    "### 4.3 MGF and characteristic function\n",
    "The MGF exists for all real \\(t\\) (bounded support). A compact special-function expression is\n",
    "\n",
    "$$M_X(t)=\\mathbb{E}[e^{tX}] = {}_1F_1\\big(a; a+1; t\\big),$$\n",
    "\n",
    "where \\({}_1F_1\\) is the confluent hypergeometric function.\n",
    "The characteristic function is\n",
    "\n",
    "$$\\varphi_X(\\omega)=\\mathbb{E}[e^{i\\omega X}] = {}_1F_1\\big(a; a+1; i\\omega\\big).$$\n",
    "\n",
    "### 4.4 Entropy\n",
    "The differential entropy (in **nats**) has a simple closed form:\n",
    "\n",
    "$$H(X)=1-\\frac{1}{a}-\\log a.$$\n",
    "\n",
    "### 4.5 Mode (shape intuition)\n",
    "- If \\(a>1\\), the density increases on \\((0,1)\\) and the mode is at \\(x=1\\).\n",
    "- If \\(a=1\\), the distribution is uniform.\n",
    "- If \\(0<a<1\\), the density decreases and diverges at 0 (mode at \\(x=0\\)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerlaw_moments(a: float) -> dict:\n",
    "    '''Key moments and summary properties for the canonical powerlaw(a) on [0,1].'''\n",
    "\n",
    "    if a <= 0:\n",
    "        raise ValueError(\"a must be > 0\")\n",
    "\n",
    "    mean = a / (a + 1.0)\n",
    "    var = a / ((a + 1.0) ** 2 * (a + 2.0))\n",
    "\n",
    "    skew = (2.0 * (1.0 - a) * math.sqrt(a + 2.0)) / ((a + 3.0) * math.sqrt(a))\n",
    "\n",
    "    excess_kurt = (6.0 * (((a - 1.0) ** 2) * (a + 2.0) - a * (a + 3.0))) / (a * (a + 3.0) * (a + 4.0))\n",
    "    kurt = excess_kurt + 3.0\n",
    "\n",
    "    entropy = 1.0 - 1.0 / a - math.log(a)\n",
    "\n",
    "    return {\n",
    "        \"mean\": mean,\n",
    "        \"variance\": var,\n",
    "        \"skewness\": skew,\n",
    "        \"kurtosis\": kurt,\n",
    "        \"excess_kurtosis\": excess_kurt,\n",
    "        \"entropy_nats\": entropy,\n",
    "    }\n",
    "\n",
    "\n",
    "def powerlaw_mgf(t: np.ndarray, a: float) -> np.ndarray:\n",
    "    '''MGF M(t) = E[e^{tX}] using SciPy's confluent hypergeometric 1F1.'''\n",
    "\n",
    "    if a <= 0:\n",
    "        raise ValueError(\"a must be > 0\")\n",
    "\n",
    "    t = np.asarray(t)\n",
    "    return special.hyp1f1(a, a + 1.0, t)\n",
    "\n",
    "\n",
    "def powerlaw_cf(w: np.ndarray, a: float) -> np.ndarray:\n",
    "    '''Characteristic function phi(w) = E[e^{i w X}].'''\n",
    "\n",
    "    if a <= 0:\n",
    "        raise ValueError(\"a must be > 0\")\n",
    "\n",
    "    w = np.asarray(w)\n",
    "    return special.hyp1f1(a, a + 1.0, 1j * w)\n",
    "\n",
    "\n",
    "# Spot-check: mean/variance via Monte Carlo and an MGF identity\n",
    "\n",
    "a0 = 2.5\n",
    "n = 200_000\n",
    "u = rng.random(n)\n",
    "# avoid exact 0 for stability in downstream logs\n",
    "u = np.clip(u, np.finfo(float).tiny, 1.0)\n",
    "samples = u ** (1.0 / a0)\n",
    "\n",
    "mom = powerlaw_moments(a0)\n",
    "\n",
    "mc_mean = samples.mean()\n",
    "mc_var = samples.var(ddof=0)\n",
    "\n",
    "# MGF check: E[e^{tX}] at t=1.2\n",
    "\n",
    "t = 1.2\n",
    "mc_mgf = np.mean(np.exp(t * samples))\n",
    "theory_mgf = float(powerlaw_mgf(t, a0))\n",
    "\n",
    "mom, (mc_mean, mc_var, mc_mgf, theory_mgf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719488b6",
   "metadata": {},
   "source": [
    "## 5) Parameter Interpretation\n",
    "\n",
    "`powerlaw` has a single shape parameter \\(a\\).\n",
    "\n",
    "### 5.1 What \\(a\\) does\n",
    "- **\\(0<a<1\\)**: mass concentrates near 0; the PDF diverges at 0.\n",
    "- **\\(a=1\\)**: uniform on \\([0,1]\\).\n",
    "- **\\(a>1\\)**: mass concentrates near 1; the PDF increases toward 1.\n",
    "\n",
    "### 5.2 Mean and median as functions of \\(a\\)\n",
    "- Mean: \\(\\mathbb{E}[X]=\\frac{a}{a+1}\\) (increases toward 1 as \\(a\\to\\infty\\))\n",
    "- Median: solve \\(F(m)=1/2\\) gives \\(m = 2^{-1/a}\\)\n",
    "\n",
    "These simple formulas make it easy to interpret fitted \\(a\\) values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d8d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape changes: PDF and CDF for different a\n",
    "\n",
    "a_values = [0.3, 0.7, 1.0, 2.0, 5.0]\n",
    "x = np.linspace(1e-4, 1 - 1e-4, 500)\n",
    "\n",
    "fig_pdf = go.Figure()\n",
    "fig_cdf = go.Figure()\n",
    "\n",
    "for a in a_values:\n",
    "    fig_pdf.add_trace(go.Scatter(x=x, y=powerlaw_pdf(x, a), mode=\"lines\", name=f\"a={a:g}\"))\n",
    "    fig_cdf.add_trace(go.Scatter(x=x, y=powerlaw_cdf(x, a), mode=\"lines\", name=f\"a={a:g}\"))\n",
    "\n",
    "fig_pdf.update_layout(\n",
    "    title=\"Powerlaw PDF (canonical on [0,1])\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"f(x)\",\n",
    "    yaxis_type=\"log\",\n",
    ")\n",
    "fig_cdf.update_layout(title=\"Powerlaw CDF\", xaxis_title=\"x\", yaxis_title=\"F(x)\")\n",
    "\n",
    "fig_pdf.show()\n",
    "fig_cdf.show()\n",
    "\n",
    "# Mean as a function of a\n",
    "agrid = np.linspace(0.2, 8, 300)\n",
    "mean_grid = agrid / (agrid + 1)\n",
    "\n",
    "fig_mean = go.Figure()\n",
    "fig_mean.add_trace(go.Scatter(x=agrid, y=mean_grid, mode=\"lines\"))\n",
    "fig_mean.update_layout(title=\"Mean E[X] = a/(a+1)\", xaxis_title=\"a\", yaxis_title=\"E[X]\")\n",
    "fig_mean.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cee37e",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### 6.1 Expectation\n",
    "Starting from the PDF \\(f(x\\mid a)=a x^{a-1}\\) on \\((0,1)\\):\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbb{E}[X]\n",
    "&= \\int_0^1 x\\, a x^{a-1}\\,dx \\\\\n",
    "&= a\\int_0^1 x^{a}\\,dx \\\\\n",
    "&= a\\left[\\frac{x^{a+1}}{a+1}\\right]_0^1 \\\\\n",
    "&= \\frac{a}{a+1}.\n",
    "\\end{align}\n",
    "\n",
    "More generally, for \\(k>-a\\):\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbb{E}[X^k]\n",
    "&= \\int_0^1 x^k\\, a x^{a-1}\\,dx\n",
    "= a\\int_0^1 x^{a+k-1}\\,dx\n",
    "= \\frac{a}{a+k}.\n",
    "\\end{align}\n",
    "\n",
    "### 6.2 Variance\n",
    "Compute \\(\\mathbb{E}[X^2]=\\frac{a}{a+2}\\) and subtract the squared mean:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathrm{Var}(X)\n",
    "&= \\mathbb{E}[X^2] - \\mathbb{E}[X]^2 \\\\\n",
    "&= \\frac{a}{a+2} - \\left(\\frac{a}{a+1}\\right)^2\n",
    "= \\frac{a}{(a+1)^2(a+2)}.\n",
    "\\end{align}\n",
    "\n",
    "### 6.3 Likelihood and MLE\n",
    "For i.i.d. data \\(x_1,\\dots,x_n\\in(0,1)\\), the likelihood is\n",
    "\n",
    "$$L(a) = \\prod_{i=1}^n a x_i^{a-1} = a^n\\,\\exp\\Big((a-1)\\sum_{i=1}^n \\log x_i\\Big).$$\n",
    "\n",
    "The log-likelihood is\n",
    "\n",
    "$$\\ell(a)= n\\log a + (a-1)\\sum_{i=1}^n \\log x_i.$$\n",
    "\n",
    "Differentiate and set to zero:\n",
    "\n",
    "$$\\ell'(a)=\\frac{n}{a} + \\sum_{i=1}^n \\log x_i = 0\\quad\\Rightarrow\\quad \\hat a = -\\frac{n}{\\sum_{i=1}^n \\log x_i}.$$\n",
    "\n",
    "Because \\(\\sum \\log x_i < 0\\) for \\(x_i\\in(0,1)\\), the MLE \\(\\hat a\\) is positive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f447e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerlaw_loglikelihood(x: np.ndarray, a: float, loc: float = 0.0, scale: float = 1.0) -> float:\n",
    "    '''Log-likelihood for i.i.d. observations under powerlaw(a, loc, scale).'''\n",
    "\n",
    "    if a <= 0:\n",
    "        return -np.inf\n",
    "    if scale <= 0:\n",
    "        return -np.inf\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    z = (x - loc) / scale\n",
    "\n",
    "    if np.any((z <= 0) | (z >= 1)):\n",
    "        return -np.inf\n",
    "\n",
    "    n = z.size\n",
    "    return n * (math.log(a) - math.log(scale)) + (a - 1.0) * float(np.sum(np.log(z)))\n",
    "\n",
    "\n",
    "def powerlaw_mle_shape(x: np.ndarray, loc: float = 0.0, scale: float = 1.0) -> float:\n",
    "    '''Closed-form MLE for the shape a when loc/scale are known.'''\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    z = (x - loc) / scale\n",
    "\n",
    "    if np.any((z <= 0) | (z >= 1)):\n",
    "        raise ValueError(\"All observations must satisfy loc < x < loc+scale\")\n",
    "\n",
    "    s = float(np.sum(np.log(z)))  # negative\n",
    "    n = z.size\n",
    "    return -n / s\n",
    "\n",
    "\n",
    "# Demonstrate the MLE on simulated data\n",
    "\n",
    "a_true = 2.5\n",
    "n = 50_000\n",
    "x = np.clip(rng.random(n), np.finfo(float).tiny, 1.0) ** (1.0 / a_true)\n",
    "\n",
    "a_hat = powerlaw_mle_shape(x)\n",
    "ll_true = powerlaw_loglikelihood(x, a_true)\n",
    "ll_hat = powerlaw_loglikelihood(x, a_hat)\n",
    "\n",
    "a_true, a_hat, (ll_true, ll_hat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389b1ede",
   "metadata": {},
   "source": [
    "## 7) Sampling & Simulation\n",
    "\n",
    "Because the CDF is \\(F(x)=x^a\\), inverse transform sampling is immediate.\n",
    "\n",
    "### 7.1 Inverse-transform algorithm (NumPy-only)\n",
    "1. Sample \\(U\\sim\\mathrm{Uniform}(0,1)\\)\n",
    "2. Return \\(X = U^{1/a}\\)\n",
    "\n",
    "This works because:\n",
    "\n",
    "$$\\mathbb{P}(U^{1/a} \\le x) = \\mathbb{P}(U \\le x^a) = x^a.$$\n",
    "\n",
    "### 7.2 Alternative view (log transform)\n",
    "If \\(X\\sim\\texttt{powerlaw}(a)\\), then \\(-\\log X\\sim\\mathrm{Exponential}(\\text{rate}=a)\\). This can be useful for diagnostics and for building hierarchical models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec40bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerlaw_rvs_numpy(a: float, size: int, rng: np.random.Generator, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    '''Sample from powerlaw(a, loc, scale) using NumPy-only inverse CDF.'''\n",
    "\n",
    "    if a <= 0:\n",
    "        raise ValueError(\"a must be > 0\")\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    u = rng.random(size)\n",
    "\n",
    "    # u can be exactly 0 with tiny probability (finite-precision RNG);\n",
    "    # clipping avoids -inf if you later take logs of samples.\n",
    "    u = np.clip(u, np.finfo(float).tiny, 1.0)\n",
    "\n",
    "    x = u ** (1.0 / a)\n",
    "    return loc + scale * x\n",
    "\n",
    "\n",
    "# Monte Carlo validation\n",
    "\n",
    "a0 = 0.6\n",
    "n = 200_000\n",
    "samples = powerlaw_rvs_numpy(a0, n, rng)\n",
    "\n",
    "mom = powerlaw_moments(a0)\n",
    "\n",
    "mc = {\n",
    "    \"mean\": samples.mean(),\n",
    "    \"variance\": samples.var(ddof=0),\n",
    "    \"skewness\": stats.skew(samples, bias=True),\n",
    "    \"excess_kurtosis\": stats.kurtosis(samples, fisher=True, bias=True),\n",
    "}\n",
    "\n",
    "mom, mc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f1c742",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We’ll visualize:\n",
    "- the PDF for multiple values of `a`\n",
    "- the CDF and an empirical CDF from Monte Carlo samples\n",
    "- a histogram of Monte Carlo samples with the theoretical PDF overlay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ce4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram + theoretical PDF overlay\n",
    "\n",
    "a = 0.6\n",
    "n = 50_000\n",
    "samples = powerlaw_rvs_numpy(a, n, rng)\n",
    "\n",
    "x_grid = np.linspace(1e-4, 1 - 1e-4, 600)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=samples,\n",
    "        nbinsx=80,\n",
    "        histnorm=\"probability density\",\n",
    "        name=\"Monte Carlo\",\n",
    "        opacity=0.6,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=x_grid, y=powerlaw_pdf(x_grid, a), mode=\"lines\", name=\"theoretical PDF\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Monte Carlo samples vs theoretical PDF (n={n}, a={a:g})\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"density\",\n",
    "    bargap=0.02,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cbee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empirical CDF vs true CDF\n",
    "\n",
    "a = 2.0\n",
    "n = 30_000\n",
    "samples = powerlaw_rvs_numpy(a, n, rng)\n",
    "\n",
    "xs = np.sort(samples)\n",
    "ys = np.arange(1, n + 1) / n\n",
    "\n",
    "x_grid = np.linspace(0, 1, 400)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=xs, y=ys, mode=\"lines\", name=\"empirical CDF\"))\n",
    "fig.add_trace(go.Scatter(x=x_grid, y=powerlaw_cdf(x_grid, a), mode=\"lines\", name=\"true CDF\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Empirical CDF vs true CDF (n={n}, a={a:g})\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"F(x)\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e14a06c",
   "metadata": {},
   "source": [
    "## 9) SciPy Integration (`scipy.stats.powerlaw`)\n",
    "\n",
    "SciPy provides `scipy.stats.powerlaw`, which implements the same distribution with an additional location-scale transform.\n",
    "\n",
    "- Canonical form: `stats.powerlaw(a)` has support \\([0,1]\\).\n",
    "- Location-scale: `stats.powerlaw(a, loc=ℓ, scale=s)` has support \\([\\ell, \\ell+s]\\).\n",
    "\n",
    "Because `powerlaw(a)` is \\(\\mathrm{Beta}(a,1)\\), you can also verify equivalence via `scipy.stats.beta(a, 1)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300220be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta, powerlaw\n",
    "\n",
    "# Define a SciPy powerlaw distribution\n",
    "\n",
    "a = 2.5\n",
    "rv = powerlaw(a, loc=0.0, scale=1.0)\n",
    "\n",
    "x_grid = np.linspace(1e-4, 1 - 1e-4, 500)\n",
    "\n",
    "# SciPy API\n",
    "pdf_scipy = rv.pdf(x_grid)\n",
    "cdf_scipy = rv.cdf(x_grid)\n",
    "\n",
    "# Compare to our implementations\n",
    "max_pdf_diff = np.max(np.abs(pdf_scipy - powerlaw_pdf(x_grid, a)))\n",
    "max_cdf_diff = np.max(np.abs(cdf_scipy - powerlaw_cdf(x_grid, a)))\n",
    "\n",
    "# Sampling\n",
    "samples_scipy = rv.rvs(size=50_000, random_state=rng)\n",
    "\n",
    "# Fit (MLE). If you know data are on [0,1], fix loc/scale.\n",
    "a_hat_fit, loc_hat, scale_hat = powerlaw.fit(samples_scipy, floc=0.0, fscale=1.0)\n",
    "\n",
    "a_hat_closed = powerlaw_mle_shape(samples_scipy)\n",
    "\n",
    "# Beta equivalence check\n",
    "rv_beta = beta(a, 1.0)\n",
    "max_pdf_diff_beta = np.max(np.abs(rv_beta.pdf(x_grid) - pdf_scipy))\n",
    "\n",
    "(max_pdf_diff, max_cdf_diff, a_hat_fit, a_hat_closed, max_pdf_diff_beta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9055e9",
   "metadata": {},
   "source": [
    "## 10) Statistical Use Cases\n",
    "\n",
    "### 10.1 Hypothesis testing\n",
    "A common simple test is whether data are **uniform** on \\([0,1]\\) (\\(a=1\\)) versus a powerlaw alternative (\\(a\\neq 1\\)).\n",
    "You can use a **likelihood ratio test** (LRT) or a goodness-of-fit test like KS.\n",
    "\n",
    "### 10.2 Bayesian modeling\n",
    "Because the likelihood in \\(a\\) has the form\n",
    "\n",
    "$$L(a) \\propto a^n\\exp\\Big(a \\sum\\log x_i\\Big),$$\n",
    "\n",
    "a **Gamma prior** on \\(a\\) is conjugate.\n",
    "\n",
    "### 10.3 Generative modeling\n",
    "`powerlaw` is a handy one-parameter generator on \\([0,1]\\):\n",
    "- generate “best-of-\\(n\\)” maxima of uniforms (exactly)\n",
    "- generate random weights/thresholds with controllable concentration near 0 or 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532fa0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis test: H0 a=1 (uniform) vs H1 a free (powerlaw)\n",
    "\n",
    "n = 5_000\n",
    "a_true = 0.6\n",
    "x = powerlaw_rvs_numpy(a_true, n, rng)\n",
    "\n",
    "# Null log-likelihood (a=1)\n",
    "ll_null = powerlaw_loglikelihood(x, a=1.0)\n",
    "\n",
    "# MLE under alternative\n",
    "\n",
    "a_hat = powerlaw_mle_shape(x)\n",
    "ll_alt = powerlaw_loglikelihood(x, a=a_hat)\n",
    "\n",
    "lrt = 2.0 * (ll_alt - ll_null)\n",
    "p_value = stats.chi2.sf(lrt, df=1)\n",
    "\n",
    "# KS test against fitted distribution\n",
    "D, p_ks = stats.kstest(x, powerlaw(a_hat).cdf)\n",
    "\n",
    "{\"a_true\": a_true, \"a_hat\": a_hat, \"LRT\": lrt, \"p_value_chi2\": p_value, \"KS_D\": D, \"KS_p\": p_ks}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aaaaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian update for a with a conjugate Gamma prior\n",
    "\n",
    "# Prior: a ~ Gamma(alpha0, rate=beta0)\n",
    "alpha0 = 2.0\n",
    "beta0 = 1.0  # rate\n",
    "\n",
    "n = 2_000\n",
    "a_true = 2.5\n",
    "x = powerlaw_rvs_numpy(a_true, n, rng)\n",
    "\n",
    "S = float(np.sum(np.log(x)))  # negative\n",
    "\n",
    "# Posterior: a | x ~ Gamma(alpha0 + n, rate=beta0 - S)\n",
    "alpha_post = alpha0 + n\n",
    "beta_post = beta0 - S\n",
    "\n",
    "post = stats.gamma(a=alpha_post, scale=1.0 / beta_post)  # SciPy gamma uses scale = 1/rate\n",
    "\n",
    "post_mean = post.mean()\n",
    "ci_95 = post.ppf([0.025, 0.975])\n",
    "\n",
    "# Plot posterior density\n",
    "\n",
    "a_grid = np.linspace(post.ppf(0.001), post.ppf(0.999), 400)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=a_grid, y=post.pdf(a_grid), mode=\"lines\", name=\"posterior\"))\n",
    "fig.add_vline(x=a_true, line_dash=\"dash\", line_color=\"black\", annotation_text=\"true a\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Posterior for a with Gamma prior (conjugate)\",\n",
    "    xaxis_title=\"a\",\n",
    "    yaxis_title=\"density\",\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "{\"a_true\": a_true, \"posterior_mean\": post_mean, \"ci_95\": ci_95}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7721ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative modeling pattern: max of n uniforms equals powerlaw(a=n)\n",
    "\n",
    "n = 5\n",
    "m = 80_000\n",
    "\n",
    "# Max of n uniforms\n",
    "u = rng.random((m, n))\n",
    "max_u = u.max(axis=1)\n",
    "\n",
    "# Equivalent powerlaw with a=n\n",
    "samples_pw = powerlaw_rvs_numpy(a=float(n), size=m, rng=rng)\n",
    "\n",
    "# Compare empirical CDFs\n",
    "xs1 = np.sort(max_u)\n",
    "ys1 = np.arange(1, m + 1) / m\n",
    "\n",
    "xs2 = np.sort(samples_pw)\n",
    "ys2 = np.arange(1, m + 1) / m\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=xs1, y=ys1, mode=\"lines\", name=\"max of n uniforms\"))\n",
    "fig.add_trace(go.Scatter(x=xs2, y=ys2, mode=\"lines\", name=\"powerlaw(a=n)\"))\n",
    "fig.update_layout(\n",
    "    title=f\"Max of n={n} uniforms vs powerlaw(a={n})\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"empirical CDF\",\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Two-sample KS test (should not reject for large m)\n",
    "ks = stats.ks_2samp(max_u, samples_pw)\n",
    "ks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f7775b",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Name confusion**: SciPy’s `powerlaw` is bounded on \\([0,1]\\); heavy-tailed “power-law” behavior is better modeled by distributions like Pareto/Zipf.\n",
    "- **Parameter constraints**: \\(a>0\\), `scale>0`. Invalid values should raise errors.\n",
    "- **Boundary values**: the canonical density is defined on \\((0,1)\\); exact 0 or 1 values make \\(\\log x\\) problematic for likelihood-based methods.\n",
    "  - In practice: clip values (with care) or model measurement noise.\n",
    "- **Divergence at 0 for \\(a<1\\)**: the PDF goes to \\(+\\infty\\) as \\(x\\to 0^+\\). For plots/integration, start at a small \\(\\varepsilon\\) like \\(10^{-6}\\).\n",
    "- **Fitting with free `loc`/`scale`**: if your data are already in \\([0,1]\\), fix `loc=0`, `scale=1` for stable estimation of \\(a\\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dddb746",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `powerlaw(a)` is a **continuous** distribution on \\([0,1]\\) with **CDF** \\(F(x)=x^a\\) and **PDF** \\(f(x)=a x^{a-1}\\).\n",
    "- It is exactly \\(\\mathrm{Beta}(a,1)\\), and for integer \\(a=n\\) it matches the distribution of \\(\\max\\{U_1,\\dots,U_n\\}\\) for uniforms.\n",
    "- Moments are simple: \\(\\mathbb{E}[X]=\\frac{a}{a+1}\\), \\(\\mathrm{Var}(X)=\\frac{a}{(a+1)^2(a+2)}\\), and \\(\\mathbb{E}[X^k]=\\frac{a}{a+k}\\).\n",
    "- Sampling is easy with inverse CDF: \\(X=U^{1/a}\\).\n",
    "- SciPy integration is straightforward with `scipy.stats.powerlaw`, using `loc`/`scale` for interval transforms.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}