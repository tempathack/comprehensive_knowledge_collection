{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec64db0",
   "metadata": {},
   "source": [
    "# Mielke Distribution (`mielke`, Mielke Beta-Kappa / Dagum)\n",
    "\n",
    "The **Mielke Beta-Kappa** distribution (often called the **Dagum distribution**) is a flexible family on **positive real values** with **polynomial (heavy) tails**.\n",
    "\n",
    "It is a good default when:\n",
    "\n",
    "- your data are **strictly positive** (precipitation amounts, income/wealth, claim sizes, waiting times)\n",
    "- you need a model that can be **very right-skewed** with **power-law tails**\n",
    "- you want **simple sampling** (closed-form inverse CDF)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "By the end you should be able to:\n",
    "\n",
    "- write the PDF/CDF/quantile function and interpret the parameters\n",
    "- compute moments (and know when they do *not* exist)\n",
    "- derive expectation/variance and the likelihood\n",
    "- sample from `mielke` using inverse-transform sampling (**NumPy-only**)\n",
    "- fit and use the distribution via `scipy.stats.mielke`\n",
    "\n",
    "## Notation\n",
    "\n",
    "- Shape parameters: $k > 0$, $s > 0$\n",
    "- Random variable: $X \\sim \\mathrm{Mielke}(k, s)$ (standard form)\n",
    "- Standard support: $x > 0$\n",
    "\n",
    "---\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "1. Title & Classification\n",
    "2. Intuition & Motivation\n",
    "3. Formal Definition\n",
    "4. Moments & Properties\n",
    "5. Parameter Interpretation\n",
    "6. Derivations\n",
    "7. Sampling & Simulation\n",
    "8. Visualization\n",
    "9. SciPy Integration\n",
    "10. Statistical Use Cases\n",
    "11. Pitfalls\n",
    "12. Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1234bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.special import gammaln, psi, logsumexp\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"scipy:\", scipy.__version__)\n",
    "print(\"plotly:\", plotly.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80231fd1",
   "metadata": {},
   "source": [
    "## 1) Title & Classification\n",
    "\n",
    "- **Name**: `mielke` (Mielke Beta-Kappa; also known as the **Dagum distribution**)\n",
    "- **Type**: **continuous**\n",
    "- **Standard support**: $x > 0$ (SciPy defines the PDF for $x \\ge 0$; if $k<1$ the density diverges as $x\\to 0^+$)\n",
    "- **Parameter space (standard form)**: $k > 0$, $s > 0$\n",
    "- **Location/scale form (SciPy)**: $X = \\mathrm{loc} + \\mathrm{scale}\\cdot Y$ with $Y \\sim \\mathrm{Mielke}(k, s)$\n",
    "  - Support becomes $x > \\mathrm{loc}$\n",
    "  - $\\mathrm{scale} > 0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519f8ba",
   "metadata": {},
   "source": [
    "## 2) Intuition & Motivation\n",
    "\n",
    "### What it models\n",
    "\n",
    "`mielke` is a **positive**, **right-skewed**, **heavy-tailed** model. It is useful when:\n",
    "\n",
    "- small values occur frequently (controlled by $k$)\n",
    "- rare, extremely large values occur (tail heaviness controlled by $s$)\n",
    "- a lognormal/gamma tail is too light\n",
    "\n",
    "The survival function decays like a power law:\n",
    "\n",
    "$$\n",
    "\\Pr(X > x) = 1 - F(x) \\sim \\frac{k}{s}\\,x^{-s}\\quad \\text{as } x\\to\\infty.\n",
    "$$\n",
    "\n",
    "So $s$ behaves like a **tail index**.\n",
    "\n",
    "### Typical real-world use cases\n",
    "\n",
    "- **Precipitation** / hydrology (Mielke introduced this family for rainfall amounts)\n",
    "- **Income/wealth** modeling (Dagum distribution in economics)\n",
    "- **Insurance claim sizes** and other positive heavy-tailed costs\n",
    "- **Reliability** / lifetime modeling when failures can occur very late\n",
    "\n",
    "### Relations to other distributions\n",
    "\n",
    "- **Burr Type III / Dagum**: `mielke(k, s)` is exactly SciPy’s `burr(c=s, d=k/s)`.\n",
    "- **Log-logistic** (`fisk`): the constraint $k=s$ gives\n",
    "  $$f(x)=\\frac{s\\,x^{s-1}}{(1+x^s)^2},$$\n",
    "  which is the log-logistic (`fisk`) density.\n",
    "- **Beta-prime connection**: if $Y = X^s$, then\n",
    "  $$f_Y(y)=\\frac{k}{s}\\,\\frac{y^{k/s-1}}{(1+y)^{1+k/s}},\\quad y>0,$$\n",
    "  so $Y$ is **Beta-prime** with parameters $(k/s,\\,1)$.\n",
    "- **Beta connection**: if $U = \\frac{X^s}{1+X^s}$, then $U\\in(0,1)$ and\n",
    "  $$U \\sim \\mathrm{Beta}(k/s, 1).$$\n",
    "  This gives an immediate sampler.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0308d90",
   "metadata": {},
   "source": [
    "## 3) Formal Definition\n",
    "\n",
    "### CDF\n",
    "\n",
    "In the standard (unshifted, unit-scale) parameterization, for $x>0$:\n",
    "\n",
    "$$\n",
    "F(x; k, s)\n",
    "= \\frac{x^k}{(1+x^s)^{k/s}}\n",
    "= \\left(\\frac{x^s}{1+x^s}\\right)^{k/s}\n",
    "= \\left(1 + x^{-s}\\right)^{-k/s},\n",
    "\\qquad k>0,\\ s>0.\n",
    "$$\n",
    "\n",
    "### PDF\n",
    "\n",
    "Differentiating the CDF gives the density:\n",
    "\n",
    "$$\n",
    "f(x; k, s)\n",
    "= \\frac{k\\,x^{k-1}}{(1+x^s)^{1+k/s}},\\qquad x>0.\n",
    "$$\n",
    "\n",
    "### Quantile function (inverse CDF)\n",
    "\n",
    "Let $p\\in(0,1)$. Solving $p = (1 + x^{-s})^{-k/s}$ gives:\n",
    "\n",
    "$$\n",
    "Q(p)\n",
    "= \\left(\\frac{p^{s/k}}{1 - p^{s/k}}\\right)^{1/s}.\n",
    "$$\n",
    "\n",
    "### Location/scale\n",
    "\n",
    "SciPy uses the standard location/scale convention:\n",
    "\n",
    "$$\n",
    "X = \\mathrm{loc} + \\mathrm{scale}\\cdot Y,\\qquad Y\\sim\\mathrm{Mielke}(k,s),\\ \\mathrm{scale}>0.\n",
    "$$\n",
    "\n",
    "Then $X$ has support $x>\\mathrm{loc}$ and\n",
    "\n",
    "$$\n",
    "f_X(x)=\\frac{1}{\\mathrm{scale}}\\,f_Y\\!\\left(\\frac{x-\\mathrm{loc}}{\\mathrm{scale}}\\right).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff92ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mielke_logpdf(x, k, s):\n",
    "    '''Log-PDF of the standard Mielke (Beta-Kappa / Dagum) distribution (loc=0, scale=1).'''\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    k = float(k)\n",
    "    s = float(s)\n",
    "\n",
    "    out = np.full_like(x, -np.inf, dtype=float)\n",
    "    if (k <= 0) or (s <= 0):\n",
    "        return out\n",
    "\n",
    "    mask = x > 0\n",
    "    xm = x[mask]\n",
    "    logx = np.log(xm)\n",
    "\n",
    "    # log(1 + x^s) computed stably as log(1 + exp(s log x))\n",
    "    log1p_xs = np.logaddexp(0.0, s * logx)\n",
    "\n",
    "    out[mask] = np.log(k) + (k - 1.0) * logx - (1.0 + k / s) * log1p_xs\n",
    "    return out\n",
    "\n",
    "\n",
    "def mielke_pdf(x, k, s):\n",
    "    return np.exp(mielke_logpdf(x, k, s))\n",
    "\n",
    "\n",
    "def mielke_logcdf(x, k, s):\n",
    "    '''Log-CDF of the standard Mielke distribution.'''\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    k = float(k)\n",
    "    s = float(s)\n",
    "\n",
    "    out = np.full_like(x, -np.inf, dtype=float)\n",
    "    if (k <= 0) or (s <= 0):\n",
    "        return out\n",
    "\n",
    "    mask = x > 0\n",
    "    xm = x[mask]\n",
    "    logx = np.log(xm)\n",
    "\n",
    "    # Use F(x) = (1 + x^{-s})^{-k/s} to avoid cancellation when x is large.\n",
    "    log1p_xnegs = np.logaddexp(0.0, -s * logx)  # log(1 + x^{-s})\n",
    "    out[mask] = -(k / s) * log1p_xnegs\n",
    "    return out\n",
    "\n",
    "\n",
    "def mielke_cdf(x, k, s):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    out = np.zeros_like(x, dtype=float)\n",
    "    mask = x > 0\n",
    "    out[mask] = np.exp(mielke_logcdf(x[mask], k, s))\n",
    "    return out\n",
    "\n",
    "\n",
    "def mielke_ppf(p, k, s):\n",
    "    '''Quantile function Q(p) for p in [0,1].'''\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    k = float(k)\n",
    "    s = float(s)\n",
    "\n",
    "    x = np.full_like(p, np.nan, dtype=float)\n",
    "    if (k <= 0) or (s <= 0):\n",
    "        return x\n",
    "\n",
    "    x[p == 0] = 0.0\n",
    "    x[p == 1] = np.inf\n",
    "\n",
    "    mask = (p > 0) & (p < 1)\n",
    "    # Let a = (s/k) log p, so q = p^{s/k} = exp(a) in (0,1).\n",
    "    a = (s / k) * np.log(p[mask])\n",
    "\n",
    "    # q/(1-q) = exp(a) / (1-exp(a)) = exp(a) / (-expm1(a)) (stable when a≈0).\n",
    "    log_ratio = a - np.log(-np.expm1(a))\n",
    "    x[mask] = np.exp(log_ratio / s)\n",
    "    return x\n",
    "\n",
    "\n",
    "def mielke_rvs_numpy(k, s, size, rng=None):\n",
    "    '''NumPy-only sampler via inverse-transform sampling.'''\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    u = rng.random(size)\n",
    "    return mielke_ppf(u, k, s)\n",
    "\n",
    "\n",
    "def mielke_raw_moment(n, k, s):\n",
    "    '''Raw moment E[X^n] for -k < n < s; returns +inf when the moment diverges.'''\n",
    "    k = float(k)\n",
    "    s = float(s)\n",
    "    n = float(n)\n",
    "\n",
    "    if (k <= 0) or (s <= 0):\n",
    "        return np.nan\n",
    "\n",
    "    # Integrability:\n",
    "    # - near 0: f(x) ~ k x^{k-1} so E[X^n] finite iff n > -k\n",
    "    # - in the tail: f(x) ~ k x^{-s-1} so E[X^n] finite iff n < s\n",
    "    if not (-k < n < s):\n",
    "        return np.inf\n",
    "\n",
    "    return np.exp(gammaln((k + n) / s) + gammaln(1.0 - n / s) - gammaln(k / s))\n",
    "\n",
    "\n",
    "def mielke_entropy(k, s):\n",
    "    '''Differential entropy of the standard Mielke distribution.'''\n",
    "    k = float(k)\n",
    "    s = float(s)\n",
    "    if (k <= 0) or (s <= 0):\n",
    "        return np.nan\n",
    "\n",
    "    D = psi(1.0 + k / s) - psi(1.0)\n",
    "    return -np.log(k) + (k - 1.0) / k + (1.0 + 1.0 / s) * D\n",
    "\n",
    "\n",
    "def mielke_summary_stats(k, s):\n",
    "    '''Mean/variance/skewness/excess kurtosis (when finite), else nan/inf.'''\n",
    "    k = float(k)\n",
    "    s = float(s)\n",
    "\n",
    "    mean = mielke_raw_moment(1.0, k, s) if s > 1 else np.inf\n",
    "    if s <= 2:\n",
    "        return mean, np.inf, np.nan, np.nan\n",
    "\n",
    "    m2 = mielke_raw_moment(2.0, k, s)\n",
    "    var = m2 - mean**2\n",
    "\n",
    "    skew = np.nan\n",
    "    exkurt = np.nan\n",
    "\n",
    "    if s > 3:\n",
    "        m3 = mielke_raw_moment(3.0, k, s)\n",
    "        mu3 = m3 - 3.0 * m2 * mean + 2.0 * mean**3\n",
    "        skew = mu3 / (var ** 1.5)\n",
    "\n",
    "    if s > 4:\n",
    "        m3 = mielke_raw_moment(3.0, k, s)  # defined since s>4\n",
    "        m4 = mielke_raw_moment(4.0, k, s)\n",
    "        mu4 = m4 - 4.0 * m3 * mean + 6.0 * m2 * mean**2 - 3.0 * mean**4\n",
    "        exkurt = mu4 / (var**2) - 3.0\n",
    "\n",
    "    return mean, var, skew, exkurt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce1852d",
   "metadata": {},
   "source": [
    "## 4) Moments & Properties\n",
    "\n",
    "### Existence of moments (key takeaway)\n",
    "\n",
    "The right tail is polynomial:\n",
    "\n",
    "$$\n",
    "\\Pr(X > x) \\sim \\frac{k}{s}\\,x^{-s}.\n",
    "$$\n",
    "\n",
    "So **positive moments** satisfy:\n",
    "\n",
    "- $\\mathbb{E}[X^n] < \\infty$ **iff** $n < s$.\n",
    "\n",
    "Near 0, $f(x)\\approx k x^{k-1}$, so **negative moments** exist iff $n > -k$.\n",
    "\n",
    "Overall:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^n] < \\infty\\quad \\Longleftrightarrow\\quad -k < n < s.\n",
    "$$\n",
    "\n",
    "### Raw moments\n",
    "\n",
    "For $-k < n < s$:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^n]\n",
    "= \\frac{\\Gamma\\left(\\tfrac{k+n}{s}\\right)\\,\\Gamma\\left(1-\\tfrac{n}{s}\\right)}{\\Gamma\\left(\\tfrac{k}{s}\\right)}.\n",
    "$$\n",
    "\n",
    "### Mean and variance\n",
    "\n",
    "- Mean (exists for $s>1$):\n",
    "  $$\\mathbb{E}[X] = \\frac{\\Gamma\\left(\\tfrac{k+1}{s}\\right)\\,\\Gamma\\left(1-\\tfrac{1}{s}\\right)}{\\Gamma\\left(\\tfrac{k}{s}\\right)}$$\n",
    "- Second moment exists for $s>2$:\n",
    "  $$\\mathbb{E}[X^2] = \\frac{\\Gamma\\left(\\tfrac{k+2}{s}\\right)\\,\\Gamma\\left(1-\\tfrac{2}{s}\\right)}{\\Gamma\\left(\\tfrac{k}{s}\\right)}$$\n",
    "- Variance (exists for $s>2$):\n",
    "  $$\\mathrm{Var}(X)=\\mathbb{E}[X^2] - \\mathbb{E}[X]^2$$\n",
    "\n",
    "### Skewness and kurtosis\n",
    "\n",
    "- Skewness exists for $s>3$\n",
    "- Excess kurtosis exists for $s>4$\n",
    "\n",
    "You can compute them from raw moments $m_n = \\mathbb{E}[X^n]$ via standard formulas.\n",
    "\n",
    "### MGF / characteristic function\n",
    "\n",
    "- The MGF $M(t)=\\mathbb{E}[e^{tX}]$ **diverges for any $t>0$** because the tail is polynomial.\n",
    "- The characteristic function $\\varphi(t)=\\mathbb{E}[e^{itX}]$ exists for all real $t$, but does not simplify to elementary functions in general.\n",
    "\n",
    "### Entropy\n",
    "\n",
    "The differential entropy has a closed form in terms of the digamma function $\\psi$:\n",
    "\n",
    "$$\n",
    "H(X)\n",
    "= -\\log k + \\frac{k-1}{k} + \\left(1+\\frac{1}{s}\\right)\\bigl(\\psi(1+k/s) - \\psi(1)\\bigr).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97ed052",
   "metadata": {},
   "outputs": [],
   "source": [
    "k0, s0 = 2.5, 1.7\n",
    "x_test = np.array([0.2, 0.5, 1.0, 2.0, 5.0])\n",
    "\n",
    "pdf_np = mielke_pdf(x_test, k0, s0)\n",
    "pdf_sp = stats.mielke.pdf(x_test, k0, s0)\n",
    "print(\"max |pdf_numpy - pdf_scipy|:\", np.max(np.abs(pdf_np - pdf_sp)))\n",
    "\n",
    "# Relationship to Burr III / Dagum in SciPy: burr(c=s, d=k/s)\n",
    "pdf_burr = stats.burr.pdf(x_test, s0, k0 / s0)\n",
    "print(\"max |mielke - burr(c=s, d=k/s)|:\", np.max(np.abs(pdf_sp - pdf_burr)))\n",
    "\n",
    "mean, var, skew, exkurt = mielke_summary_stats(k0, s0)\n",
    "mean_sp, var_sp, skew_sp, exkurt_sp = stats.mielke.stats(k0, s0, moments=\"mvsk\")\n",
    "print(\"mean:\", mean, \"(scipy:\", float(mean_sp), \")\")\n",
    "print(\"var:\", var, \"(scipy:\", float(var_sp), \")\")\n",
    "print(\"skew:\", skew, \"(scipy:\", float(skew_sp), \")\")\n",
    "print(\"excess kurtosis:\", exkurt, \"(scipy:\", float(exkurt_sp), \")\")\n",
    "\n",
    "h = mielke_entropy(k0, s0)\n",
    "print(\"entropy:\", h, \"(scipy:\", float(stats.mielke.entropy(k0, s0)), \")\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd85f58",
   "metadata": {},
   "source": [
    "## 5) Parameter Interpretation\n",
    "\n",
    "The parameters $k$ and $s$ both affect shape, but in different ways.\n",
    "\n",
    "### $s$ (tail index)\n",
    "\n",
    "From the PDF, as $x\\to\\infty$:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{k x^{k-1}}{(1+x^s)^{1+k/s}} \\sim k\\,x^{-s-1}.\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "- larger $s$ means a **lighter right tail**\n",
    "- the $n$-th moment exists iff $n < s$ (mean requires $s>1$, variance requires $s>2$)\n",
    "\n",
    "### $k$ (behavior near 0)\n",
    "\n",
    "As $x\\to 0^+$, $(1+x^s)^{-(1+k/s)}\\to 1$, so\n",
    "\n",
    "$$\n",
    "f(x) \\sim k\\,x^{k-1}.\n",
    "$$\n",
    "\n",
    "- If $k<1$, the density **diverges** at 0.\n",
    "- If $k=1$, the density is **finite and nonzero** at 0.\n",
    "- If $k>1$, the density goes to **0** at 0.\n",
    "\n",
    "A convenient derived quantity is $k/s$ (it appears in the CDF and quantiles). For example,\n",
    "\n",
    "$$\n",
    "\\mathrm{median}(X) = Q(0.5) = \\left(\\frac{0.5^{s/k}}{1-0.5^{s/k}}\\right)^{1/s}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597f11e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.logspace(-3, 3, 900)\n",
    "\n",
    "# Effect of changing k (near-zero behavior)\n",
    "s_fixed = 2.5\n",
    "k_list = [0.5, 1.0, 3.0]\n",
    "\n",
    "fig_pdf_k = go.Figure()\n",
    "for k in k_list:\n",
    "    y = np.maximum(mielke_pdf(x, k, s_fixed), 1e-300)\n",
    "    fig_pdf_k.add_trace(go.Scatter(x=x, y=y, mode=\"lines\", name=f\"k={k}, s={s_fixed}\"))\n",
    "\n",
    "fig_pdf_k.update_layout(title=\"PDF shape when varying k (s fixed)\")\n",
    "fig_pdf_k.update_xaxes(type=\"log\", title=\"x\")\n",
    "fig_pdf_k.update_yaxes(type=\"log\", title=\"pdf(x)\")\n",
    "fig_pdf_k.show()\n",
    "\n",
    "# Effect of changing s (tail heaviness)\n",
    "k_fixed = 2.5\n",
    "s_list = [0.9, 2.0, 5.0]\n",
    "\n",
    "fig_pdf_s = go.Figure()\n",
    "for s in s_list:\n",
    "    y = np.maximum(mielke_pdf(x, k_fixed, s), 1e-300)\n",
    "    fig_pdf_s.add_trace(go.Scatter(x=x, y=y, mode=\"lines\", name=f\"k={k_fixed}, s={s}\"))\n",
    "\n",
    "fig_pdf_s.update_layout(title=\"PDF shape when varying s (k fixed)\")\n",
    "fig_pdf_s.update_xaxes(type=\"log\", title=\"x\")\n",
    "fig_pdf_s.update_yaxes(type=\"log\", title=\"pdf(x)\")\n",
    "fig_pdf_s.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29ab2de",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### Expectation (raw moments)\n",
    "\n",
    "Start from the raw moment definition (standard form):\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^n] = \\int_0^\\infty x^n\\,f(x; k,s)\\,dx\n",
    "= \\int_0^\\infty x^n\\,\\frac{k x^{k-1}}{(1+x^s)^{1+k/s}}\\,dx.\n",
    "$$\n",
    "\n",
    "Combine powers and substitute $y=x^s$:\n",
    "\n",
    "- $x=y^{1/s}$\n",
    "- $dx = \\frac{1}{s}y^{1/s-1}\\,dy$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^n]\n",
    "= \\frac{k}{s}\\int_0^\\infty \\frac{y^{(k+n)/s - 1}}{(1+y)^{1+k/s}}\\,dy.\n",
    "$$\n",
    "\n",
    "Recognize the Beta-function identity\n",
    "\n",
    "$$\n",
    "\\int_0^\\infty \\frac{y^{a-1}}{(1+y)^{a+b}}\\,dy = B(a,b)=\\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)},\\qquad a,b>0.\n",
    "$$\n",
    "\n",
    "Here $a=(k+n)/s$ and $b=1-n/s$. This requires $a>0$ (i.e. $n>-k$) and $b>0$ (i.e. $n<s$). Plugging in and using $\\Gamma(1+k/s)=(k/s)\\Gamma(k/s)$ yields:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^n]\n",
    "= \\frac{\\Gamma\\left(\\tfrac{k+n}{s}\\right)\\Gamma\\left(1-\\tfrac{n}{s}\\right)}{\\Gamma\\left(\\tfrac{k}{s}\\right)}.\n",
    "$$\n",
    "\n",
    "### Variance\n",
    "\n",
    "When $s>2$:\n",
    "\n",
    "$$\n",
    "\\mathrm{Var}(X)=\\mathbb{E}[X^2]-\\mathbb{E}[X]^2,\n",
    "$$\n",
    "\n",
    "where $\\mathbb{E}[X]$ and $\\mathbb{E}[X^2]$ use the raw-moment formula above.\n",
    "\n",
    "### Likelihood\n",
    "\n",
    "Given i.i.d. data $x_1,\\dots,x_n$ with $x_i>0$, the log-likelihood (standard form) is:\n",
    "\n",
    "$$\n",
    "\\ell(k,s) = \\sum_{i=1}^n \\log f(x_i; k,s)\n",
    "= n\\log k + (k-1)\\sum_{i=1}^n \\log x_i - \\left(1+\\frac{k}{s}\\right)\\sum_{i=1}^n \\log(1+x_i^s).\n",
    "$$\n",
    "\n",
    "There is no closed-form MLE; in practice you maximize $\\ell(k,s)$ numerically (SciPy’s `fit` does this for you).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf71d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mielke_loglik(k, s, x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if (k <= 0) or (s <= 0) or np.any(x <= 0):\n",
    "        return -np.inf\n",
    "    return float(np.sum(mielke_logpdf(x, k, s)))\n",
    "\n",
    "\n",
    "# quick sanity check: log-likelihood is higher near the true parameters (on average)\n",
    "k_true, s_true = 2.5, 3.0\n",
    "x_data = mielke_rvs_numpy(k_true, s_true, size=2500, rng=rng)\n",
    "\n",
    "for (k_try, s_try) in [(1.8, 3.0), (2.5, 3.0), (3.2, 3.0), (2.5, 2.0), (2.5, 4.0)]:\n",
    "    print((k_try, s_try), mielke_loglik(k_try, s_try, x_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523cef7a",
   "metadata": {},
   "source": [
    "## 7) Sampling & Simulation (NumPy-only)\n",
    "\n",
    "Because the CDF is available in closed form, sampling is straightforward via **inverse-transform sampling**.\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "1. Draw $U\\sim\\mathrm{Uniform}(0,1)$.\n",
    "2. Return $X = Q(U)$ where\n",
    "   $$\n",
    "   Q(p) = \\left(\\frac{p^{s/k}}{1 - p^{s/k}}\\right)^{1/s}.\n",
    "   $$\n",
    "\n",
    "Equivalently (via the Beta connection):\n",
    "\n",
    "- draw $V = U^{s/k}$ so that $V\\sim\\mathrm{Beta}(k/s,1)$\n",
    "- set $X = \\left(\\frac{V}{1-V}\\right)^{1/s}$.\n",
    "\n",
    "The implementation above (`mielke_rvs_numpy`) uses the quantile function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ed7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_samp, s_samp = 2.5, 3.0\n",
    "samples = mielke_rvs_numpy(k_samp, s_samp, size=50_000, rng=rng)\n",
    "\n",
    "qs = np.array([0.1, 0.5, 0.9, 0.99])\n",
    "q_emp = np.quantile(samples, qs)\n",
    "q_theory = mielke_ppf(qs, k_samp, s_samp)\n",
    "\n",
    "print(\"Quantiles p:\", qs)\n",
    "print(\"Empirical:\", q_emp)\n",
    "print(\"Theory:\", q_theory)\n",
    "\n",
    "print(\"\\nSample mean/var (finite here since s=3>2):\")\n",
    "mean_theory = mielke_raw_moment(1, k_samp, s_samp)\n",
    "var_theory = mielke_raw_moment(2, k_samp, s_samp) - mean_theory**2\n",
    "print(\"mean:\", samples.mean(), \"(theory:\", mean_theory, \")\")\n",
    "print(\"var:\", samples.var(), \"(theory:\", var_theory, \")\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6beca90",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We’ll visualize:\n",
    "\n",
    "- the theoretical **PDF** and **CDF**\n",
    "- **Monte Carlo** samples (histogram + PDF overlay)\n",
    "- empirical CDF vs theoretical CDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb84659",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vis, s_vis = 2.5, 3.0\n",
    "x_grid = np.logspace(-3, 3, 900)\n",
    "\n",
    "# PDF\n",
    "fig_pdf = go.Figure()\n",
    "fig_pdf.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_grid,\n",
    "        y=np.maximum(mielke_pdf(x_grid, k_vis, s_vis), 1e-300),\n",
    "        mode=\"lines\",\n",
    "        name=\"pdf\",\n",
    "    )\n",
    ")\n",
    "fig_pdf.update_layout(title=f\"Mielke PDF (k={k_vis}, s={s_vis})\")\n",
    "fig_pdf.update_xaxes(type=\"log\", title=\"x\")\n",
    "fig_pdf.update_yaxes(type=\"log\", title=\"pdf(x)\")\n",
    "fig_pdf.show()\n",
    "\n",
    "# CDF\n",
    "fig_cdf = go.Figure()\n",
    "fig_cdf.add_trace(go.Scatter(x=x_grid, y=mielke_cdf(x_grid, k_vis, s_vis), mode=\"lines\", name=\"cdf\"))\n",
    "fig_cdf.update_layout(title=f\"Mielke CDF (k={k_vis}, s={s_vis})\")\n",
    "fig_cdf.update_xaxes(type=\"log\", title=\"x\")\n",
    "fig_cdf.update_yaxes(title=\"cdf(x)\")\n",
    "fig_cdf.show()\n",
    "\n",
    "# Monte Carlo samples: histogram + PDF overlay\n",
    "samples_vis = mielke_rvs_numpy(k_vis, s_vis, size=30_000, rng=rng)\n",
    "fig_hist = px.histogram(\n",
    "    samples_vis,\n",
    "    nbins=80,\n",
    "    histnorm=\"probability density\",\n",
    "    log_x=True,\n",
    "    opacity=0.55,\n",
    "    title=f\"Monte Carlo histogram vs PDF (k={k_vis}, s={s_vis})\",\n",
    ")\n",
    "fig_hist.add_trace(go.Scatter(x=x_grid, y=mielke_pdf(x_grid, k_vis, s_vis), mode=\"lines\", name=\"pdf\"))\n",
    "fig_hist.update_xaxes(title=\"x\")\n",
    "fig_hist.update_yaxes(title=\"density\")\n",
    "fig_hist.show()\n",
    "\n",
    "# Empirical CDF vs theoretical CDF\n",
    "x_sorted = np.sort(samples_vis)\n",
    "ecdf = np.arange(1, len(x_sorted) + 1) / len(x_sorted)\n",
    "\n",
    "fig_ecdf = go.Figure()\n",
    "fig_ecdf.add_trace(go.Scatter(x=x_sorted, y=ecdf, mode=\"lines\", name=\"empirical CDF\"))\n",
    "fig_ecdf.add_trace(go.Scatter(x=x_grid, y=mielke_cdf(x_grid, k_vis, s_vis), mode=\"lines\", name=\"theoretical CDF\"))\n",
    "fig_ecdf.update_layout(title=\"Empirical vs theoretical CDF\")\n",
    "fig_ecdf.update_xaxes(type=\"log\", title=\"x\")\n",
    "fig_ecdf.update_yaxes(title=\"CDF\")\n",
    "fig_ecdf.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be010388",
   "metadata": {},
   "source": [
    "## 9) SciPy Integration (`scipy.stats.mielke`)\n",
    "\n",
    "SciPy provides a full implementation:\n",
    "\n",
    "- `stats.mielke.pdf`, `logpdf`\n",
    "- `stats.mielke.cdf`, `ppf`\n",
    "- `stats.mielke.rvs`\n",
    "- `stats.mielke.fit` (MLE)\n",
    "\n",
    "Remember the Burr relation:\n",
    "\n",
    "- `stats.mielke(k, s)` is equivalent to `stats.burr(c=s, d=k/s)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a4e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_true, s_true = 2.5, 3.0\n",
    "\n",
    "dist = stats.mielke(k_true, s_true)  # loc=0, scale=1 by default\n",
    "x_eval = np.array([0.5, 1.0, 2.0, 5.0])\n",
    "print(\"pdf:\", dist.pdf(x_eval))\n",
    "print(\"cdf:\", dist.cdf(x_eval))\n",
    "\n",
    "# rvs\n",
    "data = dist.rvs(size=3000, random_state=rng)\n",
    "print(\"sample min/max:\", data.min(), data.max())\n",
    "\n",
    "# fit (fix loc=0, scale=1 to estimate only k and s)\n",
    "k_hat, s_hat, loc_hat, scale_hat = stats.mielke.fit(data, floc=0, fscale=1)\n",
    "print(\"\\nTrue (k,s):\", (k_true, s_true))\n",
    "print(\"Fit  (k,s):\", (k_hat, s_hat))\n",
    "print(\"Returned loc/scale:\", (loc_hat, scale_hat))\n",
    "\n",
    "# Compare NumPy vs SciPy implementations numerically\n",
    "x_dense = np.logspace(-3, 3, 1000)\n",
    "max_pdf_diff = np.max(np.abs(mielke_pdf(x_dense, k_true, s_true) - dist.pdf(x_dense)))\n",
    "max_cdf_diff = np.max(np.abs(mielke_cdf(x_dense, k_true, s_true) - dist.cdf(x_dense)))\n",
    "print(\"\\nmax |pdf_numpy - pdf_scipy|:\", max_pdf_diff)\n",
    "print(\"max |cdf_numpy - cdf_scipy|:\", max_cdf_diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a51f94",
   "metadata": {},
   "source": [
    "## 10) Statistical Use Cases\n",
    "\n",
    "### Hypothesis testing\n",
    "\n",
    "- **Nested model test**: the case $k=s$ is the log-logistic distribution (`fisk`). You can test\n",
    "  $$H_0: k=s\\ \\text{(log-logistic)}\\quad\\text{vs}\\quad H_1: (k,s)\\ \\text{free}$$\n",
    "  using a likelihood-ratio test (LRT).\n",
    "- **Goodness-of-fit**: QQ-plots or distribution tests (KS/AD) can be used as diagnostics. Be careful: classical p-values assume parameters are known, while in practice they’re often estimated.\n",
    "\n",
    "### Bayesian modeling\n",
    "\n",
    "For positive heavy-tailed data, you can use `mielke` as a likelihood and place priors on $(k,s)$ (e.g. log-normal or log-uniform). There is no conjugate prior, but posterior inference is straightforward with MCMC or a simple grid approximation in low dimensions.\n",
    "\n",
    "### Generative modeling\n",
    "\n",
    "- Useful as a **base distribution** for positive heavy-tailed generative models.\n",
    "- Can be used in **mixtures** to model multimodal positive data.\n",
    "- The **Beta/Beta-prime transformations** make it convenient inside larger hierarchical models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1953c8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood-ratio test example: H0 is log-logistic (fisk), H1 is mielke\n",
    "\n",
    "c0 = 2.5\n",
    "x = stats.fisk.rvs(c0, size=1500, random_state=rng)\n",
    "\n",
    "# Fit under H1 (free k,s) and H0 (fisk shape c). Fix loc=0, scale=1 for simplicity.\n",
    "k_hat1, s_hat1, _, _ = stats.mielke.fit(x, floc=0, fscale=1)\n",
    "c_hat0, _, _ = stats.fisk.fit(x, floc=0, fscale=1)\n",
    "\n",
    "ll1 = np.sum(stats.mielke.logpdf(x, k_hat1, s_hat1))\n",
    "ll0 = np.sum(stats.fisk.logpdf(x, c_hat0))\n",
    "\n",
    "lrt_stat = 2 * (ll1 - ll0)\n",
    "p_value = stats.chi2.sf(lrt_stat, df=1)\n",
    "\n",
    "print(\"True H0 (fisk c):\", c0)\n",
    "print(\"Fit H1 (k,s):\", (k_hat1, s_hat1))\n",
    "print(\"Fit H0 (fisk c):\", c_hat0)\n",
    "print(\"LRT stat:\", float(lrt_stat))\n",
    "print(\"Approx p-value (chi^2_1):\", float(p_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e07f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Bayesian grid posterior over (k,s) with a log-uniform prior p(k,s) ∝ 1/(k s)\n",
    "# This is an approximation for intuition (not a replacement for MCMC for serious work).\n",
    "\n",
    "k_true, s_true = 2.5, 3.0\n",
    "data = stats.mielke.rvs(k_true, s_true, size=400, random_state=rng)\n",
    "logx = np.log(data)\n",
    "sum_logx = logx.sum()\n",
    "n = data.size\n",
    "\n",
    "k_grid = np.linspace(0.4, 6.0, 90)\n",
    "s_grid = np.linspace(1.1, 6.0, 90)  # avoid extremely heavy tails for this demo\n",
    "\n",
    "log_post = np.empty((k_grid.size, s_grid.size), dtype=float)\n",
    "\n",
    "for j, s in enumerate(s_grid):\n",
    "    # sum_i log(1 + x_i^s) computed stably\n",
    "    s_term = np.logaddexp(0.0, s * logx).sum()\n",
    "\n",
    "    # vectorized log-likelihood over k_grid\n",
    "    loglike = n * np.log(k_grid) + (k_grid - 1.0) * sum_logx - (1.0 + k_grid / s) * s_term\n",
    "\n",
    "    # log-uniform prior over the grid bounds\n",
    "    logprior = -np.log(k_grid) - np.log(s)\n",
    "    log_post[:, j] = loglike + logprior\n",
    "\n",
    "# Normalize on the discrete grid (treating cells as equal-area for visualization)\n",
    "log_post -= logsumexp(log_post)\n",
    "post = np.exp(log_post)\n",
    "\n",
    "i_map, j_map = np.unravel_index(np.argmax(post), post.shape)\n",
    "print(\"True (k,s):\", (k_true, s_true))\n",
    "print(\"MAP  (k,s):\", (float(k_grid[i_map]), float(s_grid[j_map])))\n",
    "\n",
    "fig_post = go.Figure(\n",
    "    data=go.Contour(\n",
    "        x=s_grid,\n",
    "        y=k_grid,\n",
    "        z=post,\n",
    "        contours_coloring=\"heatmap\",\n",
    "        colorbar_title=\"posterior\",\n",
    "    )\n",
    ")\n",
    "fig_post.update_layout(title=\"Grid posterior p(k,s | data) with log-uniform prior\")\n",
    "fig_post.update_xaxes(title=\"s\")\n",
    "fig_post.update_yaxes(title=\"k\")\n",
    "fig_post.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ce9ca",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Invalid parameters**: require $k>0$ and $s>0$ (and for SciPy location/scale, `scale>0`).\n",
    "- **Moment non-existence**: mean requires $s>1$, variance requires $s>2$, etc. If $s\\le 1$, sample means are unstable and can be misleading.\n",
    "- **Near-zero behavior**: if $k<1$, the density diverges at 0; this is not a bug.\n",
    "- **Numerical issues**: direct computation of $x^s$ can overflow for large $x$ and large $s$. Prefer log-space identities like `log(1+x^s)=logaddexp(0, s log x)`.\n",
    "- **Fitting can be delicate**: heavy tails can produce extreme outliers; MLE may be sensitive to initialization and may have strong parameter correlation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37653eb3",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `mielke` is a **continuous** distribution on $x>0$ with **power-law tails**.\n",
    "- PDF: $f(x)=\\dfrac{k x^{k-1}}{(1+x^s)^{1+k/s}}$; CDF: $F(x)=(1+x^{-s})^{-k/s}$.\n",
    "- Tail index is $s$: positive moments exist iff $n<s$.\n",
    "- Closed-form raw moments and entropy are available via Gamma/digamma functions.\n",
    "- Sampling is easy via the closed-form quantile function (inverse CDF).\n",
    "- In SciPy: `scipy.stats.mielke` (equivalently `scipy.stats.burr(c=s, d=k/s)`).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}