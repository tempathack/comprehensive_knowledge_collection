{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de895bb",
   "metadata": {},
   "source": [
    "# Fisk distribution (`fisk`) — the log-logistic workhorse\n",
    "\n",
    "The **Fisk** distribution (SciPy: `scipy.stats.fisk`) is widely known in applied statistics as the **log-logistic** distribution.\n",
    "It is a **continuous** distribution on the positive real line with **Pareto-like tails**.\n",
    "\n",
    "A key representation makes much of its behavior intuitive:\n",
    "\n",
    "If \\(X \\sim \\mathrm{Fisk}(c, \\text{scale}=s)\\) with `loc=0`, then\n",
    "\n",
    "\\[\n",
    "\\log X \\sim \\mathrm{Logistic}(\\mu=\\log s,\\; \\sigma = 1/c).\n",
    "\\]\n",
    "\n",
    "So you can think of Fisk as “a **logistic distribution on the log-scale**”.\n",
    "\n",
    "## What you’ll learn\n",
    "- how to write the PDF/CDF/quantile function (and how SciPy parameterizes them)\n",
    "- which moments exist (and why many do not)\n",
    "- how to sample with **NumPy only** via inverse-CDF / logistic tricks\n",
    "- how to fit and validate the model with `scipy.stats.fisk`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd58e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import scipy\n",
    "from scipy import optimize, stats\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "# CKC convention for Plotly notebooks\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "rng = np.random.default_rng(7)\n",
    "\n",
    "print(\"Python\", platform.python_version())\n",
    "print(\"NumPy\", np.__version__)\n",
    "print(\"SciPy\", scipy.__version__)\n",
    "\n",
    "# Example parameters used throughout\n",
    "c0 = 5.0\n",
    "scale0 = 2.0\n",
    "loc0 = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da83771",
   "metadata": {},
   "source": [
    "## 1) Title & Classification\n",
    "\n",
    "- **Name**: `fisk` (Fisk / log-logistic distribution; SciPy: `scipy.stats.fisk`)\n",
    "- **Type**: **Continuous**\n",
    "- **Support (standard)**: \\(x \\in (0, \\infty)\\)\n",
    "- **Parameter space (standard)**: shape \\(c>0\\), scale \\(s>0\\)\n",
    "- **SciPy location/scale**: `loc \\in \\mathbb{R}`, `scale > 0` with\n",
    "  \\[\n",
    "  X = \\mathrm{loc} + \\mathrm{scale}\\,Z,\\quad Z \\sim \\mathrm{Fisk}(c, 1).\n",
    "  \\]\n",
    "\n",
    "We write (2-parameter form):\n",
    "\n",
    "\\[\n",
    "X \\sim \\mathrm{Fisk}(c, s).\n",
    "\\]\n",
    "\n",
    "The **standard** form is \\(\\mathrm{Fisk}(c,1)\\), i.e. `stats.fisk(c, loc=0, scale=1)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1728fc2",
   "metadata": {},
   "source": [
    "## 2) Intuition & Motivation\n",
    "\n",
    "### 2.1 What it models\n",
    "The Fisk/log-logistic distribution models **strictly positive** quantities where:\n",
    "\n",
    "- values can vary over **orders of magnitude**, and\n",
    "- the right tail is **heavy** (polynomial decay), and\n",
    "- on the **log-scale**, the distribution looks approximately **logistic**.\n",
    "\n",
    "A nice way to see the logistic link is to rewrite the CDF in terms of \\(y = \\log x\\) (with `loc=0`):\n",
    "\n",
    "\\[\n",
    "F(x) = \\frac{1}{1 + (s/x)^c} = \\sigma\\bigl(c(\\log x - \\log s)\\bigr),\n",
    "\\qquad \\sigma(t) = \\frac{1}{1+e^{-t}}.\n",
    "\\]\n",
    "\n",
    "So the “transition” happens around \\(x \\approx s\\) (because \\(\\log x - \\log s \\approx 0\\)).\n",
    "\n",
    "### 2.2 Typical real-world use cases\n",
    "- **Survival analysis / reliability**: time-to-event with a hazard that can rise and fall.\n",
    "- **Economics**: income/wealth-like quantities with heavy tails.\n",
    "- **Hydrology / environmental extremes**: positive heavy-tailed magnitudes.\n",
    "- **Generative modeling**: as a simple positive heavy-tailed component.\n",
    "\n",
    "### 2.3 Relations to other distributions\n",
    "- **Log-logistic**: Fisk is the log-logistic distribution.\n",
    "- **Logistic on the log-scale**: \\(\\log X\\) is logistic.\n",
    "- **Burr Type XII**: Fisk is a special case of Burr XII (shape parameter \\(k=1\\)).\n",
    "- **Pareto-like tails**: \\(\\mathbb{P}(X>x) \\sim (s/x)^c\\) for large \\(x\\), so \\(c\\) behaves like a tail index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395f481a",
   "metadata": {},
   "source": [
    "## 3) Formal Definition\n",
    "\n",
    "We use the common 2-parameter form with **shape** \\(c>0\\) and **scale** \\(s>0\\).\n",
    "\n",
    "### 3.1 PDF\n",
    "For \\(x>0\\):\n",
    "\n",
    "\\[\n",
    " f(x\\mid c,s) = \\frac{c}{s}\\,\\frac{(x/s)^{c-1}}{\\bigl(1 + (x/s)^c\\bigr)^2}.\n",
    "\\]\n",
    "\n",
    "### 3.2 CDF\n",
    "For \\(x>0\\):\n",
    "\n",
    "\\[\n",
    "F(x\\mid c,s) = \\frac{1}{1 + (s/x)^c}\n",
    "= \\frac{(x/s)^c}{1 + (x/s)^c}\n",
    "= \\sigma\\bigl(c(\\log x - \\log s)\\bigr).\n",
    "\\]\n",
    "\n",
    "The survival function is\n",
    "\n",
    "\\[\n",
    "\\bar F(x) = 1 - F(x) = \\frac{1}{1 + (x/s)^c}.\n",
    "\\]\n",
    "\n",
    "### 3.3 Quantile function (inverse CDF)\n",
    "For \\(u\\in(0,1)\\):\n",
    "\n",
    "\\[\n",
    "Q(u) = F^{-1}(u) = s\\left(\\frac{u}{1-u}\\right)^{1/c}.\n",
    "\\]\n",
    "\n",
    "### 3.4 SciPy parameterization\n",
    "SciPy uses:\n",
    "\n",
    "```python\n",
    "stats.fisk(c, loc=0, scale=1)\n",
    "```\n",
    "\n",
    "with \\(z = (x-\\mathrm{loc})/\\mathrm{scale}\\) and support \\(z>0\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5763168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _log1pexp(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Stable log(1+exp(a)) for real a (NumPy-only).\"\"\"\n",
    "\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    out = np.empty_like(a, dtype=float)\n",
    "\n",
    "    pos = a > 0\n",
    "    out[pos] = a[pos] + np.log1p(np.exp(-a[pos]))\n",
    "    out[~pos] = np.log1p(np.exp(a[~pos]))\n",
    "    return out\n",
    "\n",
    "\n",
    "def _expit(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Stable logistic sigmoid 1/(1+exp(-a)) (NumPy-only).\"\"\"\n",
    "\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    out = np.empty_like(a, dtype=float)\n",
    "\n",
    "    pos = a >= 0\n",
    "    out[pos] = 1.0 / (1.0 + np.exp(-a[pos]))\n",
    "\n",
    "    ea = np.exp(a[~pos])\n",
    "    out[~pos] = ea / (1.0 + ea)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _logit(p: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Stable log(p/(1-p)) for p in (0,1).\"\"\"\n",
    "\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    return np.log(p) - np.log1p(-p)\n",
    "\n",
    "\n",
    "def fisk_logpdf(x: np.ndarray, c: float, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Log-PDF of Fisk(c, loc, scale) in SciPy's parameterization.\"\"\"\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    c = float(c)\n",
    "    loc = float(loc)\n",
    "    scale = float(scale)\n",
    "\n",
    "    if c <= 0:\n",
    "        raise ValueError(\"c must be > 0\")\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    z = (x - loc) / scale\n",
    "\n",
    "    out = np.full_like(z, fill_value=-np.inf, dtype=float)\n",
    "    mask = z > 0\n",
    "    if not np.any(mask):\n",
    "        return out\n",
    "\n",
    "    logz = np.log(z[mask])\n",
    "    a = c * logz  # log(z^c)\n",
    "\n",
    "    out[mask] = (\n",
    "        np.log(c)\n",
    "        - np.log(scale)\n",
    "        + (c - 1.0) * logz\n",
    "        - 2.0 * _log1pexp(a)\n",
    "    )\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def fisk_pdf(x: np.ndarray, c: float, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"PDF of Fisk(c, loc, scale).\"\"\"\n",
    "\n",
    "    return np.exp(fisk_logpdf(x, c=c, loc=loc, scale=scale))\n",
    "\n",
    "\n",
    "def fisk_cdf(x: np.ndarray, c: float, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"CDF of Fisk(c, loc, scale).\"\"\"\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    c = float(c)\n",
    "    loc = float(loc)\n",
    "    scale = float(scale)\n",
    "\n",
    "    if c <= 0:\n",
    "        raise ValueError(\"c must be > 0\")\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    z = (x - loc) / scale\n",
    "\n",
    "    out = np.zeros_like(z, dtype=float)\n",
    "    mask = z > 0\n",
    "    if not np.any(mask):\n",
    "        return out\n",
    "\n",
    "    logz = np.log(z[mask])\n",
    "    out[mask] = _expit(c * logz)\n",
    "    return out\n",
    "\n",
    "\n",
    "def fisk_sf(x: np.ndarray, c: float, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Survival function 1 - CDF of Fisk(c, loc, scale).\"\"\"\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    c = float(c)\n",
    "    loc = float(loc)\n",
    "    scale = float(scale)\n",
    "\n",
    "    if c <= 0:\n",
    "        raise ValueError(\"c must be > 0\")\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    z = (x - loc) / scale\n",
    "\n",
    "    out = np.ones_like(z, dtype=float)\n",
    "    out[z <= 0] = 1.0\n",
    "\n",
    "    mask = z > 0\n",
    "    if not np.any(mask):\n",
    "        return out\n",
    "\n",
    "    logz = np.log(z[mask])\n",
    "    out[mask] = _expit(-c * logz)\n",
    "    return out\n",
    "\n",
    "\n",
    "def fisk_ppf(u: np.ndarray, c: float, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Quantile function (inverse CDF) of Fisk(c, loc, scale).\"\"\"\n",
    "\n",
    "    u = np.asarray(u, dtype=float)\n",
    "\n",
    "    c = float(c)\n",
    "    loc = float(loc)\n",
    "    scale = float(scale)\n",
    "\n",
    "    if c <= 0:\n",
    "        raise ValueError(\"c must be > 0\")\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    if np.any((u < 0) | (u > 1)):\n",
    "        raise ValueError(\"u must be in [0, 1]\")\n",
    "\n",
    "    out = np.full_like(u, fill_value=np.nan, dtype=float)\n",
    "    out[u == 0] = loc\n",
    "    out[u == 1] = np.inf\n",
    "\n",
    "    mask = (u > 0) & (u < 1)\n",
    "    if not np.any(mask):\n",
    "        return out\n",
    "\n",
    "    out[mask] = loc + scale * np.exp(_logit(u[mask]) / c)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaa7a78",
   "metadata": {},
   "source": [
    "## 4) Moments & Properties\n",
    "\n",
    "A useful fact is that the right tail is polynomial:\n",
    "\n",
    "\\[\n",
    "\\mathbb{P}(X>x) = \\bar F(x) = \\frac{1}{1 + (x/s)^c} \\sim (s/x)^c\\quad (x\\to\\infty).\n",
    "\\]\n",
    "\n",
    "So \\(c\\) is a **tail index**: smaller \\(c\\) means heavier tails.\n",
    "\n",
    "### 4.1 Raw moments (and existence)\n",
    "For \\(k>0\\), the raw moment exists **iff** \\(c > k\\), and\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[X^k] = s^k\\,\\Gamma\\!\\left(1+\\frac{k}{c}\\right)\\Gamma\\!\\left(1-\\frac{k}{c}\\right)\n",
    "= s^k\\,\\frac{\\frac{k\\pi}{c}}{\\sin\\left(\\frac{k\\pi}{c}\\right)}.\n",
    "\\]\n",
    "\n",
    "Consequences:\n",
    "\n",
    "- **Mean** exists for \\(c>1\\):\n",
    "  \\[\\mathbb{E}[X] = s\\,\\frac{\\pi/c}{\\sin(\\pi/c)}.\\]\n",
    "- **Variance** exists for \\(c>2\\):\n",
    "  \\[\\mathrm{Var}(X) = s^2\\left(\\frac{2\\pi/c}{\\sin(2\\pi/c)} - \\left(\\frac{\\pi/c}{\\sin(\\pi/c)}\\right)^2\\right).\\]\n",
    "- **Skewness** exists for \\(c>3\\); **kurtosis** exists for \\(c>4\\).\n",
    "\n",
    "### 4.2 Location summaries\n",
    "- **Median**: \\(\\mathrm{median}(X)=s\\) (and with SciPy `loc`, the median is `loc + scale`).\n",
    "- **Mode** (for \\(c>1\\)):\n",
    "  \\[\\mathrm{mode}(X)=s\\left(\\frac{c-1}{c+1}\\right)^{1/c}.\\]\n",
    "  For \\(c\\le 1\\), the density is decreasing and the mode is at the lower endpoint.\n",
    "\n",
    "### 4.3 MGF / characteristic function\n",
    "- The **MGF** \\(M_X(t)=\\mathbb{E}[e^{tX}]\\) does **not** exist for any \\(t>0\\) (polynomial tails cannot beat exponential growth).\n",
    "- The **characteristic function** \\(\\varphi_X(t)=\\mathbb{E}[e^{itX}]\\) exists, but it does not simplify to an elementary closed form; it’s typically computed numerically.\n",
    "\n",
    "### 4.4 Entropy\n",
    "Using the logistic-on-log-scale representation, the differential entropy is\n",
    "\n",
    "\\[\n",
    " h(X) = 2 + \\log\\left(\\frac{s}{c}\\right)\\quad \\text{(nats)}.\n",
    "\\]\n",
    "\n",
    "(Translation by `loc` does not change entropy; scaling multiplies it by adding \\(\\log(\\mathrm{scale})\\).)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f48a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisk_raw_moment(k: float, c: float, scale: float = 1.0) -> float:\n",
    "    \"\"\"Raw moment E[X^k] for Fisk(c, scale) (loc=0).\n",
    "\n",
    "    Returns np.inf if the moment diverges (c <= k).\n",
    "    \"\"\"\n",
    "\n",
    "    k = float(k)\n",
    "    c = float(c)\n",
    "    scale = float(scale)\n",
    "\n",
    "    if c <= 0:\n",
    "        raise ValueError(\"c must be > 0\")\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "    if k == 0:\n",
    "        return 1.0\n",
    "\n",
    "    if c <= k:\n",
    "        return float(np.inf)\n",
    "\n",
    "    a = np.pi * k / c\n",
    "    return float((scale**k) * (a / np.sin(a)))\n",
    "\n",
    "\n",
    "def fisk_entropy(c: float, scale: float = 1.0) -> float:\n",
    "    \"\"\"Differential entropy in nats for Fisk(c, scale) (loc drops out).\"\"\"\n",
    "\n",
    "    c = float(c)\n",
    "    scale = float(scale)\n",
    "\n",
    "    if c <= 0:\n",
    "        raise ValueError(\"c must be > 0\")\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    return float(2.0 + np.log(scale / c))\n",
    "\n",
    "\n",
    "def fisk_mode(c: float, loc: float = 0.0, scale: float = 1.0) -> float:\n",
    "    \"\"\"Mode of Fisk(c, loc, scale).\"\"\"\n",
    "\n",
    "    c = float(c)\n",
    "    loc = float(loc)\n",
    "    scale = float(scale)\n",
    "\n",
    "    if c <= 0:\n",
    "        raise ValueError(\"c must be > 0\")\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    if c <= 1:\n",
    "        return float(loc)  # density decreases from the boundary\n",
    "\n",
    "    return float(loc + scale * ((c - 1.0) / (c + 1.0)) ** (1.0 / c))\n",
    "\n",
    "\n",
    "def fisk_moments(c: float, loc: float = 0.0, scale: float = 1.0) -> dict:\n",
    "    \"\"\"Mean/variance/skewness/kurtosis (if they exist) + useful summaries.\"\"\"\n",
    "\n",
    "    c = float(c)\n",
    "    loc = float(loc)\n",
    "    scale = float(scale)\n",
    "\n",
    "    if c <= 0:\n",
    "        raise ValueError(\"c must be > 0\")\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    m1 = fisk_raw_moment(1.0, c=c, scale=scale)\n",
    "    m2 = fisk_raw_moment(2.0, c=c, scale=scale)\n",
    "    m3 = fisk_raw_moment(3.0, c=c, scale=scale)\n",
    "    m4 = fisk_raw_moment(4.0, c=c, scale=scale)\n",
    "\n",
    "    mean = loc + m1 if np.isfinite(m1) else np.inf\n",
    "\n",
    "    if np.isfinite(m1) and np.isfinite(m2):\n",
    "        var = m2 - m1**2\n",
    "    else:\n",
    "        var = np.inf\n",
    "\n",
    "    skew = np.nan\n",
    "    excess_kurt = np.nan\n",
    "\n",
    "    if np.isfinite(m1) and np.isfinite(m2) and np.isfinite(m3) and var > 0:\n",
    "        mu3 = m3 - 3 * m2 * m1 + 2 * (m1**3)\n",
    "        skew = mu3 / (var ** 1.5)\n",
    "\n",
    "    if np.isfinite(m1) and np.isfinite(m2) and np.isfinite(m3) and np.isfinite(m4) and var > 0:\n",
    "        mu4 = m4 - 4 * m3 * m1 + 6 * m2 * (m1**2) - 3 * (m1**4)\n",
    "        excess_kurt = mu4 / (var**2) - 3.0\n",
    "\n",
    "    median = loc + scale\n",
    "\n",
    "    return {\n",
    "        \"mean\": float(mean),\n",
    "        \"var\": float(var),\n",
    "        \"skew\": float(skew) if np.isfinite(skew) else np.nan,\n",
    "        \"excess_kurtosis\": float(excess_kurt) if np.isfinite(excess_kurt) else np.nan,\n",
    "        \"median\": float(median),\n",
    "        \"mode\": fisk_mode(c=c, loc=loc, scale=scale),\n",
    "        \"entropy\": fisk_entropy(c=c, scale=scale),\n",
    "    }\n",
    "\n",
    "\n",
    "m0 = fisk_moments(c0, loc=loc0, scale=scale0)\n",
    "m0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6b06b0",
   "metadata": {},
   "source": [
    "## 5) Parameter Interpretation\n",
    "\n",
    "### 5.1 Scale `s`\n",
    "- `scale = s` sets the **median**: \\(\\mathrm{median}(X)=s\\) (when `loc=0`).\n",
    "- On the log-scale, it is a **location** parameter: \\(\\mu = \\log s\\).\n",
    "\n",
    "### 5.2 Shape `c`\n",
    "- `c` controls the **steepness around the median** and the **tail heaviness**.\n",
    "- The tail index is `c`: \\(\\mathbb{P}(X>x) \\sim (s/x)^c\\).\n",
    "- Moments exist only up to order `< c`.\n",
    "- On the log-scale, `c` is the inverse of the logistic scale: \\(\\sigma = 1/c\\).\n",
    "\n",
    "### 5.3 Hazard shape (survival analysis intuition)\n",
    "The hazard rate \\(h(x)=f(x)/(1-F(x))\\) (for `loc=0`) simplifies to\n",
    "\n",
    "\\[\n",
    " h(x) = \\frac{c}{s}\\,\\frac{(x/s)^{c-1}}{1 + (x/s)^c}.\n",
    "\\]\n",
    "\n",
    "- For \\(c \\le 1\\), the hazard is **decreasing**.\n",
    "- For \\(c > 1\\), the hazard is typically **unimodal** (rises, then falls).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca2998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisk_hazard(x: np.ndarray, c: float, loc: float = 0.0, scale: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Hazard h(x) = f(x) / (1 - F(x)).\"\"\"\n",
    "\n",
    "    f = fisk_pdf(x, c=c, loc=loc, scale=scale)\n",
    "    s = fisk_sf(x, c=c, loc=loc, scale=scale)\n",
    "\n",
    "    out = np.full_like(f, fill_value=np.nan, dtype=float)\n",
    "    mask = s > 0\n",
    "    out[mask] = f[mask] / s[mask]\n",
    "    return out\n",
    "\n",
    "\n",
    "x = np.logspace(-3, 2, 800) * scale0\n",
    "c_values = [0.7, 1.0, 2.0, 5.0]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=3,\n",
    "    subplot_titles=[\"PDF (log x)\", \"CDF (log x)\", \"Hazard (log x)\"],\n",
    ")\n",
    "\n",
    "for c in c_values:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=x, y=fisk_pdf(x, c=c, scale=scale0), name=f\"c={c}\", mode=\"lines\"),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=fisk_cdf(x, c=c, scale=scale0),\n",
    "            name=f\"c={c}\",\n",
    "            mode=\"lines\",\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=fisk_hazard(x, c=c, scale=scale0),\n",
    "            name=f\"c={c}\",\n",
    "            mode=\"lines\",\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=3,\n",
    "    )\n",
    "\n",
    "for j in [1, 2, 3]:\n",
    "    fig.update_xaxes(type=\"log\", title_text=\"x\", row=1, col=j)\n",
    "\n",
    "fig.update_yaxes(title_text=\"f(x)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"F(x)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"h(x)\", row=1, col=3)\n",
    "\n",
    "fig.update_layout(title=\"Fisk distribution shape effects (scale fixed)\", height=420)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b269a4",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### 6.1 Expectation (raw moments)\n",
    "Start from the definition for \\(k>0\\):\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[X^k] = \\int_0^\\infty x^k\\,\\frac{c}{s}\\,\\frac{(x/s)^{c-1}}{(1 + (x/s)^c)^2}\\,dx.\n",
    "\\]\n",
    "\n",
    "Use the substitution \\(t = (x/s)^c\\), so \\(x = s\\,t^{1/c}\\) and \\(dx = \\frac{s}{c} t^{1/c-1}\\,dt\\). A pleasant simplification happens:\n",
    "\n",
    "\\[\n",
    "\\frac{c}{s}(x/s)^{c-1}\\,dx = \\frac{c}{s}\\,t^{(c-1)/c}\\,\\frac{s}{c}t^{1/c-1}dt = dt.\n",
    "\\]\n",
    "\n",
    "So\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[X^k] = s^k \\int_0^\\infty \\frac{t^{k/c}}{(1+t)^2}\\,dt.\n",
    "\\]\n",
    "\n",
    "Recognize the Beta-function integral:\n",
    "\n",
    "\\[\n",
    "\\int_0^\\infty \\frac{t^{p-1}}{(1+t)^{m}}\\,dt = B(p, m-p),\\quad 0<p<m.\n",
    "\\]\n",
    "\n",
    "Here \\(m=2\\) and \\(p=1+k/c\\), so the condition becomes \\(c>k\\). Then\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[X^k] = s^k\\,B\\left(1+\\frac{k}{c},\\,1-\\frac{k}{c}\\right)\n",
    "= s^k\\,\\Gamma\\left(1+\\frac{k}{c}\\right)\\Gamma\\left(1-\\frac{k}{c}\\right).\n",
    "\\]\n",
    "\n",
    "Using \\(\\Gamma(1+z)\\Gamma(1-z)=\\frac{\\pi z}{\\sin(\\pi z)}\\) gives the sine form.\n",
    "\n",
    "### 6.2 Variance\n",
    "When \\(c>2\\),\n",
    "\n",
    "\\[\n",
    "\\mathrm{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2,\n",
    "\\]\n",
    "\n",
    "with \\(\\mathbb{E}[X]\\) requiring \\(c>1\\).\n",
    "\n",
    "### 6.3 Likelihood (i.i.d. sample)\n",
    "For i.i.d. observations \\(x_1,\\dots,x_n > 0\\) (assuming `loc=0`), the log-likelihood is\n",
    "\n",
    "\\[\n",
    "\\ell(c,s) = \\sum_{i=1}^n \\log f(x_i\\mid c,s)\n",
    "= n\\log c - n\\log s + (c-1)\\sum_i\\log\\left(\\frac{x_i}{s}\\right) - 2\\sum_i \\log\\left(1+\\left(\\frac{x_i}{s}\\right)^c\\right).\n",
    "\\]\n",
    "\n",
    "There is no closed-form MLE for \\((c,s)\\); we maximize \\(\\ell\\) numerically.\n",
    "A common trick is to optimize over \\((\\log c, \\log s)\\) to enforce positivity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1878aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisk_loglikelihood(x: np.ndarray, c: float, loc: float = 0.0, scale: float = 1.0) -> float:\n",
    "    \"\"\"Total log-likelihood for i.i.d. data under Fisk(c, loc, scale).\"\"\"\n",
    "\n",
    "    return float(np.sum(fisk_logpdf(x, c=c, loc=loc, scale=scale)))\n",
    "\n",
    "\n",
    "def fisk_mle_loc_fixed(x: np.ndarray, loc: float = 0.0) -> tuple[float, float]:\n",
    "    \"\"\"Numerical MLE for (c, scale) with loc fixed.\n",
    "\n",
    "    Uses a logistic-on-log-scale initialization.\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if np.any(x <= loc):\n",
    "        raise ValueError(\"all observations must be > loc\")\n",
    "\n",
    "    x_pos = x - loc\n",
    "\n",
    "    # Initialization from log-scale logistic approximation\n",
    "    y = np.log(x_pos)\n",
    "    mu_init = float(np.median(y))\n",
    "    q25, q75 = np.quantile(y, [0.25, 0.75])\n",
    "    iqr = float(q75 - q25)\n",
    "\n",
    "    # Logistic IQR = 2*s*log(3), with s = 1/c\n",
    "    c_init = float(max(2.0 * np.log(3.0) / max(iqr, 1e-6), 1e-3))\n",
    "    scale_init = float(max(np.exp(mu_init), 1e-6))\n",
    "\n",
    "    def nll(theta: np.ndarray) -> float:\n",
    "        log_c, log_scale = float(theta[0]), float(theta[1])\n",
    "        c = float(np.exp(log_c))\n",
    "        scale = float(np.exp(log_scale))\n",
    "        return -fisk_loglikelihood(x, c=c, loc=loc, scale=scale)\n",
    "\n",
    "    res = optimize.minimize(\n",
    "        nll,\n",
    "        x0=np.array([np.log(c_init), np.log(scale_init)]),\n",
    "        method=\"Nelder-Mead\",\n",
    "        options={\"maxiter\": 5000},\n",
    "    )\n",
    "\n",
    "    log_c_hat, log_scale_hat = res.x\n",
    "    return float(np.exp(log_c_hat)), float(np.exp(log_scale_hat))\n",
    "\n",
    "\n",
    "# Quick demo on synthetic data\n",
    "x_demo = stats.fisk.rvs(c0, loc=loc0, scale=scale0, size=2000, random_state=rng)\n",
    "c_hat, scale_hat = fisk_mle_loc_fixed(x_demo, loc=loc0)\n",
    "\n",
    "print(\"true (c, scale) =\", (c0, scale0))\n",
    "print(\"MLE  (c, scale) =\", (c_hat, scale_hat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524b7dd1",
   "metadata": {},
   "source": [
    "## 7) Sampling & Simulation\n",
    "\n",
    "Inverse-transform sampling uses the quantile function.\n",
    "\n",
    "If \\(U\\sim\\mathrm{Uniform}(0,1)\\), then\n",
    "\n",
    "\\[\n",
    "X = Q(U) = \\mathrm{loc} + \\mathrm{scale}\\,\\exp\\left(\\frac{\\mathrm{logit}(U)}{c}\\right)\n",
    "= \\mathrm{loc} + \\mathrm{scale}\\left(\\frac{U}{1-U}\\right)^{1/c}.\n",
    "\\]\n",
    "\n",
    "Algorithm (NumPy-only):\n",
    "\n",
    "1. Draw \\(u_1,\\dots,u_n\\) i.i.d. from `Uniform(0,1)`.\n",
    "2. Clip away from exactly 0 or 1 (to avoid `±inf` after `logit`).\n",
    "3. Compute `z = exp(logit(u) / c)` and return `loc + scale * z`.\n",
    "\n",
    "Because the distribution is logistic on the log-scale, this is equivalent to sampling\n",
    "\n",
    "\\[\n",
    "Y \\sim \\mathrm{Logistic}(\\mu=\\log(\\mathrm{scale}), \\sigma = 1/c),\\qquad X = \\mathrm{loc}+e^Y.\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86320eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisk_rvs_numpy(\n",
    "    c: float,\n",
    "    size: int,\n",
    "    loc: float = 0.0,\n",
    "    scale: float = 1.0,\n",
    "    rng: np.random.Generator | None = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Sample Fisk(c, loc, scale) using NumPy only (inverse CDF).\"\"\"\n",
    "\n",
    "    c = float(c)\n",
    "    loc = float(loc)\n",
    "    scale = float(scale)\n",
    "\n",
    "    if c <= 0:\n",
    "        raise ValueError(\"c must be > 0\")\n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"scale must be > 0\")\n",
    "\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    u = rng.random(size)\n",
    "\n",
    "    # Avoid u=0 or u=1 exactly (would map to +/-inf)\n",
    "    eps = np.finfo(float).eps\n",
    "    u = np.clip(u, eps, 1.0 - eps)\n",
    "\n",
    "    z = np.exp(_logit(u) / c)\n",
    "    return loc + scale * z\n",
    "\n",
    "\n",
    "# Monte Carlo validation (choose c>2 so mean/variance exist)\n",
    "n = 200_000\n",
    "samples_numpy = fisk_rvs_numpy(c0, size=n, loc=loc0, scale=scale0, rng=rng)\n",
    "\n",
    "mc_mean = samples_numpy.mean()\n",
    "mc_var = samples_numpy.var(ddof=0)\n",
    "\n",
    "print(\"theory mean\", m0[\"mean\"], \"MC\", mc_mean)\n",
    "print(\"theory var \", m0[\"var\"], \"MC\", mc_var)\n",
    "\n",
    "# Compare NumPy-only sampler to SciPy sampler (quick 2-sample KS test)\n",
    "samples_scipy = stats.fisk.rvs(c0, loc=loc0, scale=scale0, size=n, random_state=rng)\n",
    "ks = stats.ks_2samp(samples_numpy[:30_000], samples_scipy[:30_000])\n",
    "ks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96afb782",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We’ll visualize:\n",
    "\n",
    "- the **PDF** with a Monte Carlo histogram overlay\n",
    "- the **CDF** vs an empirical CDF\n",
    "- the **log-scale** view (\\(\\log X\\) should look logistic)\n",
    "\n",
    "Because Fisk can be heavy-tailed, a log-x axis is often the clearest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30522725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF + histogram + CDF/ECDF\n",
    "x_grid = np.logspace(-3, 2, 600) * scale0\n",
    "\n",
    "# Empirical CDF (subsample for plotting)\n",
    "sub = np.sort(samples_numpy[:10_000])\n",
    "ecdf_y = np.arange(1, sub.size + 1) / sub.size\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=[\"PDF with Monte Carlo histogram\", \"CDF vs empirical CDF\"],\n",
    ")\n",
    "\n",
    "# Histogram (density)\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=samples_numpy,\n",
    "        histnorm=\"probability density\",\n",
    "        nbinsx=120,\n",
    "        name=\"samples\",\n",
    "        opacity=0.5,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# Theoretical PDF\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_grid,\n",
    "        y=fisk_pdf(x_grid, c=c0, loc=loc0, scale=scale0),\n",
    "        mode=\"lines\",\n",
    "        name=\"theory pdf\",\n",
    "        line=dict(width=2),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# Theoretical CDF\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_grid,\n",
    "        y=fisk_cdf(x_grid, c=c0, loc=loc0, scale=scale0),\n",
    "        mode=\"lines\",\n",
    "        name=\"theory cdf\",\n",
    "        line=dict(width=2),\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "# Empirical CDF\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=sub,\n",
    "        y=ecdf_y,\n",
    "        mode=\"lines\",\n",
    "        name=\"empirical cdf\",\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(type=\"log\", title_text=\"x\", row=1, col=1)\n",
    "fig.update_xaxes(type=\"log\", title_text=\"x\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"density\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"F(x)\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(height=420, title=f\"Fisk(c={c0}, scale={scale0})\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Log-scale view: log(X) should look logistic\n",
    "y = np.log(samples_numpy - loc0)\n",
    "mu_hat = np.median(y)\n",
    "# logistic scale estimate via IQR: IQR = 2*s*log(3)\n",
    "q25, q75 = np.quantile(y, [0.25, 0.75])\n",
    "s_hat = (q75 - q25) / (2 * np.log(3))\n",
    "\n",
    "# Compare to SciPy logistic on log-scale\n",
    "logistic_dist = stats.logistic(loc=mu_hat, scale=s_hat)\n",
    "\n",
    "y_grid = np.linspace(np.quantile(y, 0.01), np.quantile(y, 0.99), 500)\n",
    "\n",
    "fig2 = go.Figure()\n",
    "fig2.add_trace(\n",
    "    go.Histogram(x=y, histnorm=\"probability density\", nbinsx=120, name=\"log samples\", opacity=0.6)\n",
    ")\n",
    "fig2.add_trace(go.Scatter(x=y_grid, y=logistic_dist.pdf(y_grid), mode=\"lines\", name=\"logistic fit\"))\n",
    "fig2.update_layout(\n",
    "    title=\"On the log-scale, Fisk becomes logistic\",\n",
    "    xaxis_title=\"y = log(x)\",\n",
    "    yaxis_title=\"density\",\n",
    "    height=380,\n",
    ")\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7c1a7c",
   "metadata": {},
   "source": [
    "## 9) SciPy Integration (`scipy.stats.fisk`)\n",
    "\n",
    "SciPy parameterization:\n",
    "\n",
    "```python\n",
    "stats.fisk(c, loc=0, scale=1)\n",
    "```\n",
    "\n",
    "- `c` is the **shape**.\n",
    "- `loc` shifts the support to `(loc, ∞)`.\n",
    "- `scale` rescales (and in the 2-parameter form with `loc=0`, it equals the **median**).\n",
    "\n",
    "Key methods:\n",
    "- `pdf(x)`, `logpdf(x)`, `cdf(x)`, `ppf(q)`\n",
    "- `rvs(size, random_state=...)`\n",
    "- `fit(data, ...)` for MLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba71cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = stats.fisk(c0, loc=loc0, scale=scale0)\n",
    "\n",
    "x_test = np.array([0.5, 1.0, 2.0, 4.0, 8.0])\n",
    "\n",
    "pdf_scipy = dist.pdf(x_test)\n",
    "cdf_scipy = dist.cdf(x_test)\n",
    "\n",
    "pdf_ours = fisk_pdf(x_test, c=c0, loc=loc0, scale=scale0)\n",
    "cdf_ours = fisk_cdf(x_test, c=c0, loc=loc0, scale=scale0)\n",
    "\n",
    "print(\"pdf close?\", np.allclose(pdf_scipy, pdf_ours))\n",
    "print(\"cdf close?\", np.allclose(cdf_scipy, cdf_ours))\n",
    "\n",
    "# Fitting (MLE) with SciPy; fix loc if you know the support starts at 0.\n",
    "c_fit, loc_fit, scale_fit = stats.fisk.fit(samples_numpy[:30_000], floc=0)\n",
    "print(\"fit (c, loc, scale) =\", (c_fit, loc_fit, scale_fit))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c109e7",
   "metadata": {},
   "source": [
    "## 10) Statistical Use Cases\n",
    "\n",
    "### 10.1 Hypothesis testing / goodness-of-fit\n",
    "Typical workflow:\n",
    "\n",
    "1. Fit the distribution parameters (MLE).\n",
    "2. Check fit with diagnostics:\n",
    "   - **KS test** (quick but less sensitive in the tails)\n",
    "   - **QQ/PP plots** (especially important for tail fit)\n",
    "   - tail-specific checks (log-log plots, exceedance probabilities)\n",
    "\n",
    "You can also compare candidates (e.g., Fisk vs lognormal vs Weibull) using **AIC**.\n",
    "\n",
    "### 10.2 Bayesian modeling\n",
    "There is no conjugate prior for \\((c,s)\\), but Bayesian inference is straightforward with MCMC/VI.\n",
    "A useful modeling trick is to work with \\(y_i = \\log x_i\\):\n",
    "\n",
    "\\[\n",
    " y_i \\sim \\mathrm{Logistic}(\\mu=\\log s,\\,\\sigma=1/c),\n",
    "\\]\n",
    "\n",
    "and add the Jacobian term if you write the model on \\(x\\) directly.\n",
    "\n",
    "Below we’ll do a simple **grid posterior** approximation with priors on \\(\\log c\\) and \\(\\log s\\).\n",
    "\n",
    "### 10.3 Generative modeling\n",
    "Because sampling is cheap, Fisk is convenient for generating **positive heavy-tailed** synthetic data.\n",
    "For example, in an accelerated-failure-time style model, you can let the scale depend on covariates:\n",
    "\n",
    "\\[\n",
    "\\log X = \\beta^\\top x + \\varepsilon,\\quad \\varepsilon \\sim \\mathrm{Logistic}(0, 1/c).\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab5264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis testing + model comparison (AIC) on synthetic data\n",
    "true_c, true_scale = 2.5, 1.7\n",
    "x_data = fisk_rvs_numpy(true_c, size=1500, scale=true_scale, rng=rng)\n",
    "\n",
    "# Fit Fisk\n",
    "c_hat, loc_hat, scale_hat = stats.fisk.fit(x_data, floc=0)\n",
    "ll_fisk = float(np.sum(stats.fisk.logpdf(x_data, c_hat, loc=loc_hat, scale=scale_hat)))\n",
    "aic_fisk = 2 * 2 - 2 * ll_fisk  # 2 params (c, scale) since loc fixed\n",
    "\n",
    "# Fit lognormal\n",
    "s_logn, loc_logn, scale_logn = stats.lognorm.fit(x_data, floc=0)\n",
    "ll_logn = float(np.sum(stats.lognorm.logpdf(x_data, s_logn, loc=loc_logn, scale=scale_logn)))\n",
    "aic_logn = 2 * 2 - 2 * ll_logn\n",
    "\n",
    "# Fit Weibull\n",
    "c_w, loc_w, scale_w = stats.weibull_min.fit(x_data, floc=0)\n",
    "ll_w = float(np.sum(stats.weibull_min.logpdf(x_data, c_w, loc=loc_w, scale=scale_w)))\n",
    "aic_w = 2 * 2 - 2 * ll_w\n",
    "\n",
    "print(\"Fitted Fisk   (c, scale)\", (c_hat, scale_hat), \"AIC\", aic_fisk)\n",
    "print(\"Fitted lognorm(s, scale)\", (s_logn, scale_logn), \"AIC\", aic_logn)\n",
    "print(\"Fitted Weibull(c, scale)\", (c_w, scale_w), \"AIC\", aic_w)\n",
    "\n",
    "# KS test against fitted Fisk CDF (note: p-values are approximate after fitting)\n",
    "dist_hat = stats.fisk(c_hat, loc=0, scale=scale_hat)\n",
    "ks = stats.kstest(x_data, dist_hat.cdf)\n",
    "ks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92141188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Bayesian grid posterior over (c, scale) with log-normal-ish priors\n",
    "x_small = x_data[:200]\n",
    "logx = np.log(x_small)\n",
    "\n",
    "c_grid = np.linspace(0.8, 6.0, 120)\n",
    "scale_grid = np.linspace(0.3, 4.0, 140)\n",
    "log_scale_grid = np.log(scale_grid)\n",
    "\n",
    "# Priors: log c ~ N(log 2, 0.7^2), log scale ~ N(log 2, 0.7^2)\n",
    "mu0 = np.log(2.0)\n",
    "s0 = 0.7\n",
    "\n",
    "log_prior_c = stats.norm.logpdf(np.log(c_grid), loc=mu0, scale=s0)\n",
    "log_prior_scale = stats.norm.logpdf(log_scale_grid, loc=mu0, scale=s0)\n",
    "\n",
    "log_post = np.empty((c_grid.size, scale_grid.size), dtype=float)\n",
    "\n",
    "for i, c in enumerate(c_grid):\n",
    "    # Vectorized over scale_grid\n",
    "    logz = logx[:, None] - log_scale_grid[None, :]\n",
    "    a = c * logz\n",
    "\n",
    "    # logpdf for each observation and scale\n",
    "    logpdf = (\n",
    "        np.log(c)\n",
    "        - log_scale_grid[None, :]\n",
    "        + (c - 1.0) * logz\n",
    "        - 2.0 * _log1pexp(a)\n",
    "    )\n",
    "\n",
    "    loglik = logpdf.sum(axis=0)\n",
    "    log_post[i, :] = loglik + log_prior_c[i] + log_prior_scale\n",
    "\n",
    "# Normalize to probabilities\n",
    "log_post -= np.max(log_post)\n",
    "post = np.exp(log_post)\n",
    "post /= post.sum()\n",
    "\n",
    "# Posterior summaries\n",
    "c_mean = float((post.sum(axis=1) * c_grid).sum())\n",
    "scale_mean = float((post.sum(axis=0) * scale_grid).sum())\n",
    "\n",
    "ij_map = np.unravel_index(np.argmax(post), post.shape)\n",
    "c_map = float(c_grid[ij_map[0]])\n",
    "scale_map = float(scale_grid[ij_map[1]])\n",
    "\n",
    "print(\"posterior mean (c, scale) =\", (c_mean, scale_mean))\n",
    "print(\"MAP           (c, scale) =\", (c_map, scale_map))\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=go.Heatmap(\n",
    "        x=scale_grid,\n",
    "        y=c_grid,\n",
    "        z=post,\n",
    "        colorscale=\"Viridis\",\n",
    "        colorbar=dict(title=\"posterior\"),\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Grid posterior p(c, scale | data) (loc fixed to 0)\",\n",
    "    xaxis_title=\"scale\",\n",
    "    yaxis_title=\"c\",\n",
    "    height=420,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68925412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative modeling sketch: scale depends on covariates (AFT-style)\n",
    "n_gen = 1500\n",
    "x_feat = rng.normal(size=n_gen)\n",
    "\n",
    "beta0, beta1 = 0.2, 0.9\n",
    "scale_x = np.exp(beta0 + beta1 * x_feat)  # positive, log-linear\n",
    "\n",
    "u = rng.random(size=n_gen)\n",
    "u = np.clip(u, np.finfo(float).eps, 1.0 - np.finfo(float).eps)\n",
    "\n",
    "# Same shape c0, but varying scale per observation\n",
    "x_gen = scale_x * np.exp(_logit(u) / c0)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x_feat, y=x_gen, mode=\"markers\", marker=dict(size=4, opacity=0.5))\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Synthetic data: Fisk noise with covariate-dependent scale\",\n",
    "    xaxis_title=\"feature x\",\n",
    "    yaxis_title=\"generated positive outcome\",\n",
    "    height=380,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b2b14a",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Invalid parameters**: `c <= 0` or `scale <= 0` is not valid.\n",
    "- **Moment non-existence**:\n",
    "  - if `c <= 1`, the mean is infinite/undefined\n",
    "  - if `c <= 2`, the variance is infinite\n",
    "  - more generally, \\(\\mathbb{E}[X^k]\\) exists only for `k < c`\n",
    "- **Parameterization confusion**:\n",
    "  - “Fisk” and “log-logistic” are the same distribution.\n",
    "  - Many texts use \\(\\alpha\\) (shape) and \\(\\beta\\) (scale); SciPy uses `c` and `scale`.\n",
    "  - On the log-scale, the logistic **scale** is `1/c`.\n",
    "- **Numerical overflow**:\n",
    "  - direct computation of \\((x/s)^c\\) can overflow for large `x`.\n",
    "  - prefer `logpdf`, and compute the CDF via `sigmoid(c * log(x/s))`.\n",
    "- **Sampling edge cases**:\n",
    "  - inverse CDF uses `logit(u)`; clip `u` away from 0 and 1.\n",
    "- **Fitting with `loc` free**:\n",
    "  - estimating `loc` changes the support boundary and can be unstable; fix `loc` when it is known (e.g., 0 for strictly positive data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1edf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical stability demo: naive power vs log-space\n",
    "\n",
    "def fisk_pdf_naive(x: np.ndarray, c: float, scale: float = 1.0) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    z = x / scale\n",
    "    return (c / scale) * (z ** (c - 1.0)) / (1.0 + z**c) ** 2\n",
    "\n",
    "\n",
    "x_big = np.array([1e2, 1e10, 1e50])\n",
    "c_test = 5.0\n",
    "\n",
    "with np.errstate(over=\"ignore\", invalid=\"ignore\", divide=\"ignore\"):\n",
    "    naive = fisk_pdf_naive(x_big, c=c_test, scale=1.0)\n",
    "\n",
    "stable = fisk_pdf(x_big, c=c_test, scale=1.0)\n",
    "log_stable = fisk_logpdf(x_big, c=c_test, scale=1.0)\n",
    "\n",
    "print(\"x\", x_big)\n",
    "print(\"naive  pdf\", naive)\n",
    "print(\"stable pdf\", stable)\n",
    "print(\"logpdf    \", log_stable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9613853f",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `fisk` is the **log-logistic** distribution: \\(\\log X\\) is **logistic**.\n",
    "- It models **positive heavy-tailed** data; the tail index is `c`.\n",
    "- Moments exist only up to order `< c` (mean requires `c>1`, variance requires `c>2`).\n",
    "- Sampling is easy via the **inverse CDF**: `x = loc + scale * exp(logit(u)/c)`.\n",
    "- SciPy provides a robust implementation: `scipy.stats.fisk` (pdf/cdf/rvs/fit).\n",
    "\n",
    "**References**\n",
    "- SciPy: `scipy.stats.fisk`\n",
    "- Burr Type XII distribution (Fisk as a special case)\n",
    "- Logistic distribution entropy and quantiles (for the log-scale view)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}