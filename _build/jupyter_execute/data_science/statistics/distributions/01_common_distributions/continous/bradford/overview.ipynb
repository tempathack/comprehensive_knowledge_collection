{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0570df4f",
   "metadata": {},
   "source": [
    "# Bradford Distribution (`bradford`)\n",
    "\n",
    "The **Bradford distribution** is a **continuous**, one-parameter family on $[0, 1]$ with a logarithmic CDF. It can be viewed as a **scaled log-uniform** (a.k.a. *reciprocal*) distribution, making it a convenient model (or prior) when you want a bounded variable that is **more concentrated near 0** than a uniform distribution.\n",
    "\n",
    "**Learning goals**\n",
    "\n",
    "- Understand the definition (PDF/CDF/quantile) and key limiting cases.\n",
    "- Derive mean/variance and write **numerically stable** NumPy implementations.\n",
    "- Simulate and visualize the distribution, and fit it with `scipy.stats.bradford`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdb2b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "from scipy import optimize, special, stats\n",
    "import scipy\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Reproducibility / environment info\n",
    "import sys\n",
    "import plotly\n",
    "\n",
    "print(\"python:\", sys.version.split()[0])\n",
    "print(\"numpy :\", np.__version__)\n",
    "print(\"scipy :\", scipy.__version__)\n",
    "print(\"plotly:\", plotly.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4867e0cb",
   "metadata": {},
   "source": [
    "## 1) Title & Classification\n",
    "\n",
    "- **Name**: Bradford distribution (`bradford`)\n",
    "- **Type**: **continuous**\n",
    "- **Support**: $x \\in [0, 1]$ (standard form)\n",
    "- **Parameter space**: one **shape** parameter $c > 0$\n",
    "\n",
    "SciPy implements a location–scale family: if $X \\sim \\text{Bradford}(c)$ on $[0,1]$, then\n",
    "\n",
    "\\[\n",
    "Y = \\text{loc} + \\text{scale} \\cdot X\n",
    "\\]\n",
    "\n",
    "has support $[\\text{loc},\\, \\text{loc}+\\text{scale}]$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db774af3",
   "metadata": {},
   "source": [
    "## 2) Intuition & Motivation\n",
    "\n",
    "### What it models\n",
    "\n",
    "A good mental model is:\n",
    "\n",
    "> **Take a number that is uniform on a log-scale**, then linearly rescale it into $[0,1]$.\n",
    "\n",
    "Concretely, if\n",
    "\n",
    "- $U \\sim \\text{Uniform}(0,1)$\n",
    "- $Y = (1+c)^U$ (so $Y$ is **log-uniform** on $[1, 1+c]$)\n",
    "- $X = \\dfrac{Y-1}{c}$\n",
    "\n",
    "then $X$ has a Bradford distribution on $[0,1]$.\n",
    "\n",
    "This creates a **monotonically decreasing PDF**: small values are more likely, but the variable is still bounded.\n",
    "\n",
    "### Typical real-world use cases\n",
    "\n",
    "- **Diminishing returns / “early wins” curves** on a normalized domain: e.g. cumulative share of results found after scanning the first fraction of sources.\n",
    "- **Priors for small probabilities** on $[0,1]$ (a simple alternative to a very skewed Beta prior).\n",
    "- **Simple bounded generative features**: sampling a “small-ish” proportion or weight without going unbounded.\n",
    "\n",
    "### Relations to other distributions\n",
    "\n",
    "- As $c \\to 0^+$, Bradford approaches **Uniform$(0,1)$**.\n",
    "- $1 + cX$ is **log-uniform** on $[1, 1+c]$.\n",
    "- For large $c$, the PDF behaves like a truncated **$1/x$-type** shape (strong concentration near 0) while remaining integrable on $[0,1]$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac048311",
   "metadata": {},
   "source": [
    "## 3) Formal Definition\n",
    "\n",
    "Let $c > 0$. The **PDF** of the Bradford distribution on $[0,1]$ is\n",
    "\n",
    "\\[\n",
    " f(x; c) = \\frac{c}{\\ln(1+c)} \\cdot \\frac{1}{1 + cx}, \\qquad 0 \\le x \\le 1.\n",
    "\\]\n",
    "\n",
    "The **CDF** is\n",
    "\n",
    "\\[\n",
    " F(x; c) = \\frac{\\ln(1+cx)}{\\ln(1+c)}, \\qquad 0 \\le x \\le 1.\n",
    "\\]\n",
    "\n",
    "A very useful consequence is the **quantile function** (inverse CDF): for $u \\in [0,1]$,\n",
    "\n",
    "\\[\n",
    " Q(u; c) = F^{-1}(u) = \\frac{(1+c)^u - 1}{c}.\n",
    "\\]\n",
    "\n",
    "### Numerically stable notation\n",
    "\n",
    "When implementing, prefer\n",
    "\n",
    "- `log1p(z)` for $\\ln(1+z)$\n",
    "- `expm1(z)` for $\\exp(z)-1$\n",
    "\n",
    "to avoid loss of precision for small $c$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_c(c: float) -> float:\n",
    "    c = float(c)\n",
    "    if not np.isfinite(c) or c <= 0:\n",
    "        raise ValueError(f\"c must be finite and > 0, got {c!r}\")\n",
    "    return c\n",
    "\n",
    "\n",
    "def bradford_pdf(x: np.ndarray, c: float) -> np.ndarray:\n",
    "    '''Bradford(c) PDF on [0,1].'''\n",
    "    c = _validate_c(c)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    L = np.log1p(c)\n",
    "    out = np.zeros_like(x)\n",
    "    mask = (0.0 <= x) & (x <= 1.0)\n",
    "    out[mask] = c / (L * (1.0 + c * x[mask]))\n",
    "    return out\n",
    "\n",
    "\n",
    "def bradford_cdf(x: np.ndarray, c: float) -> np.ndarray:\n",
    "    '''Bradford(c) CDF on [0,1].'''\n",
    "    c = _validate_c(c)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    L = np.log1p(c)\n",
    "    out = np.zeros_like(x)\n",
    "    out[x >= 1.0] = 1.0\n",
    "    mask = (0.0 <= x) & (x < 1.0)\n",
    "    out[mask] = np.log1p(c * x[mask]) / L\n",
    "    return out\n",
    "\n",
    "\n",
    "def bradford_ppf(u: np.ndarray, c: float) -> np.ndarray:\n",
    "    '''Bradford(c) quantile function (inverse CDF) for u in [0,1].'''\n",
    "    c = _validate_c(c)\n",
    "    u = np.asarray(u, dtype=float)\n",
    "    if np.any((u < 0) | (u > 1)):\n",
    "        raise ValueError(\"u must be in [0,1]\")\n",
    "\n",
    "    # Q(u) = ((1+c)^u - 1) / c = expm1(u * log1p(c)) / c\n",
    "    return np.expm1(u * np.log1p(c)) / c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9998fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks: PDF integrates to ~1 and matches SciPy\n",
    "c = 7.5\n",
    "x_grid = np.linspace(0, 1, 20001)\n",
    "\n",
    "pdf_vals = bradford_pdf(x_grid, c)\n",
    "area = np.trapz(pdf_vals, x_grid)\n",
    "print(\"∫ pdf dx ≈\", area)\n",
    "\n",
    "dist = stats.bradford(c)\n",
    "max_abs_pdf_diff = np.max(np.abs(pdf_vals - dist.pdf(x_grid)))\n",
    "max_abs_cdf_diff = np.max(np.abs(bradford_cdf(x_grid, c) - dist.cdf(x_grid)))\n",
    "print(\"max |pdf - scipy|:\", max_abs_pdf_diff)\n",
    "print(\"max |cdf - scipy|:\", max_abs_cdf_diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c144651",
   "metadata": {},
   "source": [
    "## 4) Moments & Properties\n",
    "\n",
    "Let $L = \\ln(1+c)$.\n",
    "\n",
    "### Mean and variance\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[X] = \\frac{c - \\ln(1+c)}{c\\,\\ln(1+c)} = \\frac{1}{L} - \\frac{1}{c}.\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "\\mathrm{Var}(X) = \\frac{(c+2)\\ln(1+c) - 2c}{2c\\,[\\ln(1+c)]^2} = \\frac{(c+2)L - 2c}{2cL^2}.\n",
    "\\]\n",
    "\n",
    "### Higher moments, skewness, kurtosis\n",
    "\n",
    "You can write closed-forms for raw moments $\\mathbb{E}[X^k]$ for integer $k$ by integrating\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[X^k] = \\frac{c}{L} \\int_0^1 \\frac{x^k}{1+cx} \\, dx.\n",
    "\\]\n",
    "\n",
    "For $k=1,2,3,4$ these simplify nicely (see code below). Skewness and kurtosis follow from the first four moments.\n",
    "\n",
    "### MGF / characteristic function\n",
    "\n",
    "The MGF exists for all real $t$ (bounded support). Using the exponential integral $\\operatorname{Ei}$,\n",
    "\n",
    "\\[\n",
    "M(t) = \\mathbb{E}[e^{tX}] = \\frac{e^{-t/c}}{\\ln(1+c)}\\left[\\operatorname{Ei}\\left(\\frac{t(1+c)}{c}\\right) - \\operatorname{Ei}\\left(\\frac{t}{c}\\right)\\right].\n",
    "\\]\n",
    "\n",
    "The characteristic function is $\\varphi(\\omega) = M(i\\omega)$.\n",
    "\n",
    "### Entropy\n",
    "\n",
    "The differential entropy has a compact form:\n",
    "\n",
    "\\[\n",
    " h(X) = -\\mathbb{E}[\\ln f(X)] = \\ln\\left(\\frac{\\ln(1+c)}{c}\\right) + \\frac{1}{2}\\ln(1+c).\n",
    "\\]\n",
    "\n",
    "A neat shortcut uses the log-uniform transformation: $\\ln(1+cX) / \\ln(1+c) \\sim \\text{Uniform}(0,1)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b7ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bradford_raw_moments_1_to_4(c: float) -> tuple[float, float, float, float]:\n",
    "    '''Return (E[X], E[X^2], E[X^3], E[X^4]) for X ~ Bradford(c) on [0,1].'''\n",
    "    c = _validate_c(c)\n",
    "    L = np.log1p(c)\n",
    "\n",
    "    ex1 = 1.0 / L - 1.0 / c\n",
    "    ex2 = 1.0 / (2.0 * L) - 1.0 / (c * L) + 1.0 / (c**2)\n",
    "    ex3 = 1.0 / (3.0 * L) - 1.0 / (2.0 * c * L) + 1.0 / (c**2 * L) - 1.0 / (c**3)\n",
    "    ex4 = (\n",
    "        1.0 / (4.0 * L)\n",
    "        - 1.0 / (3.0 * c * L)\n",
    "        + 1.0 / (2.0 * c**2 * L)\n",
    "        - 1.0 / (c**3 * L)\n",
    "        + 1.0 / (c**4)\n",
    "    )\n",
    "    return ex1, ex2, ex3, ex4\n",
    "\n",
    "\n",
    "def bradford_mean_var(c: float) -> tuple[float, float]:\n",
    "    c = _validate_c(c)\n",
    "    L = np.log1p(c)\n",
    "    mean = 1.0 / L - 1.0 / c\n",
    "    var = ((c + 2.0) * L - 2.0 * c) / (2.0 * c * L**2)\n",
    "    return mean, var\n",
    "\n",
    "\n",
    "def bradford_skew_kurtosis_excess(c: float) -> tuple[float, float]:\n",
    "    '''Return (skewness, excess kurtosis) via the first four raw moments.'''\n",
    "    ex1, ex2, ex3, ex4 = bradford_raw_moments_1_to_4(c)\n",
    "\n",
    "    mean = ex1\n",
    "    var = ex2 - mean**2\n",
    "    sigma = np.sqrt(var)\n",
    "\n",
    "    mu3 = ex3 - 3 * mean * ex2 + 2 * mean**3\n",
    "    mu4 = ex4 - 4 * mean * ex3 + 6 * mean**2 * ex2 - 3 * mean**4\n",
    "\n",
    "    skew = mu3 / sigma**3\n",
    "    excess_kurt = mu4 / var**2 - 3.0\n",
    "    return skew, excess_kurt\n",
    "\n",
    "\n",
    "def bradford_entropy(c: float) -> float:\n",
    "    c = _validate_c(c)\n",
    "    L = np.log1p(c)\n",
    "    return np.log(L / c) + 0.5 * L\n",
    "\n",
    "\n",
    "def bradford_mgf(t: np.ndarray, c: float) -> np.ndarray:\n",
    "    '''MGF M(t) using SciPy's Ei implementation (works for real or complex t).'''\n",
    "    c = _validate_c(c)\n",
    "    t = np.asarray(t)\n",
    "    L = np.log1p(c)\n",
    "\n",
    "    # Ei(0) = -inf, but the limit M(0) = 1; handle t=0 explicitly.\n",
    "    out = np.empty_like(t, dtype=np.result_type(t, float))\n",
    "    mask0 = t == 0\n",
    "    out[mask0] = 1.0\n",
    "    mask = ~mask0\n",
    "    if np.any(mask):\n",
    "        tt = t[mask]\n",
    "        out[mask] = np.exp(-tt / c) / L * (special.expi(tt * (1.0 + c) / c) - special.expi(tt / c))\n",
    "    return out\n",
    "\n",
    "c = 7.5\n",
    "mean, var = bradford_mean_var(c)\n",
    "skew, excess_kurt = bradford_skew_kurtosis_excess(c)\n",
    "\n",
    "print(\"mean   :\", mean)\n",
    "print(\"var    :\", var)\n",
    "print(\"skew   :\", skew)\n",
    "print(\"ex.kurt:\", excess_kurt)\n",
    "print(\"entropy:\", bradford_entropy(c))\n",
    "\n",
    "# Compare to SciPy's built-in stats\n",
    "m, v, s, k = stats.bradford(c).stats(moments=\"mvsk\")\n",
    "print(\"\n",
    "SciPy mvsk:\", float(m), float(v), float(s), float(k))\n",
    "\n",
    "# Quick check of MGF at t=0 (should be 1)\n",
    "print(\"\n",
    "M(0) ≈\", bradford_mgf(0.0, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0132367c",
   "metadata": {},
   "source": [
    "## 5) Parameter Interpretation\n",
    "\n",
    "The single parameter $c$ controls *how strongly the density piles up near 0*.\n",
    "\n",
    "- **Small $c$**: $\\ln(1+c) \\approx c$, so $f(x;c) \\approx 1$ → nearly **Uniform$(0,1)$**.\n",
    "- **Large $c$**: the PDF becomes strongly decreasing and more concentrated near 0.\n",
    "\n",
    "Because the support is fixed, this is a convenient “one-knob” family for *bounded, right-skewed* behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9fbfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how the PDF and CDF change with c\n",
    "c_values = [0.2, 1.0, 5.0, 20.0]\n",
    "x = np.linspace(0, 1, 400)\n",
    "\n",
    "fig_pdf = go.Figure()\n",
    "fig_cdf = go.Figure()\n",
    "\n",
    "for c in c_values:\n",
    "    fig_pdf.add_trace(go.Scatter(x=x, y=bradford_pdf(x, c), mode=\"lines\", name=f\"c={c}\"))\n",
    "    fig_cdf.add_trace(go.Scatter(x=x, y=bradford_cdf(x, c), mode=\"lines\", name=f\"c={c}\"))\n",
    "\n",
    "fig_pdf.update_layout(title=\"Bradford PDF on [0,1]\", xaxis_title=\"x\", yaxis_title=\"f(x)\")\n",
    "fig_cdf.update_layout(title=\"Bradford CDF on [0,1]\", xaxis_title=\"x\", yaxis_title=\"F(x)\")\n",
    "\n",
    "fig_pdf.show()\n",
    "fig_cdf.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac829e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How mean/variance evolve with c\n",
    "c_grid = np.logspace(-2, 2, 250)  # 0.01 to 100\n",
    "means = np.array([bradford_mean_var(c)[0] for c in c_grid])\n",
    "vars_ = np.array([bradford_mean_var(c)[1] for c in c_grid])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=c_grid, y=means, mode=\"lines\", name=\"mean\"))\n",
    "fig.add_trace(go.Scatter(x=c_grid, y=vars_, mode=\"lines\", name=\"variance\", yaxis=\"y2\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Mean and variance vs c\",\n",
    "    xaxis_title=\"c (log scale)\",\n",
    "    xaxis_type=\"log\",\n",
    "    yaxis=dict(title=\"mean\"),\n",
    "    yaxis2=dict(title=\"variance\", overlaying=\"y\", side=\"right\"),\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d129b704",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "Let $L = \\ln(1+c)$ and $f(x;c)=\\dfrac{c}{L(1+cx)}$ for $x\\in[0,1]$.\n",
    "\n",
    "### Expectation\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[X] = \\frac{c}{L}\\int_0^1 \\frac{x}{1+cx}\\,dx.\n",
    "\\]\n",
    "\n",
    "Use the identity\n",
    "\n",
    "\\[\n",
    "\\frac{x}{1+cx} = \\frac{1}{c}\\left(1 - \\frac{1}{1+cx}\\right).\n",
    "\\]\n",
    "\n",
    "Then\n",
    "\n",
    "\\[\n",
    "\\int_0^1 \\frac{x}{1+cx}\\,dx = \\frac{1}{c}\\left[ x - \\frac{1}{c}\\ln(1+cx)\\right]_{0}^{1}\n",
    "= \\frac{1}{c}\\left(1 - \\frac{\\ln(1+c)}{c}\\right).\n",
    "\\]\n",
    "\n",
    "Multiplying by $\\frac{c}{L}$ gives\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[X] = \\frac{1}{L} - \\frac{1}{c}.\n",
    "\\]\n",
    "\n",
    "### Variance\n",
    "\n",
    "First compute\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[X^2] = \\frac{c}{L}\\int_0^1 \\frac{x^2}{1+cx}\\,dx.\n",
    "\\]\n",
    "\n",
    "Do a small polynomial decomposition:\n",
    "\n",
    "\\[\n",
    "\\frac{x^2}{1+cx} = \\frac{1}{c}x - \\frac{1}{c^2} + \\frac{1}{c^2(1+cx)}.\n",
    "\\]\n",
    "\n",
    "Integrate term by term to obtain\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[X^2] = \\frac{1}{2L} - \\frac{1}{cL} + \\frac{1}{c^2}.\n",
    "\\]\n",
    "\n",
    "Finally, $\\mathrm{Var}(X)=\\mathbb{E}[X^2] - (\\mathbb{E}[X])^2$ simplifies to\n",
    "\n",
    "\\[\n",
    "\\mathrm{Var}(X) = \\frac{(c+2)L - 2c}{2cL^2}.\n",
    "\\]\n",
    "\n",
    "### Likelihood (i.i.d. sample)\n",
    "\n",
    "For data $x_1,\\dots,x_n \\in [0,1]$, the log-likelihood is\n",
    "\n",
    "\\[\n",
    "\\ell(c) = \\sum_{i=1}^n \\ln f(x_i;c)\n",
    "= n\\ln c - n\\ln \\ln(1+c) - \\sum_{i=1}^n \\ln(1+c x_i).\n",
    "\\]\n",
    "\n",
    "The score equation $\\partial \\ell/\\partial c = 0$ has no closed-form solution for $\\hat c$, but it is smooth and easy to solve numerically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bfe0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bradford_loglik(c: float, x: np.ndarray) -> float:\n",
    "    c = _validate_c(c)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if np.any((x < 0) | (x > 1)):\n",
    "        raise ValueError(\"All x must be in [0,1] for the standard Bradford distribution\")\n",
    "\n",
    "    L = np.log1p(c)\n",
    "    return x.size * np.log(c) - x.size * np.log(L) - np.sum(np.log1p(c * x))\n",
    "\n",
    "\n",
    "def bradford_mle_c(x: np.ndarray, c_init: float = 1.0) -> float:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    def nll(log_c: float) -> float:\n",
    "        c = np.exp(log_c)\n",
    "        return -bradford_loglik(c, x)\n",
    "\n",
    "    res = optimize.minimize(nll, x0=np.log(c_init), method=\"BFGS\")\n",
    "    if not res.success:\n",
    "        raise RuntimeError(f\"MLE optimization failed: {res.message}\")\n",
    "    return float(np.exp(res.x[0]))\n",
    "\n",
    "\n",
    "# Demonstrate MLE recovery on simulated data\n",
    "c_true = 8.0\n",
    "n = 2000\n",
    "x_sim = bradford_ppf(rng.random(n), c_true)\n",
    "\n",
    "c_hat = bradford_mle_c(x_sim, c_init=5.0)\n",
    "print(\"c_true:\", c_true)\n",
    "print(\"c_hat :\", c_hat)\n",
    "\n",
    "# SciPy fit: fixing loc=0, scale=1 focuses fit on shape parameter\n",
    "c_scipy, loc_scipy, scale_scipy = stats.bradford.fit(x_sim, floc=0, fscale=1)\n",
    "print(\"c_fit (scipy):\", c_scipy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbfbdc0",
   "metadata": {},
   "source": [
    "## 7) Sampling & Simulation (NumPy-only)\n",
    "\n",
    "Because the CDF is explicit and strictly increasing, **inverse transform sampling** is the natural choice.\n",
    "\n",
    "From\n",
    "\n",
    "\\[\n",
    "F(x;c) = \\frac{\\ln(1+cx)}{\\ln(1+c)},\n",
    "\\]\n",
    "\n",
    "set $U\\sim \\text{Uniform}(0,1)$ and solve $U=F(X;c)$:\n",
    "\n",
    "\\[\n",
    "\\ln(1+cX) = U\\,\\ln(1+c)\\quad\\Rightarrow\\quad 1+cX = (1+c)^U\\quad\\Rightarrow\\quad X = \\frac{(1+c)^U - 1}{c}.\n",
    "\\]\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "1. Sample $U \\sim \\text{Uniform}(0,1)$.\n",
    "2. Return $X = \\text{expm1}(U\\,\\log1p(c)) / c$.\n",
    "\n",
    "This is fast, exact (up to floating point), and stable with `log1p`/`expm1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b61bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bradford_rvs_numpy(c: float, size: int | tuple[int, ...], rng: np.random.Generator) -> np.ndarray:\n",
    "    c = _validate_c(c)\n",
    "    u = rng.random(size)\n",
    "    return np.expm1(u * np.log1p(c)) / c\n",
    "\n",
    "\n",
    "c = 10.0\n",
    "samples = bradford_rvs_numpy(c, size=200_000, rng=rng)\n",
    "\n",
    "mean_theory, var_theory = bradford_mean_var(c)\n",
    "print(\"empirical mean:\", samples.mean())\n",
    "print(\"theory mean   :\", mean_theory)\n",
    "print(\"empirical var :\", samples.var())\n",
    "print(\"theory var    :\", var_theory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d6db6",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We’ll visualize\n",
    "\n",
    "- the **PDF** and **CDF** (already shown above for multiple $c$)\n",
    "- Monte Carlo samples (histogram + empirical CDF)\n",
    "\n",
    "and compare to the theoretical curves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb3230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram (Monte Carlo) + theoretical PDF overlay\n",
    "c = 10.0\n",
    "n = 50_000\n",
    "x = bradford_rvs_numpy(c, size=n, rng=rng)\n",
    "\n",
    "x_plot = np.linspace(0, 1, 400)\n",
    "\n",
    "hist = px.histogram(\n",
    "    x,\n",
    "    nbins=60,\n",
    "    histnorm=\"probability density\",\n",
    "    opacity=0.6,\n",
    "    title=f\"Monte Carlo samples vs PDF (c={c})\",\n",
    ")\n",
    "\n",
    "hist.add_trace(go.Scatter(x=x_plot, y=bradford_pdf(x_plot, c), mode=\"lines\", name=\"theoretical pdf\"))\n",
    "hist.update_layout(xaxis_title=\"x\", yaxis_title=\"density\")\n",
    "hist.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c0e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empirical CDF vs theoretical CDF\n",
    "c = 10.0\n",
    "x = bradford_rvs_numpy(c, size=30_000, rng=rng)\n",
    "\n",
    "x_sorted = np.sort(x)\n",
    "emp_cdf = np.arange(1, x_sorted.size + 1) / x_sorted.size\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x_sorted, y=emp_cdf, mode=\"lines\", name=\"empirical CDF\"))\n",
    "\n",
    "x_plot = np.linspace(0, 1, 400)\n",
    "fig.add_trace(go.Scatter(x=x_plot, y=bradford_cdf(x_plot, c), mode=\"lines\", name=\"theoretical CDF\"))\n",
    "\n",
    "fig.update_layout(title=f\"Empirical vs theoretical CDF (c={c})\", xaxis_title=\"x\", yaxis_title=\"CDF\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5802cbc0",
   "metadata": {},
   "source": [
    "## 9) SciPy Integration (`scipy.stats.bradford`)\n",
    "\n",
    "SciPy’s `stats.bradford` implements the same one-parameter family, plus optional `loc` and `scale`.\n",
    "\n",
    "Common methods:\n",
    "\n",
    "- `pdf`, `cdf`, `ppf`\n",
    "- `rvs` for sampling\n",
    "- `fit` for MLE\n",
    "\n",
    "When your data are already on $[0,1]$, it’s often best to fix `loc=0` and `scale=1` during fitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6134dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 4.0\n",
    "x = np.linspace(0, 1, 6)\n",
    "\n",
    "dist = stats.bradford(c)\n",
    "print(\"pdf:\", dist.pdf(x))\n",
    "print(\"cdf:\", dist.cdf(x))\n",
    "print(\"rvs:\", dist.rvs(size=5, random_state=rng))\n",
    "\n",
    "# Fit on synthetic data (standard support): fix loc and scale\n",
    "x_sim = dist.rvs(size=5000, random_state=rng)\n",
    "\n",
    "c_hat, loc_hat, scale_hat = stats.bradford.fit(x_sim, floc=0, fscale=1)\n",
    "print(\"\n",
    "true c:\", c)\n",
    "print(\"fit  c:\", c_hat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c40b79a",
   "metadata": {},
   "source": [
    "## 10) Statistical Use Cases\n",
    "\n",
    "### A) Hypothesis testing (likelihood ratio test)\n",
    "\n",
    "For a parametric family $\\{f(x;c)\\}$, a common test is\n",
    "\n",
    "- $H_0: c = c_0$ vs $H_1: c \\ne c_0$.\n",
    "\n",
    "Under regularity conditions, the likelihood ratio statistic\n",
    "\n",
    "\\[\n",
    "\\Lambda = 2\\,[\\ell(\\hat c) - \\ell(c_0)]\n",
    "\\]\n",
    "\n",
    "is approximately $\\chi^2_1$ for large $n$.\n",
    "\n",
    "### B) Bayesian modeling\n",
    "\n",
    "Because Bradford is a flexible, right-skewed distribution on $[0,1]$, it can serve as a **prior** for a probability parameter $p$ when you expect $p$ to be small.\n",
    "\n",
    "Below, we do a simple **grid posterior** for a Binomial likelihood without needing any probabilistic programming library.\n",
    "\n",
    "### C) Generative modeling\n",
    "\n",
    "In a generative pipeline, Bradford is a cheap way to sample a bounded “activation/proportion/weight” variable that is typically small but occasionally larger. With `loc`/`scale`, you can place the support on any finite interval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6015a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Likelihood ratio test example: H0: c = c0\n",
    "from scipy.stats import chi2\n",
    "\n",
    "c0 = 6.0\n",
    "c_true = 10.0\n",
    "n = 3000\n",
    "\n",
    "x = stats.bradford(c_true).rvs(size=n, random_state=rng)\n",
    "\n",
    "c_hat = bradford_mle_c(x, c_init=c0)\n",
    "ll_hat = bradford_loglik(c_hat, x)\n",
    "ll_0 = bradford_loglik(c0, x)\n",
    "\n",
    "lrt = 2 * (ll_hat - ll_0)\n",
    "p_value = 1 - chi2.cdf(lrt, df=1)\n",
    "\n",
    "print(\"c0   :\", c0)\n",
    "print(\"c_hat:\", c_hat)\n",
    "print(\"LRT statistic:\", lrt)\n",
    "print(\"p-value ~\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef803106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) Bayesian modeling: Bradford prior for p in a Binomial model\n",
    "# Observations: k successes out of n\n",
    "n = 50\n",
    "k = 3\n",
    "\n",
    "c_prior = 12.0  # prior mass concentrated near 0\n",
    "\n",
    "p_grid = np.linspace(1e-6, 1 - 1e-6, 4000)\n",
    "prior = bradford_pdf(p_grid, c_prior)\n",
    "\n",
    "# Binomial likelihood up to proportionality: p^k (1-p)^(n-k)\n",
    "log_like = k * np.log(p_grid) + (n - k) * np.log1p(-p_grid)\n",
    "like = np.exp(log_like - log_like.max())\n",
    "\n",
    "posterior_unnorm = prior * like\n",
    "posterior = posterior_unnorm / np.trapz(posterior_unnorm, p_grid)\n",
    "\n",
    "post_mean = np.trapz(p_grid * posterior, p_grid)\n",
    "post_map = p_grid[np.argmax(posterior)]\n",
    "\n",
    "print(\"posterior mean:\", post_mean)\n",
    "print(\"posterior MAP :\", post_map)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=p_grid, y=prior / np.trapz(prior, p_grid), mode=\"lines\", name=\"prior (normalized)\"))\n",
    "fig.add_trace(go.Scatter(x=p_grid, y=posterior, mode=\"lines\", name=\"posterior\"))\n",
    "fig.update_layout(\n",
    "    title=f\"Bradford prior (c={c_prior}) updated by Binomial(n={n}, k={k})\",\n",
    "    xaxis_title=\"p\",\n",
    "    yaxis_title=\"density\",\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68b2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C) Generative modeling: placing Bradford on an arbitrary interval [a, b]\n",
    "a, b = 2.0, 7.0\n",
    "c = 8.0\n",
    "\n",
    "# Sample X on [0,1], then map to [a,b]\n",
    "x = stats.bradford(c).rvs(size=50_000, random_state=rng)\n",
    "y = a + (b - a) * x\n",
    "\n",
    "fig = px.histogram(y, nbins=60, histnorm=\"probability density\", title=f\"Bradford(c={c}) scaled to [{a}, {b}]\")\n",
    "fig.update_layout(xaxis_title=\"y\", yaxis_title=\"density\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a2246",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Parameter validity**: the Bradford shape parameter must satisfy $c>0$. (Uniform$(0,1)$ appears as the limit $c\\to 0^+$.)\n",
    "- **Data support**: for the standard form, you must have $x \\in [0,1]$. If your data live on $[a,b]$, consider the location–scale form.\n",
    "- **Numerical stability**:\n",
    "  - Use `log1p(c)` instead of `log(1+c)`.\n",
    "  - Use `log1p(c*x)` instead of `log(1+c*x)`.\n",
    "  - Use `expm1(u*log1p(c))` when sampling.\n",
    "- **Fitting quirks**: if you let `loc` and `scale` float freely, SciPy may fit a shifted/scaled Bradford that no longer matches your intended support. Fix them when appropriate.\n",
    "- **Name collision**: “Bradford distribution” is sometimes discussed alongside *Bradford’s law* in bibliometrics; be clear whether you mean the continuous distribution implemented by SciPy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd174949",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- Bradford is a **continuous** distribution on $[0,1]$ with PDF $\\propto (1+cx)^{-1}$ and CDF $\\propto \\ln(1+cx)$.\n",
    "- It is equivalent to a **scaled log-uniform**: $1+cX$ is log-uniform on $[1,1+c]$.\n",
    "- The quantile function is explicit, enabling simple **NumPy-only inverse-CDF sampling**.\n",
    "- Mean/variance/entropy have clean formulas; skewness/kurtosis can be computed from low-order moments.\n",
    "- `scipy.stats.bradford` provides a ready-made implementation with `pdf`, `cdf`, `rvs`, and `fit`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}