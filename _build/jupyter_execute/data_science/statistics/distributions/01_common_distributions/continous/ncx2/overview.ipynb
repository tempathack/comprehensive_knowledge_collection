{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54449983",
   "metadata": {},
   "source": [
    "# Noncentral Chi-Square distribution (`ncx2`) — squared norms & test power\n",
    "\n",
    "The **noncentral chi-square** distribution generalizes the usual chi-square by allowing a **mean shift** in the underlying Gaussian components.\n",
    "\n",
    "A core generative story is:\n",
    "\n",
    "\\[\n",
    "Z \\sim \\mathcal N(\\mu, I_k), \\qquad X = \\|Z\\|_2^2 = \\sum_{i=1}^k Z_i^2 \\;\\sim\\; \\chi'^2_k(\\lambda),\n",
    "\\]\n",
    "\n",
    "where the **noncentrality** is the squared mean magnitude\n",
    "\n",
    "\\[\n",
    "\\lambda = \\|\\mu\\|_2^2.\n",
    "\\]\n",
    "\n",
    "It shows up whenever your statistic is a **sum of squares** under an alternative hypothesis: power of $z/t/F/\\chi^2$ tests, signal detection, and more.\n",
    "\n",
    "## What you’ll learn\n",
    "- classification, support, and parameter space $(\n",
    "u,\\lambda)$\n",
    "- the PDF (with a modified Bessel function) and practical CDF representations\n",
    "- moments (mean/variance/skewness/kurtosis), MGF/CF, and entropy notes\n",
    "- how $\n",
    "u$ and $\\lambda$ change the shape\n",
    "- a **NumPy-only** sampler via the Poisson–chi-square mixture\n",
    "- practical usage via `scipy.stats.ncx2` (`pdf`, `cdf`, `rvs`, `fit`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd833556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "from scipy import optimize, special, stats\n",
    "\n",
    "# Plotly rendering (CKC convention)\n",
    "pio.renderers.default = os.environ.get(\"PLOTLY_RENDERER\", \"notebook\")\n",
    "\n",
    "# Reproducibility\n",
    "rng = np.random.default_rng(7)\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "import scipy, plotly\n",
    "print(\"NumPy\", np.__version__)\n",
    "print(\"SciPy\", scipy.__version__)\n",
    "print(\"Plotly\", plotly.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813226af",
   "metadata": {},
   "source": [
    "## 1) Title & Classification\n",
    "\n",
    "- **Name:** noncentral chi-square distribution (`ncx2`)\n",
    "- **Type:** continuous\n",
    "- **Support:** $x\\in[0,\\infty)$\n",
    "- **Parameter space:** degrees of freedom $\n",
    "u>0$, noncentrality $\\lambda\\ge 0$\n",
    "- **Common notation:** $X\\sim\\chi'^2_{\n",
    "u}(\\lambda)$\n",
    "- **SciPy parameterization:** `stats.ncx2(df=ν, nc=λ, loc=0, scale=1)` (with optional `loc\\in\\mathbb R`, `scale>0`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7d3acc",
   "metadata": {},
   "source": [
    "## 2) Intuition & Motivation\n",
    "\n",
    "### What it models\n",
    "- **Energy of a shifted Gaussian vector:** $X=\\|Z\\|_2^2$ with $Z\\sim\\mathcal N(\\mu, I)$.\n",
    "- **Sum of squared signal + noise:** $\\sum_i (s_i + \u000b",
    "arepsilon_i)^2$ where $\u000b",
    "arepsilon_i$ are Gaussian noise terms.\n",
    "\n",
    "### Typical real-world use cases\n",
    "- **Power calculations** for tests that reduce to squared normal statistics (e.g. a two-sided $z$-test can be written in terms of $Z^2$).\n",
    "- **Signal detection** (energy detectors in radar/communications): distribution of observed energy under $H_1$.\n",
    "- **Likelihood ratio / score / Wald tests** in large-sample settings: many asymptotic test statistics are (noncentral) chi-square.\n",
    "\n",
    "### Relations to other distributions\n",
    "- Setting $\\lambda=0$ recovers the **central chi-square**: $\\chi'^2_{\n",
    "u}(0)=\\chi^2_{\n",
    "u}$.\n",
    "- **Poisson mixture:** if $N\\sim\\mathrm{Poisson}(\\lambda/2)$, then\n",
    "  \\[\n",
    "  X\\mid N \\sim \\chi^2_{\n",
    "u+2N}.\n",
    "  \\]\n",
    "- If $Z\\sim\\mathcal N(\\delta,1)$, then $Z^2\\sim\\chi'^2_1(\\delta^2)$.\n",
    "- Ratios lead to noncentral families: if $X_1\\sim\\chi'^2_{\n",
    "u_1}(\\lambda)$ and $X_2\\sim\\chi^2_{\n",
    "u_2}$ are independent, then\n",
    "  \\[\n",
    "  \f",
    "rac{(X_1/\n",
    "u_1)}{(X_2/\n",
    "u_2)}\\sim F'_{\n",
    "u_1,\n",
    "u_2}(\\lambda).\n",
    "  \\]\n",
    "- **Additivity:** if $X_i\\sim \\chi'^2_{\n",
    "u_i}(\\lambda_i)$ are independent, then $\\sum_i X_i\\sim\\chi'^2_{\\sum\n",
    "u_i}(\\sum\\lambda_i)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb5cb71",
   "metadata": {},
   "source": [
    "## 3) Formal Definition\n",
    "\n",
    "We write $X\\sim\\chi'^2_{\n",
    "u}(\\lambda)$ with $\n",
    "u>0$ and $\\lambda\\ge 0$.\n",
    "\n",
    "### PDF\n",
    "For $x>0$,\n",
    "\n",
    "\\[\n",
    "f(x;\n",
    "u,\\lambda)\n",
    "= \f",
    "rac12\\,\\exp\\!\\left(-\f",
    "rac{x+\\lambda}{2}\r",
    "ight)\n",
    "\\left(\f",
    "rac{x}{\\lambda}\r",
    "ight)^{\n",
    "u/4-1/2}\n",
    "I_{\n",
    "u/2-1}\\!\\left(\\sqrt{\\lambda x}\r",
    "ight),\n",
    "\\]\n",
    "\n",
    "where $I_{\u0007lpha}(\\cdot)$ is the **modified Bessel function of the first kind**.\n",
    "\n",
    "For $\\lambda=0$ this reduces to the central chi-square density\n",
    "\n",
    "\\[\n",
    "f(x;\n",
    "u,0)=\f",
    "rac{1}{2^{\n",
    "u/2}\\,\\Gamma(\n",
    "u/2)}x^{\n",
    "u/2-1}e^{-x/2},\\qquad x>0.\n",
    "\\]\n",
    "\n",
    "### CDF\n",
    "A common special-function representation uses the generalized Marcum $Q$-function $Q_m$:\n",
    "\n",
    "\\[\n",
    "F(x;\n",
    "u,\\lambda)=\\mathbb P(X\\le x)=1-Q_{\n",
    "u/2}(\\sqrt{\\lambda},\\sqrt{x}).\n",
    "\\]\n",
    "\n",
    "A numerically useful series view is a **Poisson-weighted mixture of central chi-squares**:\n",
    "\n",
    "\\[\n",
    "F(x;\n",
    "u,\\lambda) = \\sum_{j=0}^{\\infty} w_j\\,F_{\\chi^2_{\n",
    "u+2j}}(x),\n",
    "\\qquad\n",
    "w_j = e^{-\\lambda/2}\f",
    "rac{(\\lambda/2)^j}{j!}.\n",
    "\\]\n",
    "\n",
    "We’ll use this mixture again for sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf8a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncx2_logpdf(x: np.ndarray, df: float, nc: float) -> np.ndarray:\n",
    "    \"\"\"Numerically stable log-PDF for the *standard* noncentral chi-square.\n",
    "\n",
    "    Uses exp-scaled modified Bessel I (`scipy.special.ive`) and falls back\n",
    "    to the central chi-square formula when `nc=0`.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This is mainly for educational purposes; `scipy.stats.ncx2.logpdf`\n",
    "    is battle-tested and should be preferred for production.\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    df = float(df)\n",
    "    nc = float(nc)\n",
    "\n",
    "    if df <= 0:\n",
    "        raise ValueError(\"df must be > 0\")\n",
    "    if nc < 0:\n",
    "        raise ValueError(\"nc must be >= 0\")\n",
    "\n",
    "    out = np.full_like(x, -np.inf, dtype=float)\n",
    "    mask = x > 0\n",
    "\n",
    "    if nc == 0.0:\n",
    "        xm = x[mask]\n",
    "        out[mask] = (\n",
    "            (df / 2 - 1) * np.log(xm)\n",
    "            - xm / 2\n",
    "            - (df / 2) * np.log(2.0)\n",
    "            - special.gammaln(df / 2)\n",
    "        )\n",
    "        return out\n",
    "\n",
    "    xm = x[mask]\n",
    "    z = np.sqrt(nc * xm)\n",
    "    v = df / 2 - 1.0\n",
    "\n",
    "    # log(I_v(z)) via exponentially scaled ive: I_v(z) = exp(z) * ive(v, z) for z>0\n",
    "    log_iv = np.log(special.ive(v, z)) + z\n",
    "\n",
    "    out[mask] = (\n",
    "        -np.log(2.0)\n",
    "        - 0.5 * (xm + nc)\n",
    "        + (df / 4 - 0.5) * (np.log(xm) - np.log(nc))\n",
    "        + log_iv\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def ncx2_pdf(x: np.ndarray, df: float, nc: float) -> np.ndarray:\n",
    "    return np.exp(ncx2_logpdf(x, df, nc))\n",
    "\n",
    "\n",
    "def ncx2_cdf_poisson(\n",
    "    x: np.ndarray,\n",
    "    df: float,\n",
    "    nc: float,\n",
    "    *,\n",
    "    tol: float = 1e-12,\n",
    "    max_terms: int = 10_000,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"CDF via the Poisson-mixture representation.\n",
    "\n",
    "    F(x) = sum_j w_j * chi2_cdf(x; df+2j),   w_j ~ Poisson(nc/2)\n",
    "\n",
    "    This is convenient and conceptually clear, but may require many terms\n",
    "    when `nc` is very large.\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    df = float(df)\n",
    "    nc = float(nc)\n",
    "\n",
    "    if df <= 0:\n",
    "        raise ValueError(\"df must be > 0\")\n",
    "    if nc < 0:\n",
    "        raise ValueError(\"nc must be >= 0\")\n",
    "\n",
    "    cdf = np.zeros_like(x, dtype=float)\n",
    "    cdf = np.where(x < 0, 0.0, cdf)\n",
    "\n",
    "    mask = x >= 0\n",
    "    if not np.any(mask):\n",
    "        return cdf\n",
    "\n",
    "    xm = x[mask]\n",
    "\n",
    "    if nc == 0.0:\n",
    "        cdf[mask] = stats.chi2(df).cdf(xm)\n",
    "        return cdf\n",
    "\n",
    "    lam = nc / 2.0\n",
    "    w = np.exp(-lam)\n",
    "    weight_sum = w\n",
    "\n",
    "    acc = w * stats.chi2(df).cdf(xm)\n",
    "\n",
    "    j = 0\n",
    "    while (1.0 - weight_sum) > tol and j < max_terms:\n",
    "        j += 1\n",
    "        w *= lam / j\n",
    "        weight_sum += w\n",
    "        acc += w * stats.chi2(df + 2 * j).cdf(xm)\n",
    "\n",
    "    cdf[mask] = np.minimum(acc, 1.0)\n",
    "    return cdf\n",
    "\n",
    "\n",
    "# Quick sanity check: PDF integrates to ~1 for a moderate parameter choice\n",
    "_df0, _nc0 = 5.0, 6.0\n",
    "_dist0 = stats.ncx2(_df0, _nc0)\n",
    "\n",
    "xgrid = np.linspace(1e-6, _dist0.ppf(0.9999), 50_000)\n",
    "area_scipy = np.trapz(_dist0.pdf(xgrid), xgrid)\n",
    "area_numpy = np.trapz(ncx2_pdf(xgrid, _df0, _nc0), xgrid)\n",
    "area_numpy, area_scipy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47336b2c",
   "metadata": {},
   "source": [
    "## 4) Moments & Properties\n",
    "\n",
    "For $X\\sim\\chi'^2_{\n",
    "u}(\\lambda)$:\n",
    "\n",
    "| Quantity | Value |\n",
    "|---|---|\n",
    "| Mean | $\\mathbb E[X]=\n",
    "u+\\lambda$ |\n",
    "| Variance | $\\mathrm{Var}(X)=2(\n",
    "u+2\\lambda)$ |\n",
    "| Skewness | $\\gamma_1 = \\dfrac{\\sqrt{8}(\n",
    "u+3\\lambda)}{(\n",
    "u+2\\lambda)^{3/2}}$ |\n",
    "| Excess kurtosis | $\\gamma_2 = \\dfrac{12(\n",
    "u+4\\lambda)}{(\n",
    "u+2\\lambda)^2}$ |\n",
    "| MGF | $M(t)=(1-2t)^{-\n",
    "u/2}\\exp\\!\big(\tfrac{\\lambda t}{1-2t}\big)$ for $t<\tfrac12$ |\n",
    "| CF | $\u000b",
    "arphi(t)=(1-2it)^{-\n",
    "u/2}\\exp\\!\big(\tfrac{\\lambda (it)}{1-2it}\big)$ |\n",
    "\n",
    "**Entropy:** unlike the central chi-square, the noncentral case has no simple closed-form expression; it’s typically evaluated numerically (e.g. `scipy.stats.ncx2(...).entropy()`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fef9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncx2_moments(df: float, nc: float) -> dict:\n",
    "    df = float(df)\n",
    "    nc = float(nc)\n",
    "    if df <= 0:\n",
    "        raise ValueError(\"df must be > 0\")\n",
    "    if nc < 0:\n",
    "        raise ValueError(\"nc must be >= 0\")\n",
    "\n",
    "    mean = df + nc\n",
    "    var = 2.0 * (df + 2.0 * nc)\n",
    "    skew = np.sqrt(8.0) * (df + 3.0 * nc) / (df + 2.0 * nc) ** 1.5\n",
    "    ex_kurt = 12.0 * (df + 4.0 * nc) / (df + 2.0 * nc) ** 2\n",
    "\n",
    "    return {\n",
    "        \"mean\": mean,\n",
    "        \"var\": var,\n",
    "        \"skew\": skew,\n",
    "        \"excess_kurtosis\": ex_kurt,\n",
    "    }\n",
    "\n",
    "\n",
    "def ncx2_mgf(t: np.ndarray, df: float, nc: float) -> np.ndarray:\n",
    "    t = np.asarray(t, dtype=float)\n",
    "    if np.any(t >= 0.5):\n",
    "        raise ValueError(\"MGF exists only for t < 1/2\")\n",
    "    df = float(df)\n",
    "    nc = float(nc)\n",
    "\n",
    "    denom = 1.0 - 2.0 * t\n",
    "    return denom ** (-df / 2) * np.exp(nc * t / denom)\n",
    "\n",
    "\n",
    "def ncx2_cf(t: np.ndarray, df: float, nc: float) -> np.ndarray:\n",
    "    t = np.asarray(t, dtype=float)\n",
    "    df = float(df)\n",
    "    nc = float(nc)\n",
    "\n",
    "    denom = 1.0 - 2.0j * t\n",
    "    return denom ** (-df / 2) * np.exp(nc * (1.0j * t) / denom)\n",
    "\n",
    "\n",
    "df0, nc0 = 5.0, 6.0\n",
    "m = ncx2_moments(df0, nc0)\n",
    "\n",
    "# Compare to SciPy's built-in stats\n",
    "mean_s, var_s, skew_s, exkurt_s = stats.ncx2(df0, nc0).stats(moments=\"mvsk\")\n",
    "entropy_s = stats.ncx2(df0, nc0).entropy()\n",
    "\n",
    "m, (mean_s, var_s, skew_s, exkurt_s), entropy_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b2b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo check of mean/variance and the MGF at a few t\n",
    "n = 200_000\n",
    "samples = stats.ncx2(df0, nc0).rvs(size=n, random_state=rng)\n",
    "\n",
    "mc_mean = float(np.mean(samples))\n",
    "mc_var = float(np.var(samples))\n",
    "\n",
    "t_vals = np.array([-0.2, -0.05, 0.05, 0.15])\n",
    "mgf_mc = np.array([np.mean(np.exp(t * samples)) for t in t_vals])\n",
    "mgf_th = ncx2_mgf(t_vals, df0, nc0)\n",
    "\n",
    "(mc_mean, mc_var), (m[\"mean\"], m[\"var\"]), np.c_[t_vals, mgf_mc, mgf_th]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2667553d",
   "metadata": {},
   "source": [
    "## 5) Parameter Interpretation\n",
    "\n",
    "### Meaning of the parameters\n",
    "- **Degrees of freedom $\n",
    "u$**: roughly “how many squared Gaussian components” contribute. Larger $\n",
    "u$ pushes the mass right and makes the distribution less skewed.\n",
    "- **Noncentrality $\\lambda$**: the *squared* mean shift in the underlying Gaussian story.\n",
    "\n",
    "If $Z\\sim\\mathcal N(\\mu,I_\n",
    "u)$ then $\\lambda=\\|\\mu\\|^2$.\n",
    "In hypothesis testing, $\\lambda$ often equals a **squared effect size** (e.g. $\\delta^2$) and controls **power**.\n",
    "\n",
    "### Shape changes\n",
    "- Increasing $\n",
    "u$ (holding $\\lambda$ fixed) tends to make the density more symmetric and moves the mean right.\n",
    "- Increasing $\\lambda$ (holding $\n",
    "u$ fixed) shifts mass right *and* increases dispersion (since $\\mathrm{Var}(X)=2(\n",
    "u+2\\lambda)$).\n",
    "\n",
    "We’ll visualize these effects next.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c01b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF shape for different (df, nc) combinations\n",
    "param_sets = [\n",
    "    (1.0, 0.0, \"df=1, nc=0 (chi-square)\") ,\n",
    "    (5.0, 0.0, \"df=5, nc=0\"),\n",
    "    (5.0, 3.0, \"df=5, nc=3\"),\n",
    "    (5.0, 10.0, \"df=5, nc=10\"),\n",
    "    (10.0, 10.0, \"df=10, nc=10\"),\n",
    "]\n",
    "\n",
    "# Choose an x-range that covers all parameter sets reasonably well\n",
    "x_max = max(stats.ncx2(df, nc).ppf(0.999) for df, nc, _ in param_sets)\n",
    "x = np.linspace(1e-6, x_max, 800)\n",
    "\n",
    "fig = go.Figure()\n",
    "for df, nc, label in param_sets:\n",
    "    fig.add_trace(go.Scatter(x=x, y=stats.ncx2(df, nc).pdf(x), mode=\"lines\", name=label))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Noncentral chi-square PDFs for several parameter choices\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"density\",\n",
    "    width=950,\n",
    "    height=520,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1e4112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same mean, different (df, nc) => different variance/shape\n",
    "# mean = df + nc, var = 2(df + 2nc)\n",
    "mean_target = 12.0\n",
    "param_same_mean = [\n",
    "    (12.0, 0.0, \"(df=12, nc=0)\"),\n",
    "    (8.0, 4.0, \"(df=8, nc=4)\"),\n",
    "    (4.0, 8.0, \"(df=4, nc=8)\"),\n",
    "]\n",
    "\n",
    "x_max = max(stats.ncx2(df, nc).ppf(0.999) for df, nc, _ in param_same_mean)\n",
    "x = np.linspace(1e-6, x_max, 800)\n",
    "\n",
    "fig = go.Figure()\n",
    "for df, nc, label in param_same_mean:\n",
    "    v = 2 * (df + 2 * nc)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=stats.ncx2(df, nc).pdf(x),\n",
    "            mode=\"lines\",\n",
    "            name=f\"{label} (var={v:.1f})\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Different shapes with the same mean (mean={mean_target:.0f})\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"density\",\n",
    "    width=950,\n",
    "    height=520,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af754a9d",
   "metadata": {},
   "source": [
    "## 6) Derivations\n",
    "\n",
    "### Expectation and variance via the MGF\n",
    "The MGF of $X\\sim\\chi'^2_{\n",
    "u}(\\lambda)$ is\n",
    "\n",
    "\\[\n",
    "M(t)=(1-2t)^{-\n",
    "u/2}\\exp\\!\\left(\f",
    "rac{\\lambda t}{1-2t}\r",
    "ight),\\qquad t<\tfrac12.\n",
    "\\]\n",
    "\n",
    "Then\n",
    "\n",
    "\\[\n",
    "\\mathbb E[X]=M'(0)=\n",
    "u+\\lambda\n",
    "\\qquad\text{and}\\qquad\n",
    "\\mathrm{Var}(X)=M''(0)-M'(0)^2=2(\n",
    "u+2\\lambda).\n",
    "\\]\n",
    "\n",
    "### Expectation and variance via the Poisson mixture\n",
    "Using\n",
    "$X\\mid N\\sim\\chi^2_{\n",
    "u+2N}$ with $N\\sim\\mathrm{Poisson}(\\lambda/2)$:\n",
    "\n",
    "- $\\mathbb E[X\\mid N]=\n",
    "u+2N$ and $\\mathrm{Var}(X\\mid N)=2(\n",
    "u+2N)$.\n",
    "- By the law of total expectation,\n",
    "  $\\mathbb E[X]=\n",
    "u+2\\mathbb E[N]=\n",
    "u+\\lambda$.\n",
    "- By the law of total variance,\n",
    "  \\[\n",
    "  \\mathrm{Var}(X)=\\mathbb E[\\mathrm{Var}(X\\mid N)] + \\mathrm{Var}(\\mathbb E[X\\mid N])\n",
    "  = 2(\n",
    "u+\\lambda) + 4\\,\\mathrm{Var}(N)\n",
    "  = 2(\n",
    "u+\\lambda) + 4\\cdot\f",
    "rac{\\lambda}{2}\n",
    "  = 2(\n",
    "u+2\\lambda).\n",
    "  \\]\n",
    "\n",
    "### Likelihood\n",
    "For i.i.d. data $x_1,\\dots,x_n$,\n",
    "\n",
    "\\[\n",
    "\\ell(\n",
    "u,\\lambda) = \\sum_{i=1}^n \\log f(x_i;\n",
    "u,\\lambda).\n",
    "\\]\n",
    "\n",
    "Unlike the central chi-square (a Gamma family), the presence of the Bessel term means there is **no closed-form MLE** in general; parameters are typically estimated numerically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967cfcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncx2_loglikelihood(x: np.ndarray, df: float, nc: float) -> float:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if np.any(x < 0):\n",
    "        return -np.inf\n",
    "    return float(np.sum(stats.ncx2(df, nc).logpdf(x)))\n",
    "\n",
    "\n",
    "# Likelihood surface (fix df, vary nc)\n",
    "df_true, nc_true = 4.0, 7.0\n",
    "x_obs = stats.ncx2(df_true, nc_true).rvs(size=4000, random_state=rng)\n",
    "\n",
    "nc_grid = np.linspace(0.0, 18.0, 200)\n",
    "ll = np.array([ncx2_loglikelihood(x_obs, df_true, nc) for nc in nc_grid])\n",
    "\n",
    "res = optimize.minimize_scalar(\n",
    "    lambda nc: -ncx2_loglikelihood(x_obs, df_true, nc),\n",
    "    bounds=(0.0, 30.0),\n",
    "    method=\"bounded\",\n",
    ")\n",
    "\n",
    "nc_mle = float(res.x)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=nc_grid, y=ll, mode=\"lines\", name=\"log-likelihood\"))\n",
    "fig.add_vline(x=nc_true, line_dash=\"dash\", line_color=\"green\", annotation_text=\"true nc\")\n",
    "fig.add_vline(x=nc_mle, line_dash=\"dot\", line_color=\"red\", annotation_text=\"MLE (df fixed)\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Log-likelihood as a function of noncentrality (df fixed)\",\n",
    "    xaxis_title=\"nc\",\n",
    "    yaxis_title=\"log-likelihood\",\n",
    "    width=950,\n",
    "    height=520,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "nc_true, nc_mle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e483ffb",
   "metadata": {},
   "source": [
    "## 7) Sampling & Simulation\n",
    "\n",
    "A very useful identity is the **Poisson mixture**:\n",
    "\n",
    "\\[\n",
    "N\\sim\\mathrm{Poisson}(\\lambda/2),\\qquad X\\mid N \\sim \\chi^2_{\n",
    "u+2N}.\n",
    "\\]\n",
    "\n",
    "So sampling $X\\sim\\chi'^2_{\n",
    "u}(\\lambda)$ can be done by:\n",
    "\n",
    "1. Sample $N\\sim\\mathrm{Poisson}(\\lambda/2)$.\n",
    "2. Sample $Y\\sim\\chi^2_{\n",
    "u+2N}$.\n",
    "3. Return $X=Y$.\n",
    "\n",
    "Because a central chi-square is a Gamma,\n",
    "\n",
    "\\[\n",
    "\\chi^2_{k}\\;\\equiv\\;\\mathrm{Gamma}\\left(\u0007lpha=\tfrac{k}{2},\\;\theta=2\r",
    "ight),\n",
    "\\]\n",
    "\n",
    "we just need a **NumPy-only Gamma sampler**. We’ll reuse Marsaglia–Tsang (2000).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad446fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_rvs_numpy(shape: float, size: int, rng: np.random.Generator) -> np.ndarray:\n",
    "    '''Sample Gamma(shape, scale=1) using NumPy only (Marsaglia-Tsang).'''\n",
    "\n",
    "    k = float(shape)\n",
    "    if k <= 0:\n",
    "        raise ValueError(\"shape must be > 0\")\n",
    "\n",
    "    # k < 1: boost to k+1 and apply power transform\n",
    "    if k < 1:\n",
    "        g = gamma_rvs_numpy(k + 1.0, size, rng)\n",
    "        u = rng.random(size)\n",
    "        return g * (u ** (1.0 / k))\n",
    "\n",
    "    # k >= 1: Marsaglia–Tsang\n",
    "    d = k - 1.0 / 3.0\n",
    "    c = 1.0 / np.sqrt(9.0 * d)\n",
    "\n",
    "    out = np.empty(size, dtype=float)\n",
    "    filled = 0\n",
    "\n",
    "    while filled < size:\n",
    "        n = size - filled\n",
    "        x = rng.standard_normal(n)\n",
    "        v = 1.0 + c * x\n",
    "        v = v * v * v  # (1 + c x)^3\n",
    "        u = rng.random(n)\n",
    "\n",
    "        positive = v > 0\n",
    "\n",
    "        # First (cheap) acceptance\n",
    "        accept = positive & (u < 1.0 - 0.0331 * (x**4))\n",
    "\n",
    "        # Second acceptance (log test)\n",
    "        log_v = np.zeros_like(v)\n",
    "        log_v[positive] = np.log(v[positive])\n",
    "\n",
    "        accept2 = positive & (~accept) & (\n",
    "            np.log(u) < 0.5 * x * x + d * (1.0 - v + log_v)\n",
    "        )\n",
    "\n",
    "        accept = accept | accept2\n",
    "        accepted = d * v[accept]\n",
    "\n",
    "        take = min(accepted.size, n)\n",
    "        out[filled : filled + take] = accepted[:take]\n",
    "        filled += take\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def chisquare_rvs_numpy(df: float, size: int, rng: np.random.Generator) -> np.ndarray:\n",
    "    '''Sample ChiSquare(df) using Gamma(df/2, scale=2).'''\n",
    "    return 2.0 * gamma_rvs_numpy(df / 2.0, size, rng)\n",
    "\n",
    "\n",
    "def ncx2_rvs_numpy(df: float, nc: float, size: int, rng: np.random.Generator) -> np.ndarray:\n",
    "    '''Sample noncentral chi-square via the Poisson mixture (NumPy only).'''\n",
    "\n",
    "    df = float(df)\n",
    "    nc = float(nc)\n",
    "    if df <= 0:\n",
    "        raise ValueError(\"df must be > 0\")\n",
    "    if nc < 0:\n",
    "        raise ValueError(\"nc must be >= 0\")\n",
    "\n",
    "    n = rng.poisson(nc / 2.0, size=size)\n",
    "    out = np.empty(size, dtype=float)\n",
    "\n",
    "    # Group by unique Poisson counts to avoid per-sample loops\n",
    "    for n_val in np.unique(n):\n",
    "        mask = n == n_val\n",
    "        df_eff = df + 2.0 * float(n_val)\n",
    "        out[mask] = chisquare_rvs_numpy(df_eff, int(np.sum(mask)), rng)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Monte Carlo validation\n",
    "n = 120_000\n",
    "samples_numpy = ncx2_rvs_numpy(df0, nc0, n, rng)\n",
    "\n",
    "(np.mean(samples_numpy), np.var(samples_numpy)), (m[\"mean\"], m[\"var\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d604271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare NumPy-only sampler to SciPy (quick KS test)\n",
    "dist = stats.ncx2(df0, nc0)\n",
    "ks_stat, ks_p = stats.kstest(samples_numpy[::10], dist.cdf)  # subsample for speed\n",
    "ks_stat, ks_p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bbdd58",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "We’ll visualize:\n",
    "- the theoretical **PDF** and **CDF**\n",
    "- **Monte Carlo** samples from our NumPy-only sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae857c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF + histogram (Monte Carlo)\n",
    "dist = stats.ncx2(df0, nc0)\n",
    "x = np.linspace(1e-6, dist.ppf(0.9995), 800)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=samples_numpy,\n",
    "        nbinsx=70,\n",
    "        histnorm=\"probability density\",\n",
    "        name=\"Monte Carlo (NumPy-only)\",\n",
    "        opacity=0.55,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=x, y=dist.pdf(x), mode=\"lines\", name=\"True PDF (SciPy)\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Noncentral chi-square PDF with samples (df={df0}, nc={nc0})\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"density\",\n",
    "    width=950,\n",
    "    height=520,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b7ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDF: theoretical vs empirical\n",
    "x = np.linspace(0, dist.ppf(0.9995), 700)\n",
    "\n",
    "emp_x = np.sort(samples_numpy)\n",
    "emp_cdf = np.arange(1, emp_x.size + 1) / emp_x.size\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=dist.cdf(x), mode=\"lines\", name=\"True CDF (SciPy)\"))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=emp_x[::300],\n",
    "        y=emp_cdf[::300],\n",
    "        mode=\"markers\",\n",
    "        name=\"Empirical CDF (subsample)\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"CDF comparison\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"F(x)\",\n",
    "    width=950,\n",
    "    height=520,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f6d43",
   "metadata": {},
   "source": [
    "## 9) SciPy Integration (`scipy.stats.ncx2`)\n",
    "\n",
    "`scipy.stats.ncx2` implements the standard distribution (plus `loc`/`scale`). Common methods:\n",
    "\n",
    "- `pdf(x)`, `logpdf(x)`\n",
    "- `cdf(x)`, `sf(x)` (often prefer `sf` for tiny tail probabilities)\n",
    "- `rvs(size=..., random_state=...)`\n",
    "- `fit(data, ...)` for MLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ab13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = stats.ncx2(df0, nc0)\n",
    "\n",
    "x_test = np.array([0.5, 2.0, 8.0])\n",
    "\n",
    "print('pdf:', dist.pdf(x_test))\n",
    "print('cdf:', dist.cdf(x_test))\n",
    "print('sf :', dist.sf(x_test))\n",
    "print('rvs:', dist.rvs(size=5, random_state=rng))\n",
    "\n",
    "# Fit (MLE) on synthetic data; fix loc=0, scale=1 to estimate only (df, nc)\n",
    "data = dist.rvs(size=4000, random_state=rng)\n",
    "df_hat, nc_hat, loc_hat, scale_hat = stats.ncx2.fit(data, floc=0, fscale=1)\n",
    "\n",
    "(df0, nc0), (df_hat, nc_hat, loc_hat, scale_hat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1a32e5",
   "metadata": {},
   "source": [
    "## 10) Statistical Use Cases\n",
    "\n",
    "### 10.1 Hypothesis testing: power of a two-sided $z$-test\n",
    "If $\bar X\\sim\\mathcal N(\\mu,\\sigma^2/n)$ and you test $H_0:\\mu=0$ with\n",
    "\n",
    "\\[\n",
    "Z = \f",
    "rac{\\sqrt{n}\\,\bar X}{\\sigma},\n",
    "\\]\n",
    "\n",
    "then under $H_1$ with true mean $\\mu=\\mu_1$ we have $Z\\sim\\mathcal N(\\delta,1)$ where $\\delta=\\sqrt{n}\\,\\mu_1/\\sigma$.\n",
    "So\n",
    "\n",
    "\\[\n",
    "Z^2\\sim\\chi'^2_1(\\delta^2),\n",
    "\\]\n",
    "\n",
    "and the two-sided rejection region $|Z|>z_{1-\u0007lpha/2}$ becomes $Z^2>z_{1-\u0007lpha/2}^2$.\n",
    "\n",
    "### 10.2 Bayesian modeling: infer the noncentrality\n",
    "In detection problems you may observe an energy-like statistic $x$ and treat $\\lambda$ (signal strength) as unknown:\n",
    "\n",
    "\\[\n",
    "\\lambda \\sim p(\\lambda),\\qquad x\\mid\\lambda \\sim \\chi'^2_{\n",
    "u}(\\lambda).\n",
    "\\]\n",
    "\n",
    "The posterior is proportional to $p(\\lambda)\\,f(x;\n",
    "u,\\lambda)$ (usually computed numerically).\n",
    "\n",
    "### 10.3 Generative modeling: squared norm of a Gaussian\n",
    "If $Z\\sim\\mathcal N(\\mu,I_k)$ then $\\|Z\\|^2\\sim\\chi'^2_k(\\|\\mu\\|^2)$. This gives a simple generator for positive “energy” features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34904a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.1 Power curve for a two-sided z-test using ncx2\n",
    "alpha = 0.05\n",
    "zcrit = stats.norm.ppf(1 - alpha / 2)\n",
    "crit = zcrit**2\n",
    "\n",
    "sigma = 1.0\n",
    "n = 40\n",
    "\n",
    "mu_vals = np.linspace(0.0, 0.8, 120)\n",
    "delta2 = (np.sqrt(n) * mu_vals / sigma) ** 2\n",
    "power = 1.0 - stats.ncx2(df=1, nc=delta2).cdf(crit)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=mu_vals, y=power, mode=\"lines\", name=\"power\"))\n",
    "fig.update_layout(\n",
    "    title=f\"Power of two-sided z-test (alpha={alpha}, n={n}, sigma={sigma})\",\n",
    "    xaxis_title=\"true mean |μ1| (effect size)\",\n",
    "    yaxis_title=\"power\",\n",
    "    yaxis_range=[0, 1],\n",
    "    width=950,\n",
    "    height=520,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "power[:5], crit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf37e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.2 Bayesian inference on nc (lambda) via a grid posterior\n",
    "nu = 4.0\n",
    "x_obs = 14.0\n",
    "\n",
    "# Prior: Gamma(a, rate=b) on lambda\n",
    "# (not conjugate here; this is just a reasonable positive prior)\n",
    "a, b = 2.0, 0.3  # mean a/b ~ 6.67\n",
    "\n",
    "lam_grid = np.linspace(0.0, 40.0, 900)\n",
    "\n",
    "log_prior = (a - 1) * np.log(lam_grid + 1e-12) - b * lam_grid  # unnormalized\n",
    "log_like = stats.ncx2(nu, lam_grid).logpdf(x_obs)\n",
    "log_post = log_prior + log_like\n",
    "\n",
    "log_post -= np.max(log_post)\n",
    "post = np.exp(log_post)\n",
    "post /= np.trapz(post, lam_grid)\n",
    "\n",
    "post_mean = float(np.trapz(lam_grid * post, lam_grid))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=lam_grid, y=post, mode=\"lines\", name=\"posterior\"))\n",
    "fig.add_vline(x=post_mean, line_dash=\"dash\", line_color=\"red\", annotation_text=\"posterior mean\")\n",
    "fig.update_layout(\n",
    "    title=f\"Posterior over nc=λ given x={x_obs} (df={nu})\",\n",
    "    xaxis_title=\"λ\",\n",
    "    yaxis_title=\"posterior density\",\n",
    "    width=950,\n",
    "    height=520,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "post_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.3 Generative model: ||N(mu, I)||^2 matches ncx2\n",
    "k = 3\n",
    "mu = np.array([1.5, -0.5, 0.75])\n",
    "lam = float(mu @ mu)\n",
    "\n",
    "z = rng.standard_normal((80_000, k)) + mu\n",
    "x = np.sum(z * z, axis=1)\n",
    "\n",
    "dist = stats.ncx2(k, lam)\n",
    "xx = np.linspace(1e-6, dist.ppf(0.9995), 800)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=x,\n",
    "        nbinsx=70,\n",
    "        histnorm=\"probability density\",\n",
    "        name=\"Monte Carlo: ||N(μ,I)||^2\",\n",
    "        opacity=0.55,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=xx, y=dist.pdf(xx), mode=\"lines\", name=f\"ncx2(df={k}, nc=||μ||^2={lam:.3f})\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Squared norm of a shifted Gaussian is noncentral chi-square\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"density\",\n",
    "    width=950,\n",
    "    height=520,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "lam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c318e1",
   "metadata": {},
   "source": [
    "## 11) Pitfalls\n",
    "\n",
    "- **Invalid parameters:** you must have `df > 0` and `nc >= 0`.\n",
    "- **Parameterization gotcha:** SciPy’s `ncx2` also supports `loc` and `scale`; most theory assumes `loc=0`, `scale=1`.\n",
    "- **PDF at/near 0:** depending on $(\n",
    "u,\\lambda)$ the density can be very steep near zero; avoid evaluating exactly at `x=0` in naive code.\n",
    "- **Numerical stability:** the Bessel term can overflow for large $\\lambda x$; prefer `logpdf`/`ive`-based formulas.\n",
    "- **Tail probabilities:** prefer `sf` over `1-cdf` when probabilities are tiny.\n",
    "- **Poisson-mixture truncation:** the series CDF needs many terms when $\\lambda$ is large; production code uses specialized algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a8253f",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "\n",
    "- `ncx2` is a **continuous** distribution on $[0,\\infty)$ with parameters $(\n",
    "u,\\lambda)$.\n",
    "- It is the distribution of **squared norms** of shifted Gaussian vectors and underpins many **power** calculations.\n",
    "- The PDF involves a **modified Bessel** function; a key computational view is the **Poisson mixture** of central chi-squares.\n",
    "- Mean/variance are simple: $\n",
    "u+\\lambda$ and $2(\n",
    "u+2\\lambda)$.\n",
    "- Sampling is easy with NumPy using the Poisson-mixture + Gamma sampler.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}