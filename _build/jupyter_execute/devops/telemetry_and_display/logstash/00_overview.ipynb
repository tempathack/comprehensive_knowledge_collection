{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a81a2b0",
   "metadata": {},
   "source": [
    "# Logstash\n",
    "\n",
    "**Logstash** is a data processing pipeline in the Elastic Stack. It ingests events from many sources, **parses/transforms/enriches** them, and ships them to one or more destinations (often Elasticsearch).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f5f0e5",
   "metadata": {},
   "source": [
    "## Goals\n",
    "- Understand the Logstash pipeline model: **inputs -> filters -> outputs**.\n",
    "- Know why Logstash is useful in logging architectures.\n",
    "- See a realistic configuration example (Nginx access logs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f7c5a4",
   "metadata": {},
   "source": [
    "## Why is it used?\n",
    "- Turn raw logs into **structured fields** (JSON documents).\n",
    "- **Normalize** data across many teams/services.\n",
    "- **Enrich** events (geoip, user-agent parsing, add env/version, lookups).\n",
    "- Route to multiple outputs (Elasticsearch + S3 archive + stdout for debugging).\n",
    "\n",
    "When you already log structured JSON, you may not need Logstash at all (agents can ship directly), but it is still useful for central enrichment/routing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4c4d92",
   "metadata": {},
   "source": [
    "## How it works (mental model)\n",
    "Pipeline pseudocode:\n",
    "\n",
    "```text\n",
    "for event in input_stream:\n",
    "  event = parse(event)         # grok/json/dissect\n",
    "  event = enrich(event)        # add service/env/geoip/user_agent\n",
    "  event = normalize(event)     # rename fields, types, timestamps\n",
    "  if should_drop(event):\n",
    "    continue\n",
    "  send(event, outputs)\n",
    "```\n",
    "\n",
    "Config is declarative: you choose plugins for inputs/filters/outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1a32a5",
   "metadata": {},
   "source": [
    "## Example: parse Nginx access logs -> Elasticsearch\n",
    "A minimal-ish Logstash pipeline:\n",
    "\n",
    "```conf\n",
    "input {\n",
    "  beats {\n",
    "    port => 5044\n",
    "  }\n",
    "}\n",
    "\n",
    "filter {\n",
    "  grok {\n",
    "    match => { \"message\" => \"%{COMBINEDAPACHELOG}\" }\n",
    "  }\n",
    "\n",
    "  # convert the parsed timestamp into @timestamp\n",
    "  date {\n",
    "    match => [ \"timestamp\", \"dd/MMM/yyyy:HH:mm:ss Z\" ]\n",
    "  }\n",
    "\n",
    "  mutate {\n",
    "    add_field => { \"service\" => \"edge\" }\n",
    "    add_field => { \"env\" => \"prod\" }\n",
    "  }\n",
    "}\n",
    "\n",
    "output {\n",
    "  elasticsearch {\n",
    "    hosts => [\"http://elasticsearch:9200\"]\n",
    "    index => \"nginx-%{+YYYY.MM.dd}\"\n",
    "  }\n",
    "  stdout { codec => rubydebug }\n",
    "}\n",
    "```\n",
    "\n",
    "Notes:\n",
    "- The **Beats input** commonly receives events from Filebeat.\n",
    "- `grok` turns free-form text into fields; prefer structured logs when possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09b4c60",
   "metadata": {},
   "source": [
    "## Practical tips\n",
    "- Prefer **structured JSON logging** in apps; use Logstash mainly for enrichment and routing.\n",
    "- Use `dissect` when patterns are fixed (faster than grok).\n",
    "- Standardize field names (`service`, `env`, `region`, `version`, `trace_id`).\n",
    "- Treat parsing as a product: test pipelines against sample logs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d7b1e",
   "metadata": {},
   "source": [
    "## Operational notes\n",
    "- **Backpressure**: Elasticsearch slowdowns can propagate; plan buffering.\n",
    "- **Persistent queues** can improve resilience (disk-backed buffering).\n",
    "- Scale horizontally by running multiple Logstash instances behind a load balancer.\n",
    "- Watch CPU usage for grok-heavy pipelines.\n",
    "\n",
    "## Exercises\n",
    "- Write a grok pattern to parse a custom app log format.\n",
    "- Add geoip enrichment and visualize top countries in Kibana.\n",
    "\n",
    "## References\n",
    "- Logstash docs: https://www.elastic.co/guide/en/logstash/current/introduction.html\n",
    "- Grok patterns: https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}