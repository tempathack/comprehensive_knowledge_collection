{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa3c2e5e",
   "metadata": {},
   "source": [
    "# Elasticsearch\n",
    "\n",
    "**Elasticsearch** is a distributed search and analytics engine. In observability it is most commonly used to **index and search logs** (JSON events) and run aggregations for dashboards and investigations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8a4fb8",
   "metadata": {},
   "source": [
    "## Goals\n",
    "- Understand what Elasticsearch stores (documents) and how it searches (indexes).\n",
    "- Know the core objects: **index**, **document**, **mapping**, **shard/replica**.\n",
    "- See how logs are ingested and queried with examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd3c1a2",
   "metadata": {},
   "source": [
    "## What is it?\n",
    "- A **document store** for JSON-like data.\n",
    "- A **full-text search engine** (inverted index) with fast filtering.\n",
    "- A **distributed system** (clusters, shards, replication) for scaling throughput and storage.\n",
    "\n",
    "In a logs use case, each log event becomes a document with fields like `service`, `level`, `http.status`, `trace_id`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a8b4a7",
   "metadata": {},
   "source": [
    "## Why is it used?\n",
    "- **Fast interactive search** (\"find all errors for service X in region Y during deploy Z\").\n",
    "- **Aggregations** for analytics (counts over time, top endpoints, error breakdowns).\n",
    "- Works well with **semi-structured** data (logs with lots of fields).\n",
    "\n",
    "Tradeoffs:\n",
    "- Great for search/aggregations, but **storage can get expensive** at high volume.\n",
    "- Requires attention to **mappings**, **shards**, and **retention**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c6d7c6",
   "metadata": {},
   "source": [
    "## Core concepts\n",
    "- **Document**: one JSON event (a single log line after parsing).\n",
    "- **Index**: a collection of documents (often time-based like `logs-2026.01.07`).\n",
    "- **Mapping**: schema for fields (types like keyword/text/date/long).\n",
    "- **Shard**: a partition of an index (scaling).\n",
    "- **Replica**: a copy of a shard (resilience + read scaling).\n",
    "- **Ingest pipeline**: server-side processing steps (parse/enrich) at index time.\n",
    "- **ILM / retention**: rollover + delete old data to control cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b7b1c",
   "metadata": {},
   "source": [
    "## How it is used (logs pipeline)\n",
    "A common end-to-end flow:\n",
    "\n",
    "```\n",
    "app -> stdout/file -> shipper (Filebeat/Fluent Bit) -> Logstash -> Elasticsearch -> Kibana\n",
    "```\n",
    "\n",
    "Key idea: shipper/Logstash turns \"raw text\" into **structured fields**, Elasticsearch stores them so you can search and aggregate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c4f7e8",
   "metadata": {},
   "source": [
    "## Example: indexing log events (Bulk API)\n",
    "Elasticsearch supports efficient ingestion with the NDJSON bulk format:\n",
    "\n",
    "```bash\n",
    "curl -XPOST 'http://es:9200/_bulk' \\\n",
    "  -H 'Content-Type: application/x-ndjson' \\\n",
    "  --data-binary @- <<'NDJSON'\n",
    "{ \"index\": { \"_index\": \"logs-checkout-2026.01.07\" } }\n",
    "{ \"ts\":\"2026-01-07T20:13:11Z\", \"level\":\"error\", \"service\":\"checkout\", \"msg\":\"timeout\", \"http\": {\"status\": 504} }\n",
    "{ \"index\": { \"_index\": \"logs-checkout-2026.01.07\" } }\n",
    "{ \"ts\":\"2026-01-07T20:13:12Z\", \"level\":\"info\", \"service\":\"checkout\", \"msg\":\"retry\", \"http\": {\"status\": 200} }\n",
    "NDJSON\n",
    "```\n",
    "\n",
    "In practice you rarely do this manually; an agent/Logstash usually sends events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab70c77",
   "metadata": {},
   "source": [
    "## Example: searching + aggregating\n",
    "A typical query filters by service/time/status and aggregates by status:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"filter\": [\n",
    "        {\"term\": {\"service\": \"checkout\"}},\n",
    "        {\"range\": {\"http.status\": {\"gte\": 500}}},\n",
    "        {\"range\": {\"ts\": {\"gte\": \"now-15m\"}}}\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"aggs\": {\n",
    "    \"by_status\": {\"terms\": {\"field\": \"http.status\"}}\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "This is the kind of query Kibana builds behind the scenes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1f9b3c",
   "metadata": {},
   "source": [
    "## Pitfalls and operational notes\n",
    "- **Mapping mistakes** are painful later (e.g., treating IDs as `text` instead of `keyword`).\n",
    "- **Too many shards**: overhead grows; size shards sensibly.\n",
    "- **Hot vs warm data**: recent logs need fast storage; older logs can move to cheaper tiers.\n",
    "- **Retention**: always set ILM/rollover/delete; logs grow without bound.\n",
    "- **Security**: enable auth/TLS and restrict who can read logs.\n",
    "\n",
    "## Exercises\n",
    "- Design an index naming + retention policy (7d hot, 30d warm, delete after 90d).\n",
    "- Pick 5 fields you would standardize across all services (service, env, region, version, trace_id).\n",
    "\n",
    "## References\n",
    "- Elasticsearch docs: https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html\n",
    "- Data streams & ILM: https://www.elastic.co/guide/en/elasticsearch/reference/current/data-streams.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}