{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Design Case Studies\n",
    "\n",
    "This notebook covers three essential system design case studies with detailed requirements, architecture diagrams, and implementation considerations.\n",
    "\n",
    "| Case Study | Key Concepts | Complexity |\n",
    "|------------|--------------|------------|\n",
    "| URL Shortener | Hashing, Base62, Caching | Medium |\n",
    "| Rate Limiter | Token Bucket, Sliding Window, Redis | Medium |\n",
    "| News Feed | Fan-out, Ranking, Timeline | High |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ce80cd",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. URL Shortener (TinyURL)\n",
    "\n",
    "### Functional Requirements\n",
    "- Given a long URL, generate a short unique alias\n",
    "- Redirect short URL to original URL\n",
    "- Custom aliases (optional)\n",
    "- Link expiration (optional)\n",
    "- Analytics (click count, location)\n",
    "\n",
    "### Non-Functional Requirements\n",
    "- High availability (99.9%)\n",
    "- Low latency redirects (<100ms)\n",
    "- Short URLs should be unpredictable\n",
    "- Scale: 100M URLs/day creation, 10:1 read/write ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3e84c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capacity Estimation - URL Shortener\n",
    "\n",
    "# Traffic estimates\n",
    "urls_per_day = 100_000_000  # 100M new URLs/day\n",
    "read_write_ratio = 10\n",
    "reads_per_day = urls_per_day * read_write_ratio  # 1B reads/day\n",
    "\n",
    "# QPS calculations\n",
    "seconds_per_day = 86400\n",
    "write_qps = urls_per_day / seconds_per_day\n",
    "read_qps = reads_per_day / seconds_per_day\n",
    "\n",
    "print(f\"Write QPS: {write_qps:,.0f}\")\n",
    "print(f\"Read QPS: {read_qps:,.0f}\")\n",
    "print(f\"Peak QPS (2x): {read_qps * 2:,.0f}\")\n",
    "\n",
    "# Storage estimates (5 years)\n",
    "years = 5\n",
    "total_urls = urls_per_day * 365 * years\n",
    "avg_url_size = 500  # bytes (original URL)\n",
    "short_url_size = 7  # bytes\n",
    "metadata_size = 100  # bytes (timestamps, user_id, etc.)\n",
    "record_size = avg_url_size + short_url_size + metadata_size\n",
    "\n",
    "total_storage_bytes = total_urls * record_size\n",
    "total_storage_tb = total_storage_bytes / (1024**4)\n",
    "\n",
    "print(f\"\\nTotal URLs (5 years): {total_urls:,.0f}\")\n",
    "print(f\"Storage needed: {total_storage_tb:.1f} TB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca700171",
   "metadata": {},
   "source": [
    "### Architecture Diagram\n",
    "\n",
    "```\n",
    "                                    ┌─────────────────┐\n",
    "                                    │   Load Balancer │\n",
    "                                    └────────┬────────┘\n",
    "                                             │\n",
    "                    ┌────────────────────────┼────────────────────────┐\n",
    "                    │                        │                        │\n",
    "              ┌─────▼─────┐            ┌─────▼─────┐            ┌─────▼─────┐\n",
    "              │ App Server│            │ App Server│            │ App Server│\n",
    "              └─────┬─────┘            └─────┬─────┘            └─────┬─────┘\n",
    "                    │                        │                        │\n",
    "                    └────────────────────────┼────────────────────────┘\n",
    "                                             │\n",
    "                    ┌────────────────────────┼────────────────────────┐\n",
    "                    │                        │                        │\n",
    "              ┌─────▼─────┐            ┌─────▼─────┐            ┌─────▼─────┐\n",
    "              │   Cache   │            │   Cache   │            │   Cache   │\n",
    "              │  (Redis)  │            │  (Redis)  │            │  (Redis)  │\n",
    "              └───────────┘            └───────────┘            └───────────┘\n",
    "                                             │\n",
    "                    ┌────────────────────────┼────────────────────────┐\n",
    "                    │                        │                        │\n",
    "              ┌─────▼─────┐            ┌─────▼─────┐            ┌─────▼─────┐\n",
    "              │  DB Shard │            │  DB Shard │            │  DB Shard │\n",
    "              │  (Range)  │            │  (Range)  │            │  (Range)  │\n",
    "              └───────────┘            └───────────┘            └───────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c3fac6",
   "metadata": {},
   "source": [
    "### Database Schema\n",
    "\n",
    "```sql\n",
    "-- Main URL table (sharded by short_url hash)\n",
    "CREATE TABLE urls (\n",
    "    id              BIGINT PRIMARY KEY,\n",
    "    short_url       VARCHAR(7) UNIQUE NOT NULL,\n",
    "    original_url    VARCHAR(2048) NOT NULL,\n",
    "    user_id         BIGINT,\n",
    "    created_at      TIMESTAMP DEFAULT NOW(),\n",
    "    expires_at      TIMESTAMP,\n",
    "    click_count     BIGINT DEFAULT 0,\n",
    "    INDEX idx_short_url (short_url),\n",
    "    INDEX idx_user_id (user_id)\n",
    ");\n",
    "\n",
    "-- Analytics table (async writes)\n",
    "CREATE TABLE url_analytics (\n",
    "    id          BIGINT PRIMARY KEY,\n",
    "    short_url   VARCHAR(7),\n",
    "    clicked_at  TIMESTAMP,\n",
    "    ip_address  VARCHAR(45),\n",
    "    user_agent  VARCHAR(512),\n",
    "    referrer    VARCHAR(2048)\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5434c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL Shortening Algorithms\n",
    "import hashlib\n",
    "import string\n",
    "\n",
    "# Base62 encoding (0-9, a-z, A-Z)\n",
    "BASE62 = string.digits + string.ascii_lowercase + string.ascii_uppercase\n",
    "\n",
    "def base62_encode(num: int) -> str:\n",
    "    \"\"\"Convert number to base62 string.\"\"\"\n",
    "    if num == 0:\n",
    "        return BASE62[0]\n",
    "    result = []\n",
    "    while num:\n",
    "        result.append(BASE62[num % 62])\n",
    "        num //= 62\n",
    "    return ''.join(reversed(result))\n",
    "\n",
    "def base62_decode(s: str) -> int:\n",
    "    \"\"\"Convert base62 string to number.\"\"\"\n",
    "    num = 0\n",
    "    for char in s:\n",
    "        num = num * 62 + BASE62.index(char)\n",
    "    return num\n",
    "\n",
    "# Method 1: Counter-based (requires distributed counter)\n",
    "def generate_short_url_counter(counter_id: int) -> str:\n",
    "    return base62_encode(counter_id).zfill(7)\n",
    "\n",
    "# Method 2: MD5 hash (first 43 bits -> 7 chars base62)\n",
    "def generate_short_url_hash(long_url: str) -> str:\n",
    "    hash_bytes = hashlib.md5(long_url.encode()).digest()\n",
    "    hash_int = int.from_bytes(hash_bytes[:6], 'big')  # First 48 bits\n",
    "    return base62_encode(hash_int)[:7]\n",
    "\n",
    "# Capacity: 62^7 = 3.5 trillion unique URLs\n",
    "print(f\"Base62 with 7 chars capacity: {62**7:,} URLs\")\n",
    "print(f\"\\nExamples:\")\n",
    "print(f\"Counter 1000000: {generate_short_url_counter(1000000)}\")\n",
    "print(f\"Hash 'https://example.com': {generate_short_url_hash('https://example.com')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec1972",
   "metadata": {},
   "source": [
    "### Key Design Decisions & Trade-offs\n",
    "\n",
    "| Decision | Option A | Option B | Recommendation |\n",
    "|----------|----------|----------|----------------|\n",
    "| **ID Generation** | Counter (ZooKeeper) | MD5 Hash + collision check | Counter for predictable performance |\n",
    "| **Database** | SQL (PostgreSQL) | NoSQL (DynamoDB) | NoSQL for simpler horizontal scaling |\n",
    "| **Caching** | Write-through | Write-around + TTL | Write-around (most URLs read once) |\n",
    "| **Sharding** | Range-based | Hash-based | Hash-based (even distribution) |\n",
    "| **Expiration** | Lazy deletion | Background job | Lazy + periodic cleanup |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ddfcec",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Rate Limiter\n",
    "\n",
    "### Functional Requirements\n",
    "- Limit requests per user/IP/API key\n",
    "- Different limits for different APIs\n",
    "- Return appropriate headers (X-RateLimit-*)\n",
    "- Distributed rate limiting across servers\n",
    "\n",
    "### Non-Functional Requirements\n",
    "- Low latency (<1ms overhead)\n",
    "- High availability\n",
    "- Accurate limiting (no false positives)\n",
    "- Memory efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cd34e4",
   "metadata": {},
   "source": [
    "### Architecture Diagram\n",
    "\n",
    "```\n",
    "    ┌──────────┐     ┌──────────────────┐     ┌──────────────┐\n",
    "    │  Client  │────▶│  API Gateway /   │────▶│  Application │\n",
    "    └──────────┘     │  Load Balancer   │     │   Servers    │\n",
    "                     └────────┬─────────┘     └──────────────┘\n",
    "                              │\n",
    "                              │ Check Rate Limit\n",
    "                              ▼\n",
    "                     ┌──────────────────┐\n",
    "                     │  Rate Limiter    │\n",
    "                     │    Service       │\n",
    "                     └────────┬─────────┘\n",
    "                              │\n",
    "                              ▼\n",
    "                     ┌──────────────────┐\n",
    "                     │  Redis Cluster   │\n",
    "                     │  (Distributed    │\n",
    "                     │   Counters)      │\n",
    "                     └──────────────────┘\n",
    "                              │\n",
    "            ┌─────────────────┼─────────────────┐\n",
    "            ▼                 ▼                 ▼\n",
    "      ┌──────────┐      ┌──────────┐      ┌──────────┐\n",
    "      │  Rules   │      │  Rules   │      │  Rules   │\n",
    "      │  Config  │      │  Config  │      │  Config  │\n",
    "      └──────────┘      └──────────┘      └──────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750bec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rate Limiting Algorithms\n",
    "import time\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TokenBucket:\n",
    "    \"\"\"Token Bucket Algorithm - smooth rate limiting.\"\"\"\n",
    "    capacity: int           # Max tokens\n",
    "    refill_rate: float      # Tokens per second\n",
    "    tokens: float = None\n",
    "    last_refill: float = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.tokens = self.capacity\n",
    "        self.last_refill = time.time()\n",
    "    \n",
    "    def allow_request(self, tokens_needed: int = 1) -> bool:\n",
    "        self._refill()\n",
    "        if self.tokens >= tokens_needed:\n",
    "            self.tokens -= tokens_needed\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def _refill(self):\n",
    "        now = time.time()\n",
    "        elapsed = now - self.last_refill\n",
    "        self.tokens = min(self.capacity, self.tokens + elapsed * self.refill_rate)\n",
    "        self.last_refill = now\n",
    "\n",
    "# Demo\n",
    "bucket = TokenBucket(capacity=10, refill_rate=2)  # 10 max, 2/sec refill\n",
    "print(\"Token Bucket (capacity=10, refill=2/sec):\")\n",
    "for i in range(12):\n",
    "    result = bucket.allow_request()\n",
    "    print(f\"  Request {i+1}: {'✓ Allowed' if result else '✗ Denied'} (tokens: {bucket.tokens:.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68503554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding Window Log Algorithm\n",
    "class SlidingWindowLog:\n",
    "    \"\"\"Precise but memory-intensive rate limiting.\"\"\"\n",
    "    def __init__(self, max_requests: int, window_seconds: int):\n",
    "        self.max_requests = max_requests\n",
    "        self.window_seconds = window_seconds\n",
    "        self.requests = deque()  # Timestamps of requests\n",
    "    \n",
    "    def allow_request(self) -> bool:\n",
    "        now = time.time()\n",
    "        window_start = now - self.window_seconds\n",
    "        \n",
    "        # Remove old requests outside window\n",
    "        while self.requests and self.requests[0] < window_start:\n",
    "            self.requests.popleft()\n",
    "        \n",
    "        if len(self.requests) < self.max_requests:\n",
    "            self.requests.append(now)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "# Sliding Window Counter (hybrid approach)\n",
    "class SlidingWindowCounter:\n",
    "    \"\"\"Memory-efficient approximation.\"\"\"\n",
    "    def __init__(self, max_requests: int, window_seconds: int):\n",
    "        self.max_requests = max_requests\n",
    "        self.window_seconds = window_seconds\n",
    "        self.prev_count = 0\n",
    "        self.curr_count = 0\n",
    "        self.curr_window_start = int(time.time())\n",
    "    \n",
    "    def allow_request(self) -> bool:\n",
    "        now = int(time.time())\n",
    "        window_start = now - (now % self.window_seconds)\n",
    "        \n",
    "        # Rotate windows if needed\n",
    "        if window_start != self.curr_window_start:\n",
    "            self.prev_count = self.curr_count\n",
    "            self.curr_count = 0\n",
    "            self.curr_window_start = window_start\n",
    "        \n",
    "        # Weighted count\n",
    "        elapsed_ratio = (now % self.window_seconds) / self.window_seconds\n",
    "        weighted_count = self.prev_count * (1 - elapsed_ratio) + self.curr_count\n",
    "        \n",
    "        if weighted_count < self.max_requests:\n",
    "            self.curr_count += 1\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "print(\"Algorithm Comparison:\")\n",
    "print(\"┌─────────────────────┬──────────────┬─────────────────┐\")\n",
    "print(\"│ Algorithm           │ Memory       │ Accuracy        │\")\n",
    "print(\"├─────────────────────┼──────────────┼─────────────────┤\")\n",
    "print(\"│ Token Bucket        │ O(1)         │ Allows bursts   │\")\n",
    "print(\"│ Sliding Window Log  │ O(n)         │ Precise         │\")\n",
    "print(\"│ Sliding Window Ctr  │ O(1)         │ ~99% accurate   │\")\n",
    "print(\"│ Fixed Window        │ O(1)         │ Edge spikes     │\")\n",
    "print(\"└─────────────────────┴──────────────┴─────────────────┘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bc7804",
   "metadata": {},
   "source": [
    "### Redis Implementation Patterns\n",
    "\n",
    "```python\n",
    "# Token Bucket in Redis (Lua script for atomicity)\n",
    "TOKEN_BUCKET_SCRIPT = \"\"\"\n",
    "local key = KEYS[1]\n",
    "local capacity = tonumber(ARGV[1])\n",
    "local refill_rate = tonumber(ARGV[2])\n",
    "local now = tonumber(ARGV[3])\n",
    "local requested = tonumber(ARGV[4])\n",
    "\n",
    "local bucket = redis.call('HMGET', key, 'tokens', 'last_refill')\n",
    "local tokens = tonumber(bucket[1]) or capacity\n",
    "local last_refill = tonumber(bucket[2]) or now\n",
    "\n",
    "-- Refill tokens\n",
    "local elapsed = now - last_refill\n",
    "tokens = math.min(capacity, tokens + elapsed * refill_rate)\n",
    "\n",
    "local allowed = 0\n",
    "if tokens >= requested then\n",
    "    tokens = tokens - requested\n",
    "    allowed = 1\n",
    "end\n",
    "\n",
    "redis.call('HMSET', key, 'tokens', tokens, 'last_refill', now)\n",
    "redis.call('EXPIRE', key, capacity / refill_rate * 2)\n",
    "\n",
    "return {allowed, tokens}\n",
    "\"\"\"\n",
    "\n",
    "# Sliding Window Counter in Redis\n",
    "SLIDING_WINDOW_SCRIPT = \"\"\"\n",
    "local key = KEYS[1]\n",
    "local window = tonumber(ARGV[1])\n",
    "local limit = tonumber(ARGV[2])\n",
    "local now = tonumber(ARGV[3])\n",
    "\n",
    "-- Remove old entries\n",
    "redis.call('ZREMRANGEBYSCORE', key, 0, now - window)\n",
    "\n",
    "local count = redis.call('ZCARD', key)\n",
    "if count < limit then\n",
    "    redis.call('ZADD', key, now, now .. math.random())\n",
    "    redis.call('EXPIRE', key, window)\n",
    "    return {1, limit - count - 1}  -- allowed, remaining\n",
    "end\n",
    "return {0, 0}  -- denied, 0 remaining\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9935957c",
   "metadata": {},
   "source": [
    "### Trade-offs & Decisions\n",
    "\n",
    "| Aspect | Consideration |\n",
    "|--------|---------------|\n",
    "| **Location** | API Gateway (centralized) vs Application (distributed) - Gateway preferred for consistency |\n",
    "| **Granularity** | Per-user, per-IP, per-API key, global - Usually combination |\n",
    "| **Failure Mode** | Fail-open (allow) vs Fail-closed (deny) - Depends on security requirements |\n",
    "| **Response** | 429 Too Many Requests + Retry-After header |\n",
    "| **Sync** | Eventual consistency OK for most cases (slight over-limit acceptable) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b048e20f",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. News Feed System\n",
    "\n",
    "### Functional Requirements\n",
    "- Users can create posts (text, images, videos)\n",
    "- Users follow other users\n",
    "- Home feed shows posts from followed users\n",
    "- Feed is sorted by relevance/time\n",
    "- Support likes, comments, shares\n",
    "\n",
    "### Non-Functional Requirements\n",
    "- Feed generation: <500ms\n",
    "- Highly available (99.99%)\n",
    "- Scale: 500M DAU, avg 200 follows per user\n",
    "- Eventually consistent (few seconds delay OK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f322a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capacity Estimation - News Feed\n",
    "\n",
    "dau = 500_000_000  # 500M daily active users\n",
    "avg_follows = 200\n",
    "posts_per_user_per_day = 2\n",
    "feed_refreshes_per_day = 10\n",
    "\n",
    "# Post creation traffic\n",
    "posts_per_day = dau * posts_per_user_per_day\n",
    "post_write_qps = posts_per_day / 86400\n",
    "\n",
    "# Feed read traffic\n",
    "feed_reads_per_day = dau * feed_refreshes_per_day\n",
    "feed_read_qps = feed_reads_per_day / 86400\n",
    "\n",
    "print(f\"Posts created/day: {posts_per_day:,.0f}\")\n",
    "print(f\"Post write QPS: {post_write_qps:,.0f}\")\n",
    "print(f\"Feed read QPS: {feed_read_qps:,.0f}\")\n",
    "\n",
    "# Fan-out estimation\n",
    "avg_followers = 200\n",
    "fanout_writes_per_second = post_write_qps * avg_followers\n",
    "print(f\"\\nFan-out writes/sec (push model): {fanout_writes_per_second:,.0f}\")\n",
    "\n",
    "# Storage (posts for 30 days)\n",
    "post_size_kb = 5  # Average including metadata\n",
    "posts_30_days = posts_per_day * 30\n",
    "storage_tb = (posts_30_days * post_size_kb * 1024) / (1024**4)\n",
    "print(f\"\\nPost storage (30 days): {storage_tb:.1f} TB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb2df26",
   "metadata": {},
   "source": [
    "### High-Level Architecture\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────┐\n",
    "│                              CLIENTS                                     │\n",
    "└────────────────────────────────┬────────────────────────────────────────┘\n",
    "                                 │\n",
    "                                 ▼\n",
    "┌─────────────────────────────────────────────────────────────────────────┐\n",
    "│                           LOAD BALANCER                                  │\n",
    "└────────────────────────────────┬────────────────────────────────────────┘\n",
    "                                 │\n",
    "         ┌───────────────────────┼───────────────────────┐\n",
    "         │                       │                       │\n",
    "         ▼                       ▼                       ▼\n",
    "┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐\n",
    "│   Post Service  │    │   Feed Service  │    │  User Service   │\n",
    "│   (Write Path)  │    │   (Read Path)   │    │  (Graph/Follow) │\n",
    "└────────┬────────┘    └────────┬────────┘    └────────┬────────┘\n",
    "         │                      │                      │\n",
    "         │                      ▼                      │\n",
    "         │             ┌─────────────────┐             │\n",
    "         │             │  Feed Ranking   │             │\n",
    "         │             │    Service      │             │\n",
    "         │             └────────┬────────┘             │\n",
    "         │                      │                      │\n",
    "         ▼                      ▼                      ▼\n",
    "┌─────────────────────────────────────────────────────────────────────────┐\n",
    "│                            CACHE LAYER                                   │\n",
    "│    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐                │\n",
    "│    │ Post Cache  │    │ Feed Cache  │    │ User Cache  │                │\n",
    "│    │   (Redis)   │    │   (Redis)   │    │   (Redis)   │                │\n",
    "│    └─────────────┘    └─────────────┘    └─────────────┘                │\n",
    "└─────────────────────────────────────────────────────────────────────────┘\n",
    "                                 │\n",
    "         ┌───────────────────────┼───────────────────────┐\n",
    "         ▼                       ▼                       ▼\n",
    "┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐\n",
    "│   Posts DB      │    │   Feed Store    │    │  Social Graph   │\n",
    "│  (Cassandra)    │    │    (Redis)      │    │   (Neo4j/SQL)   │\n",
    "└─────────────────┘    └─────────────────┘    └─────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0cc8ca",
   "metadata": {},
   "source": [
    "### Fan-out Strategies\n",
    "\n",
    "```\n",
    "PUSH (Fan-out on Write)                    PULL (Fan-out on Read)\n",
    "========================                    =====================\n",
    "\n",
    "User A posts                               User B requests feed\n",
    "     │                                          │\n",
    "     ▼                                          ▼\n",
    "┌─────────────┐                           ┌─────────────┐\n",
    "│ Get all     │                           │ Get followed│\n",
    "│ followers   │                           │ users list  │\n",
    "└──────┬──────┘                           └──────┬──────┘\n",
    "       │                                         │\n",
    "       ▼                                         ▼\n",
    "┌─────────────┐                           ┌─────────────┐\n",
    "│ Write post  │                           │ Fetch posts │\n",
    "│ to each     │                           │ from each   │\n",
    "│ follower's  │                           │ followed    │\n",
    "│ feed cache  │                           │ user        │\n",
    "└─────────────┘                           └──────┬──────┘\n",
    "                                                 │\n",
    "                                                 ▼\n",
    "                                          ┌─────────────┐\n",
    "                                          │ Merge & Rank│\n",
    "                                          │ in memory   │\n",
    "                                          └─────────────┘\n",
    "\n",
    "✓ Fast reads                              ✓ No wasted writes\n",
    "✓ Pre-computed feed                       ✓ Fresh content\n",
    "✗ Slow writes for celebrities             ✗ Slow reads\n",
    "✗ Wasted storage                          ✗ High read amplification\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509c0dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Fan-out Strategy Implementation\n",
    "\n",
    "CELEBRITY_THRESHOLD = 10000  # Followers\n",
    "\n",
    "class HybridFanout:\n",
    "    \"\"\"Push for regular users, Pull for celebrities.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feed_cache = {}      # user_id -> list of post_ids\n",
    "        self.posts_db = {}        # post_id -> post_data\n",
    "        self.followers = {}       # user_id -> set of follower_ids\n",
    "        self.celebrities = set()  # Users with many followers\n",
    "    \n",
    "    def create_post(self, user_id: str, post: dict) -> None:\n",
    "        post_id = f\"post_{len(self.posts_db)}\"\n",
    "        post['author_id'] = user_id\n",
    "        self.posts_db[post_id] = post\n",
    "        \n",
    "        if user_id in self.celebrities:\n",
    "            # Celebrity: Don't fan out, will be pulled on read\n",
    "            print(f\"Celebrity post {post_id} - stored, no fan-out\")\n",
    "        else:\n",
    "            # Regular user: Push to all followers' caches\n",
    "            followers = self.followers.get(user_id, set())\n",
    "            for follower in followers:\n",
    "                if follower not in self.feed_cache:\n",
    "                    self.feed_cache[follower] = []\n",
    "                self.feed_cache[follower].insert(0, post_id)\n",
    "            print(f\"Regular post {post_id} - pushed to {len(followers)} followers\")\n",
    "    \n",
    "    def get_feed(self, user_id: str, following: list) -> list:\n",
    "        # Get pre-computed feed (from push)\n",
    "        feed_posts = self.feed_cache.get(user_id, [])[:50]\n",
    "        \n",
    "        # Pull celebrity posts\n",
    "        celebrity_posts = []\n",
    "        for celeb in [u for u in following if u in self.celebrities]:\n",
    "            celeb_posts = [pid for pid, p in self.posts_db.items() \n",
    "                          if p['author_id'] == celeb]\n",
    "            celebrity_posts.extend(celeb_posts[:10])\n",
    "        \n",
    "        # Merge and rank\n",
    "        all_posts = list(set(feed_posts + celebrity_posts))\n",
    "        return sorted(all_posts, key=lambda x: self.posts_db[x].get('timestamp', 0), \n",
    "                     reverse=True)[:20]\n",
    "\n",
    "# Demo\n",
    "fanout = HybridFanout()\n",
    "fanout.followers['user_a'] = {'user_b', 'user_c'}  # Regular user\n",
    "fanout.followers['celeb'] = set(f'user_{i}' for i in range(15000))  # Celebrity\n",
    "fanout.celebrities.add('celeb')\n",
    "\n",
    "fanout.create_post('user_a', {'content': 'Hello!', 'timestamp': 1})\n",
    "fanout.create_post('celeb', {'content': 'Celeb post!', 'timestamp': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737cb16c",
   "metadata": {},
   "source": [
    "### Feed Ranking\n",
    "\n",
    "```python\n",
    "# Simplified ranking score calculation\n",
    "def calculate_score(post, user_id):\n",
    "    # Engagement signals\n",
    "    likes_score = log(post.likes + 1) * 2\n",
    "    comments_score = log(post.comments + 1) * 3\n",
    "    shares_score = log(post.shares + 1) * 4\n",
    "    \n",
    "    # Recency decay (half-life = 6 hours)\n",
    "    age_hours = (now() - post.created_at).hours\n",
    "    recency_score = 1 / (1 + age_hours / 6)\n",
    "    \n",
    "    # Affinity (user-author relationship)\n",
    "    affinity = get_interaction_score(user_id, post.author_id)\n",
    "    \n",
    "    # Content type boost\n",
    "    type_boost = {'video': 1.5, 'image': 1.2, 'text': 1.0}[post.type]\n",
    "    \n",
    "    return (likes_score + comments_score + shares_score) \\\n",
    "           * recency_score * affinity * type_boost\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2077a022",
   "metadata": {},
   "source": [
    "### Database Choices\n",
    "\n",
    "| Data | Storage | Rationale |\n",
    "|------|---------|----------|\n",
    "| **Posts** | Cassandra / DynamoDB | High write throughput, time-series partitioning |\n",
    "| **Feed Cache** | Redis (Sorted Sets) | Fast reads, automatic ordering, TTL |\n",
    "| **Social Graph** | Neo4j / TAO (FB) | Efficient traversal, friend-of-friend queries |\n",
    "| **User Profiles** | PostgreSQL | Strong consistency, ACID for auth |\n",
    "| **Media** | S3 + CDN | Blob storage, global distribution |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff8f353",
   "metadata": {},
   "source": [
    "### Key Trade-offs Summary\n",
    "\n",
    "| Decision | Trade-off |\n",
    "|----------|----------|\n",
    "| **Push vs Pull** | Hybrid: Push for regular users (fast reads), Pull for celebrities (avoid hot partitions) |\n",
    "| **Consistency** | Eventual consistency acceptable - users won't notice 1-2 second delay |\n",
    "| **Feed Length** | Cache last 800 posts per user, older posts fetched from DB |\n",
    "| **Ranking** | Real-time ranking expensive - pre-compute + lightweight re-ranking |\n",
    "| **Sharding** | Shard by user_id for feed cache, by post_id for posts DB |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a4a7f",
   "metadata": {},
   "source": [
    "---\n",
    "## Quick Reference: Common Patterns\n",
    "\n",
    "| Pattern | Use Case | Example |\n",
    "|---------|----------|--------|\n",
    "| **Write-behind cache** | High write volume | News feed cache |\n",
    "| **Read-through cache** | Frequent reads | URL shortener lookups |\n",
    "| **Sharding** | Horizontal scale | User ID hash-based |\n",
    "| **Async processing** | Decoupling | Fan-out via message queue |\n",
    "| **Circuit breaker** | Fault tolerance | Rate limiter fallback |\n",
    "| **Bloom filter** | Existence check | \"Have I seen this URL?\" |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
