{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Design: Scalability Patterns\n",
    "\n",
    "Essential patterns and strategies for building scalable distributed systems.\n",
    "\n",
    "## Topics Covered\n",
    "1. Horizontal vs Vertical Scaling\n",
    "2. Load Balancing Algorithms\n",
    "3. Caching Strategies\n",
    "4. Database Scaling\n",
    "5. Message Queues & Event-Driven Architecture\n",
    "6. CQRS & Event Sourcing\n",
    "7. Rate Limiting Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b962cfaf",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Horizontal vs Vertical Scaling\n",
    "\n",
    "```\n",
    "VERTICAL SCALING (Scale Up)          HORIZONTAL SCALING (Scale Out)\n",
    "┌─────────────────────┐              ┌─────────┐ ┌─────────┐ ┌─────────┐\n",
    "│                     │              │ Server  │ │ Server  │ │ Server  │\n",
    "│   BIGGER SERVER     │              │   1     │ │   2     │ │   3     │\n",
    "│   ↑ CPU, RAM, SSD   │              └────┬────┘ └────┬────┘ └────┬────┘\n",
    "│                     │                   │          │          │\n",
    "└─────────────────────┘                   └──────────┼──────────┘\n",
    "                                                     │\n",
    "                                              ┌──────┴──────┐\n",
    "                                              │Load Balancer│\n",
    "                                              └─────────────┘\n",
    "```\n",
    "\n",
    "| Aspect | Vertical Scaling | Horizontal Scaling |\n",
    "|--------|------------------|-------------------|\n",
    "| **Approach** | Add resources to single server | Add more servers |\n",
    "| **Limit** | Hardware ceiling | Virtually unlimited |\n",
    "| **Downtime** | Usually required | Zero downtime possible |\n",
    "| **Cost** | Expensive at scale | Cost-effective |\n",
    "| **Complexity** | Simple | Complex (distributed) |\n",
    "| **Fault Tolerance** | Single point of failure | High availability |\n",
    "| **Data Consistency** | Easy | Challenging |\n",
    "| **Use Case** | Databases, legacy apps | Stateless web servers |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e6d5ba",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Balancing Algorithms\n",
    "\n",
    "```\n",
    "                    ┌─────────────────────────────────────────┐\n",
    "                    │           LOAD BALANCER                 │\n",
    "                    │                                         │\n",
    "  Clients ──────────►  Algorithms:                           │\n",
    "                    │  • Round Robin                          │\n",
    "                    │  • Weighted Round Robin                 │\n",
    "                    │  • Least Connections                    │\n",
    "                    │  • IP Hash (Consistent Hashing)         │\n",
    "                    │  • Random                               │\n",
    "                    └────────────┬───────────┬───────────┬────┘\n",
    "                                 │           │           │\n",
    "                                 ▼           ▼           ▼\n",
    "                            ┌────────┐ ┌────────┐ ┌────────┐\n",
    "                            │Server 1│ │Server 2│ │Server 3│\n",
    "                            └────────┘ └────────┘ └────────┘\n",
    "```\n",
    "\n",
    "| Algorithm | How It Works | Best For |\n",
    "|-----------|--------------|----------|\n",
    "| **Round Robin** | Sequential distribution | Homogeneous servers |\n",
    "| **Weighted RR** | Higher weight = more requests | Mixed capacity servers |\n",
    "| **Least Connections** | Route to server with fewest active connections | Long-lived connections |\n",
    "| **IP Hash** | Hash client IP to consistent server | Session affinity |\n",
    "| **Random** | Random server selection | Simple, stateless |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f105245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from bisect import bisect_right\n",
    "from collections import defaultdict\n",
    "\n",
    "class ConsistentHashing:\n",
    "    \"\"\"Consistent hashing for distributed load balancing.\"\"\"\n",
    "    \n",
    "    def __init__(self, replicas: int = 100):\n",
    "        self.replicas = replicas  # Virtual nodes per server\n",
    "        self.ring = []            # Sorted hash positions\n",
    "        self.nodes = {}           # Hash -> server mapping\n",
    "    \n",
    "    def _hash(self, key: str) -> int:\n",
    "        return int(hashlib.md5(key.encode()).hexdigest(), 16)\n",
    "    \n",
    "    def add_node(self, node: str):\n",
    "        \"\"\"Add a server with virtual nodes.\"\"\"\n",
    "        for i in range(self.replicas):\n",
    "            virtual_key = f\"{node}:{i}\"\n",
    "            hash_val = self._hash(virtual_key)\n",
    "            self.ring.append(hash_val)\n",
    "            self.nodes[hash_val] = node\n",
    "        self.ring.sort()\n",
    "    \n",
    "    def remove_node(self, node: str):\n",
    "        \"\"\"Remove a server and its virtual nodes.\"\"\"\n",
    "        for i in range(self.replicas):\n",
    "            virtual_key = f\"{node}:{i}\"\n",
    "            hash_val = self._hash(virtual_key)\n",
    "            self.ring.remove(hash_val)\n",
    "            del self.nodes[hash_val]\n",
    "    \n",
    "    def get_node(self, key: str) -> str:\n",
    "        \"\"\"Get the server responsible for a key.\"\"\"\n",
    "        if not self.ring:\n",
    "            return None\n",
    "        hash_val = self._hash(key)\n",
    "        idx = bisect_right(self.ring, hash_val) % len(self.ring)\n",
    "        return self.nodes[self.ring[idx]]\n",
    "\n",
    "# Demo\n",
    "ch = ConsistentHashing(replicas=50)\n",
    "for server in [\"server-1\", \"server-2\", \"server-3\"]:\n",
    "    ch.add_node(server)\n",
    "\n",
    "# Distribution test\n",
    "distribution = defaultdict(int)\n",
    "for i in range(1000):\n",
    "    key = f\"user:{i}\"\n",
    "    distribution[ch.get_node(key)] += 1\n",
    "\n",
    "print(\"Key Distribution:\")\n",
    "for server, count in sorted(distribution.items()):\n",
    "    print(f\"  {server}: {count} keys ({count/10:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e20b1e",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Caching Strategies\n",
    "\n",
    "### Cache-Aside (Lazy Loading)\n",
    "```\n",
    "┌──────┐    1. Get    ┌───────┐   2. Miss   ┌──────────┐\n",
    "│Client│ ──────────► │ Cache │ ──────────► │ Database │\n",
    "└──────┘             └───┬───┘             └────┬─────┘\n",
    "    ▲                    │                      │\n",
    "    │     4. Return      │    3. Return Data   │\n",
    "    └────────────────────┴──────────────────────┘\n",
    "           (+ Update Cache)\n",
    "```\n",
    "\n",
    "### Write-Through\n",
    "```\n",
    "┌──────┐   1. Write   ┌───────┐   2. Write   ┌──────────┐\n",
    "│Client│ ──────────► │ Cache │ ──────────► │ Database │\n",
    "└──────┘             └───────┘   (sync)     └──────────┘\n",
    "```\n",
    "\n",
    "### Write-Behind (Write-Back)\n",
    "```\n",
    "┌──────┐   1. Write   ┌───────┐  2. Async   ┌──────────┐\n",
    "│Client│ ──────────► │ Cache │ ─ ─ ─ ─ ─► │ Database │\n",
    "└──────┘  (returns)  └───────┘  (batched)  └──────────┘\n",
    "```\n",
    "\n",
    "| Strategy | Consistency | Latency | Data Loss Risk | Use Case |\n",
    "|----------|-------------|---------|----------------|----------|\n",
    "| **Cache-Aside** | Eventual | Read: Low on hit | Low | Read-heavy workloads |\n",
    "| **Write-Through** | Strong | Write: Higher | None | Critical data |\n",
    "| **Write-Behind** | Eventual | Write: Lowest | Possible | High write throughput |\n",
    "| **Read-Through** | Eventual | Read: Low | Low | Simplified app logic |\n",
    "\n",
    "### Cache Invalidation Strategies\n",
    "- **TTL (Time-to-Live)**: Expires after fixed duration\n",
    "- **Event-based**: Invalidate on data change\n",
    "- **Version-based**: Cache key includes version number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae4e7ab",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Database Scaling\n",
    "\n",
    "### Replication\n",
    "```\n",
    "                    ┌──────────────┐\n",
    "     Writes ──────► │   PRIMARY    │ ◄────── Reads\n",
    "                    └──────┬───────┘\n",
    "                           │ Replication\n",
    "              ┌────────────┼────────────┐\n",
    "              ▼            ▼            ▼\n",
    "        ┌──────────┐ ┌──────────┐ ┌──────────┐\n",
    "        │ REPLICA  │ │ REPLICA  │ │ REPLICA  │ ◄── Reads\n",
    "        └──────────┘ └──────────┘ └──────────┘\n",
    "```\n",
    "\n",
    "### Sharding (Horizontal Partitioning)\n",
    "```\n",
    "                    ┌─────────────────┐\n",
    "      Requests ───► │ Shard Router    │\n",
    "                    └────────┬────────┘\n",
    "                             │ Shard Key Routing\n",
    "              ┌──────────────┼──────────────┐\n",
    "              ▼              ▼              ▼\n",
    "        ┌──────────┐   ┌──────────┐   ┌──────────┐\n",
    "        │ Shard 1  │   │ Shard 2  │   │ Shard 3  │\n",
    "        │ Users A-H│   │ Users I-P│   │ Users Q-Z│\n",
    "        └──────────┘   └──────────┘   └──────────┘\n",
    "```\n",
    "\n",
    "| Approach | Pros | Cons | Best For |\n",
    "|----------|------|------|----------|\n",
    "| **Read Replicas** | Simple, read scaling | Write bottleneck, replication lag | Read-heavy apps |\n",
    "| **Sharding** | Write scaling, data locality | Complex queries, resharding pain | Large datasets |\n",
    "\n",
    "### Sharding Strategies\n",
    "- **Range-based**: Shard by value ranges (e.g., date, ID range)\n",
    "- **Hash-based**: Consistent hashing on shard key\n",
    "- **Directory-based**: Lookup table maps keys to shards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3d0909",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Message Queues & Event-Driven Architecture\n",
    "\n",
    "### Message Queue Pattern\n",
    "```\n",
    "┌──────────┐     ┌─────────────────────────┐     ┌──────────┐\n",
    "│ Producer │────►│     MESSAGE QUEUE       │────►│ Consumer │\n",
    "└──────────┘     │  ┌───┬───┬───┬───┬───┐  │     └──────────┘\n",
    "                 │  │msg│msg│msg│msg│msg│  │     ┌──────────┐\n",
    "┌──────────┐     │  └───┴───┴───┴───┴───┘  │────►│ Consumer │\n",
    "│ Producer │────►│                         │     └──────────┘\n",
    "└──────────┘     └─────────────────────────┘\n",
    "```\n",
    "\n",
    "### Pub/Sub Pattern\n",
    "```\n",
    "┌───────────┐              ┌───────────────┐\n",
    "│ Publisher │──── Topic ──►│   BROKER      │\n",
    "└───────────┘    \"orders\"  │               │\n",
    "                           │  ┌─────────┐  │     ┌────────────┐\n",
    "                           │  │Topic:   │──┼────►│Subscriber A│\n",
    "                           │  │\"orders\" │  │     └────────────┘\n",
    "                           │  └─────────┘  │     ┌────────────┐\n",
    "                           │               │────►│Subscriber B│\n",
    "                           └───────────────┘     └────────────┘\n",
    "```\n",
    "\n",
    "| Feature | Message Queue | Pub/Sub |\n",
    "|---------|---------------|---------|\n",
    "| **Delivery** | One consumer per message | All subscribers receive |\n",
    "| **Use Case** | Task distribution | Event broadcasting |\n",
    "| **Examples** | RabbitMQ, SQS | Kafka, Redis Pub/Sub |\n",
    "\n",
    "### Benefits\n",
    "- **Decoupling**: Services communicate without direct dependencies\n",
    "- **Buffering**: Handle traffic spikes gracefully\n",
    "- **Reliability**: Message persistence and retry mechanisms\n",
    "- **Scalability**: Add consumers independently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a94b712",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. CQRS & Event Sourcing\n",
    "\n",
    "### CQRS (Command Query Responsibility Segregation)\n",
    "```\n",
    "                         ┌──────────────────────────────────────┐\n",
    "                         │              APPLICATION             │\n",
    "                         └──────────────────────────────────────┘\n",
    "                                    │              │\n",
    "              Commands (Write)      │              │       Queries (Read)\n",
    "                    ┌───────────────┘              └───────────────┐\n",
    "                    ▼                                              ▼\n",
    "           ┌─────────────────┐                          ┌─────────────────┐\n",
    "           │  Command Model  │                          │   Query Model   │\n",
    "           │  (Write Store)  │ ─────── Sync ──────────► │  (Read Store)   │\n",
    "           │  Normalized     │                          │  Denormalized   │\n",
    "           └─────────────────┘                          └─────────────────┘\n",
    "```\n",
    "\n",
    "### Event Sourcing\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                      EVENT STORE                                │\n",
    "│  ┌────────┐  ┌────────┐  ┌────────┐  ┌────────┐  ┌────────┐    │\n",
    "│  │Created │─►│Updated │─►│Shipped │─►│Delivered│─►│ ...    │   │\n",
    "│  │Order   │  │Address │  │        │  │         │  │        │   │\n",
    "│  │t=1     │  │t=2     │  │t=3     │  │t=4      │  │        │   │\n",
    "│  └────────┘  └────────┘  └────────┘  └────────┘  └────────┘   │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "                              ▼ Replay Events\n",
    "                    ┌─────────────────────┐\n",
    "                    │   Current State     │\n",
    "                    │   (Materialized)    │\n",
    "                    └─────────────────────┘\n",
    "```\n",
    "\n",
    "| Pattern | Key Idea | Benefits | Challenges |\n",
    "|---------|----------|----------|------------|\n",
    "| **CQRS** | Separate read/write models | Optimized reads, scale independently | Eventual consistency |\n",
    "| **Event Sourcing** | Store events, not state | Full audit trail, temporal queries | Event schema evolution |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f68e86d",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Rate Limiting Algorithms\n",
    "\n",
    "```\n",
    "┌──────────────────────────────────────────────────────────────────┐\n",
    "│                    RATE LIMITING ALGORITHMS                      │\n",
    "├─────────────────┬───────────────────┬────────────────────────────┤\n",
    "│  Token Bucket   │  Leaky Bucket     │  Sliding Window Log        │\n",
    "│                 │                   │                            │\n",
    "│  ┌───────────┐  │  ┌───────────┐    │  [t1][t2][t3]...[tn]      │\n",
    "│  │● ● ● ●    │  │  │~~~~~~~~~│▼   │  └────── window ────────┘  │\n",
    "│  │  tokens   │  │  │  queue   │    │                            │\n",
    "│  └───────────┘  │  └──────────┘    │  Count requests in window  │\n",
    "│                 │                   │                            │\n",
    "│  Bursty traffic │  Smooth output    │  Precise, memory heavy     │\n",
    "└─────────────────┴───────────────────┴────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a170bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import deque\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class TokenBucket:\n",
    "    \"\"\"Token Bucket: Allows burst traffic up to bucket size.\"\"\"\n",
    "    capacity: int          # Max tokens\n",
    "    refill_rate: float     # Tokens per second\n",
    "    tokens: float = field(init=False)\n",
    "    last_refill: float = field(init=False)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.tokens = self.capacity\n",
    "        self.last_refill = time.time()\n",
    "    \n",
    "    def _refill(self):\n",
    "        now = time.time()\n",
    "        elapsed = now - self.last_refill\n",
    "        self.tokens = min(self.capacity, self.tokens + elapsed * self.refill_rate)\n",
    "        self.last_refill = now\n",
    "    \n",
    "    def allow_request(self, tokens: int = 1) -> bool:\n",
    "        self._refill()\n",
    "        if self.tokens >= tokens:\n",
    "            self.tokens -= tokens\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "@dataclass\n",
    "class LeakyBucket:\n",
    "    \"\"\"Leaky Bucket: Smooths output rate regardless of input bursts.\"\"\"\n",
    "    capacity: int          # Queue size\n",
    "    leak_rate: float       # Requests processed per second\n",
    "    queue: deque = field(default_factory=deque)\n",
    "    last_leak: float = field(init=False)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.last_leak = time.time()\n",
    "    \n",
    "    def _leak(self):\n",
    "        now = time.time()\n",
    "        elapsed = now - self.last_leak\n",
    "        leak_count = int(elapsed * self.leak_rate)\n",
    "        for _ in range(min(leak_count, len(self.queue))):\n",
    "            self.queue.popleft()\n",
    "        if leak_count > 0:\n",
    "            self.last_leak = now\n",
    "    \n",
    "    def allow_request(self) -> bool:\n",
    "        self._leak()\n",
    "        if len(self.queue) < self.capacity:\n",
    "            self.queue.append(time.time())\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "@dataclass\n",
    "class SlidingWindowLog:\n",
    "    \"\"\"Sliding Window Log: Precise rate limiting with request timestamps.\"\"\"\n",
    "    window_size: float     # Window in seconds\n",
    "    max_requests: int      # Max requests per window\n",
    "    timestamps: deque = field(default_factory=deque)\n",
    "    \n",
    "    def allow_request(self) -> bool:\n",
    "        now = time.time()\n",
    "        window_start = now - self.window_size\n",
    "        \n",
    "        # Remove expired timestamps\n",
    "        while self.timestamps and self.timestamps[0] < window_start:\n",
    "            self.timestamps.popleft()\n",
    "        \n",
    "        if len(self.timestamps) < self.max_requests:\n",
    "            self.timestamps.append(now)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "@dataclass \n",
    "class SlidingWindowCounter:\n",
    "    \"\"\"Sliding Window Counter: Memory-efficient approximation.\"\"\"\n",
    "    window_size: float\n",
    "    max_requests: int\n",
    "    current_count: int = 0\n",
    "    previous_count: int = 0\n",
    "    current_window_start: float = field(init=False)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.current_window_start = time.time()\n",
    "    \n",
    "    def allow_request(self) -> bool:\n",
    "        now = time.time()\n",
    "        elapsed = now - self.current_window_start\n",
    "        \n",
    "        # Rotate windows if needed\n",
    "        if elapsed >= self.window_size:\n",
    "            self.previous_count = self.current_count\n",
    "            self.current_count = 0\n",
    "            self.current_window_start = now\n",
    "            elapsed = 0\n",
    "        \n",
    "        # Weighted count from previous window\n",
    "        weight = 1 - (elapsed / self.window_size)\n",
    "        estimated = self.previous_count * weight + self.current_count\n",
    "        \n",
    "        if estimated < self.max_requests:\n",
    "            self.current_count += 1\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f97ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Compare rate limiters\n",
    "def test_rate_limiter(limiter, name: str, requests: int = 15):\n",
    "    \"\"\"Test rate limiter with burst of requests.\"\"\"\n",
    "    results = [limiter.allow_request() for _ in range(requests)]\n",
    "    allowed = sum(results)\n",
    "    print(f\"{name}: {allowed}/{requests} allowed\")\n",
    "    print(f\"  Pattern: {''.join(['✓' if r else '✗' for r in results])}\")\n",
    "\n",
    "print(\"=== Rate Limiter Comparison (10 req/sec limit, burst of 15) ===\\n\")\n",
    "\n",
    "test_rate_limiter(TokenBucket(capacity=10, refill_rate=10), \"Token Bucket\")\n",
    "test_rate_limiter(LeakyBucket(capacity=10, leak_rate=10), \"Leaky Bucket\")\n",
    "test_rate_limiter(SlidingWindowLog(window_size=1.0, max_requests=10), \"Sliding Window Log\")\n",
    "test_rate_limiter(SlidingWindowCounter(window_size=1.0, max_requests=10), \"Sliding Window Counter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1215e295",
   "metadata": {},
   "source": [
    "### Rate Limiting Comparison\n",
    "\n",
    "| Algorithm | Memory | Precision | Burst Handling | Use Case |\n",
    "|-----------|--------|-----------|----------------|----------|\n",
    "| **Token Bucket** | O(1) | Good | Allows bursts | API rate limiting |\n",
    "| **Leaky Bucket** | O(n) | Good | Smooths bursts | Traffic shaping |\n",
    "| **Sliding Window Log** | O(n) | Exact | No bursts | Strict limits |\n",
    "| **Sliding Window Counter** | O(1) | Approximate | Partial bursts | Scalable APIs |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975df13a",
   "metadata": {},
   "source": [
    "---\n",
    "## Quick Reference: Scalability Checklist\n",
    "\n",
    "```\n",
    "┌──────────────────────────────────────────────────────────────────┐\n",
    "│                 SCALABILITY DECISION TREE                        │\n",
    "├──────────────────────────────────────────────────────────────────┤\n",
    "│                                                                  │\n",
    "│  ┌─ Read Heavy? ──► Add Read Replicas + Caching                 │\n",
    "│  │                                                               │\n",
    "│  ├─ Write Heavy? ──► Sharding + Write-Behind Cache              │\n",
    "│  │                                                               │\n",
    "│  ├─ Spiky Traffic? ──► Auto-scaling + Message Queues            │\n",
    "│  │                                                               │\n",
    "│  ├─ Global Users? ──► CDN + Regional Deployments                │\n",
    "│  │                                                               │\n",
    "│  └─ Complex Queries? ──► CQRS + Materialized Views              │\n",
    "│                                                                  │\n",
    "└──────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Key Takeaways\n",
    "1. **Start simple** - Vertical scaling until you can't\n",
    "2. **Stateless services** - Enable horizontal scaling\n",
    "3. **Cache aggressively** - Reduce database load\n",
    "4. **Async processing** - Decouple with message queues\n",
    "5. **Measure first** - Profile before optimizing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
