{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reliability & Disaster Recovery\n",
    "\n",
    "Building systems that remain operational despite failures. This guide covers availability calculations, failure modes, redundancy strategies, and disaster recovery planning.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "| Term | Definition |\n",
    "|------|------------|\n",
    "| **Availability** | Percentage of time a system is operational |\n",
    "| **SLA** | Service Level Agreement - contractual uptime commitment |\n",
    "| **RTO** | Recovery Time Objective - max acceptable downtime |\n",
    "| **RPO** | Recovery Point Objective - max acceptable data loss (time) |\n",
    "| **MTBF** | Mean Time Between Failures |\n",
    "| **MTTR** | Mean Time To Recovery |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a98779",
   "metadata": {},
   "source": [
    "## Availability & SLA Calculations\n",
    "\n",
    "**Availability Formula:**\n",
    "$$\\text{Availability} = \\frac{\\text{MTBF}}{\\text{MTBF} + \\text{MTTR}} = \\frac{\\text{Uptime}}{\\text{Total Time}}$$\n",
    "\n",
    "**The \"Nines\" of Availability:**\n",
    "\n",
    "| Availability | Downtime/Year | Downtime/Month | Downtime/Week |\n",
    "|--------------|---------------|----------------|---------------|\n",
    "| 99% (two 9s) | 3.65 days | 7.31 hours | 1.68 hours |\n",
    "| 99.9% (three 9s) | 8.77 hours | 43.83 min | 10.08 min |\n",
    "| 99.99% (four 9s) | 52.60 min | 4.38 min | 1.01 min |\n",
    "| 99.999% (five 9s) | 5.26 min | 26.30 sec | 6.05 sec |\n",
    "\n",
    "**Composite Availability:**\n",
    "- **Series (all must work):** $A_{total} = A_1 \\times A_2 \\times ... \\times A_n$\n",
    "- **Parallel (any can work):** $A_{total} = 1 - (1-A_1) \\times (1-A_2) \\times ... \\times (1-A_n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7adeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Availability Calculations\n",
    "\n",
    "def availability_from_mtbf(mtbf_hours: float, mttr_hours: float) -> float:\n",
    "    \"\"\"Calculate availability from MTBF and MTTR.\"\"\"\n",
    "    return mtbf_hours / (mtbf_hours + mttr_hours)\n",
    "\n",
    "def downtime_per_year(availability: float) -> dict:\n",
    "    \"\"\"Calculate allowed downtime for a given availability.\"\"\"\n",
    "    minutes_per_year = 365.25 * 24 * 60\n",
    "    downtime_minutes = minutes_per_year * (1 - availability)\n",
    "    return {\n",
    "        \"availability\": f\"{availability * 100:.4f}%\",\n",
    "        \"downtime_per_year\": f\"{downtime_minutes:.2f} minutes ({downtime_minutes/60:.2f} hours)\",\n",
    "        \"downtime_per_month\": f\"{downtime_minutes/12:.2f} minutes\",\n",
    "        \"downtime_per_day\": f\"{downtime_minutes/365.25:.4f} minutes\"\n",
    "    }\n",
    "\n",
    "def series_availability(*availabilities: float) -> float:\n",
    "    \"\"\"Components in series - ALL must work (multiply).\"\"\"\n",
    "    result = 1.0\n",
    "    for a in availabilities:\n",
    "        result *= a\n",
    "    return result\n",
    "\n",
    "def parallel_availability(*availabilities: float) -> float:\n",
    "    \"\"\"Components in parallel - ANY can work (redundancy).\"\"\"\n",
    "    failure_prob = 1.0\n",
    "    for a in availabilities:\n",
    "        failure_prob *= (1 - a)\n",
    "    return 1 - failure_prob\n",
    "\n",
    "# Example: Web application with load balancer -> 2 app servers -> database\n",
    "print(\"=== Availability Calculations ===\")\n",
    "print(f\"\\nFour 9s downtime: {downtime_per_year(0.9999)}\")\n",
    "\n",
    "# Single points of failure\n",
    "lb_avail = 0.999\n",
    "app_avail = 0.99\n",
    "db_avail = 0.999\n",
    "\n",
    "# Without redundancy (series)\n",
    "single_path = series_availability(lb_avail, app_avail, db_avail)\n",
    "print(f\"\\nSingle path availability: {single_path:.6f} ({single_path*100:.4f}%)\")\n",
    "\n",
    "# With 2 redundant app servers\n",
    "redundant_apps = parallel_availability(app_avail, app_avail)\n",
    "with_redundancy = series_availability(lb_avail, redundant_apps, db_avail)\n",
    "print(f\"With 2 app servers: {with_redundancy:.6f} ({with_redundancy*100:.4f}%)\")\n",
    "\n",
    "# With 3 redundant app servers\n",
    "triple_apps = parallel_availability(app_avail, app_avail, app_avail)\n",
    "with_triple = series_availability(lb_avail, triple_apps, db_avail)\n",
    "print(f\"With 3 app servers: {with_triple:.6f} ({with_triple*100:.4f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73de989",
   "metadata": {},
   "source": [
    "## Failure Modes\n",
    "\n",
    "### Hardware Failures\n",
    "| Component | Typical MTBF | Mitigation |\n",
    "|-----------|--------------|------------|\n",
    "| HDD | 300K-1M hours | RAID, replication |\n",
    "| SSD | 1-2M hours | Redundancy, backups |\n",
    "| Server | 50K-100K hours | Clustering, spare parts |\n",
    "| Network Switch | 200K+ hours | Redundant paths |\n",
    "| Power Supply | 100K+ hours | Dual PSU, UPS |\n",
    "\n",
    "### Software Failures\n",
    "- **Memory leaks** → Graceful restarts, memory limits\n",
    "- **Deadlocks** → Timeouts, lock ordering\n",
    "- **Resource exhaustion** → Rate limiting, circuit breakers\n",
    "- **Configuration errors** → GitOps, validation, canary deployments\n",
    "- **Dependency failures** → Fallbacks, graceful degradation\n",
    "\n",
    "### Network Failures\n",
    "- **Partition** → CAP theorem considerations\n",
    "- **Latency spikes** → Timeouts, async processing\n",
    "- **DNS failures** → Multiple DNS providers, caching\n",
    "- **BGP issues** → Multi-region, anycast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a2cb86",
   "metadata": {},
   "source": [
    "## Redundancy Strategies\n",
    "\n",
    "### Active-Active\n",
    "```\n",
    "┌─────────────┐    ┌─────────────┐\n",
    "│  Server A   │◄──►│  Server B   │   Both handle traffic\n",
    "│  (Active)   │    │  (Active)   │   Load balanced\n",
    "└─────────────┘    └─────────────┘\n",
    "```\n",
    "✅ Full capacity utilization, instant failover  \n",
    "❌ Complex state synchronization, split-brain risk\n",
    "\n",
    "### Active-Passive (Hot Standby)\n",
    "```\n",
    "┌─────────────┐    ┌─────────────┐\n",
    "│  Server A   │───►│  Server B   │   B receives updates\n",
    "│  (Active)   │    │  (Standby)  │   Ready to take over\n",
    "└─────────────┘    └─────────────┘\n",
    "```\n",
    "✅ Simple, no split-brain  \n",
    "❌ Wasted capacity, failover delay\n",
    "\n",
    "### N+1 / N+2 Redundancy\n",
    "- **N+1**: One spare for N active (e.g., 4 servers, need 3 for load)\n",
    "- **N+2**: Two spares (handles maintenance + failure simultaneously)\n",
    "\n",
    "### Geographic Redundancy\n",
    "| Pattern | Latency | Cost | RPO |\n",
    "|---------|---------|------|-----|\n",
    "| Same rack | <1ms | Low | 0 |\n",
    "| Same datacenter | 1-5ms | Medium | 0 |\n",
    "| Same region | 5-20ms | Medium | Seconds |\n",
    "| Cross-region | 50-200ms | High | Minutes |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbd71b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RTO/RPO and Backup Strategy Calculator\n",
    "\n",
    "def calculate_data_loss(rpo_hours: float, write_rate_mb_per_hour: float) -> float:\n",
    "    \"\"\"Calculate maximum data loss in MB based on RPO.\"\"\"\n",
    "    return rpo_hours * write_rate_mb_per_hour\n",
    "\n",
    "def calculate_backup_frequency(rpo_hours: float, safety_margin: float = 0.8) -> float:\n",
    "    \"\"\"Calculate required backup frequency to meet RPO.\"\"\"\n",
    "    return rpo_hours * safety_margin  # Back up more frequently than RPO\n",
    "\n",
    "def estimate_recovery_time(data_size_gb: float, restore_speed_mbps: float, \n",
    "                           setup_time_min: float = 30) -> float:\n",
    "    \"\"\"Estimate recovery time in minutes.\"\"\"\n",
    "    data_mb = data_size_gb * 1024\n",
    "    transfer_time_sec = (data_mb * 8) / restore_speed_mbps\n",
    "    return setup_time_min + (transfer_time_sec / 60)\n",
    "\n",
    "def disaster_recovery_tiers():\n",
    "    \"\"\"Common DR tier definitions.\"\"\"\n",
    "    return {\n",
    "        \"Tier 1 - Mission Critical\": {\"RTO\": \"< 1 hour\", \"RPO\": \"< 15 min\", \"Strategy\": \"Active-Active multi-region\"},\n",
    "        \"Tier 2 - Business Critical\": {\"RTO\": \"< 4 hours\", \"RPO\": \"< 1 hour\", \"Strategy\": \"Hot standby\"},\n",
    "        \"Tier 3 - Important\": {\"RTO\": \"< 24 hours\", \"RPO\": \"< 4 hours\", \"Strategy\": \"Warm standby\"},\n",
    "        \"Tier 4 - Non-Critical\": {\"RTO\": \"< 72 hours\", \"RPO\": \"< 24 hours\", \"Strategy\": \"Cold backup\"}\n",
    "    }\n",
    "\n",
    "print(\"=== Disaster Recovery Planning ===\")\n",
    "print(\"\\nDR Tiers:\")\n",
    "for tier, config in disaster_recovery_tiers().items():\n",
    "    print(f\"  {tier}: RTO {config['RTO']}, RPO {config['RPO']} -> {config['Strategy']}\")\n",
    "\n",
    "# Example: E-commerce database\n",
    "print(\"\\n=== E-commerce Database Example ===\")\n",
    "rpo = 1  # 1 hour RPO\n",
    "write_rate = 500  # 500 MB/hour of transactions\n",
    "db_size = 500  # 500 GB database\n",
    "restore_speed = 1000  # 1 Gbps restore speed\n",
    "\n",
    "max_loss = calculate_data_loss(rpo, write_rate)\n",
    "backup_freq = calculate_backup_frequency(rpo)\n",
    "recovery_time = estimate_recovery_time(db_size, restore_speed)\n",
    "\n",
    "print(f\"RPO: {rpo} hour -> Max data loss: {max_loss} MB\")\n",
    "print(f\"Recommended backup frequency: Every {backup_freq:.1f} hours\")\n",
    "print(f\"Estimated recovery time: {recovery_time:.1f} minutes ({recovery_time/60:.2f} hours)\")\n",
    "print(f\"\\n⚠️  If RTO < {recovery_time/60:.2f} hours, need hot standby or replication!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278eb1b1",
   "metadata": {},
   "source": [
    "## Backup Strategies\n",
    "\n",
    "### 3-2-1 Rule\n",
    "- **3** copies of data\n",
    "- **2** different storage types (disk, tape, cloud)\n",
    "- **1** offsite copy\n",
    "\n",
    "### Backup Types\n",
    "\n",
    "| Type | Description | Restore Time | Storage |\n",
    "|------|-------------|--------------|----------|\n",
    "| **Full** | Complete copy | Fast | High |\n",
    "| **Incremental** | Changes since last backup | Slow (chain) | Low |\n",
    "| **Differential** | Changes since last full | Medium | Medium |\n",
    "| **Continuous (CDP)** | Real-time replication | Instant | High |\n",
    "\n",
    "### Database Backup Strategies\n",
    "```\n",
    "┌─────────────────────────────────────────────────────┐\n",
    "│  Sunday    Mon   Tue   Wed   Thu   Fri   Sat       │\n",
    "│  [FULL] → [Inc] → [Inc] → [Inc] → [Inc] → [Inc] → [Inc]\n",
    "│           ↑       ↑       ↑       ↑       ↑       ↑\n",
    "│           └───────┴───────┴───────┴───────┴───────┘\n",
    "│                   Transaction Log Backups (hourly)\n",
    "└─────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d2054d",
   "metadata": {},
   "source": [
    "## Failover Patterns\n",
    "\n",
    "### DNS Failover\n",
    "```\n",
    "User → DNS (health check) → Primary OK? → Primary Server\n",
    "                         → Primary DOWN? → Secondary Server\n",
    "```\n",
    "⚠️ **Limitation**: DNS TTL causes propagation delay\n",
    "\n",
    "### Load Balancer Failover\n",
    "```\n",
    "              ┌──► Server 1 (healthy) ✓\n",
    "User → LB ───┼──► Server 2 (healthy) ✓\n",
    "              └──► Server 3 (failed)  ✗ (removed from pool)\n",
    "```\n",
    "\n",
    "### Database Failover\n",
    "\n",
    "| Pattern | Failover Time | Data Loss | Complexity |\n",
    "|---------|---------------|-----------|------------|\n",
    "| Manual | Minutes-Hours | Possible | Low |\n",
    "| Automated (leader election) | Seconds | Minimal | Medium |\n",
    "| Multi-master | Zero | Zero | High |\n",
    "\n",
    "### Circuit Breaker Pattern\n",
    "```\n",
    "CLOSED ──(failures > threshold)──► OPEN\n",
    "   ▲                                 │\n",
    "   │                          (timeout)\n",
    "   │                                 ▼\n",
    "   └────(success)──── HALF-OPEN ◄───┘\n",
    "                      (test request)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc04941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Circuit Breaker Implementation Example\n",
    "import time\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "class CircuitState(Enum):\n",
    "    CLOSED = \"closed\"      # Normal operation\n",
    "    OPEN = \"open\"          # Failing, reject requests\n",
    "    HALF_OPEN = \"half_open\"  # Testing recovery\n",
    "\n",
    "@dataclass\n",
    "class CircuitBreaker:\n",
    "    failure_threshold: int = 5\n",
    "    recovery_timeout: float = 30.0\n",
    "    success_threshold: int = 3\n",
    "    \n",
    "    state: CircuitState = field(default=CircuitState.CLOSED)\n",
    "    failures: int = field(default=0)\n",
    "    successes: int = field(default=0)\n",
    "    last_failure_time: float = field(default=0)\n",
    "    \n",
    "    def can_execute(self) -> bool:\n",
    "        if self.state == CircuitState.CLOSED:\n",
    "            return True\n",
    "        elif self.state == CircuitState.OPEN:\n",
    "            if time.time() - self.last_failure_time >= self.recovery_timeout:\n",
    "                self.state = CircuitState.HALF_OPEN\n",
    "                self.successes = 0\n",
    "                return True\n",
    "            return False\n",
    "        else:  # HALF_OPEN\n",
    "            return True\n",
    "    \n",
    "    def record_success(self):\n",
    "        if self.state == CircuitState.HALF_OPEN:\n",
    "            self.successes += 1\n",
    "            if self.successes >= self.success_threshold:\n",
    "                self.state = CircuitState.CLOSED\n",
    "                self.failures = 0\n",
    "        elif self.state == CircuitState.CLOSED:\n",
    "            self.failures = 0\n",
    "    \n",
    "    def record_failure(self):\n",
    "        self.failures += 1\n",
    "        self.last_failure_time = time.time()\n",
    "        if self.state == CircuitState.HALF_OPEN:\n",
    "            self.state = CircuitState.OPEN\n",
    "        elif self.failures >= self.failure_threshold:\n",
    "            self.state = CircuitState.OPEN\n",
    "\n",
    "# Simulate circuit breaker behavior\n",
    "cb = CircuitBreaker(failure_threshold=3, recovery_timeout=5)\n",
    "\n",
    "print(\"=== Circuit Breaker Simulation ===\")\n",
    "events = [(\"success\", True), (\"failure\", False), (\"failure\", False), \n",
    "          (\"failure\", False), (\"attempt\", None), (\"wait_recovery\", None)]\n",
    "\n",
    "for event, success in events:\n",
    "    if event == \"wait_recovery\":\n",
    "        print(f\"  ... waiting {cb.recovery_timeout}s for recovery timeout ...\")\n",
    "        cb.last_failure_time = time.time() - cb.recovery_timeout - 1  # Simulate wait\n",
    "    elif event == \"attempt\":\n",
    "        can_exec = cb.can_execute()\n",
    "        print(f\"  Attempt: can_execute={can_exec}, state={cb.state.value}\")\n",
    "    else:\n",
    "        if cb.can_execute():\n",
    "            if success:\n",
    "                cb.record_success()\n",
    "            else:\n",
    "                cb.record_failure()\n",
    "        print(f\"  {event}: state={cb.state.value}, failures={cb.failures}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300d4935",
   "metadata": {},
   "source": [
    "## Chaos Engineering Basics\n",
    "\n",
    "**Principle**: Proactively inject failures to discover weaknesses before they cause outages.\n",
    "\n",
    "### Chaos Engineering Process\n",
    "1. **Hypothesize** steady-state behavior\n",
    "2. **Introduce** realistic failure (smallest blast radius first)\n",
    "3. **Observe** system behavior\n",
    "4. **Learn** and improve resilience\n",
    "\n",
    "### Common Experiments\n",
    "\n",
    "| Experiment | Simulates | Tools |\n",
    "|------------|-----------|-------|\n",
    "| Kill process/container | Crash | `kill -9`, Chaos Monkey |\n",
    "| Network latency | Slow network | `tc netem`, Toxiproxy |\n",
    "| Packet loss | Unreliable network | `tc netem`, Chaos Mesh |\n",
    "| CPU stress | Resource contention | `stress-ng` |\n",
    "| Disk full | Storage failure | `fallocate` |\n",
    "| AZ/Region failure | Cloud outage | AWS FIS, Gremlin |\n",
    "| DNS failure | Resolution issues | Block DNS, Chaos Mesh |\n",
    "\n",
    "### Chaos Maturity Model\n",
    "```\n",
    "Level 0: No chaos testing\n",
    "Level 1: Manual experiments in staging\n",
    "Level 2: Automated experiments in staging\n",
    "Level 3: Automated experiments in production (off-peak)\n",
    "Level 4: Continuous chaos in production (GameDay ready)\n",
    "```\n",
    "\n",
    "### Key Metrics to Monitor\n",
    "- Error rates and latency percentiles\n",
    "- Service availability and SLO burn rate\n",
    "- Cascade failures across services\n",
    "- Recovery time after fault injection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
